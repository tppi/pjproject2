diff --git a/aconfigure b/aconfigure
index 7faf6e2..b9251f0 100755
--- a/aconfigure
+++ b/aconfigure
@@ -622,6 +622,10 @@ ac_subst_vars='LTLIBOBJS
 LIBOBJS
 ac_main_obj
 ac_host
+ac_webrtc_aec3_ldflags
+ac_webrtc_aec3_cflags
+ac_webrtc_aec3_instset
+ac_no_webrtc_aec3
 ac_webrtc_ldflags
 ac_webrtc_cflags
 ac_webrtc_instset
@@ -693,6 +697,7 @@ ac_pa_cflags
 ac_external_pa
 ac_pjmedia_snd
 ac_pjmedia_resample
+ac_external_webrtc_aec3
 ac_external_webrtc
 ac_external_yuv
 ac_srtp_shutdown_present
@@ -799,6 +804,7 @@ with_external_gsm
 with_external_srtp
 with_external_yuv
 with_external_webrtc
+with_external_webrtc_aec3
 enable_resample
 enable_sound
 with_external_pa
@@ -846,6 +852,7 @@ with_bcg729
 enable_bcg729
 enable_libyuv
 enable_libwebrtc
+enable_libwebrtc_aec3
 '
       ac_precious_vars='build_alias
 host_alias
@@ -1521,6 +1528,7 @@ Optional Features:
   --disable-bcg729        Disable bcg729 (default: not disabled)
   --disable-libyuv        Exclude libyuv in the build
   --disable-libwebrtc     Exclude libwebrtc in the build
+  --enable-libwebrtc-aec3 Build libwebrtc-aec3 that's included in PJSIP
 
 Optional Packages:
   --with-PACKAGE[=ARG]    use PACKAGE [ARG=yes]
@@ -1550,6 +1558,12 @@ Optional Packages:
                           make sure that webrtc is accessible to use (hint:
                           use CFLAGS and LDFLAGS env var to set the
                           include/lib paths)
+  --with-external-webrtc-aec3
+                          Use external webrtc AEC3 development files, not the
+                          one in "third_party" directory. When this option is
+                          set, make sure that webrtc is accessible to use
+                          (hint: use CFLAGS and LDFLAGS env var to set the
+                          include/lib paths)
   --with-external-pa      Use external PortAudio development files. When this
                           option is set, make sure that PortAudio is
                           accessible to use (hint: use CFLAGS and LDFLAGS env
@@ -6354,6 +6368,44 @@ fi
 
 
 
+ac_external_webrtc_aec3=0
+
+
+# Check whether --with-external-webrtc-aec3 was given.
+if test "${with_external_webrtc_aec3+set}" = set; then :
+  withval=$with_external_webrtc_aec3;
+	if test "x$with_external_webrtc_aec3" != "xno"; then
+		# Test webrtc AEC3 installation
+		{ $as_echo "$as_me:${as_lineno-$LINENO}: checking if external webrtc AEC3 is installed" >&5
+$as_echo_n "checking if external webrtc AEC3 is installed... " >&6; }
+		cat confdefs.h - <<_ACEOF >conftest.$ac_ext
+/* end confdefs.h.  */
+#include "modules/audio_processing/aec3/echo_canceller3.h"
+
+int
+main ()
+{
+EchoCanceller3 ec(EchoCanceller3Config(), 16000, 1, 1);
+  ;
+  return 0;
+}
+_ACEOF
+if ac_fn_c_try_compile "$LINENO"; then :
+  { $as_echo "$as_me:${as_lineno-$LINENO}: result: yes!!" >&5
+$as_echo "yes!!" >&6; }
+				   ac_external_webrtc_aec3="1"
+
+else
+  as_fn_error $? "Unable to use external webrtc AEC3. If webrtc development files are not available in the default locations, use CFLAGS and LDFLAGS env var to set the include/lib paths" "$LINENO" 5
+fi
+rm -f core conftest.err conftest.$ac_objext conftest.$ac_ext
+	fi
+
+
+fi
+
+
+
 ac_pjmedia_resample=libresample
 
 # Check whether --enable-resample was given.
@@ -9187,6 +9239,141 @@ fi
 
 
 
+
+
+# Check whether --enable-libwebrtc_aec3 was given.
+if test "${enable_libwebrtc_aec3+set}" = set; then :
+  enableval=$enable_libwebrtc_aec3;
+           	if test "$enable_libwebrtc_aec3" = "yes"; then
+		  # Test if we can build WebRtc AEC3
+		  { $as_echo "$as_me:${as_lineno-$LINENO}: checking if WebRtc AEC3 can be compiled with C++17" >&5
+$as_echo_n "checking if WebRtc AEC3 can be compiled with C++17... " >&6; }
+
+		  SAVED_CXXFLAGS="$CXXFLAGS"
+		  CXXFLAGS="$CXXFLAGS -std=c++17"
+
+		  ac_ext=cpp
+ac_cpp='$CXXCPP $CPPFLAGS'
+ac_compile='$CXX -c $CXXFLAGS $CPPFLAGS conftest.$ac_ext >&5'
+ac_link='$CXX -o conftest$ac_exeext $CXXFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'
+ac_compiler_gnu=$ac_cv_cxx_compiler_gnu
+
+		  cat confdefs.h - <<_ACEOF >conftest.$ac_ext
+/* end confdefs.h.  */
+
+int
+main ()
+{
+
+  ;
+  return 0;
+}
+_ACEOF
+if ac_fn_cxx_try_link "$LINENO"; then :
+  { $as_echo "$as_me:${as_lineno-$LINENO}: result: yes" >&5
+$as_echo "yes" >&6; }
+		   LD="$CXX"
+else
+  { $as_echo "$as_me:${as_lineno-$LINENO}: result: no" >&5
+$as_echo "no" >&6; }
+		   CXXFLAGS="$SAVED_CXXFLAGS"
+		   ac_no_webrtc_aec3=1
+		   $as_echo "#define PJMEDIA_HAS_LIBWEBRTC_AEC3 0" >>confdefs.h
+
+fi
+rm -f core conftest.err conftest.$ac_objext \
+    conftest$ac_exeext conftest.$ac_ext
+		  ac_ext=c
+ac_cpp='$CPP $CPPFLAGS'
+ac_compile='$CC -c $CFLAGS $CPPFLAGS conftest.$ac_ext >&5'
+ac_link='$CC -o conftest$ac_exeext $CFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'
+ac_compiler_gnu=$ac_cv_c_compiler_gnu
+
+
+		  case $target in
+		      *-apple-darwin_ios*)
+			case $target in
+			    arm64*)
+				ac_webrtc_aec3_instset=neon
+				ac_webrtc_aec3_cflags="-DWEBRTC_ARCH_ARM64"
+			    	;;
+			    *arm*)
+				ac_webrtc_aec3_instset=neon
+			    	;;
+			    *)
+				ac_webrtc_aec3_instset=sse2
+			    	;;
+			esac
+		        ;;
+		      *android*)
+			case $TARGET_ABI in
+			    armeabi-v7a)
+				ac_webrtc_aec3_instset=neon
+				ac_webrtc_aec3_cflags="-mfloat-abi=softfp -mfpu=neon"
+			    	;;
+			    armeabi)
+				ac_webrtc_aec3_instset=neon
+				ac_webrtc_aec3_cflags="-mthumb -mfloat-abi=softfp -mfpu=neon -march=armv7"
+			    	;;
+			    arm64*)
+				ac_webrtc_aec3_instset=neon
+				ac_webrtc_aec3_cflags="-DWEBRTC_ARCH_ARM64"
+			    	;;
+			    x86*)
+			    	ac_webrtc_aec3_instset=sse2
+			    	;;
+			esac
+		        ;;
+		     *mingw* | *cygw*)
+			ac_webrtc_aec3_instset=sse2
+			ac_webrtc_aec3_cflags="-msse2"
+			;;
+		     *win32* | *w32* | *darwin* | *linux*)
+                         case $target in
+                             armv7l*gnueabihf)
+                                 ac_webrtc_aec3_instset=neon
+                                 ac_webrtc_aec3_cflags="-DWEBRTC_ARCH_ARMV7 -mfloat-abi=hard -mfpu=neon"
+                                 ;;
+			     arm-apple-darwin*)
+				 ac_webrtc_aec3_instset=neon
+				 ac_webrtc_aec3_cflags="-DWEBRTC_ARCH_ARM64"
+			    	 ;;
+                             *)
+                                 ac_webrtc_aec3_instset=sse2
+                                 ;;
+                         esac
+                         case $target in
+                             *darwin*)
+                                 ac_webrtc_aec3_cflags+=" -DWEBRTC_MAC=1"
+                                 ;;
+                         esac
+			;;
+		     *)
+			;;
+		  esac
+		  ac_webrtc_aec3_cflags+=" -DWEBRTC_APM_DEBUG_DUMP=0 -DWEBRTC_POSIX=1"
+           	else
+           	  ac_no_webrtc_aec3=1
+           	  $as_echo "#define PJMEDIA_HAS_LIBWEBRTC_AEC3 0" >>confdefs.h
+
+             	  { $as_echo "$as_me:${as_lineno-$LINENO}: result: Checking if libwebrtc-aec3 is enabled...no" >&5
+$as_echo "Checking if libwebrtc-aec3 is enabled...no" >&6; }
+          	fi
+
+
+else
+  ac_no_webrtc_aec3=1
+	       $as_echo "#define PJMEDIA_HAS_LIBWEBRTC_AEC3 0" >>confdefs.h
+
+	       { $as_echo "$as_me:${as_lineno-$LINENO}: result: Checking if libwebrtc-aec3 is enabled...no" >&5
+$as_echo "Checking if libwebrtc-aec3 is enabled...no" >&6; }
+
+fi
+
+
+
+
+
 { $as_echo "$as_me:${as_lineno-$LINENO}: checking if select() needs correct nfds" >&5
 $as_echo_n "checking if select() needs correct nfds... " >&6; }
 case $target in
diff --git a/aconfigure.ac b/aconfigure.ac
index 35d5770..c9129b9 100644
--- a/aconfigure.ac
+++ b/aconfigure.ac
@@ -673,6 +673,27 @@ AC_ARG_WITH(external-webrtc,
     )
 
 
+dnl # Use external webrtc AEC3 installation
+AC_SUBST(ac_external_webrtc_aec3,0)
+AC_ARG_WITH(external-webrtc-aec3,
+    AS_HELP_STRING([--with-external-webrtc-aec3],
+		   [Use external webrtc AEC3 development files, not the one in "third_party" directory. When this option is set, make sure that webrtc is accessible to use (hint: use CFLAGS and LDFLAGS env var to set the include/lib paths)]),
+    [
+	if test "x$with_external_webrtc_aec3" != "xno"; then
+		# Test webrtc AEC3 installation
+		AC_MSG_CHECKING([if external webrtc AEC3 is installed])
+		AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[#include "modules/audio_processing/aec3/echo_canceller3.h"
+		]],
+						  [EchoCanceller3 ec(EchoCanceller3Config(), 16000, 1, 1);])],
+				  [AC_MSG_RESULT(yes!!)
+				   ac_external_webrtc_aec3="1"
+				   ],
+				  [AC_MSG_ERROR([Unable to use external webrtc AEC3. If webrtc development files are not available in the default locations, use CFLAGS and LDFLAGS env var to set the include/lib paths])])
+	fi
+    ]
+    )
+
+
 dnl # Resample implementation
 AC_SUBST(ac_pjmedia_resample,libresample)
 AC_ARG_ENABLE(resample,
@@ -2184,6 +2205,106 @@ AC_ARG_ENABLE(libwebrtc,
 	      ])
 
 
+dnl # Include webrtc AEC3
+AC_SUBST(ac_no_webrtc_aec3)
+AC_SUBST(ac_webrtc_aec3_instset)
+AC_SUBST(ac_webrtc_aec3_cflags)
+AC_SUBST(ac_webrtc_aec3_ldflags)
+AC_ARG_ENABLE(libwebrtc_aec3,
+	      AS_HELP_STRING([--enable-libwebrtc-aec3],
+			     [Build libwebrtc-aec3 that's included in PJSIP]),
+	      [
+           	if test "$enable_libwebrtc_aec3" = "yes"; then
+		  # Test if we can build WebRtc AEC3
+		  AC_MSG_CHECKING([if WebRtc AEC3 can be compiled with C++17])
+	
+		  SAVED_CXXFLAGS="$CXXFLAGS"
+		  CXXFLAGS="$CXXFLAGS -std=c++17"
+		  
+		  AC_LANG_PUSH([C++])
+		  AC_LINK_IFELSE([AC_LANG_PROGRAM([[]], [])],
+		  [AC_MSG_RESULT(yes)
+		   LD="$CXX"],
+		  [AC_MSG_RESULT(no)
+		   CXXFLAGS="$SAVED_CXXFLAGS"
+		   ac_no_webrtc_aec3=1
+		   AC_DEFINE(PJMEDIA_HAS_LIBWEBRTC_AEC3,0)])
+		  AC_LANG_POP([C++])
+
+		  case $target in
+		      *-apple-darwin_ios*)
+			case $target in
+			    arm64*)
+				ac_webrtc_aec3_instset=neon
+				ac_webrtc_aec3_cflags="-DWEBRTC_ARCH_ARM64"
+			    	;;
+			    *arm*)
+				ac_webrtc_aec3_instset=neon
+			    	;;
+			    *)
+				ac_webrtc_aec3_instset=sse2
+			    	;;
+			esac
+		        ;;
+		      *android*)
+			case $TARGET_ABI in
+			    armeabi-v7a)
+				ac_webrtc_aec3_instset=neon
+				ac_webrtc_aec3_cflags="-mfloat-abi=softfp -mfpu=neon"
+			    	;;
+			    armeabi)
+				ac_webrtc_aec3_instset=neon
+				ac_webrtc_aec3_cflags="-mthumb -mfloat-abi=softfp -mfpu=neon -march=armv7"
+			    	;;
+			    arm64*)
+				ac_webrtc_aec3_instset=neon
+				ac_webrtc_aec3_cflags="-DWEBRTC_ARCH_ARM64"
+			    	;;
+			    x86*)
+			    	ac_webrtc_aec3_instset=sse2
+			    	;;
+			esac
+		        ;;
+		     *mingw* | *cygw*)
+			ac_webrtc_aec3_instset=sse2
+			ac_webrtc_aec3_cflags="-msse2"
+			;;
+		     *win32* | *w32* | *darwin* | *linux*)
+                         case $target in
+                             armv7l*gnueabihf)
+                                 ac_webrtc_aec3_instset=neon
+                                 ac_webrtc_aec3_cflags="-DWEBRTC_ARCH_ARMV7 -mfloat-abi=hard -mfpu=neon"
+                                 ;;
+			     arm-apple-darwin*)
+				 ac_webrtc_aec3_instset=neon
+				 ac_webrtc_aec3_cflags="-DWEBRTC_ARCH_ARM64"
+			    	 ;;
+                             *)
+                                 ac_webrtc_aec3_instset=sse2
+                                 ;;
+                         esac
+                         case $target in
+                             *darwin*)
+                                 ac_webrtc_aec3_cflags+=" -DWEBRTC_MAC=1"
+                                 ;;
+                         esac
+			;;
+		     *)
+			;;
+		  esac
+		  ac_webrtc_aec3_cflags+=" -DWEBRTC_APM_DEBUG_DUMP=0 -DWEBRTC_POSIX=1"
+           	else
+           	  ac_no_webrtc_aec3=1
+           	  AC_DEFINE(PJMEDIA_HAS_LIBWEBRTC_AEC3,0)
+             	  AC_MSG_RESULT([Checking if libwebrtc-aec3 is enabled...no])
+          	fi
+	      ],
+	      [ac_no_webrtc_aec3=1
+	       AC_DEFINE(PJMEDIA_HAS_LIBWEBRTC_AEC3,0)
+	       AC_MSG_RESULT([Checking if libwebrtc-aec3 is enabled...no])
+	      ])
+
+
 dnl ##########################################
 dnl #
 dnl # MANUAL CONFIG
diff --git a/build.mak.in b/build.mak.in
index d6c954d..697c3e2 100644
--- a/build.mak.in
+++ b/build.mak.in
@@ -152,6 +152,20 @@ endif
 endif
 endif
 
+ifneq (@ac_no_webrtc_aec3@,1)
+ifeq (@ac_external_webrtc_aec3@,1)
+APP_THIRD_PARTY_EXT += -lwebrtc-aec3
+else
+APP_THIRD_PARTY_LIB_FILES += $(PJ_DIR)/third_party/lib/libwebrtc-aec3-$(LIB_SUFFIX)
+ifeq ($(PJ_SHARED_LIBRARIES),)
+APP_THIRD_PARTY_LIBS += -lwebrtc-aec3-$(TARGET_NAME)
+else
+APP_THIRD_PARTY_LIBS += -lwebrtc-aec3
+APP_THIRD_PARTY_LIB_FILES += $(PJ_DIR)/third_party/lib/libwebrtc-aec3.$(SHLIB_SUFFIX).$(PJ_VERSION_MAJOR) $(PJ_DIR)/third_party/lib/libwebrtc.$(SHLIB_SUFFIX)
+endif
+endif
+endif
+
 
 # Additional flags
 @ac_build_mak_vars@
diff --git a/build/rules.mak b/build/rules.mak
index f2ef26b..eeb6996 100644
--- a/build/rules.mak
+++ b/build/rules.mak
@@ -228,8 +228,8 @@ depend:
 	for F in $(FULL_SRCS); do \
 	   if test -f $$F; then \
 	     echo "$(OBJDIR)/" | tr -d '\n' >> $(DEP_FILE); \
-	     if echo $$F | grep -q .cpp$$; then \
-		dep="$(CC) -M $(DEPCXXFLAGS) $$F"; \
+	     if echo $$F | grep -q "\.c[c|pp]"; then \
+		dep="$(CXX) -M $(DEPCXXFLAGS) $$F"; \
 	     else \
 		dep="$(CC) -M $(DEPCFLAGS) $$F"; \
 	     fi; \
diff --git a/pjmedia/build/Makefile b/pjmedia/build/Makefile
index 700847d..130b63f 100644
--- a/pjmedia/build/Makefile
+++ b/pjmedia/build/Makefile
@@ -62,8 +62,8 @@ export PJMEDIA_OBJS += $(OS_OBJS) $(M_OBJS) $(CC_OBJS) $(HOST_OBJS) \
 			bidirectional.o clock_thread.o codec.o conference.o \
 			conf_switch.o converter.o  converter_libswscale.o converter_libyuv.o \
 			delaybuf.o echo_common.o \
-			echo_port.o echo_suppress.o echo_webrtc.o endpoint.o errno.o \
-			event.o format.o ffmpeg_util.o \
+			echo_port.o echo_suppress.o echo_webrtc.o echo_webrtc_aec3.o \
+			endpoint.o errno.o event.o format.o ffmpeg_util.o \
 			g711.o jbuf.o master_port.o mem_capture.o mem_player.o \
 			null_port.o plc_common.o port.o splitcomb.o \
 			resample_resample.o resample_libsamplerate.o resample_speex.o \
diff --git a/pjmedia/build/os-auto.mak.in b/pjmedia/build/os-auto.mak.in
index 64377f6..8b26a16 100644
--- a/pjmedia/build/os-auto.mak.in
+++ b/pjmedia/build/os-auto.mak.in
@@ -226,6 +226,19 @@ export CFLAGS += -I$(THIRD_PARTY)/webrtc/src
 endif
 endif
 
+#
+# libwebrtc-aec3
+#
+ifeq (@ac_no_webrtc_aec3@,1)
+export CFLAGS += -DPJMEDIA_HAS_WEBRTC_AEC3=0
+else
+export CFLAGS += -DPJMEDIA_HAS_WEBRTC_AEC3=1 @ac_webrtc_aec3_cflags@
+
+ifeq (@ac_external_webrtc@,0)
+export CFLAGS += -I$(THIRD_PARTY)/webrtc_aec3/src
+endif
+endif
+
 
 #
 # MacOSX specific
diff --git a/pjmedia/include/pjmedia/echo.h b/pjmedia/include/pjmedia/echo.h
index c808a61..2f53d6b 100644
--- a/pjmedia/include/pjmedia/echo.h
+++ b/pjmedia/include/pjmedia/echo.h
@@ -59,34 +59,36 @@ typedef enum pjmedia_echo_flag
 {
     /**
      * Use any available backend echo canceller algorithm. This is
-     * the default settings. This setting is mutually exclusive with
-     * PJMEDIA_ECHO_SIMPLE and PJMEDIA_ECHO_SPEEX.
+     * the default settings. You can only choose one backend.
      */
     PJMEDIA_ECHO_DEFAULT= 0,
 
     /**
      * Force to use Speex AEC as the backend echo canceller algorithm.
-     * This setting is mutually exclusive with PJMEDIA_ECHO_SIMPLE and
-     * PJMEDIA_ECHO_WEBRTC.
+     * You can only choose one backend.
      */
     PJMEDIA_ECHO_SPEEX	= 1,
 
     /**
      * If PJMEDIA_ECHO_SIMPLE flag is specified during echo canceller
      * creation, then a simple echo suppressor will be used instead of
-     * an accoustic echo cancellation. This setting is mutually exclusive
-     * with PJMEDIA_ECHO_SPEEX and PJMEDIA_ECHO_WEBRTC.
+     * an accoustic echo cancellation. You can only choose one backend.
      */
     PJMEDIA_ECHO_SIMPLE	= 2,
 
     /**
      * Force to use WebRTC AEC as the backend echo canceller algorithm.
-     * This setting is mutually exclusive with PJMEDIA_ECHO_SIMPLE and
-     * PJMEDIA_ECHO_SPEEX.
+     * You can only choose one backend.
      */
     PJMEDIA_ECHO_WEBRTC = 3,
 
     /**
+     * Force to use WebRTC AEC3 as the backend echo canceller algorithm.
+     * You can only choose one backend.
+     */
+    PJMEDIA_ECHO_WEBRTC_AEC3 = 4,
+
+    /**
      * For internal use.
      */
     PJMEDIA_ECHO_ALGO_MASK = 15,
@@ -116,6 +118,12 @@ typedef enum pjmedia_echo_flag
      * canceller will also apply noise suppressor method to reduce noise.
      */
     PJMEDIA_ECHO_USE_NOISE_SUPPRESSOR = 128,
+
+    /**
+     * If PJMEDIA_ECHO_USE_GAIN_CONTROLLER flag is specified, the echo
+     * canceller will also apply automatic gain control.
+     */
+    PJMEDIA_ECHO_USE_GAIN_CONTROLLER = 256,
     
     /**
      * Use default aggressiveness setting for the echo canceller algorithm. 
@@ -129,26 +137,26 @@ typedef enum pjmedia_echo_flag
      * algorithm. This setting is mutually exclusive with the other
      * aggressiveness settings.
      */
-    PJMEDIA_ECHO_AGGRESSIVENESS_CONSERVATIVE = 0x100,
+    PJMEDIA_ECHO_AGGRESSIVENESS_CONSERVATIVE = 0x1000,
     
     /**
      * Use moderate aggressiveness setting for the echo canceller algorithm. 
      * This setting is mutually exclusive with the other aggressiveness
      * settings.
      */
-    PJMEDIA_ECHO_AGGRESSIVENESS_MODERATE = 0x200,
+    PJMEDIA_ECHO_AGGRESSIVENESS_MODERATE = 0x2000,
     
     /**
      * Use aggressive aggressiveness setting for the echo canceller
      * algorithm. This setting is mutually exclusive with the other
      * aggressiveness settings.
      */
-    PJMEDIA_ECHO_AGGRESSIVENESS_AGGRESSIVE = 0x300,
+    PJMEDIA_ECHO_AGGRESSIVENESS_AGGRESSIVE = 0x3000,
     
     /**
      * For internal use.
      */
-    PJMEDIA_ECHO_AGGRESSIVENESS_MASK = 0xF00
+    PJMEDIA_ECHO_AGGRESSIVENESS_MASK = 0xF000
 
 } pjmedia_echo_flag;
 
@@ -168,10 +176,22 @@ typedef struct pjmedia_echo_stat
     const char *name;
 
     /**
-     * Echo delay median value (in ms).
+     * Echo delay value (in ms).
+     * PJMEDIA_ECHO_STAT_NOT_SPECIFIED if unavailable.
+     */
+    int 	delay;
+
+    /**
+     * Echo return loss.
+     * PJMEDIA_ECHO_STAT_NOT_SPECIFIED if unavailable.
+     */
+    double 	return_loss;
+
+    /**
+     * Echo return loss enhancement.
      * PJMEDIA_ECHO_STAT_NOT_SPECIFIED if unavailable.
      */
-    int 	median;
+    double 	return_loss_enh;
 
     /**
      * Echo delay standard deviation (in ms).
diff --git a/pjmedia/src/pjmedia/echo_common.c b/pjmedia/src/pjmedia/echo_common.c
index edf7361..f16a02d 100644
--- a/pjmedia/src/pjmedia/echo_common.c
+++ b/pjmedia/src/pjmedia/echo_common.c
@@ -146,10 +146,29 @@ static struct ec_operations webrtc_aec_op =
 };
 #endif
 
+/*
+ * WebRTC AEC3 prototypes
+ */
+#if defined(PJMEDIA_HAS_WEBRTC_AEC3) && PJMEDIA_HAS_WEBRTC_AEC3!=0
+static struct ec_operations webrtc_aec3_op =
+{
+    "WebRTC AEC3",
+    &webrtc_aec3_create,
+    &webrtc_aec3_destroy,
+    &webrtc_aec3_reset,
+    &webrtc_aec3_cancel_echo,
+    NULL,
+    NULL,
+    &webrtc_aec3_get_stat
+};
+#endif
+
 PJ_DEF(void) pjmedia_echo_stat_default(pjmedia_echo_stat *stat)
 {
     pj_bzero(stat, sizeof(pjmedia_echo_stat));
-    stat->median = PJMEDIA_ECHO_STAT_NOT_SPECIFIED;
+    stat->delay = PJMEDIA_ECHO_STAT_NOT_SPECIFIED;
+    stat->return_loss = (double)PJMEDIA_ECHO_STAT_NOT_SPECIFIED;
+    stat->return_loss_enh = (double)PJMEDIA_ECHO_STAT_NOT_SPECIFIED;
     stat->std = PJMEDIA_ECHO_STAT_NOT_SPECIFIED;
     stat->frac_delay = (float)PJMEDIA_ECHO_STAT_NOT_SPECIFIED;
     stat->duration = PJMEDIA_ECHO_STAT_NOT_SPECIFIED;
@@ -226,6 +245,13 @@ PJ_DEF(pj_status_t) pjmedia_echo_create2(pj_pool_t *pool,
         ec->op = &webrtc_aec_op;
 #endif
         
+#if defined(PJMEDIA_HAS_WEBRTC_AEC3) && PJMEDIA_HAS_WEBRTC_AEC3!=0
+    } else if ((options & PJMEDIA_ECHO_ALGO_MASK)==PJMEDIA_ECHO_WEBRTC_AEC3 ||
+               (options & PJMEDIA_ECHO_ALGO_MASK) == PJMEDIA_ECHO_DEFAULT)
+    {
+        ec->op = &webrtc_aec3_op;
+#endif
+
     } else {
 	ec->op = &echo_supp_op;
     }
diff --git a/pjmedia/src/pjmedia/echo_internal.h b/pjmedia/src/pjmedia/echo_internal.h
index f5a7016..58d6976 100644
--- a/pjmedia/src/pjmedia/echo_internal.h
+++ b/pjmedia/src/pjmedia/echo_internal.h
@@ -97,6 +97,22 @@ PJ_DECL(pj_status_t) webrtc_aec_cancel_echo(void *state,
                                             unsigned options,
                                             void *reserved );
 
+PJ_DECL(pj_status_t) webrtc_aec3_create(pj_pool_t *pool,
+                                        unsigned clock_rate,
+                                        unsigned channel_count,
+                                        unsigned samples_per_frame,
+                                        unsigned tail_ms,
+                                        unsigned options,
+                                        void **p_echo );
+PJ_DECL(pj_status_t) webrtc_aec3_destroy(void *state );
+PJ_DECL(pj_status_t) webrtc_aec3_get_stat(void *state,
+					  pjmedia_echo_stat *p_stat);
+PJ_DECL(void) webrtc_aec3_reset(void *state );
+PJ_DECL(pj_status_t) webrtc_aec3_cancel_echo(void *state,
+                                             pj_int16_t *rec_frm,
+                                             const pj_int16_t *play_frm,
+                                             unsigned options,
+                                             void *reserved );
 
 PJ_END_DECL
 
diff --git a/pjmedia/src/pjmedia/echo_webrtc.c b/pjmedia/src/pjmedia/echo_webrtc.c
index 4d3cb5e..7718fbc 100644
--- a/pjmedia/src/pjmedia/echo_webrtc.c
+++ b/pjmedia/src/pjmedia/echo_webrtc.c
@@ -1,4 +1,3 @@
-/* $Id$ */
 /* 
  * Copyright (C) 2011-2015 Teluu Inc. (http://www.teluu.com)
  *
@@ -357,7 +356,7 @@ PJ_DEF(pj_status_t) webrtc_aec_get_stat(void *state,
 {
     webrtc_ec *echo = (webrtc_ec*) state;
 
-    if (WebRtcAec_GetDelayMetrics(echo->AEC_inst, &p_stat->median,
+    if (WebRtcAec_GetDelayMetrics(echo->AEC_inst, &p_stat->delay,
     				  &p_stat->std, &p_stat->frac_delay) != 0)
     {
         return PJ_EUNKNOWN;
@@ -369,7 +368,7 @@ PJ_DEF(pj_status_t) webrtc_aec_get_stat(void *state,
         pj_ansi_snprintf(p_stat->buf_, sizeof(p_stat->buf_),
 		     	 "WebRTC delay metric: median=%d, std=%d, "
             	     	 "frac of poor delay=%.02f",
-            	     	 p_stat->median, p_stat->std, p_stat->frac_delay);
+            	     	 p_stat->delay, p_stat->std, p_stat->frac_delay);
 
     return PJ_SUCCESS;
 }
diff --git a/pjmedia/src/pjmedia/echo_webrtc_aec3.cpp b/pjmedia/src/pjmedia/echo_webrtc_aec3.cpp
new file mode 100644
index 0000000..ec4dadf
--- /dev/null
+++ b/pjmedia/src/pjmedia/echo_webrtc_aec3.cpp
@@ -0,0 +1,267 @@
+/* 
+ * Copyright (C) 2011-2021 Teluu Inc. (http://www.teluu.com)
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA 
+ */
+
+#include <pjmedia/echo.h>
+#include <pjmedia/errno.h>
+#include <pj/assert.h>
+#include <pj/log.h>
+#include <pj/pool.h>
+#include <pj/string.h>
+
+#if defined(PJMEDIA_HAS_WEBRTC_AEC3) && PJMEDIA_HAS_WEBRTC_AEC3 != 0
+
+#include "modules/audio_processing/aec3/echo_canceller3.h"
+#include "modules/audio_processing/ns/noise_suppressor.h"
+#include "modules/audio_processing/gain_controller2.h"
+#include "modules/audio_processing/audio_buffer.h"
+
+using namespace webrtc;
+
+#include "echo_internal.h"
+
+#define THIS_FILE		"echo_webrtc_aec3.cpp"
+
+typedef struct webrtc_ec
+{
+    unsigned    options;
+    unsigned	samples_per_frame;
+    unsigned    clock_rate;
+    unsigned	channel_count;
+    unsigned	frame_length;
+    unsigned	num_bands;
+
+    pj_bool_t 	get_metrics;
+    EchoControl::Metrics metrics;
+
+    EchoControl     *aec;
+    NoiseSuppressor *ns;
+    GainController2 *agc;
+    AudioBuffer     *cap_buf;
+    AudioBuffer     *rend_buf;
+} webrtc_ec;
+
+
+/*
+ * Create the AEC.
+ */
+PJ_DEF(pj_status_t) webrtc_aec3_create(pj_pool_t *pool,
+                                       unsigned clock_rate,
+                                       unsigned channel_count,
+                                       unsigned samples_per_frame,
+                                       unsigned tail_ms,
+                                       unsigned options,
+                                       void **p_echo )
+{
+    webrtc_ec *echo;
+   
+    *p_echo = NULL;
+    
+    echo = PJ_POOL_ZALLOC_T(pool, webrtc_ec);
+    PJ_ASSERT_RETURN(echo != NULL, PJ_ENOMEM);
+    
+    if (clock_rate != 16000 && clock_rate != 32000 && clock_rate != 48000) {
+    	PJ_LOG(3, (THIS_FILE, "Unsupported clock rate for WebRTC AEC3"));
+    	return PJ_ENOTSUP;
+    }
+    
+    echo->options = options;    
+    echo->channel_count = channel_count;
+    echo->samples_per_frame = samples_per_frame;
+    echo->clock_rate = clock_rate;
+    echo->frame_length = clock_rate/100;
+    echo->num_bands = clock_rate/16000;
+    
+    echo->aec = new EchoCanceller3(EchoCanceller3Config(), clock_rate,
+    				   channel_count, channel_count);
+    
+    echo->cap_buf = new AudioBuffer(clock_rate, channel_count, clock_rate,
+                        	    channel_count, clock_rate, channel_count);
+    echo->rend_buf = new AudioBuffer(clock_rate, channel_count, clock_rate,
+                       		     channel_count, clock_rate, channel_count);
+
+    if (options & PJMEDIA_ECHO_USE_NOISE_SUPPRESSOR) {
+	NsConfig cfg;
+	/* Valid values are 6, 12, 18, 21 dB */
+	cfg.target_level = NsConfig::SuppressionLevel::k12dB;
+	echo->ns = new NoiseSuppressor(cfg, clock_rate, channel_count);
+    }
+
+    if (options & PJMEDIA_ECHO_USE_GAIN_CONTROLLER) {
+	echo->agc = new GainController2();
+	echo->agc->Initialize(clock_rate);
+	
+	AudioProcessing::Config::GainController2 cfg;
+	cfg.adaptive_digital.enabled = true;
+	if (GainController2::Validate(cfg))
+	    echo->agc->ApplyConfig(cfg);
+    }
+
+    /* Done */
+    *p_echo = echo;
+    return PJ_SUCCESS;
+}
+
+
+/*
+ * Destroy AEC
+ */
+PJ_DEF(pj_status_t) webrtc_aec3_destroy(void *state )
+{
+    webrtc_ec *echo = (webrtc_ec*) state;
+    PJ_ASSERT_RETURN(echo, PJ_EINVAL);
+    
+    if (echo->aec) {
+    	delete echo->aec;
+    	echo->aec = NULL;
+    }
+    if (echo->ns) {
+    	delete echo->ns;
+    	echo->ns = NULL;
+    }
+    if (echo->agc) {
+    	delete echo->agc;
+    	echo->agc = NULL;
+    }
+    
+    if (echo->cap_buf) {
+    	delete echo->cap_buf;
+    	echo->cap_buf = NULL;
+    }    
+    if (echo->rend_buf) {
+    	delete echo->rend_buf;
+    	echo->rend_buf = NULL;
+    }
+
+    return PJ_SUCCESS;
+}
+
+
+/*
+ * Reset AEC
+ */
+PJ_DEF(void) webrtc_aec3_reset(void *state )
+{
+    webrtc_ec *echo = (webrtc_ec*) state;
+    
+    pj_assert(echo != NULL);
+    
+    PJ_LOG(4, (THIS_FILE, "WebRTC AEC3 reset no-op"));
+}
+
+
+/*
+ * Perform echo cancellation.
+ */
+PJ_DEF(pj_status_t) webrtc_aec3_cancel_echo(void *state,
+					    pj_int16_t *rec_frm,
+					    const pj_int16_t *play_frm,
+					    unsigned options,
+					    void *reserved )
+{
+    webrtc_ec *echo = (webrtc_ec*) state;
+    unsigned i;
+
+    PJ_UNUSED_ARG(options);
+    PJ_UNUSED_ARG(reserved);
+
+    /* Sanity checks */
+    PJ_ASSERT_RETURN(echo && rec_frm && play_frm, PJ_EINVAL);
+
+    for (i = 0; i < echo->samples_per_frame;
+    	 i += echo->frame_length)
+    {
+	StreamConfig scfg(echo->clock_rate, echo->channel_count);
+
+    	echo->cap_buf->CopyFrom(rec_frm + i, scfg);
+    	echo->rend_buf->CopyFrom(play_frm + i, scfg);
+
+    	if (echo->clock_rate > 16000) {
+      	    echo->cap_buf->SplitIntoFrequencyBands();
+      	    echo->rend_buf->SplitIntoFrequencyBands();
+    	}
+
+    	echo->aec->AnalyzeCapture(echo->cap_buf);
+      	echo->aec->AnalyzeRender(echo->rend_buf);
+      	
+      	if (echo->ns) {
+      	    echo->ns->Analyze(*echo->cap_buf);
+      	    echo->ns->Process(echo->cap_buf);
+      	}
+      	
+      	echo->aec->ProcessCapture(echo->cap_buf, false);
+
+      	if (echo->agc) {
+      	    echo->agc->Process(echo->cap_buf);
+      	}
+
+    	if (echo->clock_rate > 16000) {
+      	    echo->cap_buf->MergeFrequencyBands();
+	}
+
+     	echo->cap_buf->CopyTo(scfg, rec_frm + i);
+    }
+
+    if (echo->get_metrics) {
+    	echo->metrics = echo->aec->GetMetrics();
+    	echo->get_metrics = PJ_FALSE;
+    }
+
+    return PJ_SUCCESS;
+}
+
+
+PJ_DEF(pj_status_t) webrtc_aec3_get_stat(void *state,
+					 pjmedia_echo_stat *p_stat)
+{
+    webrtc_ec *echo = (webrtc_ec*) state;
+    unsigned i = 0;
+
+    if (!echo || !echo->aec)
+    	return PJ_EINVAL;    
+
+    /* We cannot perform get metrics here since it may cause a race
+     * condition with echo cancellation process and crash with:
+     * "Check failed: !race_checker.RaceDetected()".
+     * (The doc of EchoCanceller3 specifies that "The class is supposed
+     * to be used in a non-concurrent manner").
+     *
+     * So we just do a simple dispatch. Using mutex seems like
+     * an overkill here.
+     */
+    // echo->metrics = echo->aec->GetMetrics();
+    echo->get_metrics = PJ_TRUE;
+    while (echo->get_metrics && i < 100000) i++;
+
+    p_stat->delay = echo->metrics.delay_ms;
+    p_stat->return_loss = echo->metrics.echo_return_loss;
+    p_stat->return_loss_enh = echo->metrics.echo_return_loss_enhancement;
+
+    p_stat->name = "WebRTC AEC3";
+    p_stat->stat_info.ptr = p_stat->buf_;
+    p_stat->stat_info.slen =
+        pj_ansi_snprintf(p_stat->buf_, sizeof(p_stat->buf_),
+		     	 "WebRTC AEC3 metrics: delay=%d ms, "
+            	     	 "return loss=%.02f, return loss enh=%.02f",
+            	     	 p_stat->delay, p_stat->return_loss,
+            	     	 p_stat->return_loss_enh);
+
+    return PJ_SUCCESS;
+}
+
+
+#endif
diff --git a/pjsip-apps/src/pjsua/pjsua_app_config.c b/pjsip-apps/src/pjsua/pjsua_app_config.c
index 046b17b..03e476f 100644
--- a/pjsip-apps/src/pjsua/pjsua_app_config.c
+++ b/pjsip-apps/src/pjsua/pjsua_app_config.c
@@ -152,7 +152,7 @@ static void usage(void)
     puts  ("  --ec-tail=MSEC      Set echo canceller tail length (default="
 	   			  xstr(PJSUA_DEFAULT_EC_TAIL_LEN) ")");
     puts  ("  --ec-opt=OPT        Select echo canceller algorithm (0=default, ");
-    puts  ("                        1=speex, 2=suppressor, 3=WebRtc)");
+    puts  ("                        1=speex, 2=suppressor, 3=WebRtc, 4=WebRtc AEC3)");
     puts  ("  --ilbc-mode=MODE    Set iLBC codec mode (20 or 30, default is "
     				  xstr(PJSUA_DEFAULT_ILBC_MODE) ")");
     puts  ("  --capture-dev=id    Audio capture device ID (default=-1)");
@@ -1270,6 +1270,8 @@ static pj_status_t parse_args(int argc, char *argv[],
 
 	case OPT_EC_OPT:
 	    cfg->media_cfg.ec_options = my_atoi(pj_optarg);
+	    if (cfg->media_cfg.ec_options > 0)
+	    	cfg->media_cfg.ec_options |= PJMEDIA_ECHO_USE_SW_ECHO;
 	    break;
 
 	case OPT_QUALITY:
diff --git a/third_party/build/os-auto.mak.in b/third_party/build/os-auto.mak.in
index b2f4ffb..0b50178 100644
--- a/third_party/build/os-auto.mak.in
+++ b/third_party/build/os-auto.mak.in
@@ -121,3 +121,31 @@ else # Generic fixed point
 endif
 endif
 endif
+
+ifneq (@ac_no_webrtc_aec3@,1)
+ifeq (@ac_external_webrtc_aec3@,1)
+# External webrtc AEC3
+else
+DIRS += webrtc_aec3
+WEBRTC_AEC3_OTHER_CFLAGS = -fexceptions @ac_webrtc_aec3_cflags@
+ifneq ($(findstring sse2,@ac_webrtc_aec3_instset@),)
+    export WEBRTC_AEC3_SRC = \
+	common_audio/resampler/sinc_resampler_sse.o \
+	common_audio/third_party/ooura/fft_size_128/ooura_fft_sse2.o
+    export WEBRTC_AEC3_SRC += \
+	common_audio/resampler/sinc_resampler_avx2.o \
+	modules/audio_processing/aec3/adaptive_fir_filter_erl_avx2.o \
+	modules/audio_processing/aec3/adaptive_fir_filter_avx2.o \
+	modules/audio_processing/aec3/fft_data_avx2.o \
+	modules/audio_processing/aec3/matched_filter_avx2.o \
+	modules/audio_processing/aec3/vector_math_avx2.o \
+	modules/audio_processing/agc2/rnn_vad/vector_math_avx2.o
+    WEBRTC_AEC3_OTHER_CFLAGS += -mfma
+else ifneq ($(findstring neon,@ac_webrtc_aec3_instset@),)
+    export WEBRTC_AEC3_SRC = \
+	common_audio/resampler/sinc_resampler_neon.o \
+	common_audio/third_party/ooura/fft_size_128/ooura_fft_neon.o
+    WEBRTC_AEC3_OTHER_CFLAGS += -DWEBRTC_HAS_NEON
+endif
+endif
+endif
diff --git a/third_party/build/webrtc_aec3/Makefile b/third_party/build/webrtc_aec3/Makefile
new file mode 100644
index 0000000..26c036d
--- /dev/null
+++ b/third_party/build/webrtc_aec3/Makefile
@@ -0,0 +1,209 @@
+include ../../../build.mak
+include ../../../build/common.mak
+include ../os-$(OS_NAME).mak
+
+export LIBDIR := ../../lib
+
+RULES_MAK := $(PJDIR)/build/rules.mak
+
+export WEBRTC_AEC3_LIB := libwebrtc-aec3-$(TARGET_NAME)$(LIBEXT)
+
+ifeq ($(PJ_SHARED_LIBRARIES),)
+else
+export WEBRTC_AEC3_SONAME := libwebrtc-aec3.$(SHLIB_SUFFIX)
+export WEBRTC_AEC3_SHLIB := $(WEBRTC_AEC3_SONAME).$(PJ_VERSION_MAJOR)
+endif
+
+###############################################################################
+# Gather all flags.
+#
+export _CFLAGS 	:= $(CC_CFLAGS) $(OS_CFLAGS) $(HOST_CFLAGS) $(M_CFLAGS) \
+		   $(CFLAGS) $(CC_INC). $(CC_INC)../../webrtc_aec3/src  \
+		   $(CC_INC)../../../pjlib/include
+export _CXXFLAGS:= $(CC_CXXFLAGS) $(OS_CXXFLAGS) $(M_CXXFLAGS) \
+		   $(HOST_CXXFLAGS) $(CXXFLAGS) $(_CFLAGS)
+export _LDFLAGS := $(CC_LDFLAGS) $(OS_LDFLAGS) $(M_LDFLAGS) $(HOST_LDFLAGS) \
+		   $(LDFLAGS) 
+
+export WEBRTC_AEC3_SRCDIR = ../../webrtc_aec3/src/
+export WEBRTC_AEC3_OBJS = \
+	absl/types/bad_optional_access.o \
+	common_audio/audio_util.o \
+	common_audio/third_party/ooura/fft_size_128/ooura_fft.o \
+	common_audio/third_party/ooura/fft_size_256/fft4g.o \
+	common_audio/resampler/push_resampler.o \
+	common_audio/resampler/push_sinc_resampler.o \
+	common_audio/resampler/sinc_resampler.o \
+	common_audio/signal_processing/splitting_filter.o \
+	api/audio/channel_layout.o \
+	api/audio/echo_canceller3_config.o \
+	api/audio/echo_canceller3_factory.o \
+	api/audio/echo_detector_creator.o \
+	modules/audio_processing/audio_buffer.o \
+	modules/audio_processing/gain_controller2.o \
+	modules/audio_processing/high_pass_filter.o \
+	modules/audio_processing/splitting_filter.o \
+	modules/audio_processing/three_band_filter_bank.o \
+	modules/audio_processing/aec3/adaptive_fir_filter_erl.o \
+	modules/audio_processing/aec3/adaptive_fir_filter.o \
+	modules/audio_processing/aec3/aec_state.o \
+	modules/audio_processing/aec3/aec3_common.o \
+	modules/audio_processing/aec3/aec3_fft.o \
+	modules/audio_processing/aec3/alignment_mixer.o \
+	modules/audio_processing/aec3/api_call_jitter_metrics.o \
+	modules/audio_processing/aec3/block_framer.o \
+	modules/audio_processing/aec3/block_delay_buffer.o \
+	modules/audio_processing/aec3/block_buffer.o \
+	modules/audio_processing/aec3/block_processor_metrics.o \
+	modules/audio_processing/aec3/block_processor.o \
+	modules/audio_processing/aec3/clockdrift_detector.o \
+	modules/audio_processing/aec3/coarse_filter_update_gain.o \
+	modules/audio_processing/aec3/comfort_noise_generator.o \
+	modules/audio_processing/aec3/decimator.o \
+	modules/audio_processing/aec3/dominant_nearend_detector.o \
+	modules/audio_processing/aec3/downsampled_render_buffer.o \
+	modules/audio_processing/aec3/echo_audibility.o \
+	modules/audio_processing/aec3/echo_canceller3.o \
+	modules/audio_processing/aec3/echo_path_delay_estimator.o \
+	modules/audio_processing/aec3/echo_path_variability.o \
+	modules/audio_processing/aec3/echo_remover_metrics.o \
+	modules/audio_processing/aec3/echo_remover.o \
+	modules/audio_processing/aec3/erl_estimator.o \
+	modules/audio_processing/aec3/erle_estimator.o \
+	modules/audio_processing/aec3/fft_buffer.o \
+	modules/audio_processing/aec3/filter_analyzer.o \
+	modules/audio_processing/aec3/frame_blocker.o \
+	modules/audio_processing/aec3/fullband_erle_estimator.o \
+	modules/audio_processing/aec3/matched_filter_lag_aggregator.o \
+	modules/audio_processing/aec3/matched_filter.o \
+	modules/audio_processing/aec3/moving_average.o \
+	modules/audio_processing/aec3/refined_filter_update_gain.o \
+	modules/audio_processing/aec3/render_buffer.o \
+	modules/audio_processing/aec3/render_delay_buffer.o \
+	modules/audio_processing/aec3/render_delay_controller_metrics.o \
+	modules/audio_processing/aec3/render_delay_controller.o \
+	modules/audio_processing/aec3/render_signal_analyzer.o \
+	modules/audio_processing/aec3/residual_echo_estimator.o \
+	modules/audio_processing/aec3/reverb_decay_estimator.o \
+	modules/audio_processing/aec3/reverb_frequency_response.o \
+	modules/audio_processing/aec3/reverb_model_estimator.o \
+	modules/audio_processing/aec3/reverb_model.o \
+	modules/audio_processing/aec3/signal_dependent_erle_estimator.o \
+	modules/audio_processing/aec3/spectrum_buffer.o \
+	modules/audio_processing/aec3/stationarity_estimator.o \
+	modules/audio_processing/aec3/subband_erle_estimator.o \
+	modules/audio_processing/aec3/subband_nearend_detector.o \
+	modules/audio_processing/aec3/subtractor_output_analyzer.o \
+	modules/audio_processing/aec3/subtractor_output.o \
+	modules/audio_processing/aec3/subtractor.o \
+	modules/audio_processing/aec3/suppression_filter.o \
+	modules/audio_processing/aec3/suppression_gain.o \
+	modules/audio_processing/aec3/transparent_mode.o \
+	modules/audio_processing/agc2/adaptive_agc.o \
+	modules/audio_processing/agc2/adaptive_digital_gain_applier.o \
+	modules/audio_processing/agc2/adaptive_mode_level_estimator.o \
+	modules/audio_processing/agc2/biquad_filter.o \
+	modules/audio_processing/agc2/compute_interpolated_gain_curve.o \
+	modules/audio_processing/agc2/cpu_features.o \
+	modules/audio_processing/agc2/down_sampler.o \
+	modules/audio_processing/agc2/fixed_digital_level_estimator.o \
+	modules/audio_processing/agc2/gain_applier.o \
+	modules/audio_processing/agc2/interpolated_gain_curve.o \
+	modules/audio_processing/agc2/limiter_db_gain_curve.o \
+	modules/audio_processing/agc2/limiter.o \
+	modules/audio_processing/agc2/noise_level_estimator.o \
+	modules/audio_processing/agc2/noise_spectrum_estimator.o \
+	modules/audio_processing/agc2/saturation_protector_buffer.o \
+	modules/audio_processing/agc2/saturation_protector.o \
+	modules/audio_processing/agc2/signal_classifier.o \
+	modules/audio_processing/agc2/vad_with_level.o \
+	modules/audio_processing/agc2/vector_float_frame.o \
+	modules/audio_processing/agc2/rnn_vad/auto_correlation.o \
+	modules/audio_processing/agc2/rnn_vad/features_extraction.o \
+	modules/audio_processing/agc2/rnn_vad/lp_residual.o \
+	modules/audio_processing/agc2/rnn_vad/rnn.o \
+	modules/audio_processing/agc2/rnn_vad/rnn_fc.o \
+	modules/audio_processing/agc2/rnn_vad/rnn_gru.o \
+	modules/audio_processing/agc2/rnn_vad/pitch_search_internal.o \
+	modules/audio_processing/agc2/rnn_vad/pitch_search.o \
+	modules/audio_processing/agc2/rnn_vad/spectral_features_internal.o \
+	modules/audio_processing/agc2/rnn_vad/spectral_features.o \
+	modules/audio_processing/ns/fast_math.o \
+	modules/audio_processing/ns/histograms.o \
+	modules/audio_processing/ns/noise_estimator.o \
+	modules/audio_processing/ns/noise_suppressor.o \
+	modules/audio_processing/ns/ns_fft.o \
+	modules/audio_processing/ns/prior_signal_model_estimator.o \
+	modules/audio_processing/ns/prior_signal_model.o \
+	modules/audio_processing/ns/quantile_noise_estimator.o \
+	modules/audio_processing/ns/signal_model_estimator.o \
+	modules/audio_processing/ns/signal_model.o \
+	modules/audio_processing/ns/speech_probability_estimator.o \
+	modules/audio_processing/ns/suppression_params.o \
+	modules/audio_processing/ns/wiener_filter.o \
+	modules/audio_processing/logging/apm_data_dumper.o \
+	modules/audio_processing/utility/cascaded_biquad_filter.o \
+	modules/audio_processing/utility/delay_estimator_wrapper.o \
+	modules/audio_processing/utility/delay_estimator.o \
+	modules/audio_processing/utility/pffft_wrapper.o \
+	rtc_base/checks.o \
+	rtc_base/logging.o \
+	rtc_base/platform_thread_types.o \
+	rtc_base/race_checker.o \
+	rtc_base/string_encode.o \
+	rtc_base/string_to_number.o \
+	rtc_base/string_utils.o \
+	rtc_base/system_time.o \
+	rtc_base/time_utils.o \
+	rtc_base/experiments/field_trial_parser.o \
+	rtc_base/memory/aligned_malloc.o \
+	rtc_base/strings/string_builder.o \
+	rtc_base/synchronization/mutex.o \
+	rtc_base/synchronization/yield.o \
+	rtc_base/system/file_wrapper.o \
+	system_wrappers/source/cpu_features.o \
+	system_wrappers/source/field_trial.o \
+	system_wrappers/source/metrics.o \
+	third_party/rnnoise/src/rnn_vad_weights.o \
+	third_party/pffft/src/pffft.o \
+	$(WEBRTC_AEC3_SRC)
+
+export WEBRTC_AEC3_CFLAGS = $(_CFLAGS) $(WEBRTC_AEC3_OTHER_CFLAGS)
+export WEBRTC_AEC3_CXXFLAGS = $(WEBRTC_AEC3_CFLAGS) $(_CXXFLAGS)
+
+
+export CC_OUT CC AR RANLIB HOST_MV HOST_RM HOST_RMDIR HOST_MKDIR OBJEXT LD LDOUT 
+###############################################################################
+# Main entry
+#
+# $(TARGET) is defined in os-$(OS_NAME).mak file in current directory.
+#
+TARGETS := $(WEBRTC_AEC3_LIB) $(WEBRTC_AEC3_SONAME)
+
+all: $(TARGETS)
+
+doc:
+	cd .. && doxygen docs/doxygen.cfg
+
+dep: depend
+distclean: realclean
+
+.PHONY: all dep depend clean realclean distclean
+.PHONY: $(TARGETS)
+.PHONY: $(WEBRTC_AEC3_LIB) $(WEBRTC_AEC3_SONAME)
+
+libwebrtc-aec3: $(WEBRTC_AEC3_LIB)
+$(WEBRTC_AEC3_SONAME): $(WEBRTC_AEC3_LIB)
+$(WEBRTC_AEC3_LIB) $(WEBRTC_AEC3_SONAME):
+	$(MAKE) -f $(RULES_MAK) APP=WEBRTC_AEC3 app=libwebrtc-aec3 $(subst /,$(HOST_PSEP),$(LIBDIR)/$@)
+
+clean print_lib:
+	$(MAKE) -f $(RULES_MAK) APP=WEBRTC_AEC3 app=libwebrtc-aec3 $@
+
+realclean:
+	$(subst @@,$(subst /,$(HOST_PSEP),.webrtc-aec3-$(TARGET_NAME).depend),$(HOST_RMR))
+	
+	$(MAKE) -f $(RULES_MAK) APP=WEBRTC_AEC3 app=libwebrtc-aec3 $@
+
+depend:
+	$(MAKE) -f $(RULES_MAK) APP=WEBRTC_AEC3 app=libwebrtc-aec3 $@
diff --git a/third_party/webrtc_aec3/LICENSE b/third_party/webrtc_aec3/LICENSE
new file mode 100644
index 0000000..4c41b7b
--- /dev/null
+++ b/third_party/webrtc_aec3/LICENSE
@@ -0,0 +1,29 @@
+Copyright (c) 2011, The WebRTC project authors. All rights reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+
+  * Redistributions of source code must retain the above copyright
+    notice, this list of conditions and the following disclaimer.
+
+  * Redistributions in binary form must reproduce the above copyright
+    notice, this list of conditions and the following disclaimer in
+    the documentation and/or other materials provided with the
+    distribution.
+
+  * Neither the name of Google nor the names of its contributors may
+    be used to endorse or promote products derived from this software
+    without specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
diff --git a/third_party/webrtc_aec3/OWNERS b/third_party/webrtc_aec3/OWNERS
new file mode 100644
index 0000000..73c75a0
--- /dev/null
+++ b/third_party/webrtc_aec3/OWNERS
@@ -0,0 +1,19 @@
+henrika@webrtc.org
+hta@webrtc.org
+juberti@webrtc.org
+mflodman@webrtc.org
+stefan@webrtc.org
+tommi@webrtc.org
+per-file .gitignore=*
+per-file .gn=mbonadei@webrtc.org
+per-file *.gn=mbonadei@webrtc.org
+per-file *.gni=mbonadei@webrtc.org
+per-file AUTHORS=*
+per-file DEPS=*
+per-file pylintrc=phoglund@webrtc.org
+per-file WATCHLISTS=*
+per-file abseil-in-webrtc.md=danilchap@webrtc.org
+per-file abseil-in-webrtc.md=mbonadei@webrtc.org
+per-file style-guide.md=danilchap@webrtc.org
+per-file native-api.md=mbonadei@webrtc.org
+per-file *.lua=titovartem@webrtc.org
diff --git a/third_party/webrtc_aec3/PATENTS b/third_party/webrtc_aec3/PATENTS
new file mode 100644
index 0000000..190607a
--- /dev/null
+++ b/third_party/webrtc_aec3/PATENTS
@@ -0,0 +1,24 @@
+Additional IP Rights Grant (Patents)
+
+"This implementation" means the copyrightable works distributed by
+Google as part of the WebRTC code package.
+
+Google hereby grants to you a perpetual, worldwide, non-exclusive,
+no-charge, irrevocable (except as stated in this section) patent
+license to make, have made, use, offer to sell, sell, import,
+transfer, and otherwise run, modify and propagate the contents of this
+implementation of the WebRTC code package, where such license applies
+only to those patent claims, both currently owned by Google and
+acquired in the future, licensable by Google that are necessarily
+infringed by this implementation of the WebRTC code package. This
+grant does not include claims that would be infringed only as a
+consequence of further modification of this implementation. If you or
+your agent or exclusive licensee institute or order or agree to the
+institution of patent litigation against any entity (including a
+cross-claim or counterclaim in a lawsuit) alleging that this
+implementation of the WebRTC code package or any code incorporated
+within this implementation of the WebRTC code package constitutes
+direct or contributory patent infringement, or inducement of patent
+infringement, then any patent rights granted to you under this License
+for this implementation of the WebRTC code package shall terminate as
+of the date such litigation is filed.
diff --git a/third_party/webrtc_aec3/PJSIP_NOTES b/third_party/webrtc_aec3/PJSIP_NOTES
new file mode 100644
index 0000000..111c269
--- /dev/null
+++ b/third_party/webrtc_aec3/PJSIP_NOTES
@@ -0,0 +1,48 @@
+The WebRtc source is cloned from the repo:
+https://webrtc.googlesource.com/src
+dated Apr 21 2021
+license: third_party/webrtc_aec3/LICENSE
+
+The abseil's source in src/absl is not part of WebRtc and taken separately from:
+https://github.com/abseil/abseil-cpp
+dated Apr 20 2021
+abseil's license: src/absl/LICENSE
+
+src/third_party's source is obtained from:
+* rnnoise
+https://chromium.googlesource.com/chromium/src/+/HEAD/third_party/rnnoise
+dated Apr 30 2021
+license: src/third_party/rnnoise/COPYING
+
+* pffft
+https://bitbucket.org/jpommier/pffft/src/master/
+dated Apr 30 2021
+license: src/third_party/pffft/README.txt
+
+Local changes:
+1. Undeclared PR_SET_NAME on Android.
+diff --git a/third_party/webrtc_aec3/src/rtc_base/platform_thread_types.cc b/third_party/webrtc_aec3/src/rtc_base/platform_thread_types.cc
+index b0243b41d..fc7a09000 100644
+--- a/third_party/webrtc_aec3/src/rtc_base/platform_thread_types.cc
++++ b/third_party/webrtc_aec3/src/rtc_base/platform_thread_types.cc
+@@ -105,7 +105,7 @@ void SetCurrentThreadName(const char* name) {
+   } __except (EXCEPTION_EXECUTE_HANDLER) {  // NOLINT
+   }
+ #pragma warning(pop)
+-#elif defined(WEBRTC_LINUX) || defined(WEBRTC_ANDROID)
++#elif defined(WEBRTC_LINUX) // || defined(WEBRTC_ANDROID)
+   prctl(PR_SET_NAME, reinterpret_cast<unsigned long>(name));  // NOLINT
+ #elif defined(WEBRTC_MAC) || defined(WEBRTC_IOS)
+   pthread_setname_np(name);
+
+2. Error: 'unique_ptr' is not a member of 'std' on Linux.
+diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model_estimator.h
+index 3b9971aba..e4e954067 100644
+--- a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model_estimator.h
++++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model_estimator.h
+@@ -12,6 +12,7 @@
+ #define MODULES_AUDIO_PROCESSING_AEC3_REVERB_MODEL_ESTIMATOR_H_
+ 
+ #include <array>
++#include <memory>
+ #include <vector>
diff --git a/third_party/webrtc_aec3/README.md b/third_party/webrtc_aec3/README.md
new file mode 100644
index 0000000..0a7b5ea
--- /dev/null
+++ b/third_party/webrtc_aec3/README.md
@@ -0,0 +1,31 @@
+**WebRTC is a free, open software project** that provides browsers and mobile
+applications with Real-Time Communications (RTC) capabilities via simple APIs.
+The WebRTC components have been optimized to best serve this purpose.
+
+**Our mission:** To enable rich, high-quality RTC applications to be
+developed for the browser, mobile platforms, and IoT devices, and allow them
+all to communicate via a common set of protocols.
+
+The WebRTC initiative is a project supported by Google, Mozilla and Opera,
+amongst others.
+
+### Development
+
+See [here][native-dev] for instructions on how to get started
+developing with the native code.
+
+[Authoritative list](native-api.md) of directories that contain the
+native API header files.
+
+### More info
+
+ * Official web site: http://www.webrtc.org
+ * Master source code repo: https://webrtc.googlesource.com/src
+ * Samples and reference apps: https://github.com/webrtc
+ * Mailing list: http://groups.google.com/group/discuss-webrtc
+ * Continuous build: https://ci.chromium.org/p/webrtc/g/ci/console
+ * [Coding style guide](style-guide.md)
+ * [Code of conduct](CODE_OF_CONDUCT.md)
+ * [Reporting bugs](docs/bug-reporting.md)
+
+[native-dev]: https://webrtc.googlesource.com/src/+/refs/heads/master/docs/native-code/index.md
diff --git a/third_party/webrtc_aec3/src/absl/AUTHORS b/third_party/webrtc_aec3/src/absl/AUTHORS
new file mode 100644
index 0000000..976d31d
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/AUTHORS
@@ -0,0 +1,6 @@
+# This is the list of Abseil authors for copyright purposes.
+#
+# This does not necessarily list everyone who has contributed code, since in
+# some cases, their employer may be the copyright holder.  To see the full list
+# of contributors, see the revision history in source control.
+Google Inc.
diff --git a/third_party/webrtc_aec3/src/absl/LICENSE b/third_party/webrtc_aec3/src/absl/LICENSE
new file mode 100644
index 0000000..ccd61dc
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/LICENSE
@@ -0,0 +1,203 @@
+
+                                 Apache License
+                           Version 2.0, January 2004
+                        https://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      "License" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      "Licensor" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      "Legal Entity" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      "control" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      "You" (or "Your") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      "Source" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      "Object" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      "Work" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      "Derivative Works" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      "Contribution" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, "submitted"
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as "Not a Contribution."
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an "AS IS" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
+
+   APPENDIX: How to apply the Apache License to your work.
+
+      To apply the Apache License to your work, attach the following
+      boilerplate notice, with the fields enclosed by brackets "[]"
+      replaced with your own identifying information. (Don't include
+      the brackets!)  The text should be enclosed in the appropriate
+      comment syntax for the file format. We also recommend that a
+      file or class name and description of purpose be included on the
+      same "printed page" as the copyright notice for easier
+      identification within third-party archives.
+
+   Copyright [yyyy] [name of copyright owner]
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       https://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+
diff --git a/third_party/webrtc_aec3/src/absl/README.md b/third_party/webrtc_aec3/src/absl/README.md
new file mode 100644
index 0000000..264c4b3
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/README.md
@@ -0,0 +1,139 @@
+# Abseil - C++ Common Libraries
+
+The repository contains the Abseil C++ library code. Abseil is an open-source
+collection of C++ code (compliant to C++11) designed to augment the C++
+standard library.
+
+## Table of Contents
+
+- [About Abseil](#about)
+- [Quickstart](#quickstart)
+- [Building Abseil](#build)
+- [Support](#support)
+- [Codemap](#codemap)
+- [Releases](#releases)
+- [License](#license)
+- [Links](#links)
+
+<a name="about"></a>
+## About Abseil
+
+Abseil is an open-source collection of C++ library code designed to augment
+the C++ standard library. The Abseil library code is collected from Google's
+own C++ code base, has been extensively tested and used in production, and
+is the same code we depend on in our daily coding lives.
+
+In some cases, Abseil provides pieces missing from the C++ standard; in
+others, Abseil provides alternatives to the standard for special needs
+we've found through usage in the Google code base. We denote those cases
+clearly within the library code we provide you.
+
+Abseil is not meant to be a competitor to the standard library; we've
+just found that many of these utilities serve a purpose within our code
+base, and we now want to provide those resources to the C++ community as
+a whole.
+
+<a name="quickstart"></a>
+## Quickstart
+
+If you want to just get started, make sure you at least run through the
+[Abseil Quickstart](https://abseil.io/docs/cpp/quickstart). The Quickstart
+contains information about setting up your development environment, downloading
+the Abseil code, running tests, and getting a simple binary working.
+
+<a name="build"></a>
+## Building Abseil
+
+[Bazel](https://bazel.build) and [CMake](https://cmake.org/) are the official
+build systems for Abseil.
+
+See the [quickstart](https://abseil.io/docs/cpp/quickstart) for more information
+on building Abseil using the Bazel build system.
+
+If you require CMake support, please check the [CMake build
+instructions](CMake/README.md) and [CMake
+Quickstart](https://abseil.io/docs/cpp/quickstart-cmake).
+
+## Support
+
+Abseil is officially supported on many platforms. See the [Abseil
+platform support
+guide](https://abseil.io/docs/cpp/platforms/platforms) for details on
+supported operating systems, compilers, CPUs, etc.
+
+## Codemap
+
+Abseil contains the following C++ library components:
+
+* [`base`](absl/base/) Abseil Fundamentals
+  <br /> The `base` library contains initialization code and other code which
+  all other Abseil code depends on. Code within `base` may not depend on any
+  other code (other than the C++ standard library).
+* [`algorithm`](absl/algorithm/)
+  <br /> The `algorithm` library contains additions to the C++ `<algorithm>`
+  library and container-based versions of such algorithms.
+* [`cleanup`](absl/cleanup/)
+  <br /> The `cleanup` library contains the control-flow-construct-like type
+  `absl::Cleanup` which is used for executing a callback on scope exit.
+* [`container`](absl/container/)
+  <br /> The `container` library contains additional STL-style containers,
+  including Abseil's unordered "Swiss table" containers.
+* [`debugging`](absl/debugging/)
+  <br /> The `debugging` library contains code useful for enabling leak
+  checks, and stacktrace and symbolization utilities.
+* [`hash`](absl/hash/)
+  <br /> The `hash` library contains the hashing framework and default hash
+  functor implementations for hashable types in Abseil.
+* [`memory`](absl/memory/)
+  <br /> The `memory` library contains C++11-compatible versions of
+  `std::make_unique()` and related memory management facilities.
+* [`meta`](absl/meta/)
+  <br /> The `meta` library contains C++11-compatible versions of type checks
+  available within C++14 and C++17 versions of the C++ `<type_traits>` library.
+* [`numeric`](absl/numeric/)
+  <br /> The `numeric` library contains C++11-compatible 128-bit integers.
+* [`status`](absl/status/)
+  <br /> The `status` contains abstractions for error handling, specifically
+  `absl::Status` and `absl::StatusOr<T>`.
+* [`strings`](absl/strings/)
+  <br /> The `strings` library contains a variety of strings routines and
+  utilities, including a C++11-compatible version of the C++17
+  `std::string_view` type.
+* [`synchronization`](absl/synchronization/)
+  <br /> The `synchronization` library contains concurrency primitives (Abseil's
+  `absl::Mutex` class, an alternative to `std::mutex`) and a variety of
+  synchronization abstractions.
+* [`time`](absl/time/)
+  <br /> The `time` library contains abstractions for computing with absolute
+  points in time, durations of time, and formatting and parsing time within
+  time zones.
+* [`types`](absl/types/)
+  <br /> The `types` library contains non-container utility types, like a
+  C++11-compatible version of the C++17 `std::optional` type.
+* [`utility`](absl/utility/)
+  <br /> The `utility` library contains utility and helper code.
+
+## Releases
+
+Abseil recommends users "live-at-head" (update to the latest commit from the
+master branch as often as possible). However, we realize this philosophy doesn't
+work for every project, so we also provide [Long Term Support
+Releases](https://github.com/abseil/abseil-cpp/releases) to which we backport
+fixes for severe bugs. See our [release
+management](https://abseil.io/about/releases) document for more details.
+
+## License
+
+The Abseil C++ library is licensed under the terms of the Apache
+license. See [LICENSE](LICENSE) for more information.
+
+## Links
+
+For more information about Abseil:
+
+* Consult our [Abseil Introduction](https://abseil.io/about/intro)
+* Read [Why Adopt Abseil](https://abseil.io/about/philosophy) to understand our
+  design philosophy.
+* Peruse our
+  [Abseil Compatibility Guarantees](https://abseil.io/about/compatibility) to
+  understand both what we promise to you, and what we expect of you in return.
diff --git a/third_party/webrtc_aec3/src/absl/base/attributes.h b/third_party/webrtc_aec3/src/absl/base/attributes.h
new file mode 100644
index 0000000..294e5d0
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/attributes.h
@@ -0,0 +1,731 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+// This header file defines macros for declaring attributes for functions,
+// types, and variables.
+//
+// These macros are used within Abseil and allow the compiler to optimize, where
+// applicable, certain function calls.
+//
+// Most macros here are exposing GCC or Clang features, and are stubbed out for
+// other compilers.
+//
+// GCC attributes documentation:
+//   https://gcc.gnu.org/onlinedocs/gcc-4.7.0/gcc/Function-Attributes.html
+//   https://gcc.gnu.org/onlinedocs/gcc-4.7.0/gcc/Variable-Attributes.html
+//   https://gcc.gnu.org/onlinedocs/gcc-4.7.0/gcc/Type-Attributes.html
+//
+// Most attributes in this file are already supported by GCC 4.7. However, some
+// of them are not supported in older version of Clang. Thus, we check
+// `__has_attribute()` first. If the check fails, we check if we are on GCC and
+// assume the attribute exists on GCC (which is verified on GCC 4.7).
+
+#ifndef ABSL_BASE_ATTRIBUTES_H_
+#define ABSL_BASE_ATTRIBUTES_H_
+
+#include "absl/base/config.h"
+
+// ABSL_HAVE_ATTRIBUTE
+//
+// A function-like feature checking macro that is a wrapper around
+// `__has_attribute`, which is defined by GCC 5+ and Clang and evaluates to a
+// nonzero constant integer if the attribute is supported or 0 if not.
+//
+// It evaluates to zero if `__has_attribute` is not defined by the compiler.
+//
+// GCC: https://gcc.gnu.org/gcc-5/changes.html
+// Clang: https://clang.llvm.org/docs/LanguageExtensions.html
+#ifdef __has_attribute
+#define ABSL_HAVE_ATTRIBUTE(x) __has_attribute(x)
+#else
+#define ABSL_HAVE_ATTRIBUTE(x) 0
+#endif
+
+// ABSL_HAVE_CPP_ATTRIBUTE
+//
+// A function-like feature checking macro that accepts C++11 style attributes.
+// It's a wrapper around `__has_cpp_attribute`, defined by ISO C++ SD-6
+// (https://en.cppreference.com/w/cpp/experimental/feature_test). If we don't
+// find `__has_cpp_attribute`, will evaluate to 0.
+#if defined(__cplusplus) && defined(__has_cpp_attribute)
+// NOTE: requiring __cplusplus above should not be necessary, but
+// works around https://bugs.llvm.org/show_bug.cgi?id=23435.
+#define ABSL_HAVE_CPP_ATTRIBUTE(x) __has_cpp_attribute(x)
+#else
+#define ABSL_HAVE_CPP_ATTRIBUTE(x) 0
+#endif
+
+// -----------------------------------------------------------------------------
+// Function Attributes
+// -----------------------------------------------------------------------------
+//
+// GCC: https://gcc.gnu.org/onlinedocs/gcc/Function-Attributes.html
+// Clang: https://clang.llvm.org/docs/AttributeReference.html
+
+// ABSL_PRINTF_ATTRIBUTE
+// ABSL_SCANF_ATTRIBUTE
+//
+// Tells the compiler to perform `printf` format string checking if the
+// compiler supports it; see the 'format' attribute in
+// <https://gcc.gnu.org/onlinedocs/gcc-4.7.0/gcc/Function-Attributes.html>.
+//
+// Note: As the GCC manual states, "[s]ince non-static C++ methods
+// have an implicit 'this' argument, the arguments of such methods
+// should be counted from two, not one."
+#if ABSL_HAVE_ATTRIBUTE(format) || (defined(__GNUC__) && !defined(__clang__))
+#define ABSL_PRINTF_ATTRIBUTE(string_index, first_to_check) \
+  __attribute__((__format__(__printf__, string_index, first_to_check)))
+#define ABSL_SCANF_ATTRIBUTE(string_index, first_to_check) \
+  __attribute__((__format__(__scanf__, string_index, first_to_check)))
+#else
+#define ABSL_PRINTF_ATTRIBUTE(string_index, first_to_check)
+#define ABSL_SCANF_ATTRIBUTE(string_index, first_to_check)
+#endif
+
+// ABSL_ATTRIBUTE_ALWAYS_INLINE
+// ABSL_ATTRIBUTE_NOINLINE
+//
+// Forces functions to either inline or not inline. Introduced in gcc 3.1.
+#if ABSL_HAVE_ATTRIBUTE(always_inline) || \
+    (defined(__GNUC__) && !defined(__clang__))
+#define ABSL_ATTRIBUTE_ALWAYS_INLINE __attribute__((always_inline))
+#define ABSL_HAVE_ATTRIBUTE_ALWAYS_INLINE 1
+#else
+#define ABSL_ATTRIBUTE_ALWAYS_INLINE
+#endif
+
+#if ABSL_HAVE_ATTRIBUTE(noinline) || (defined(__GNUC__) && !defined(__clang__))
+#define ABSL_ATTRIBUTE_NOINLINE __attribute__((noinline))
+#define ABSL_HAVE_ATTRIBUTE_NOINLINE 1
+#else
+#define ABSL_ATTRIBUTE_NOINLINE
+#endif
+
+// ABSL_ATTRIBUTE_NO_TAIL_CALL
+//
+// Prevents the compiler from optimizing away stack frames for functions which
+// end in a call to another function.
+#if ABSL_HAVE_ATTRIBUTE(disable_tail_calls)
+#define ABSL_HAVE_ATTRIBUTE_NO_TAIL_CALL 1
+#define ABSL_ATTRIBUTE_NO_TAIL_CALL __attribute__((disable_tail_calls))
+#elif defined(__GNUC__) && !defined(__clang__) && !defined(__e2k__)
+#define ABSL_HAVE_ATTRIBUTE_NO_TAIL_CALL 1
+#define ABSL_ATTRIBUTE_NO_TAIL_CALL \
+  __attribute__((optimize("no-optimize-sibling-calls")))
+#else
+#define ABSL_ATTRIBUTE_NO_TAIL_CALL
+#define ABSL_HAVE_ATTRIBUTE_NO_TAIL_CALL 0
+#endif
+
+// ABSL_ATTRIBUTE_WEAK
+//
+// Tags a function as weak for the purposes of compilation and linking.
+// Weak attributes did not work properly in LLVM's Windows backend before
+// 9.0.0, so disable them there. See https://bugs.llvm.org/show_bug.cgi?id=37598
+// for further information.
+// The MinGW compiler doesn't complain about the weak attribute until the link
+// step, presumably because Windows doesn't use ELF binaries.
+#if (ABSL_HAVE_ATTRIBUTE(weak) ||                   \
+     (defined(__GNUC__) && !defined(__clang__))) && \
+    (!defined(_WIN32) || __clang_major__ < 9) && !defined(__MINGW32__)
+#undef ABSL_ATTRIBUTE_WEAK
+#define ABSL_ATTRIBUTE_WEAK __attribute__((weak))
+#define ABSL_HAVE_ATTRIBUTE_WEAK 1
+#else
+#define ABSL_ATTRIBUTE_WEAK
+#define ABSL_HAVE_ATTRIBUTE_WEAK 0
+#endif
+
+// ABSL_ATTRIBUTE_NONNULL
+//
+// Tells the compiler either (a) that a particular function parameter
+// should be a non-null pointer, or (b) that all pointer arguments should
+// be non-null.
+//
+// Note: As the GCC manual states, "[s]ince non-static C++ methods
+// have an implicit 'this' argument, the arguments of such methods
+// should be counted from two, not one."
+//
+// Args are indexed starting at 1.
+//
+// For non-static class member functions, the implicit `this` argument
+// is arg 1, and the first explicit argument is arg 2. For static class member
+// functions, there is no implicit `this`, and the first explicit argument is
+// arg 1.
+//
+// Example:
+//
+//   /* arg_a cannot be null, but arg_b can */
+//   void Function(void* arg_a, void* arg_b) ABSL_ATTRIBUTE_NONNULL(1);
+//
+//   class C {
+//     /* arg_a cannot be null, but arg_b can */
+//     void Method(void* arg_a, void* arg_b) ABSL_ATTRIBUTE_NONNULL(2);
+//
+//     /* arg_a cannot be null, but arg_b can */
+//     static void StaticMethod(void* arg_a, void* arg_b)
+//     ABSL_ATTRIBUTE_NONNULL(1);
+//   };
+//
+// If no arguments are provided, then all pointer arguments should be non-null.
+//
+//  /* No pointer arguments may be null. */
+//  void Function(void* arg_a, void* arg_b, int arg_c) ABSL_ATTRIBUTE_NONNULL();
+//
+// NOTE: The GCC nonnull attribute actually accepts a list of arguments, but
+// ABSL_ATTRIBUTE_NONNULL does not.
+#if ABSL_HAVE_ATTRIBUTE(nonnull) || (defined(__GNUC__) && !defined(__clang__))
+#define ABSL_ATTRIBUTE_NONNULL(arg_index) __attribute__((nonnull(arg_index)))
+#else
+#define ABSL_ATTRIBUTE_NONNULL(...)
+#endif
+
+// ABSL_ATTRIBUTE_NORETURN
+//
+// Tells the compiler that a given function never returns.
+#if ABSL_HAVE_ATTRIBUTE(noreturn) || (defined(__GNUC__) && !defined(__clang__))
+#define ABSL_ATTRIBUTE_NORETURN __attribute__((noreturn))
+#elif defined(_MSC_VER)
+#define ABSL_ATTRIBUTE_NORETURN __declspec(noreturn)
+#else
+#define ABSL_ATTRIBUTE_NORETURN
+#endif
+
+// ABSL_ATTRIBUTE_NO_SANITIZE_ADDRESS
+//
+// Tells the AddressSanitizer (or other memory testing tools) to ignore a given
+// function. Useful for cases when a function reads random locations on stack,
+// calls _exit from a cloned subprocess, deliberately accesses buffer
+// out of bounds or does other scary things with memory.
+// NOTE: GCC supports AddressSanitizer(asan) since 4.8.
+// https://gcc.gnu.org/gcc-4.8/changes.html
+#if ABSL_HAVE_ATTRIBUTE(no_sanitize_address)
+#define ABSL_ATTRIBUTE_NO_SANITIZE_ADDRESS __attribute__((no_sanitize_address))
+#else
+#define ABSL_ATTRIBUTE_NO_SANITIZE_ADDRESS
+#endif
+
+// ABSL_ATTRIBUTE_NO_SANITIZE_MEMORY
+//
+// Tells the MemorySanitizer to relax the handling of a given function. All "Use
+// of uninitialized value" warnings from such functions will be suppressed, and
+// all values loaded from memory will be considered fully initialized.  This
+// attribute is similar to the ABSL_ATTRIBUTE_NO_SANITIZE_ADDRESS attribute
+// above, but deals with initialized-ness rather than addressability issues.
+// NOTE: MemorySanitizer(msan) is supported by Clang but not GCC.
+#if ABSL_HAVE_ATTRIBUTE(no_sanitize_memory)
+#define ABSL_ATTRIBUTE_NO_SANITIZE_MEMORY __attribute__((no_sanitize_memory))
+#else
+#define ABSL_ATTRIBUTE_NO_SANITIZE_MEMORY
+#endif
+
+// ABSL_ATTRIBUTE_NO_SANITIZE_THREAD
+//
+// Tells the ThreadSanitizer to not instrument a given function.
+// NOTE: GCC supports ThreadSanitizer(tsan) since 4.8.
+// https://gcc.gnu.org/gcc-4.8/changes.html
+#if ABSL_HAVE_ATTRIBUTE(no_sanitize_thread)
+#define ABSL_ATTRIBUTE_NO_SANITIZE_THREAD __attribute__((no_sanitize_thread))
+#else
+#define ABSL_ATTRIBUTE_NO_SANITIZE_THREAD
+#endif
+
+// ABSL_ATTRIBUTE_NO_SANITIZE_UNDEFINED
+//
+// Tells the UndefinedSanitizer to ignore a given function. Useful for cases
+// where certain behavior (eg. division by zero) is being used intentionally.
+// NOTE: GCC supports UndefinedBehaviorSanitizer(ubsan) since 4.9.
+// https://gcc.gnu.org/gcc-4.9/changes.html
+#if ABSL_HAVE_ATTRIBUTE(no_sanitize_undefined)
+#define ABSL_ATTRIBUTE_NO_SANITIZE_UNDEFINED \
+  __attribute__((no_sanitize_undefined))
+#elif ABSL_HAVE_ATTRIBUTE(no_sanitize)
+#define ABSL_ATTRIBUTE_NO_SANITIZE_UNDEFINED \
+  __attribute__((no_sanitize("undefined")))
+#else
+#define ABSL_ATTRIBUTE_NO_SANITIZE_UNDEFINED
+#endif
+
+// ABSL_ATTRIBUTE_NO_SANITIZE_CFI
+//
+// Tells the ControlFlowIntegrity sanitizer to not instrument a given function.
+// See https://clang.llvm.org/docs/ControlFlowIntegrity.html for details.
+#if ABSL_HAVE_ATTRIBUTE(no_sanitize)
+#define ABSL_ATTRIBUTE_NO_SANITIZE_CFI __attribute__((no_sanitize("cfi")))
+#else
+#define ABSL_ATTRIBUTE_NO_SANITIZE_CFI
+#endif
+
+// ABSL_ATTRIBUTE_NO_SANITIZE_SAFESTACK
+//
+// Tells the SafeStack to not instrument a given function.
+// See https://clang.llvm.org/docs/SafeStack.html for details.
+#if ABSL_HAVE_ATTRIBUTE(no_sanitize)
+#define ABSL_ATTRIBUTE_NO_SANITIZE_SAFESTACK \
+  __attribute__((no_sanitize("safe-stack")))
+#else
+#define ABSL_ATTRIBUTE_NO_SANITIZE_SAFESTACK
+#endif
+
+// ABSL_ATTRIBUTE_RETURNS_NONNULL
+//
+// Tells the compiler that a particular function never returns a null pointer.
+#if ABSL_HAVE_ATTRIBUTE(returns_nonnull) || \
+    (defined(__GNUC__) && \
+     (__GNUC__ > 5 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 9)) && \
+     !defined(__clang__))
+#define ABSL_ATTRIBUTE_RETURNS_NONNULL __attribute__((returns_nonnull))
+#else
+#define ABSL_ATTRIBUTE_RETURNS_NONNULL
+#endif
+
+// ABSL_HAVE_ATTRIBUTE_SECTION
+//
+// Indicates whether labeled sections are supported. Weak symbol support is
+// a prerequisite. Labeled sections are not supported on Darwin/iOS.
+#ifdef ABSL_HAVE_ATTRIBUTE_SECTION
+#error ABSL_HAVE_ATTRIBUTE_SECTION cannot be directly set
+#elif (ABSL_HAVE_ATTRIBUTE(section) ||                \
+       (defined(__GNUC__) && !defined(__clang__))) && \
+    !defined(__APPLE__) && ABSL_HAVE_ATTRIBUTE_WEAK
+#define ABSL_HAVE_ATTRIBUTE_SECTION 1
+
+// ABSL_ATTRIBUTE_SECTION
+//
+// Tells the compiler/linker to put a given function into a section and define
+// `__start_ ## name` and `__stop_ ## name` symbols to bracket the section.
+// This functionality is supported by GNU linker.  Any function annotated with
+// `ABSL_ATTRIBUTE_SECTION` must not be inlined, or it will be placed into
+// whatever section its caller is placed into.
+//
+#ifndef ABSL_ATTRIBUTE_SECTION
+#define ABSL_ATTRIBUTE_SECTION(name) \
+  __attribute__((section(#name))) __attribute__((noinline))
+#endif
+
+
+// ABSL_ATTRIBUTE_SECTION_VARIABLE
+//
+// Tells the compiler/linker to put a given variable into a section and define
+// `__start_ ## name` and `__stop_ ## name` symbols to bracket the section.
+// This functionality is supported by GNU linker.
+#ifndef ABSL_ATTRIBUTE_SECTION_VARIABLE
+#define ABSL_ATTRIBUTE_SECTION_VARIABLE(name) __attribute__((section(#name)))
+#endif
+
+// ABSL_DECLARE_ATTRIBUTE_SECTION_VARS
+//
+// A weak section declaration to be used as a global declaration
+// for ABSL_ATTRIBUTE_SECTION_START|STOP(name) to compile and link
+// even without functions with ABSL_ATTRIBUTE_SECTION(name).
+// ABSL_DEFINE_ATTRIBUTE_SECTION should be in the exactly one file; it's
+// a no-op on ELF but not on Mach-O.
+//
+#ifndef ABSL_DECLARE_ATTRIBUTE_SECTION_VARS
+#define ABSL_DECLARE_ATTRIBUTE_SECTION_VARS(name) \
+  extern char __start_##name[] ABSL_ATTRIBUTE_WEAK;    \
+  extern char __stop_##name[] ABSL_ATTRIBUTE_WEAK
+#endif
+#ifndef ABSL_DEFINE_ATTRIBUTE_SECTION_VARS
+#define ABSL_INIT_ATTRIBUTE_SECTION_VARS(name)
+#define ABSL_DEFINE_ATTRIBUTE_SECTION_VARS(name)
+#endif
+
+// ABSL_ATTRIBUTE_SECTION_START
+//
+// Returns `void*` pointers to start/end of a section of code with
+// functions having ABSL_ATTRIBUTE_SECTION(name).
+// Returns 0 if no such functions exist.
+// One must ABSL_DECLARE_ATTRIBUTE_SECTION_VARS(name) for this to compile and
+// link.
+//
+#define ABSL_ATTRIBUTE_SECTION_START(name) \
+  (reinterpret_cast<void *>(__start_##name))
+#define ABSL_ATTRIBUTE_SECTION_STOP(name) \
+  (reinterpret_cast<void *>(__stop_##name))
+
+#else  // !ABSL_HAVE_ATTRIBUTE_SECTION
+
+#define ABSL_HAVE_ATTRIBUTE_SECTION 0
+
+// provide dummy definitions
+#define ABSL_ATTRIBUTE_SECTION(name)
+#define ABSL_ATTRIBUTE_SECTION_VARIABLE(name)
+#define ABSL_INIT_ATTRIBUTE_SECTION_VARS(name)
+#define ABSL_DEFINE_ATTRIBUTE_SECTION_VARS(name)
+#define ABSL_DECLARE_ATTRIBUTE_SECTION_VARS(name)
+#define ABSL_ATTRIBUTE_SECTION_START(name) (reinterpret_cast<void *>(0))
+#define ABSL_ATTRIBUTE_SECTION_STOP(name) (reinterpret_cast<void *>(0))
+
+#endif  // ABSL_ATTRIBUTE_SECTION
+
+// ABSL_ATTRIBUTE_STACK_ALIGN_FOR_OLD_LIBC
+//
+// Support for aligning the stack on 32-bit x86.
+#if ABSL_HAVE_ATTRIBUTE(force_align_arg_pointer) || \
+    (defined(__GNUC__) && !defined(__clang__))
+#if defined(__i386__)
+#define ABSL_ATTRIBUTE_STACK_ALIGN_FOR_OLD_LIBC \
+  __attribute__((force_align_arg_pointer))
+#define ABSL_REQUIRE_STACK_ALIGN_TRAMPOLINE (0)
+#elif defined(__x86_64__)
+#define ABSL_REQUIRE_STACK_ALIGN_TRAMPOLINE (1)
+#define ABSL_ATTRIBUTE_STACK_ALIGN_FOR_OLD_LIBC
+#else  // !__i386__ && !__x86_64
+#define ABSL_REQUIRE_STACK_ALIGN_TRAMPOLINE (0)
+#define ABSL_ATTRIBUTE_STACK_ALIGN_FOR_OLD_LIBC
+#endif  // __i386__
+#else
+#define ABSL_ATTRIBUTE_STACK_ALIGN_FOR_OLD_LIBC
+#define ABSL_REQUIRE_STACK_ALIGN_TRAMPOLINE (0)
+#endif
+
+// ABSL_MUST_USE_RESULT
+//
+// Tells the compiler to warn about unused results.
+//
+// When annotating a function, it must appear as the first part of the
+// declaration or definition. The compiler will warn if the return value from
+// such a function is unused:
+//
+//   ABSL_MUST_USE_RESULT Sprocket* AllocateSprocket();
+//   AllocateSprocket();  // Triggers a warning.
+//
+// When annotating a class, it is equivalent to annotating every function which
+// returns an instance.
+//
+//   class ABSL_MUST_USE_RESULT Sprocket {};
+//   Sprocket();  // Triggers a warning.
+//
+//   Sprocket MakeSprocket();
+//   MakeSprocket();  // Triggers a warning.
+//
+// Note that references and pointers are not instances:
+//
+//   Sprocket* SprocketPointer();
+//   SprocketPointer();  // Does *not* trigger a warning.
+//
+// ABSL_MUST_USE_RESULT allows using cast-to-void to suppress the unused result
+// warning. For that, warn_unused_result is used only for clang but not for gcc.
+// https://gcc.gnu.org/bugzilla/show_bug.cgi?id=66425
+//
+// Note: past advice was to place the macro after the argument list.
+#if ABSL_HAVE_ATTRIBUTE(nodiscard)
+#define ABSL_MUST_USE_RESULT [[nodiscard]]
+#elif defined(__clang__) && ABSL_HAVE_ATTRIBUTE(warn_unused_result)
+#define ABSL_MUST_USE_RESULT __attribute__((warn_unused_result))
+#else
+#define ABSL_MUST_USE_RESULT
+#endif
+
+// ABSL_ATTRIBUTE_HOT, ABSL_ATTRIBUTE_COLD
+//
+// Tells GCC that a function is hot or cold. GCC can use this information to
+// improve static analysis, i.e. a conditional branch to a cold function
+// is likely to be not-taken.
+// This annotation is used for function declarations.
+//
+// Example:
+//
+//   int foo() ABSL_ATTRIBUTE_HOT;
+#if ABSL_HAVE_ATTRIBUTE(hot) || (defined(__GNUC__) && !defined(__clang__))
+#define ABSL_ATTRIBUTE_HOT __attribute__((hot))
+#else
+#define ABSL_ATTRIBUTE_HOT
+#endif
+
+#if ABSL_HAVE_ATTRIBUTE(cold) || (defined(__GNUC__) && !defined(__clang__))
+#define ABSL_ATTRIBUTE_COLD __attribute__((cold))
+#else
+#define ABSL_ATTRIBUTE_COLD
+#endif
+
+// ABSL_XRAY_ALWAYS_INSTRUMENT, ABSL_XRAY_NEVER_INSTRUMENT, ABSL_XRAY_LOG_ARGS
+//
+// We define the ABSL_XRAY_ALWAYS_INSTRUMENT and ABSL_XRAY_NEVER_INSTRUMENT
+// macro used as an attribute to mark functions that must always or never be
+// instrumented by XRay. Currently, this is only supported in Clang/LLVM.
+//
+// For reference on the LLVM XRay instrumentation, see
+// http://llvm.org/docs/XRay.html.
+//
+// A function with the XRAY_ALWAYS_INSTRUMENT macro attribute in its declaration
+// will always get the XRay instrumentation sleds. These sleds may introduce
+// some binary size and runtime overhead and must be used sparingly.
+//
+// These attributes only take effect when the following conditions are met:
+//
+//   * The file/target is built in at least C++11 mode, with a Clang compiler
+//     that supports XRay attributes.
+//   * The file/target is built with the -fxray-instrument flag set for the
+//     Clang/LLVM compiler.
+//   * The function is defined in the translation unit (the compiler honors the
+//     attribute in either the definition or the declaration, and must match).
+//
+// There are cases when, even when building with XRay instrumentation, users
+// might want to control specifically which functions are instrumented for a
+// particular build using special-case lists provided to the compiler. These
+// special case lists are provided to Clang via the
+// -fxray-always-instrument=... and -fxray-never-instrument=... flags. The
+// attributes in source take precedence over these special-case lists.
+//
+// To disable the XRay attributes at build-time, users may define
+// ABSL_NO_XRAY_ATTRIBUTES. Do NOT define ABSL_NO_XRAY_ATTRIBUTES on specific
+// packages/targets, as this may lead to conflicting definitions of functions at
+// link-time.
+//
+// XRay isn't currently supported on Android:
+// https://github.com/android/ndk/issues/368
+#if ABSL_HAVE_CPP_ATTRIBUTE(clang::xray_always_instrument) && \
+    !defined(ABSL_NO_XRAY_ATTRIBUTES) && !defined(__ANDROID__)
+#define ABSL_XRAY_ALWAYS_INSTRUMENT [[clang::xray_always_instrument]]
+#define ABSL_XRAY_NEVER_INSTRUMENT [[clang::xray_never_instrument]]
+#if ABSL_HAVE_CPP_ATTRIBUTE(clang::xray_log_args)
+#define ABSL_XRAY_LOG_ARGS(N) \
+    [[clang::xray_always_instrument, clang::xray_log_args(N)]]
+#else
+#define ABSL_XRAY_LOG_ARGS(N) [[clang::xray_always_instrument]]
+#endif
+#else
+#define ABSL_XRAY_ALWAYS_INSTRUMENT
+#define ABSL_XRAY_NEVER_INSTRUMENT
+#define ABSL_XRAY_LOG_ARGS(N)
+#endif
+
+// ABSL_ATTRIBUTE_REINITIALIZES
+//
+// Indicates that a member function reinitializes the entire object to a known
+// state, independent of the previous state of the object.
+//
+// The clang-tidy check bugprone-use-after-move allows member functions marked
+// with this attribute to be called on objects that have been moved from;
+// without the attribute, this would result in a use-after-move warning.
+#if ABSL_HAVE_CPP_ATTRIBUTE(clang::reinitializes)
+#define ABSL_ATTRIBUTE_REINITIALIZES [[clang::reinitializes]]
+#else
+#define ABSL_ATTRIBUTE_REINITIALIZES
+#endif
+
+// -----------------------------------------------------------------------------
+// Variable Attributes
+// -----------------------------------------------------------------------------
+
+// ABSL_ATTRIBUTE_UNUSED
+//
+// Prevents the compiler from complaining about variables that appear unused.
+//
+// For code or headers that are assured to only build with C++17 and up, prefer
+// just using the standard '[[maybe_unused]]' directly over this macro.
+//
+// Due to differences in positioning requirements between the old, compiler
+// specific __attribute__ syntax and the now standard [[maybe_unused]], this
+// macro does not attempt to take advantage of '[[maybe_unused]]'.
+#if ABSL_HAVE_ATTRIBUTE(unused) || (defined(__GNUC__) && !defined(__clang__))
+#undef ABSL_ATTRIBUTE_UNUSED
+#define ABSL_ATTRIBUTE_UNUSED __attribute__((__unused__))
+#else
+#define ABSL_ATTRIBUTE_UNUSED
+#endif
+
+// ABSL_ATTRIBUTE_INITIAL_EXEC
+//
+// Tells the compiler to use "initial-exec" mode for a thread-local variable.
+// See http://people.redhat.com/drepper/tls.pdf for the gory details.
+#if ABSL_HAVE_ATTRIBUTE(tls_model) || (defined(__GNUC__) && !defined(__clang__))
+#define ABSL_ATTRIBUTE_INITIAL_EXEC __attribute__((tls_model("initial-exec")))
+#else
+#define ABSL_ATTRIBUTE_INITIAL_EXEC
+#endif
+
+// ABSL_ATTRIBUTE_PACKED
+//
+// Instructs the compiler not to use natural alignment for a tagged data
+// structure, but instead to reduce its alignment to 1. This attribute can
+// either be applied to members of a structure or to a structure in its
+// entirety. Applying this attribute (judiciously) to a structure in its
+// entirety to optimize the memory footprint of very commonly-used structs is
+// fine. Do not apply this attribute to a structure in its entirety if the
+// purpose is to control the offsets of the members in the structure. Instead,
+// apply this attribute only to structure members that need it.
+//
+// When applying ABSL_ATTRIBUTE_PACKED only to specific structure members the
+// natural alignment of structure members not annotated is preserved. Aligned
+// member accesses are faster than non-aligned member accesses even if the
+// targeted microprocessor supports non-aligned accesses.
+#if ABSL_HAVE_ATTRIBUTE(packed) || (defined(__GNUC__) && !defined(__clang__))
+#define ABSL_ATTRIBUTE_PACKED __attribute__((__packed__))
+#else
+#define ABSL_ATTRIBUTE_PACKED
+#endif
+
+// ABSL_ATTRIBUTE_FUNC_ALIGN
+//
+// Tells the compiler to align the function start at least to certain
+// alignment boundary
+#if ABSL_HAVE_ATTRIBUTE(aligned) || (defined(__GNUC__) && !defined(__clang__))
+#define ABSL_ATTRIBUTE_FUNC_ALIGN(bytes) __attribute__((aligned(bytes)))
+#else
+#define ABSL_ATTRIBUTE_FUNC_ALIGN(bytes)
+#endif
+
+// ABSL_FALLTHROUGH_INTENDED
+//
+// Annotates implicit fall-through between switch labels, allowing a case to
+// indicate intentional fallthrough and turn off warnings about any lack of a
+// `break` statement. The ABSL_FALLTHROUGH_INTENDED macro should be followed by
+// a semicolon and can be used in most places where `break` can, provided that
+// no statements exist between it and the next switch label.
+//
+// Example:
+//
+//  switch (x) {
+//    case 40:
+//    case 41:
+//      if (truth_is_out_there) {
+//        ++x;
+//        ABSL_FALLTHROUGH_INTENDED;  // Use instead of/along with annotations
+//                                    // in comments
+//      } else {
+//        return x;
+//      }
+//    case 42:
+//      ...
+//
+// Notes: when compiled with clang in C++11 mode, the ABSL_FALLTHROUGH_INTENDED
+// macro is expanded to the [[clang::fallthrough]] attribute, which is analysed
+// when  performing switch labels fall-through diagnostic
+// (`-Wimplicit-fallthrough`). See clang documentation on language extensions
+// for details:
+// https://clang.llvm.org/docs/AttributeReference.html#fallthrough-clang-fallthrough
+//
+// When used with unsupported compilers, the ABSL_FALLTHROUGH_INTENDED macro
+// has no effect on diagnostics. In any case this macro has no effect on runtime
+// behavior and performance of code.
+
+#ifdef ABSL_FALLTHROUGH_INTENDED
+#error "ABSL_FALLTHROUGH_INTENDED should not be defined."
+#endif
+
+// TODO(zhangxy): Use c++17 standard [[fallthrough]] macro, when supported.
+#if defined(__clang__) && defined(__has_warning)
+#if __has_feature(cxx_attributes) && __has_warning("-Wimplicit-fallthrough")
+#define ABSL_FALLTHROUGH_INTENDED [[clang::fallthrough]]
+#endif
+#elif defined(__GNUC__) && __GNUC__ >= 7
+#define ABSL_FALLTHROUGH_INTENDED [[gnu::fallthrough]]
+#endif
+
+#ifndef ABSL_FALLTHROUGH_INTENDED
+#define ABSL_FALLTHROUGH_INTENDED \
+  do {                            \
+  } while (0)
+#endif
+
+// ABSL_DEPRECATED()
+//
+// Marks a deprecated class, struct, enum, function, method and variable
+// declarations. The macro argument is used as a custom diagnostic message (e.g.
+// suggestion of a better alternative).
+//
+// Examples:
+//
+//   class ABSL_DEPRECATED("Use Bar instead") Foo {...};
+//
+//   ABSL_DEPRECATED("Use Baz() instead") void Bar() {...}
+//
+//   template <typename T>
+//   ABSL_DEPRECATED("Use DoThat() instead")
+//   void DoThis();
+//
+// Every usage of a deprecated entity will trigger a warning when compiled with
+// clang's `-Wdeprecated-declarations` option. This option is turned off by
+// default, but the warnings will be reported by clang-tidy.
+#if defined(__clang__) && defined(__cplusplus) && __cplusplus >= 201103L
+#define ABSL_DEPRECATED(message) __attribute__((deprecated(message)))
+#endif
+
+#ifndef ABSL_DEPRECATED
+#define ABSL_DEPRECATED(message)
+#endif
+
+// ABSL_CONST_INIT
+//
+// A variable declaration annotated with the `ABSL_CONST_INIT` attribute will
+// not compile (on supported platforms) unless the variable has a constant
+// initializer. This is useful for variables with static and thread storage
+// duration, because it guarantees that they will not suffer from the so-called
+// "static init order fiasco".  Prefer to put this attribute on the most visible
+// declaration of the variable, if there's more than one, because code that
+// accesses the variable can then use the attribute for optimization.
+//
+// Example:
+//
+//   class MyClass {
+//    public:
+//     ABSL_CONST_INIT static MyType my_var;
+//   };
+//
+//   MyType MyClass::my_var = MakeMyType(...);
+//
+// Note that this attribute is redundant if the variable is declared constexpr.
+#if ABSL_HAVE_CPP_ATTRIBUTE(clang::require_constant_initialization)
+#define ABSL_CONST_INIT [[clang::require_constant_initialization]]
+#else
+#define ABSL_CONST_INIT
+#endif  // ABSL_HAVE_CPP_ATTRIBUTE(clang::require_constant_initialization)
+
+// ABSL_ATTRIBUTE_PURE_FUNCTION
+//
+// ABSL_ATTRIBUTE_PURE_FUNCTION is used to annotate declarations of "pure"
+// functions. A function is pure if its return value is only a function of its
+// arguments. The pure attribute prohibits a function from modifying the state
+// of the program that is observable by means other than inspecting the
+// function's return value. Declaring such functions with the pure attribute
+// allows the compiler to avoid emitting some calls in repeated invocations of
+// the function with the same argument values.
+//
+// Example:
+//
+//  ABSL_ATTRIBUTE_PURE_FUNCTION int64_t ToInt64Milliseconds(Duration d);
+#if ABSL_HAVE_CPP_ATTRIBUTE(gnu::pure)
+#define ABSL_ATTRIBUTE_PURE_FUNCTION [[gnu::pure]]
+#elif ABSL_HAVE_ATTRIBUTE(pure)
+#define ABSL_ATTRIBUTE_PURE_FUNCTION __attribute__((pure))
+#else
+#define ABSL_ATTRIBUTE_PURE_FUNCTION
+#endif
+
+// ABSL_ATTRIBUTE_LIFETIME_BOUND indicates that a resource owned by a function
+// parameter or implicit object parameter is retained by the return value of the
+// annotated function (or, for a parameter of a constructor, in the value of the
+// constructed object). This attribute causes warnings to be produced if a
+// temporary object does not live long enough.
+//
+// When applied to a reference parameter, the referenced object is assumed to be
+// retained by the return value of the function. When applied to a non-reference
+// parameter (for example, a pointer or a class type), all temporaries
+// referenced by the parameter are assumed to be retained by the return value of
+// the function.
+//
+// See also the upstream documentation:
+// https://clang.llvm.org/docs/AttributeReference.html#lifetimebound
+#if ABSL_HAVE_CPP_ATTRIBUTE(clang::lifetimebound)
+#define ABSL_ATTRIBUTE_LIFETIME_BOUND [[clang::lifetimebound]]
+#elif ABSL_HAVE_ATTRIBUTE(lifetimebound)
+#define ABSL_ATTRIBUTE_LIFETIME_BOUND __attribute__((lifetimebound))
+#else
+#define ABSL_ATTRIBUTE_LIFETIME_BOUND
+#endif
+
+#endif  // ABSL_BASE_ATTRIBUTES_H_
diff --git a/third_party/webrtc_aec3/src/absl/base/config.h b/third_party/webrtc_aec3/src/absl/base/config.h
new file mode 100644
index 0000000..7abc75a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/config.h
@@ -0,0 +1,730 @@
+//
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+// -----------------------------------------------------------------------------
+// File: config.h
+// -----------------------------------------------------------------------------
+//
+// This header file defines a set of macros for checking the presence of
+// important compiler and platform features. Such macros can be used to
+// produce portable code by parameterizing compilation based on the presence or
+// lack of a given feature.
+//
+// We define a "feature" as some interface we wish to program to: for example,
+// a library function or system call. A value of `1` indicates support for
+// that feature; any other value indicates the feature support is undefined.
+//
+// Example:
+//
+// Suppose a programmer wants to write a program that uses the 'mmap()' system
+// call. The Abseil macro for that feature (`ABSL_HAVE_MMAP`) allows you to
+// selectively include the `mmap.h` header and bracket code using that feature
+// in the macro:
+//
+//   #include "absl/base/config.h"
+//
+//   #ifdef ABSL_HAVE_MMAP
+//   #include "sys/mman.h"
+//   #endif  //ABSL_HAVE_MMAP
+//
+//   ...
+//   #ifdef ABSL_HAVE_MMAP
+//   void *ptr = mmap(...);
+//   ...
+//   #endif  // ABSL_HAVE_MMAP
+
+#ifndef ABSL_BASE_CONFIG_H_
+#define ABSL_BASE_CONFIG_H_
+
+// Included for the __GLIBC__ macro (or similar macros on other systems).
+#include <limits.h>
+
+#ifdef __cplusplus
+// Included for __GLIBCXX__, _LIBCPP_VERSION
+#include <cstddef>
+#endif  // __cplusplus
+
+#if defined(__APPLE__)
+// Included for TARGET_OS_IPHONE, __IPHONE_OS_VERSION_MIN_REQUIRED,
+// __IPHONE_8_0.
+#include <Availability.h>
+#include <TargetConditionals.h>
+#endif
+
+#include "absl/base/options.h"
+#include "absl/base/policy_checks.h"
+
+// Helper macro to convert a CPP variable to a string literal.
+#define ABSL_INTERNAL_DO_TOKEN_STR(x) #x
+#define ABSL_INTERNAL_TOKEN_STR(x) ABSL_INTERNAL_DO_TOKEN_STR(x)
+
+// -----------------------------------------------------------------------------
+// Abseil namespace annotations
+// -----------------------------------------------------------------------------
+
+// ABSL_NAMESPACE_BEGIN/ABSL_NAMESPACE_END
+//
+// An annotation placed at the beginning/end of each `namespace absl` scope.
+// This is used to inject an inline namespace.
+//
+// The proper way to write Abseil code in the `absl` namespace is:
+//
+// namespace absl {
+// ABSL_NAMESPACE_BEGIN
+//
+// void Foo();  // absl::Foo().
+//
+// ABSL_NAMESPACE_END
+// }  // namespace absl
+//
+// Users of Abseil should not use these macros, because users of Abseil should
+// not write `namespace absl {` in their own code for any reason.  (Abseil does
+// not support forward declarations of its own types, nor does it support
+// user-provided specialization of Abseil templates.  Code that violates these
+// rules may be broken without warning.)
+#if !defined(ABSL_OPTION_USE_INLINE_NAMESPACE) || \
+    !defined(ABSL_OPTION_INLINE_NAMESPACE_NAME)
+#error options.h is misconfigured.
+#endif
+
+// Check that ABSL_OPTION_INLINE_NAMESPACE_NAME is neither "head" nor ""
+#if defined(__cplusplus) && ABSL_OPTION_USE_INLINE_NAMESPACE == 1
+
+#define ABSL_INTERNAL_INLINE_NAMESPACE_STR \
+  ABSL_INTERNAL_TOKEN_STR(ABSL_OPTION_INLINE_NAMESPACE_NAME)
+
+static_assert(ABSL_INTERNAL_INLINE_NAMESPACE_STR[0] != '\0',
+              "options.h misconfigured: ABSL_OPTION_INLINE_NAMESPACE_NAME must "
+              "not be empty.");
+static_assert(ABSL_INTERNAL_INLINE_NAMESPACE_STR[0] != 'h' ||
+                  ABSL_INTERNAL_INLINE_NAMESPACE_STR[1] != 'e' ||
+                  ABSL_INTERNAL_INLINE_NAMESPACE_STR[2] != 'a' ||
+                  ABSL_INTERNAL_INLINE_NAMESPACE_STR[3] != 'd' ||
+                  ABSL_INTERNAL_INLINE_NAMESPACE_STR[4] != '\0',
+              "options.h misconfigured: ABSL_OPTION_INLINE_NAMESPACE_NAME must "
+              "be changed to a new, unique identifier name.");
+
+#endif
+
+#if ABSL_OPTION_USE_INLINE_NAMESPACE == 0
+#define ABSL_NAMESPACE_BEGIN
+#define ABSL_NAMESPACE_END
+#define ABSL_INTERNAL_C_SYMBOL(x) x
+#elif ABSL_OPTION_USE_INLINE_NAMESPACE == 1
+#define ABSL_NAMESPACE_BEGIN \
+  inline namespace ABSL_OPTION_INLINE_NAMESPACE_NAME {
+#define ABSL_NAMESPACE_END }
+#define ABSL_INTERNAL_C_SYMBOL_HELPER_2(x, v) x##_##v
+#define ABSL_INTERNAL_C_SYMBOL_HELPER_1(x, v) \
+  ABSL_INTERNAL_C_SYMBOL_HELPER_2(x, v)
+#define ABSL_INTERNAL_C_SYMBOL(x) \
+  ABSL_INTERNAL_C_SYMBOL_HELPER_1(x, ABSL_OPTION_INLINE_NAMESPACE_NAME)
+#else
+#error options.h is misconfigured.
+#endif
+
+// -----------------------------------------------------------------------------
+// Compiler Feature Checks
+// -----------------------------------------------------------------------------
+
+// ABSL_HAVE_BUILTIN()
+//
+// Checks whether the compiler supports a Clang Feature Checking Macro, and if
+// so, checks whether it supports the provided builtin function "x" where x
+// is one of the functions noted in
+// https://clang.llvm.org/docs/LanguageExtensions.html
+//
+// Note: Use this macro to avoid an extra level of #ifdef __has_builtin check.
+// http://releases.llvm.org/3.3/tools/clang/docs/LanguageExtensions.html
+#ifdef __has_builtin
+#define ABSL_HAVE_BUILTIN(x) __has_builtin(x)
+#else
+#define ABSL_HAVE_BUILTIN(x) 0
+#endif
+
+#if defined(__is_identifier)
+#define ABSL_INTERNAL_HAS_KEYWORD(x) !(__is_identifier(x))
+#else
+#define ABSL_INTERNAL_HAS_KEYWORD(x) 0
+#endif
+
+#ifdef __has_feature
+#define ABSL_HAVE_FEATURE(f) __has_feature(f)
+#else
+#define ABSL_HAVE_FEATURE(f) 0
+#endif
+
+// ABSL_HAVE_TLS is defined to 1 when __thread should be supported.
+// We assume __thread is supported on Linux when compiled with Clang or compiled
+// against libstdc++ with _GLIBCXX_HAVE_TLS defined.
+#ifdef ABSL_HAVE_TLS
+#error ABSL_HAVE_TLS cannot be directly set
+#elif defined(__linux__) && (defined(__clang__) || defined(_GLIBCXX_HAVE_TLS))
+#define ABSL_HAVE_TLS 1
+#endif
+
+// ABSL_HAVE_STD_IS_TRIVIALLY_DESTRUCTIBLE
+//
+// Checks whether `std::is_trivially_destructible<T>` is supported.
+//
+// Notes: All supported compilers using libc++ support this feature, as does
+// gcc >= 4.8.1 using libstdc++, and Visual Studio.
+#ifdef ABSL_HAVE_STD_IS_TRIVIALLY_DESTRUCTIBLE
+#error ABSL_HAVE_STD_IS_TRIVIALLY_DESTRUCTIBLE cannot be directly set
+#elif defined(_LIBCPP_VERSION) ||                                        \
+    (!defined(__clang__) && defined(__GNUC__) && defined(__GLIBCXX__) && \
+     (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 8))) ||        \
+    defined(_MSC_VER)
+#define ABSL_HAVE_STD_IS_TRIVIALLY_DESTRUCTIBLE 1
+#endif
+
+// ABSL_HAVE_STD_IS_TRIVIALLY_CONSTRUCTIBLE
+//
+// Checks whether `std::is_trivially_default_constructible<T>` and
+// `std::is_trivially_copy_constructible<T>` are supported.
+
+// ABSL_HAVE_STD_IS_TRIVIALLY_ASSIGNABLE
+//
+// Checks whether `std::is_trivially_copy_assignable<T>` is supported.
+
+// Notes: Clang with libc++ supports these features, as does gcc >= 5.1 with
+// either libc++ or libstdc++, and Visual Studio (but not NVCC).
+#if defined(ABSL_HAVE_STD_IS_TRIVIALLY_CONSTRUCTIBLE)
+#error ABSL_HAVE_STD_IS_TRIVIALLY_CONSTRUCTIBLE cannot be directly set
+#elif defined(ABSL_HAVE_STD_IS_TRIVIALLY_ASSIGNABLE)
+#error ABSL_HAVE_STD_IS_TRIVIALLY_ASSIGNABLE cannot directly set
+#elif (defined(__clang__) && defined(_LIBCPP_VERSION)) ||        \
+    (!defined(__clang__) && defined(__GNUC__) &&                 \
+     (__GNUC__ > 7 || (__GNUC__ == 7 && __GNUC_MINOR__ >= 4)) && \
+     (defined(_LIBCPP_VERSION) || defined(__GLIBCXX__))) ||      \
+    (defined(_MSC_VER) && !defined(__NVCC__))
+#define ABSL_HAVE_STD_IS_TRIVIALLY_CONSTRUCTIBLE 1
+#define ABSL_HAVE_STD_IS_TRIVIALLY_ASSIGNABLE 1
+#endif
+
+// ABSL_HAVE_SOURCE_LOCATION_CURRENT
+//
+// Indicates whether `absl::SourceLocation::current()` will return useful
+// information in some contexts.
+#ifndef ABSL_HAVE_SOURCE_LOCATION_CURRENT
+#if ABSL_INTERNAL_HAS_KEYWORD(__builtin_LINE) && \
+    ABSL_INTERNAL_HAS_KEYWORD(__builtin_FILE)
+#define ABSL_HAVE_SOURCE_LOCATION_CURRENT 1
+#elif defined(__GNUC__) && __GNUC__ >= 5
+#define ABSL_HAVE_SOURCE_LOCATION_CURRENT 1
+#endif
+#endif
+
+// ABSL_HAVE_THREAD_LOCAL
+//
+// Checks whether C++11's `thread_local` storage duration specifier is
+// supported.
+#ifdef ABSL_HAVE_THREAD_LOCAL
+#error ABSL_HAVE_THREAD_LOCAL cannot be directly set
+#elif defined(__APPLE__)
+// Notes:
+// * Xcode's clang did not support `thread_local` until version 8, and
+//   even then not for all iOS < 9.0.
+// * Xcode 9.3 started disallowing `thread_local` for 32-bit iOS simulator
+//   targeting iOS 9.x.
+// * Xcode 10 moves the deployment target check for iOS < 9.0 to link time
+//   making ABSL_HAVE_FEATURE unreliable there.
+//
+#if ABSL_HAVE_FEATURE(cxx_thread_local) && \
+    !(TARGET_OS_IPHONE && __IPHONE_OS_VERSION_MIN_REQUIRED < __IPHONE_9_0)
+#define ABSL_HAVE_THREAD_LOCAL 1
+#endif
+#else  // !defined(__APPLE__)
+#define ABSL_HAVE_THREAD_LOCAL 1
+#endif
+
+// There are platforms for which TLS should not be used even though the compiler
+// makes it seem like it's supported (Android NDK < r12b for example).
+// This is primarily because of linker problems and toolchain misconfiguration:
+// Abseil does not intend to support this indefinitely. Currently, the newest
+// toolchain that we intend to support that requires this behavior is the
+// r11 NDK - allowing for a 5 year support window on that means this option
+// is likely to be removed around June of 2021.
+// TLS isn't supported until NDK r12b per
+// https://developer.android.com/ndk/downloads/revision_history.html
+// Since NDK r16, `__NDK_MAJOR__` and `__NDK_MINOR__` are defined in
+// <android/ndk-version.h>. For NDK < r16, users should define these macros,
+// e.g. `-D__NDK_MAJOR__=11 -D__NKD_MINOR__=0` for NDK r11.
+#if defined(__ANDROID__) && defined(__clang__)
+#if __has_include(<android/ndk-version.h>)
+#include <android/ndk-version.h>
+#endif  // __has_include(<android/ndk-version.h>)
+#if defined(__ANDROID__) && defined(__clang__) && defined(__NDK_MAJOR__) && \
+    defined(__NDK_MINOR__) &&                                               \
+    ((__NDK_MAJOR__ < 12) || ((__NDK_MAJOR__ == 12) && (__NDK_MINOR__ < 1)))
+#undef ABSL_HAVE_TLS
+#undef ABSL_HAVE_THREAD_LOCAL
+#endif
+#endif  // defined(__ANDROID__) && defined(__clang__)
+
+// ABSL_HAVE_INTRINSIC_INT128
+//
+// Checks whether the __int128 compiler extension for a 128-bit integral type is
+// supported.
+//
+// Note: __SIZEOF_INT128__ is defined by Clang and GCC when __int128 is
+// supported, but we avoid using it in certain cases:
+// * On Clang:
+//   * Building using Clang for Windows, where the Clang runtime library has
+//     128-bit support only on LP64 architectures, but Windows is LLP64.
+// * On Nvidia's nvcc:
+//   * nvcc also defines __GNUC__ and __SIZEOF_INT128__, but not all versions
+//     actually support __int128.
+#ifdef ABSL_HAVE_INTRINSIC_INT128
+#error ABSL_HAVE_INTRINSIC_INT128 cannot be directly set
+#elif defined(__SIZEOF_INT128__)
+#if (defined(__clang__) && !defined(_WIN32)) || \
+    (defined(__CUDACC__) && __CUDACC_VER_MAJOR__ >= 9) ||                \
+    (defined(__GNUC__) && !defined(__clang__) && !defined(__CUDACC__))
+#define ABSL_HAVE_INTRINSIC_INT128 1
+#elif defined(__CUDACC__)
+// __CUDACC_VER__ is a full version number before CUDA 9, and is defined to a
+// string explaining that it has been removed starting with CUDA 9. We use
+// nested #ifs because there is no short-circuiting in the preprocessor.
+// NOTE: `__CUDACC__` could be undefined while `__CUDACC_VER__` is defined.
+#if __CUDACC_VER__ >= 70000
+#define ABSL_HAVE_INTRINSIC_INT128 1
+#endif  // __CUDACC_VER__ >= 70000
+#endif  // defined(__CUDACC__)
+#endif  // ABSL_HAVE_INTRINSIC_INT128
+
+// ABSL_HAVE_EXCEPTIONS
+//
+// Checks whether the compiler both supports and enables exceptions. Many
+// compilers support a "no exceptions" mode that disables exceptions.
+//
+// Generally, when ABSL_HAVE_EXCEPTIONS is not defined:
+//
+// * Code using `throw` and `try` may not compile.
+// * The `noexcept` specifier will still compile and behave as normal.
+// * The `noexcept` operator may still return `false`.
+//
+// For further details, consult the compiler's documentation.
+#ifdef ABSL_HAVE_EXCEPTIONS
+#error ABSL_HAVE_EXCEPTIONS cannot be directly set.
+
+#elif defined(__clang__)
+
+#if __clang_major__ > 3 || (__clang_major__ == 3 && __clang_minor__ >= 6)
+// Clang >= 3.6
+#if ABSL_HAVE_FEATURE(cxx_exceptions)
+#define ABSL_HAVE_EXCEPTIONS 1
+#endif  // ABSL_HAVE_FEATURE(cxx_exceptions)
+#else
+// Clang < 3.6
+// http://releases.llvm.org/3.6.0/tools/clang/docs/ReleaseNotes.html#the-exceptions-macro
+#if defined(__EXCEPTIONS) && ABSL_HAVE_FEATURE(cxx_exceptions)
+#define ABSL_HAVE_EXCEPTIONS 1
+#endif  // defined(__EXCEPTIONS) && ABSL_HAVE_FEATURE(cxx_exceptions)
+#endif  // __clang_major__ > 3 || (__clang_major__ == 3 && __clang_minor__ >= 6)
+
+// Handle remaining special cases and default to exceptions being supported.
+#elif !(defined(__GNUC__) && (__GNUC__ < 5) && !defined(__EXCEPTIONS)) &&    \
+    !(defined(__GNUC__) && (__GNUC__ >= 5) && !defined(__cpp_exceptions)) && \
+    !(defined(_MSC_VER) && !defined(_CPPUNWIND))
+#define ABSL_HAVE_EXCEPTIONS 1
+#endif
+
+// -----------------------------------------------------------------------------
+// Platform Feature Checks
+// -----------------------------------------------------------------------------
+
+// Currently supported operating systems and associated preprocessor
+// symbols:
+//
+//   Linux and Linux-derived           __linux__
+//   Android                           __ANDROID__ (implies __linux__)
+//   Linux (non-Android)               __linux__ && !__ANDROID__
+//   Darwin (macOS and iOS)            __APPLE__
+//   Akaros (http://akaros.org)        __ros__
+//   Windows                           _WIN32
+//   NaCL                              __native_client__
+//   AsmJS                             __asmjs__
+//   WebAssembly                       __wasm__
+//   Fuchsia                           __Fuchsia__
+//
+// Note that since Android defines both __ANDROID__ and __linux__, one
+// may probe for either Linux or Android by simply testing for __linux__.
+
+// ABSL_HAVE_MMAP
+//
+// Checks whether the platform has an mmap(2) implementation as defined in
+// POSIX.1-2001.
+#ifdef ABSL_HAVE_MMAP
+#error ABSL_HAVE_MMAP cannot be directly set
+#elif defined(__linux__) || defined(__APPLE__) || defined(__FreeBSD__) ||   \
+    defined(__ros__) || defined(__native_client__) || defined(__asmjs__) || \
+    defined(__wasm__) || defined(__Fuchsia__) || defined(__sun) || \
+    defined(__ASYLO__) || defined(__myriad2__)
+#define ABSL_HAVE_MMAP 1
+#endif
+
+// ABSL_HAVE_PTHREAD_GETSCHEDPARAM
+//
+// Checks whether the platform implements the pthread_(get|set)schedparam(3)
+// functions as defined in POSIX.1-2001.
+#ifdef ABSL_HAVE_PTHREAD_GETSCHEDPARAM
+#error ABSL_HAVE_PTHREAD_GETSCHEDPARAM cannot be directly set
+#elif defined(__linux__) || defined(__APPLE__) || defined(__FreeBSD__) || \
+    defined(__ros__)
+#define ABSL_HAVE_PTHREAD_GETSCHEDPARAM 1
+#endif
+
+// ABSL_HAVE_SCHED_GETCPU
+//
+// Checks whether sched_getcpu is available.
+#ifdef ABSL_HAVE_SCHED_GETCPU
+#error ABSL_HAVE_SCHED_GETCPU cannot be directly set
+#elif defined(__linux__)
+#define ABSL_HAVE_SCHED_GETCPU 1
+#endif
+
+// ABSL_HAVE_SCHED_YIELD
+//
+// Checks whether the platform implements sched_yield(2) as defined in
+// POSIX.1-2001.
+#ifdef ABSL_HAVE_SCHED_YIELD
+#error ABSL_HAVE_SCHED_YIELD cannot be directly set
+#elif defined(__linux__) || defined(__ros__) || defined(__native_client__)
+#define ABSL_HAVE_SCHED_YIELD 1
+#endif
+
+// ABSL_HAVE_SEMAPHORE_H
+//
+// Checks whether the platform supports the <semaphore.h> header and sem_init(3)
+// family of functions as standardized in POSIX.1-2001.
+//
+// Note: While Apple provides <semaphore.h> for both iOS and macOS, it is
+// explicitly deprecated and will cause build failures if enabled for those
+// platforms.  We side-step the issue by not defining it here for Apple
+// platforms.
+#ifdef ABSL_HAVE_SEMAPHORE_H
+#error ABSL_HAVE_SEMAPHORE_H cannot be directly set
+#elif defined(__linux__) || defined(__ros__)
+#define ABSL_HAVE_SEMAPHORE_H 1
+#endif
+
+// ABSL_HAVE_ALARM
+//
+// Checks whether the platform supports the <signal.h> header and alarm(2)
+// function as standardized in POSIX.1-2001.
+#ifdef ABSL_HAVE_ALARM
+#error ABSL_HAVE_ALARM cannot be directly set
+#elif defined(__GOOGLE_GRTE_VERSION__)
+// feature tests for Google's GRTE
+#define ABSL_HAVE_ALARM 1
+#elif defined(__GLIBC__)
+// feature test for glibc
+#define ABSL_HAVE_ALARM 1
+#elif defined(_MSC_VER)
+// feature tests for Microsoft's library
+#elif defined(__MINGW32__)
+// mingw32 doesn't provide alarm(2):
+// https://osdn.net/projects/mingw/scm/git/mingw-org-wsl/blobs/5.2-trunk/mingwrt/include/unistd.h
+// mingw-w64 provides a no-op implementation:
+// https://sourceforge.net/p/mingw-w64/mingw-w64/ci/master/tree/mingw-w64-crt/misc/alarm.c
+#elif defined(__EMSCRIPTEN__)
+// emscripten doesn't support signals
+#elif defined(__Fuchsia__)
+// Signals don't exist on fuchsia.
+#elif defined(__native_client__)
+#else
+// other standard libraries
+#define ABSL_HAVE_ALARM 1
+#endif
+
+// ABSL_IS_LITTLE_ENDIAN
+// ABSL_IS_BIG_ENDIAN
+//
+// Checks the endianness of the platform.
+//
+// Notes: uses the built in endian macros provided by GCC (since 4.6) and
+// Clang (since 3.2); see
+// https://gcc.gnu.org/onlinedocs/cpp/Common-Predefined-Macros.html.
+// Otherwise, if _WIN32, assume little endian. Otherwise, bail with an error.
+#if defined(ABSL_IS_BIG_ENDIAN)
+#error "ABSL_IS_BIG_ENDIAN cannot be directly set."
+#endif
+#if defined(ABSL_IS_LITTLE_ENDIAN)
+#error "ABSL_IS_LITTLE_ENDIAN cannot be directly set."
+#endif
+
+#if (defined(__BYTE_ORDER__) && defined(__ORDER_LITTLE_ENDIAN__) && \
+     __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__)
+#define ABSL_IS_LITTLE_ENDIAN 1
+#elif defined(__BYTE_ORDER__) && defined(__ORDER_BIG_ENDIAN__) && \
+    __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__
+#define ABSL_IS_BIG_ENDIAN 1
+#elif defined(_WIN32)
+#define ABSL_IS_LITTLE_ENDIAN 1
+#else
+#error "absl endian detection needs to be set up for your compiler"
+#endif
+
+// macOS 10.13 and iOS 10.11 don't let you use <any>, <optional>, or <variant>
+// even though the headers exist and are publicly noted to work.  See
+// https://github.com/abseil/abseil-cpp/issues/207 and
+// https://developer.apple.com/documentation/xcode_release_notes/xcode_10_release_notes
+// libc++ spells out the availability requirements in the file
+// llvm-project/libcxx/include/__config via the #define
+// _LIBCPP_AVAILABILITY_BAD_OPTIONAL_ACCESS.
+#if defined(__APPLE__) && defined(_LIBCPP_VERSION) && \
+  ((defined(__ENVIRONMENT_MAC_OS_X_VERSION_MIN_REQUIRED__) && \
+   __ENVIRONMENT_MAC_OS_X_VERSION_MIN_REQUIRED__ < 101400) || \
+  (defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__) && \
+   __ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__ < 120000) || \
+  (defined(__ENVIRONMENT_WATCH_OS_VERSION_MIN_REQUIRED__) && \
+   __ENVIRONMENT_WATCH_OS_VERSION_MIN_REQUIRED__ < 50000) || \
+  (defined(__ENVIRONMENT_TV_OS_VERSION_MIN_REQUIRED__) && \
+   __ENVIRONMENT_TV_OS_VERSION_MIN_REQUIRED__ < 120000))
+#define ABSL_INTERNAL_APPLE_CXX17_TYPES_UNAVAILABLE 1
+#else
+#define ABSL_INTERNAL_APPLE_CXX17_TYPES_UNAVAILABLE 0
+#endif
+
+// ABSL_HAVE_STD_ANY
+//
+// Checks whether C++17 std::any is available by checking whether <any> exists.
+#ifdef ABSL_HAVE_STD_ANY
+#error "ABSL_HAVE_STD_ANY cannot be directly set."
+#endif
+
+#ifdef __has_include
+#if __has_include(<any>) && defined(__cplusplus) && __cplusplus >= 201703L && \
+    !ABSL_INTERNAL_APPLE_CXX17_TYPES_UNAVAILABLE
+#define ABSL_HAVE_STD_ANY 1
+#endif
+#endif
+
+// ABSL_HAVE_STD_OPTIONAL
+//
+// Checks whether C++17 std::optional is available.
+#ifdef ABSL_HAVE_STD_OPTIONAL
+#error "ABSL_HAVE_STD_OPTIONAL cannot be directly set."
+#endif
+
+#ifdef __has_include
+#if __has_include(<optional>) && defined(__cplusplus) && \
+    __cplusplus >= 201703L && !ABSL_INTERNAL_APPLE_CXX17_TYPES_UNAVAILABLE
+#define ABSL_HAVE_STD_OPTIONAL 1
+#endif
+#endif
+
+// ABSL_HAVE_STD_VARIANT
+//
+// Checks whether C++17 std::variant is available.
+#ifdef ABSL_HAVE_STD_VARIANT
+#error "ABSL_HAVE_STD_VARIANT cannot be directly set."
+#endif
+
+#ifdef __has_include
+#if __has_include(<variant>) && defined(__cplusplus) && \
+    __cplusplus >= 201703L && !ABSL_INTERNAL_APPLE_CXX17_TYPES_UNAVAILABLE
+#define ABSL_HAVE_STD_VARIANT 1
+#endif
+#endif
+
+// ABSL_HAVE_STD_STRING_VIEW
+//
+// Checks whether C++17 std::string_view is available.
+#ifdef ABSL_HAVE_STD_STRING_VIEW
+#error "ABSL_HAVE_STD_STRING_VIEW cannot be directly set."
+#endif
+
+#ifdef __has_include
+#if __has_include(<string_view>) && defined(__cplusplus) && \
+    __cplusplus >= 201703L
+#define ABSL_HAVE_STD_STRING_VIEW 1
+#endif
+#endif
+
+// For MSVC, `__has_include` is supported in VS 2017 15.3, which is later than
+// the support for <optional>, <any>, <string_view>, <variant>. So we use
+// _MSC_VER to check whether we have VS 2017 RTM (when <optional>, <any>,
+// <string_view>, <variant> is implemented) or higher. Also, `__cplusplus` is
+// not correctly set by MSVC, so we use `_MSVC_LANG` to check the language
+// version.
+// TODO(zhangxy): fix tests before enabling aliasing for `std::any`.
+#if defined(_MSC_VER) && _MSC_VER >= 1910 &&         \
+    ((defined(_MSVC_LANG) && _MSVC_LANG > 201402) || \
+     (defined(__cplusplus) && __cplusplus > 201402))
+// #define ABSL_HAVE_STD_ANY 1
+#define ABSL_HAVE_STD_OPTIONAL 1
+#define ABSL_HAVE_STD_VARIANT 1
+#define ABSL_HAVE_STD_STRING_VIEW 1
+#endif
+
+// ABSL_USES_STD_ANY
+//
+// Indicates whether absl::any is an alias for std::any.
+#if !defined(ABSL_OPTION_USE_STD_ANY)
+#error options.h is misconfigured.
+#elif ABSL_OPTION_USE_STD_ANY == 0 || \
+    (ABSL_OPTION_USE_STD_ANY == 2 && !defined(ABSL_HAVE_STD_ANY))
+#undef ABSL_USES_STD_ANY
+#elif ABSL_OPTION_USE_STD_ANY == 1 || \
+    (ABSL_OPTION_USE_STD_ANY == 2 && defined(ABSL_HAVE_STD_ANY))
+#define ABSL_USES_STD_ANY 1
+#else
+#error options.h is misconfigured.
+#endif
+
+// ABSL_USES_STD_OPTIONAL
+//
+// Indicates whether absl::optional is an alias for std::optional.
+#if !defined(ABSL_OPTION_USE_STD_OPTIONAL)
+#error options.h is misconfigured.
+#elif ABSL_OPTION_USE_STD_OPTIONAL == 0 || \
+    (ABSL_OPTION_USE_STD_OPTIONAL == 2 && !defined(ABSL_HAVE_STD_OPTIONAL))
+#undef ABSL_USES_STD_OPTIONAL
+#elif ABSL_OPTION_USE_STD_OPTIONAL == 1 || \
+    (ABSL_OPTION_USE_STD_OPTIONAL == 2 && defined(ABSL_HAVE_STD_OPTIONAL))
+#define ABSL_USES_STD_OPTIONAL 1
+#else
+#error options.h is misconfigured.
+#endif
+
+// ABSL_USES_STD_VARIANT
+//
+// Indicates whether absl::variant is an alias for std::variant.
+#if !defined(ABSL_OPTION_USE_STD_VARIANT)
+#error options.h is misconfigured.
+#elif ABSL_OPTION_USE_STD_VARIANT == 0 || \
+    (ABSL_OPTION_USE_STD_VARIANT == 2 && !defined(ABSL_HAVE_STD_VARIANT))
+#undef ABSL_USES_STD_VARIANT
+#elif ABSL_OPTION_USE_STD_VARIANT == 1 || \
+    (ABSL_OPTION_USE_STD_VARIANT == 2 && defined(ABSL_HAVE_STD_VARIANT))
+#define ABSL_USES_STD_VARIANT 1
+#else
+#error options.h is misconfigured.
+#endif
+
+// ABSL_USES_STD_STRING_VIEW
+//
+// Indicates whether absl::string_view is an alias for std::string_view.
+#if !defined(ABSL_OPTION_USE_STD_STRING_VIEW)
+#error options.h is misconfigured.
+#elif ABSL_OPTION_USE_STD_STRING_VIEW == 0 || \
+    (ABSL_OPTION_USE_STD_STRING_VIEW == 2 &&  \
+     !defined(ABSL_HAVE_STD_STRING_VIEW))
+#undef ABSL_USES_STD_STRING_VIEW
+#elif ABSL_OPTION_USE_STD_STRING_VIEW == 1 || \
+    (ABSL_OPTION_USE_STD_STRING_VIEW == 2 &&  \
+     defined(ABSL_HAVE_STD_STRING_VIEW))
+#define ABSL_USES_STD_STRING_VIEW 1
+#else
+#error options.h is misconfigured.
+#endif
+
+// In debug mode, MSVC 2017's std::variant throws a EXCEPTION_ACCESS_VIOLATION
+// SEH exception from emplace for variant<SomeStruct> when constructing the
+// struct can throw. This defeats some of variant_test and
+// variant_exception_safety_test.
+#if defined(_MSC_VER) && _MSC_VER >= 1700 && defined(_DEBUG)
+#define ABSL_INTERNAL_MSVC_2017_DBG_MODE
+#endif
+
+// ABSL_INTERNAL_MANGLED_NS
+// ABSL_INTERNAL_MANGLED_BACKREFERENCE
+//
+// Internal macros for building up mangled names in our internal fork of CCTZ.
+// This implementation detail is only needed and provided for the MSVC build.
+//
+// These macros both expand to string literals.  ABSL_INTERNAL_MANGLED_NS is
+// the mangled spelling of the `absl` namespace, and
+// ABSL_INTERNAL_MANGLED_BACKREFERENCE is a back-reference integer representing
+// the proper count to skip past the CCTZ fork namespace names.  (This number
+// is one larger when there is an inline namespace name to skip.)
+#if defined(_MSC_VER)
+#if ABSL_OPTION_USE_INLINE_NAMESPACE == 0
+#define ABSL_INTERNAL_MANGLED_NS "absl"
+#define ABSL_INTERNAL_MANGLED_BACKREFERENCE "5"
+#else
+#define ABSL_INTERNAL_MANGLED_NS \
+  ABSL_INTERNAL_TOKEN_STR(ABSL_OPTION_INLINE_NAMESPACE_NAME) "@absl"
+#define ABSL_INTERNAL_MANGLED_BACKREFERENCE "6"
+#endif
+#endif
+
+#undef ABSL_INTERNAL_HAS_KEYWORD
+
+// ABSL_DLL
+//
+// When building Abseil as a DLL, this macro expands to `__declspec(dllexport)`
+// so we can annotate symbols appropriately as being exported. When used in
+// headers consuming a DLL, this macro expands to `__declspec(dllimport)` so
+// that consumers know the symbol is defined inside the DLL. In all other cases,
+// the macro expands to nothing.
+#if defined(_MSC_VER)
+#if defined(ABSL_BUILD_DLL)
+#define ABSL_DLL __declspec(dllexport)
+#elif defined(ABSL_CONSUME_DLL)
+#define ABSL_DLL __declspec(dllimport)
+#else
+#define ABSL_DLL
+#endif
+#else
+#define ABSL_DLL
+#endif  // defined(_MSC_VER)
+
+// ABSL_HAVE_MEMORY_SANITIZER
+//
+// MemorySanitizer (MSan) is a detector of uninitialized reads. It consists of
+// a compiler instrumentation module and a run-time library.
+#ifdef ABSL_HAVE_MEMORY_SANITIZER
+#error "ABSL_HAVE_MEMORY_SANITIZER cannot be directly set."
+#elif defined(__SANITIZE_MEMORY__)
+#define ABSL_HAVE_MEMORY_SANITIZER 1
+#elif !defined(__native_client__) && ABSL_HAVE_FEATURE(memory_sanitizer)
+#define ABSL_HAVE_MEMORY_SANITIZER 1
+#endif
+
+// ABSL_HAVE_THREAD_SANITIZER
+//
+// ThreadSanitizer (TSan) is a fast data race detector.
+#ifdef ABSL_HAVE_THREAD_SANITIZER
+#error "ABSL_HAVE_THREAD_SANITIZER cannot be directly set."
+#elif defined(__SANITIZE_THREAD__)
+#define ABSL_HAVE_THREAD_SANITIZER 1
+#elif ABSL_HAVE_FEATURE(thread_sanitizer)
+#define ABSL_HAVE_THREAD_SANITIZER 1
+#endif
+
+// ABSL_HAVE_ADDRESS_SANITIZER
+//
+// AddressSanitizer (ASan) is a fast memory error detector.
+#ifdef ABSL_HAVE_ADDRESS_SANITIZER
+#error "ABSL_HAVE_ADDRESS_SANITIZER cannot be directly set."
+#elif defined(__SANITIZE_ADDRESS__)
+#define ABSL_HAVE_ADDRESS_SANITIZER 1
+#elif ABSL_HAVE_FEATURE(address_sanitizer)
+#define ABSL_HAVE_ADDRESS_SANITIZER 1
+#endif
+
+// ABSL_HAVE_CLASS_TEMPLATE_ARGUMENT_DEDUCTION
+//
+// Class template argument deduction is a language feature added in C++17.
+#ifdef ABSL_HAVE_CLASS_TEMPLATE_ARGUMENT_DEDUCTION
+#error "ABSL_HAVE_CLASS_TEMPLATE_ARGUMENT_DEDUCTION cannot be directly set."
+#elif defined(__cpp_deduction_guides)
+#define ABSL_HAVE_CLASS_TEMPLATE_ARGUMENT_DEDUCTION 1
+#endif
+
+#endif  // ABSL_BASE_CONFIG_H_
diff --git a/third_party/webrtc_aec3/src/absl/base/const_init.h b/third_party/webrtc_aec3/src/absl/base/const_init.h
new file mode 100644
index 0000000..16520b6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/const_init.h
@@ -0,0 +1,76 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+// -----------------------------------------------------------------------------
+// kConstInit
+// -----------------------------------------------------------------------------
+//
+// A constructor tag used to mark an object as safe for use as a global
+// variable, avoiding the usual lifetime issues that can affect globals.
+
+#ifndef ABSL_BASE_CONST_INIT_H_
+#define ABSL_BASE_CONST_INIT_H_
+
+#include "absl/base/config.h"
+
+// In general, objects with static storage duration (such as global variables)
+// can trigger tricky object lifetime situations.  Attempting to access them
+// from the constructors or destructors of other global objects can result in
+// undefined behavior, unless their constructors and destructors are designed
+// with this issue in mind.
+//
+// The normal way to deal with this issue in C++11 is to use constant
+// initialization and trivial destructors.
+//
+// Constant initialization is guaranteed to occur before any other code
+// executes.  Constructors that are declared 'constexpr' are eligible for
+// constant initialization.  You can annotate a variable declaration with the
+// ABSL_CONST_INIT macro to express this intent.  For compilers that support
+// it, this annotation will cause a compilation error for declarations that
+// aren't subject to constant initialization (perhaps because a runtime value
+// was passed as a constructor argument).
+//
+// On program shutdown, lifetime issues can be avoided on global objects by
+// ensuring that they contain  trivial destructors.  A class has a trivial
+// destructor unless it has a user-defined destructor, a virtual method or base
+// class, or a data member or base class with a non-trivial destructor of its
+// own.  Objects with static storage duration and a trivial destructor are not
+// cleaned up on program shutdown, and are thus safe to access from other code
+// running during shutdown.
+//
+// For a few core Abseil classes, we make a best effort to allow for safe global
+// instances, even though these classes have non-trivial destructors.  These
+// objects can be created with the absl::kConstInit tag.  For example:
+//   ABSL_CONST_INIT absl::Mutex global_mutex(absl::kConstInit);
+//
+// The line above declares a global variable of type absl::Mutex which can be
+// accessed at any point during startup or shutdown.  global_mutex's destructor
+// will still run, but will not invalidate the object.  Note that C++ specifies
+// that accessing an object after its destructor has run results in undefined
+// behavior, but this pattern works on the toolchains we support.
+//
+// The absl::kConstInit tag should only be used to define objects with static
+// or thread_local storage duration.
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+
+enum ConstInitType {
+  kConstInit,
+};
+
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#endif  // ABSL_BASE_CONST_INIT_H_
diff --git a/third_party/webrtc_aec3/src/absl/base/internal/atomic_hook.h b/third_party/webrtc_aec3/src/absl/base/internal/atomic_hook.h
new file mode 100644
index 0000000..ae21cd7
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/internal/atomic_hook.h
@@ -0,0 +1,200 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef ABSL_BASE_INTERNAL_ATOMIC_HOOK_H_
+#define ABSL_BASE_INTERNAL_ATOMIC_HOOK_H_
+
+#include <atomic>
+#include <cassert>
+#include <cstdint>
+#include <utility>
+
+#include "absl/base/attributes.h"
+#include "absl/base/config.h"
+
+#if defined(_MSC_VER) && !defined(__clang__)
+#define ABSL_HAVE_WORKING_CONSTEXPR_STATIC_INIT 0
+#else
+#define ABSL_HAVE_WORKING_CONSTEXPR_STATIC_INIT 1
+#endif
+
+#if defined(_MSC_VER)
+#define ABSL_HAVE_WORKING_ATOMIC_POINTER 0
+#else
+#define ABSL_HAVE_WORKING_ATOMIC_POINTER 1
+#endif
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+namespace base_internal {
+
+template <typename T>
+class AtomicHook;
+
+// To workaround AtomicHook not being constant-initializable on some platforms,
+// prefer to annotate instances with `ABSL_INTERNAL_ATOMIC_HOOK_ATTRIBUTES`
+// instead of `ABSL_CONST_INIT`.
+#if ABSL_HAVE_WORKING_CONSTEXPR_STATIC_INIT
+#define ABSL_INTERNAL_ATOMIC_HOOK_ATTRIBUTES ABSL_CONST_INIT
+#else
+#define ABSL_INTERNAL_ATOMIC_HOOK_ATTRIBUTES
+#endif
+
+// `AtomicHook` is a helper class, templatized on a raw function pointer type,
+// for implementing Abseil customization hooks.  It is a callable object that
+// dispatches to the registered hook.  Objects of type `AtomicHook` must have
+// static or thread storage duration.
+//
+// A default constructed object performs a no-op (and returns a default
+// constructed object) if no hook has been registered.
+//
+// Hooks can be pre-registered via constant initialization, for example:
+//
+// ABSL_INTERNAL_ATOMIC_HOOK_ATTRIBUTES static AtomicHook<void(*)()>
+//     my_hook(DefaultAction);
+//
+// and then changed at runtime via a call to `Store()`.
+//
+// Reads and writes guarantee memory_order_acquire/memory_order_release
+// semantics.
+template <typename ReturnType, typename... Args>
+class AtomicHook<ReturnType (*)(Args...)> {
+ public:
+  using FnPtr = ReturnType (*)(Args...);
+
+  // Constructs an object that by default performs a no-op (and
+  // returns a default constructed object) when no hook as been registered.
+  constexpr AtomicHook() : AtomicHook(DummyFunction) {}
+
+  // Constructs an object that by default dispatches to/returns the
+  // pre-registered default_fn when no hook has been registered at runtime.
+#if ABSL_HAVE_WORKING_ATOMIC_POINTER && ABSL_HAVE_WORKING_CONSTEXPR_STATIC_INIT
+  explicit constexpr AtomicHook(FnPtr default_fn)
+      : hook_(default_fn), default_fn_(default_fn) {}
+#elif ABSL_HAVE_WORKING_CONSTEXPR_STATIC_INIT
+  explicit constexpr AtomicHook(FnPtr default_fn)
+      : hook_(kUninitialized), default_fn_(default_fn) {}
+#else
+  // As of January 2020, on all known versions of MSVC this constructor runs in
+  // the global constructor sequence.  If `Store()` is called by a dynamic
+  // initializer, we want to preserve the value, even if this constructor runs
+  // after the call to `Store()`.  If not, `hook_` will be
+  // zero-initialized by the linker and we have no need to set it.
+  // https://developercommunity.visualstudio.com/content/problem/336946/class-with-constexpr-constructor-not-using-static.html
+  explicit constexpr AtomicHook(FnPtr default_fn)
+      : /* hook_(deliberately omitted), */ default_fn_(default_fn) {
+    static_assert(kUninitialized == 0, "here we rely on zero-initialization");
+  }
+#endif
+
+  // Stores the provided function pointer as the value for this hook.
+  //
+  // This is intended to be called once.  Multiple calls are legal only if the
+  // same function pointer is provided for each call.  The store is implemented
+  // as a memory_order_release operation, and read accesses are implemented as
+  // memory_order_acquire.
+  void Store(FnPtr fn) {
+    bool success = DoStore(fn);
+    static_cast<void>(success);
+    assert(success);
+  }
+
+  // Invokes the registered callback.  If no callback has yet been registered, a
+  // default-constructed object of the appropriate type is returned instead.
+  template <typename... CallArgs>
+  ReturnType operator()(CallArgs&&... args) const {
+    return DoLoad()(std::forward<CallArgs>(args)...);
+  }
+
+  // Returns the registered callback, or nullptr if none has been registered.
+  // Useful if client code needs to conditionalize behavior based on whether a
+  // callback was registered.
+  //
+  // Note that atomic_hook.Load()() and atomic_hook() have different semantics:
+  // operator()() will perform a no-op if no callback was registered, while
+  // Load()() will dereference a null function pointer.  Prefer operator()() to
+  // Load()() unless you must conditionalize behavior on whether a hook was
+  // registered.
+  FnPtr Load() const {
+    FnPtr ptr = DoLoad();
+    return (ptr == DummyFunction) ? nullptr : ptr;
+  }
+
+ private:
+  static ReturnType DummyFunction(Args...) {
+    return ReturnType();
+  }
+
+  // Current versions of MSVC (as of September 2017) have a broken
+  // implementation of std::atomic<T*>:  Its constructor attempts to do the
+  // equivalent of a reinterpret_cast in a constexpr context, which is not
+  // allowed.
+  //
+  // This causes an issue when building with LLVM under Windows.  To avoid this,
+  // we use a less-efficient, intptr_t-based implementation on Windows.
+#if ABSL_HAVE_WORKING_ATOMIC_POINTER
+  // Return the stored value, or DummyFunction if no value has been stored.
+  FnPtr DoLoad() const { return hook_.load(std::memory_order_acquire); }
+
+  // Store the given value.  Returns false if a different value was already
+  // stored to this object.
+  bool DoStore(FnPtr fn) {
+    assert(fn);
+    FnPtr expected = default_fn_;
+    const bool store_succeeded = hook_.compare_exchange_strong(
+        expected, fn, std::memory_order_acq_rel, std::memory_order_acquire);
+    const bool same_value_already_stored = (expected == fn);
+    return store_succeeded || same_value_already_stored;
+  }
+
+  std::atomic<FnPtr> hook_;
+#else  // !ABSL_HAVE_WORKING_ATOMIC_POINTER
+  // Use a sentinel value unlikely to be the address of an actual function.
+  static constexpr intptr_t kUninitialized = 0;
+
+  static_assert(sizeof(intptr_t) >= sizeof(FnPtr),
+                "intptr_t can't contain a function pointer");
+
+  FnPtr DoLoad() const {
+    const intptr_t value = hook_.load(std::memory_order_acquire);
+    if (value == kUninitialized) {
+      return default_fn_;
+    }
+    return reinterpret_cast<FnPtr>(value);
+  }
+
+  bool DoStore(FnPtr fn) {
+    assert(fn);
+    const auto value = reinterpret_cast<intptr_t>(fn);
+    intptr_t expected = kUninitialized;
+    const bool store_succeeded = hook_.compare_exchange_strong(
+        expected, value, std::memory_order_acq_rel, std::memory_order_acquire);
+    const bool same_value_already_stored = (expected == value);
+    return store_succeeded || same_value_already_stored;
+  }
+
+  std::atomic<intptr_t> hook_;
+#endif
+
+  const FnPtr default_fn_;
+};
+
+#undef ABSL_HAVE_WORKING_ATOMIC_POINTER
+#undef ABSL_HAVE_WORKING_CONSTEXPR_STATIC_INIT
+
+}  // namespace base_internal
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#endif  // ABSL_BASE_INTERNAL_ATOMIC_HOOK_H_
diff --git a/third_party/webrtc_aec3/src/absl/base/internal/identity.h b/third_party/webrtc_aec3/src/absl/base/internal/identity.h
new file mode 100644
index 0000000..a3154ed
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/internal/identity.h
@@ -0,0 +1,37 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+
+#ifndef ABSL_BASE_INTERNAL_IDENTITY_H_
+#define ABSL_BASE_INTERNAL_IDENTITY_H_
+
+#include "absl/base/config.h"
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+namespace internal {
+
+template <typename T>
+struct identity {
+  typedef T type;
+};
+
+template <typename T>
+using identity_t = typename identity<T>::type;
+
+}  // namespace internal
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#endif  // ABSL_BASE_INTERNAL_IDENTITY_H_
diff --git a/third_party/webrtc_aec3/src/absl/base/internal/inline_variable.h b/third_party/webrtc_aec3/src/absl/base/internal/inline_variable.h
new file mode 100644
index 0000000..130d8c2
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/internal/inline_variable.h
@@ -0,0 +1,107 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef ABSL_BASE_INTERNAL_INLINE_VARIABLE_EMULATION_H_
+#define ABSL_BASE_INTERNAL_INLINE_VARIABLE_EMULATION_H_
+
+#include <type_traits>
+
+#include "absl/base/internal/identity.h"
+
+// File:
+//   This file define a macro that allows the creation of or emulation of C++17
+//   inline variables based on whether or not the feature is supported.
+
+////////////////////////////////////////////////////////////////////////////////
+// Macro: ABSL_INTERNAL_INLINE_CONSTEXPR(type, name, init)
+//
+// Description:
+//   Expands to the equivalent of an inline constexpr instance of the specified
+//   `type` and `name`, initialized to the value `init`. If the compiler being
+//   used is detected as supporting actual inline variables as a language
+//   feature, then the macro expands to an actual inline variable definition.
+//
+// Requires:
+//   `type` is a type that is usable in an extern variable declaration.
+//
+// Requires: `name` is a valid identifier
+//
+// Requires:
+//   `init` is an expression that can be used in the following definition:
+//     constexpr type name = init;
+//
+// Usage:
+//
+//   // Equivalent to: `inline constexpr size_t variant_npos = -1;`
+//   ABSL_INTERNAL_INLINE_CONSTEXPR(size_t, variant_npos, -1);
+//
+// Differences in implementation:
+//   For a direct, language-level inline variable, decltype(name) will be the
+//   type that was specified along with const qualification, whereas for
+//   emulated inline variables, decltype(name) may be different (in practice
+//   it will likely be a reference type).
+////////////////////////////////////////////////////////////////////////////////
+
+#ifdef __cpp_inline_variables
+
+// Clang's -Wmissing-variable-declarations option erroneously warned that
+// inline constexpr objects need to be pre-declared. This has now been fixed,
+// but we will need to support this workaround for people building with older
+// versions of clang.
+//
+// Bug: https://bugs.llvm.org/show_bug.cgi?id=35862
+//
+// Note:
+//   identity_t is used here so that the const and name are in the
+//   appropriate place for pointer types, reference types, function pointer
+//   types, etc..
+#if defined(__clang__)
+#define ABSL_INTERNAL_EXTERN_DECL(type, name) \
+  extern const ::absl::internal::identity_t<type> name;
+#else  // Otherwise, just define the macro to do nothing.
+#define ABSL_INTERNAL_EXTERN_DECL(type, name)
+#endif  // defined(__clang__)
+
+// See above comment at top of file for details.
+#define ABSL_INTERNAL_INLINE_CONSTEXPR(type, name, init) \
+  ABSL_INTERNAL_EXTERN_DECL(type, name)                  \
+  inline constexpr ::absl::internal::identity_t<type> name = init
+
+#else
+
+// See above comment at top of file for details.
+//
+// Note:
+//   identity_t is used here so that the const and name are in the
+//   appropriate place for pointer types, reference types, function pointer
+//   types, etc..
+#define ABSL_INTERNAL_INLINE_CONSTEXPR(var_type, name, init)                  \
+  template <class /*AbslInternalDummy*/ = void>                               \
+  struct AbslInternalInlineVariableHolder##name {                             \
+    static constexpr ::absl::internal::identity_t<var_type> kInstance = init; \
+  };                                                                          \
+                                                                              \
+  template <class AbslInternalDummy>                                          \
+  constexpr ::absl::internal::identity_t<var_type>                            \
+      AbslInternalInlineVariableHolder##name<AbslInternalDummy>::kInstance;   \
+                                                                              \
+  static constexpr const ::absl::internal::identity_t<var_type>&              \
+      name = /* NOLINT */                                                     \
+      AbslInternalInlineVariableHolder##name<>::kInstance;                    \
+  static_assert(sizeof(void (*)(decltype(name))) != 0,                        \
+                "Silence unused variable warnings.")
+
+#endif  // __cpp_inline_variables
+
+#endif  // ABSL_BASE_INTERNAL_INLINE_VARIABLE_EMULATION_H_
diff --git a/third_party/webrtc_aec3/src/absl/base/internal/invoke.h b/third_party/webrtc_aec3/src/absl/base/internal/invoke.h
new file mode 100644
index 0000000..5c71f32
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/internal/invoke.h
@@ -0,0 +1,187 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+// absl::base_internal::invoke(f, args...) is an implementation of
+// INVOKE(f, args...) from section [func.require] of the C++ standard.
+//
+// [func.require]
+// Define INVOKE (f, t1, t2, ..., tN) as follows:
+// 1. (t1.*f)(t2, ..., tN) when f is a pointer to a member function of a class T
+//    and t1 is an object of type T or a reference to an object of type T or a
+//    reference to an object of a type derived from T;
+// 2. ((*t1).*f)(t2, ..., tN) when f is a pointer to a member function of a
+//    class T and t1 is not one of the types described in the previous item;
+// 3. t1.*f when N == 1 and f is a pointer to member data of a class T and t1 is
+//    an object of type T or a reference to an object of type T or a reference
+//    to an object of a type derived from T;
+// 4. (*t1).*f when N == 1 and f is a pointer to member data of a class T and t1
+//    is not one of the types described in the previous item;
+// 5. f(t1, t2, ..., tN) in all other cases.
+//
+// The implementation is SFINAE-friendly: substitution failure within invoke()
+// isn't an error.
+
+#ifndef ABSL_BASE_INTERNAL_INVOKE_H_
+#define ABSL_BASE_INTERNAL_INVOKE_H_
+
+#include <algorithm>
+#include <type_traits>
+#include <utility>
+
+#include "absl/meta/type_traits.h"
+
+// The following code is internal implementation detail.  See the comment at the
+// top of this file for the API documentation.
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+namespace base_internal {
+
+// The five classes below each implement one of the clauses from the definition
+// of INVOKE. The inner class template Accept<F, Args...> checks whether the
+// clause is applicable; static function template Invoke(f, args...) does the
+// invocation.
+//
+// By separating the clause selection logic from invocation we make sure that
+// Invoke() does exactly what the standard says.
+
+template <typename Derived>
+struct StrippedAccept {
+  template <typename... Args>
+  struct Accept : Derived::template AcceptImpl<typename std::remove_cv<
+                      typename std::remove_reference<Args>::type>::type...> {};
+};
+
+// (t1.*f)(t2, ..., tN) when f is a pointer to a member function of a class T
+// and t1 is an object of type T or a reference to an object of type T or a
+// reference to an object of a type derived from T.
+struct MemFunAndRef : StrippedAccept<MemFunAndRef> {
+  template <typename... Args>
+  struct AcceptImpl : std::false_type {};
+
+  template <typename MemFunType, typename C, typename Obj, typename... Args>
+  struct AcceptImpl<MemFunType C::*, Obj, Args...>
+      : std::integral_constant<bool, std::is_base_of<C, Obj>::value &&
+                                         absl::is_function<MemFunType>::value> {
+  };
+
+  template <typename MemFun, typename Obj, typename... Args>
+  static decltype((std::declval<Obj>().*
+                   std::declval<MemFun>())(std::declval<Args>()...))
+  Invoke(MemFun&& mem_fun, Obj&& obj, Args&&... args) {
+    return (std::forward<Obj>(obj).*
+            std::forward<MemFun>(mem_fun))(std::forward<Args>(args)...);
+  }
+};
+
+// ((*t1).*f)(t2, ..., tN) when f is a pointer to a member function of a
+// class T and t1 is not one of the types described in the previous item.
+struct MemFunAndPtr : StrippedAccept<MemFunAndPtr> {
+  template <typename... Args>
+  struct AcceptImpl : std::false_type {};
+
+  template <typename MemFunType, typename C, typename Ptr, typename... Args>
+  struct AcceptImpl<MemFunType C::*, Ptr, Args...>
+      : std::integral_constant<bool, !std::is_base_of<C, Ptr>::value &&
+                                         absl::is_function<MemFunType>::value> {
+  };
+
+  template <typename MemFun, typename Ptr, typename... Args>
+  static decltype(((*std::declval<Ptr>()).*
+                   std::declval<MemFun>())(std::declval<Args>()...))
+  Invoke(MemFun&& mem_fun, Ptr&& ptr, Args&&... args) {
+    return ((*std::forward<Ptr>(ptr)).*
+            std::forward<MemFun>(mem_fun))(std::forward<Args>(args)...);
+  }
+};
+
+// t1.*f when N == 1 and f is a pointer to member data of a class T and t1 is
+// an object of type T or a reference to an object of type T or a reference
+// to an object of a type derived from T.
+struct DataMemAndRef : StrippedAccept<DataMemAndRef> {
+  template <typename... Args>
+  struct AcceptImpl : std::false_type {};
+
+  template <typename R, typename C, typename Obj>
+  struct AcceptImpl<R C::*, Obj>
+      : std::integral_constant<bool, std::is_base_of<C, Obj>::value &&
+                                         !absl::is_function<R>::value> {};
+
+  template <typename DataMem, typename Ref>
+  static decltype(std::declval<Ref>().*std::declval<DataMem>()) Invoke(
+      DataMem&& data_mem, Ref&& ref) {
+    return std::forward<Ref>(ref).*std::forward<DataMem>(data_mem);
+  }
+};
+
+// (*t1).*f when N == 1 and f is a pointer to member data of a class T and t1
+// is not one of the types described in the previous item.
+struct DataMemAndPtr : StrippedAccept<DataMemAndPtr> {
+  template <typename... Args>
+  struct AcceptImpl : std::false_type {};
+
+  template <typename R, typename C, typename Ptr>
+  struct AcceptImpl<R C::*, Ptr>
+      : std::integral_constant<bool, !std::is_base_of<C, Ptr>::value &&
+                                         !absl::is_function<R>::value> {};
+
+  template <typename DataMem, typename Ptr>
+  static decltype((*std::declval<Ptr>()).*std::declval<DataMem>()) Invoke(
+      DataMem&& data_mem, Ptr&& ptr) {
+    return (*std::forward<Ptr>(ptr)).*std::forward<DataMem>(data_mem);
+  }
+};
+
+// f(t1, t2, ..., tN) in all other cases.
+struct Callable {
+  // Callable doesn't have Accept because it's the last clause that gets picked
+  // when none of the previous clauses are applicable.
+  template <typename F, typename... Args>
+  static decltype(std::declval<F>()(std::declval<Args>()...)) Invoke(
+      F&& f, Args&&... args) {
+    return std::forward<F>(f)(std::forward<Args>(args)...);
+  }
+};
+
+// Resolves to the first matching clause.
+template <typename... Args>
+struct Invoker {
+  typedef typename std::conditional<
+      MemFunAndRef::Accept<Args...>::value, MemFunAndRef,
+      typename std::conditional<
+          MemFunAndPtr::Accept<Args...>::value, MemFunAndPtr,
+          typename std::conditional<
+              DataMemAndRef::Accept<Args...>::value, DataMemAndRef,
+              typename std::conditional<DataMemAndPtr::Accept<Args...>::value,
+                                        DataMemAndPtr, Callable>::type>::type>::
+          type>::type type;
+};
+
+// The result type of Invoke<F, Args...>.
+template <typename F, typename... Args>
+using invoke_result_t = decltype(Invoker<F, Args...>::type::Invoke(
+    std::declval<F>(), std::declval<Args>()...));
+
+// Invoke(f, args...) is an implementation of INVOKE(f, args...) from section
+// [func.require] of the C++ standard.
+template <typename F, typename... Args>
+invoke_result_t<F, Args...> invoke(F&& f, Args&&... args) {
+  return Invoker<F, Args...>::type::Invoke(std::forward<F>(f),
+                                           std::forward<Args>(args)...);
+}
+}  // namespace base_internal
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#endif  // ABSL_BASE_INTERNAL_INVOKE_H_
diff --git a/third_party/webrtc_aec3/src/absl/base/internal/raw_logging.cc b/third_party/webrtc_aec3/src/absl/base/internal/raw_logging.cc
new file mode 100644
index 0000000..074e026
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/internal/raw_logging.cc
@@ -0,0 +1,242 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "absl/base/internal/raw_logging.h"
+
+#include <stddef.h>
+#include <cstdarg>
+#include <cstdio>
+#include <cstdlib>
+#include <cstring>
+
+#include "absl/base/attributes.h"
+#include "absl/base/config.h"
+#include "absl/base/internal/atomic_hook.h"
+#include "absl/base/log_severity.h"
+
+// We know how to perform low-level writes to stderr in POSIX and Windows.  For
+// these platforms, we define the token ABSL_LOW_LEVEL_WRITE_SUPPORTED.
+// Much of raw_logging.cc becomes a no-op when we can't output messages,
+// although a FATAL ABSL_RAW_LOG message will still abort the process.
+
+// ABSL_HAVE_POSIX_WRITE is defined when the platform provides posix write()
+// (as from unistd.h)
+//
+// This preprocessor token is also defined in raw_io.cc.  If you need to copy
+// this, consider moving both to config.h instead.
+#if defined(__linux__) || defined(__APPLE__) || defined(__FreeBSD__) || \
+    defined(__Fuchsia__) || defined(__native_client__) || \
+    defined(__EMSCRIPTEN__) || defined(__ASYLO__)
+
+#include <unistd.h>
+
+#define ABSL_HAVE_POSIX_WRITE 1
+#define ABSL_LOW_LEVEL_WRITE_SUPPORTED 1
+#else
+#undef ABSL_HAVE_POSIX_WRITE
+#endif
+
+// ABSL_HAVE_SYSCALL_WRITE is defined when the platform provides the syscall
+//   syscall(SYS_write, /*int*/ fd, /*char* */ buf, /*size_t*/ len);
+// for low level operations that want to avoid libc.
+#if (defined(__linux__) || defined(__FreeBSD__)) && !defined(__ANDROID__)
+#include <sys/syscall.h>
+#define ABSL_HAVE_SYSCALL_WRITE 1
+#define ABSL_LOW_LEVEL_WRITE_SUPPORTED 1
+#else
+#undef ABSL_HAVE_SYSCALL_WRITE
+#endif
+
+#ifdef _WIN32
+#include <io.h>
+
+#define ABSL_HAVE_RAW_IO 1
+#define ABSL_LOW_LEVEL_WRITE_SUPPORTED 1
+#else
+#undef ABSL_HAVE_RAW_IO
+#endif
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+namespace raw_logging_internal {
+namespace {
+
+// TODO(gfalcon): We want raw-logging to work on as many platforms as possible.
+// Explicitly `#error` out when not `ABSL_LOW_LEVEL_WRITE_SUPPORTED`, except for
+// a selected set of platforms for which we expect not to be able to raw log.
+
+ABSL_INTERNAL_ATOMIC_HOOK_ATTRIBUTES
+    absl::base_internal::AtomicHook<LogPrefixHook>
+        log_prefix_hook;
+ABSL_INTERNAL_ATOMIC_HOOK_ATTRIBUTES
+    absl::base_internal::AtomicHook<AbortHook>
+        abort_hook;
+
+#ifdef ABSL_LOW_LEVEL_WRITE_SUPPORTED
+constexpr char kTruncated[] = " ... (message truncated)\n";
+
+// sprintf the format to the buffer, adjusting *buf and *size to reflect the
+// consumed bytes, and return whether the message fit without truncation.  If
+// truncation occurred, if possible leave room in the buffer for the message
+// kTruncated[].
+bool VADoRawLog(char** buf, int* size, const char* format, va_list ap)
+    ABSL_PRINTF_ATTRIBUTE(3, 0);
+bool VADoRawLog(char** buf, int* size, const char* format, va_list ap) {
+  int n = vsnprintf(*buf, *size, format, ap);
+  bool result = true;
+  if (n < 0 || n > *size) {
+    result = false;
+    if (static_cast<size_t>(*size) > sizeof(kTruncated)) {
+      n = *size - sizeof(kTruncated);  // room for truncation message
+    } else {
+      n = 0;  // no room for truncation message
+    }
+  }
+  *size -= n;
+  *buf += n;
+  return result;
+}
+#endif  // ABSL_LOW_LEVEL_WRITE_SUPPORTED
+
+constexpr int kLogBufSize = 3000;
+
+// CAVEAT: vsnprintf called from *DoRawLog below has some (exotic) code paths
+// that invoke malloc() and getenv() that might acquire some locks.
+
+// Helper for RawLog below.
+// *DoRawLog writes to *buf of *size and move them past the written portion.
+// It returns true iff there was no overflow or error.
+bool DoRawLog(char** buf, int* size, const char* format, ...)
+    ABSL_PRINTF_ATTRIBUTE(3, 4);
+bool DoRawLog(char** buf, int* size, const char* format, ...) {
+  va_list ap;
+  va_start(ap, format);
+  int n = vsnprintf(*buf, *size, format, ap);
+  va_end(ap);
+  if (n < 0 || n > *size) return false;
+  *size -= n;
+  *buf += n;
+  return true;
+}
+
+void RawLogVA(absl::LogSeverity severity, const char* file, int line,
+              const char* format, va_list ap) ABSL_PRINTF_ATTRIBUTE(4, 0);
+void RawLogVA(absl::LogSeverity severity, const char* file, int line,
+              const char* format, va_list ap) {
+  char buffer[kLogBufSize];
+  char* buf = buffer;
+  int size = sizeof(buffer);
+#ifdef ABSL_LOW_LEVEL_WRITE_SUPPORTED
+  bool enabled = true;
+#else
+  bool enabled = false;
+#endif
+
+#ifdef ABSL_MIN_LOG_LEVEL
+  if (severity < static_cast<absl::LogSeverity>(ABSL_MIN_LOG_LEVEL) &&
+      severity < absl::LogSeverity::kFatal) {
+    enabled = false;
+  }
+#endif
+
+  auto log_prefix_hook_ptr = log_prefix_hook.Load();
+  if (log_prefix_hook_ptr) {
+    enabled = log_prefix_hook_ptr(severity, file, line, &buf, &size);
+  } else {
+    if (enabled) {
+      DoRawLog(&buf, &size, "[%s : %d] RAW: ", file, line);
+    }
+  }
+  const char* const prefix_end = buf;
+
+#ifdef ABSL_LOW_LEVEL_WRITE_SUPPORTED
+  if (enabled) {
+    bool no_chop = VADoRawLog(&buf, &size, format, ap);
+    if (no_chop) {
+      DoRawLog(&buf, &size, "\n");
+    } else {
+      DoRawLog(&buf, &size, "%s", kTruncated);
+    }
+    SafeWriteToStderr(buffer, strlen(buffer));
+  }
+#else
+  static_cast<void>(format);
+  static_cast<void>(ap);
+#endif
+
+  // Abort the process after logging a FATAL message, even if the output itself
+  // was suppressed.
+  if (severity == absl::LogSeverity::kFatal) {
+    abort_hook(file, line, buffer, prefix_end, buffer + kLogBufSize);
+    abort();
+  }
+}
+
+// Non-formatting version of RawLog().
+//
+// TODO(gfalcon): When string_view no longer depends on base, change this
+// interface to take its message as a string_view instead.
+void DefaultInternalLog(absl::LogSeverity severity, const char* file, int line,
+                        const std::string& message) {
+  RawLog(severity, file, line, "%.*s", static_cast<int>(message.size()),
+         message.data());
+}
+
+}  // namespace
+
+void SafeWriteToStderr(const char *s, size_t len) {
+#if defined(ABSL_HAVE_SYSCALL_WRITE)
+  syscall(SYS_write, STDERR_FILENO, s, len);
+#elif defined(ABSL_HAVE_POSIX_WRITE)
+  write(STDERR_FILENO, s, len);
+#elif defined(ABSL_HAVE_RAW_IO)
+  _write(/* stderr */ 2, s, len);
+#else
+  // stderr logging unsupported on this platform
+  (void) s;
+  (void) len;
+#endif
+}
+
+void RawLog(absl::LogSeverity severity, const char* file, int line,
+            const char* format, ...) {
+  va_list ap;
+  va_start(ap, format);
+  RawLogVA(severity, file, line, format, ap);
+  va_end(ap);
+}
+
+bool RawLoggingFullySupported() {
+#ifdef ABSL_LOW_LEVEL_WRITE_SUPPORTED
+  return true;
+#else  // !ABSL_LOW_LEVEL_WRITE_SUPPORTED
+  return false;
+#endif  // !ABSL_LOW_LEVEL_WRITE_SUPPORTED
+}
+
+ABSL_INTERNAL_ATOMIC_HOOK_ATTRIBUTES ABSL_DLL
+    absl::base_internal::AtomicHook<InternalLogFunction>
+        internal_log_function(DefaultInternalLog);
+
+void RegisterLogPrefixHook(LogPrefixHook func) { log_prefix_hook.Store(func); }
+
+void RegisterAbortHook(AbortHook func) { abort_hook.Store(func); }
+
+void RegisterInternalLogFunction(InternalLogFunction func) {
+  internal_log_function.Store(func);
+}
+
+}  // namespace raw_logging_internal
+ABSL_NAMESPACE_END
+}  // namespace absl
diff --git a/third_party/webrtc_aec3/src/absl/base/internal/raw_logging.h b/third_party/webrtc_aec3/src/absl/base/internal/raw_logging.h
new file mode 100644
index 0000000..2bf7aab
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/internal/raw_logging.h
@@ -0,0 +1,195 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+// Thread-safe logging routines that do not allocate any memory or
+// acquire any locks, and can therefore be used by low-level memory
+// allocation, synchronization, and signal-handling code.
+
+#ifndef ABSL_BASE_INTERNAL_RAW_LOGGING_H_
+#define ABSL_BASE_INTERNAL_RAW_LOGGING_H_
+
+#include <string>
+
+#include "absl/base/attributes.h"
+#include "absl/base/config.h"
+#include "absl/base/internal/atomic_hook.h"
+#include "absl/base/log_severity.h"
+#include "absl/base/macros.h"
+#include "absl/base/optimization.h"
+#include "absl/base/port.h"
+
+// This is similar to LOG(severity) << format..., but
+// * it is to be used ONLY by low-level modules that can't use normal LOG()
+// * it is designed to be a low-level logger that does not allocate any
+//   memory and does not need any locks, hence:
+// * it logs straight and ONLY to STDERR w/o buffering
+// * it uses an explicit printf-format and arguments list
+// * it will silently chop off really long message strings
+// Usage example:
+//   ABSL_RAW_LOG(ERROR, "Failed foo with %i: %s", status, error);
+// This will print an almost standard log line like this to stderr only:
+//   E0821 211317 file.cc:123] RAW: Failed foo with 22: bad_file
+
+#define ABSL_RAW_LOG(severity, ...)                                            \
+  do {                                                                         \
+    constexpr const char* absl_raw_logging_internal_basename =                 \
+        ::absl::raw_logging_internal::Basename(__FILE__,                       \
+                                               sizeof(__FILE__) - 1);          \
+    ::absl::raw_logging_internal::RawLog(ABSL_RAW_LOGGING_INTERNAL_##severity, \
+                                         absl_raw_logging_internal_basename,   \
+                                         __LINE__, __VA_ARGS__);               \
+  } while (0)
+
+// Similar to CHECK(condition) << message, but for low-level modules:
+// we use only ABSL_RAW_LOG that does not allocate memory.
+// We do not want to provide args list here to encourage this usage:
+//   if (!cond)  ABSL_RAW_LOG(FATAL, "foo ...", hard_to_compute_args);
+// so that the args are not computed when not needed.
+#define ABSL_RAW_CHECK(condition, message)                             \
+  do {                                                                 \
+    if (ABSL_PREDICT_FALSE(!(condition))) {                            \
+      ABSL_RAW_LOG(FATAL, "Check %s failed: %s", #condition, message); \
+    }                                                                  \
+  } while (0)
+
+// ABSL_INTERNAL_LOG and ABSL_INTERNAL_CHECK work like the RAW variants above,
+// except that if the richer log library is linked into the binary, we dispatch
+// to that instead.  This is potentially useful for internal logging and
+// assertions, where we are using RAW_LOG neither for its async-signal-safety
+// nor for its non-allocating nature, but rather because raw logging has very
+// few other dependencies.
+//
+// The API is a subset of the above: each macro only takes two arguments.  Use
+// StrCat if you need to build a richer message.
+#define ABSL_INTERNAL_LOG(severity, message)                                 \
+  do {                                                                       \
+    constexpr const char* absl_raw_logging_internal_filename = __FILE__;     \
+    ::absl::raw_logging_internal::internal_log_function(                     \
+        ABSL_RAW_LOGGING_INTERNAL_##severity,                                \
+        absl_raw_logging_internal_filename, __LINE__, message);              \
+    if (ABSL_RAW_LOGGING_INTERNAL_##severity == ::absl::LogSeverity::kFatal) \
+      ABSL_INTERNAL_UNREACHABLE;                                             \
+  } while (0)
+
+#define ABSL_INTERNAL_CHECK(condition, message)                    \
+  do {                                                             \
+    if (ABSL_PREDICT_FALSE(!(condition))) {                        \
+      std::string death_message = "Check " #condition " failed: "; \
+      death_message += std::string(message);                       \
+      ABSL_INTERNAL_LOG(FATAL, death_message);                     \
+    }                                                              \
+  } while (0)
+
+#define ABSL_RAW_LOGGING_INTERNAL_INFO ::absl::LogSeverity::kInfo
+#define ABSL_RAW_LOGGING_INTERNAL_WARNING ::absl::LogSeverity::kWarning
+#define ABSL_RAW_LOGGING_INTERNAL_ERROR ::absl::LogSeverity::kError
+#define ABSL_RAW_LOGGING_INTERNAL_FATAL ::absl::LogSeverity::kFatal
+#define ABSL_RAW_LOGGING_INTERNAL_LEVEL(severity) \
+  ::absl::NormalizeLogSeverity(severity)
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+namespace raw_logging_internal {
+
+// Helper function to implement ABSL_RAW_LOG
+// Logs format... at "severity" level, reporting it
+// as called from file:line.
+// This does not allocate memory or acquire locks.
+void RawLog(absl::LogSeverity severity, const char* file, int line,
+            const char* format, ...) ABSL_PRINTF_ATTRIBUTE(4, 5);
+
+// Writes the provided buffer directly to stderr, in a safe, low-level manner.
+//
+// In POSIX this means calling write(), which is async-signal safe and does
+// not malloc.  If the platform supports the SYS_write syscall, we invoke that
+// directly to side-step any libc interception.
+void SafeWriteToStderr(const char *s, size_t len);
+
+// compile-time function to get the "base" filename, that is, the part of
+// a filename after the last "/" or "\" path separator.  The search starts at
+// the end of the string; the second parameter is the length of the string.
+constexpr const char* Basename(const char* fname, int offset) {
+  return offset == 0 || fname[offset - 1] == '/' || fname[offset - 1] == '\\'
+             ? fname + offset
+             : Basename(fname, offset - 1);
+}
+
+// For testing only.
+// Returns true if raw logging is fully supported. When it is not
+// fully supported, no messages will be emitted, but a log at FATAL
+// severity will cause an abort.
+//
+// TODO(gfalcon): Come up with a better name for this method.
+bool RawLoggingFullySupported();
+
+// Function type for a raw_logging customization hook for suppressing messages
+// by severity, and for writing custom prefixes on non-suppressed messages.
+//
+// The installed hook is called for every raw log invocation.  The message will
+// be logged to stderr only if the hook returns true.  FATAL errors will cause
+// the process to abort, even if writing to stderr is suppressed.  The hook is
+// also provided with an output buffer, where it can write a custom log message
+// prefix.
+//
+// The raw_logging system does not allocate memory or grab locks.  User-provided
+// hooks must avoid these operations, and must not throw exceptions.
+//
+// 'severity' is the severity level of the message being written.
+// 'file' and 'line' are the file and line number where the ABSL_RAW_LOG macro
+// was located.
+// 'buffer' and 'buf_size' are pointers to the buffer and buffer size.  If the
+// hook writes a prefix, it must increment *buffer and decrement *buf_size
+// accordingly.
+using LogPrefixHook = bool (*)(absl::LogSeverity severity, const char* file,
+                               int line, char** buffer, int* buf_size);
+
+// Function type for a raw_logging customization hook called to abort a process
+// when a FATAL message is logged.  If the provided AbortHook() returns, the
+// logging system will call abort().
+//
+// 'file' and 'line' are the file and line number where the ABSL_RAW_LOG macro
+// was located.
+// The NUL-terminated logged message lives in the buffer between 'buf_start'
+// and 'buf_end'.  'prefix_end' points to the first non-prefix character of the
+// buffer (as written by the LogPrefixHook.)
+using AbortHook = void (*)(const char* file, int line, const char* buf_start,
+                           const char* prefix_end, const char* buf_end);
+
+// Internal logging function for ABSL_INTERNAL_LOG to dispatch to.
+//
+// TODO(gfalcon): When string_view no longer depends on base, change this
+// interface to take its message as a string_view instead.
+using InternalLogFunction = void (*)(absl::LogSeverity severity,
+                                     const char* file, int line,
+                                     const std::string& message);
+
+ABSL_INTERNAL_ATOMIC_HOOK_ATTRIBUTES ABSL_DLL extern base_internal::AtomicHook<
+    InternalLogFunction>
+    internal_log_function;
+
+// Registers hooks of the above types.  Only a single hook of each type may be
+// registered.  It is an error to call these functions multiple times with
+// different input arguments.
+//
+// These functions are safe to call at any point during initialization; they do
+// not block or malloc, and are async-signal safe.
+void RegisterLogPrefixHook(LogPrefixHook func);
+void RegisterAbortHook(AbortHook func);
+void RegisterInternalLogFunction(InternalLogFunction func);
+
+}  // namespace raw_logging_internal
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#endif  // ABSL_BASE_INTERNAL_RAW_LOGGING_H_
diff --git a/third_party/webrtc_aec3/src/absl/base/internal/throw_delegate.cc b/third_party/webrtc_aec3/src/absl/base/internal/throw_delegate.cc
new file mode 100644
index 0000000..c260ff1
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/internal/throw_delegate.cc
@@ -0,0 +1,212 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "absl/base/internal/throw_delegate.h"
+
+#include <cstdlib>
+#include <functional>
+#include <new>
+#include <stdexcept>
+
+#include "absl/base/config.h"
+#include "absl/base/internal/raw_logging.h"
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+namespace base_internal {
+
+// NOTE: The various STL exception throwing functions are placed within the
+// #ifdef blocks so the symbols aren't exposed on platforms that don't support
+// them, such as the Android NDK. For example, ANGLE fails to link when building
+// within AOSP without them, since the STL functions don't exist.
+namespace {
+#ifdef ABSL_HAVE_EXCEPTIONS
+template <typename T>
+[[noreturn]] void Throw(const T& error) {
+  throw error;
+}
+#endif
+}  // namespace
+
+void ThrowStdLogicError(const std::string& what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::logic_error(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg.c_str());
+  std::abort();
+#endif
+}
+void ThrowStdLogicError(const char* what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::logic_error(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg);
+  std::abort();
+#endif
+}
+void ThrowStdInvalidArgument(const std::string& what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::invalid_argument(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg.c_str());
+  std::abort();
+#endif
+}
+void ThrowStdInvalidArgument(const char* what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::invalid_argument(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg);
+  std::abort();
+#endif
+}
+
+void ThrowStdDomainError(const std::string& what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::domain_error(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg.c_str());
+  std::abort();
+#endif
+}
+void ThrowStdDomainError(const char* what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::domain_error(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg);
+  std::abort();
+#endif
+}
+
+void ThrowStdLengthError(const std::string& what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::length_error(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg.c_str());
+  std::abort();
+#endif
+}
+void ThrowStdLengthError(const char* what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::length_error(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg);
+  std::abort();
+#endif
+}
+
+void ThrowStdOutOfRange(const std::string& what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::out_of_range(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg.c_str());
+  std::abort();
+#endif
+}
+void ThrowStdOutOfRange(const char* what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::out_of_range(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg);
+  std::abort();
+#endif
+}
+
+void ThrowStdRuntimeError(const std::string& what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::runtime_error(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg.c_str());
+  std::abort();
+#endif
+}
+void ThrowStdRuntimeError(const char* what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::runtime_error(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg);
+  std::abort();
+#endif
+}
+
+void ThrowStdRangeError(const std::string& what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::range_error(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg.c_str());
+  std::abort();
+#endif
+}
+void ThrowStdRangeError(const char* what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::range_error(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg);
+  std::abort();
+#endif
+}
+
+void ThrowStdOverflowError(const std::string& what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::overflow_error(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg.c_str());
+  std::abort();
+#endif
+}
+void ThrowStdOverflowError(const char* what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::overflow_error(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg);
+  std::abort();
+#endif
+}
+
+void ThrowStdUnderflowError(const std::string& what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::underflow_error(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg.c_str());
+  std::abort();
+#endif
+}
+void ThrowStdUnderflowError(const char* what_arg) {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::underflow_error(what_arg));
+#else
+  ABSL_RAW_LOG(FATAL, "%s", what_arg);
+  std::abort();
+#endif
+}
+
+void ThrowStdBadFunctionCall() {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::bad_function_call());
+#else
+  std::abort();
+#endif
+}
+
+void ThrowStdBadAlloc() {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  Throw(std::bad_alloc());
+#else
+  std::abort();
+#endif
+}
+
+}  // namespace base_internal
+ABSL_NAMESPACE_END
+}  // namespace absl
diff --git a/third_party/webrtc_aec3/src/absl/base/internal/throw_delegate.h b/third_party/webrtc_aec3/src/absl/base/internal/throw_delegate.h
new file mode 100644
index 0000000..075f527
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/internal/throw_delegate.h
@@ -0,0 +1,75 @@
+//
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+
+#ifndef ABSL_BASE_INTERNAL_THROW_DELEGATE_H_
+#define ABSL_BASE_INTERNAL_THROW_DELEGATE_H_
+
+#include <string>
+
+#include "absl/base/config.h"
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+namespace base_internal {
+
+// Helper functions that allow throwing exceptions consistently from anywhere.
+// The main use case is for header-based libraries (eg templates), as they will
+// be built by many different targets with their own compiler options.
+// In particular, this will allow a safe way to throw exceptions even if the
+// caller is compiled with -fno-exceptions.  This is intended for implementing
+// things like map<>::at(), which the standard documents as throwing an
+// exception on error.
+//
+// Using other techniques like #if tricks could lead to ODR violations.
+//
+// You shouldn't use it unless you're writing code that you know will be built
+// both with and without exceptions and you need to conform to an interface
+// that uses exceptions.
+
+[[noreturn]] void ThrowStdLogicError(const std::string& what_arg);
+[[noreturn]] void ThrowStdLogicError(const char* what_arg);
+[[noreturn]] void ThrowStdInvalidArgument(const std::string& what_arg);
+[[noreturn]] void ThrowStdInvalidArgument(const char* what_arg);
+[[noreturn]] void ThrowStdDomainError(const std::string& what_arg);
+[[noreturn]] void ThrowStdDomainError(const char* what_arg);
+[[noreturn]] void ThrowStdLengthError(const std::string& what_arg);
+[[noreturn]] void ThrowStdLengthError(const char* what_arg);
+[[noreturn]] void ThrowStdOutOfRange(const std::string& what_arg);
+[[noreturn]] void ThrowStdOutOfRange(const char* what_arg);
+[[noreturn]] void ThrowStdRuntimeError(const std::string& what_arg);
+[[noreturn]] void ThrowStdRuntimeError(const char* what_arg);
+[[noreturn]] void ThrowStdRangeError(const std::string& what_arg);
+[[noreturn]] void ThrowStdRangeError(const char* what_arg);
+[[noreturn]] void ThrowStdOverflowError(const std::string& what_arg);
+[[noreturn]] void ThrowStdOverflowError(const char* what_arg);
+[[noreturn]] void ThrowStdUnderflowError(const std::string& what_arg);
+[[noreturn]] void ThrowStdUnderflowError(const char* what_arg);
+
+[[noreturn]] void ThrowStdBadFunctionCall();
+[[noreturn]] void ThrowStdBadAlloc();
+
+// ThrowStdBadArrayNewLength() cannot be consistently supported because
+// std::bad_array_new_length is missing in libstdc++ until 4.9.0.
+// https://gcc.gnu.org/onlinedocs/gcc-4.8.3/libstdc++/api/a01379_source.html
+// https://gcc.gnu.org/onlinedocs/gcc-4.9.0/libstdc++/api/a01327_source.html
+// libcxx (as of 3.2) and msvc (as of 2015) both have it.
+// [[noreturn]] void ThrowStdBadArrayNewLength();
+
+}  // namespace base_internal
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#endif  // ABSL_BASE_INTERNAL_THROW_DELEGATE_H_
diff --git a/third_party/webrtc_aec3/src/absl/base/log_severity.cc b/third_party/webrtc_aec3/src/absl/base/log_severity.cc
new file mode 100644
index 0000000..72312af
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/log_severity.cc
@@ -0,0 +1,27 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "absl/base/log_severity.h"
+
+#include <ostream>
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+
+std::ostream& operator<<(std::ostream& os, absl::LogSeverity s) {
+  if (s == absl::NormalizeLogSeverity(s)) return os << absl::LogSeverityName(s);
+  return os << "absl::LogSeverity(" << static_cast<int>(s) << ")";
+}
+ABSL_NAMESPACE_END
+}  // namespace absl
diff --git a/third_party/webrtc_aec3/src/absl/base/log_severity.h b/third_party/webrtc_aec3/src/absl/base/log_severity.h
new file mode 100644
index 0000000..2236422
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/log_severity.h
@@ -0,0 +1,121 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef ABSL_BASE_LOG_SEVERITY_H_
+#define ABSL_BASE_LOG_SEVERITY_H_
+
+#include <array>
+#include <ostream>
+
+#include "absl/base/attributes.h"
+#include "absl/base/config.h"
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+
+// absl::LogSeverity
+//
+// Four severity levels are defined. Logging APIs should terminate the program
+// when a message is logged at severity `kFatal`; the other levels have no
+// special semantics.
+//
+// Values other than the four defined levels (e.g. produced by `static_cast`)
+// are valid, but their semantics when passed to a function, macro, or flag
+// depend on the function, macro, or flag. The usual behavior is to normalize
+// such values to a defined severity level, however in some cases values other
+// than the defined levels are useful for comparison.
+//
+// Example:
+//
+//   // Effectively disables all logging:
+//   SetMinLogLevel(static_cast<absl::LogSeverity>(100));
+//
+// Abseil flags may be defined with type `LogSeverity`. Dependency layering
+// constraints require that the `AbslParseFlag()` overload be declared and
+// defined in the flags library itself rather than here. The `AbslUnparseFlag()`
+// overload is defined there as well for consistency.
+//
+// absl::LogSeverity Flag String Representation
+//
+// An `absl::LogSeverity` has a string representation used for parsing
+// command-line flags based on the enumerator name (e.g. `kFatal`) or
+// its unprefixed name (without the `k`) in any case-insensitive form. (E.g.
+// "FATAL", "fatal" or "Fatal" are all valid.) Unparsing such flags produces an
+// unprefixed string representation in all caps (e.g. "FATAL") or an integer.
+//
+// Additionally, the parser accepts arbitrary integers (as if the type were
+// `int`).
+//
+// Examples:
+//
+//   --my_log_level=kInfo
+//   --my_log_level=INFO
+//   --my_log_level=info
+//   --my_log_level=0
+//
+// Unparsing a flag produces the same result as `absl::LogSeverityName()` for
+// the standard levels and a base-ten integer otherwise.
+enum class LogSeverity : int {
+  kInfo = 0,
+  kWarning = 1,
+  kError = 2,
+  kFatal = 3,
+};
+
+// LogSeverities()
+//
+// Returns an iterable of all standard `absl::LogSeverity` values, ordered from
+// least to most severe.
+constexpr std::array<absl::LogSeverity, 4> LogSeverities() {
+  return {{absl::LogSeverity::kInfo, absl::LogSeverity::kWarning,
+           absl::LogSeverity::kError, absl::LogSeverity::kFatal}};
+}
+
+// LogSeverityName()
+//
+// Returns the all-caps string representation (e.g. "INFO") of the specified
+// severity level if it is one of the standard levels and "UNKNOWN" otherwise.
+constexpr const char* LogSeverityName(absl::LogSeverity s) {
+  return s == absl::LogSeverity::kInfo
+             ? "INFO"
+             : s == absl::LogSeverity::kWarning
+                   ? "WARNING"
+                   : s == absl::LogSeverity::kError
+                         ? "ERROR"
+                         : s == absl::LogSeverity::kFatal ? "FATAL" : "UNKNOWN";
+}
+
+// NormalizeLogSeverity()
+//
+// Values less than `kInfo` normalize to `kInfo`; values greater than `kFatal`
+// normalize to `kError` (**NOT** `kFatal`).
+constexpr absl::LogSeverity NormalizeLogSeverity(absl::LogSeverity s) {
+  return s < absl::LogSeverity::kInfo
+             ? absl::LogSeverity::kInfo
+             : s > absl::LogSeverity::kFatal ? absl::LogSeverity::kError : s;
+}
+constexpr absl::LogSeverity NormalizeLogSeverity(int s) {
+  return absl::NormalizeLogSeverity(static_cast<absl::LogSeverity>(s));
+}
+
+// operator<<
+//
+// The exact representation of a streamed `absl::LogSeverity` is deliberately
+// unspecified; do not rely on it.
+std::ostream& operator<<(std::ostream& os, absl::LogSeverity s);
+
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#endif  // ABSL_BASE_LOG_SEVERITY_H_
diff --git a/third_party/webrtc_aec3/src/absl/base/macros.h b/third_party/webrtc_aec3/src/absl/base/macros.h
new file mode 100644
index 0000000..3e085a9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/macros.h
@@ -0,0 +1,158 @@
+//
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+// -----------------------------------------------------------------------------
+// File: macros.h
+// -----------------------------------------------------------------------------
+//
+// This header file defines the set of language macros used within Abseil code.
+// For the set of macros used to determine supported compilers and platforms,
+// see absl/base/config.h instead.
+//
+// This code is compiled directly on many platforms, including client
+// platforms like Windows, Mac, and embedded systems.  Before making
+// any changes here, make sure that you're not breaking any platforms.
+
+#ifndef ABSL_BASE_MACROS_H_
+#define ABSL_BASE_MACROS_H_
+
+#include <cassert>
+#include <cstddef>
+
+#include "absl/base/attributes.h"
+#include "absl/base/config.h"
+#include "absl/base/optimization.h"
+#include "absl/base/port.h"
+
+// ABSL_ARRAYSIZE()
+//
+// Returns the number of elements in an array as a compile-time constant, which
+// can be used in defining new arrays. If you use this macro on a pointer by
+// mistake, you will get a compile-time error.
+#define ABSL_ARRAYSIZE(array) \
+  (sizeof(::absl::macros_internal::ArraySizeHelper(array)))
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+namespace macros_internal {
+// Note: this internal template function declaration is used by ABSL_ARRAYSIZE.
+// The function doesn't need a definition, as we only use its type.
+template <typename T, size_t N>
+auto ArraySizeHelper(const T (&array)[N]) -> char (&)[N];
+}  // namespace macros_internal
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+// ABSL_BAD_CALL_IF()
+//
+// Used on a function overload to trap bad calls: any call that matches the
+// overload will cause a compile-time error. This macro uses a clang-specific
+// "enable_if" attribute, as described at
+// https://clang.llvm.org/docs/AttributeReference.html#enable-if
+//
+// Overloads which use this macro should be bracketed by
+// `#ifdef ABSL_BAD_CALL_IF`.
+//
+// Example:
+//
+//   int isdigit(int c);
+//   #ifdef ABSL_BAD_CALL_IF
+//   int isdigit(int c)
+//     ABSL_BAD_CALL_IF(c <= -1 || c > 255,
+//                       "'c' must have the value of an unsigned char or EOF");
+//   #endif // ABSL_BAD_CALL_IF
+#if ABSL_HAVE_ATTRIBUTE(enable_if)
+#define ABSL_BAD_CALL_IF(expr, msg) \
+  __attribute__((enable_if(expr, "Bad call trap"), unavailable(msg)))
+#endif
+
+// ABSL_ASSERT()
+//
+// In C++11, `assert` can't be used portably within constexpr functions.
+// ABSL_ASSERT functions as a runtime assert but works in C++11 constexpr
+// functions.  Example:
+//
+// constexpr double Divide(double a, double b) {
+//   return ABSL_ASSERT(b != 0), a / b;
+// }
+//
+// This macro is inspired by
+// https://akrzemi1.wordpress.com/2017/05/18/asserts-in-constexpr-functions/
+#if defined(NDEBUG)
+#define ABSL_ASSERT(expr) \
+  (false ? static_cast<void>(expr) : static_cast<void>(0))
+#else
+#define ABSL_ASSERT(expr)                           \
+  (ABSL_PREDICT_TRUE((expr)) ? static_cast<void>(0) \
+                             : [] { assert(false && #expr); }())  // NOLINT
+#endif
+
+// `ABSL_INTERNAL_HARDENING_ABORT()` controls how `ABSL_HARDENING_ASSERT()`
+// aborts the program in release mode (when NDEBUG is defined). The
+// implementation should abort the program as quickly as possible and ideally it
+// should not be possible to ignore the abort request.
+#if (ABSL_HAVE_BUILTIN(__builtin_trap) &&         \
+     ABSL_HAVE_BUILTIN(__builtin_unreachable)) || \
+    (defined(__GNUC__) && !defined(__clang__))
+#define ABSL_INTERNAL_HARDENING_ABORT() \
+  do {                                  \
+    __builtin_trap();                   \
+    __builtin_unreachable();            \
+  } while (false)
+#else
+#define ABSL_INTERNAL_HARDENING_ABORT() abort()
+#endif
+
+// ABSL_HARDENING_ASSERT()
+//
+// `ABSL_HARDENING_ASSERT()` is like `ABSL_ASSERT()`, but used to implement
+// runtime assertions that should be enabled in hardened builds even when
+// `NDEBUG` is defined.
+//
+// When `NDEBUG` is not defined, `ABSL_HARDENING_ASSERT()` is identical to
+// `ABSL_ASSERT()`.
+//
+// See `ABSL_OPTION_HARDENED` in `absl/base/options.h` for more information on
+// hardened mode.
+#if ABSL_OPTION_HARDENED == 1 && defined(NDEBUG)
+#define ABSL_HARDENING_ASSERT(expr)                 \
+  (ABSL_PREDICT_TRUE((expr)) ? static_cast<void>(0) \
+                             : [] { ABSL_INTERNAL_HARDENING_ABORT(); }())
+#else
+#define ABSL_HARDENING_ASSERT(expr) ABSL_ASSERT(expr)
+#endif
+
+#ifdef ABSL_HAVE_EXCEPTIONS
+#define ABSL_INTERNAL_TRY try
+#define ABSL_INTERNAL_CATCH_ANY catch (...)
+#define ABSL_INTERNAL_RETHROW do { throw; } while (false)
+#else  // ABSL_HAVE_EXCEPTIONS
+#define ABSL_INTERNAL_TRY if (true)
+#define ABSL_INTERNAL_CATCH_ANY else if (false)
+#define ABSL_INTERNAL_RETHROW do {} while (false)
+#endif  // ABSL_HAVE_EXCEPTIONS
+
+// `ABSL_INTERNAL_UNREACHABLE` is an unreachable statement.  A program which
+// reaches one has undefined behavior, and the compiler may optimize
+// accordingly.
+#if defined(__GNUC__) || ABSL_HAVE_BUILTIN(__builtin_unreachable)
+#define ABSL_INTERNAL_UNREACHABLE __builtin_unreachable()
+#elif defined(_MSC_VER)
+#define ABSL_INTERNAL_UNREACHABLE __assume(0)
+#else
+#define ABSL_INTERNAL_UNREACHABLE
+#endif
+
+#endif  // ABSL_BASE_MACROS_H_
diff --git a/third_party/webrtc_aec3/src/absl/base/optimization.h b/third_party/webrtc_aec3/src/absl/base/optimization.h
new file mode 100644
index 0000000..d090be1
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/optimization.h
@@ -0,0 +1,244 @@
+//
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+// -----------------------------------------------------------------------------
+// File: optimization.h
+// -----------------------------------------------------------------------------
+//
+// This header file defines portable macros for performance optimization.
+
+#ifndef ABSL_BASE_OPTIMIZATION_H_
+#define ABSL_BASE_OPTIMIZATION_H_
+
+#include <assert.h>
+
+#include "absl/base/config.h"
+
+// ABSL_BLOCK_TAIL_CALL_OPTIMIZATION
+//
+// Instructs the compiler to avoid optimizing tail-call recursion. This macro is
+// useful when you wish to preserve the existing function order within a stack
+// trace for logging, debugging, or profiling purposes.
+//
+// Example:
+//
+//   int f() {
+//     int result = g();
+//     ABSL_BLOCK_TAIL_CALL_OPTIMIZATION();
+//     return result;
+//   }
+#if defined(__pnacl__)
+#define ABSL_BLOCK_TAIL_CALL_OPTIMIZATION() if (volatile int x = 0) { (void)x; }
+#elif defined(__clang__)
+// Clang will not tail call given inline volatile assembly.
+#define ABSL_BLOCK_TAIL_CALL_OPTIMIZATION() __asm__ __volatile__("")
+#elif defined(__GNUC__)
+// GCC will not tail call given inline volatile assembly.
+#define ABSL_BLOCK_TAIL_CALL_OPTIMIZATION() __asm__ __volatile__("")
+#elif defined(_MSC_VER)
+#include <intrin.h>
+// The __nop() intrinsic blocks the optimisation.
+#define ABSL_BLOCK_TAIL_CALL_OPTIMIZATION() __nop()
+#else
+#define ABSL_BLOCK_TAIL_CALL_OPTIMIZATION() if (volatile int x = 0) { (void)x; }
+#endif
+
+// ABSL_CACHELINE_SIZE
+//
+// Explicitly defines the size of the L1 cache for purposes of alignment.
+// Setting the cacheline size allows you to specify that certain objects be
+// aligned on a cacheline boundary with `ABSL_CACHELINE_ALIGNED` declarations.
+// (See below.)
+//
+// NOTE: this macro should be replaced with the following C++17 features, when
+// those are generally available:
+//
+//   * `std::hardware_constructive_interference_size`
+//   * `std::hardware_destructive_interference_size`
+//
+// See http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0154r1.html
+// for more information.
+#if defined(__GNUC__)
+// Cache line alignment
+#if defined(__i386__) || defined(__x86_64__)
+#define ABSL_CACHELINE_SIZE 64
+#elif defined(__powerpc64__)
+#define ABSL_CACHELINE_SIZE 128
+#elif defined(__aarch64__)
+// We would need to read special register ctr_el0 to find out L1 dcache size.
+// This value is a good estimate based on a real aarch64 machine.
+#define ABSL_CACHELINE_SIZE 64
+#elif defined(__arm__)
+// Cache line sizes for ARM: These values are not strictly correct since
+// cache line sizes depend on implementations, not architectures.  There
+// are even implementations with cache line sizes configurable at boot
+// time.
+#if defined(__ARM_ARCH_5T__)
+#define ABSL_CACHELINE_SIZE 32
+#elif defined(__ARM_ARCH_7A__)
+#define ABSL_CACHELINE_SIZE 64
+#endif
+#endif
+
+#ifndef ABSL_CACHELINE_SIZE
+// A reasonable default guess.  Note that overestimates tend to waste more
+// space, while underestimates tend to waste more time.
+#define ABSL_CACHELINE_SIZE 64
+#endif
+
+// ABSL_CACHELINE_ALIGNED
+//
+// Indicates that the declared object be cache aligned using
+// `ABSL_CACHELINE_SIZE` (see above). Cacheline aligning objects allows you to
+// load a set of related objects in the L1 cache for performance improvements.
+// Cacheline aligning objects properly allows constructive memory sharing and
+// prevents destructive (or "false") memory sharing.
+//
+// NOTE: callers should replace uses of this macro with `alignas()` using
+// `std::hardware_constructive_interference_size` and/or
+// `std::hardware_destructive_interference_size` when C++17 becomes available to
+// them.
+//
+// See http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0154r1.html
+// for more information.
+//
+// On some compilers, `ABSL_CACHELINE_ALIGNED` expands to an `__attribute__`
+// or `__declspec` attribute. For compilers where this is not known to work,
+// the macro expands to nothing.
+//
+// No further guarantees are made here. The result of applying the macro
+// to variables and types is always implementation-defined.
+//
+// WARNING: It is easy to use this attribute incorrectly, even to the point
+// of causing bugs that are difficult to diagnose, crash, etc. It does not
+// of itself guarantee that objects are aligned to a cache line.
+//
+// NOTE: Some compilers are picky about the locations of annotations such as
+// this attribute, so prefer to put it at the beginning of your declaration.
+// For example,
+//
+//   ABSL_CACHELINE_ALIGNED static Foo* foo = ...
+//
+//   class ABSL_CACHELINE_ALIGNED Bar { ...
+//
+// Recommendations:
+//
+// 1) Consult compiler documentation; this comment is not kept in sync as
+//    toolchains evolve.
+// 2) Verify your use has the intended effect. This often requires inspecting
+//    the generated machine code.
+// 3) Prefer applying this attribute to individual variables. Avoid
+//    applying it to types. This tends to localize the effect.
+#define ABSL_CACHELINE_ALIGNED __attribute__((aligned(ABSL_CACHELINE_SIZE)))
+#elif defined(_MSC_VER)
+#define ABSL_CACHELINE_SIZE 64
+#define ABSL_CACHELINE_ALIGNED __declspec(align(ABSL_CACHELINE_SIZE))
+#else
+#define ABSL_CACHELINE_SIZE 64
+#define ABSL_CACHELINE_ALIGNED
+#endif
+
+// ABSL_PREDICT_TRUE, ABSL_PREDICT_FALSE
+//
+// Enables the compiler to prioritize compilation using static analysis for
+// likely paths within a boolean branch.
+//
+// Example:
+//
+//   if (ABSL_PREDICT_TRUE(expression)) {
+//     return result;                        // Faster if more likely
+//   } else {
+//     return 0;
+//   }
+//
+// Compilers can use the information that a certain branch is not likely to be
+// taken (for instance, a CHECK failure) to optimize for the common case in
+// the absence of better information (ie. compiling gcc with `-fprofile-arcs`).
+//
+// Recommendation: Modern CPUs dynamically predict branch execution paths,
+// typically with accuracy greater than 97%. As a result, annotating every
+// branch in a codebase is likely counterproductive; however, annotating
+// specific branches that are both hot and consistently mispredicted is likely
+// to yield performance improvements.
+#if ABSL_HAVE_BUILTIN(__builtin_expect) || \
+    (defined(__GNUC__) && !defined(__clang__))
+#define ABSL_PREDICT_FALSE(x) (__builtin_expect(false || (x), false))
+#define ABSL_PREDICT_TRUE(x) (__builtin_expect(false || (x), true))
+#else
+#define ABSL_PREDICT_FALSE(x) (x)
+#define ABSL_PREDICT_TRUE(x) (x)
+#endif
+
+// ABSL_INTERNAL_ASSUME(cond)
+// Informs the compiler that a condition is always true and that it can assume
+// it to be true for optimization purposes. The call has undefined behavior if
+// the condition is false.
+// In !NDEBUG mode, the condition is checked with an assert().
+// NOTE: The expression must not have side effects, as it will only be evaluated
+// in some compilation modes and not others.
+//
+// Example:
+//
+//   int x = ...;
+//   ABSL_INTERNAL_ASSUME(x >= 0);
+//   // The compiler can optimize the division to a simple right shift using the
+//   // assumption specified above.
+//   int y = x / 16;
+//
+#if !defined(NDEBUG)
+#define ABSL_INTERNAL_ASSUME(cond) assert(cond)
+#elif ABSL_HAVE_BUILTIN(__builtin_assume)
+#define ABSL_INTERNAL_ASSUME(cond) __builtin_assume(cond)
+#elif defined(__GNUC__) || ABSL_HAVE_BUILTIN(__builtin_unreachable)
+#define ABSL_INTERNAL_ASSUME(cond)        \
+  do {                                    \
+    if (!(cond)) __builtin_unreachable(); \
+  } while (0)
+#elif defined(_MSC_VER)
+#define ABSL_INTERNAL_ASSUME(cond) __assume(cond)
+#else
+#define ABSL_INTERNAL_ASSUME(cond)      \
+  do {                                  \
+    static_cast<void>(false && (cond)); \
+  } while (0)
+#endif
+
+// ABSL_INTERNAL_UNIQUE_SMALL_NAME(cond)
+// This macro forces small unique name on a static file level symbols like
+// static local variables or static functions. This is intended to be used in
+// macro definitions to optimize the cost of generated code. Do NOT use it on
+// symbols exported from translation unit since it may cause a link time
+// conflict.
+//
+// Example:
+//
+// #define MY_MACRO(txt)
+// namespace {
+//  char VeryVeryLongVarName[] ABSL_INTERNAL_UNIQUE_SMALL_NAME() = txt;
+//  const char* VeryVeryLongFuncName() ABSL_INTERNAL_UNIQUE_SMALL_NAME();
+//  const char* VeryVeryLongFuncName() { return txt; }
+// }
+//
+
+#if defined(__GNUC__)
+#define ABSL_INTERNAL_UNIQUE_SMALL_NAME2(x) #x
+#define ABSL_INTERNAL_UNIQUE_SMALL_NAME1(x) ABSL_INTERNAL_UNIQUE_SMALL_NAME2(x)
+#define ABSL_INTERNAL_UNIQUE_SMALL_NAME() \
+  asm(ABSL_INTERNAL_UNIQUE_SMALL_NAME1(.absl.__COUNTER__))
+#else
+#define ABSL_INTERNAL_UNIQUE_SMALL_NAME()
+#endif
+
+#endif  // ABSL_BASE_OPTIMIZATION_H_
diff --git a/third_party/webrtc_aec3/src/absl/base/options.h b/third_party/webrtc_aec3/src/absl/base/options.h
new file mode 100644
index 0000000..230bf1e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/options.h
@@ -0,0 +1,238 @@
+// Copyright 2019 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+// -----------------------------------------------------------------------------
+// File: options.h
+// -----------------------------------------------------------------------------
+//
+// This file contains Abseil configuration options for setting specific
+// implementations instead of letting Abseil determine which implementation to
+// use at compile-time. Setting these options may be useful for package or build
+// managers who wish to guarantee ABI stability within binary builds (which are
+// otherwise difficult to enforce).
+//
+// *** IMPORTANT NOTICE FOR PACKAGE MANAGERS:  It is important that
+// maintainers of package managers who wish to package Abseil read and
+// understand this file! ***
+//
+// Abseil contains a number of possible configuration endpoints, based on
+// parameters such as the detected platform, language version, or command-line
+// flags used to invoke the underlying binary. As is the case with all
+// libraries, binaries which contain Abseil code must ensure that separate
+// packages use the same compiled copy of Abseil to avoid a diamond dependency
+// problem, which can occur if two packages built with different Abseil
+// configuration settings are linked together. Diamond dependency problems in
+// C++ may manifest as violations to the One Definition Rule (ODR) (resulting in
+// linker errors), or undefined behavior (resulting in crashes).
+//
+// Diamond dependency problems can be avoided if all packages utilize the same
+// exact version of Abseil. Building from source code with the same compilation
+// parameters is the easiest way to avoid such dependency problems. However, for
+// package managers who cannot control such compilation parameters, we are
+// providing the file to allow you to inject ABI (Application Binary Interface)
+// stability across builds. Settings options in this file will neither change
+// API nor ABI, providing a stable copy of Abseil between packages.
+//
+// Care must be taken to keep options within these configurations isolated
+// from any other dynamic settings, such as command-line flags which could alter
+// these options. This file is provided specifically to help build and package
+// managers provide a stable copy of Abseil within their libraries and binaries;
+// other developers should not have need to alter the contents of this file.
+//
+// -----------------------------------------------------------------------------
+// Usage
+// -----------------------------------------------------------------------------
+//
+// For any particular package release, set the appropriate definitions within
+// this file to whatever value makes the most sense for your package(s). Note
+// that, by default, most of these options, at the moment, affect the
+// implementation of types; future options may affect other implementation
+// details.
+//
+// NOTE: the defaults within this file all assume that Abseil can select the
+// proper Abseil implementation at compile-time, which will not be sufficient
+// to guarantee ABI stability to package managers.
+
+#ifndef ABSL_BASE_OPTIONS_H_
+#define ABSL_BASE_OPTIONS_H_
+
+// Include a standard library header to allow configuration based on the
+// standard library in use.
+#ifdef __cplusplus
+#include <ciso646>
+#endif
+
+// -----------------------------------------------------------------------------
+// Type Compatibility Options
+// -----------------------------------------------------------------------------
+//
+// ABSL_OPTION_USE_STD_ANY
+//
+// This option controls whether absl::any is implemented as an alias to
+// std::any, or as an independent implementation.
+//
+// A value of 0 means to use Abseil's implementation.  This requires only C++11
+// support, and is expected to work on every toolchain we support.
+//
+// A value of 1 means to use an alias to std::any.  This requires that all code
+// using Abseil is built in C++17 mode or later.
+//
+// A value of 2 means to detect the C++ version being used to compile Abseil,
+// and use an alias only if a working std::any is available.  This option is
+// useful when you are building your entire program, including all of its
+// dependencies, from source.  It should not be used otherwise -- for example,
+// if you are distributing Abseil in a binary package manager -- since in
+// mode 2, absl::any will name a different type, with a different mangled name
+// and binary layout, depending on the compiler flags passed by the end user.
+// For more info, see https://abseil.io/about/design/dropin-types.
+//
+// User code should not inspect this macro.  To check in the preprocessor if
+// absl::any is a typedef of std::any, use the feature macro ABSL_USES_STD_ANY.
+
+#define ABSL_OPTION_USE_STD_ANY 2
+
+
+// ABSL_OPTION_USE_STD_OPTIONAL
+//
+// This option controls whether absl::optional is implemented as an alias to
+// std::optional, or as an independent implementation.
+//
+// A value of 0 means to use Abseil's implementation.  This requires only C++11
+// support, and is expected to work on every toolchain we support.
+//
+// A value of 1 means to use an alias to std::optional.  This requires that all
+// code using Abseil is built in C++17 mode or later.
+//
+// A value of 2 means to detect the C++ version being used to compile Abseil,
+// and use an alias only if a working std::optional is available.  This option
+// is useful when you are building your program from source.  It should not be
+// used otherwise -- for example, if you are distributing Abseil in a binary
+// package manager -- since in mode 2, absl::optional will name a different
+// type, with a different mangled name and binary layout, depending on the
+// compiler flags passed by the end user.  For more info, see
+// https://abseil.io/about/design/dropin-types.
+
+// User code should not inspect this macro.  To check in the preprocessor if
+// absl::optional is a typedef of std::optional, use the feature macro
+// ABSL_USES_STD_OPTIONAL.
+
+#define ABSL_OPTION_USE_STD_OPTIONAL 2
+
+
+// ABSL_OPTION_USE_STD_STRING_VIEW
+//
+// This option controls whether absl::string_view is implemented as an alias to
+// std::string_view, or as an independent implementation.
+//
+// A value of 0 means to use Abseil's implementation.  This requires only C++11
+// support, and is expected to work on every toolchain we support.
+//
+// A value of 1 means to use an alias to std::string_view.  This requires that
+// all code using Abseil is built in C++17 mode or later.
+//
+// A value of 2 means to detect the C++ version being used to compile Abseil,
+// and use an alias only if a working std::string_view is available.  This
+// option is useful when you are building your program from source.  It should
+// not be used otherwise -- for example, if you are distributing Abseil in a
+// binary package manager -- since in mode 2, absl::string_view will name a
+// different type, with a different mangled name and binary layout, depending on
+// the compiler flags passed by the end user.  For more info, see
+// https://abseil.io/about/design/dropin-types.
+//
+// User code should not inspect this macro.  To check in the preprocessor if
+// absl::string_view is a typedef of std::string_view, use the feature macro
+// ABSL_USES_STD_STRING_VIEW.
+
+#define ABSL_OPTION_USE_STD_STRING_VIEW 2
+
+// ABSL_OPTION_USE_STD_VARIANT
+//
+// This option controls whether absl::variant is implemented as an alias to
+// std::variant, or as an independent implementation.
+//
+// A value of 0 means to use Abseil's implementation.  This requires only C++11
+// support, and is expected to work on every toolchain we support.
+//
+// A value of 1 means to use an alias to std::variant.  This requires that all
+// code using Abseil is built in C++17 mode or later.
+//
+// A value of 2 means to detect the C++ version being used to compile Abseil,
+// and use an alias only if a working std::variant is available.  This option
+// is useful when you are building your program from source.  It should not be
+// used otherwise -- for example, if you are distributing Abseil in a binary
+// package manager -- since in mode 2, absl::variant will name a different
+// type, with a different mangled name and binary layout, depending on the
+// compiler flags passed by the end user.  For more info, see
+// https://abseil.io/about/design/dropin-types.
+//
+// User code should not inspect this macro.  To check in the preprocessor if
+// absl::variant is a typedef of std::variant, use the feature macro
+// ABSL_USES_STD_VARIANT.
+
+#define ABSL_OPTION_USE_STD_VARIANT 2
+
+
+// ABSL_OPTION_USE_INLINE_NAMESPACE
+// ABSL_OPTION_INLINE_NAMESPACE_NAME
+//
+// These options controls whether all entities in the absl namespace are
+// contained within an inner inline namespace.  This does not affect the
+// user-visible API of Abseil, but it changes the mangled names of all symbols.
+//
+// This can be useful as a version tag if you are distributing Abseil in
+// precompiled form.  This will prevent a binary library build of Abseil with
+// one inline namespace being used with headers configured with a different
+// inline namespace name.  Binary packagers are reminded that Abseil does not
+// guarantee any ABI stability in Abseil, so any update of Abseil or
+// configuration change in such a binary package should be combined with a
+// new, unique value for the inline namespace name.
+//
+// A value of 0 means not to use inline namespaces.
+//
+// A value of 1 means to use an inline namespace with the given name inside
+// namespace absl.  If this is set, ABSL_OPTION_INLINE_NAMESPACE_NAME must also
+// be changed to a new, unique identifier name.  In particular "head" is not
+// allowed.
+
+#define ABSL_OPTION_USE_INLINE_NAMESPACE 0
+#define ABSL_OPTION_INLINE_NAMESPACE_NAME head
+
+// ABSL_OPTION_HARDENED
+//
+// This option enables a "hardened" build in release mode (in this context,
+// release mode is defined as a build where the `NDEBUG` macro is defined).
+//
+// A value of 0 means that "hardened" mode is not enabled.
+//
+// A value of 1 means that "hardened" mode is enabled.
+//
+// Hardened builds have additional security checks enabled when `NDEBUG` is
+// defined. Defining `NDEBUG` is normally used to turn `assert()` macro into a
+// no-op, as well as disabling other bespoke program consistency checks. By
+// defining ABSL_OPTION_HARDENED to 1, a select set of checks remain enabled in
+// release mode. These checks guard against programming errors that may lead to
+// security vulnerabilities. In release mode, when one of these programming
+// errors is encountered, the program will immediately abort, possibly without
+// any attempt at logging.
+//
+// The checks enabled by this option are not free; they do incur runtime cost.
+//
+// The checks enabled by this option are always active when `NDEBUG` is not
+// defined, even in the case when ABSL_OPTION_HARDENED is defined to 0. The
+// checks enabled by this option may abort the program in a different way and
+// log additional information when `NDEBUG` is not defined.
+
+#define ABSL_OPTION_HARDENED 0
+
+#endif  // ABSL_BASE_OPTIONS_H_
diff --git a/third_party/webrtc_aec3/src/absl/base/policy_checks.h b/third_party/webrtc_aec3/src/absl/base/policy_checks.h
new file mode 100644
index 0000000..06b3243
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/policy_checks.h
@@ -0,0 +1,111 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+// -----------------------------------------------------------------------------
+// File: policy_checks.h
+// -----------------------------------------------------------------------------
+//
+// This header enforces a minimum set of policies at build time, such as the
+// supported compiler and library versions. Unsupported configurations are
+// reported with `#error`. This enforcement is best effort, so successfully
+// compiling this header does not guarantee a supported configuration.
+
+#ifndef ABSL_BASE_POLICY_CHECKS_H_
+#define ABSL_BASE_POLICY_CHECKS_H_
+
+// Included for the __GLIBC_PREREQ macro used below.
+#include <limits.h>
+
+// Included for the _STLPORT_VERSION macro used below.
+#if defined(__cplusplus)
+#include <cstddef>
+#endif
+
+// -----------------------------------------------------------------------------
+// Operating System Check
+// -----------------------------------------------------------------------------
+
+#if defined(__CYGWIN__)
+#error "Cygwin is not supported."
+#endif
+
+// -----------------------------------------------------------------------------
+// Toolchain Check
+// -----------------------------------------------------------------------------
+
+// We support MSVC++ 14.0 update 2 and later.
+// This minimum will go up.
+#if defined(_MSC_FULL_VER) && _MSC_FULL_VER < 190023918 && !defined(__clang__)
+#error "This package requires Visual Studio 2015 Update 2 or higher."
+#endif
+
+// We support gcc 4.7 and later.
+// This minimum will go up.
+#if defined(__GNUC__) && !defined(__clang__)
+#if __GNUC__ < 4 || (__GNUC__ == 4 && __GNUC_MINOR__ < 7)
+#error "This package requires gcc 4.7 or higher."
+#endif
+#endif
+
+// We support Apple Xcode clang 4.2.1 (version 421.11.65) and later.
+// This corresponds to Apple Xcode version 4.5.
+// This minimum will go up.
+#if defined(__apple_build_version__) && __apple_build_version__ < 4211165
+#error "This package requires __apple_build_version__ of 4211165 or higher."
+#endif
+
+// -----------------------------------------------------------------------------
+// C++ Version Check
+// -----------------------------------------------------------------------------
+
+// Enforce C++11 as the minimum.  Note that Visual Studio has not
+// advanced __cplusplus despite being good enough for our purposes, so
+// so we exempt it from the check.
+#if defined(__cplusplus) && !defined(_MSC_VER)
+#if __cplusplus < 201103L
+#error "C++ versions less than C++11 are not supported."
+#endif
+#endif
+
+// -----------------------------------------------------------------------------
+// Standard Library Check
+// -----------------------------------------------------------------------------
+
+#if defined(_STLPORT_VERSION)
+#error "STLPort is not supported."
+#endif
+
+// -----------------------------------------------------------------------------
+// `char` Size Check
+// -----------------------------------------------------------------------------
+
+// Abseil currently assumes CHAR_BIT == 8. If you would like to use Abseil on a
+// platform where this is not the case, please provide us with the details about
+// your platform so we can consider relaxing this requirement.
+#if CHAR_BIT != 8
+#error "Abseil assumes CHAR_BIT == 8."
+#endif
+
+// -----------------------------------------------------------------------------
+// `int` Size Check
+// -----------------------------------------------------------------------------
+
+// Abseil currently assumes that an int is 4 bytes. If you would like to use
+// Abseil on a platform where this is not the case, please provide us with the
+// details about your platform so we can consider relaxing this requirement.
+#if INT_MAX < 2147483647
+#error "Abseil assumes that int is at least 4 bytes. "
+#endif
+
+#endif  // ABSL_BASE_POLICY_CHECKS_H_
diff --git a/third_party/webrtc_aec3/src/absl/base/port.h b/third_party/webrtc_aec3/src/absl/base/port.h
new file mode 100644
index 0000000..5bc4d6c
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/base/port.h
@@ -0,0 +1,25 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+// This files is a forwarding header for other headers containing various
+// portability macros and functions.
+
+#ifndef ABSL_BASE_PORT_H_
+#define ABSL_BASE_PORT_H_
+
+#include "absl/base/attributes.h"
+#include "absl/base/config.h"
+#include "absl/base/optimization.h"
+
+#endif  // ABSL_BASE_PORT_H_
diff --git a/third_party/webrtc_aec3/src/absl/memory/memory.h b/third_party/webrtc_aec3/src/absl/memory/memory.h
new file mode 100644
index 0000000..2b5ff62
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/memory/memory.h
@@ -0,0 +1,699 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+// -----------------------------------------------------------------------------
+// File: memory.h
+// -----------------------------------------------------------------------------
+//
+// This header file contains utility functions for managing the creation and
+// conversion of smart pointers. This file is an extension to the C++
+// standard <memory> library header file.
+
+#ifndef ABSL_MEMORY_MEMORY_H_
+#define ABSL_MEMORY_MEMORY_H_
+
+#include <cstddef>
+#include <limits>
+#include <memory>
+#include <new>
+#include <type_traits>
+#include <utility>
+
+#include "absl/base/macros.h"
+#include "absl/meta/type_traits.h"
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+
+// -----------------------------------------------------------------------------
+// Function Template: WrapUnique()
+// -----------------------------------------------------------------------------
+//
+// Adopts ownership from a raw pointer and transfers it to the returned
+// `std::unique_ptr`, whose type is deduced. Because of this deduction, *do not*
+// specify the template type `T` when calling `WrapUnique`.
+//
+// Example:
+//   X* NewX(int, int);
+//   auto x = WrapUnique(NewX(1, 2));  // 'x' is std::unique_ptr<X>.
+//
+// Do not call WrapUnique with an explicit type, as in
+// `WrapUnique<X>(NewX(1, 2))`.  The purpose of WrapUnique is to automatically
+// deduce the pointer type. If you wish to make the type explicit, just use
+// `std::unique_ptr` directly.
+//
+//   auto x = std::unique_ptr<X>(NewX(1, 2));
+//                  - or -
+//   std::unique_ptr<X> x(NewX(1, 2));
+//
+// While `absl::WrapUnique` is useful for capturing the output of a raw
+// pointer factory, prefer 'absl::make_unique<T>(args...)' over
+// 'absl::WrapUnique(new T(args...))'.
+//
+//   auto x = WrapUnique(new X(1, 2));  // works, but nonideal.
+//   auto x = make_unique<X>(1, 2);     // safer, standard, avoids raw 'new'.
+//
+// Note that `absl::WrapUnique(p)` is valid only if `delete p` is a valid
+// expression. In particular, `absl::WrapUnique()` cannot wrap pointers to
+// arrays, functions or void, and it must not be used to capture pointers
+// obtained from array-new expressions (even though that would compile!).
+template <typename T>
+std::unique_ptr<T> WrapUnique(T* ptr) {
+  static_assert(!std::is_array<T>::value, "array types are unsupported");
+  static_assert(std::is_object<T>::value, "non-object types are unsupported");
+  return std::unique_ptr<T>(ptr);
+}
+
+namespace memory_internal {
+
+// Traits to select proper overload and return type for `absl::make_unique<>`.
+template <typename T>
+struct MakeUniqueResult {
+  using scalar = std::unique_ptr<T>;
+};
+template <typename T>
+struct MakeUniqueResult<T[]> {
+  using array = std::unique_ptr<T[]>;
+};
+template <typename T, size_t N>
+struct MakeUniqueResult<T[N]> {
+  using invalid = void;
+};
+
+}  // namespace memory_internal
+
+// gcc 4.8 has __cplusplus at 201301 but the libstdc++ shipped with it doesn't
+// define make_unique.  Other supported compilers either just define __cplusplus
+// as 201103 but have make_unique (msvc), or have make_unique whenever
+// __cplusplus > 201103 (clang).
+#if (__cplusplus > 201103L || defined(_MSC_VER)) && \
+    !(defined(__GLIBCXX__) && !defined(__cpp_lib_make_unique))
+using std::make_unique;
+#else
+// -----------------------------------------------------------------------------
+// Function Template: make_unique<T>()
+// -----------------------------------------------------------------------------
+//
+// Creates a `std::unique_ptr<>`, while avoiding issues creating temporaries
+// during the construction process. `absl::make_unique<>` also avoids redundant
+// type declarations, by avoiding the need to explicitly use the `new` operator.
+//
+// This implementation of `absl::make_unique<>` is designed for C++11 code and
+// will be replaced in C++14 by the equivalent `std::make_unique<>` abstraction.
+// `absl::make_unique<>` is designed to be 100% compatible with
+// `std::make_unique<>` so that the eventual migration will involve a simple
+// rename operation.
+//
+// For more background on why `std::unique_ptr<T>(new T(a,b))` is problematic,
+// see Herb Sutter's explanation on
+// (Exception-Safe Function Calls)[https://herbsutter.com/gotw/_102/].
+// (In general, reviewers should treat `new T(a,b)` with scrutiny.)
+//
+// Example usage:
+//
+//    auto p = make_unique<X>(args...);  // 'p'  is a std::unique_ptr<X>
+//    auto pa = make_unique<X[]>(5);     // 'pa' is a std::unique_ptr<X[]>
+//
+// Three overloads of `absl::make_unique` are required:
+//
+//   - For non-array T:
+//
+//       Allocates a T with `new T(std::forward<Args> args...)`,
+//       forwarding all `args` to T's constructor.
+//       Returns a `std::unique_ptr<T>` owning that object.
+//
+//   - For an array of unknown bounds T[]:
+//
+//       `absl::make_unique<>` will allocate an array T of type U[] with
+//       `new U[n]()` and return a `std::unique_ptr<U[]>` owning that array.
+//
+//       Note that 'U[n]()' is different from 'U[n]', and elements will be
+//       value-initialized. Note as well that `std::unique_ptr` will perform its
+//       own destruction of the array elements upon leaving scope, even though
+//       the array [] does not have a default destructor.
+//
+//       NOTE: an array of unknown bounds T[] may still be (and often will be)
+//       initialized to have a size, and will still use this overload. E.g:
+//
+//         auto my_array = absl::make_unique<int[]>(10);
+//
+//   - For an array of known bounds T[N]:
+//
+//       `absl::make_unique<>` is deleted (like with `std::make_unique<>`) as
+//       this overload is not useful.
+//
+//       NOTE: an array of known bounds T[N] is not considered a useful
+//       construction, and may cause undefined behavior in templates. E.g:
+//
+//         auto my_array = absl::make_unique<int[10]>();
+//
+//       In those cases, of course, you can still use the overload above and
+//       simply initialize it to its desired size:
+//
+//         auto my_array = absl::make_unique<int[]>(10);
+
+// `absl::make_unique` overload for non-array types.
+template <typename T, typename... Args>
+typename memory_internal::MakeUniqueResult<T>::scalar make_unique(
+    Args&&... args) {
+  return std::unique_ptr<T>(new T(std::forward<Args>(args)...));
+}
+
+// `absl::make_unique` overload for an array T[] of unknown bounds.
+// The array allocation needs to use the `new T[size]` form and cannot take
+// element constructor arguments. The `std::unique_ptr` will manage destructing
+// these array elements.
+template <typename T>
+typename memory_internal::MakeUniqueResult<T>::array make_unique(size_t n) {
+  return std::unique_ptr<T>(new typename absl::remove_extent_t<T>[n]());
+}
+
+// `absl::make_unique` overload for an array T[N] of known bounds.
+// This construction will be rejected.
+template <typename T, typename... Args>
+typename memory_internal::MakeUniqueResult<T>::invalid make_unique(
+    Args&&... /* args */) = delete;
+#endif
+
+// -----------------------------------------------------------------------------
+// Function Template: RawPtr()
+// -----------------------------------------------------------------------------
+//
+// Extracts the raw pointer from a pointer-like value `ptr`. `absl::RawPtr` is
+// useful within templates that need to handle a complement of raw pointers,
+// `std::nullptr_t`, and smart pointers.
+template <typename T>
+auto RawPtr(T&& ptr) -> decltype(std::addressof(*ptr)) {
+  // ptr is a forwarding reference to support Ts with non-const operators.
+  return (ptr != nullptr) ? std::addressof(*ptr) : nullptr;
+}
+inline std::nullptr_t RawPtr(std::nullptr_t) { return nullptr; }
+
+// -----------------------------------------------------------------------------
+// Function Template: ShareUniquePtr()
+// -----------------------------------------------------------------------------
+//
+// Adopts a `std::unique_ptr` rvalue and returns a `std::shared_ptr` of deduced
+// type. Ownership (if any) of the held value is transferred to the returned
+// shared pointer.
+//
+// Example:
+//
+//     auto up = absl::make_unique<int>(10);
+//     auto sp = absl::ShareUniquePtr(std::move(up));  // shared_ptr<int>
+//     CHECK_EQ(*sp, 10);
+//     CHECK(up == nullptr);
+//
+// Note that this conversion is correct even when T is an array type, and more
+// generally it works for *any* deleter of the `unique_ptr` (single-object
+// deleter, array deleter, or any custom deleter), since the deleter is adopted
+// by the shared pointer as well. The deleter is copied (unless it is a
+// reference).
+//
+// Implements the resolution of [LWG 2415](http://wg21.link/lwg2415), by which a
+// null shared pointer does not attempt to call the deleter.
+template <typename T, typename D>
+std::shared_ptr<T> ShareUniquePtr(std::unique_ptr<T, D>&& ptr) {
+  return ptr ? std::shared_ptr<T>(std::move(ptr)) : std::shared_ptr<T>();
+}
+
+// -----------------------------------------------------------------------------
+// Function Template: WeakenPtr()
+// -----------------------------------------------------------------------------
+//
+// Creates a weak pointer associated with a given shared pointer. The returned
+// value is a `std::weak_ptr` of deduced type.
+//
+// Example:
+//
+//    auto sp = std::make_shared<int>(10);
+//    auto wp = absl::WeakenPtr(sp);
+//    CHECK_EQ(sp.get(), wp.lock().get());
+//    sp.reset();
+//    CHECK(wp.lock() == nullptr);
+//
+template <typename T>
+std::weak_ptr<T> WeakenPtr(const std::shared_ptr<T>& ptr) {
+  return std::weak_ptr<T>(ptr);
+}
+
+namespace memory_internal {
+
+// ExtractOr<E, O, D>::type evaluates to E<O> if possible. Otherwise, D.
+template <template <typename> class Extract, typename Obj, typename Default,
+          typename>
+struct ExtractOr {
+  using type = Default;
+};
+
+template <template <typename> class Extract, typename Obj, typename Default>
+struct ExtractOr<Extract, Obj, Default, void_t<Extract<Obj>>> {
+  using type = Extract<Obj>;
+};
+
+template <template <typename> class Extract, typename Obj, typename Default>
+using ExtractOrT = typename ExtractOr<Extract, Obj, Default, void>::type;
+
+// Extractors for the features of allocators.
+template <typename T>
+using GetPointer = typename T::pointer;
+
+template <typename T>
+using GetConstPointer = typename T::const_pointer;
+
+template <typename T>
+using GetVoidPointer = typename T::void_pointer;
+
+template <typename T>
+using GetConstVoidPointer = typename T::const_void_pointer;
+
+template <typename T>
+using GetDifferenceType = typename T::difference_type;
+
+template <typename T>
+using GetSizeType = typename T::size_type;
+
+template <typename T>
+using GetPropagateOnContainerCopyAssignment =
+    typename T::propagate_on_container_copy_assignment;
+
+template <typename T>
+using GetPropagateOnContainerMoveAssignment =
+    typename T::propagate_on_container_move_assignment;
+
+template <typename T>
+using GetPropagateOnContainerSwap = typename T::propagate_on_container_swap;
+
+template <typename T>
+using GetIsAlwaysEqual = typename T::is_always_equal;
+
+template <typename T>
+struct GetFirstArg;
+
+template <template <typename...> class Class, typename T, typename... Args>
+struct GetFirstArg<Class<T, Args...>> {
+  using type = T;
+};
+
+template <typename Ptr, typename = void>
+struct ElementType {
+  using type = typename GetFirstArg<Ptr>::type;
+};
+
+template <typename T>
+struct ElementType<T, void_t<typename T::element_type>> {
+  using type = typename T::element_type;
+};
+
+template <typename T, typename U>
+struct RebindFirstArg;
+
+template <template <typename...> class Class, typename T, typename... Args,
+          typename U>
+struct RebindFirstArg<Class<T, Args...>, U> {
+  using type = Class<U, Args...>;
+};
+
+template <typename T, typename U, typename = void>
+struct RebindPtr {
+  using type = typename RebindFirstArg<T, U>::type;
+};
+
+template <typename T, typename U>
+struct RebindPtr<T, U, void_t<typename T::template rebind<U>>> {
+  using type = typename T::template rebind<U>;
+};
+
+template <typename T, typename U>
+constexpr bool HasRebindAlloc(...) {
+  return false;
+}
+
+template <typename T, typename U>
+constexpr bool HasRebindAlloc(typename T::template rebind<U>::other*) {
+  return true;
+}
+
+template <typename T, typename U, bool = HasRebindAlloc<T, U>(nullptr)>
+struct RebindAlloc {
+  using type = typename RebindFirstArg<T, U>::type;
+};
+
+template <typename T, typename U>
+struct RebindAlloc<T, U, true> {
+  using type = typename T::template rebind<U>::other;
+};
+
+}  // namespace memory_internal
+
+// -----------------------------------------------------------------------------
+// Class Template: pointer_traits
+// -----------------------------------------------------------------------------
+//
+// An implementation of C++11's std::pointer_traits.
+//
+// Provided for portability on toolchains that have a working C++11 compiler,
+// but the standard library is lacking in C++11 support. For example, some
+// version of the Android NDK.
+//
+
+template <typename Ptr>
+struct pointer_traits {
+  using pointer = Ptr;
+
+  // element_type:
+  // Ptr::element_type if present. Otherwise T if Ptr is a template
+  // instantiation Template<T, Args...>
+  using element_type = typename memory_internal::ElementType<Ptr>::type;
+
+  // difference_type:
+  // Ptr::difference_type if present, otherwise std::ptrdiff_t
+  using difference_type =
+      memory_internal::ExtractOrT<memory_internal::GetDifferenceType, Ptr,
+                                  std::ptrdiff_t>;
+
+  // rebind:
+  // Ptr::rebind<U> if exists, otherwise Template<U, Args...> if Ptr is a
+  // template instantiation Template<T, Args...>
+  template <typename U>
+  using rebind = typename memory_internal::RebindPtr<Ptr, U>::type;
+
+  // pointer_to:
+  // Calls Ptr::pointer_to(r)
+  static pointer pointer_to(element_type& r) {  // NOLINT(runtime/references)
+    return Ptr::pointer_to(r);
+  }
+};
+
+// Specialization for T*.
+template <typename T>
+struct pointer_traits<T*> {
+  using pointer = T*;
+  using element_type = T;
+  using difference_type = std::ptrdiff_t;
+
+  template <typename U>
+  using rebind = U*;
+
+  // pointer_to:
+  // Calls std::addressof(r)
+  static pointer pointer_to(
+      element_type& r) noexcept {  // NOLINT(runtime/references)
+    return std::addressof(r);
+  }
+};
+
+// -----------------------------------------------------------------------------
+// Class Template: allocator_traits
+// -----------------------------------------------------------------------------
+//
+// A C++11 compatible implementation of C++17's std::allocator_traits.
+//
+#if __cplusplus >= 201703L
+using std::allocator_traits;
+#else  // __cplusplus >= 201703L
+template <typename Alloc>
+struct allocator_traits {
+  using allocator_type = Alloc;
+
+  // value_type:
+  // Alloc::value_type
+  using value_type = typename Alloc::value_type;
+
+  // pointer:
+  // Alloc::pointer if present, otherwise value_type*
+  using pointer = memory_internal::ExtractOrT<memory_internal::GetPointer,
+                                              Alloc, value_type*>;
+
+  // const_pointer:
+  // Alloc::const_pointer if present, otherwise
+  // absl::pointer_traits<pointer>::rebind<const value_type>
+  using const_pointer =
+      memory_internal::ExtractOrT<memory_internal::GetConstPointer, Alloc,
+                                  typename absl::pointer_traits<pointer>::
+                                      template rebind<const value_type>>;
+
+  // void_pointer:
+  // Alloc::void_pointer if present, otherwise
+  // absl::pointer_traits<pointer>::rebind<void>
+  using void_pointer = memory_internal::ExtractOrT<
+      memory_internal::GetVoidPointer, Alloc,
+      typename absl::pointer_traits<pointer>::template rebind<void>>;
+
+  // const_void_pointer:
+  // Alloc::const_void_pointer if present, otherwise
+  // absl::pointer_traits<pointer>::rebind<const void>
+  using const_void_pointer = memory_internal::ExtractOrT<
+      memory_internal::GetConstVoidPointer, Alloc,
+      typename absl::pointer_traits<pointer>::template rebind<const void>>;
+
+  // difference_type:
+  // Alloc::difference_type if present, otherwise
+  // absl::pointer_traits<pointer>::difference_type
+  using difference_type = memory_internal::ExtractOrT<
+      memory_internal::GetDifferenceType, Alloc,
+      typename absl::pointer_traits<pointer>::difference_type>;
+
+  // size_type:
+  // Alloc::size_type if present, otherwise
+  // std::make_unsigned<difference_type>::type
+  using size_type = memory_internal::ExtractOrT<
+      memory_internal::GetSizeType, Alloc,
+      typename std::make_unsigned<difference_type>::type>;
+
+  // propagate_on_container_copy_assignment:
+  // Alloc::propagate_on_container_copy_assignment if present, otherwise
+  // std::false_type
+  using propagate_on_container_copy_assignment = memory_internal::ExtractOrT<
+      memory_internal::GetPropagateOnContainerCopyAssignment, Alloc,
+      std::false_type>;
+
+  // propagate_on_container_move_assignment:
+  // Alloc::propagate_on_container_move_assignment if present, otherwise
+  // std::false_type
+  using propagate_on_container_move_assignment = memory_internal::ExtractOrT<
+      memory_internal::GetPropagateOnContainerMoveAssignment, Alloc,
+      std::false_type>;
+
+  // propagate_on_container_swap:
+  // Alloc::propagate_on_container_swap if present, otherwise std::false_type
+  using propagate_on_container_swap =
+      memory_internal::ExtractOrT<memory_internal::GetPropagateOnContainerSwap,
+                                  Alloc, std::false_type>;
+
+  // is_always_equal:
+  // Alloc::is_always_equal if present, otherwise std::is_empty<Alloc>::type
+  using is_always_equal =
+      memory_internal::ExtractOrT<memory_internal::GetIsAlwaysEqual, Alloc,
+                                  typename std::is_empty<Alloc>::type>;
+
+  // rebind_alloc:
+  // Alloc::rebind<T>::other if present, otherwise Alloc<T, Args> if this Alloc
+  // is Alloc<U, Args>
+  template <typename T>
+  using rebind_alloc = typename memory_internal::RebindAlloc<Alloc, T>::type;
+
+  // rebind_traits:
+  // absl::allocator_traits<rebind_alloc<T>>
+  template <typename T>
+  using rebind_traits = absl::allocator_traits<rebind_alloc<T>>;
+
+  // allocate(Alloc& a, size_type n):
+  // Calls a.allocate(n)
+  static pointer allocate(Alloc& a,  // NOLINT(runtime/references)
+                          size_type n) {
+    return a.allocate(n);
+  }
+
+  // allocate(Alloc& a, size_type n, const_void_pointer hint):
+  // Calls a.allocate(n, hint) if possible.
+  // If not possible, calls a.allocate(n)
+  static pointer allocate(Alloc& a, size_type n,  // NOLINT(runtime/references)
+                          const_void_pointer hint) {
+    return allocate_impl(0, a, n, hint);
+  }
+
+  // deallocate(Alloc& a, pointer p, size_type n):
+  // Calls a.deallocate(p, n)
+  static void deallocate(Alloc& a, pointer p,  // NOLINT(runtime/references)
+                         size_type n) {
+    a.deallocate(p, n);
+  }
+
+  // construct(Alloc& a, T* p, Args&&... args):
+  // Calls a.construct(p, std::forward<Args>(args)...) if possible.
+  // If not possible, calls
+  //   ::new (static_cast<void*>(p)) T(std::forward<Args>(args)...)
+  template <typename T, typename... Args>
+  static void construct(Alloc& a, T* p,  // NOLINT(runtime/references)
+                        Args&&... args) {
+    construct_impl(0, a, p, std::forward<Args>(args)...);
+  }
+
+  // destroy(Alloc& a, T* p):
+  // Calls a.destroy(p) if possible. If not possible, calls p->~T().
+  template <typename T>
+  static void destroy(Alloc& a, T* p) {  // NOLINT(runtime/references)
+    destroy_impl(0, a, p);
+  }
+
+  // max_size(const Alloc& a):
+  // Returns a.max_size() if possible. If not possible, returns
+  //   std::numeric_limits<size_type>::max() / sizeof(value_type)
+  static size_type max_size(const Alloc& a) { return max_size_impl(0, a); }
+
+  // select_on_container_copy_construction(const Alloc& a):
+  // Returns a.select_on_container_copy_construction() if possible.
+  // If not possible, returns a.
+  static Alloc select_on_container_copy_construction(const Alloc& a) {
+    return select_on_container_copy_construction_impl(0, a);
+  }
+
+ private:
+  template <typename A>
+  static auto allocate_impl(int, A& a,  // NOLINT(runtime/references)
+                            size_type n, const_void_pointer hint)
+      -> decltype(a.allocate(n, hint)) {
+    return a.allocate(n, hint);
+  }
+  static pointer allocate_impl(char, Alloc& a,  // NOLINT(runtime/references)
+                               size_type n, const_void_pointer) {
+    return a.allocate(n);
+  }
+
+  template <typename A, typename... Args>
+  static auto construct_impl(int, A& a,  // NOLINT(runtime/references)
+                             Args&&... args)
+      -> decltype(a.construct(std::forward<Args>(args)...)) {
+    a.construct(std::forward<Args>(args)...);
+  }
+
+  template <typename T, typename... Args>
+  static void construct_impl(char, Alloc&, T* p, Args&&... args) {
+    ::new (static_cast<void*>(p)) T(std::forward<Args>(args)...);
+  }
+
+  template <typename A, typename T>
+  static auto destroy_impl(int, A& a,  // NOLINT(runtime/references)
+                           T* p) -> decltype(a.destroy(p)) {
+    a.destroy(p);
+  }
+  template <typename T>
+  static void destroy_impl(char, Alloc&, T* p) {
+    p->~T();
+  }
+
+  template <typename A>
+  static auto max_size_impl(int, const A& a) -> decltype(a.max_size()) {
+    return a.max_size();
+  }
+  static size_type max_size_impl(char, const Alloc&) {
+    return (std::numeric_limits<size_type>::max)() / sizeof(value_type);
+  }
+
+  template <typename A>
+  static auto select_on_container_copy_construction_impl(int, const A& a)
+      -> decltype(a.select_on_container_copy_construction()) {
+    return a.select_on_container_copy_construction();
+  }
+  static Alloc select_on_container_copy_construction_impl(char,
+                                                          const Alloc& a) {
+    return a;
+  }
+};
+#endif  // __cplusplus >= 201703L
+
+namespace memory_internal {
+
+// This template alias transforms Alloc::is_nothrow into a metafunction with
+// Alloc as a parameter so it can be used with ExtractOrT<>.
+template <typename Alloc>
+using GetIsNothrow = typename Alloc::is_nothrow;
+
+}  // namespace memory_internal
+
+// ABSL_ALLOCATOR_NOTHROW is a build time configuration macro for user to
+// specify whether the default allocation function can throw or never throws.
+// If the allocation function never throws, user should define it to a non-zero
+// value (e.g. via `-DABSL_ALLOCATOR_NOTHROW`).
+// If the allocation function can throw, user should leave it undefined or
+// define it to zero.
+//
+// allocator_is_nothrow<Alloc> is a traits class that derives from
+// Alloc::is_nothrow if present, otherwise std::false_type. It's specialized
+// for Alloc = std::allocator<T> for any type T according to the state of
+// ABSL_ALLOCATOR_NOTHROW.
+//
+// default_allocator_is_nothrow is a class that derives from std::true_type
+// when the default allocator (global operator new) never throws, and
+// std::false_type when it can throw. It is a convenience shorthand for writing
+// allocator_is_nothrow<std::allocator<T>> (T can be any type).
+// NOTE: allocator_is_nothrow<std::allocator<T>> is guaranteed to derive from
+// the same type for all T, because users should specialize neither
+// allocator_is_nothrow nor std::allocator.
+template <typename Alloc>
+struct allocator_is_nothrow
+    : memory_internal::ExtractOrT<memory_internal::GetIsNothrow, Alloc,
+                                  std::false_type> {};
+
+#if defined(ABSL_ALLOCATOR_NOTHROW) && ABSL_ALLOCATOR_NOTHROW
+template <typename T>
+struct allocator_is_nothrow<std::allocator<T>> : std::true_type {};
+struct default_allocator_is_nothrow : std::true_type {};
+#else
+struct default_allocator_is_nothrow : std::false_type {};
+#endif
+
+namespace memory_internal {
+template <typename Allocator, typename Iterator, typename... Args>
+void ConstructRange(Allocator& alloc, Iterator first, Iterator last,
+                    const Args&... args) {
+  for (Iterator cur = first; cur != last; ++cur) {
+    ABSL_INTERNAL_TRY {
+      std::allocator_traits<Allocator>::construct(alloc, std::addressof(*cur),
+                                                  args...);
+    }
+    ABSL_INTERNAL_CATCH_ANY {
+      while (cur != first) {
+        --cur;
+        std::allocator_traits<Allocator>::destroy(alloc, std::addressof(*cur));
+      }
+      ABSL_INTERNAL_RETHROW;
+    }
+  }
+}
+
+template <typename Allocator, typename Iterator, typename InputIterator>
+void CopyRange(Allocator& alloc, Iterator destination, InputIterator first,
+               InputIterator last) {
+  for (Iterator cur = destination; first != last;
+       static_cast<void>(++cur), static_cast<void>(++first)) {
+    ABSL_INTERNAL_TRY {
+      std::allocator_traits<Allocator>::construct(alloc, std::addressof(*cur),
+                                                  *first);
+    }
+    ABSL_INTERNAL_CATCH_ANY {
+      while (cur != destination) {
+        --cur;
+        std::allocator_traits<Allocator>::destroy(alloc, std::addressof(*cur));
+      }
+      ABSL_INTERNAL_RETHROW;
+    }
+  }
+}
+}  // namespace memory_internal
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#endif  // ABSL_MEMORY_MEMORY_H_
diff --git a/third_party/webrtc_aec3/src/absl/meta/type_traits.h b/third_party/webrtc_aec3/src/absl/meta/type_traits.h
new file mode 100644
index 0000000..b5427a4
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/meta/type_traits.h
@@ -0,0 +1,788 @@
+//
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+// -----------------------------------------------------------------------------
+// type_traits.h
+// -----------------------------------------------------------------------------
+//
+// This file contains C++11-compatible versions of standard <type_traits> API
+// functions for determining the characteristics of types. Such traits can
+// support type inference, classification, and transformation, as well as
+// make it easier to write templates based on generic type behavior.
+//
+// See https://en.cppreference.com/w/cpp/header/type_traits
+//
+// WARNING: use of many of the constructs in this header will count as "complex
+// template metaprogramming", so before proceeding, please carefully consider
+// https://google.github.io/styleguide/cppguide.html#Template_metaprogramming
+//
+// WARNING: using template metaprogramming to detect or depend on API
+// features is brittle and not guaranteed. Neither the standard library nor
+// Abseil provides any guarantee that APIs are stable in the face of template
+// metaprogramming. Use with caution.
+#ifndef ABSL_META_TYPE_TRAITS_H_
+#define ABSL_META_TYPE_TRAITS_H_
+
+#include <stddef.h>
+#include <functional>
+#include <type_traits>
+
+#include "absl/base/config.h"
+
+// MSVC constructibility traits do not detect destructor properties and so our
+// implementations should not use them as a source-of-truth.
+#if defined(_MSC_VER) && !defined(__clang__) && !defined(__GNUC__)
+#define ABSL_META_INTERNAL_STD_CONSTRUCTION_TRAITS_DONT_CHECK_DESTRUCTION 1
+#endif
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+
+// Defined and documented later on in this file.
+template <typename T>
+struct is_trivially_destructible;
+
+// Defined and documented later on in this file.
+template <typename T>
+struct is_trivially_move_assignable;
+
+namespace type_traits_internal {
+
+// Silence MSVC warnings about the destructor being defined as deleted.
+#if defined(_MSC_VER) && !defined(__GNUC__)
+#pragma warning(push)
+#pragma warning(disable : 4624)
+#endif  // defined(_MSC_VER) && !defined(__GNUC__)
+
+template <class T>
+union SingleMemberUnion {
+  T t;
+};
+
+// Restore the state of the destructor warning that was silenced above.
+#if defined(_MSC_VER) && !defined(__GNUC__)
+#pragma warning(pop)
+#endif  // defined(_MSC_VER) && !defined(__GNUC__)
+
+template <class T>
+struct IsTriviallyMoveConstructibleObject
+    : std::integral_constant<
+          bool, std::is_move_constructible<
+                    type_traits_internal::SingleMemberUnion<T>>::value &&
+                    absl::is_trivially_destructible<T>::value> {};
+
+template <class T>
+struct IsTriviallyCopyConstructibleObject
+    : std::integral_constant<
+          bool, std::is_copy_constructible<
+                    type_traits_internal::SingleMemberUnion<T>>::value &&
+                    absl::is_trivially_destructible<T>::value> {};
+
+template <class T>
+struct IsTriviallyMoveAssignableReference : std::false_type {};
+
+template <class T>
+struct IsTriviallyMoveAssignableReference<T&>
+    : absl::is_trivially_move_assignable<T>::type {};
+
+template <class T>
+struct IsTriviallyMoveAssignableReference<T&&>
+    : absl::is_trivially_move_assignable<T>::type {};
+
+template <typename... Ts>
+struct VoidTImpl {
+  using type = void;
+};
+
+// This trick to retrieve a default alignment is necessary for our
+// implementation of aligned_storage_t to be consistent with any implementation
+// of std::aligned_storage.
+template <size_t Len, typename T = std::aligned_storage<Len>>
+struct default_alignment_of_aligned_storage;
+
+template <size_t Len, size_t Align>
+struct default_alignment_of_aligned_storage<Len,
+                                            std::aligned_storage<Len, Align>> {
+  static constexpr size_t value = Align;
+};
+
+////////////////////////////////
+// Library Fundamentals V2 TS //
+////////////////////////////////
+
+// NOTE: The `is_detected` family of templates here differ from the library
+// fundamentals specification in that for library fundamentals, `Op<Args...>` is
+// evaluated as soon as the type `is_detected<Op, Args...>` undergoes
+// substitution, regardless of whether or not the `::value` is accessed. That
+// is inconsistent with all other standard traits and prevents lazy evaluation
+// in larger contexts (such as if the `is_detected` check is a trailing argument
+// of a `conjunction`. This implementation opts to instead be lazy in the same
+// way that the standard traits are (this "defect" of the detection idiom
+// specifications has been reported).
+
+template <class Enabler, template <class...> class Op, class... Args>
+struct is_detected_impl {
+  using type = std::false_type;
+};
+
+template <template <class...> class Op, class... Args>
+struct is_detected_impl<typename VoidTImpl<Op<Args...>>::type, Op, Args...> {
+  using type = std::true_type;
+};
+
+template <template <class...> class Op, class... Args>
+struct is_detected : is_detected_impl<void, Op, Args...>::type {};
+
+template <class Enabler, class To, template <class...> class Op, class... Args>
+struct is_detected_convertible_impl {
+  using type = std::false_type;
+};
+
+template <class To, template <class...> class Op, class... Args>
+struct is_detected_convertible_impl<
+    typename std::enable_if<std::is_convertible<Op<Args...>, To>::value>::type,
+    To, Op, Args...> {
+  using type = std::true_type;
+};
+
+template <class To, template <class...> class Op, class... Args>
+struct is_detected_convertible
+    : is_detected_convertible_impl<void, To, Op, Args...>::type {};
+
+template <typename T>
+using IsCopyAssignableImpl =
+    decltype(std::declval<T&>() = std::declval<const T&>());
+
+template <typename T>
+using IsMoveAssignableImpl = decltype(std::declval<T&>() = std::declval<T&&>());
+
+}  // namespace type_traits_internal
+
+// MSVC 19.20 has a regression that causes our workarounds to fail, but their
+// std forms now appear to be compliant.
+#if defined(_MSC_VER) && !defined(__clang__) && (_MSC_VER >= 1920)
+
+template <typename T>
+using is_copy_assignable = std::is_copy_assignable<T>;
+
+template <typename T>
+using is_move_assignable = std::is_move_assignable<T>;
+
+#else
+
+template <typename T>
+struct is_copy_assignable : type_traits_internal::is_detected<
+                                type_traits_internal::IsCopyAssignableImpl, T> {
+};
+
+template <typename T>
+struct is_move_assignable : type_traits_internal::is_detected<
+                                type_traits_internal::IsMoveAssignableImpl, T> {
+};
+
+#endif
+
+// void_t()
+//
+// Ignores the type of any its arguments and returns `void`. In general, this
+// metafunction allows you to create a general case that maps to `void` while
+// allowing specializations that map to specific types.
+//
+// This metafunction is designed to be a drop-in replacement for the C++17
+// `std::void_t` metafunction.
+//
+// NOTE: `absl::void_t` does not use the standard-specified implementation so
+// that it can remain compatible with gcc < 5.1. This can introduce slightly
+// different behavior, such as when ordering partial specializations.
+template <typename... Ts>
+using void_t = typename type_traits_internal::VoidTImpl<Ts...>::type;
+
+// conjunction
+//
+// Performs a compile-time logical AND operation on the passed types (which
+// must have  `::value` members convertible to `bool`. Short-circuits if it
+// encounters any `false` members (and does not compare the `::value` members
+// of any remaining arguments).
+//
+// This metafunction is designed to be a drop-in replacement for the C++17
+// `std::conjunction` metafunction.
+template <typename... Ts>
+struct conjunction : std::true_type {};
+
+template <typename T, typename... Ts>
+struct conjunction<T, Ts...>
+    : std::conditional<T::value, conjunction<Ts...>, T>::type {};
+
+template <typename T>
+struct conjunction<T> : T {};
+
+// disjunction
+//
+// Performs a compile-time logical OR operation on the passed types (which
+// must have  `::value` members convertible to `bool`. Short-circuits if it
+// encounters any `true` members (and does not compare the `::value` members
+// of any remaining arguments).
+//
+// This metafunction is designed to be a drop-in replacement for the C++17
+// `std::disjunction` metafunction.
+template <typename... Ts>
+struct disjunction : std::false_type {};
+
+template <typename T, typename... Ts>
+struct disjunction<T, Ts...> :
+      std::conditional<T::value, T, disjunction<Ts...>>::type {};
+
+template <typename T>
+struct disjunction<T> : T {};
+
+// negation
+//
+// Performs a compile-time logical NOT operation on the passed type (which
+// must have  `::value` members convertible to `bool`.
+//
+// This metafunction is designed to be a drop-in replacement for the C++17
+// `std::negation` metafunction.
+template <typename T>
+struct negation : std::integral_constant<bool, !T::value> {};
+
+// is_function()
+//
+// Determines whether the passed type `T` is a function type.
+//
+// This metafunction is designed to be a drop-in replacement for the C++11
+// `std::is_function()` metafunction for platforms that have incomplete C++11
+// support (such as libstdc++ 4.x).
+//
+// This metafunction works because appending `const` to a type does nothing to
+// function types and reference types (and forms a const-qualified type
+// otherwise).
+template <typename T>
+struct is_function
+    : std::integral_constant<
+          bool, !(std::is_reference<T>::value ||
+                  std::is_const<typename std::add_const<T>::type>::value)> {};
+
+// is_trivially_destructible()
+//
+// Determines whether the passed type `T` is trivially destructible.
+//
+// This metafunction is designed to be a drop-in replacement for the C++11
+// `std::is_trivially_destructible()` metafunction for platforms that have
+// incomplete C++11 support (such as libstdc++ 4.x). On any platforms that do
+// fully support C++11, we check whether this yields the same result as the std
+// implementation.
+//
+// NOTE: the extensions (__has_trivial_xxx) are implemented in gcc (version >=
+// 4.3) and clang. Since we are supporting libstdc++ > 4.7, they should always
+// be present. These  extensions are documented at
+// https://gcc.gnu.org/onlinedocs/gcc/Type-Traits.html#Type-Traits.
+template <typename T>
+struct is_trivially_destructible
+    : std::integral_constant<bool, __has_trivial_destructor(T) &&
+                                   std::is_destructible<T>::value> {
+#ifdef ABSL_HAVE_STD_IS_TRIVIALLY_DESTRUCTIBLE
+ private:
+  static constexpr bool compliant = std::is_trivially_destructible<T>::value ==
+                                    is_trivially_destructible::value;
+  static_assert(compliant || std::is_trivially_destructible<T>::value,
+                "Not compliant with std::is_trivially_destructible; "
+                "Standard: false, Implementation: true");
+  static_assert(compliant || !std::is_trivially_destructible<T>::value,
+                "Not compliant with std::is_trivially_destructible; "
+                "Standard: true, Implementation: false");
+#endif  // ABSL_HAVE_STD_IS_TRIVIALLY_DESTRUCTIBLE
+};
+
+// is_trivially_default_constructible()
+//
+// Determines whether the passed type `T` is trivially default constructible.
+//
+// This metafunction is designed to be a drop-in replacement for the C++11
+// `std::is_trivially_default_constructible()` metafunction for platforms that
+// have incomplete C++11 support (such as libstdc++ 4.x). On any platforms that
+// do fully support C++11, we check whether this yields the same result as the
+// std implementation.
+//
+// NOTE: according to the C++ standard, Section: 20.15.4.3 [meta.unary.prop]
+// "The predicate condition for a template specialization is_constructible<T,
+// Args...> shall be satisfied if and only if the following variable
+// definition would be well-formed for some invented variable t:
+//
+// T t(declval<Args>()...);
+//
+// is_trivially_constructible<T, Args...> additionally requires that the
+// variable definition does not call any operation that is not trivial.
+// For the purposes of this check, the call to std::declval is considered
+// trivial."
+//
+// Notes from https://en.cppreference.com/w/cpp/types/is_constructible:
+// In many implementations, is_nothrow_constructible also checks if the
+// destructor throws because it is effectively noexcept(T(arg)). Same
+// applies to is_trivially_constructible, which, in these implementations, also
+// requires that the destructor is trivial.
+// GCC bug 51452: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=51452
+// LWG issue 2116: http://cplusplus.github.io/LWG/lwg-active.html#2116.
+//
+// "T obj();" need to be well-formed and not call any nontrivial operation.
+// Nontrivially destructible types will cause the expression to be nontrivial.
+template <typename T>
+struct is_trivially_default_constructible
+    : std::integral_constant<bool, __has_trivial_constructor(T) &&
+                                   std::is_default_constructible<T>::value &&
+                                   is_trivially_destructible<T>::value> {
+#if defined(ABSL_HAVE_STD_IS_TRIVIALLY_CONSTRUCTIBLE) && \
+    !defined(                                            \
+        ABSL_META_INTERNAL_STD_CONSTRUCTION_TRAITS_DONT_CHECK_DESTRUCTION)
+ private:
+  static constexpr bool compliant =
+      std::is_trivially_default_constructible<T>::value ==
+      is_trivially_default_constructible::value;
+  static_assert(compliant || std::is_trivially_default_constructible<T>::value,
+                "Not compliant with std::is_trivially_default_constructible; "
+                "Standard: false, Implementation: true");
+  static_assert(compliant || !std::is_trivially_default_constructible<T>::value,
+                "Not compliant with std::is_trivially_default_constructible; "
+                "Standard: true, Implementation: false");
+#endif  // ABSL_HAVE_STD_IS_TRIVIALLY_CONSTRUCTIBLE
+};
+
+// is_trivially_move_constructible()
+//
+// Determines whether the passed type `T` is trivially move constructible.
+//
+// This metafunction is designed to be a drop-in replacement for the C++11
+// `std::is_trivially_move_constructible()` metafunction for platforms that have
+// incomplete C++11 support (such as libstdc++ 4.x). On any platforms that do
+// fully support C++11, we check whether this yields the same result as the std
+// implementation.
+//
+// NOTE: `T obj(declval<T>());` needs to be well-formed and not call any
+// nontrivial operation.  Nontrivially destructible types will cause the
+// expression to be nontrivial.
+template <typename T>
+struct is_trivially_move_constructible
+    : std::conditional<
+          std::is_object<T>::value && !std::is_array<T>::value,
+          type_traits_internal::IsTriviallyMoveConstructibleObject<T>,
+          std::is_reference<T>>::type::type {
+#if defined(ABSL_HAVE_STD_IS_TRIVIALLY_CONSTRUCTIBLE) && \
+    !defined(                                            \
+        ABSL_META_INTERNAL_STD_CONSTRUCTION_TRAITS_DONT_CHECK_DESTRUCTION)
+ private:
+  static constexpr bool compliant =
+      std::is_trivially_move_constructible<T>::value ==
+      is_trivially_move_constructible::value;
+  static_assert(compliant || std::is_trivially_move_constructible<T>::value,
+                "Not compliant with std::is_trivially_move_constructible; "
+                "Standard: false, Implementation: true");
+  static_assert(compliant || !std::is_trivially_move_constructible<T>::value,
+                "Not compliant with std::is_trivially_move_constructible; "
+                "Standard: true, Implementation: false");
+#endif  // ABSL_HAVE_STD_IS_TRIVIALLY_CONSTRUCTIBLE
+};
+
+// is_trivially_copy_constructible()
+//
+// Determines whether the passed type `T` is trivially copy constructible.
+//
+// This metafunction is designed to be a drop-in replacement for the C++11
+// `std::is_trivially_copy_constructible()` metafunction for platforms that have
+// incomplete C++11 support (such as libstdc++ 4.x). On any platforms that do
+// fully support C++11, we check whether this yields the same result as the std
+// implementation.
+//
+// NOTE: `T obj(declval<const T&>());` needs to be well-formed and not call any
+// nontrivial operation.  Nontrivially destructible types will cause the
+// expression to be nontrivial.
+template <typename T>
+struct is_trivially_copy_constructible
+    : std::conditional<
+          std::is_object<T>::value && !std::is_array<T>::value,
+          type_traits_internal::IsTriviallyCopyConstructibleObject<T>,
+          std::is_lvalue_reference<T>>::type::type {
+#if defined(ABSL_HAVE_STD_IS_TRIVIALLY_CONSTRUCTIBLE) && \
+    !defined(                                            \
+        ABSL_META_INTERNAL_STD_CONSTRUCTION_TRAITS_DONT_CHECK_DESTRUCTION)
+ private:
+  static constexpr bool compliant =
+      std::is_trivially_copy_constructible<T>::value ==
+      is_trivially_copy_constructible::value;
+  static_assert(compliant || std::is_trivially_copy_constructible<T>::value,
+                "Not compliant with std::is_trivially_copy_constructible; "
+                "Standard: false, Implementation: true");
+  static_assert(compliant || !std::is_trivially_copy_constructible<T>::value,
+                "Not compliant with std::is_trivially_copy_constructible; "
+                "Standard: true, Implementation: false");
+#endif  // ABSL_HAVE_STD_IS_TRIVIALLY_CONSTRUCTIBLE
+};
+
+// is_trivially_move_assignable()
+//
+// Determines whether the passed type `T` is trivially move assignable.
+//
+// This metafunction is designed to be a drop-in replacement for the C++11
+// `std::is_trivially_move_assignable()` metafunction for platforms that have
+// incomplete C++11 support (such as libstdc++ 4.x). On any platforms that do
+// fully support C++11, we check whether this yields the same result as the std
+// implementation.
+//
+// NOTE: `is_assignable<T, U>::value` is `true` if the expression
+// `declval<T>() = declval<U>()` is well-formed when treated as an unevaluated
+// operand. `is_trivially_assignable<T, U>` requires the assignment to call no
+// operation that is not trivial. `is_trivially_copy_assignable<T>` is simply
+// `is_trivially_assignable<T&, T>`.
+template <typename T>
+struct is_trivially_move_assignable
+    : std::conditional<
+          std::is_object<T>::value && !std::is_array<T>::value &&
+              std::is_move_assignable<T>::value,
+          std::is_move_assignable<type_traits_internal::SingleMemberUnion<T>>,
+          type_traits_internal::IsTriviallyMoveAssignableReference<T>>::type::
+          type {
+#ifdef ABSL_HAVE_STD_IS_TRIVIALLY_ASSIGNABLE
+ private:
+  static constexpr bool compliant =
+      std::is_trivially_move_assignable<T>::value ==
+      is_trivially_move_assignable::value;
+  static_assert(compliant || std::is_trivially_move_assignable<T>::value,
+                "Not compliant with std::is_trivially_move_assignable; "
+                "Standard: false, Implementation: true");
+  static_assert(compliant || !std::is_trivially_move_assignable<T>::value,
+                "Not compliant with std::is_trivially_move_assignable; "
+                "Standard: true, Implementation: false");
+#endif  // ABSL_HAVE_STD_IS_TRIVIALLY_ASSIGNABLE
+};
+
+// is_trivially_copy_assignable()
+//
+// Determines whether the passed type `T` is trivially copy assignable.
+//
+// This metafunction is designed to be a drop-in replacement for the C++11
+// `std::is_trivially_copy_assignable()` metafunction for platforms that have
+// incomplete C++11 support (such as libstdc++ 4.x). On any platforms that do
+// fully support C++11, we check whether this yields the same result as the std
+// implementation.
+//
+// NOTE: `is_assignable<T, U>::value` is `true` if the expression
+// `declval<T>() = declval<U>()` is well-formed when treated as an unevaluated
+// operand. `is_trivially_assignable<T, U>` requires the assignment to call no
+// operation that is not trivial. `is_trivially_copy_assignable<T>` is simply
+// `is_trivially_assignable<T&, const T&>`.
+template <typename T>
+struct is_trivially_copy_assignable
+    : std::integral_constant<
+          bool, __has_trivial_assign(typename std::remove_reference<T>::type) &&
+                    absl::is_copy_assignable<T>::value> {
+#ifdef ABSL_HAVE_STD_IS_TRIVIALLY_ASSIGNABLE
+ private:
+  static constexpr bool compliant =
+      std::is_trivially_copy_assignable<T>::value ==
+      is_trivially_copy_assignable::value;
+  static_assert(compliant || std::is_trivially_copy_assignable<T>::value,
+                "Not compliant with std::is_trivially_copy_assignable; "
+                "Standard: false, Implementation: true");
+  static_assert(compliant || !std::is_trivially_copy_assignable<T>::value,
+                "Not compliant with std::is_trivially_copy_assignable; "
+                "Standard: true, Implementation: false");
+#endif  // ABSL_HAVE_STD_IS_TRIVIALLY_ASSIGNABLE
+};
+
+#if defined(__cpp_lib_remove_cvref) && __cpp_lib_remove_cvref >= 201711L
+template <typename T>
+using remove_cvref = std::remove_cvref<T>;
+
+template <typename T>
+using remove_cvref_t = typename std::remove_cvref<T>::type;
+#else
+// remove_cvref()
+//
+// C++11 compatible implementation of std::remove_cvref which was added in
+// C++20.
+template <typename T>
+struct remove_cvref {
+  using type =
+      typename std::remove_cv<typename std::remove_reference<T>::type>::type;
+};
+
+template <typename T>
+using remove_cvref_t = typename remove_cvref<T>::type;
+#endif
+
+namespace type_traits_internal {
+// is_trivially_copyable()
+//
+// Determines whether the passed type `T` is trivially copyable.
+//
+// This metafunction is designed to be a drop-in replacement for the C++11
+// `std::is_trivially_copyable()` metafunction for platforms that have
+// incomplete C++11 support (such as libstdc++ 4.x). We use the C++17 definition
+// of TriviallyCopyable.
+//
+// NOTE: `is_trivially_copyable<T>::value` is `true` if all of T's copy/move
+// constructors/assignment operators are trivial or deleted, T has at least
+// one non-deleted copy/move constructor/assignment operator, and T is trivially
+// destructible. Arrays of trivially copyable types are trivially copyable.
+//
+// We expose this metafunction only for internal use within absl.
+template <typename T>
+class is_trivially_copyable_impl {
+  using ExtentsRemoved = typename std::remove_all_extents<T>::type;
+  static constexpr bool kIsCopyOrMoveConstructible =
+      std::is_copy_constructible<ExtentsRemoved>::value ||
+      std::is_move_constructible<ExtentsRemoved>::value;
+  static constexpr bool kIsCopyOrMoveAssignable =
+      absl::is_copy_assignable<ExtentsRemoved>::value ||
+      absl::is_move_assignable<ExtentsRemoved>::value;
+
+ public:
+  static constexpr bool kValue =
+      (__has_trivial_copy(ExtentsRemoved) || !kIsCopyOrMoveConstructible) &&
+      (__has_trivial_assign(ExtentsRemoved) || !kIsCopyOrMoveAssignable) &&
+      (kIsCopyOrMoveConstructible || kIsCopyOrMoveAssignable) &&
+      is_trivially_destructible<ExtentsRemoved>::value &&
+      // We need to check for this explicitly because otherwise we'll say
+      // references are trivial copyable when compiled by MSVC.
+      !std::is_reference<ExtentsRemoved>::value;
+};
+
+template <typename T>
+struct is_trivially_copyable
+    : std::integral_constant<
+          bool, type_traits_internal::is_trivially_copyable_impl<T>::kValue> {};
+}  // namespace type_traits_internal
+
+// -----------------------------------------------------------------------------
+// C++14 "_t" trait aliases
+// -----------------------------------------------------------------------------
+
+template <typename T>
+using remove_cv_t = typename std::remove_cv<T>::type;
+
+template <typename T>
+using remove_const_t = typename std::remove_const<T>::type;
+
+template <typename T>
+using remove_volatile_t = typename std::remove_volatile<T>::type;
+
+template <typename T>
+using add_cv_t = typename std::add_cv<T>::type;
+
+template <typename T>
+using add_const_t = typename std::add_const<T>::type;
+
+template <typename T>
+using add_volatile_t = typename std::add_volatile<T>::type;
+
+template <typename T>
+using remove_reference_t = typename std::remove_reference<T>::type;
+
+template <typename T>
+using add_lvalue_reference_t = typename std::add_lvalue_reference<T>::type;
+
+template <typename T>
+using add_rvalue_reference_t = typename std::add_rvalue_reference<T>::type;
+
+template <typename T>
+using remove_pointer_t = typename std::remove_pointer<T>::type;
+
+template <typename T>
+using add_pointer_t = typename std::add_pointer<T>::type;
+
+template <typename T>
+using make_signed_t = typename std::make_signed<T>::type;
+
+template <typename T>
+using make_unsigned_t = typename std::make_unsigned<T>::type;
+
+template <typename T>
+using remove_extent_t = typename std::remove_extent<T>::type;
+
+template <typename T>
+using remove_all_extents_t = typename std::remove_all_extents<T>::type;
+
+template <size_t Len, size_t Align = type_traits_internal::
+                          default_alignment_of_aligned_storage<Len>::value>
+using aligned_storage_t = typename std::aligned_storage<Len, Align>::type;
+
+template <typename T>
+using decay_t = typename std::decay<T>::type;
+
+template <bool B, typename T = void>
+using enable_if_t = typename std::enable_if<B, T>::type;
+
+template <bool B, typename T, typename F>
+using conditional_t = typename std::conditional<B, T, F>::type;
+
+template <typename... T>
+using common_type_t = typename std::common_type<T...>::type;
+
+template <typename T>
+using underlying_type_t = typename std::underlying_type<T>::type;
+
+
+namespace type_traits_internal {
+
+#if __cplusplus >= 201703L
+// std::result_of is deprecated (C++17) or removed (C++20)
+template<typename> struct result_of;
+template<typename F, typename... Args>
+struct result_of<F(Args...)> : std::invoke_result<F, Args...> {};
+#else
+template<typename F> using result_of = std::result_of<F>;
+#endif
+
+}  // namespace type_traits_internal
+
+template<typename F>
+using result_of_t = typename type_traits_internal::result_of<F>::type;
+
+namespace type_traits_internal {
+// In MSVC we can't probe std::hash or stdext::hash because it triggers a
+// static_assert instead of failing substitution. Libc++ prior to 4.0
+// also used a static_assert.
+//
+#if defined(_MSC_VER) || (defined(_LIBCPP_VERSION) && \
+                          _LIBCPP_VERSION < 4000 && _LIBCPP_STD_VER > 11)
+#define ABSL_META_INTERNAL_STD_HASH_SFINAE_FRIENDLY_ 0
+#else
+#define ABSL_META_INTERNAL_STD_HASH_SFINAE_FRIENDLY_ 1
+#endif
+
+#if !ABSL_META_INTERNAL_STD_HASH_SFINAE_FRIENDLY_
+template <typename Key, typename = size_t>
+struct IsHashable : std::true_type {};
+#else   // ABSL_META_INTERNAL_STD_HASH_SFINAE_FRIENDLY_
+template <typename Key, typename = void>
+struct IsHashable : std::false_type {};
+
+template <typename Key>
+struct IsHashable<
+    Key,
+    absl::enable_if_t<std::is_convertible<
+        decltype(std::declval<std::hash<Key>&>()(std::declval<Key const&>())),
+        std::size_t>::value>> : std::true_type {};
+#endif  // !ABSL_META_INTERNAL_STD_HASH_SFINAE_FRIENDLY_
+
+struct AssertHashEnabledHelper {
+ private:
+  static void Sink(...) {}
+  struct NAT {};
+
+  template <class Key>
+  static auto GetReturnType(int)
+      -> decltype(std::declval<std::hash<Key>>()(std::declval<Key const&>()));
+  template <class Key>
+  static NAT GetReturnType(...);
+
+  template <class Key>
+  static std::nullptr_t DoIt() {
+    static_assert(IsHashable<Key>::value,
+                  "std::hash<Key> does not provide a call operator");
+    static_assert(
+        std::is_default_constructible<std::hash<Key>>::value,
+        "std::hash<Key> must be default constructible when it is enabled");
+    static_assert(
+        std::is_copy_constructible<std::hash<Key>>::value,
+        "std::hash<Key> must be copy constructible when it is enabled");
+    static_assert(absl::is_copy_assignable<std::hash<Key>>::value,
+                  "std::hash<Key> must be copy assignable when it is enabled");
+    // is_destructible is unchecked as it's implied by each of the
+    // is_constructible checks.
+    using ReturnType = decltype(GetReturnType<Key>(0));
+    static_assert(std::is_same<ReturnType, NAT>::value ||
+                      std::is_same<ReturnType, size_t>::value,
+                  "std::hash<Key> must return size_t");
+    return nullptr;
+  }
+
+  template <class... Ts>
+  friend void AssertHashEnabled();
+};
+
+template <class... Ts>
+inline void AssertHashEnabled() {
+  using Helper = AssertHashEnabledHelper;
+  Helper::Sink(Helper::DoIt<Ts>()...);
+}
+
+}  // namespace type_traits_internal
+
+// An internal namespace that is required to implement the C++17 swap traits.
+// It is not further nested in type_traits_internal to avoid long symbol names.
+namespace swap_internal {
+
+// Necessary for the traits.
+using std::swap;
+
+// This declaration prevents global `swap` and `absl::swap` overloads from being
+// considered unless ADL picks them up.
+void swap();
+
+template <class T>
+using IsSwappableImpl = decltype(swap(std::declval<T&>(), std::declval<T&>()));
+
+// NOTE: This dance with the default template parameter is for MSVC.
+template <class T,
+          class IsNoexcept = std::integral_constant<
+              bool, noexcept(swap(std::declval<T&>(), std::declval<T&>()))>>
+using IsNothrowSwappableImpl = typename std::enable_if<IsNoexcept::value>::type;
+
+// IsSwappable
+//
+// Determines whether the standard swap idiom is a valid expression for
+// arguments of type `T`.
+template <class T>
+struct IsSwappable
+    : absl::type_traits_internal::is_detected<IsSwappableImpl, T> {};
+
+// IsNothrowSwappable
+//
+// Determines whether the standard swap idiom is a valid expression for
+// arguments of type `T` and is noexcept.
+template <class T>
+struct IsNothrowSwappable
+    : absl::type_traits_internal::is_detected<IsNothrowSwappableImpl, T> {};
+
+// Swap()
+//
+// Performs the swap idiom from a namespace where valid candidates may only be
+// found in `std` or via ADL.
+template <class T, absl::enable_if_t<IsSwappable<T>::value, int> = 0>
+void Swap(T& lhs, T& rhs) noexcept(IsNothrowSwappable<T>::value) {
+  swap(lhs, rhs);
+}
+
+// StdSwapIsUnconstrained
+//
+// Some standard library implementations are broken in that they do not
+// constrain `std::swap`. This will effectively tell us if we are dealing with
+// one of those implementations.
+using StdSwapIsUnconstrained = IsSwappable<void()>;
+
+}  // namespace swap_internal
+
+namespace type_traits_internal {
+
+// Make the swap-related traits/function accessible from this namespace.
+using swap_internal::IsNothrowSwappable;
+using swap_internal::IsSwappable;
+using swap_internal::Swap;
+using swap_internal::StdSwapIsUnconstrained;
+
+}  // namespace type_traits_internal
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#endif  // ABSL_META_TYPE_TRAITS_H_
diff --git a/third_party/webrtc_aec3/src/absl/strings/string_view.cc b/third_party/webrtc_aec3/src/absl/strings/string_view.cc
new file mode 100644
index 0000000..c5f5de9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/strings/string_view.cc
@@ -0,0 +1,235 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "absl/strings/string_view.h"
+
+#ifndef ABSL_USES_STD_STRING_VIEW
+
+#include <algorithm>
+#include <climits>
+#include <cstring>
+#include <ostream>
+
+#include "absl/strings/internal/memutil.h"
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+
+namespace {
+void WritePadding(std::ostream& o, size_t pad) {
+  char fill_buf[32];
+  memset(fill_buf, o.fill(), sizeof(fill_buf));
+  while (pad) {
+    size_t n = std::min(pad, sizeof(fill_buf));
+    o.write(fill_buf, n);
+    pad -= n;
+  }
+}
+
+class LookupTable {
+ public:
+  // For each character in wanted, sets the index corresponding
+  // to the ASCII code of that character. This is used by
+  // the find_.*_of methods below to tell whether or not a character is in
+  // the lookup table in constant time.
+  explicit LookupTable(string_view wanted) {
+    for (char c : wanted) {
+      table_[Index(c)] = true;
+    }
+  }
+  bool operator[](char c) const { return table_[Index(c)]; }
+
+ private:
+  static unsigned char Index(char c) { return static_cast<unsigned char>(c); }
+  bool table_[UCHAR_MAX + 1] = {};
+};
+
+}  // namespace
+
+std::ostream& operator<<(std::ostream& o, string_view piece) {
+  std::ostream::sentry sentry(o);
+  if (sentry) {
+    size_t lpad = 0;
+    size_t rpad = 0;
+    if (static_cast<size_t>(o.width()) > piece.size()) {
+      size_t pad = o.width() - piece.size();
+      if ((o.flags() & o.adjustfield) == o.left) {
+        rpad = pad;
+      } else {
+        lpad = pad;
+      }
+    }
+    if (lpad) WritePadding(o, lpad);
+    o.write(piece.data(), piece.size());
+    if (rpad) WritePadding(o, rpad);
+    o.width(0);
+  }
+  return o;
+}
+
+string_view::size_type string_view::find(string_view s, size_type pos) const
+    noexcept {
+  if (empty() || pos > length_) {
+    if (empty() && pos == 0 && s.empty()) return 0;
+    return npos;
+  }
+  const char* result =
+      strings_internal::memmatch(ptr_ + pos, length_ - pos, s.ptr_, s.length_);
+  return result ? result - ptr_ : npos;
+}
+
+string_view::size_type string_view::find(char c, size_type pos) const noexcept {
+  if (empty() || pos >= length_) {
+    return npos;
+  }
+  const char* result =
+      static_cast<const char*>(memchr(ptr_ + pos, c, length_ - pos));
+  return result != nullptr ? result - ptr_ : npos;
+}
+
+string_view::size_type string_view::rfind(string_view s, size_type pos) const
+    noexcept {
+  if (length_ < s.length_) return npos;
+  if (s.empty()) return std::min(length_, pos);
+  const char* last = ptr_ + std::min(length_ - s.length_, pos) + s.length_;
+  const char* result = std::find_end(ptr_, last, s.ptr_, s.ptr_ + s.length_);
+  return result != last ? result - ptr_ : npos;
+}
+
+// Search range is [0..pos] inclusive.  If pos == npos, search everything.
+string_view::size_type string_view::rfind(char c, size_type pos) const
+    noexcept {
+  // Note: memrchr() is not available on Windows.
+  if (empty()) return npos;
+  for (size_type i = std::min(pos, length_ - 1);; --i) {
+    if (ptr_[i] == c) {
+      return i;
+    }
+    if (i == 0) break;
+  }
+  return npos;
+}
+
+string_view::size_type string_view::find_first_of(string_view s,
+                                                  size_type pos) const
+    noexcept {
+  if (empty() || s.empty()) {
+    return npos;
+  }
+  // Avoid the cost of LookupTable() for a single-character search.
+  if (s.length_ == 1) return find_first_of(s.ptr_[0], pos);
+  LookupTable tbl(s);
+  for (size_type i = pos; i < length_; ++i) {
+    if (tbl[ptr_[i]]) {
+      return i;
+    }
+  }
+  return npos;
+}
+
+string_view::size_type string_view::find_first_not_of(string_view s,
+                                                      size_type pos) const
+    noexcept {
+  if (empty()) return npos;
+  // Avoid the cost of LookupTable() for a single-character search.
+  if (s.length_ == 1) return find_first_not_of(s.ptr_[0], pos);
+  LookupTable tbl(s);
+  for (size_type i = pos; i < length_; ++i) {
+    if (!tbl[ptr_[i]]) {
+      return i;
+    }
+  }
+  return npos;
+}
+
+string_view::size_type string_view::find_first_not_of(char c,
+                                                      size_type pos) const
+    noexcept {
+  if (empty()) return npos;
+  for (; pos < length_; ++pos) {
+    if (ptr_[pos] != c) {
+      return pos;
+    }
+  }
+  return npos;
+}
+
+string_view::size_type string_view::find_last_of(string_view s,
+                                                 size_type pos) const noexcept {
+  if (empty() || s.empty()) return npos;
+  // Avoid the cost of LookupTable() for a single-character search.
+  if (s.length_ == 1) return find_last_of(s.ptr_[0], pos);
+  LookupTable tbl(s);
+  for (size_type i = std::min(pos, length_ - 1);; --i) {
+    if (tbl[ptr_[i]]) {
+      return i;
+    }
+    if (i == 0) break;
+  }
+  return npos;
+}
+
+string_view::size_type string_view::find_last_not_of(string_view s,
+                                                     size_type pos) const
+    noexcept {
+  if (empty()) return npos;
+  size_type i = std::min(pos, length_ - 1);
+  if (s.empty()) return i;
+  // Avoid the cost of LookupTable() for a single-character search.
+  if (s.length_ == 1) return find_last_not_of(s.ptr_[0], pos);
+  LookupTable tbl(s);
+  for (;; --i) {
+    if (!tbl[ptr_[i]]) {
+      return i;
+    }
+    if (i == 0) break;
+  }
+  return npos;
+}
+
+string_view::size_type string_view::find_last_not_of(char c,
+                                                     size_type pos) const
+    noexcept {
+  if (empty()) return npos;
+  size_type i = std::min(pos, length_ - 1);
+  for (;; --i) {
+    if (ptr_[i] != c) {
+      return i;
+    }
+    if (i == 0) break;
+  }
+  return npos;
+}
+
+// MSVC has non-standard behavior that implicitly creates definitions for static
+// const members. These implicit definitions conflict with explicit out-of-class
+// member definitions that are required by the C++ standard, resulting in
+// LNK1169 "multiply defined" errors at link time. __declspec(selectany) asks
+// MSVC to choose only one definition for the symbol it decorates. See details
+// at https://msdn.microsoft.com/en-us/library/34h23df8(v=vs.100).aspx
+#ifdef _MSC_VER
+#define ABSL_STRING_VIEW_SELECTANY __declspec(selectany)
+#else
+#define ABSL_STRING_VIEW_SELECTANY
+#endif
+
+ABSL_STRING_VIEW_SELECTANY
+constexpr string_view::size_type string_view::npos;
+ABSL_STRING_VIEW_SELECTANY
+constexpr string_view::size_type string_view::kMaxSize;
+
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#endif  // ABSL_USES_STD_STRING_VIEW
diff --git a/third_party/webrtc_aec3/src/absl/strings/string_view.h b/third_party/webrtc_aec3/src/absl/strings/string_view.h
new file mode 100644
index 0000000..1f14a75
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/strings/string_view.h
@@ -0,0 +1,628 @@
+//
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+// -----------------------------------------------------------------------------
+// File: string_view.h
+// -----------------------------------------------------------------------------
+//
+// This file contains the definition of the `absl::string_view` class. A
+// `string_view` points to a contiguous span of characters, often part or all of
+// another `std::string`, double-quoted string literal, character array, or even
+// another `string_view`.
+//
+// This `absl::string_view` abstraction is designed to be a drop-in
+// replacement for the C++17 `std::string_view` abstraction.
+#ifndef ABSL_STRINGS_STRING_VIEW_H_
+#define ABSL_STRINGS_STRING_VIEW_H_
+
+#include <algorithm>
+#include <cassert>
+#include <cstddef>
+#include <cstring>
+#include <iosfwd>
+#include <iterator>
+#include <limits>
+#include <string>
+
+#include "absl/base/attributes.h"
+#include "absl/base/config.h"
+#include "absl/base/internal/throw_delegate.h"
+#include "absl/base/macros.h"
+#include "absl/base/optimization.h"
+#include "absl/base/port.h"
+
+#ifdef ABSL_USES_STD_STRING_VIEW
+
+#include <string_view>  // IWYU pragma: export
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+using string_view = std::string_view;
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#else  // ABSL_USES_STD_STRING_VIEW
+
+#if ABSL_HAVE_BUILTIN(__builtin_memcmp) || \
+    (defined(__GNUC__) && !defined(__clang__))
+#define ABSL_INTERNAL_STRING_VIEW_MEMCMP __builtin_memcmp
+#else  // ABSL_HAVE_BUILTIN(__builtin_memcmp)
+#define ABSL_INTERNAL_STRING_VIEW_MEMCMP memcmp
+#endif  // ABSL_HAVE_BUILTIN(__builtin_memcmp)
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+
+// absl::string_view
+//
+// A `string_view` provides a lightweight view into the string data provided by
+// a `std::string`, double-quoted string literal, character array, or even
+// another `string_view`. A `string_view` does *not* own the string to which it
+// points, and that data cannot be modified through the view.
+//
+// You can use `string_view` as a function or method parameter anywhere a
+// parameter can receive a double-quoted string literal, `const char*`,
+// `std::string`, or another `absl::string_view` argument with no need to copy
+// the string data. Systematic use of `string_view` within function arguments
+// reduces data copies and `strlen()` calls.
+//
+// Because of its small size, prefer passing `string_view` by value:
+//
+//   void MyFunction(absl::string_view arg);
+//
+// If circumstances require, you may also pass one by const reference:
+//
+//   void MyFunction(const absl::string_view& arg);  // not preferred
+//
+// Passing by value generates slightly smaller code for many architectures.
+//
+// In either case, the source data of the `string_view` must outlive the
+// `string_view` itself.
+//
+// A `string_view` is also suitable for local variables if you know that the
+// lifetime of the underlying object is longer than the lifetime of your
+// `string_view` variable. However, beware of binding a `string_view` to a
+// temporary value:
+//
+//   // BAD use of string_view: lifetime problem
+//   absl::string_view sv = obj.ReturnAString();
+//
+//   // GOOD use of string_view: str outlives sv
+//   std::string str = obj.ReturnAString();
+//   absl::string_view sv = str;
+//
+// Due to lifetime issues, a `string_view` is sometimes a poor choice for a
+// return value and usually a poor choice for a data member. If you do use a
+// `string_view` this way, it is your responsibility to ensure that the object
+// pointed to by the `string_view` outlives the `string_view`.
+//
+// A `string_view` may represent a whole string or just part of a string. For
+// example, when splitting a string, `std::vector<absl::string_view>` is a
+// natural data type for the output.
+//
+// For another example, a Cord is a non-contiguous, potentially very
+// long string-like object.  The Cord class has an interface that iteratively
+// provides string_view objects that point to the successive pieces of a Cord
+// object.
+//
+// When constructed from a source which is NUL-terminated, the `string_view`
+// itself will not include the NUL-terminator unless a specific size (including
+// the NUL) is passed to the constructor. As a result, common idioms that work
+// on NUL-terminated strings do not work on `string_view` objects. If you write
+// code that scans a `string_view`, you must check its length rather than test
+// for nul, for example. Note, however, that nuls may still be embedded within
+// a `string_view` explicitly.
+//
+// You may create a null `string_view` in two ways:
+//
+//   absl::string_view sv;
+//   absl::string_view sv(nullptr, 0);
+//
+// For the above, `sv.data() == nullptr`, `sv.length() == 0`, and
+// `sv.empty() == true`. Also, if you create a `string_view` with a non-null
+// pointer then `sv.data() != nullptr`. Thus, you can use `string_view()` to
+// signal an undefined value that is different from other `string_view` values
+// in a similar fashion to how `const char* p1 = nullptr;` is different from
+// `const char* p2 = "";`. However, in practice, it is not recommended to rely
+// on this behavior.
+//
+// Be careful not to confuse a null `string_view` with an empty one. A null
+// `string_view` is an empty `string_view`, but some empty `string_view`s are
+// not null. Prefer checking for emptiness over checking for null.
+//
+// There are many ways to create an empty string_view:
+//
+//   const char* nullcp = nullptr;
+//   // string_view.size() will return 0 in all cases.
+//   absl::string_view();
+//   absl::string_view(nullcp, 0);
+//   absl::string_view("");
+//   absl::string_view("", 0);
+//   absl::string_view("abcdef", 0);
+//   absl::string_view("abcdef" + 6, 0);
+//
+// All empty `string_view` objects whether null or not, are equal:
+//
+//   absl::string_view() == absl::string_view("", 0)
+//   absl::string_view(nullptr, 0) == absl::string_view("abcdef"+6, 0)
+class string_view {
+ public:
+  using traits_type = std::char_traits<char>;
+  using value_type = char;
+  using pointer = char*;
+  using const_pointer = const char*;
+  using reference = char&;
+  using const_reference = const char&;
+  using const_iterator = const char*;
+  using iterator = const_iterator;
+  using const_reverse_iterator = std::reverse_iterator<const_iterator>;
+  using reverse_iterator = const_reverse_iterator;
+  using size_type = size_t;
+  using difference_type = std::ptrdiff_t;
+
+  static constexpr size_type npos = static_cast<size_type>(-1);
+
+  // Null `string_view` constructor
+  constexpr string_view() noexcept : ptr_(nullptr), length_(0) {}
+
+  // Implicit constructors
+
+  template <typename Allocator>
+  string_view(  // NOLINT(runtime/explicit)
+      const std::basic_string<char, std::char_traits<char>, Allocator>& str
+          ABSL_ATTRIBUTE_LIFETIME_BOUND) noexcept
+      // This is implemented in terms of `string_view(p, n)` so `str.size()`
+      // doesn't need to be reevaluated after `ptr_` is set.
+      : string_view(str.data(), str.size()) {}
+
+  // Implicit constructor of a `string_view` from NUL-terminated `str`. When
+  // accepting possibly null strings, use `absl::NullSafeStringView(str)`
+  // instead (see below).
+  constexpr string_view(const char* str)  // NOLINT(runtime/explicit)
+      : ptr_(str),
+        length_(str ? CheckLengthInternal(StrlenInternal(str)) : 0) {}
+
+  // Implicit constructor of a `string_view` from a `const char*` and length.
+  constexpr string_view(const char* data, size_type len)
+      : ptr_(data), length_(CheckLengthInternal(len)) {}
+
+  // NOTE: Harmlessly omitted to work around gdb bug.
+  //   constexpr string_view(const string_view&) noexcept = default;
+  //   string_view& operator=(const string_view&) noexcept = default;
+
+  // Iterators
+
+  // string_view::begin()
+  //
+  // Returns an iterator pointing to the first character at the beginning of the
+  // `string_view`, or `end()` if the `string_view` is empty.
+  constexpr const_iterator begin() const noexcept { return ptr_; }
+
+  // string_view::end()
+  //
+  // Returns an iterator pointing just beyond the last character at the end of
+  // the `string_view`. This iterator acts as a placeholder; attempting to
+  // access it results in undefined behavior.
+  constexpr const_iterator end() const noexcept { return ptr_ + length_; }
+
+  // string_view::cbegin()
+  //
+  // Returns a const iterator pointing to the first character at the beginning
+  // of the `string_view`, or `end()` if the `string_view` is empty.
+  constexpr const_iterator cbegin() const noexcept { return begin(); }
+
+  // string_view::cend()
+  //
+  // Returns a const iterator pointing just beyond the last character at the end
+  // of the `string_view`. This pointer acts as a placeholder; attempting to
+  // access its element results in undefined behavior.
+  constexpr const_iterator cend() const noexcept { return end(); }
+
+  // string_view::rbegin()
+  //
+  // Returns a reverse iterator pointing to the last character at the end of the
+  // `string_view`, or `rend()` if the `string_view` is empty.
+  const_reverse_iterator rbegin() const noexcept {
+    return const_reverse_iterator(end());
+  }
+
+  // string_view::rend()
+  //
+  // Returns a reverse iterator pointing just before the first character at the
+  // beginning of the `string_view`. This pointer acts as a placeholder;
+  // attempting to access its element results in undefined behavior.
+  const_reverse_iterator rend() const noexcept {
+    return const_reverse_iterator(begin());
+  }
+
+  // string_view::crbegin()
+  //
+  // Returns a const reverse iterator pointing to the last character at the end
+  // of the `string_view`, or `crend()` if the `string_view` is empty.
+  const_reverse_iterator crbegin() const noexcept { return rbegin(); }
+
+  // string_view::crend()
+  //
+  // Returns a const reverse iterator pointing just before the first character
+  // at the beginning of the `string_view`. This pointer acts as a placeholder;
+  // attempting to access its element results in undefined behavior.
+  const_reverse_iterator crend() const noexcept { return rend(); }
+
+  // Capacity Utilities
+
+  // string_view::size()
+  //
+  // Returns the number of characters in the `string_view`.
+  constexpr size_type size() const noexcept {
+    return length_;
+  }
+
+  // string_view::length()
+  //
+  // Returns the number of characters in the `string_view`. Alias for `size()`.
+  constexpr size_type length() const noexcept { return size(); }
+
+  // string_view::max_size()
+  //
+  // Returns the maximum number of characters the `string_view` can hold.
+  constexpr size_type max_size() const noexcept { return kMaxSize; }
+
+  // string_view::empty()
+  //
+  // Checks if the `string_view` is empty (refers to no characters).
+  constexpr bool empty() const noexcept { return length_ == 0; }
+
+  // string_view::operator[]
+  //
+  // Returns the ith element of the `string_view` using the array operator.
+  // Note that this operator does not perform any bounds checking.
+  constexpr const_reference operator[](size_type i) const {
+    return ABSL_HARDENING_ASSERT(i < size()), ptr_[i];
+  }
+
+  // string_view::at()
+  //
+  // Returns the ith element of the `string_view`. Bounds checking is performed,
+  // and an exception of type `std::out_of_range` will be thrown on invalid
+  // access.
+  constexpr const_reference at(size_type i) const {
+    return ABSL_PREDICT_TRUE(i < size())
+               ? ptr_[i]
+               : ((void)base_internal::ThrowStdOutOfRange(
+                      "absl::string_view::at"),
+                  ptr_[i]);
+  }
+
+  // string_view::front()
+  //
+  // Returns the first element of a `string_view`.
+  constexpr const_reference front() const {
+    return ABSL_HARDENING_ASSERT(!empty()), ptr_[0];
+  }
+
+  // string_view::back()
+  //
+  // Returns the last element of a `string_view`.
+  constexpr const_reference back() const {
+    return ABSL_HARDENING_ASSERT(!empty()), ptr_[size() - 1];
+  }
+
+  // string_view::data()
+  //
+  // Returns a pointer to the underlying character array (which is of course
+  // stored elsewhere). Note that `string_view::data()` may contain embedded nul
+  // characters, but the returned buffer may or may not be NUL-terminated;
+  // therefore, do not pass `data()` to a routine that expects a NUL-terminated
+  // string.
+  constexpr const_pointer data() const noexcept { return ptr_; }
+
+  // Modifiers
+
+  // string_view::remove_prefix()
+  //
+  // Removes the first `n` characters from the `string_view`. Note that the
+  // underlying string is not changed, only the view.
+  void remove_prefix(size_type n) {
+    ABSL_HARDENING_ASSERT(n <= length_);
+    ptr_ += n;
+    length_ -= n;
+  }
+
+  // string_view::remove_suffix()
+  //
+  // Removes the last `n` characters from the `string_view`. Note that the
+  // underlying string is not changed, only the view.
+  void remove_suffix(size_type n) {
+    ABSL_HARDENING_ASSERT(n <= length_);
+    length_ -= n;
+  }
+
+  // string_view::swap()
+  //
+  // Swaps this `string_view` with another `string_view`.
+  void swap(string_view& s) noexcept {
+    auto t = *this;
+    *this = s;
+    s = t;
+  }
+
+  // Explicit conversion operators
+
+  // Converts to `std::basic_string`.
+  template <typename A>
+  explicit operator std::basic_string<char, traits_type, A>() const {
+    if (!data()) return {};
+    return std::basic_string<char, traits_type, A>(data(), size());
+  }
+
+  // string_view::copy()
+  //
+  // Copies the contents of the `string_view` at offset `pos` and length `n`
+  // into `buf`.
+  size_type copy(char* buf, size_type n, size_type pos = 0) const {
+    if (ABSL_PREDICT_FALSE(pos > length_)) {
+      base_internal::ThrowStdOutOfRange("absl::string_view::copy");
+    }
+    size_type rlen = (std::min)(length_ - pos, n);
+    if (rlen > 0) {
+      const char* start = ptr_ + pos;
+      traits_type::copy(buf, start, rlen);
+    }
+    return rlen;
+  }
+
+  // string_view::substr()
+  //
+  // Returns a "substring" of the `string_view` (at offset `pos` and length
+  // `n`) as another string_view. This function throws `std::out_of_bounds` if
+  // `pos > size`.
+  // Use absl::ClippedSubstr if you need a truncating substr operation.
+  constexpr string_view substr(size_type pos, size_type n = npos) const {
+    return ABSL_PREDICT_FALSE(pos > length_)
+               ? (base_internal::ThrowStdOutOfRange(
+                      "absl::string_view::substr"),
+                  string_view())
+               : string_view(ptr_ + pos, Min(n, length_ - pos));
+  }
+
+  // string_view::compare()
+  //
+  // Performs a lexicographical comparison between this `string_view` and
+  // another `string_view` `x`, returning a negative value if `*this` is less
+  // than `x`, 0 if `*this` is equal to `x`, and a positive value if `*this`
+  // is greater than `x`.
+  constexpr int compare(string_view x) const noexcept {
+    return CompareImpl(length_, x.length_,
+                       Min(length_, x.length_) == 0
+                           ? 0
+                           : ABSL_INTERNAL_STRING_VIEW_MEMCMP(
+                                 ptr_, x.ptr_, Min(length_, x.length_)));
+  }
+
+  // Overload of `string_view::compare()` for comparing a substring of the
+  // 'string_view` and another `absl::string_view`.
+  int compare(size_type pos1, size_type count1, string_view v) const {
+    return substr(pos1, count1).compare(v);
+  }
+
+  // Overload of `string_view::compare()` for comparing a substring of the
+  // `string_view` and a substring of another `absl::string_view`.
+  int compare(size_type pos1, size_type count1, string_view v, size_type pos2,
+              size_type count2) const {
+    return substr(pos1, count1).compare(v.substr(pos2, count2));
+  }
+
+  // Overload of `string_view::compare()` for comparing a `string_view` and a
+  // a different  C-style string `s`.
+  int compare(const char* s) const { return compare(string_view(s)); }
+
+  // Overload of `string_view::compare()` for comparing a substring of the
+  // `string_view` and a different string C-style string `s`.
+  int compare(size_type pos1, size_type count1, const char* s) const {
+    return substr(pos1, count1).compare(string_view(s));
+  }
+
+  // Overload of `string_view::compare()` for comparing a substring of the
+  // `string_view` and a substring of a different C-style string `s`.
+  int compare(size_type pos1, size_type count1, const char* s,
+              size_type count2) const {
+    return substr(pos1, count1).compare(string_view(s, count2));
+  }
+
+  // Find Utilities
+
+  // string_view::find()
+  //
+  // Finds the first occurrence of the substring `s` within the `string_view`,
+  // returning the position of the first character's match, or `npos` if no
+  // match was found.
+  size_type find(string_view s, size_type pos = 0) const noexcept;
+
+  // Overload of `string_view::find()` for finding the given character `c`
+  // within the `string_view`.
+  size_type find(char c, size_type pos = 0) const noexcept;
+
+  // string_view::rfind()
+  //
+  // Finds the last occurrence of a substring `s` within the `string_view`,
+  // returning the position of the first character's match, or `npos` if no
+  // match was found.
+  size_type rfind(string_view s, size_type pos = npos) const
+      noexcept;
+
+  // Overload of `string_view::rfind()` for finding the last given character `c`
+  // within the `string_view`.
+  size_type rfind(char c, size_type pos = npos) const noexcept;
+
+  // string_view::find_first_of()
+  //
+  // Finds the first occurrence of any of the characters in `s` within the
+  // `string_view`, returning the start position of the match, or `npos` if no
+  // match was found.
+  size_type find_first_of(string_view s, size_type pos = 0) const
+      noexcept;
+
+  // Overload of `string_view::find_first_of()` for finding a character `c`
+  // within the `string_view`.
+  size_type find_first_of(char c, size_type pos = 0) const
+      noexcept {
+    return find(c, pos);
+  }
+
+  // string_view::find_last_of()
+  //
+  // Finds the last occurrence of any of the characters in `s` within the
+  // `string_view`, returning the start position of the match, or `npos` if no
+  // match was found.
+  size_type find_last_of(string_view s, size_type pos = npos) const
+      noexcept;
+
+  // Overload of `string_view::find_last_of()` for finding a character `c`
+  // within the `string_view`.
+  size_type find_last_of(char c, size_type pos = npos) const
+      noexcept {
+    return rfind(c, pos);
+  }
+
+  // string_view::find_first_not_of()
+  //
+  // Finds the first occurrence of any of the characters not in `s` within the
+  // `string_view`, returning the start position of the first non-match, or
+  // `npos` if no non-match was found.
+  size_type find_first_not_of(string_view s, size_type pos = 0) const noexcept;
+
+  // Overload of `string_view::find_first_not_of()` for finding a character
+  // that is not `c` within the `string_view`.
+  size_type find_first_not_of(char c, size_type pos = 0) const noexcept;
+
+  // string_view::find_last_not_of()
+  //
+  // Finds the last occurrence of any of the characters not in `s` within the
+  // `string_view`, returning the start position of the last non-match, or
+  // `npos` if no non-match was found.
+  size_type find_last_not_of(string_view s,
+                                          size_type pos = npos) const noexcept;
+
+  // Overload of `string_view::find_last_not_of()` for finding a character
+  // that is not `c` within the `string_view`.
+  size_type find_last_not_of(char c, size_type pos = npos) const
+      noexcept;
+
+ private:
+  static constexpr size_type kMaxSize =
+      (std::numeric_limits<difference_type>::max)();
+
+  static constexpr size_type CheckLengthInternal(size_type len) {
+    return ABSL_HARDENING_ASSERT(len <= kMaxSize), len;
+  }
+
+  static constexpr size_type StrlenInternal(const char* str) {
+#if defined(_MSC_VER) && _MSC_VER >= 1910 && !defined(__clang__)
+    // MSVC 2017+ can evaluate this at compile-time.
+    const char* begin = str;
+    while (*str != '\0') ++str;
+    return str - begin;
+#elif ABSL_HAVE_BUILTIN(__builtin_strlen) || \
+    (defined(__GNUC__) && !defined(__clang__))
+    // GCC has __builtin_strlen according to
+    // https://gcc.gnu.org/onlinedocs/gcc-4.7.0/gcc/Other-Builtins.html, but
+    // ABSL_HAVE_BUILTIN doesn't detect that, so we use the extra checks above.
+    // __builtin_strlen is constexpr.
+    return __builtin_strlen(str);
+#else
+    return str ? strlen(str) : 0;
+#endif
+  }
+
+  static constexpr size_t Min(size_type length_a, size_type length_b) {
+    return length_a < length_b ? length_a : length_b;
+  }
+
+  static constexpr int CompareImpl(size_type length_a, size_type length_b,
+                                   int compare_result) {
+    return compare_result == 0 ? static_cast<int>(length_a > length_b) -
+                                     static_cast<int>(length_a < length_b)
+                               : (compare_result < 0 ? -1 : 1);
+  }
+
+  const char* ptr_;
+  size_type length_;
+};
+
+// This large function is defined inline so that in a fairly common case where
+// one of the arguments is a literal, the compiler can elide a lot of the
+// following comparisons.
+constexpr bool operator==(string_view x, string_view y) noexcept {
+  return x.size() == y.size() &&
+         (x.empty() ||
+          ABSL_INTERNAL_STRING_VIEW_MEMCMP(x.data(), y.data(), x.size()) == 0);
+}
+
+constexpr bool operator!=(string_view x, string_view y) noexcept {
+  return !(x == y);
+}
+
+constexpr bool operator<(string_view x, string_view y) noexcept {
+  return x.compare(y) < 0;
+}
+
+constexpr bool operator>(string_view x, string_view y) noexcept {
+  return y < x;
+}
+
+constexpr bool operator<=(string_view x, string_view y) noexcept {
+  return !(y < x);
+}
+
+constexpr bool operator>=(string_view x, string_view y) noexcept {
+  return !(x < y);
+}
+
+// IO Insertion Operator
+std::ostream& operator<<(std::ostream& o, string_view piece);
+
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#undef ABSL_INTERNAL_STRING_VIEW_MEMCMP
+
+#endif  // ABSL_USES_STD_STRING_VIEW
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+
+// ClippedSubstr()
+//
+// Like `s.substr(pos, n)`, but clips `pos` to an upper bound of `s.size()`.
+// Provided because std::string_view::substr throws if `pos > size()`
+inline string_view ClippedSubstr(string_view s, size_t pos,
+                                 size_t n = string_view::npos) {
+  pos = (std::min)(pos, static_cast<size_t>(s.size()));
+  return s.substr(pos, n);
+}
+
+// NullSafeStringView()
+//
+// Creates an `absl::string_view` from a pointer `p` even if it's null-valued.
+// This function should be used where an `absl::string_view` can be created from
+// a possibly-null pointer.
+constexpr string_view NullSafeStringView(const char* p) {
+  return p ? string_view(p) : string_view();
+}
+
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#endif  // ABSL_STRINGS_STRING_VIEW_H_
diff --git a/third_party/webrtc_aec3/src/absl/types/bad_optional_access.cc b/third_party/webrtc_aec3/src/absl/types/bad_optional_access.cc
new file mode 100644
index 0000000..26aca70
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/types/bad_optional_access.cc
@@ -0,0 +1,48 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "absl/types/bad_optional_access.h"
+
+#ifndef ABSL_USES_STD_OPTIONAL
+
+#include <cstdlib>
+
+#include "absl/base/config.h"
+#include "absl/base/internal/raw_logging.h"
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+
+bad_optional_access::~bad_optional_access() = default;
+
+const char* bad_optional_access::what() const noexcept {
+  return "optional has no value";
+}
+
+namespace optional_internal {
+
+void throw_bad_optional_access() {
+#ifdef ABSL_HAVE_EXCEPTIONS
+  throw bad_optional_access();
+#else
+  ABSL_RAW_LOG(FATAL, "Bad optional access");
+  abort();
+#endif
+}
+
+}  // namespace optional_internal
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#endif  // ABSL_USES_STD_OPTIONAL
diff --git a/third_party/webrtc_aec3/src/absl/types/bad_optional_access.h b/third_party/webrtc_aec3/src/absl/types/bad_optional_access.h
new file mode 100644
index 0000000..a500286
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/types/bad_optional_access.h
@@ -0,0 +1,78 @@
+// Copyright 2018 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+// -----------------------------------------------------------------------------
+// bad_optional_access.h
+// -----------------------------------------------------------------------------
+//
+// This header file defines the `absl::bad_optional_access` type.
+
+#ifndef ABSL_TYPES_BAD_OPTIONAL_ACCESS_H_
+#define ABSL_TYPES_BAD_OPTIONAL_ACCESS_H_
+
+#include <stdexcept>
+
+#include "absl/base/config.h"
+
+#ifdef ABSL_USES_STD_OPTIONAL
+
+#include <optional>
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+using std::bad_optional_access;
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#else  // ABSL_USES_STD_OPTIONAL
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+
+// -----------------------------------------------------------------------------
+// bad_optional_access
+// -----------------------------------------------------------------------------
+//
+// An `absl::bad_optional_access` type is an exception type that is thrown when
+// attempting to access an `absl::optional` object that does not contain a
+// value.
+//
+// Example:
+//
+//   absl::optional<int> o;
+//
+//   try {
+//     int n = o.value();
+//   } catch(const absl::bad_optional_access& e) {
+//     std::cout << "Bad optional access: " << e.what() << '\n';
+//   }
+class bad_optional_access : public std::exception {
+ public:
+  bad_optional_access() = default;
+  ~bad_optional_access() override;
+  const char* what() const noexcept override;
+};
+
+namespace optional_internal {
+
+// throw delegator
+[[noreturn]] void throw_bad_optional_access();
+
+}  // namespace optional_internal
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#endif  // ABSL_USES_STD_OPTIONAL
+
+#endif  // ABSL_TYPES_BAD_OPTIONAL_ACCESS_H_
diff --git a/third_party/webrtc_aec3/src/absl/types/internal/optional.h b/third_party/webrtc_aec3/src/absl/types/internal/optional.h
new file mode 100644
index 0000000..92932b6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/types/internal/optional.h
@@ -0,0 +1,396 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+#ifndef ABSL_TYPES_INTERNAL_OPTIONAL_H_
+#define ABSL_TYPES_INTERNAL_OPTIONAL_H_
+
+#include <functional>
+#include <new>
+#include <type_traits>
+#include <utility>
+
+#include "absl/base/internal/inline_variable.h"
+#include "absl/memory/memory.h"
+#include "absl/meta/type_traits.h"
+#include "absl/utility/utility.h"
+
+// ABSL_OPTIONAL_USE_INHERITING_CONSTRUCTORS
+//
+// Inheriting constructors is supported in GCC 4.8+, Clang 3.3+ and MSVC 2015.
+// __cpp_inheriting_constructors is a predefined macro and a recommended way to
+// check for this language feature, but GCC doesn't support it until 5.0 and
+// Clang doesn't support it until 3.6.
+// Also, MSVC 2015 has a bug: it doesn't inherit the constexpr template
+// constructor. For example, the following code won't work on MSVC 2015 Update3:
+// struct Base {
+//   int t;
+//   template <typename T>
+//   constexpr Base(T t_) : t(t_) {}
+// };
+// struct Foo : Base {
+//   using Base::Base;
+// }
+// constexpr Foo foo(0);  // doesn't work on MSVC 2015
+#if defined(__clang__)
+#if __has_feature(cxx_inheriting_constructors)
+#define ABSL_OPTIONAL_USE_INHERITING_CONSTRUCTORS 1
+#endif
+#elif (defined(__GNUC__) &&                                       \
+       (__GNUC__ > 4 || __GNUC__ == 4 && __GNUC_MINOR__ >= 8)) || \
+    (__cpp_inheriting_constructors >= 200802) ||                  \
+    (defined(_MSC_VER) && _MSC_VER >= 1910)
+#define ABSL_OPTIONAL_USE_INHERITING_CONSTRUCTORS 1
+#endif
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+
+// Forward declaration
+template <typename T>
+class optional;
+
+namespace optional_internal {
+
+// This tag type is used as a constructor parameter type for `nullopt_t`.
+struct init_t {
+  explicit init_t() = default;
+};
+
+struct empty_struct {};
+
+// This class stores the data in optional<T>.
+// It is specialized based on whether T is trivially destructible.
+// This is the specialization for non trivially destructible type.
+template <typename T, bool unused = std::is_trivially_destructible<T>::value>
+class optional_data_dtor_base {
+  struct dummy_type {
+    static_assert(sizeof(T) % sizeof(empty_struct) == 0, "");
+    // Use an array to avoid GCC 6 placement-new warning.
+    empty_struct data[sizeof(T) / sizeof(empty_struct)];
+  };
+
+ protected:
+  // Whether there is data or not.
+  bool engaged_;
+  // Data storage
+  union {
+    T data_;
+    dummy_type dummy_;
+  };
+
+  void destruct() noexcept {
+    if (engaged_) {
+      data_.~T();
+      engaged_ = false;
+    }
+  }
+
+  // dummy_ must be initialized for constexpr constructor.
+  constexpr optional_data_dtor_base() noexcept : engaged_(false), dummy_{{}} {}
+
+  template <typename... Args>
+  constexpr explicit optional_data_dtor_base(in_place_t, Args&&... args)
+      : engaged_(true), data_(absl::forward<Args>(args)...) {}
+
+  ~optional_data_dtor_base() { destruct(); }
+};
+
+// Specialization for trivially destructible type.
+template <typename T>
+class optional_data_dtor_base<T, true> {
+  struct dummy_type {
+    static_assert(sizeof(T) % sizeof(empty_struct) == 0, "");
+    // Use array to avoid GCC 6 placement-new warning.
+    empty_struct data[sizeof(T) / sizeof(empty_struct)];
+  };
+
+ protected:
+  // Whether there is data or not.
+  bool engaged_;
+  // Data storage
+  union {
+    T data_;
+    dummy_type dummy_;
+  };
+  void destruct() noexcept { engaged_ = false; }
+
+  // dummy_ must be initialized for constexpr constructor.
+  constexpr optional_data_dtor_base() noexcept : engaged_(false), dummy_{{}} {}
+
+  template <typename... Args>
+  constexpr explicit optional_data_dtor_base(in_place_t, Args&&... args)
+      : engaged_(true), data_(absl::forward<Args>(args)...) {}
+};
+
+template <typename T>
+class optional_data_base : public optional_data_dtor_base<T> {
+ protected:
+  using base = optional_data_dtor_base<T>;
+#ifdef ABSL_OPTIONAL_USE_INHERITING_CONSTRUCTORS
+  using base::base;
+#else
+  optional_data_base() = default;
+
+  template <typename... Args>
+  constexpr explicit optional_data_base(in_place_t t, Args&&... args)
+      : base(t, absl::forward<Args>(args)...) {}
+#endif
+
+  template <typename... Args>
+  void construct(Args&&... args) {
+    // Use dummy_'s address to work around casting cv-qualified T* to void*.
+    ::new (static_cast<void*>(&this->dummy_)) T(std::forward<Args>(args)...);
+    this->engaged_ = true;
+  }
+
+  template <typename U>
+  void assign(U&& u) {
+    if (this->engaged_) {
+      this->data_ = std::forward<U>(u);
+    } else {
+      construct(std::forward<U>(u));
+    }
+  }
+};
+
+// TODO(absl-team): Add another class using
+// std::is_trivially_move_constructible trait when available to match
+// http://cplusplus.github.io/LWG/lwg-defects.html#2900, for types that
+// have trivial move but nontrivial copy.
+// Also, we should be checking is_trivially_copyable here, which is not
+// supported now, so we use is_trivially_* traits instead.
+template <typename T,
+          bool unused = absl::is_trivially_copy_constructible<T>::value&&
+              absl::is_trivially_copy_assignable<typename std::remove_cv<
+                  T>::type>::value&& std::is_trivially_destructible<T>::value>
+class optional_data;
+
+// Trivially copyable types
+template <typename T>
+class optional_data<T, true> : public optional_data_base<T> {
+ protected:
+#ifdef ABSL_OPTIONAL_USE_INHERITING_CONSTRUCTORS
+  using optional_data_base<T>::optional_data_base;
+#else
+  optional_data() = default;
+
+  template <typename... Args>
+  constexpr explicit optional_data(in_place_t t, Args&&... args)
+      : optional_data_base<T>(t, absl::forward<Args>(args)...) {}
+#endif
+};
+
+template <typename T>
+class optional_data<T, false> : public optional_data_base<T> {
+ protected:
+#ifdef ABSL_OPTIONAL_USE_INHERITING_CONSTRUCTORS
+  using optional_data_base<T>::optional_data_base;
+#else
+  template <typename... Args>
+  constexpr explicit optional_data(in_place_t t, Args&&... args)
+      : optional_data_base<T>(t, absl::forward<Args>(args)...) {}
+#endif
+
+  optional_data() = default;
+
+  optional_data(const optional_data& rhs) : optional_data_base<T>() {
+    if (rhs.engaged_) {
+      this->construct(rhs.data_);
+    }
+  }
+
+  optional_data(optional_data&& rhs) noexcept(
+      absl::default_allocator_is_nothrow::value ||
+      std::is_nothrow_move_constructible<T>::value)
+      : optional_data_base<T>() {
+    if (rhs.engaged_) {
+      this->construct(std::move(rhs.data_));
+    }
+  }
+
+  optional_data& operator=(const optional_data& rhs) {
+    if (rhs.engaged_) {
+      this->assign(rhs.data_);
+    } else {
+      this->destruct();
+    }
+    return *this;
+  }
+
+  optional_data& operator=(optional_data&& rhs) noexcept(
+      std::is_nothrow_move_assignable<T>::value&&
+          std::is_nothrow_move_constructible<T>::value) {
+    if (rhs.engaged_) {
+      this->assign(std::move(rhs.data_));
+    } else {
+      this->destruct();
+    }
+    return *this;
+  }
+};
+
+// Ordered by level of restriction, from low to high.
+// Copyable implies movable.
+enum class copy_traits { copyable = 0, movable = 1, non_movable = 2 };
+
+// Base class for enabling/disabling copy/move constructor.
+template <copy_traits>
+class optional_ctor_base;
+
+template <>
+class optional_ctor_base<copy_traits::copyable> {
+ public:
+  constexpr optional_ctor_base() = default;
+  optional_ctor_base(const optional_ctor_base&) = default;
+  optional_ctor_base(optional_ctor_base&&) = default;
+  optional_ctor_base& operator=(const optional_ctor_base&) = default;
+  optional_ctor_base& operator=(optional_ctor_base&&) = default;
+};
+
+template <>
+class optional_ctor_base<copy_traits::movable> {
+ public:
+  constexpr optional_ctor_base() = default;
+  optional_ctor_base(const optional_ctor_base&) = delete;
+  optional_ctor_base(optional_ctor_base&&) = default;
+  optional_ctor_base& operator=(const optional_ctor_base&) = default;
+  optional_ctor_base& operator=(optional_ctor_base&&) = default;
+};
+
+template <>
+class optional_ctor_base<copy_traits::non_movable> {
+ public:
+  constexpr optional_ctor_base() = default;
+  optional_ctor_base(const optional_ctor_base&) = delete;
+  optional_ctor_base(optional_ctor_base&&) = delete;
+  optional_ctor_base& operator=(const optional_ctor_base&) = default;
+  optional_ctor_base& operator=(optional_ctor_base&&) = default;
+};
+
+// Base class for enabling/disabling copy/move assignment.
+template <copy_traits>
+class optional_assign_base;
+
+template <>
+class optional_assign_base<copy_traits::copyable> {
+ public:
+  constexpr optional_assign_base() = default;
+  optional_assign_base(const optional_assign_base&) = default;
+  optional_assign_base(optional_assign_base&&) = default;
+  optional_assign_base& operator=(const optional_assign_base&) = default;
+  optional_assign_base& operator=(optional_assign_base&&) = default;
+};
+
+template <>
+class optional_assign_base<copy_traits::movable> {
+ public:
+  constexpr optional_assign_base() = default;
+  optional_assign_base(const optional_assign_base&) = default;
+  optional_assign_base(optional_assign_base&&) = default;
+  optional_assign_base& operator=(const optional_assign_base&) = delete;
+  optional_assign_base& operator=(optional_assign_base&&) = default;
+};
+
+template <>
+class optional_assign_base<copy_traits::non_movable> {
+ public:
+  constexpr optional_assign_base() = default;
+  optional_assign_base(const optional_assign_base&) = default;
+  optional_assign_base(optional_assign_base&&) = default;
+  optional_assign_base& operator=(const optional_assign_base&) = delete;
+  optional_assign_base& operator=(optional_assign_base&&) = delete;
+};
+
+template <typename T>
+struct ctor_copy_traits {
+  static constexpr copy_traits traits =
+      std::is_copy_constructible<T>::value
+          ? copy_traits::copyable
+          : std::is_move_constructible<T>::value ? copy_traits::movable
+                                                 : copy_traits::non_movable;
+};
+
+template <typename T>
+struct assign_copy_traits {
+  static constexpr copy_traits traits =
+      absl::is_copy_assignable<T>::value && std::is_copy_constructible<T>::value
+          ? copy_traits::copyable
+          : absl::is_move_assignable<T>::value &&
+                    std::is_move_constructible<T>::value
+                ? copy_traits::movable
+                : copy_traits::non_movable;
+};
+
+// Whether T is constructible or convertible from optional<U>.
+template <typename T, typename U>
+struct is_constructible_convertible_from_optional
+    : std::integral_constant<
+          bool, std::is_constructible<T, optional<U>&>::value ||
+                    std::is_constructible<T, optional<U>&&>::value ||
+                    std::is_constructible<T, const optional<U>&>::value ||
+                    std::is_constructible<T, const optional<U>&&>::value ||
+                    std::is_convertible<optional<U>&, T>::value ||
+                    std::is_convertible<optional<U>&&, T>::value ||
+                    std::is_convertible<const optional<U>&, T>::value ||
+                    std::is_convertible<const optional<U>&&, T>::value> {};
+
+// Whether T is constructible or convertible or assignable from optional<U>.
+template <typename T, typename U>
+struct is_constructible_convertible_assignable_from_optional
+    : std::integral_constant<
+          bool, is_constructible_convertible_from_optional<T, U>::value ||
+                    std::is_assignable<T&, optional<U>&>::value ||
+                    std::is_assignable<T&, optional<U>&&>::value ||
+                    std::is_assignable<T&, const optional<U>&>::value ||
+                    std::is_assignable<T&, const optional<U>&&>::value> {};
+
+// Helper function used by [optional.relops], [optional.comp_with_t],
+// for checking whether an expression is convertible to bool.
+bool convertible_to_bool(bool);
+
+// Base class for std::hash<absl::optional<T>>:
+// If std::hash<std::remove_const_t<T>> is enabled, it provides operator() to
+// compute the hash; Otherwise, it is disabled.
+// Reference N4659 23.14.15 [unord.hash].
+template <typename T, typename = size_t>
+struct optional_hash_base {
+  optional_hash_base() = delete;
+  optional_hash_base(const optional_hash_base&) = delete;
+  optional_hash_base(optional_hash_base&&) = delete;
+  optional_hash_base& operator=(const optional_hash_base&) = delete;
+  optional_hash_base& operator=(optional_hash_base&&) = delete;
+};
+
+template <typename T>
+struct optional_hash_base<T, decltype(std::hash<absl::remove_const_t<T> >()(
+                                 std::declval<absl::remove_const_t<T> >()))> {
+  using argument_type = absl::optional<T>;
+  using result_type = size_t;
+  size_t operator()(const absl::optional<T>& opt) const {
+    absl::type_traits_internal::AssertHashEnabled<absl::remove_const_t<T>>();
+    if (opt) {
+      return std::hash<absl::remove_const_t<T> >()(*opt);
+    } else {
+      return static_cast<size_t>(0x297814aaad196e6dULL);
+    }
+  }
+};
+
+}  // namespace optional_internal
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#undef ABSL_OPTIONAL_USE_INHERITING_CONSTRUCTORS
+
+#endif  // ABSL_TYPES_INTERNAL_OPTIONAL_H_
diff --git a/third_party/webrtc_aec3/src/absl/types/optional.h b/third_party/webrtc_aec3/src/absl/types/optional.h
new file mode 100644
index 0000000..61540cf
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/types/optional.h
@@ -0,0 +1,776 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+// -----------------------------------------------------------------------------
+// optional.h
+// -----------------------------------------------------------------------------
+//
+// This header file defines the `absl::optional` type for holding a value which
+// may or may not be present. This type is useful for providing value semantics
+// for operations that may either wish to return or hold "something-or-nothing".
+//
+// Example:
+//
+//   // A common way to signal operation failure is to provide an output
+//   // parameter and a bool return type:
+//   bool AcquireResource(const Input&, Resource * out);
+//
+//   // Providing an absl::optional return type provides a cleaner API:
+//   absl::optional<Resource> AcquireResource(const Input&);
+//
+// `absl::optional` is a C++11 compatible version of the C++17 `std::optional`
+// abstraction and is designed to be a drop-in replacement for code compliant
+// with C++17.
+#ifndef ABSL_TYPES_OPTIONAL_H_
+#define ABSL_TYPES_OPTIONAL_H_
+
+#include "absl/base/config.h"   // TODO(calabrese) IWYU removal?
+#include "absl/utility/utility.h"
+
+#ifdef ABSL_USES_STD_OPTIONAL
+
+#include <optional>  // IWYU pragma: export
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+using std::bad_optional_access;
+using std::optional;
+using std::make_optional;
+using std::nullopt_t;
+using std::nullopt;
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#else  // ABSL_USES_STD_OPTIONAL
+
+#include <cassert>
+#include <functional>
+#include <initializer_list>
+#include <type_traits>
+#include <utility>
+
+#include "absl/base/attributes.h"
+#include "absl/base/internal/inline_variable.h"
+#include "absl/meta/type_traits.h"
+#include "absl/types/bad_optional_access.h"
+#include "absl/types/internal/optional.h"
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+
+// nullopt_t
+//
+// Class type for `absl::nullopt` used to indicate an `absl::optional<T>` type
+// that does not contain a value.
+struct nullopt_t {
+  // It must not be default-constructible to avoid ambiguity for opt = {}.
+  explicit constexpr nullopt_t(optional_internal::init_t) noexcept {}
+};
+
+// nullopt
+//
+// A tag constant of type `absl::nullopt_t` used to indicate an empty
+// `absl::optional` in certain functions, such as construction or assignment.
+ABSL_INTERNAL_INLINE_CONSTEXPR(nullopt_t, nullopt,
+                               nullopt_t(optional_internal::init_t()));
+
+// -----------------------------------------------------------------------------
+// absl::optional
+// -----------------------------------------------------------------------------
+//
+// A value of type `absl::optional<T>` holds either a value of `T` or an
+// "empty" value.  When it holds a value of `T`, it stores it as a direct
+// sub-object, so `sizeof(optional<T>)` is approximately
+// `sizeof(T) + sizeof(bool)`.
+//
+// This implementation is based on the specification in the latest draft of the
+// C++17 `std::optional` specification as of May 2017, section 20.6.
+//
+// Differences between `absl::optional<T>` and `std::optional<T>` include:
+//
+//    * `constexpr` is not used for non-const member functions.
+//      (dependency on some differences between C++11 and C++14.)
+//    * `absl::nullopt` and `absl::in_place` are not declared `constexpr`. We
+//      need the inline variable support in C++17 for external linkage.
+//    * Throws `absl::bad_optional_access` instead of
+//      `std::bad_optional_access`.
+//    * `make_optional()` cannot be declared `constexpr` due to the absence of
+//      guaranteed copy elision.
+//    * The move constructor's `noexcept` specification is stronger, i.e. if the
+//      default allocator is non-throwing (via setting
+//      `ABSL_ALLOCATOR_NOTHROW`), it evaluates to `noexcept(true)`, because
+//      we assume
+//       a) move constructors should only throw due to allocation failure and
+//       b) if T's move constructor allocates, it uses the same allocation
+//          function as the default allocator.
+//
+template <typename T>
+class optional : private optional_internal::optional_data<T>,
+                 private optional_internal::optional_ctor_base<
+                     optional_internal::ctor_copy_traits<T>::traits>,
+                 private optional_internal::optional_assign_base<
+                     optional_internal::assign_copy_traits<T>::traits> {
+  using data_base = optional_internal::optional_data<T>;
+
+ public:
+  typedef T value_type;
+
+  // Constructors
+
+  // Constructs an `optional` holding an empty value, NOT a default constructed
+  // `T`.
+  constexpr optional() noexcept {}
+
+  // Constructs an `optional` initialized with `nullopt` to hold an empty value.
+  constexpr optional(nullopt_t) noexcept {}  // NOLINT(runtime/explicit)
+
+  // Copy constructor, standard semantics
+  optional(const optional&) = default;
+
+  // Move constructor, standard semantics
+  optional(optional&&) = default;
+
+  // Constructs a non-empty `optional` direct-initialized value of type `T` from
+  // the arguments `std::forward<Args>(args)...`  within the `optional`.
+  // (The `in_place_t` is a tag used to indicate that the contained object
+  // should be constructed in-place.)
+  template <typename InPlaceT, typename... Args,
+            absl::enable_if_t<absl::conjunction<
+                std::is_same<InPlaceT, in_place_t>,
+                std::is_constructible<T, Args&&...> >::value>* = nullptr>
+  constexpr explicit optional(InPlaceT, Args&&... args)
+      : data_base(in_place_t(), absl::forward<Args>(args)...) {}
+
+  // Constructs a non-empty `optional` direct-initialized value of type `T` from
+  // the arguments of an initializer_list and `std::forward<Args>(args)...`.
+  // (The `in_place_t` is a tag used to indicate that the contained object
+  // should be constructed in-place.)
+  template <typename U, typename... Args,
+            typename = typename std::enable_if<std::is_constructible<
+                T, std::initializer_list<U>&, Args&&...>::value>::type>
+  constexpr explicit optional(in_place_t, std::initializer_list<U> il,
+                              Args&&... args)
+      : data_base(in_place_t(), il, absl::forward<Args>(args)...) {
+  }
+
+  // Value constructor (implicit)
+  template <
+      typename U = T,
+      typename std::enable_if<
+          absl::conjunction<absl::negation<std::is_same<
+                                in_place_t, typename std::decay<U>::type> >,
+                            absl::negation<std::is_same<
+                                optional<T>, typename std::decay<U>::type> >,
+                            std::is_convertible<U&&, T>,
+                            std::is_constructible<T, U&&> >::value,
+          bool>::type = false>
+  constexpr optional(U&& v) : data_base(in_place_t(), absl::forward<U>(v)) {}
+
+  // Value constructor (explicit)
+  template <
+      typename U = T,
+      typename std::enable_if<
+          absl::conjunction<absl::negation<std::is_same<
+                                in_place_t, typename std::decay<U>::type>>,
+                            absl::negation<std::is_same<
+                                optional<T>, typename std::decay<U>::type>>,
+                            absl::negation<std::is_convertible<U&&, T>>,
+                            std::is_constructible<T, U&&>>::value,
+          bool>::type = false>
+  explicit constexpr optional(U&& v)
+      : data_base(in_place_t(), absl::forward<U>(v)) {}
+
+  // Converting copy constructor (implicit)
+  template <typename U,
+            typename std::enable_if<
+                absl::conjunction<
+                    absl::negation<std::is_same<T, U> >,
+                    std::is_constructible<T, const U&>,
+                    absl::negation<
+                        optional_internal::
+                            is_constructible_convertible_from_optional<T, U> >,
+                    std::is_convertible<const U&, T> >::value,
+                bool>::type = false>
+  optional(const optional<U>& rhs) {
+    if (rhs) {
+      this->construct(*rhs);
+    }
+  }
+
+  // Converting copy constructor (explicit)
+  template <typename U,
+            typename std::enable_if<
+                absl::conjunction<
+                    absl::negation<std::is_same<T, U>>,
+                    std::is_constructible<T, const U&>,
+                    absl::negation<
+                        optional_internal::
+                            is_constructible_convertible_from_optional<T, U>>,
+                    absl::negation<std::is_convertible<const U&, T>>>::value,
+                bool>::type = false>
+  explicit optional(const optional<U>& rhs) {
+    if (rhs) {
+      this->construct(*rhs);
+    }
+  }
+
+  // Converting move constructor (implicit)
+  template <typename U,
+            typename std::enable_if<
+                absl::conjunction<
+                    absl::negation<std::is_same<T, U> >,
+                    std::is_constructible<T, U&&>,
+                    absl::negation<
+                        optional_internal::
+                            is_constructible_convertible_from_optional<T, U> >,
+                    std::is_convertible<U&&, T> >::value,
+                bool>::type = false>
+  optional(optional<U>&& rhs) {
+    if (rhs) {
+      this->construct(std::move(*rhs));
+    }
+  }
+
+  // Converting move constructor (explicit)
+  template <
+      typename U,
+      typename std::enable_if<
+          absl::conjunction<
+              absl::negation<std::is_same<T, U>>, std::is_constructible<T, U&&>,
+              absl::negation<
+                  optional_internal::is_constructible_convertible_from_optional<
+                      T, U>>,
+              absl::negation<std::is_convertible<U&&, T>>>::value,
+          bool>::type = false>
+  explicit optional(optional<U>&& rhs) {
+    if (rhs) {
+      this->construct(std::move(*rhs));
+    }
+  }
+
+  // Destructor. Trivial if `T` is trivially destructible.
+  ~optional() = default;
+
+  // Assignment Operators
+
+  // Assignment from `nullopt`
+  //
+  // Example:
+  //
+  //   struct S { int value; };
+  //   optional<S> opt = absl::nullopt;  // Could also use opt = { };
+  optional& operator=(nullopt_t) noexcept {
+    this->destruct();
+    return *this;
+  }
+
+  // Copy assignment operator, standard semantics
+  optional& operator=(const optional& src) = default;
+
+  // Move assignment operator, standard semantics
+  optional& operator=(optional&& src) = default;
+
+  // Value assignment operators
+  template <
+      typename U = T,
+      typename = typename std::enable_if<absl::conjunction<
+          absl::negation<
+              std::is_same<optional<T>, typename std::decay<U>::type>>,
+          absl::negation<
+              absl::conjunction<std::is_scalar<T>,
+                                std::is_same<T, typename std::decay<U>::type>>>,
+          std::is_constructible<T, U>, std::is_assignable<T&, U>>::value>::type>
+  optional& operator=(U&& v) {
+    this->assign(std::forward<U>(v));
+    return *this;
+  }
+
+  template <
+      typename U,
+      typename = typename std::enable_if<absl::conjunction<
+          absl::negation<std::is_same<T, U>>,
+          std::is_constructible<T, const U&>, std::is_assignable<T&, const U&>,
+          absl::negation<
+              optional_internal::
+                  is_constructible_convertible_assignable_from_optional<
+                      T, U>>>::value>::type>
+  optional& operator=(const optional<U>& rhs) {
+    if (rhs) {
+      this->assign(*rhs);
+    } else {
+      this->destruct();
+    }
+    return *this;
+  }
+
+  template <typename U,
+            typename = typename std::enable_if<absl::conjunction<
+                absl::negation<std::is_same<T, U>>, std::is_constructible<T, U>,
+                std::is_assignable<T&, U>,
+                absl::negation<
+                    optional_internal::
+                        is_constructible_convertible_assignable_from_optional<
+                            T, U>>>::value>::type>
+  optional& operator=(optional<U>&& rhs) {
+    if (rhs) {
+      this->assign(std::move(*rhs));
+    } else {
+      this->destruct();
+    }
+    return *this;
+  }
+
+  // Modifiers
+
+  // optional::reset()
+  //
+  // Destroys the inner `T` value of an `absl::optional` if one is present.
+  ABSL_ATTRIBUTE_REINITIALIZES void reset() noexcept { this->destruct(); }
+
+  // optional::emplace()
+  //
+  // (Re)constructs the underlying `T` in-place with the given forwarded
+  // arguments.
+  //
+  // Example:
+  //
+  //   optional<Foo> opt;
+  //   opt.emplace(arg1,arg2,arg3);  // Constructs Foo(arg1,arg2,arg3)
+  //
+  // If the optional is non-empty, and the `args` refer to subobjects of the
+  // current object, then behaviour is undefined, because the current object
+  // will be destructed before the new object is constructed with `args`.
+  template <typename... Args,
+            typename = typename std::enable_if<
+                std::is_constructible<T, Args&&...>::value>::type>
+  T& emplace(Args&&... args) {
+    this->destruct();
+    this->construct(std::forward<Args>(args)...);
+    return reference();
+  }
+
+  // Emplace reconstruction overload for an initializer list and the given
+  // forwarded arguments.
+  //
+  // Example:
+  //
+  //   struct Foo {
+  //     Foo(std::initializer_list<int>);
+  //   };
+  //
+  //   optional<Foo> opt;
+  //   opt.emplace({1,2,3});  // Constructs Foo({1,2,3})
+  template <typename U, typename... Args,
+            typename = typename std::enable_if<std::is_constructible<
+                T, std::initializer_list<U>&, Args&&...>::value>::type>
+  T& emplace(std::initializer_list<U> il, Args&&... args) {
+    this->destruct();
+    this->construct(il, std::forward<Args>(args)...);
+    return reference();
+  }
+
+  // Swaps
+
+  // Swap, standard semantics
+  void swap(optional& rhs) noexcept(
+      std::is_nothrow_move_constructible<T>::value&&
+          type_traits_internal::IsNothrowSwappable<T>::value) {
+    if (*this) {
+      if (rhs) {
+        type_traits_internal::Swap(**this, *rhs);
+      } else {
+        rhs.construct(std::move(**this));
+        this->destruct();
+      }
+    } else {
+      if (rhs) {
+        this->construct(std::move(*rhs));
+        rhs.destruct();
+      } else {
+        // No effect (swap(disengaged, disengaged)).
+      }
+    }
+  }
+
+  // Observers
+
+  // optional::operator->()
+  //
+  // Accesses the underlying `T` value's member `m` of an `optional`. If the
+  // `optional` is empty, behavior is undefined.
+  //
+  // If you need myOpt->foo in constexpr, use (*myOpt).foo instead.
+  const T* operator->() const {
+    ABSL_HARDENING_ASSERT(this->engaged_);
+    return std::addressof(this->data_);
+  }
+  T* operator->() {
+    ABSL_HARDENING_ASSERT(this->engaged_);
+    return std::addressof(this->data_);
+  }
+
+  // optional::operator*()
+  //
+  // Accesses the underlying `T` value of an `optional`. If the `optional` is
+  // empty, behavior is undefined.
+  constexpr const T& operator*() const& {
+    return ABSL_HARDENING_ASSERT(this->engaged_), reference();
+  }
+  T& operator*() & {
+    ABSL_HARDENING_ASSERT(this->engaged_);
+    return reference();
+  }
+  constexpr const T&& operator*() const && {
+    return ABSL_HARDENING_ASSERT(this->engaged_), absl::move(reference());
+  }
+  T&& operator*() && {
+    ABSL_HARDENING_ASSERT(this->engaged_);
+    return std::move(reference());
+  }
+
+  // optional::operator bool()
+  //
+  // Returns false if and only if the `optional` is empty.
+  //
+  //   if (opt) {
+  //     // do something with *opt or opt->;
+  //   } else {
+  //     // opt is empty.
+  //   }
+  //
+  constexpr explicit operator bool() const noexcept { return this->engaged_; }
+
+  // optional::has_value()
+  //
+  // Determines whether the `optional` contains a value. Returns `false` if and
+  // only if `*this` is empty.
+  constexpr bool has_value() const noexcept { return this->engaged_; }
+
+// Suppress bogus warning on MSVC: MSVC complains call to reference() after
+// throw_bad_optional_access() is unreachable.
+#ifdef _MSC_VER
+#pragma warning(push)
+#pragma warning(disable : 4702)
+#endif  // _MSC_VER
+  // optional::value()
+  //
+  // Returns a reference to an `optional`s underlying value. The constness
+  // and lvalue/rvalue-ness of the `optional` is preserved to the view of
+  // the `T` sub-object. Throws `absl::bad_optional_access` when the `optional`
+  // is empty.
+  constexpr const T& value() const & {
+    return static_cast<bool>(*this)
+               ? reference()
+               : (optional_internal::throw_bad_optional_access(), reference());
+  }
+  T& value() & {
+    return static_cast<bool>(*this)
+               ? reference()
+               : (optional_internal::throw_bad_optional_access(), reference());
+  }
+  T&& value() && {  // NOLINT(build/c++11)
+    return std::move(
+        static_cast<bool>(*this)
+            ? reference()
+            : (optional_internal::throw_bad_optional_access(), reference()));
+  }
+  constexpr const T&& value() const && {  // NOLINT(build/c++11)
+    return absl::move(
+        static_cast<bool>(*this)
+            ? reference()
+            : (optional_internal::throw_bad_optional_access(), reference()));
+  }
+#ifdef _MSC_VER
+#pragma warning(pop)
+#endif  // _MSC_VER
+
+  // optional::value_or()
+  //
+  // Returns either the value of `T` or a passed default `v` if the `optional`
+  // is empty.
+  template <typename U>
+  constexpr T value_or(U&& v) const& {
+    static_assert(std::is_copy_constructible<value_type>::value,
+                  "optional<T>::value_or: T must be copy constructible");
+    static_assert(std::is_convertible<U&&, value_type>::value,
+                  "optional<T>::value_or: U must be convertible to T");
+    return static_cast<bool>(*this)
+               ? **this
+               : static_cast<T>(absl::forward<U>(v));
+  }
+  template <typename U>
+  T value_or(U&& v) && {  // NOLINT(build/c++11)
+    static_assert(std::is_move_constructible<value_type>::value,
+                  "optional<T>::value_or: T must be move constructible");
+    static_assert(std::is_convertible<U&&, value_type>::value,
+                  "optional<T>::value_or: U must be convertible to T");
+    return static_cast<bool>(*this) ? std::move(**this)
+                                    : static_cast<T>(std::forward<U>(v));
+  }
+
+ private:
+  // Private accessors for internal storage viewed as reference to T.
+  constexpr const T& reference() const { return this->data_; }
+  T& reference() { return this->data_; }
+
+  // T constraint checks.  You can't have an optional of nullopt_t, in_place_t
+  // or a reference.
+  static_assert(
+      !std::is_same<nullopt_t, typename std::remove_cv<T>::type>::value,
+      "optional<nullopt_t> is not allowed.");
+  static_assert(
+      !std::is_same<in_place_t, typename std::remove_cv<T>::type>::value,
+      "optional<in_place_t> is not allowed.");
+  static_assert(!std::is_reference<T>::value,
+                "optional<reference> is not allowed.");
+};
+
+// Non-member functions
+
+// swap()
+//
+// Performs a swap between two `absl::optional` objects, using standard
+// semantics.
+template <typename T, typename std::enable_if<
+                          std::is_move_constructible<T>::value &&
+                              type_traits_internal::IsSwappable<T>::value,
+                          bool>::type = false>
+void swap(optional<T>& a, optional<T>& b) noexcept(noexcept(a.swap(b))) {
+  a.swap(b);
+}
+
+// make_optional()
+//
+// Creates a non-empty `optional<T>` where the type of `T` is deduced. An
+// `absl::optional` can also be explicitly instantiated with
+// `make_optional<T>(v)`.
+//
+// Note: `make_optional()` constructions may be declared `constexpr` for
+// trivially copyable types `T`. Non-trivial types require copy elision
+// support in C++17 for `make_optional` to support `constexpr` on such
+// non-trivial types.
+//
+// Example:
+//
+//   constexpr absl::optional<int> opt = absl::make_optional(1);
+//   static_assert(opt.value() == 1, "");
+template <typename T>
+constexpr optional<typename std::decay<T>::type> make_optional(T&& v) {
+  return optional<typename std::decay<T>::type>(absl::forward<T>(v));
+}
+
+template <typename T, typename... Args>
+constexpr optional<T> make_optional(Args&&... args) {
+  return optional<T>(in_place_t(), absl::forward<Args>(args)...);
+}
+
+template <typename T, typename U, typename... Args>
+constexpr optional<T> make_optional(std::initializer_list<U> il,
+                                    Args&&... args) {
+  return optional<T>(in_place_t(), il,
+                     absl::forward<Args>(args)...);
+}
+
+// Relational operators [optional.relops]
+
+// Empty optionals are considered equal to each other and less than non-empty
+// optionals. Supports relations between optional<T> and optional<U>, between
+// optional<T> and U, and between optional<T> and nullopt.
+//
+// Note: We're careful to support T having non-bool relationals.
+
+// Requires: The expression, e.g. "*x == *y" shall be well-formed and its result
+// shall be convertible to bool.
+// The C++17 (N4606) "Returns:" statements are translated into
+// code in an obvious way here, and the original text retained as function docs.
+// Returns: If bool(x) != bool(y), false; otherwise if bool(x) == false, true;
+// otherwise *x == *y.
+template <typename T, typename U>
+constexpr auto operator==(const optional<T>& x, const optional<U>& y)
+    -> decltype(optional_internal::convertible_to_bool(*x == *y)) {
+  return static_cast<bool>(x) != static_cast<bool>(y)
+             ? false
+             : static_cast<bool>(x) == false ? true
+                                             : static_cast<bool>(*x == *y);
+}
+
+// Returns: If bool(x) != bool(y), true; otherwise, if bool(x) == false, false;
+// otherwise *x != *y.
+template <typename T, typename U>
+constexpr auto operator!=(const optional<T>& x, const optional<U>& y)
+    -> decltype(optional_internal::convertible_to_bool(*x != *y)) {
+  return static_cast<bool>(x) != static_cast<bool>(y)
+             ? true
+             : static_cast<bool>(x) == false ? false
+                                             : static_cast<bool>(*x != *y);
+}
+// Returns: If !y, false; otherwise, if !x, true; otherwise *x < *y.
+template <typename T, typename U>
+constexpr auto operator<(const optional<T>& x, const optional<U>& y)
+    -> decltype(optional_internal::convertible_to_bool(*x < *y)) {
+  return !y ? false : !x ? true : static_cast<bool>(*x < *y);
+}
+// Returns: If !x, false; otherwise, if !y, true; otherwise *x > *y.
+template <typename T, typename U>
+constexpr auto operator>(const optional<T>& x, const optional<U>& y)
+    -> decltype(optional_internal::convertible_to_bool(*x > *y)) {
+  return !x ? false : !y ? true : static_cast<bool>(*x > *y);
+}
+// Returns: If !x, true; otherwise, if !y, false; otherwise *x <= *y.
+template <typename T, typename U>
+constexpr auto operator<=(const optional<T>& x, const optional<U>& y)
+    -> decltype(optional_internal::convertible_to_bool(*x <= *y)) {
+  return !x ? true : !y ? false : static_cast<bool>(*x <= *y);
+}
+// Returns: If !y, true; otherwise, if !x, false; otherwise *x >= *y.
+template <typename T, typename U>
+constexpr auto operator>=(const optional<T>& x, const optional<U>& y)
+    -> decltype(optional_internal::convertible_to_bool(*x >= *y)) {
+  return !y ? true : !x ? false : static_cast<bool>(*x >= *y);
+}
+
+// Comparison with nullopt [optional.nullops]
+// The C++17 (N4606) "Returns:" statements are used directly here.
+template <typename T>
+constexpr bool operator==(const optional<T>& x, nullopt_t) noexcept {
+  return !x;
+}
+template <typename T>
+constexpr bool operator==(nullopt_t, const optional<T>& x) noexcept {
+  return !x;
+}
+template <typename T>
+constexpr bool operator!=(const optional<T>& x, nullopt_t) noexcept {
+  return static_cast<bool>(x);
+}
+template <typename T>
+constexpr bool operator!=(nullopt_t, const optional<T>& x) noexcept {
+  return static_cast<bool>(x);
+}
+template <typename T>
+constexpr bool operator<(const optional<T>&, nullopt_t) noexcept {
+  return false;
+}
+template <typename T>
+constexpr bool operator<(nullopt_t, const optional<T>& x) noexcept {
+  return static_cast<bool>(x);
+}
+template <typename T>
+constexpr bool operator<=(const optional<T>& x, nullopt_t) noexcept {
+  return !x;
+}
+template <typename T>
+constexpr bool operator<=(nullopt_t, const optional<T>&) noexcept {
+  return true;
+}
+template <typename T>
+constexpr bool operator>(const optional<T>& x, nullopt_t) noexcept {
+  return static_cast<bool>(x);
+}
+template <typename T>
+constexpr bool operator>(nullopt_t, const optional<T>&) noexcept {
+  return false;
+}
+template <typename T>
+constexpr bool operator>=(const optional<T>&, nullopt_t) noexcept {
+  return true;
+}
+template <typename T>
+constexpr bool operator>=(nullopt_t, const optional<T>& x) noexcept {
+  return !x;
+}
+
+// Comparison with T [optional.comp_with_t]
+
+// Requires: The expression, e.g. "*x == v" shall be well-formed and its result
+// shall be convertible to bool.
+// The C++17 (N4606) "Equivalent to:" statements are used directly here.
+template <typename T, typename U>
+constexpr auto operator==(const optional<T>& x, const U& v)
+    -> decltype(optional_internal::convertible_to_bool(*x == v)) {
+  return static_cast<bool>(x) ? static_cast<bool>(*x == v) : false;
+}
+template <typename T, typename U>
+constexpr auto operator==(const U& v, const optional<T>& x)
+    -> decltype(optional_internal::convertible_to_bool(v == *x)) {
+  return static_cast<bool>(x) ? static_cast<bool>(v == *x) : false;
+}
+template <typename T, typename U>
+constexpr auto operator!=(const optional<T>& x, const U& v)
+    -> decltype(optional_internal::convertible_to_bool(*x != v)) {
+  return static_cast<bool>(x) ? static_cast<bool>(*x != v) : true;
+}
+template <typename T, typename U>
+constexpr auto operator!=(const U& v, const optional<T>& x)
+    -> decltype(optional_internal::convertible_to_bool(v != *x)) {
+  return static_cast<bool>(x) ? static_cast<bool>(v != *x) : true;
+}
+template <typename T, typename U>
+constexpr auto operator<(const optional<T>& x, const U& v)
+    -> decltype(optional_internal::convertible_to_bool(*x < v)) {
+  return static_cast<bool>(x) ? static_cast<bool>(*x < v) : true;
+}
+template <typename T, typename U>
+constexpr auto operator<(const U& v, const optional<T>& x)
+    -> decltype(optional_internal::convertible_to_bool(v < *x)) {
+  return static_cast<bool>(x) ? static_cast<bool>(v < *x) : false;
+}
+template <typename T, typename U>
+constexpr auto operator<=(const optional<T>& x, const U& v)
+    -> decltype(optional_internal::convertible_to_bool(*x <= v)) {
+  return static_cast<bool>(x) ? static_cast<bool>(*x <= v) : true;
+}
+template <typename T, typename U>
+constexpr auto operator<=(const U& v, const optional<T>& x)
+    -> decltype(optional_internal::convertible_to_bool(v <= *x)) {
+  return static_cast<bool>(x) ? static_cast<bool>(v <= *x) : false;
+}
+template <typename T, typename U>
+constexpr auto operator>(const optional<T>& x, const U& v)
+    -> decltype(optional_internal::convertible_to_bool(*x > v)) {
+  return static_cast<bool>(x) ? static_cast<bool>(*x > v) : false;
+}
+template <typename T, typename U>
+constexpr auto operator>(const U& v, const optional<T>& x)
+    -> decltype(optional_internal::convertible_to_bool(v > *x)) {
+  return static_cast<bool>(x) ? static_cast<bool>(v > *x) : true;
+}
+template <typename T, typename U>
+constexpr auto operator>=(const optional<T>& x, const U& v)
+    -> decltype(optional_internal::convertible_to_bool(*x >= v)) {
+  return static_cast<bool>(x) ? static_cast<bool>(*x >= v) : false;
+}
+template <typename T, typename U>
+constexpr auto operator>=(const U& v, const optional<T>& x)
+    -> decltype(optional_internal::convertible_to_bool(v >= *x)) {
+  return static_cast<bool>(x) ? static_cast<bool>(v >= *x) : true;
+}
+
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+namespace std {
+
+// std::hash specialization for absl::optional.
+template <typename T>
+struct hash<absl::optional<T> >
+    : absl::optional_internal::optional_hash_base<T> {};
+
+}  // namespace std
+
+#undef ABSL_MSVC_CONSTEXPR_BUG_IN_UNION_LIKE_CLASS
+
+#endif  // ABSL_USES_STD_OPTIONAL
+
+#endif  // ABSL_TYPES_OPTIONAL_H_
diff --git a/third_party/webrtc_aec3/src/absl/utility/utility.h b/third_party/webrtc_aec3/src/absl/utility/utility.h
new file mode 100644
index 0000000..bf92322
--- /dev/null
+++ b/third_party/webrtc_aec3/src/absl/utility/utility.h
@@ -0,0 +1,350 @@
+// Copyright 2017 The Abseil Authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      https://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+// This header file contains C++11 versions of standard <utility> header
+// abstractions available within C++14 and C++17, and are designed to be drop-in
+// replacement for code compliant with C++14 and C++17.
+//
+// The following abstractions are defined:
+//
+//   * integer_sequence<T, Ints...>  == std::integer_sequence<T, Ints...>
+//   * index_sequence<Ints...>       == std::index_sequence<Ints...>
+//   * make_integer_sequence<T, N>   == std::make_integer_sequence<T, N>
+//   * make_index_sequence<N>        == std::make_index_sequence<N>
+//   * index_sequence_for<Ts...>     == std::index_sequence_for<Ts...>
+//   * apply<Functor, Tuple>         == std::apply<Functor, Tuple>
+//   * exchange<T>                   == std::exchange<T>
+//   * make_from_tuple<T>            == std::make_from_tuple<T>
+//
+// This header file also provides the tag types `in_place_t`, `in_place_type_t`,
+// and `in_place_index_t`, as well as the constant `in_place`, and
+// `constexpr` `std::move()` and `std::forward()` implementations in C++11.
+//
+// References:
+//
+//  https://en.cppreference.com/w/cpp/utility/integer_sequence
+//  https://en.cppreference.com/w/cpp/utility/apply
+//  http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3658.html
+
+#ifndef ABSL_UTILITY_UTILITY_H_
+#define ABSL_UTILITY_UTILITY_H_
+
+#include <cstddef>
+#include <cstdlib>
+#include <tuple>
+#include <utility>
+
+#include "absl/base/config.h"
+#include "absl/base/internal/inline_variable.h"
+#include "absl/base/internal/invoke.h"
+#include "absl/meta/type_traits.h"
+
+namespace absl {
+ABSL_NAMESPACE_BEGIN
+
+// integer_sequence
+//
+// Class template representing a compile-time integer sequence. An instantiation
+// of `integer_sequence<T, Ints...>` has a sequence of integers encoded in its
+// type through its template arguments (which is a common need when
+// working with C++11 variadic templates). `absl::integer_sequence` is designed
+// to be a drop-in replacement for C++14's `std::integer_sequence`.
+//
+// Example:
+//
+//   template< class T, T... Ints >
+//   void user_function(integer_sequence<T, Ints...>);
+//
+//   int main()
+//   {
+//     // user_function's `T` will be deduced to `int` and `Ints...`
+//     // will be deduced to `0, 1, 2, 3, 4`.
+//     user_function(make_integer_sequence<int, 5>());
+//   }
+template <typename T, T... Ints>
+struct integer_sequence {
+  using value_type = T;
+  static constexpr size_t size() noexcept { return sizeof...(Ints); }
+};
+
+// index_sequence
+//
+// A helper template for an `integer_sequence` of `size_t`,
+// `absl::index_sequence` is designed to be a drop-in replacement for C++14's
+// `std::index_sequence`.
+template <size_t... Ints>
+using index_sequence = integer_sequence<size_t, Ints...>;
+
+namespace utility_internal {
+
+template <typename Seq, size_t SeqSize, size_t Rem>
+struct Extend;
+
+// Note that SeqSize == sizeof...(Ints). It's passed explicitly for efficiency.
+template <typename T, T... Ints, size_t SeqSize>
+struct Extend<integer_sequence<T, Ints...>, SeqSize, 0> {
+  using type = integer_sequence<T, Ints..., (Ints + SeqSize)...>;
+};
+
+template <typename T, T... Ints, size_t SeqSize>
+struct Extend<integer_sequence<T, Ints...>, SeqSize, 1> {
+  using type = integer_sequence<T, Ints..., (Ints + SeqSize)..., 2 * SeqSize>;
+};
+
+// Recursion helper for 'make_integer_sequence<T, N>'.
+// 'Gen<T, N>::type' is an alias for 'integer_sequence<T, 0, 1, ... N-1>'.
+template <typename T, size_t N>
+struct Gen {
+  using type =
+      typename Extend<typename Gen<T, N / 2>::type, N / 2, N % 2>::type;
+};
+
+template <typename T>
+struct Gen<T, 0> {
+  using type = integer_sequence<T>;
+};
+
+template <typename T>
+struct InPlaceTypeTag {
+  explicit InPlaceTypeTag() = delete;
+  InPlaceTypeTag(const InPlaceTypeTag&) = delete;
+  InPlaceTypeTag& operator=(const InPlaceTypeTag&) = delete;
+};
+
+template <size_t I>
+struct InPlaceIndexTag {
+  explicit InPlaceIndexTag() = delete;
+  InPlaceIndexTag(const InPlaceIndexTag&) = delete;
+  InPlaceIndexTag& operator=(const InPlaceIndexTag&) = delete;
+};
+
+}  // namespace utility_internal
+
+// Compile-time sequences of integers
+
+// make_integer_sequence
+//
+// This template alias is equivalent to
+// `integer_sequence<int, 0, 1, ..., N-1>`, and is designed to be a drop-in
+// replacement for C++14's `std::make_integer_sequence`.
+template <typename T, T N>
+using make_integer_sequence = typename utility_internal::Gen<T, N>::type;
+
+// make_index_sequence
+//
+// This template alias is equivalent to `index_sequence<0, 1, ..., N-1>`,
+// and is designed to be a drop-in replacement for C++14's
+// `std::make_index_sequence`.
+template <size_t N>
+using make_index_sequence = make_integer_sequence<size_t, N>;
+
+// index_sequence_for
+//
+// Converts a typename pack into an index sequence of the same length, and
+// is designed to be a drop-in replacement for C++14's
+// `std::index_sequence_for()`
+template <typename... Ts>
+using index_sequence_for = make_index_sequence<sizeof...(Ts)>;
+
+// Tag types
+
+#ifdef ABSL_USES_STD_OPTIONAL
+
+using std::in_place_t;
+using std::in_place;
+
+#else  // ABSL_USES_STD_OPTIONAL
+
+// in_place_t
+//
+// Tag type used to specify in-place construction, such as with
+// `absl::optional`, designed to be a drop-in replacement for C++17's
+// `std::in_place_t`.
+struct in_place_t {};
+
+ABSL_INTERNAL_INLINE_CONSTEXPR(in_place_t, in_place, {});
+
+#endif  // ABSL_USES_STD_OPTIONAL
+
+#if defined(ABSL_USES_STD_ANY) || defined(ABSL_USES_STD_VARIANT)
+using std::in_place_type;
+using std::in_place_type_t;
+#else
+
+// in_place_type_t
+//
+// Tag type used for in-place construction when the type to construct needs to
+// be specified, such as with `absl::any`, designed to be a drop-in replacement
+// for C++17's `std::in_place_type_t`.
+template <typename T>
+using in_place_type_t = void (*)(utility_internal::InPlaceTypeTag<T>);
+
+template <typename T>
+void in_place_type(utility_internal::InPlaceTypeTag<T>) {}
+#endif  // ABSL_USES_STD_ANY || ABSL_USES_STD_VARIANT
+
+#ifdef ABSL_USES_STD_VARIANT
+using std::in_place_index;
+using std::in_place_index_t;
+#else
+
+// in_place_index_t
+//
+// Tag type used for in-place construction when the type to construct needs to
+// be specified, such as with `absl::any`, designed to be a drop-in replacement
+// for C++17's `std::in_place_index_t`.
+template <size_t I>
+using in_place_index_t = void (*)(utility_internal::InPlaceIndexTag<I>);
+
+template <size_t I>
+void in_place_index(utility_internal::InPlaceIndexTag<I>) {}
+#endif  // ABSL_USES_STD_VARIANT
+
+// Constexpr move and forward
+
+// move()
+//
+// A constexpr version of `std::move()`, designed to be a drop-in replacement
+// for C++14's `std::move()`.
+template <typename T>
+constexpr absl::remove_reference_t<T>&& move(T&& t) noexcept {
+  return static_cast<absl::remove_reference_t<T>&&>(t);
+}
+
+// forward()
+//
+// A constexpr version of `std::forward()`, designed to be a drop-in replacement
+// for C++14's `std::forward()`.
+template <typename T>
+constexpr T&& forward(
+    absl::remove_reference_t<T>& t) noexcept {  // NOLINT(runtime/references)
+  return static_cast<T&&>(t);
+}
+
+namespace utility_internal {
+// Helper method for expanding tuple into a called method.
+template <typename Functor, typename Tuple, std::size_t... Indexes>
+auto apply_helper(Functor&& functor, Tuple&& t, index_sequence<Indexes...>)
+    -> decltype(absl::base_internal::invoke(
+        absl::forward<Functor>(functor),
+        std::get<Indexes>(absl::forward<Tuple>(t))...)) {
+  return absl::base_internal::invoke(
+      absl::forward<Functor>(functor),
+      std::get<Indexes>(absl::forward<Tuple>(t))...);
+}
+
+}  // namespace utility_internal
+
+// apply
+//
+// Invokes a Callable using elements of a tuple as its arguments.
+// Each element of the tuple corresponds to an argument of the call (in order).
+// Both the Callable argument and the tuple argument are perfect-forwarded.
+// For member-function Callables, the first tuple element acts as the `this`
+// pointer. `absl::apply` is designed to be a drop-in replacement for C++17's
+// `std::apply`. Unlike C++17's `std::apply`, this is not currently `constexpr`.
+//
+// Example:
+//
+//   class Foo {
+//    public:
+//     void Bar(int);
+//   };
+//   void user_function1(int, std::string);
+//   void user_function2(std::unique_ptr<Foo>);
+//   auto user_lambda = [](int, int) {};
+//
+//   int main()
+//   {
+//       std::tuple<int, std::string> tuple1(42, "bar");
+//       // Invokes the first user function on int, std::string.
+//       absl::apply(&user_function1, tuple1);
+//
+//       std::tuple<std::unique_ptr<Foo>> tuple2(absl::make_unique<Foo>());
+//       // Invokes the user function that takes ownership of the unique
+//       // pointer.
+//       absl::apply(&user_function2, std::move(tuple2));
+//
+//       auto foo = absl::make_unique<Foo>();
+//       std::tuple<Foo*, int> tuple3(foo.get(), 42);
+//       // Invokes the method Bar on foo with one argument, 42.
+//       absl::apply(&Foo::Bar, tuple3);
+//
+//       std::tuple<int, int> tuple4(8, 9);
+//       // Invokes a lambda.
+//       absl::apply(user_lambda, tuple4);
+//   }
+template <typename Functor, typename Tuple>
+auto apply(Functor&& functor, Tuple&& t)
+    -> decltype(utility_internal::apply_helper(
+        absl::forward<Functor>(functor), absl::forward<Tuple>(t),
+        absl::make_index_sequence<std::tuple_size<
+            typename std::remove_reference<Tuple>::type>::value>{})) {
+  return utility_internal::apply_helper(
+      absl::forward<Functor>(functor), absl::forward<Tuple>(t),
+      absl::make_index_sequence<std::tuple_size<
+          typename std::remove_reference<Tuple>::type>::value>{});
+}
+
+// exchange
+//
+// Replaces the value of `obj` with `new_value` and returns the old value of
+// `obj`.  `absl::exchange` is designed to be a drop-in replacement for C++14's
+// `std::exchange`.
+//
+// Example:
+//
+//   Foo& operator=(Foo&& other) {
+//     ptr1_ = absl::exchange(other.ptr1_, nullptr);
+//     int1_ = absl::exchange(other.int1_, -1);
+//     return *this;
+//   }
+template <typename T, typename U = T>
+T exchange(T& obj, U&& new_value) {
+  T old_value = absl::move(obj);
+  obj = absl::forward<U>(new_value);
+  return old_value;
+}
+
+namespace utility_internal {
+template <typename T, typename Tuple, size_t... I>
+T make_from_tuple_impl(Tuple&& tup, absl::index_sequence<I...>) {
+  return T(std::get<I>(std::forward<Tuple>(tup))...);
+}
+}  // namespace utility_internal
+
+// make_from_tuple
+//
+// Given the template parameter type `T` and a tuple of arguments
+// `std::tuple(arg0, arg1, ..., argN)` constructs an object of type `T` as if by
+// calling `T(arg0, arg1, ..., argN)`.
+//
+// Example:
+//
+//   std::tuple<const char*, size_t> args("hello world", 5);
+//   auto s = absl::make_from_tuple<std::string>(args);
+//   assert(s == "hello");
+//
+template <typename T, typename Tuple>
+constexpr T make_from_tuple(Tuple&& tup) {
+  return utility_internal::make_from_tuple_impl<T>(
+      std::forward<Tuple>(tup),
+      absl::make_index_sequence<
+          std::tuple_size<absl::decay_t<Tuple>>::value>{});
+}
+
+ABSL_NAMESPACE_END
+}  // namespace absl
+
+#endif  // ABSL_UTILITY_UTILITY_H_
diff --git a/third_party/webrtc_aec3/src/api/array_view.h b/third_party/webrtc_aec3/src/api/array_view.h
new file mode 100644
index 0000000..df365cb
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/array_view.h
@@ -0,0 +1,328 @@
+/*
+ *  Copyright 2015 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef API_ARRAY_VIEW_H_
+#define API_ARRAY_VIEW_H_
+
+#include <algorithm>
+#include <array>
+#include <iterator>
+#include <type_traits>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/type_traits.h"
+
+namespace rtc {
+
+// tl;dr: rtc::ArrayView is the same thing as gsl::span from the Guideline
+//        Support Library.
+//
+// Many functions read from or write to arrays. The obvious way to do this is
+// to use two arguments, a pointer to the first element and an element count:
+//
+//   bool Contains17(const int* arr, size_t size) {
+//     for (size_t i = 0; i < size; ++i) {
+//       if (arr[i] == 17)
+//         return true;
+//     }
+//     return false;
+//   }
+//
+// This is flexible, since it doesn't matter how the array is stored (C array,
+// std::vector, rtc::Buffer, ...), but it's error-prone because the caller has
+// to correctly specify the array length:
+//
+//   Contains17(arr, arraysize(arr));     // C array
+//   Contains17(arr.data(), arr.size());  // std::vector
+//   Contains17(arr, size);               // pointer + size
+//   ...
+//
+// It's also kind of messy to have two separate arguments for what is
+// conceptually a single thing.
+//
+// Enter rtc::ArrayView<T>. It contains a T pointer (to an array it doesn't
+// own) and a count, and supports the basic things you'd expect, such as
+// indexing and iteration. It allows us to write our function like this:
+//
+//   bool Contains17(rtc::ArrayView<const int> arr) {
+//     for (auto e : arr) {
+//       if (e == 17)
+//         return true;
+//     }
+//     return false;
+//   }
+//
+// And even better, because a bunch of things will implicitly convert to
+// ArrayView, we can call it like this:
+//
+//   Contains17(arr);                             // C array
+//   Contains17(arr);                             // std::vector
+//   Contains17(rtc::ArrayView<int>(arr, size));  // pointer + size
+//   Contains17(nullptr);                         // nullptr -> empty ArrayView
+//   ...
+//
+// ArrayView<T> stores both a pointer and a size, but you may also use
+// ArrayView<T, N>, which has a size that's fixed at compile time (which means
+// it only has to store the pointer).
+//
+// One important point is that ArrayView<T> and ArrayView<const T> are
+// different types, which allow and don't allow mutation of the array elements,
+// respectively. The implicit conversions work just like you'd hope, so that
+// e.g. vector<int> will convert to either ArrayView<int> or ArrayView<const
+// int>, but const vector<int> will convert only to ArrayView<const int>.
+// (ArrayView itself can be the source type in such conversions, so
+// ArrayView<int> will convert to ArrayView<const int>.)
+//
+// Note: ArrayView is tiny (just a pointer and a count if variable-sized, just
+// a pointer if fix-sized) and trivially copyable, so it's probably cheaper to
+// pass it by value than by const reference.
+
+namespace impl {
+
+// Magic constant for indicating that the size of an ArrayView is variable
+// instead of fixed.
+enum : std::ptrdiff_t { kArrayViewVarSize = -4711 };
+
+// Base class for ArrayViews of fixed nonzero size.
+template <typename T, std::ptrdiff_t Size>
+class ArrayViewBase {
+  static_assert(Size > 0, "ArrayView size must be variable or non-negative");
+
+ public:
+  ArrayViewBase(T* data, size_t size) : data_(data) {}
+
+  static constexpr size_t size() { return Size; }
+  static constexpr bool empty() { return false; }
+  T* data() const { return data_; }
+
+ protected:
+  static constexpr bool fixed_size() { return true; }
+
+ private:
+  T* data_;
+};
+
+// Specialized base class for ArrayViews of fixed zero size.
+template <typename T>
+class ArrayViewBase<T, 0> {
+ public:
+  explicit ArrayViewBase(T* data, size_t size) {}
+
+  static constexpr size_t size() { return 0; }
+  static constexpr bool empty() { return true; }
+  T* data() const { return nullptr; }
+
+ protected:
+  static constexpr bool fixed_size() { return true; }
+};
+
+// Specialized base class for ArrayViews of variable size.
+template <typename T>
+class ArrayViewBase<T, impl::kArrayViewVarSize> {
+ public:
+  ArrayViewBase(T* data, size_t size)
+      : data_(size == 0 ? nullptr : data), size_(size) {}
+
+  size_t size() const { return size_; }
+  bool empty() const { return size_ == 0; }
+  T* data() const { return data_; }
+
+ protected:
+  static constexpr bool fixed_size() { return false; }
+
+ private:
+  T* data_;
+  size_t size_;
+};
+
+}  // namespace impl
+
+template <typename T, std::ptrdiff_t Size = impl::kArrayViewVarSize>
+class ArrayView final : public impl::ArrayViewBase<T, Size> {
+ public:
+  using value_type = T;
+  using const_iterator = const T*;
+
+  // Construct an ArrayView from a pointer and a length.
+  template <typename U>
+  ArrayView(U* data, size_t size)
+      : impl::ArrayViewBase<T, Size>::ArrayViewBase(data, size) {
+    RTC_DCHECK_EQ(size == 0 ? nullptr : data, this->data());
+    RTC_DCHECK_EQ(size, this->size());
+    RTC_DCHECK_EQ(!this->data(),
+                  this->size() == 0);  // data is null iff size == 0.
+  }
+
+  // Construct an empty ArrayView. Note that fixed-size ArrayViews of size > 0
+  // cannot be empty.
+  ArrayView() : ArrayView(nullptr, 0) {}
+  ArrayView(std::nullptr_t)  // NOLINT
+      : ArrayView() {}
+  ArrayView(std::nullptr_t, size_t size)
+      : ArrayView(static_cast<T*>(nullptr), size) {
+    static_assert(Size == 0 || Size == impl::kArrayViewVarSize, "");
+    RTC_DCHECK_EQ(0, size);
+  }
+
+  // Construct an ArrayView from a C-style array.
+  template <typename U, size_t N>
+  ArrayView(U (&array)[N])  // NOLINT
+      : ArrayView(array, N) {
+    static_assert(Size == N || Size == impl::kArrayViewVarSize,
+                  "Array size must match ArrayView size");
+  }
+
+  // (Only if size is fixed.) Construct a fixed size ArrayView<T, N> from a
+  // non-const std::array instance. For an ArrayView with variable size, the
+  // used ctor is ArrayView(U& u) instead.
+  template <typename U,
+            size_t N,
+            typename std::enable_if<
+                Size == static_cast<std::ptrdiff_t>(N)>::type* = nullptr>
+  ArrayView(std::array<U, N>& u)  // NOLINT
+      : ArrayView(u.data(), u.size()) {}
+
+  // (Only if size is fixed.) Construct a fixed size ArrayView<T, N> where T is
+  // const from a const(expr) std::array instance. For an ArrayView with
+  // variable size, the used ctor is ArrayView(U& u) instead.
+  template <typename U,
+            size_t N,
+            typename std::enable_if<
+                Size == static_cast<std::ptrdiff_t>(N)>::type* = nullptr>
+  ArrayView(const std::array<U, N>& u)  // NOLINT
+      : ArrayView(u.data(), u.size()) {}
+
+  // (Only if size is fixed.) Construct an ArrayView from any type U that has a
+  // static constexpr size() method whose return value is equal to Size, and a
+  // data() method whose return value converts implicitly to T*. In particular,
+  // this means we allow conversion from ArrayView<T, N> to ArrayView<const T,
+  // N>, but not the other way around. We also don't allow conversion from
+  // ArrayView<T> to ArrayView<T, N>, or from ArrayView<T, M> to ArrayView<T,
+  // N> when M != N.
+  template <
+      typename U,
+      typename std::enable_if<Size != impl::kArrayViewVarSize &&
+                              HasDataAndSize<U, T>::value>::type* = nullptr>
+  ArrayView(U& u)  // NOLINT
+      : ArrayView(u.data(), u.size()) {
+    static_assert(U::size() == Size, "Sizes must match exactly");
+  }
+  template <
+      typename U,
+      typename std::enable_if<Size != impl::kArrayViewVarSize &&
+                              HasDataAndSize<U, T>::value>::type* = nullptr>
+  ArrayView(const U& u)  // NOLINT(runtime/explicit)
+      : ArrayView(u.data(), u.size()) {
+    static_assert(U::size() == Size, "Sizes must match exactly");
+  }
+
+  // (Only if size is variable.) Construct an ArrayView from any type U that
+  // has a size() method whose return value converts implicitly to size_t, and
+  // a data() method whose return value converts implicitly to T*. In
+  // particular, this means we allow conversion from ArrayView<T> to
+  // ArrayView<const T>, but not the other way around. Other allowed
+  // conversions include
+  // ArrayView<T, N> to ArrayView<T> or ArrayView<const T>,
+  // std::vector<T> to ArrayView<T> or ArrayView<const T>,
+  // const std::vector<T> to ArrayView<const T>,
+  // rtc::Buffer to ArrayView<uint8_t> or ArrayView<const uint8_t>, and
+  // const rtc::Buffer to ArrayView<const uint8_t>.
+  template <
+      typename U,
+      typename std::enable_if<Size == impl::kArrayViewVarSize &&
+                              HasDataAndSize<U, T>::value>::type* = nullptr>
+  ArrayView(U& u)  // NOLINT
+      : ArrayView(u.data(), u.size()) {}
+  template <
+      typename U,
+      typename std::enable_if<Size == impl::kArrayViewVarSize &&
+                              HasDataAndSize<U, T>::value>::type* = nullptr>
+  ArrayView(const U& u)  // NOLINT(runtime/explicit)
+      : ArrayView(u.data(), u.size()) {}
+
+  // Indexing and iteration. These allow mutation even if the ArrayView is
+  // const, because the ArrayView doesn't own the array. (To prevent mutation,
+  // use a const element type.)
+  T& operator[](size_t idx) const {
+    RTC_DCHECK_LT(idx, this->size());
+    RTC_DCHECK(this->data());
+    return this->data()[idx];
+  }
+  T* begin() const { return this->data(); }
+  T* end() const { return this->data() + this->size(); }
+  const T* cbegin() const { return this->data(); }
+  const T* cend() const { return this->data() + this->size(); }
+  std::reverse_iterator<T*> rbegin() const {
+    return std::make_reverse_iterator(end());
+  }
+  std::reverse_iterator<T*> rend() const {
+    return std::make_reverse_iterator(begin());
+  }
+  std::reverse_iterator<const T*> crbegin() const {
+    return std::make_reverse_iterator(cend());
+  }
+  std::reverse_iterator<const T*> crend() const {
+    return std::make_reverse_iterator(cbegin());
+  }
+
+  ArrayView<T> subview(size_t offset, size_t size) const {
+    return offset < this->size()
+               ? ArrayView<T>(this->data() + offset,
+                              std::min(size, this->size() - offset))
+               : ArrayView<T>();
+  }
+  ArrayView<T> subview(size_t offset) const {
+    return subview(offset, this->size());
+  }
+};
+
+// Comparing two ArrayViews compares their (pointer,size) pairs; it does *not*
+// dereference the pointers.
+template <typename T, std::ptrdiff_t Size1, std::ptrdiff_t Size2>
+bool operator==(const ArrayView<T, Size1>& a, const ArrayView<T, Size2>& b) {
+  return a.data() == b.data() && a.size() == b.size();
+}
+template <typename T, std::ptrdiff_t Size1, std::ptrdiff_t Size2>
+bool operator!=(const ArrayView<T, Size1>& a, const ArrayView<T, Size2>& b) {
+  return !(a == b);
+}
+
+// Variable-size ArrayViews are the size of two pointers; fixed-size ArrayViews
+// are the size of one pointer. (And as a special case, fixed-size ArrayViews
+// of size 0 require no storage.)
+static_assert(sizeof(ArrayView<int>) == 2 * sizeof(int*), "");
+static_assert(sizeof(ArrayView<int, 17>) == sizeof(int*), "");
+static_assert(std::is_empty<ArrayView<int, 0>>::value, "");
+
+template <typename T>
+inline ArrayView<T> MakeArrayView(T* data, size_t size) {
+  return ArrayView<T>(data, size);
+}
+
+// Only for primitive types that have the same size and aligment.
+// Allow reinterpret cast of the array view to another primitive type of the
+// same size.
+// Template arguments order is (U, T, Size) to allow deduction of the template
+// arguments in client calls: reinterpret_array_view<target_type>(array_view).
+template <typename U, typename T, std::ptrdiff_t Size>
+inline ArrayView<U, Size> reinterpret_array_view(ArrayView<T, Size> view) {
+  static_assert(sizeof(U) == sizeof(T) && alignof(U) == alignof(T),
+                "ArrayView reinterpret_cast is only supported for casting "
+                "between views that represent the same chunk of memory.");
+  static_assert(
+      std::is_fundamental<T>::value && std::is_fundamental<U>::value,
+      "ArrayView reinterpret_cast is only supported for casting between "
+      "fundamental types.");
+  return ArrayView<U, Size>(reinterpret_cast<U*>(view.data()), view.size());
+}
+
+}  // namespace rtc
+
+#endif  // API_ARRAY_VIEW_H_
diff --git a/third_party/webrtc_aec3/src/api/audio/BUILD.gn b/third_party/webrtc_aec3/src/api/audio/BUILD.gn
new file mode 100644
index 0000000..d0465bb
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/BUILD.gn
@@ -0,0 +1,108 @@
+# Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+#
+# Use of this source code is governed by a BSD-style license
+# that can be found in the LICENSE file in the root of the source
+# tree. An additional intellectual property rights grant can be found
+# in the file PATENTS.  All contributing project authors may
+# be found in the AUTHORS file in the root of the source tree.
+
+import("../../webrtc.gni")
+
+rtc_library("audio_frame_api") {
+  visibility = [ "*" ]
+  sources = [
+    "audio_frame.cc",
+    "audio_frame.h",
+    "channel_layout.cc",
+    "channel_layout.h",
+  ]
+
+  deps = [
+    "..:rtp_packet_info",
+    "../../rtc_base:checks",
+    "../../rtc_base:rtc_base_approved",
+  ]
+}
+
+rtc_source_set("audio_frame_processor") {
+  visibility = [ "*" ]
+  sources = [ "audio_frame_processor.h" ]
+}
+
+rtc_source_set("audio_mixer_api") {
+  visibility = [ "*" ]
+  sources = [ "audio_mixer.h" ]
+
+  deps = [
+    ":audio_frame_api",
+    "../../rtc_base:rtc_base_approved",
+  ]
+}
+
+rtc_library("aec3_config") {
+  visibility = [ "*" ]
+  sources = [
+    "echo_canceller3_config.cc",
+    "echo_canceller3_config.h",
+  ]
+  deps = [
+    "../../rtc_base:checks",
+    "../../rtc_base:rtc_base_approved",
+    "../../rtc_base:safe_minmax",
+    "../../rtc_base/system:rtc_export",
+  ]
+}
+
+rtc_library("aec3_config_json") {
+  visibility = [ "*" ]
+  allow_poison = [ "rtc_json" ]
+  sources = [
+    "echo_canceller3_config_json.cc",
+    "echo_canceller3_config_json.h",
+  ]
+  deps = [
+    ":aec3_config",
+    "../../rtc_base:checks",
+    "../../rtc_base:rtc_base_approved",
+    "../../rtc_base:rtc_json",
+    "../../rtc_base/system:rtc_export",
+  ]
+  absl_deps = [ "//third_party/abseil-cpp/absl/strings" ]
+}
+
+rtc_library("aec3_factory") {
+  visibility = [ "*" ]
+  configs += [ "../../modules/audio_processing:apm_debug_dump" ]
+  sources = [
+    "echo_canceller3_factory.cc",
+    "echo_canceller3_factory.h",
+  ]
+
+  deps = [
+    ":aec3_config",
+    ":echo_control",
+    "../../modules/audio_processing/aec3",
+    "../../rtc_base:rtc_base_approved",
+    "../../rtc_base/system:rtc_export",
+  ]
+}
+
+rtc_source_set("echo_control") {
+  visibility = [ "*" ]
+  sources = [ "echo_control.h" ]
+  deps = [ "../../rtc_base:checks" ]
+}
+
+rtc_source_set("echo_detector_creator") {
+  visibility = [ "*" ]
+  sources = [
+    "echo_detector_creator.cc",
+    "echo_detector_creator.h",
+  ]
+  deps = [
+    "../../api:scoped_refptr",
+    "../../modules/audio_processing:api",
+    "../../modules/audio_processing:audio_processing",
+    "../../rtc_base:refcount",
+  ]
+}
diff --git a/third_party/webrtc_aec3/src/api/audio/OWNERS b/third_party/webrtc_aec3/src/api/audio/OWNERS
new file mode 100644
index 0000000..bb499b4
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/OWNERS
@@ -0,0 +1,2 @@
+gustaf@webrtc.org
+peah@webrtc.org
diff --git a/third_party/webrtc_aec3/src/api/audio/audio_frame.cc b/third_party/webrtc_aec3/src/api/audio/audio_frame.cc
new file mode 100644
index 0000000..c6e5cf4
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/audio_frame.cc
@@ -0,0 +1,164 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "api/audio/audio_frame.h"
+
+#include <string.h>
+#include <algorithm>
+#include <utility>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/time_utils.h"
+
+namespace webrtc {
+
+AudioFrame::AudioFrame() {
+  // Visual Studio doesn't like this in the class definition.
+  static_assert(sizeof(data_) == kMaxDataSizeBytes, "kMaxDataSizeBytes");
+}
+
+void swap(AudioFrame& a, AudioFrame& b) {
+  using std::swap;
+  swap(a.timestamp_, b.timestamp_);
+  swap(a.elapsed_time_ms_, b.elapsed_time_ms_);
+  swap(a.ntp_time_ms_, b.ntp_time_ms_);
+  swap(a.samples_per_channel_, b.samples_per_channel_);
+  swap(a.sample_rate_hz_, b.sample_rate_hz_);
+  swap(a.num_channels_, b.num_channels_);
+  swap(a.channel_layout_, b.channel_layout_);
+  swap(a.speech_type_, b.speech_type_);
+  swap(a.vad_activity_, b.vad_activity_);
+  swap(a.profile_timestamp_ms_, b.profile_timestamp_ms_);
+  swap(a.packet_infos_, b.packet_infos_);
+  const size_t length_a = a.samples_per_channel_ * a.num_channels_;
+  const size_t length_b = b.samples_per_channel_ * b.num_channels_;
+  RTC_DCHECK_LE(length_a, AudioFrame::kMaxDataSizeSamples);
+  RTC_DCHECK_LE(length_b, AudioFrame::kMaxDataSizeSamples);
+  std::swap_ranges(a.data_, a.data_ + std::max(length_a, length_b), b.data_);
+  swap(a.muted_, b.muted_);
+  swap(a.absolute_capture_timestamp_ms_, b.absolute_capture_timestamp_ms_);
+}
+
+void AudioFrame::Reset() {
+  ResetWithoutMuting();
+  muted_ = true;
+}
+
+void AudioFrame::ResetWithoutMuting() {
+  // TODO(wu): Zero is a valid value for |timestamp_|. We should initialize
+  // to an invalid value, or add a new member to indicate invalidity.
+  timestamp_ = 0;
+  elapsed_time_ms_ = -1;
+  ntp_time_ms_ = -1;
+  samples_per_channel_ = 0;
+  sample_rate_hz_ = 0;
+  num_channels_ = 0;
+  channel_layout_ = CHANNEL_LAYOUT_NONE;
+  speech_type_ = kUndefined;
+  vad_activity_ = kVadUnknown;
+  profile_timestamp_ms_ = 0;
+  packet_infos_ = RtpPacketInfos();
+  absolute_capture_timestamp_ms_ = absl::nullopt;
+}
+
+void AudioFrame::UpdateFrame(uint32_t timestamp,
+                             const int16_t* data,
+                             size_t samples_per_channel,
+                             int sample_rate_hz,
+                             SpeechType speech_type,
+                             VADActivity vad_activity,
+                             size_t num_channels) {
+  timestamp_ = timestamp;
+  samples_per_channel_ = samples_per_channel;
+  sample_rate_hz_ = sample_rate_hz;
+  speech_type_ = speech_type;
+  vad_activity_ = vad_activity;
+  num_channels_ = num_channels;
+  channel_layout_ = GuessChannelLayout(num_channels);
+  if (channel_layout_ != CHANNEL_LAYOUT_UNSUPPORTED) {
+    RTC_DCHECK_EQ(num_channels, ChannelLayoutToChannelCount(channel_layout_));
+  }
+
+  const size_t length = samples_per_channel * num_channels;
+  RTC_CHECK_LE(length, kMaxDataSizeSamples);
+  if (data != nullptr) {
+    memcpy(data_, data, sizeof(int16_t) * length);
+    muted_ = false;
+  } else {
+    muted_ = true;
+  }
+}
+
+void AudioFrame::CopyFrom(const AudioFrame& src) {
+  if (this == &src)
+    return;
+
+  timestamp_ = src.timestamp_;
+  elapsed_time_ms_ = src.elapsed_time_ms_;
+  ntp_time_ms_ = src.ntp_time_ms_;
+  packet_infos_ = src.packet_infos_;
+  muted_ = src.muted();
+  samples_per_channel_ = src.samples_per_channel_;
+  sample_rate_hz_ = src.sample_rate_hz_;
+  speech_type_ = src.speech_type_;
+  vad_activity_ = src.vad_activity_;
+  num_channels_ = src.num_channels_;
+  channel_layout_ = src.channel_layout_;
+  absolute_capture_timestamp_ms_ = src.absolute_capture_timestamp_ms();
+
+  const size_t length = samples_per_channel_ * num_channels_;
+  RTC_CHECK_LE(length, kMaxDataSizeSamples);
+  if (!src.muted()) {
+    memcpy(data_, src.data(), sizeof(int16_t) * length);
+    muted_ = false;
+  }
+}
+
+void AudioFrame::UpdateProfileTimeStamp() {
+  profile_timestamp_ms_ = rtc::TimeMillis();
+}
+
+int64_t AudioFrame::ElapsedProfileTimeMs() const {
+  if (profile_timestamp_ms_ == 0) {
+    // Profiling has not been activated.
+    return -1;
+  }
+  return rtc::TimeSince(profile_timestamp_ms_);
+}
+
+const int16_t* AudioFrame::data() const {
+  return muted_ ? empty_data() : data_;
+}
+
+// TODO(henrik.lundin) Can we skip zeroing the buffer?
+// See https://bugs.chromium.org/p/webrtc/issues/detail?id=5647.
+int16_t* AudioFrame::mutable_data() {
+  if (muted_) {
+    memset(data_, 0, kMaxDataSizeBytes);
+    muted_ = false;
+  }
+  return data_;
+}
+
+void AudioFrame::Mute() {
+  muted_ = true;
+}
+
+bool AudioFrame::muted() const {
+  return muted_;
+}
+
+// static
+const int16_t* AudioFrame::empty_data() {
+  static int16_t* null_data = new int16_t[kMaxDataSizeSamples]();
+  return &null_data[0];
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/api/audio/audio_frame.h b/third_party/webrtc_aec3/src/api/audio/audio_frame.h
new file mode 100644
index 0000000..78539f5
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/audio_frame.h
@@ -0,0 +1,177 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef API_AUDIO_AUDIO_FRAME_H_
+#define API_AUDIO_AUDIO_FRAME_H_
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include <utility>
+
+#include "api/audio/channel_layout.h"
+#include "api/rtp_packet_infos.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+/* This class holds up to 120 ms of super-wideband (32 kHz) stereo audio. It
+ * allows for adding and subtracting frames while keeping track of the resulting
+ * states.
+ *
+ * Notes
+ * - This is a de-facto api, not designed for external use. The AudioFrame class
+ *   is in need of overhaul or even replacement, and anyone depending on it
+ *   should be prepared for that.
+ * - The total number of samples is samples_per_channel_ * num_channels_.
+ * - Stereo data is interleaved starting with the left channel.
+ */
+class AudioFrame {
+ public:
+  // Using constexpr here causes linker errors unless the variable also has an
+  // out-of-class definition, which is impractical in this header-only class.
+  // (This makes no sense because it compiles as an enum value, which we most
+  // certainly cannot take the address of, just fine.) C++17 introduces inline
+  // variables which should allow us to switch to constexpr and keep this a
+  // header-only class.
+  enum : size_t {
+    // Stereo, 32 kHz, 120 ms (2 * 32 * 120)
+    // Stereo, 192 kHz, 20 ms (2 * 192 * 20)
+    kMaxDataSizeSamples = 7680,
+    kMaxDataSizeBytes = kMaxDataSizeSamples * sizeof(int16_t),
+  };
+
+  enum VADActivity { kVadActive = 0, kVadPassive = 1, kVadUnknown = 2 };
+  enum SpeechType {
+    kNormalSpeech = 0,
+    kPLC = 1,
+    kCNG = 2,
+    kPLCCNG = 3,
+    kCodecPLC = 5,
+    kUndefined = 4
+  };
+
+  AudioFrame();
+
+  friend void swap(AudioFrame& a, AudioFrame& b);
+
+  // Resets all members to their default state.
+  void Reset();
+  // Same as Reset(), but leaves mute state unchanged. Muting a frame requires
+  // the buffer to be zeroed on the next call to mutable_data(). Callers
+  // intending to write to the buffer immediately after Reset() can instead use
+  // ResetWithoutMuting() to skip this wasteful zeroing.
+  void ResetWithoutMuting();
+
+  void UpdateFrame(uint32_t timestamp,
+                   const int16_t* data,
+                   size_t samples_per_channel,
+                   int sample_rate_hz,
+                   SpeechType speech_type,
+                   VADActivity vad_activity,
+                   size_t num_channels = 1);
+
+  void CopyFrom(const AudioFrame& src);
+
+  // Sets a wall-time clock timestamp in milliseconds to be used for profiling
+  // of time between two points in the audio chain.
+  // Example:
+  //   t0: UpdateProfileTimeStamp()
+  //   t1: ElapsedProfileTimeMs() => t1 - t0 [msec]
+  void UpdateProfileTimeStamp();
+  // Returns the time difference between now and when UpdateProfileTimeStamp()
+  // was last called. Returns -1 if UpdateProfileTimeStamp() has not yet been
+  // called.
+  int64_t ElapsedProfileTimeMs() const;
+
+  // data() returns a zeroed static buffer if the frame is muted.
+  // mutable_frame() always returns a non-static buffer; the first call to
+  // mutable_frame() zeros the non-static buffer and marks the frame unmuted.
+  const int16_t* data() const;
+  int16_t* mutable_data();
+
+  // Prefer to mute frames using AudioFrameOperations::Mute.
+  void Mute();
+  // Frame is muted by default.
+  bool muted() const;
+
+  size_t max_16bit_samples() const { return kMaxDataSizeSamples; }
+  size_t samples_per_channel() const { return samples_per_channel_; }
+  size_t num_channels() const { return num_channels_; }
+  ChannelLayout channel_layout() const { return channel_layout_; }
+  int sample_rate_hz() const { return sample_rate_hz_; }
+
+  void set_absolute_capture_timestamp_ms(
+      int64_t absolute_capture_time_stamp_ms) {
+    absolute_capture_timestamp_ms_ = absolute_capture_time_stamp_ms;
+  }
+
+  absl::optional<int64_t> absolute_capture_timestamp_ms() const {
+    return absolute_capture_timestamp_ms_;
+  }
+
+  // RTP timestamp of the first sample in the AudioFrame.
+  uint32_t timestamp_ = 0;
+  // Time since the first frame in milliseconds.
+  // -1 represents an uninitialized value.
+  int64_t elapsed_time_ms_ = -1;
+  // NTP time of the estimated capture time in local timebase in milliseconds.
+  // -1 represents an uninitialized value.
+  int64_t ntp_time_ms_ = -1;
+  size_t samples_per_channel_ = 0;
+  int sample_rate_hz_ = 0;
+  size_t num_channels_ = 0;
+  ChannelLayout channel_layout_ = CHANNEL_LAYOUT_NONE;
+  SpeechType speech_type_ = kUndefined;
+  VADActivity vad_activity_ = kVadUnknown;
+  // Monotonically increasing timestamp intended for profiling of audio frames.
+  // Typically used for measuring elapsed time between two different points in
+  // the audio path. No lock is used to save resources and we are thread safe
+  // by design.
+  // TODO(nisse@webrtc.org): consider using absl::optional.
+  int64_t profile_timestamp_ms_ = 0;
+
+  // Information about packets used to assemble this audio frame. This is needed
+  // by |SourceTracker| when the frame is delivered to the RTCRtpReceiver's
+  // MediaStreamTrack, in order to implement getContributingSources(). See:
+  // https://w3c.github.io/webrtc-pc/#dom-rtcrtpreceiver-getcontributingsources
+  //
+  // TODO(bugs.webrtc.org/10757):
+  //   Note that this information might not be fully accurate since we currently
+  //   don't have a proper way to track it across the audio sync buffer. The
+  //   sync buffer is the small sample-holding buffer located after the audio
+  //   decoder and before where samples are assembled into output frames.
+  //
+  // |RtpPacketInfos| may also be empty if the audio samples did not come from
+  // RTP packets. E.g. if the audio were locally generated by packet loss
+  // concealment, comfort noise generation, etc.
+  RtpPacketInfos packet_infos_;
+
+ private:
+  // A permanently zeroed out buffer to represent muted frames. This is a
+  // header-only class, so the only way to avoid creating a separate empty
+  // buffer per translation unit is to wrap a static in an inline function.
+  static const int16_t* empty_data();
+
+  int16_t data_[kMaxDataSizeSamples];
+  bool muted_ = true;
+
+  // Absolute capture timestamp when this audio frame was originally captured.
+  // This is only valid for audio frames captured on this machine. The absolute
+  // capture timestamp of a received frame is found in |packet_infos_|.
+  // This timestamp MUST be based on the same clock as rtc::TimeMillis().
+  absl::optional<int64_t> absolute_capture_timestamp_ms_;
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(AudioFrame);
+};
+
+}  // namespace webrtc
+
+#endif  // API_AUDIO_AUDIO_FRAME_H_
diff --git a/third_party/webrtc_aec3/src/api/audio/audio_frame_processor.h b/third_party/webrtc_aec3/src/api/audio/audio_frame_processor.h
new file mode 100644
index 0000000..bc21d14
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/audio_frame_processor.h
@@ -0,0 +1,43 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef API_AUDIO_AUDIO_FRAME_PROCESSOR_H_
+#define API_AUDIO_AUDIO_FRAME_PROCESSOR_H_
+
+#include <functional>
+#include <memory>
+
+namespace webrtc {
+
+class AudioFrame;
+
+// If passed into PeerConnectionFactory, will be used for additional
+// processing of captured audio frames, performed before encoding.
+// Implementations must be thread-safe.
+class AudioFrameProcessor {
+ public:
+  using OnAudioFrameCallback = std::function<void(std::unique_ptr<AudioFrame>)>;
+  virtual ~AudioFrameProcessor() = default;
+
+  // Processes the frame received from WebRTC, is called by WebRTC off the
+  // realtime audio capturing path. AudioFrameProcessor must reply with
+  // processed frames by calling |sink_callback| if it was provided in SetSink()
+  // call. |sink_callback| can be called in the context of Process().
+  virtual void Process(std::unique_ptr<AudioFrame> frame) = 0;
+
+  // Atomically replaces the current sink with the new one. Before the
+  // first call to this function, or if the provided |sink_callback| is nullptr,
+  // processed frames are simply discarded.
+  virtual void SetSink(OnAudioFrameCallback sink_callback) = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // API_AUDIO_AUDIO_FRAME_PROCESSOR_H_
diff --git a/third_party/webrtc_aec3/src/api/audio/audio_mixer.h b/third_party/webrtc_aec3/src/api/audio/audio_mixer.h
new file mode 100644
index 0000000..b290cfa
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/audio_mixer.h
@@ -0,0 +1,80 @@
+/*
+ *  Copyright (c) 2011 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef API_AUDIO_AUDIO_MIXER_H_
+#define API_AUDIO_AUDIO_MIXER_H_
+
+#include <memory>
+
+#include "api/audio/audio_frame.h"
+#include "rtc_base/ref_count.h"
+
+namespace webrtc {
+
+// WORK IN PROGRESS
+// This class is under development and is not yet intended for for use outside
+// of WebRtc/Libjingle.
+class AudioMixer : public rtc::RefCountInterface {
+ public:
+  // A callback class that all mixer participants must inherit from/implement.
+  class Source {
+   public:
+    enum class AudioFrameInfo {
+      kNormal,  // The samples in audio_frame are valid and should be used.
+      kMuted,   // The samples in audio_frame should not be used, but
+                // should be implicitly interpreted as zero. Other
+                // fields in audio_frame may be read and should
+                // contain meaningful values.
+      kError,   // The audio_frame will not be used.
+    };
+
+    // Overwrites |audio_frame|. The data_ field is overwritten with
+    // 10 ms of new audio (either 1 or 2 interleaved channels) at
+    // |sample_rate_hz|. All fields in |audio_frame| must be updated.
+    virtual AudioFrameInfo GetAudioFrameWithInfo(int sample_rate_hz,
+                                                 AudioFrame* audio_frame) = 0;
+
+    // A way for a mixer implementation to distinguish participants.
+    virtual int Ssrc() const = 0;
+
+    // A way for this source to say that GetAudioFrameWithInfo called
+    // with this sample rate or higher will not cause quality loss.
+    virtual int PreferredSampleRate() const = 0;
+
+    virtual ~Source() {}
+  };
+
+  // Returns true if adding was successful. A source is never added
+  // twice. Addition and removal can happen on different threads.
+  virtual bool AddSource(Source* audio_source) = 0;
+
+  // Removal is never attempted if a source has not been successfully
+  // added to the mixer.
+  virtual void RemoveSource(Source* audio_source) = 0;
+
+  // Performs mixing by asking registered audio sources for audio. The
+  // mixed result is placed in the provided AudioFrame. This method
+  // will only be called from a single thread. The channels argument
+  // specifies the number of channels of the mix result. The mixer
+  // should mix at a rate that doesn't cause quality loss of the
+  // sources' audio. The mixing rate is one of the rates listed in
+  // AudioProcessing::NativeRate. All fields in
+  // |audio_frame_for_mixing| must be updated.
+  virtual void Mix(size_t number_of_channels,
+                   AudioFrame* audio_frame_for_mixing) = 0;
+
+ protected:
+  // Since the mixer is reference counted, the destructor may be
+  // called from any thread.
+  ~AudioMixer() override {}
+};
+}  // namespace webrtc
+
+#endif  // API_AUDIO_AUDIO_MIXER_H_
diff --git a/third_party/webrtc_aec3/src/api/audio/channel_layout.cc b/third_party/webrtc_aec3/src/api/audio/channel_layout.cc
new file mode 100644
index 0000000..567f4d9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/channel_layout.cc
@@ -0,0 +1,282 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "api/audio/channel_layout.h"
+
+#include <stddef.h>
+
+#include "rtc_base/arraysize.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+
+namespace webrtc {
+
+static const int kLayoutToChannels[] = {
+    0,  // CHANNEL_LAYOUT_NONE
+    0,  // CHANNEL_LAYOUT_UNSUPPORTED
+    1,  // CHANNEL_LAYOUT_MONO
+    2,  // CHANNEL_LAYOUT_STEREO
+    3,  // CHANNEL_LAYOUT_2_1
+    3,  // CHANNEL_LAYOUT_SURROUND
+    4,  // CHANNEL_LAYOUT_4_0
+    4,  // CHANNEL_LAYOUT_2_2
+    4,  // CHANNEL_LAYOUT_QUAD
+    5,  // CHANNEL_LAYOUT_5_0
+    6,  // CHANNEL_LAYOUT_5_1
+    5,  // CHANNEL_LAYOUT_5_0_BACK
+    6,  // CHANNEL_LAYOUT_5_1_BACK
+    7,  // CHANNEL_LAYOUT_7_0
+    8,  // CHANNEL_LAYOUT_7_1
+    8,  // CHANNEL_LAYOUT_7_1_WIDE
+    2,  // CHANNEL_LAYOUT_STEREO_DOWNMIX
+    3,  // CHANNEL_LAYOUT_2POINT1
+    4,  // CHANNEL_LAYOUT_3_1
+    5,  // CHANNEL_LAYOUT_4_1
+    6,  // CHANNEL_LAYOUT_6_0
+    6,  // CHANNEL_LAYOUT_6_0_FRONT
+    6,  // CHANNEL_LAYOUT_HEXAGONAL
+    7,  // CHANNEL_LAYOUT_6_1
+    7,  // CHANNEL_LAYOUT_6_1_BACK
+    7,  // CHANNEL_LAYOUT_6_1_FRONT
+    7,  // CHANNEL_LAYOUT_7_0_FRONT
+    8,  // CHANNEL_LAYOUT_7_1_WIDE_BACK
+    8,  // CHANNEL_LAYOUT_OCTAGONAL
+    0,  // CHANNEL_LAYOUT_DISCRETE
+    3,  // CHANNEL_LAYOUT_STEREO_AND_KEYBOARD_MIC
+    5,  // CHANNEL_LAYOUT_4_1_QUAD_SIDE
+    0,  // CHANNEL_LAYOUT_BITSTREAM
+};
+
+// The channel orderings for each layout as specified by FFmpeg. Each value
+// represents the index of each channel in each layout.  Values of -1 mean the
+// channel at that index is not used for that layout. For example, the left side
+// surround sound channel in FFmpeg's 5.1 layout is in the 5th position (because
+// the order is L, R, C, LFE, LS, RS), so
+// kChannelOrderings[CHANNEL_LAYOUT_5_1][SIDE_LEFT] = 4;
+static const int kChannelOrderings[CHANNEL_LAYOUT_MAX + 1][CHANNELS_MAX + 1] = {
+    // FL | FR | FC | LFE | BL | BR | FLofC | FRofC | BC | SL | SR
+
+    // CHANNEL_LAYOUT_NONE
+    {-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1},
+
+    // CHANNEL_LAYOUT_UNSUPPORTED
+    {-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1},
+
+    // CHANNEL_LAYOUT_MONO
+    {-1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1},
+
+    // CHANNEL_LAYOUT_STEREO
+    {0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1},
+
+    // CHANNEL_LAYOUT_2_1
+    {0, 1, -1, -1, -1, -1, -1, -1, 2, -1, -1},
+
+    // CHANNEL_LAYOUT_SURROUND
+    {0, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1},
+
+    // CHANNEL_LAYOUT_4_0
+    {0, 1, 2, -1, -1, -1, -1, -1, 3, -1, -1},
+
+    // CHANNEL_LAYOUT_2_2
+    {0, 1, -1, -1, -1, -1, -1, -1, -1, 2, 3},
+
+    // CHANNEL_LAYOUT_QUAD
+    {0, 1, -1, -1, 2, 3, -1, -1, -1, -1, -1},
+
+    // CHANNEL_LAYOUT_5_0
+    {0, 1, 2, -1, -1, -1, -1, -1, -1, 3, 4},
+
+    // CHANNEL_LAYOUT_5_1
+    {0, 1, 2, 3, -1, -1, -1, -1, -1, 4, 5},
+
+    // FL | FR | FC | LFE | BL | BR | FLofC | FRofC | BC | SL | SR
+
+    // CHANNEL_LAYOUT_5_0_BACK
+    {0, 1, 2, -1, 3, 4, -1, -1, -1, -1, -1},
+
+    // CHANNEL_LAYOUT_5_1_BACK
+    {0, 1, 2, 3, 4, 5, -1, -1, -1, -1, -1},
+
+    // CHANNEL_LAYOUT_7_0
+    {0, 1, 2, -1, 5, 6, -1, -1, -1, 3, 4},
+
+    // CHANNEL_LAYOUT_7_1
+    {0, 1, 2, 3, 6, 7, -1, -1, -1, 4, 5},
+
+    // CHANNEL_LAYOUT_7_1_WIDE
+    {0, 1, 2, 3, -1, -1, 6, 7, -1, 4, 5},
+
+    // CHANNEL_LAYOUT_STEREO_DOWNMIX
+    {0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1},
+
+    // CHANNEL_LAYOUT_2POINT1
+    {0, 1, -1, 2, -1, -1, -1, -1, -1, -1, -1},
+
+    // CHANNEL_LAYOUT_3_1
+    {0, 1, 2, 3, -1, -1, -1, -1, -1, -1, -1},
+
+    // CHANNEL_LAYOUT_4_1
+    {0, 1, 2, 4, -1, -1, -1, -1, 3, -1, -1},
+
+    // CHANNEL_LAYOUT_6_0
+    {0, 1, 2, -1, -1, -1, -1, -1, 5, 3, 4},
+
+    // CHANNEL_LAYOUT_6_0_FRONT
+    {0, 1, -1, -1, -1, -1, 4, 5, -1, 2, 3},
+
+    // FL | FR | FC | LFE | BL | BR | FLofC | FRofC | BC | SL | SR
+
+    // CHANNEL_LAYOUT_HEXAGONAL
+    {0, 1, 2, -1, 3, 4, -1, -1, 5, -1, -1},
+
+    // CHANNEL_LAYOUT_6_1
+    {0, 1, 2, 3, -1, -1, -1, -1, 6, 4, 5},
+
+    // CHANNEL_LAYOUT_6_1_BACK
+    {0, 1, 2, 3, 4, 5, -1, -1, 6, -1, -1},
+
+    // CHANNEL_LAYOUT_6_1_FRONT
+    {0, 1, -1, 6, -1, -1, 4, 5, -1, 2, 3},
+
+    // CHANNEL_LAYOUT_7_0_FRONT
+    {0, 1, 2, -1, -1, -1, 5, 6, -1, 3, 4},
+
+    // CHANNEL_LAYOUT_7_1_WIDE_BACK
+    {0, 1, 2, 3, 4, 5, 6, 7, -1, -1, -1},
+
+    // CHANNEL_LAYOUT_OCTAGONAL
+    {0, 1, 2, -1, 5, 6, -1, -1, 7, 3, 4},
+
+    // CHANNEL_LAYOUT_DISCRETE
+    {-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1},
+
+    // CHANNEL_LAYOUT_STEREO_AND_KEYBOARD_MIC
+    {0, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1},
+
+    // CHANNEL_LAYOUT_4_1_QUAD_SIDE
+    {0, 1, -1, 4, -1, -1, -1, -1, -1, 2, 3},
+
+    // CHANNEL_LAYOUT_BITSTREAM
+    {-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1},
+
+    // FL | FR | FC | LFE | BL | BR | FLofC | FRofC | BC | SL | SR
+};
+
+int ChannelLayoutToChannelCount(ChannelLayout layout) {
+  RTC_DCHECK_LT(static_cast<size_t>(layout), arraysize(kLayoutToChannels));
+  RTC_DCHECK_LE(kLayoutToChannels[layout], kMaxConcurrentChannels);
+  return kLayoutToChannels[layout];
+}
+
+// Converts a channel count into a channel layout.
+ChannelLayout GuessChannelLayout(int channels) {
+  switch (channels) {
+    case 1:
+      return CHANNEL_LAYOUT_MONO;
+    case 2:
+      return CHANNEL_LAYOUT_STEREO;
+    case 3:
+      return CHANNEL_LAYOUT_SURROUND;
+    case 4:
+      return CHANNEL_LAYOUT_QUAD;
+    case 5:
+      return CHANNEL_LAYOUT_5_0;
+    case 6:
+      return CHANNEL_LAYOUT_5_1;
+    case 7:
+      return CHANNEL_LAYOUT_6_1;
+    case 8:
+      return CHANNEL_LAYOUT_7_1;
+    default:
+      RTC_DLOG(LS_WARNING) << "Unsupported channel count: " << channels;
+  }
+  return CHANNEL_LAYOUT_UNSUPPORTED;
+}
+
+int ChannelOrder(ChannelLayout layout, Channels channel) {
+  RTC_DCHECK_LT(static_cast<size_t>(layout), arraysize(kChannelOrderings));
+  RTC_DCHECK_LT(static_cast<size_t>(channel), arraysize(kChannelOrderings[0]));
+  return kChannelOrderings[layout][channel];
+}
+
+const char* ChannelLayoutToString(ChannelLayout layout) {
+  switch (layout) {
+    case CHANNEL_LAYOUT_NONE:
+      return "NONE";
+    case CHANNEL_LAYOUT_UNSUPPORTED:
+      return "UNSUPPORTED";
+    case CHANNEL_LAYOUT_MONO:
+      return "MONO";
+    case CHANNEL_LAYOUT_STEREO:
+      return "STEREO";
+    case CHANNEL_LAYOUT_2_1:
+      return "2.1";
+    case CHANNEL_LAYOUT_SURROUND:
+      return "SURROUND";
+    case CHANNEL_LAYOUT_4_0:
+      return "4.0";
+    case CHANNEL_LAYOUT_2_2:
+      return "QUAD_SIDE";
+    case CHANNEL_LAYOUT_QUAD:
+      return "QUAD";
+    case CHANNEL_LAYOUT_5_0:
+      return "5.0";
+    case CHANNEL_LAYOUT_5_1:
+      return "5.1";
+    case CHANNEL_LAYOUT_5_0_BACK:
+      return "5.0_BACK";
+    case CHANNEL_LAYOUT_5_1_BACK:
+      return "5.1_BACK";
+    case CHANNEL_LAYOUT_7_0:
+      return "7.0";
+    case CHANNEL_LAYOUT_7_1:
+      return "7.1";
+    case CHANNEL_LAYOUT_7_1_WIDE:
+      return "7.1_WIDE";
+    case CHANNEL_LAYOUT_STEREO_DOWNMIX:
+      return "STEREO_DOWNMIX";
+    case CHANNEL_LAYOUT_2POINT1:
+      return "2POINT1";
+    case CHANNEL_LAYOUT_3_1:
+      return "3.1";
+    case CHANNEL_LAYOUT_4_1:
+      return "4.1";
+    case CHANNEL_LAYOUT_6_0:
+      return "6.0";
+    case CHANNEL_LAYOUT_6_0_FRONT:
+      return "6.0_FRONT";
+    case CHANNEL_LAYOUT_HEXAGONAL:
+      return "HEXAGONAL";
+    case CHANNEL_LAYOUT_6_1:
+      return "6.1";
+    case CHANNEL_LAYOUT_6_1_BACK:
+      return "6.1_BACK";
+    case CHANNEL_LAYOUT_6_1_FRONT:
+      return "6.1_FRONT";
+    case CHANNEL_LAYOUT_7_0_FRONT:
+      return "7.0_FRONT";
+    case CHANNEL_LAYOUT_7_1_WIDE_BACK:
+      return "7.1_WIDE_BACK";
+    case CHANNEL_LAYOUT_OCTAGONAL:
+      return "OCTAGONAL";
+    case CHANNEL_LAYOUT_DISCRETE:
+      return "DISCRETE";
+    case CHANNEL_LAYOUT_STEREO_AND_KEYBOARD_MIC:
+      return "STEREO_AND_KEYBOARD_MIC";
+    case CHANNEL_LAYOUT_4_1_QUAD_SIDE:
+      return "4.1_QUAD_SIDE";
+    case CHANNEL_LAYOUT_BITSTREAM:
+      return "BITSTREAM";
+  }
+  RTC_NOTREACHED() << "Invalid channel layout provided: " << layout;
+  return "";
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/api/audio/channel_layout.h b/third_party/webrtc_aec3/src/api/audio/channel_layout.h
new file mode 100644
index 0000000..175aee7
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/channel_layout.h
@@ -0,0 +1,165 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef API_AUDIO_CHANNEL_LAYOUT_H_
+#define API_AUDIO_CHANNEL_LAYOUT_H_
+
+namespace webrtc {
+
+// This file is derived from Chromium's base/channel_layout.h.
+
+// Enumerates the various representations of the ordering of audio channels.
+// Logged to UMA, so never reuse a value, always add new/greater ones!
+enum ChannelLayout {
+  CHANNEL_LAYOUT_NONE = 0,
+  CHANNEL_LAYOUT_UNSUPPORTED = 1,
+
+  // Front C
+  CHANNEL_LAYOUT_MONO = 2,
+
+  // Front L, Front R
+  CHANNEL_LAYOUT_STEREO = 3,
+
+  // Front L, Front R, Back C
+  CHANNEL_LAYOUT_2_1 = 4,
+
+  // Front L, Front R, Front C
+  CHANNEL_LAYOUT_SURROUND = 5,
+
+  // Front L, Front R, Front C, Back C
+  CHANNEL_LAYOUT_4_0 = 6,
+
+  // Front L, Front R, Side L, Side R
+  CHANNEL_LAYOUT_2_2 = 7,
+
+  // Front L, Front R, Back L, Back R
+  CHANNEL_LAYOUT_QUAD = 8,
+
+  // Front L, Front R, Front C, Side L, Side R
+  CHANNEL_LAYOUT_5_0 = 9,
+
+  // Front L, Front R, Front C, LFE, Side L, Side R
+  CHANNEL_LAYOUT_5_1 = 10,
+
+  // Front L, Front R, Front C, Back L, Back R
+  CHANNEL_LAYOUT_5_0_BACK = 11,
+
+  // Front L, Front R, Front C, LFE, Back L, Back R
+  CHANNEL_LAYOUT_5_1_BACK = 12,
+
+  // Front L, Front R, Front C, Side L, Side R, Back L, Back R
+  CHANNEL_LAYOUT_7_0 = 13,
+
+  // Front L, Front R, Front C, LFE, Side L, Side R, Back L, Back R
+  CHANNEL_LAYOUT_7_1 = 14,
+
+  // Front L, Front R, Front C, LFE, Side L, Side R, Front LofC, Front RofC
+  CHANNEL_LAYOUT_7_1_WIDE = 15,
+
+  // Stereo L, Stereo R
+  CHANNEL_LAYOUT_STEREO_DOWNMIX = 16,
+
+  // Stereo L, Stereo R, LFE
+  CHANNEL_LAYOUT_2POINT1 = 17,
+
+  // Stereo L, Stereo R, Front C, LFE
+  CHANNEL_LAYOUT_3_1 = 18,
+
+  // Stereo L, Stereo R, Front C, Rear C, LFE
+  CHANNEL_LAYOUT_4_1 = 19,
+
+  // Stereo L, Stereo R, Front C, Side L, Side R, Back C
+  CHANNEL_LAYOUT_6_0 = 20,
+
+  // Stereo L, Stereo R, Side L, Side R, Front LofC, Front RofC
+  CHANNEL_LAYOUT_6_0_FRONT = 21,
+
+  // Stereo L, Stereo R, Front C, Rear L, Rear R, Rear C
+  CHANNEL_LAYOUT_HEXAGONAL = 22,
+
+  // Stereo L, Stereo R, Front C, LFE, Side L, Side R, Rear Center
+  CHANNEL_LAYOUT_6_1 = 23,
+
+  // Stereo L, Stereo R, Front C, LFE, Back L, Back R, Rear Center
+  CHANNEL_LAYOUT_6_1_BACK = 24,
+
+  // Stereo L, Stereo R, Side L, Side R, Front LofC, Front RofC, LFE
+  CHANNEL_LAYOUT_6_1_FRONT = 25,
+
+  // Front L, Front R, Front C, Side L, Side R, Front LofC, Front RofC
+  CHANNEL_LAYOUT_7_0_FRONT = 26,
+
+  // Front L, Front R, Front C, LFE, Back L, Back R, Front LofC, Front RofC
+  CHANNEL_LAYOUT_7_1_WIDE_BACK = 27,
+
+  // Front L, Front R, Front C, Side L, Side R, Rear L, Back R, Back C.
+  CHANNEL_LAYOUT_OCTAGONAL = 28,
+
+  // Channels are not explicitly mapped to speakers.
+  CHANNEL_LAYOUT_DISCRETE = 29,
+
+  // Front L, Front R, Front C. Front C contains the keyboard mic audio. This
+  // layout is only intended for input for WebRTC. The Front C channel
+  // is stripped away in the WebRTC audio input pipeline and never seen outside
+  // of that.
+  CHANNEL_LAYOUT_STEREO_AND_KEYBOARD_MIC = 30,
+
+  // Front L, Front R, Side L, Side R, LFE
+  CHANNEL_LAYOUT_4_1_QUAD_SIDE = 31,
+
+  // Actual channel layout is specified in the bitstream and the actual channel
+  // count is unknown at Chromium media pipeline level (useful for audio
+  // pass-through mode).
+  CHANNEL_LAYOUT_BITSTREAM = 32,
+
+  // Max value, must always equal the largest entry ever logged.
+  CHANNEL_LAYOUT_MAX = CHANNEL_LAYOUT_BITSTREAM
+};
+
+// Note: Do not reorder or reassign these values; other code depends on their
+// ordering to operate correctly. E.g., CoreAudio channel layout computations.
+enum Channels {
+  LEFT = 0,
+  RIGHT,
+  CENTER,
+  LFE,
+  BACK_LEFT,
+  BACK_RIGHT,
+  LEFT_OF_CENTER,
+  RIGHT_OF_CENTER,
+  BACK_CENTER,
+  SIDE_LEFT,
+  SIDE_RIGHT,
+  CHANNELS_MAX =
+      SIDE_RIGHT,  // Must always equal the largest value ever logged.
+};
+
+// The maximum number of concurrently active channels for all possible layouts.
+// ChannelLayoutToChannelCount() will never return a value higher than this.
+constexpr int kMaxConcurrentChannels = 8;
+
+// Returns the expected channel position in an interleaved stream.  Values of -1
+// mean the channel at that index is not used for that layout.  Values range
+// from 0 to ChannelLayoutToChannelCount(layout) - 1.
+int ChannelOrder(ChannelLayout layout, Channels channel);
+
+// Returns the number of channels in a given ChannelLayout.
+int ChannelLayoutToChannelCount(ChannelLayout layout);
+
+// Given the number of channels, return the best layout,
+// or return CHANNEL_LAYOUT_UNSUPPORTED if there is no good match.
+ChannelLayout GuessChannelLayout(int channels);
+
+// Returns a string representation of the channel layout.
+const char* ChannelLayoutToString(ChannelLayout layout);
+
+}  // namespace webrtc
+
+#endif  // API_AUDIO_CHANNEL_LAYOUT_H_
diff --git a/third_party/webrtc_aec3/src/api/audio/echo_canceller3_config.cc b/third_party/webrtc_aec3/src/api/audio/echo_canceller3_config.cc
new file mode 100644
index 0000000..5f1923e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/echo_canceller3_config.cc
@@ -0,0 +1,271 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "api/audio/echo_canceller3_config.h"
+
+#include <algorithm>
+#include <cmath>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_minmax.h"
+
+namespace webrtc {
+namespace {
+bool Limit(float* value, float min, float max) {
+  float clamped = rtc::SafeClamp(*value, min, max);
+  clamped = std::isfinite(clamped) ? clamped : min;
+  bool res = *value == clamped;
+  *value = clamped;
+  return res;
+}
+
+bool Limit(size_t* value, size_t min, size_t max) {
+  size_t clamped = rtc::SafeClamp(*value, min, max);
+  bool res = *value == clamped;
+  *value = clamped;
+  return res;
+}
+
+bool Limit(int* value, int min, int max) {
+  int clamped = rtc::SafeClamp(*value, min, max);
+  bool res = *value == clamped;
+  *value = clamped;
+  return res;
+}
+
+bool FloorLimit(size_t* value, size_t min) {
+  size_t clamped = *value >= min ? *value : min;
+  bool res = *value == clamped;
+  *value = clamped;
+  return res;
+}
+
+}  // namespace
+
+EchoCanceller3Config::EchoCanceller3Config() = default;
+EchoCanceller3Config::EchoCanceller3Config(const EchoCanceller3Config& e) =
+    default;
+EchoCanceller3Config& EchoCanceller3Config::operator=(
+    const EchoCanceller3Config& e) = default;
+EchoCanceller3Config::Delay::Delay() = default;
+EchoCanceller3Config::Delay::Delay(const EchoCanceller3Config::Delay& e) =
+    default;
+EchoCanceller3Config::Delay& EchoCanceller3Config::Delay::operator=(
+    const Delay& e) = default;
+
+EchoCanceller3Config::EchoModel::EchoModel() = default;
+EchoCanceller3Config::EchoModel::EchoModel(
+    const EchoCanceller3Config::EchoModel& e) = default;
+EchoCanceller3Config::EchoModel& EchoCanceller3Config::EchoModel::operator=(
+    const EchoModel& e) = default;
+
+EchoCanceller3Config::Suppressor::Suppressor() = default;
+EchoCanceller3Config::Suppressor::Suppressor(
+    const EchoCanceller3Config::Suppressor& e) = default;
+EchoCanceller3Config::Suppressor& EchoCanceller3Config::Suppressor::operator=(
+    const Suppressor& e) = default;
+
+EchoCanceller3Config::Suppressor::MaskingThresholds::MaskingThresholds(
+    float enr_transparent,
+    float enr_suppress,
+    float emr_transparent)
+    : enr_transparent(enr_transparent),
+      enr_suppress(enr_suppress),
+      emr_transparent(emr_transparent) {}
+EchoCanceller3Config::Suppressor::MaskingThresholds::MaskingThresholds(
+    const EchoCanceller3Config::Suppressor::MaskingThresholds& e) = default;
+EchoCanceller3Config::Suppressor::MaskingThresholds&
+EchoCanceller3Config::Suppressor::MaskingThresholds::operator=(
+    const MaskingThresholds& e) = default;
+
+EchoCanceller3Config::Suppressor::Tuning::Tuning(MaskingThresholds mask_lf,
+                                                 MaskingThresholds mask_hf,
+                                                 float max_inc_factor,
+                                                 float max_dec_factor_lf)
+    : mask_lf(mask_lf),
+      mask_hf(mask_hf),
+      max_inc_factor(max_inc_factor),
+      max_dec_factor_lf(max_dec_factor_lf) {}
+EchoCanceller3Config::Suppressor::Tuning::Tuning(
+    const EchoCanceller3Config::Suppressor::Tuning& e) = default;
+EchoCanceller3Config::Suppressor::Tuning&
+EchoCanceller3Config::Suppressor::Tuning::operator=(const Tuning& e) = default;
+
+bool EchoCanceller3Config::Validate(EchoCanceller3Config* config) {
+  RTC_DCHECK(config);
+  EchoCanceller3Config* c = config;
+  bool res = true;
+
+  if (c->delay.down_sampling_factor != 4 &&
+      c->delay.down_sampling_factor != 8) {
+    c->delay.down_sampling_factor = 4;
+    res = false;
+  }
+
+  res = res & Limit(&c->delay.default_delay, 0, 5000);
+  res = res & Limit(&c->delay.num_filters, 0, 5000);
+  res = res & Limit(&c->delay.delay_headroom_samples, 0, 5000);
+  res = res & Limit(&c->delay.hysteresis_limit_blocks, 0, 5000);
+  res = res & Limit(&c->delay.fixed_capture_delay_samples, 0, 5000);
+  res = res & Limit(&c->delay.delay_estimate_smoothing, 0.f, 1.f);
+  res = res & Limit(&c->delay.delay_candidate_detection_threshold, 0.f, 1.f);
+  res = res & Limit(&c->delay.delay_selection_thresholds.initial, 1, 250);
+  res = res & Limit(&c->delay.delay_selection_thresholds.converged, 1, 250);
+
+  res = res & FloorLimit(&c->filter.refined.length_blocks, 1);
+  res = res & Limit(&c->filter.refined.leakage_converged, 0.f, 1000.f);
+  res = res & Limit(&c->filter.refined.leakage_diverged, 0.f, 1000.f);
+  res = res & Limit(&c->filter.refined.error_floor, 0.f, 1000.f);
+  res = res & Limit(&c->filter.refined.error_ceil, 0.f, 100000000.f);
+  res = res & Limit(&c->filter.refined.noise_gate, 0.f, 100000000.f);
+
+  res = res & FloorLimit(&c->filter.refined_initial.length_blocks, 1);
+  res = res & Limit(&c->filter.refined_initial.leakage_converged, 0.f, 1000.f);
+  res = res & Limit(&c->filter.refined_initial.leakage_diverged, 0.f, 1000.f);
+  res = res & Limit(&c->filter.refined_initial.error_floor, 0.f, 1000.f);
+  res = res & Limit(&c->filter.refined_initial.error_ceil, 0.f, 100000000.f);
+  res = res & Limit(&c->filter.refined_initial.noise_gate, 0.f, 100000000.f);
+
+  if (c->filter.refined.length_blocks <
+      c->filter.refined_initial.length_blocks) {
+    c->filter.refined_initial.length_blocks = c->filter.refined.length_blocks;
+    res = false;
+  }
+
+  res = res & FloorLimit(&c->filter.coarse.length_blocks, 1);
+  res = res & Limit(&c->filter.coarse.rate, 0.f, 1.f);
+  res = res & Limit(&c->filter.coarse.noise_gate, 0.f, 100000000.f);
+
+  res = res & FloorLimit(&c->filter.coarse_initial.length_blocks, 1);
+  res = res & Limit(&c->filter.coarse_initial.rate, 0.f, 1.f);
+  res = res & Limit(&c->filter.coarse_initial.noise_gate, 0.f, 100000000.f);
+
+  if (c->filter.coarse.length_blocks < c->filter.coarse_initial.length_blocks) {
+    c->filter.coarse_initial.length_blocks = c->filter.coarse.length_blocks;
+    res = false;
+  }
+
+  res = res & Limit(&c->filter.config_change_duration_blocks, 0, 100000);
+  res = res & Limit(&c->filter.initial_state_seconds, 0.f, 100.f);
+  res = res & Limit(&c->filter.coarse_reset_hangover_blocks, 0, 2500);
+
+  res = res & Limit(&c->erle.min, 1.f, 100000.f);
+  res = res & Limit(&c->erle.max_l, 1.f, 100000.f);
+  res = res & Limit(&c->erle.max_h, 1.f, 100000.f);
+  if (c->erle.min > c->erle.max_l || c->erle.min > c->erle.max_h) {
+    c->erle.min = std::min(c->erle.max_l, c->erle.max_h);
+    res = false;
+  }
+  res = res & Limit(&c->erle.num_sections, 1, c->filter.refined.length_blocks);
+
+  res = res & Limit(&c->ep_strength.default_gain, 0.f, 1000000.f);
+  res = res & Limit(&c->ep_strength.default_len, -1.f, 1.f);
+
+  res =
+      res & Limit(&c->echo_audibility.low_render_limit, 0.f, 32768.f * 32768.f);
+  res = res &
+        Limit(&c->echo_audibility.normal_render_limit, 0.f, 32768.f * 32768.f);
+  res = res & Limit(&c->echo_audibility.floor_power, 0.f, 32768.f * 32768.f);
+  res = res & Limit(&c->echo_audibility.audibility_threshold_lf, 0.f,
+                    32768.f * 32768.f);
+  res = res & Limit(&c->echo_audibility.audibility_threshold_mf, 0.f,
+                    32768.f * 32768.f);
+  res = res & Limit(&c->echo_audibility.audibility_threshold_hf, 0.f,
+                    32768.f * 32768.f);
+
+  res = res &
+        Limit(&c->render_levels.active_render_limit, 0.f, 32768.f * 32768.f);
+  res = res & Limit(&c->render_levels.poor_excitation_render_limit, 0.f,
+                    32768.f * 32768.f);
+  res = res & Limit(&c->render_levels.poor_excitation_render_limit_ds8, 0.f,
+                    32768.f * 32768.f);
+
+  res = res & Limit(&c->echo_model.noise_floor_hold, 0, 1000);
+  res = res & Limit(&c->echo_model.min_noise_floor_power, 0, 2000000.f);
+  res = res & Limit(&c->echo_model.stationary_gate_slope, 0, 1000000.f);
+  res = res & Limit(&c->echo_model.noise_gate_power, 0, 1000000.f);
+  res = res & Limit(&c->echo_model.noise_gate_slope, 0, 1000000.f);
+  res = res & Limit(&c->echo_model.render_pre_window_size, 0, 100);
+  res = res & Limit(&c->echo_model.render_post_window_size, 0, 100);
+
+  res = res & Limit(&c->comfort_noise.noise_floor_dbfs, -200.f, 0.f);
+
+  res = res & Limit(&c->suppressor.nearend_average_blocks, 1, 5000);
+
+  res = res &
+        Limit(&c->suppressor.normal_tuning.mask_lf.enr_transparent, 0.f, 100.f);
+  res = res &
+        Limit(&c->suppressor.normal_tuning.mask_lf.enr_suppress, 0.f, 100.f);
+  res = res &
+        Limit(&c->suppressor.normal_tuning.mask_lf.emr_transparent, 0.f, 100.f);
+  res = res &
+        Limit(&c->suppressor.normal_tuning.mask_hf.enr_transparent, 0.f, 100.f);
+  res = res &
+        Limit(&c->suppressor.normal_tuning.mask_hf.enr_suppress, 0.f, 100.f);
+  res = res &
+        Limit(&c->suppressor.normal_tuning.mask_hf.emr_transparent, 0.f, 100.f);
+  res = res & Limit(&c->suppressor.normal_tuning.max_inc_factor, 0.f, 100.f);
+  res = res & Limit(&c->suppressor.normal_tuning.max_dec_factor_lf, 0.f, 100.f);
+
+  res = res & Limit(&c->suppressor.nearend_tuning.mask_lf.enr_transparent, 0.f,
+                    100.f);
+  res = res &
+        Limit(&c->suppressor.nearend_tuning.mask_lf.enr_suppress, 0.f, 100.f);
+  res = res & Limit(&c->suppressor.nearend_tuning.mask_lf.emr_transparent, 0.f,
+                    100.f);
+  res = res & Limit(&c->suppressor.nearend_tuning.mask_hf.enr_transparent, 0.f,
+                    100.f);
+  res = res &
+        Limit(&c->suppressor.nearend_tuning.mask_hf.enr_suppress, 0.f, 100.f);
+  res = res & Limit(&c->suppressor.nearend_tuning.mask_hf.emr_transparent, 0.f,
+                    100.f);
+  res = res & Limit(&c->suppressor.nearend_tuning.max_inc_factor, 0.f, 100.f);
+  res =
+      res & Limit(&c->suppressor.nearend_tuning.max_dec_factor_lf, 0.f, 100.f);
+
+  res = res & Limit(&c->suppressor.dominant_nearend_detection.enr_threshold,
+                    0.f, 1000000.f);
+  res = res & Limit(&c->suppressor.dominant_nearend_detection.snr_threshold,
+                    0.f, 1000000.f);
+  res = res & Limit(&c->suppressor.dominant_nearend_detection.hold_duration, 0,
+                    10000);
+  res = res & Limit(&c->suppressor.dominant_nearend_detection.trigger_threshold,
+                    0, 10000);
+
+  res = res &
+        Limit(&c->suppressor.subband_nearend_detection.nearend_average_blocks,
+              1, 1024);
+  res =
+      res & Limit(&c->suppressor.subband_nearend_detection.subband1.low, 0, 65);
+  res = res & Limit(&c->suppressor.subband_nearend_detection.subband1.high,
+                    c->suppressor.subband_nearend_detection.subband1.low, 65);
+  res =
+      res & Limit(&c->suppressor.subband_nearend_detection.subband2.low, 0, 65);
+  res = res & Limit(&c->suppressor.subband_nearend_detection.subband2.high,
+                    c->suppressor.subband_nearend_detection.subband2.low, 65);
+  res = res & Limit(&c->suppressor.subband_nearend_detection.nearend_threshold,
+                    0.f, 1.e24f);
+  res = res & Limit(&c->suppressor.subband_nearend_detection.snr_threshold, 0.f,
+                    1.e24f);
+
+  res = res & Limit(&c->suppressor.high_bands_suppression.enr_threshold, 0.f,
+                    1000000.f);
+  res = res & Limit(&c->suppressor.high_bands_suppression.max_gain_during_echo,
+                    0.f, 1.f);
+  res = res & Limit(&c->suppressor.high_bands_suppression
+                         .anti_howling_activation_threshold,
+                    0.f, 32768.f * 32768.f);
+  res = res & Limit(&c->suppressor.high_bands_suppression.anti_howling_gain,
+                    0.f, 1.f);
+
+  res = res & Limit(&c->suppressor.floor_first_increase, 0.f, 1000000.f);
+
+  return res;
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/api/audio/echo_canceller3_config.h b/third_party/webrtc_aec3/src/api/audio/echo_canceller3_config.h
new file mode 100644
index 0000000..8ffc3d9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/echo_canceller3_config.h
@@ -0,0 +1,232 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef API_AUDIO_ECHO_CANCELLER3_CONFIG_H_
+#define API_AUDIO_ECHO_CANCELLER3_CONFIG_H_
+
+#include <stddef.h>  // size_t
+
+#include "rtc_base/system/rtc_export.h"
+
+namespace webrtc {
+
+// Configuration struct for EchoCanceller3
+struct RTC_EXPORT EchoCanceller3Config {
+  // Checks and updates the config parameters to lie within (mostly) reasonable
+  // ranges. Returns true if and only of the config did not need to be changed.
+  static bool Validate(EchoCanceller3Config* config);
+
+  EchoCanceller3Config();
+  EchoCanceller3Config(const EchoCanceller3Config& e);
+  EchoCanceller3Config& operator=(const EchoCanceller3Config& other);
+
+  struct Buffering {
+    size_t excess_render_detection_interval_blocks = 250;
+    size_t max_allowed_excess_render_blocks = 8;
+  } buffering;
+
+  struct Delay {
+    Delay();
+    Delay(const Delay& e);
+    Delay& operator=(const Delay& e);
+    size_t default_delay = 5;
+    size_t down_sampling_factor = 4;
+    size_t num_filters = 5;
+    size_t delay_headroom_samples = 32;
+    size_t hysteresis_limit_blocks = 1;
+    size_t fixed_capture_delay_samples = 0;
+    float delay_estimate_smoothing = 0.7f;
+    float delay_candidate_detection_threshold = 0.2f;
+    struct DelaySelectionThresholds {
+      int initial;
+      int converged;
+    } delay_selection_thresholds = {5, 20};
+    bool use_external_delay_estimator = false;
+    bool log_warning_on_delay_changes = false;
+    struct AlignmentMixing {
+      bool downmix;
+      bool adaptive_selection;
+      float activity_power_threshold;
+      bool prefer_first_two_channels;
+    };
+    AlignmentMixing render_alignment_mixing = {false, true, 10000.f, true};
+    AlignmentMixing capture_alignment_mixing = {false, true, 10000.f, false};
+  } delay;
+
+  struct Filter {
+    struct RefinedConfiguration {
+      size_t length_blocks;
+      float leakage_converged;
+      float leakage_diverged;
+      float error_floor;
+      float error_ceil;
+      float noise_gate;
+    };
+
+    struct CoarseConfiguration {
+      size_t length_blocks;
+      float rate;
+      float noise_gate;
+    };
+
+    RefinedConfiguration refined = {13,     0.00005f, 0.05f,
+                                    0.001f, 2.f,      20075344.f};
+    CoarseConfiguration coarse = {13, 0.7f, 20075344.f};
+
+    RefinedConfiguration refined_initial = {12,     0.005f, 0.5f,
+                                            0.001f, 2.f,    20075344.f};
+    CoarseConfiguration coarse_initial = {12, 0.9f, 20075344.f};
+
+    size_t config_change_duration_blocks = 250;
+    float initial_state_seconds = 2.5f;
+    int coarse_reset_hangover_blocks = 25;
+    bool conservative_initial_phase = false;
+    bool enable_coarse_filter_output_usage = true;
+    bool use_linear_filter = true;
+    bool high_pass_filter_echo_reference = false;
+    bool export_linear_aec_output = false;
+  } filter;
+
+  struct Erle {
+    float min = 1.f;
+    float max_l = 4.f;
+    float max_h = 1.5f;
+    bool onset_detection = true;
+    size_t num_sections = 1;
+    bool clamp_quality_estimate_to_zero = true;
+    bool clamp_quality_estimate_to_one = true;
+  } erle;
+
+  struct EpStrength {
+    float default_gain = 1.f;
+    float default_len = 0.83f;
+    bool echo_can_saturate = true;
+    bool bounded_erl = false;
+    bool erle_onset_compensation_in_dominant_nearend = false;
+  } ep_strength;
+
+  struct EchoAudibility {
+    float low_render_limit = 4 * 64.f;
+    float normal_render_limit = 64.f;
+    float floor_power = 2 * 64.f;
+    float audibility_threshold_lf = 10;
+    float audibility_threshold_mf = 10;
+    float audibility_threshold_hf = 10;
+    bool use_stationarity_properties = false;
+    bool use_stationarity_properties_at_init = false;
+  } echo_audibility;
+
+  struct RenderLevels {
+    float active_render_limit = 100.f;
+    float poor_excitation_render_limit = 150.f;
+    float poor_excitation_render_limit_ds8 = 20.f;
+    float render_power_gain_db = 0.f;
+  } render_levels;
+
+  struct EchoRemovalControl {
+    bool has_clock_drift = false;
+    bool linear_and_stable_echo_path = false;
+  } echo_removal_control;
+
+  struct EchoModel {
+    EchoModel();
+    EchoModel(const EchoModel& e);
+    EchoModel& operator=(const EchoModel& e);
+    size_t noise_floor_hold = 50;
+    float min_noise_floor_power = 1638400.f;
+    float stationary_gate_slope = 10.f;
+    float noise_gate_power = 27509.42f;
+    float noise_gate_slope = 0.3f;
+    size_t render_pre_window_size = 1;
+    size_t render_post_window_size = 1;
+    bool model_reverb_in_nonlinear_mode = true;
+  } echo_model;
+
+  struct ComfortNoise {
+    float noise_floor_dbfs = -96.03406f;
+  } comfort_noise;
+
+  struct Suppressor {
+    Suppressor();
+    Suppressor(const Suppressor& e);
+    Suppressor& operator=(const Suppressor& e);
+
+    size_t nearend_average_blocks = 4;
+
+    struct MaskingThresholds {
+      MaskingThresholds(float enr_transparent,
+                        float enr_suppress,
+                        float emr_transparent);
+      MaskingThresholds(const MaskingThresholds& e);
+      MaskingThresholds& operator=(const MaskingThresholds& e);
+      float enr_transparent;
+      float enr_suppress;
+      float emr_transparent;
+    };
+
+    struct Tuning {
+      Tuning(MaskingThresholds mask_lf,
+             MaskingThresholds mask_hf,
+             float max_inc_factor,
+             float max_dec_factor_lf);
+      Tuning(const Tuning& e);
+      Tuning& operator=(const Tuning& e);
+      MaskingThresholds mask_lf;
+      MaskingThresholds mask_hf;
+      float max_inc_factor;
+      float max_dec_factor_lf;
+    };
+
+    Tuning normal_tuning = Tuning(MaskingThresholds(.3f, .4f, .3f),
+                                  MaskingThresholds(.07f, .1f, .3f),
+                                  2.0f,
+                                  0.25f);
+    Tuning nearend_tuning = Tuning(MaskingThresholds(1.09f, 1.1f, .3f),
+                                   MaskingThresholds(.1f, .3f, .3f),
+                                   2.0f,
+                                   0.25f);
+
+    struct DominantNearendDetection {
+      float enr_threshold = .25f;
+      float enr_exit_threshold = 10.f;
+      float snr_threshold = 30.f;
+      int hold_duration = 50;
+      int trigger_threshold = 12;
+      bool use_during_initial_phase = true;
+    } dominant_nearend_detection;
+
+    struct SubbandNearendDetection {
+      size_t nearend_average_blocks = 1;
+      struct SubbandRegion {
+        size_t low;
+        size_t high;
+      };
+      SubbandRegion subband1 = {1, 1};
+      SubbandRegion subband2 = {1, 1};
+      float nearend_threshold = 1.f;
+      float snr_threshold = 1.f;
+    } subband_nearend_detection;
+
+    bool use_subband_nearend_detection = false;
+
+    struct HighBandsSuppression {
+      float enr_threshold = 1.f;
+      float max_gain_during_echo = 1.f;
+      float anti_howling_activation_threshold = 400.f;
+      float anti_howling_gain = 1.f;
+    } high_bands_suppression;
+
+    float floor_first_increase = 0.00001f;
+    bool conservative_hf_suppression = false;
+  } suppressor;
+};
+}  // namespace webrtc
+
+#endif  // API_AUDIO_ECHO_CANCELLER3_CONFIG_H_
diff --git a/third_party/webrtc_aec3/src/api/audio/echo_canceller3_config_json.cc b/third_party/webrtc_aec3/src/api/audio/echo_canceller3_config_json.cc
new file mode 100644
index 0000000..89256b3
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/echo_canceller3_config_json.cc
@@ -0,0 +1,705 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "api/audio/echo_canceller3_config_json.h"
+
+#include <stddef.h>
+
+#include <string>
+#include <vector>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+#include "rtc_base/strings/json.h"
+#include "rtc_base/strings/string_builder.h"
+
+namespace webrtc {
+namespace {
+void ReadParam(const Json::Value& root, std::string param_name, bool* param) {
+  RTC_DCHECK(param);
+  bool v;
+  if (rtc::GetBoolFromJsonObject(root, param_name, &v)) {
+    *param = v;
+  }
+}
+
+void ReadParam(const Json::Value& root, std::string param_name, size_t* param) {
+  RTC_DCHECK(param);
+  int v;
+  if (rtc::GetIntFromJsonObject(root, param_name, &v) && v >= 0) {
+    *param = v;
+  }
+}
+
+void ReadParam(const Json::Value& root, std::string param_name, int* param) {
+  RTC_DCHECK(param);
+  int v;
+  if (rtc::GetIntFromJsonObject(root, param_name, &v)) {
+    *param = v;
+  }
+}
+
+void ReadParam(const Json::Value& root, std::string param_name, float* param) {
+  RTC_DCHECK(param);
+  double v;
+  if (rtc::GetDoubleFromJsonObject(root, param_name, &v)) {
+    *param = static_cast<float>(v);
+  }
+}
+
+void ReadParam(const Json::Value& root,
+               std::string param_name,
+               EchoCanceller3Config::Filter::RefinedConfiguration* param) {
+  RTC_DCHECK(param);
+  Json::Value json_array;
+  if (rtc::GetValueFromJsonObject(root, param_name, &json_array)) {
+    std::vector<double> v;
+    rtc::JsonArrayToDoubleVector(json_array, &v);
+    if (v.size() != 6) {
+      RTC_LOG(LS_ERROR) << "Incorrect array size for " << param_name;
+      return;
+    }
+    param->length_blocks = static_cast<size_t>(v[0]);
+    param->leakage_converged = static_cast<float>(v[1]);
+    param->leakage_diverged = static_cast<float>(v[2]);
+    param->error_floor = static_cast<float>(v[3]);
+    param->error_ceil = static_cast<float>(v[4]);
+    param->noise_gate = static_cast<float>(v[5]);
+  }
+}
+
+void ReadParam(const Json::Value& root,
+               std::string param_name,
+               EchoCanceller3Config::Filter::CoarseConfiguration* param) {
+  RTC_DCHECK(param);
+  Json::Value json_array;
+  if (rtc::GetValueFromJsonObject(root, param_name, &json_array)) {
+    std::vector<double> v;
+    rtc::JsonArrayToDoubleVector(json_array, &v);
+    if (v.size() != 3) {
+      RTC_LOG(LS_ERROR) << "Incorrect array size for " << param_name;
+      return;
+    }
+    param->length_blocks = static_cast<size_t>(v[0]);
+    param->rate = static_cast<float>(v[1]);
+    param->noise_gate = static_cast<float>(v[2]);
+  }
+}
+
+void ReadParam(const Json::Value& root,
+               std::string param_name,
+               EchoCanceller3Config::Delay::AlignmentMixing* param) {
+  RTC_DCHECK(param);
+
+  Json::Value subsection;
+  if (rtc::GetValueFromJsonObject(root, param_name, &subsection)) {
+    ReadParam(subsection, "downmix", &param->downmix);
+    ReadParam(subsection, "adaptive_selection", &param->adaptive_selection);
+    ReadParam(subsection, "activity_power_threshold",
+              &param->activity_power_threshold);
+    ReadParam(subsection, "prefer_first_two_channels",
+              &param->prefer_first_two_channels);
+  }
+}
+
+void ReadParam(
+    const Json::Value& root,
+    std::string param_name,
+    EchoCanceller3Config::Suppressor::SubbandNearendDetection::SubbandRegion*
+        param) {
+  RTC_DCHECK(param);
+  Json::Value json_array;
+  if (rtc::GetValueFromJsonObject(root, param_name, &json_array)) {
+    std::vector<int> v;
+    rtc::JsonArrayToIntVector(json_array, &v);
+    if (v.size() != 2) {
+      RTC_LOG(LS_ERROR) << "Incorrect array size for " << param_name;
+      return;
+    }
+    param->low = static_cast<size_t>(v[0]);
+    param->high = static_cast<size_t>(v[1]);
+  }
+}
+
+void ReadParam(const Json::Value& root,
+               std::string param_name,
+               EchoCanceller3Config::Suppressor::MaskingThresholds* param) {
+  RTC_DCHECK(param);
+  Json::Value json_array;
+  if (rtc::GetValueFromJsonObject(root, param_name, &json_array)) {
+    std::vector<double> v;
+    rtc::JsonArrayToDoubleVector(json_array, &v);
+    if (v.size() != 3) {
+      RTC_LOG(LS_ERROR) << "Incorrect array size for " << param_name;
+      return;
+    }
+    param->enr_transparent = static_cast<float>(v[0]);
+    param->enr_suppress = static_cast<float>(v[1]);
+    param->emr_transparent = static_cast<float>(v[2]);
+  }
+}
+}  // namespace
+
+void Aec3ConfigFromJsonString(absl::string_view json_string,
+                              EchoCanceller3Config* config,
+                              bool* parsing_successful) {
+  RTC_DCHECK(config);
+  RTC_DCHECK(parsing_successful);
+  EchoCanceller3Config& cfg = *config;
+  cfg = EchoCanceller3Config();
+  *parsing_successful = true;
+
+  Json::Value root;
+  bool success = Json::Reader().parse(std::string(json_string), root);
+  if (!success) {
+    RTC_LOG(LS_ERROR) << "Incorrect JSON format: " << json_string;
+    *parsing_successful = false;
+    return;
+  }
+
+  Json::Value aec3_root;
+  success = rtc::GetValueFromJsonObject(root, "aec3", &aec3_root);
+  if (!success) {
+    RTC_LOG(LS_ERROR) << "Missing AEC3 config field: " << json_string;
+    *parsing_successful = false;
+    return;
+  }
+
+  Json::Value section;
+  if (rtc::GetValueFromJsonObject(aec3_root, "buffering", &section)) {
+    ReadParam(section, "excess_render_detection_interval_blocks",
+              &cfg.buffering.excess_render_detection_interval_blocks);
+    ReadParam(section, "max_allowed_excess_render_blocks",
+              &cfg.buffering.max_allowed_excess_render_blocks);
+  }
+
+  if (rtc::GetValueFromJsonObject(aec3_root, "delay", &section)) {
+    ReadParam(section, "default_delay", &cfg.delay.default_delay);
+    ReadParam(section, "down_sampling_factor", &cfg.delay.down_sampling_factor);
+    ReadParam(section, "num_filters", &cfg.delay.num_filters);
+    ReadParam(section, "delay_headroom_samples",
+              &cfg.delay.delay_headroom_samples);
+    ReadParam(section, "hysteresis_limit_blocks",
+              &cfg.delay.hysteresis_limit_blocks);
+    ReadParam(section, "fixed_capture_delay_samples",
+              &cfg.delay.fixed_capture_delay_samples);
+    ReadParam(section, "delay_estimate_smoothing",
+              &cfg.delay.delay_estimate_smoothing);
+    ReadParam(section, "delay_candidate_detection_threshold",
+              &cfg.delay.delay_candidate_detection_threshold);
+
+    Json::Value subsection;
+    if (rtc::GetValueFromJsonObject(section, "delay_selection_thresholds",
+                                    &subsection)) {
+      ReadParam(subsection, "initial",
+                &cfg.delay.delay_selection_thresholds.initial);
+      ReadParam(subsection, "converged",
+                &cfg.delay.delay_selection_thresholds.converged);
+    }
+
+    ReadParam(section, "use_external_delay_estimator",
+              &cfg.delay.use_external_delay_estimator);
+    ReadParam(section, "log_warning_on_delay_changes",
+              &cfg.delay.log_warning_on_delay_changes);
+
+    ReadParam(section, "render_alignment_mixing",
+              &cfg.delay.render_alignment_mixing);
+    ReadParam(section, "capture_alignment_mixing",
+              &cfg.delay.capture_alignment_mixing);
+  }
+
+  if (rtc::GetValueFromJsonObject(aec3_root, "filter", &section)) {
+    ReadParam(section, "refined", &cfg.filter.refined);
+    ReadParam(section, "coarse", &cfg.filter.coarse);
+    ReadParam(section, "refined_initial", &cfg.filter.refined_initial);
+    ReadParam(section, "coarse_initial", &cfg.filter.coarse_initial);
+    ReadParam(section, "config_change_duration_blocks",
+              &cfg.filter.config_change_duration_blocks);
+    ReadParam(section, "initial_state_seconds",
+              &cfg.filter.initial_state_seconds);
+    ReadParam(section, "coarse_reset_hangover_blocks",
+              &cfg.filter.coarse_reset_hangover_blocks);
+    ReadParam(section, "conservative_initial_phase",
+              &cfg.filter.conservative_initial_phase);
+    ReadParam(section, "enable_coarse_filter_output_usage",
+              &cfg.filter.enable_coarse_filter_output_usage);
+    ReadParam(section, "use_linear_filter", &cfg.filter.use_linear_filter);
+    ReadParam(section, "high_pass_filter_echo_reference",
+              &cfg.filter.high_pass_filter_echo_reference);
+    ReadParam(section, "export_linear_aec_output",
+              &cfg.filter.export_linear_aec_output);
+  }
+
+  if (rtc::GetValueFromJsonObject(aec3_root, "erle", &section)) {
+    ReadParam(section, "min", &cfg.erle.min);
+    ReadParam(section, "max_l", &cfg.erle.max_l);
+    ReadParam(section, "max_h", &cfg.erle.max_h);
+    ReadParam(section, "onset_detection", &cfg.erle.onset_detection);
+    ReadParam(section, "num_sections", &cfg.erle.num_sections);
+    ReadParam(section, "clamp_quality_estimate_to_zero",
+              &cfg.erle.clamp_quality_estimate_to_zero);
+    ReadParam(section, "clamp_quality_estimate_to_one",
+              &cfg.erle.clamp_quality_estimate_to_one);
+  }
+
+  if (rtc::GetValueFromJsonObject(aec3_root, "ep_strength", &section)) {
+    ReadParam(section, "default_gain", &cfg.ep_strength.default_gain);
+    ReadParam(section, "default_len", &cfg.ep_strength.default_len);
+    ReadParam(section, "echo_can_saturate", &cfg.ep_strength.echo_can_saturate);
+    ReadParam(section, "bounded_erl", &cfg.ep_strength.bounded_erl);
+    ReadParam(section, "erle_onset_compensation_in_dominant_nearend",
+              &cfg.ep_strength.erle_onset_compensation_in_dominant_nearend);
+  }
+
+  if (rtc::GetValueFromJsonObject(aec3_root, "echo_audibility", &section)) {
+    ReadParam(section, "low_render_limit",
+              &cfg.echo_audibility.low_render_limit);
+    ReadParam(section, "normal_render_limit",
+              &cfg.echo_audibility.normal_render_limit);
+
+    ReadParam(section, "floor_power", &cfg.echo_audibility.floor_power);
+    ReadParam(section, "audibility_threshold_lf",
+              &cfg.echo_audibility.audibility_threshold_lf);
+    ReadParam(section, "audibility_threshold_mf",
+              &cfg.echo_audibility.audibility_threshold_mf);
+    ReadParam(section, "audibility_threshold_hf",
+              &cfg.echo_audibility.audibility_threshold_hf);
+    ReadParam(section, "use_stationarity_properties",
+              &cfg.echo_audibility.use_stationarity_properties);
+    ReadParam(section, "use_stationarity_properties_at_init",
+              &cfg.echo_audibility.use_stationarity_properties_at_init);
+  }
+
+  if (rtc::GetValueFromJsonObject(aec3_root, "render_levels", &section)) {
+    ReadParam(section, "active_render_limit",
+              &cfg.render_levels.active_render_limit);
+    ReadParam(section, "poor_excitation_render_limit",
+              &cfg.render_levels.poor_excitation_render_limit);
+    ReadParam(section, "poor_excitation_render_limit_ds8",
+              &cfg.render_levels.poor_excitation_render_limit_ds8);
+    ReadParam(section, "render_power_gain_db",
+              &cfg.render_levels.render_power_gain_db);
+  }
+
+  if (rtc::GetValueFromJsonObject(aec3_root, "echo_removal_control",
+                                  &section)) {
+    ReadParam(section, "has_clock_drift",
+              &cfg.echo_removal_control.has_clock_drift);
+    ReadParam(section, "linear_and_stable_echo_path",
+              &cfg.echo_removal_control.linear_and_stable_echo_path);
+  }
+
+  if (rtc::GetValueFromJsonObject(aec3_root, "echo_model", &section)) {
+    Json::Value subsection;
+    ReadParam(section, "noise_floor_hold", &cfg.echo_model.noise_floor_hold);
+    ReadParam(section, "min_noise_floor_power",
+              &cfg.echo_model.min_noise_floor_power);
+    ReadParam(section, "stationary_gate_slope",
+              &cfg.echo_model.stationary_gate_slope);
+    ReadParam(section, "noise_gate_power", &cfg.echo_model.noise_gate_power);
+    ReadParam(section, "noise_gate_slope", &cfg.echo_model.noise_gate_slope);
+    ReadParam(section, "render_pre_window_size",
+              &cfg.echo_model.render_pre_window_size);
+    ReadParam(section, "render_post_window_size",
+              &cfg.echo_model.render_post_window_size);
+    ReadParam(section, "model_reverb_in_nonlinear_mode",
+              &cfg.echo_model.model_reverb_in_nonlinear_mode);
+  }
+
+  if (rtc::GetValueFromJsonObject(aec3_root, "comfort_noise", &section)) {
+    ReadParam(section, "noise_floor_dbfs", &cfg.comfort_noise.noise_floor_dbfs);
+  }
+
+  Json::Value subsection;
+  if (rtc::GetValueFromJsonObject(aec3_root, "suppressor", &section)) {
+    ReadParam(section, "nearend_average_blocks",
+              &cfg.suppressor.nearend_average_blocks);
+
+    if (rtc::GetValueFromJsonObject(section, "normal_tuning", &subsection)) {
+      ReadParam(subsection, "mask_lf", &cfg.suppressor.normal_tuning.mask_lf);
+      ReadParam(subsection, "mask_hf", &cfg.suppressor.normal_tuning.mask_hf);
+      ReadParam(subsection, "max_inc_factor",
+                &cfg.suppressor.normal_tuning.max_inc_factor);
+      ReadParam(subsection, "max_dec_factor_lf",
+                &cfg.suppressor.normal_tuning.max_dec_factor_lf);
+    }
+
+    if (rtc::GetValueFromJsonObject(section, "nearend_tuning", &subsection)) {
+      ReadParam(subsection, "mask_lf", &cfg.suppressor.nearend_tuning.mask_lf);
+      ReadParam(subsection, "mask_hf", &cfg.suppressor.nearend_tuning.mask_hf);
+      ReadParam(subsection, "max_inc_factor",
+                &cfg.suppressor.nearend_tuning.max_inc_factor);
+      ReadParam(subsection, "max_dec_factor_lf",
+                &cfg.suppressor.nearend_tuning.max_dec_factor_lf);
+    }
+
+    if (rtc::GetValueFromJsonObject(section, "dominant_nearend_detection",
+                                    &subsection)) {
+      ReadParam(subsection, "enr_threshold",
+                &cfg.suppressor.dominant_nearend_detection.enr_threshold);
+      ReadParam(subsection, "enr_exit_threshold",
+                &cfg.suppressor.dominant_nearend_detection.enr_exit_threshold);
+      ReadParam(subsection, "snr_threshold",
+                &cfg.suppressor.dominant_nearend_detection.snr_threshold);
+      ReadParam(subsection, "hold_duration",
+                &cfg.suppressor.dominant_nearend_detection.hold_duration);
+      ReadParam(subsection, "trigger_threshold",
+                &cfg.suppressor.dominant_nearend_detection.trigger_threshold);
+      ReadParam(
+          subsection, "use_during_initial_phase",
+          &cfg.suppressor.dominant_nearend_detection.use_during_initial_phase);
+    }
+
+    if (rtc::GetValueFromJsonObject(section, "subband_nearend_detection",
+                                    &subsection)) {
+      ReadParam(
+          subsection, "nearend_average_blocks",
+          &cfg.suppressor.subband_nearend_detection.nearend_average_blocks);
+      ReadParam(subsection, "subband1",
+                &cfg.suppressor.subband_nearend_detection.subband1);
+      ReadParam(subsection, "subband2",
+                &cfg.suppressor.subband_nearend_detection.subband2);
+      ReadParam(subsection, "nearend_threshold",
+                &cfg.suppressor.subband_nearend_detection.nearend_threshold);
+      ReadParam(subsection, "snr_threshold",
+                &cfg.suppressor.subband_nearend_detection.snr_threshold);
+    }
+
+    ReadParam(section, "use_subband_nearend_detection",
+              &cfg.suppressor.use_subband_nearend_detection);
+
+    if (rtc::GetValueFromJsonObject(section, "high_bands_suppression",
+                                    &subsection)) {
+      ReadParam(subsection, "enr_threshold",
+                &cfg.suppressor.high_bands_suppression.enr_threshold);
+      ReadParam(subsection, "max_gain_during_echo",
+                &cfg.suppressor.high_bands_suppression.max_gain_during_echo);
+      ReadParam(subsection, "anti_howling_activation_threshold",
+                &cfg.suppressor.high_bands_suppression
+                     .anti_howling_activation_threshold);
+      ReadParam(subsection, "anti_howling_gain",
+                &cfg.suppressor.high_bands_suppression.anti_howling_gain);
+    }
+
+    ReadParam(section, "floor_first_increase",
+              &cfg.suppressor.floor_first_increase);
+    ReadParam(section, "conservative_hf_suppression",
+              &cfg.suppressor.conservative_hf_suppression);
+  }
+}
+
+EchoCanceller3Config Aec3ConfigFromJsonString(absl::string_view json_string) {
+  EchoCanceller3Config cfg;
+  bool not_used;
+  Aec3ConfigFromJsonString(json_string, &cfg, &not_used);
+  return cfg;
+}
+
+std::string Aec3ConfigToJsonString(const EchoCanceller3Config& config) {
+  rtc::StringBuilder ost;
+  ost << "{";
+  ost << "\"aec3\": {";
+  ost << "\"buffering\": {";
+  ost << "\"excess_render_detection_interval_blocks\": "
+      << config.buffering.excess_render_detection_interval_blocks << ",";
+  ost << "\"max_allowed_excess_render_blocks\": "
+      << config.buffering.max_allowed_excess_render_blocks;
+  ost << "},";
+
+  ost << "\"delay\": {";
+  ost << "\"default_delay\": " << config.delay.default_delay << ",";
+  ost << "\"down_sampling_factor\": " << config.delay.down_sampling_factor
+      << ",";
+  ost << "\"num_filters\": " << config.delay.num_filters << ",";
+  ost << "\"delay_headroom_samples\": " << config.delay.delay_headroom_samples
+      << ",";
+  ost << "\"hysteresis_limit_blocks\": " << config.delay.hysteresis_limit_blocks
+      << ",";
+  ost << "\"fixed_capture_delay_samples\": "
+      << config.delay.fixed_capture_delay_samples << ",";
+  ost << "\"delay_estimate_smoothing\": "
+      << config.delay.delay_estimate_smoothing << ",";
+  ost << "\"delay_candidate_detection_threshold\": "
+      << config.delay.delay_candidate_detection_threshold << ",";
+
+  ost << "\"delay_selection_thresholds\": {";
+  ost << "\"initial\": " << config.delay.delay_selection_thresholds.initial
+      << ",";
+  ost << "\"converged\": " << config.delay.delay_selection_thresholds.converged;
+  ost << "},";
+
+  ost << "\"use_external_delay_estimator\": "
+      << (config.delay.use_external_delay_estimator ? "true" : "false") << ",";
+  ost << "\"log_warning_on_delay_changes\": "
+      << (config.delay.log_warning_on_delay_changes ? "true" : "false") << ",";
+
+  ost << "\"render_alignment_mixing\": {";
+  ost << "\"downmix\": "
+      << (config.delay.render_alignment_mixing.downmix ? "true" : "false")
+      << ",";
+  ost << "\"adaptive_selection\": "
+      << (config.delay.render_alignment_mixing.adaptive_selection ? "true"
+                                                                  : "false")
+      << ",";
+  ost << "\"activity_power_threshold\": "
+      << config.delay.render_alignment_mixing.activity_power_threshold << ",";
+  ost << "\"prefer_first_two_channels\": "
+      << (config.delay.render_alignment_mixing.prefer_first_two_channels
+              ? "true"
+              : "false");
+  ost << "},";
+
+  ost << "\"capture_alignment_mixing\": {";
+  ost << "\"downmix\": "
+      << (config.delay.capture_alignment_mixing.downmix ? "true" : "false")
+      << ",";
+  ost << "\"adaptive_selection\": "
+      << (config.delay.capture_alignment_mixing.adaptive_selection ? "true"
+                                                                   : "false")
+      << ",";
+  ost << "\"activity_power_threshold\": "
+      << config.delay.capture_alignment_mixing.activity_power_threshold << ",";
+  ost << "\"prefer_first_two_channels\": "
+      << (config.delay.capture_alignment_mixing.prefer_first_two_channels
+              ? "true"
+              : "false");
+  ost << "}";
+  ost << "},";
+
+  ost << "\"filter\": {";
+
+  ost << "\"refined\": [";
+  ost << config.filter.refined.length_blocks << ",";
+  ost << config.filter.refined.leakage_converged << ",";
+  ost << config.filter.refined.leakage_diverged << ",";
+  ost << config.filter.refined.error_floor << ",";
+  ost << config.filter.refined.error_ceil << ",";
+  ost << config.filter.refined.noise_gate;
+  ost << "],";
+
+  ost << "\"coarse\": [";
+  ost << config.filter.coarse.length_blocks << ",";
+  ost << config.filter.coarse.rate << ",";
+  ost << config.filter.coarse.noise_gate;
+  ost << "],";
+
+  ost << "\"refined_initial\": [";
+  ost << config.filter.refined_initial.length_blocks << ",";
+  ost << config.filter.refined_initial.leakage_converged << ",";
+  ost << config.filter.refined_initial.leakage_diverged << ",";
+  ost << config.filter.refined_initial.error_floor << ",";
+  ost << config.filter.refined_initial.error_ceil << ",";
+  ost << config.filter.refined_initial.noise_gate;
+  ost << "],";
+
+  ost << "\"coarse_initial\": [";
+  ost << config.filter.coarse_initial.length_blocks << ",";
+  ost << config.filter.coarse_initial.rate << ",";
+  ost << config.filter.coarse_initial.noise_gate;
+  ost << "],";
+
+  ost << "\"config_change_duration_blocks\": "
+      << config.filter.config_change_duration_blocks << ",";
+  ost << "\"initial_state_seconds\": " << config.filter.initial_state_seconds
+      << ",";
+  ost << "\"coarse_reset_hangover_blocks\": "
+      << config.filter.coarse_reset_hangover_blocks << ",";
+  ost << "\"conservative_initial_phase\": "
+      << (config.filter.conservative_initial_phase ? "true" : "false") << ",";
+  ost << "\"enable_coarse_filter_output_usage\": "
+      << (config.filter.enable_coarse_filter_output_usage ? "true" : "false")
+      << ",";
+  ost << "\"use_linear_filter\": "
+      << (config.filter.use_linear_filter ? "true" : "false") << ",";
+  ost << "\"high_pass_filter_echo_reference\": "
+      << (config.filter.high_pass_filter_echo_reference ? "true" : "false")
+      << ",";
+  ost << "\"export_linear_aec_output\": "
+      << (config.filter.export_linear_aec_output ? "true" : "false");
+
+  ost << "},";
+
+  ost << "\"erle\": {";
+  ost << "\"min\": " << config.erle.min << ",";
+  ost << "\"max_l\": " << config.erle.max_l << ",";
+  ost << "\"max_h\": " << config.erle.max_h << ",";
+  ost << "\"onset_detection\": "
+      << (config.erle.onset_detection ? "true" : "false") << ",";
+  ost << "\"num_sections\": " << config.erle.num_sections << ",";
+  ost << "\"clamp_quality_estimate_to_zero\": "
+      << (config.erle.clamp_quality_estimate_to_zero ? "true" : "false") << ",";
+  ost << "\"clamp_quality_estimate_to_one\": "
+      << (config.erle.clamp_quality_estimate_to_one ? "true" : "false");
+  ost << "},";
+
+  ost << "\"ep_strength\": {";
+  ost << "\"default_gain\": " << config.ep_strength.default_gain << ",";
+  ost << "\"default_len\": " << config.ep_strength.default_len << ",";
+  ost << "\"echo_can_saturate\": "
+      << (config.ep_strength.echo_can_saturate ? "true" : "false") << ",";
+  ost << "\"bounded_erl\": "
+      << (config.ep_strength.bounded_erl ? "true" : "false") << ",";
+  ost << "\"erle_onset_compensation_in_dominant_nearend\": "
+      << (config.ep_strength.erle_onset_compensation_in_dominant_nearend
+              ? "true"
+              : "false");
+  ost << "},";
+
+  ost << "\"echo_audibility\": {";
+  ost << "\"low_render_limit\": " << config.echo_audibility.low_render_limit
+      << ",";
+  ost << "\"normal_render_limit\": "
+      << config.echo_audibility.normal_render_limit << ",";
+  ost << "\"floor_power\": " << config.echo_audibility.floor_power << ",";
+  ost << "\"audibility_threshold_lf\": "
+      << config.echo_audibility.audibility_threshold_lf << ",";
+  ost << "\"audibility_threshold_mf\": "
+      << config.echo_audibility.audibility_threshold_mf << ",";
+  ost << "\"audibility_threshold_hf\": "
+      << config.echo_audibility.audibility_threshold_hf << ",";
+  ost << "\"use_stationarity_properties\": "
+      << (config.echo_audibility.use_stationarity_properties ? "true" : "false")
+      << ",";
+  ost << "\"use_stationarity_properties_at_init\": "
+      << (config.echo_audibility.use_stationarity_properties_at_init ? "true"
+                                                                     : "false");
+  ost << "},";
+
+  ost << "\"render_levels\": {";
+  ost << "\"active_render_limit\": " << config.render_levels.active_render_limit
+      << ",";
+  ost << "\"poor_excitation_render_limit\": "
+      << config.render_levels.poor_excitation_render_limit << ",";
+  ost << "\"poor_excitation_render_limit_ds8\": "
+      << config.render_levels.poor_excitation_render_limit_ds8 << ",";
+  ost << "\"render_power_gain_db\": "
+      << config.render_levels.render_power_gain_db;
+  ost << "},";
+
+  ost << "\"echo_removal_control\": {";
+  ost << "\"has_clock_drift\": "
+      << (config.echo_removal_control.has_clock_drift ? "true" : "false")
+      << ",";
+  ost << "\"linear_and_stable_echo_path\": "
+      << (config.echo_removal_control.linear_and_stable_echo_path ? "true"
+                                                                  : "false");
+
+  ost << "},";
+
+  ost << "\"echo_model\": {";
+  ost << "\"noise_floor_hold\": " << config.echo_model.noise_floor_hold << ",";
+  ost << "\"min_noise_floor_power\": "
+      << config.echo_model.min_noise_floor_power << ",";
+  ost << "\"stationary_gate_slope\": "
+      << config.echo_model.stationary_gate_slope << ",";
+  ost << "\"noise_gate_power\": " << config.echo_model.noise_gate_power << ",";
+  ost << "\"noise_gate_slope\": " << config.echo_model.noise_gate_slope << ",";
+  ost << "\"render_pre_window_size\": "
+      << config.echo_model.render_pre_window_size << ",";
+  ost << "\"render_post_window_size\": "
+      << config.echo_model.render_post_window_size << ",";
+  ost << "\"model_reverb_in_nonlinear_mode\": "
+      << (config.echo_model.model_reverb_in_nonlinear_mode ? "true" : "false");
+  ost << "},";
+
+  ost << "\"comfort_noise\": {";
+  ost << "\"noise_floor_dbfs\": " << config.comfort_noise.noise_floor_dbfs;
+  ost << "},";
+
+  ost << "\"suppressor\": {";
+  ost << "\"nearend_average_blocks\": "
+      << config.suppressor.nearend_average_blocks << ",";
+  ost << "\"normal_tuning\": {";
+  ost << "\"mask_lf\": [";
+  ost << config.suppressor.normal_tuning.mask_lf.enr_transparent << ",";
+  ost << config.suppressor.normal_tuning.mask_lf.enr_suppress << ",";
+  ost << config.suppressor.normal_tuning.mask_lf.emr_transparent;
+  ost << "],";
+  ost << "\"mask_hf\": [";
+  ost << config.suppressor.normal_tuning.mask_hf.enr_transparent << ",";
+  ost << config.suppressor.normal_tuning.mask_hf.enr_suppress << ",";
+  ost << config.suppressor.normal_tuning.mask_hf.emr_transparent;
+  ost << "],";
+  ost << "\"max_inc_factor\": "
+      << config.suppressor.normal_tuning.max_inc_factor << ",";
+  ost << "\"max_dec_factor_lf\": "
+      << config.suppressor.normal_tuning.max_dec_factor_lf;
+  ost << "},";
+  ost << "\"nearend_tuning\": {";
+  ost << "\"mask_lf\": [";
+  ost << config.suppressor.nearend_tuning.mask_lf.enr_transparent << ",";
+  ost << config.suppressor.nearend_tuning.mask_lf.enr_suppress << ",";
+  ost << config.suppressor.nearend_tuning.mask_lf.emr_transparent;
+  ost << "],";
+  ost << "\"mask_hf\": [";
+  ost << config.suppressor.nearend_tuning.mask_hf.enr_transparent << ",";
+  ost << config.suppressor.nearend_tuning.mask_hf.enr_suppress << ",";
+  ost << config.suppressor.nearend_tuning.mask_hf.emr_transparent;
+  ost << "],";
+  ost << "\"max_inc_factor\": "
+      << config.suppressor.nearend_tuning.max_inc_factor << ",";
+  ost << "\"max_dec_factor_lf\": "
+      << config.suppressor.nearend_tuning.max_dec_factor_lf;
+  ost << "},";
+  ost << "\"dominant_nearend_detection\": {";
+  ost << "\"enr_threshold\": "
+      << config.suppressor.dominant_nearend_detection.enr_threshold << ",";
+  ost << "\"enr_exit_threshold\": "
+      << config.suppressor.dominant_nearend_detection.enr_exit_threshold << ",";
+  ost << "\"snr_threshold\": "
+      << config.suppressor.dominant_nearend_detection.snr_threshold << ",";
+  ost << "\"hold_duration\": "
+      << config.suppressor.dominant_nearend_detection.hold_duration << ",";
+  ost << "\"trigger_threshold\": "
+      << config.suppressor.dominant_nearend_detection.trigger_threshold << ",";
+  ost << "\"use_during_initial_phase\": "
+      << config.suppressor.dominant_nearend_detection.use_during_initial_phase;
+  ost << "},";
+  ost << "\"subband_nearend_detection\": {";
+  ost << "\"nearend_average_blocks\": "
+      << config.suppressor.subband_nearend_detection.nearend_average_blocks
+      << ",";
+  ost << "\"subband1\": [";
+  ost << config.suppressor.subband_nearend_detection.subband1.low << ",";
+  ost << config.suppressor.subband_nearend_detection.subband1.high;
+  ost << "],";
+  ost << "\"subband2\": [";
+  ost << config.suppressor.subband_nearend_detection.subband2.low << ",";
+  ost << config.suppressor.subband_nearend_detection.subband2.high;
+  ost << "],";
+  ost << "\"nearend_threshold\": "
+      << config.suppressor.subband_nearend_detection.nearend_threshold << ",";
+  ost << "\"snr_threshold\": "
+      << config.suppressor.subband_nearend_detection.snr_threshold;
+  ost << "},";
+  ost << "\"use_subband_nearend_detection\": "
+      << config.suppressor.use_subband_nearend_detection << ",";
+  ost << "\"high_bands_suppression\": {";
+  ost << "\"enr_threshold\": "
+      << config.suppressor.high_bands_suppression.enr_threshold << ",";
+  ost << "\"max_gain_during_echo\": "
+      << config.suppressor.high_bands_suppression.max_gain_during_echo << ",";
+  ost << "\"anti_howling_activation_threshold\": "
+      << config.suppressor.high_bands_suppression
+             .anti_howling_activation_threshold
+      << ",";
+  ost << "\"anti_howling_gain\": "
+      << config.suppressor.high_bands_suppression.anti_howling_gain;
+  ost << "},";
+  ost << "\"floor_first_increase\": " << config.suppressor.floor_first_increase
+      << ",";
+  ost << "\"conservative_hf_suppression\": "
+      << config.suppressor.conservative_hf_suppression;
+  ost << "}";
+  ost << "}";
+  ost << "}";
+
+  return ost.Release();
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/api/audio/echo_canceller3_config_json.h b/third_party/webrtc_aec3/src/api/audio/echo_canceller3_config_json.h
new file mode 100644
index 0000000..ecee954
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/echo_canceller3_config_json.h
@@ -0,0 +1,45 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef API_AUDIO_ECHO_CANCELLER3_CONFIG_JSON_H_
+#define API_AUDIO_ECHO_CANCELLER3_CONFIG_JSON_H_
+
+#include <string>
+
+#include "absl/strings/string_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "rtc_base/system/rtc_export.h"
+
+namespace webrtc {
+// Parses a JSON-encoded string into an Aec3 config. Fields corresponds to
+// substruct names, with the addition that there must be a top-level node
+// "aec3". Produces default config values for anything that cannot be parsed
+// from the string. If any error was found in the parsing, parsing_successful is
+// set to false.
+RTC_EXPORT void Aec3ConfigFromJsonString(absl::string_view json_string,
+                                         EchoCanceller3Config* config,
+                                         bool* parsing_successful);
+
+// To be deprecated.
+// Parses a JSON-encoded string into an Aec3 config. Fields corresponds to
+// substruct names, with the addition that there must be a top-level node
+// "aec3". Returns default config values for anything that cannot be parsed from
+// the string.
+RTC_EXPORT EchoCanceller3Config
+Aec3ConfigFromJsonString(absl::string_view json_string);
+
+// Encodes an Aec3 config in JSON format. Fields corresponds to substruct names,
+// with the addition that the top-level node is named "aec3".
+RTC_EXPORT std::string Aec3ConfigToJsonString(
+    const EchoCanceller3Config& config);
+
+}  // namespace webrtc
+
+#endif  // API_AUDIO_ECHO_CANCELLER3_CONFIG_JSON_H_
diff --git a/third_party/webrtc_aec3/src/api/audio/echo_canceller3_factory.cc b/third_party/webrtc_aec3/src/api/audio/echo_canceller3_factory.cc
new file mode 100644
index 0000000..d65a726
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/echo_canceller3_factory.cc
@@ -0,0 +1,31 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "api/audio/echo_canceller3_factory.h"
+
+#include <memory>
+
+#include "modules/audio_processing/aec3/echo_canceller3.h"
+
+namespace webrtc {
+
+EchoCanceller3Factory::EchoCanceller3Factory() {}
+
+EchoCanceller3Factory::EchoCanceller3Factory(const EchoCanceller3Config& config)
+    : config_(config) {}
+
+std::unique_ptr<EchoControl> EchoCanceller3Factory::Create(
+    int sample_rate_hz,
+    int num_render_channels,
+    int num_capture_channels) {
+  return std::make_unique<EchoCanceller3>(
+      config_, sample_rate_hz, num_render_channels, num_capture_channels);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/api/audio/echo_canceller3_factory.h b/third_party/webrtc_aec3/src/api/audio/echo_canceller3_factory.h
new file mode 100644
index 0000000..8b53800
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/echo_canceller3_factory.h
@@ -0,0 +1,41 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef API_AUDIO_ECHO_CANCELLER3_FACTORY_H_
+#define API_AUDIO_ECHO_CANCELLER3_FACTORY_H_
+
+#include <memory>
+
+#include "api/audio/echo_canceller3_config.h"
+#include "api/audio/echo_control.h"
+#include "rtc_base/system/rtc_export.h"
+
+namespace webrtc {
+
+class RTC_EXPORT EchoCanceller3Factory : public EchoControlFactory {
+ public:
+  // Factory producing EchoCanceller3 instances with the default configuration.
+  EchoCanceller3Factory();
+
+  // Factory producing EchoCanceller3 instances with the specified
+  // configuration.
+  explicit EchoCanceller3Factory(const EchoCanceller3Config& config);
+
+  // Creates an EchoCanceller3 with a specified channel count and sampling rate.
+  std::unique_ptr<EchoControl> Create(int sample_rate_hz,
+                                      int num_render_channels,
+                                      int num_capture_channels) override;
+
+ private:
+  const EchoCanceller3Config config_;
+};
+}  // namespace webrtc
+
+#endif  // API_AUDIO_ECHO_CANCELLER3_FACTORY_H_
diff --git a/third_party/webrtc_aec3/src/api/audio/echo_control.h b/third_party/webrtc_aec3/src/api/audio/echo_control.h
new file mode 100644
index 0000000..74fbc27
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/echo_control.h
@@ -0,0 +1,75 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef API_AUDIO_ECHO_CONTROL_H_
+#define API_AUDIO_ECHO_CONTROL_H_
+
+#include <memory>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+class AudioBuffer;
+
+// Interface for an acoustic echo cancellation (AEC) submodule.
+class EchoControl {
+ public:
+  // Analysis (not changing) of the render signal.
+  virtual void AnalyzeRender(AudioBuffer* render) = 0;
+
+  // Analysis (not changing) of the capture signal.
+  virtual void AnalyzeCapture(AudioBuffer* capture) = 0;
+
+  // Processes the capture signal in order to remove the echo.
+  virtual void ProcessCapture(AudioBuffer* capture, bool level_change) = 0;
+
+  // As above, but also returns the linear filter output.
+  virtual void ProcessCapture(AudioBuffer* capture,
+                              AudioBuffer* linear_output,
+                              bool level_change) = 0;
+
+  struct Metrics {
+    double echo_return_loss;
+    double echo_return_loss_enhancement;
+    int delay_ms;
+  };
+
+  // Collect current metrics from the echo controller.
+  virtual Metrics GetMetrics() const = 0;
+
+  // Provides an optional external estimate of the audio buffer delay.
+  virtual void SetAudioBufferDelay(int delay_ms) = 0;
+
+  // Specifies whether the capture output will be used. The purpose of this is
+  // to allow the echo controller to deactivate some of the processing when the
+  // resulting output is anyway not used, for instance when the endpoint is
+  // muted.
+  // TODO(b/177830919): Make pure virtual.
+  virtual void SetCaptureOutputUsage(bool capture_output_used) {}
+
+  // Returns wheter the signal is altered.
+  virtual bool ActiveProcessing() const = 0;
+
+  virtual ~EchoControl() {}
+};
+
+// Interface for a factory that creates EchoControllers.
+class EchoControlFactory {
+ public:
+  virtual std::unique_ptr<EchoControl> Create(int sample_rate_hz,
+                                              int num_render_channels,
+                                              int num_capture_channels) = 0;
+
+  virtual ~EchoControlFactory() = default;
+};
+}  // namespace webrtc
+
+#endif  // API_AUDIO_ECHO_CONTROL_H_
diff --git a/third_party/webrtc_aec3/src/api/audio/echo_detector_creator.cc b/third_party/webrtc_aec3/src/api/audio/echo_detector_creator.cc
new file mode 100644
index 0000000..4c3d9e6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/echo_detector_creator.cc
@@ -0,0 +1,21 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "api/audio/echo_detector_creator.h"
+
+#include "modules/audio_processing/residual_echo_detector.h"
+#include "rtc_base/ref_counted_object.h"
+
+namespace webrtc {
+
+rtc::scoped_refptr<EchoDetector> CreateEchoDetector() {
+  return new rtc::RefCountedObject<ResidualEchoDetector>();
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/api/audio/echo_detector_creator.h b/third_party/webrtc_aec3/src/api/audio/echo_detector_creator.h
new file mode 100644
index 0000000..5ba171d
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/echo_detector_creator.h
@@ -0,0 +1,26 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef API_AUDIO_ECHO_DETECTOR_CREATOR_H_
+#define API_AUDIO_ECHO_DETECTOR_CREATOR_H_
+
+#include "api/scoped_refptr.h"
+#include "modules/audio_processing/include/audio_processing.h"
+
+namespace webrtc {
+
+// Returns an instance of the WebRTC implementation of a residual echo detector.
+// It can be provided to the webrtc::AudioProcessingBuilder to obtain the
+// usual residual echo metrics.
+rtc::scoped_refptr<EchoDetector> CreateEchoDetector();
+
+}  // namespace webrtc
+
+#endif  // API_AUDIO_ECHO_DETECTOR_CREATOR_H_
diff --git a/third_party/webrtc_aec3/src/api/audio/test/BUILD.gn b/third_party/webrtc_aec3/src/api/audio/test/BUILD.gn
new file mode 100644
index 0000000..d62baf1
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/test/BUILD.gn
@@ -0,0 +1,31 @@
+# Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+#
+# Use of this source code is governed by a BSD-style license
+# that can be found in the LICENSE file in the root of the source
+# tree. An additional intellectual property rights grant can be found
+# in the file PATENTS.  All contributing project authors may
+# be found in the AUTHORS file in the root of the source tree.
+
+import("../../../webrtc.gni")
+if (is_android) {
+  import("//build/config/android/config.gni")
+  import("//build/config/android/rules.gni")
+}
+
+if (rtc_include_tests) {
+  rtc_library("audio_api_unittests") {
+    testonly = true
+    sources = [
+      "audio_frame_unittest.cc",
+      "echo_canceller3_config_json_unittest.cc",
+      "echo_canceller3_config_unittest.cc",
+    ]
+    deps = [
+      "..:aec3_config",
+      "..:aec3_config_json",
+      "..:audio_frame_api",
+      "../../../rtc_base:rtc_base_approved",
+      "../../../test:test_support",
+    ]
+  }
+}
diff --git a/third_party/webrtc_aec3/src/api/audio/test/audio_frame_unittest.cc b/third_party/webrtc_aec3/src/api/audio/test/audio_frame_unittest.cc
new file mode 100644
index 0000000..f8d3318
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/test/audio_frame_unittest.cc
@@ -0,0 +1,186 @@
+/*
+ *  Copyright 2018 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "api/audio/audio_frame.h"
+
+#include <stdint.h>
+#include <string.h>  // memcmp
+
+#include "test/gtest.h"
+
+namespace webrtc {
+
+namespace {
+
+bool AllSamplesAre(int16_t sample, const AudioFrame& frame) {
+  const int16_t* frame_data = frame.data();
+  for (size_t i = 0; i < frame.max_16bit_samples(); i++) {
+    if (frame_data[i] != sample) {
+      return false;
+    }
+  }
+  return true;
+}
+
+constexpr uint32_t kTimestamp = 27;
+constexpr int kSampleRateHz = 16000;
+constexpr size_t kNumChannelsMono = 1;
+constexpr size_t kNumChannelsStereo = 2;
+constexpr size_t kNumChannels5_1 = 6;
+constexpr size_t kSamplesPerChannel = kSampleRateHz / 100;
+
+}  // namespace
+
+TEST(AudioFrameTest, FrameStartsMuted) {
+  AudioFrame frame;
+  EXPECT_TRUE(frame.muted());
+  EXPECT_TRUE(AllSamplesAre(0, frame));
+}
+
+TEST(AudioFrameTest, UnmutedFrameIsInitiallyZeroed) {
+  AudioFrame frame;
+  frame.mutable_data();
+  EXPECT_FALSE(frame.muted());
+  EXPECT_TRUE(AllSamplesAre(0, frame));
+}
+
+TEST(AudioFrameTest, MutedFrameBufferIsZeroed) {
+  AudioFrame frame;
+  int16_t* frame_data = frame.mutable_data();
+  for (size_t i = 0; i < frame.max_16bit_samples(); i++) {
+    frame_data[i] = 17;
+  }
+  ASSERT_TRUE(AllSamplesAre(17, frame));
+  frame.Mute();
+  EXPECT_TRUE(frame.muted());
+  EXPECT_TRUE(AllSamplesAre(0, frame));
+}
+
+TEST(AudioFrameTest, UpdateFrameMono) {
+  AudioFrame frame;
+  int16_t samples[kNumChannelsMono * kSamplesPerChannel] = {17};
+  frame.UpdateFrame(kTimestamp, samples, kSamplesPerChannel, kSampleRateHz,
+                    AudioFrame::kPLC, AudioFrame::kVadActive, kNumChannelsMono);
+
+  EXPECT_EQ(kTimestamp, frame.timestamp_);
+  EXPECT_EQ(kSamplesPerChannel, frame.samples_per_channel());
+  EXPECT_EQ(kSampleRateHz, frame.sample_rate_hz());
+  EXPECT_EQ(AudioFrame::kPLC, frame.speech_type_);
+  EXPECT_EQ(AudioFrame::kVadActive, frame.vad_activity_);
+  EXPECT_EQ(kNumChannelsMono, frame.num_channels());
+  EXPECT_EQ(CHANNEL_LAYOUT_MONO, frame.channel_layout());
+
+  EXPECT_FALSE(frame.muted());
+  EXPECT_EQ(0, memcmp(samples, frame.data(), sizeof(samples)));
+
+  frame.UpdateFrame(kTimestamp, nullptr /* data*/, kSamplesPerChannel,
+                    kSampleRateHz, AudioFrame::kPLC, AudioFrame::kVadActive,
+                    kNumChannelsMono);
+  EXPECT_TRUE(frame.muted());
+  EXPECT_TRUE(AllSamplesAre(0, frame));
+}
+
+TEST(AudioFrameTest, UpdateFrameMultiChannel) {
+  AudioFrame frame;
+  frame.UpdateFrame(kTimestamp, nullptr /* data */, kSamplesPerChannel,
+                    kSampleRateHz, AudioFrame::kPLC, AudioFrame::kVadActive,
+                    kNumChannelsStereo);
+  EXPECT_EQ(kSamplesPerChannel, frame.samples_per_channel());
+  EXPECT_EQ(kNumChannelsStereo, frame.num_channels());
+  EXPECT_EQ(CHANNEL_LAYOUT_STEREO, frame.channel_layout());
+
+  frame.UpdateFrame(kTimestamp, nullptr /* data */, kSamplesPerChannel,
+                    kSampleRateHz, AudioFrame::kPLC, AudioFrame::kVadActive,
+                    kNumChannels5_1);
+  EXPECT_EQ(kSamplesPerChannel, frame.samples_per_channel());
+  EXPECT_EQ(kNumChannels5_1, frame.num_channels());
+  EXPECT_EQ(CHANNEL_LAYOUT_5_1, frame.channel_layout());
+}
+
+TEST(AudioFrameTest, CopyFrom) {
+  AudioFrame frame1;
+  AudioFrame frame2;
+
+  int16_t samples[kNumChannelsMono * kSamplesPerChannel] = {17};
+  frame2.UpdateFrame(kTimestamp, samples, kSamplesPerChannel, kSampleRateHz,
+                     AudioFrame::kPLC, AudioFrame::kVadActive,
+                     kNumChannelsMono);
+  frame1.CopyFrom(frame2);
+
+  EXPECT_EQ(frame2.timestamp_, frame1.timestamp_);
+  EXPECT_EQ(frame2.samples_per_channel_, frame1.samples_per_channel_);
+  EXPECT_EQ(frame2.sample_rate_hz_, frame1.sample_rate_hz_);
+  EXPECT_EQ(frame2.speech_type_, frame1.speech_type_);
+  EXPECT_EQ(frame2.vad_activity_, frame1.vad_activity_);
+  EXPECT_EQ(frame2.num_channels_, frame1.num_channels_);
+
+  EXPECT_EQ(frame2.muted(), frame1.muted());
+  EXPECT_EQ(0, memcmp(frame2.data(), frame1.data(), sizeof(samples)));
+
+  frame2.UpdateFrame(kTimestamp, nullptr /* data */, kSamplesPerChannel,
+                     kSampleRateHz, AudioFrame::kPLC, AudioFrame::kVadActive,
+                     kNumChannelsMono);
+  frame1.CopyFrom(frame2);
+
+  EXPECT_EQ(frame2.muted(), frame1.muted());
+  EXPECT_EQ(0, memcmp(frame2.data(), frame1.data(), sizeof(samples)));
+}
+
+TEST(AudioFrameTest, SwapFrames) {
+  AudioFrame frame1, frame2;
+  int16_t samples1[kNumChannelsMono * kSamplesPerChannel];
+  for (size_t i = 0; i < kNumChannelsMono * kSamplesPerChannel; ++i) {
+    samples1[i] = i;
+  }
+  frame1.UpdateFrame(kTimestamp, samples1, kSamplesPerChannel, kSampleRateHz,
+                     AudioFrame::kPLC, AudioFrame::kVadActive,
+                     kNumChannelsMono);
+  frame1.set_absolute_capture_timestamp_ms(12345678);
+  const auto frame1_channel_layout = frame1.channel_layout();
+
+  int16_t samples2[(kNumChannelsMono + 1) * (kSamplesPerChannel + 1)];
+  for (size_t i = 0; i < (kNumChannelsMono + 1) * (kSamplesPerChannel + 1);
+       ++i) {
+    samples2[i] = 1000 + i;
+  }
+  frame2.UpdateFrame(kTimestamp + 1, samples2, kSamplesPerChannel + 1,
+                     kSampleRateHz + 1, AudioFrame::kNormalSpeech,
+                     AudioFrame::kVadPassive, kNumChannelsMono + 1);
+  const auto frame2_channel_layout = frame2.channel_layout();
+
+  swap(frame1, frame2);
+
+  EXPECT_EQ(kTimestamp + 1, frame1.timestamp_);
+  ASSERT_EQ(kSamplesPerChannel + 1, frame1.samples_per_channel_);
+  EXPECT_EQ(kSampleRateHz + 1, frame1.sample_rate_hz_);
+  EXPECT_EQ(AudioFrame::kNormalSpeech, frame1.speech_type_);
+  EXPECT_EQ(AudioFrame::kVadPassive, frame1.vad_activity_);
+  ASSERT_EQ(kNumChannelsMono + 1, frame1.num_channels_);
+  for (size_t i = 0; i < (kNumChannelsMono + 1) * (kSamplesPerChannel + 1);
+       ++i) {
+    EXPECT_EQ(samples2[i], frame1.data()[i]);
+  }
+  EXPECT_FALSE(frame1.absolute_capture_timestamp_ms());
+  EXPECT_EQ(frame2_channel_layout, frame1.channel_layout());
+
+  EXPECT_EQ(kTimestamp, frame2.timestamp_);
+  ASSERT_EQ(kSamplesPerChannel, frame2.samples_per_channel_);
+  EXPECT_EQ(kSampleRateHz, frame2.sample_rate_hz_);
+  EXPECT_EQ(AudioFrame::kPLC, frame2.speech_type_);
+  EXPECT_EQ(AudioFrame::kVadActive, frame2.vad_activity_);
+  ASSERT_EQ(kNumChannelsMono, frame2.num_channels_);
+  for (size_t i = 0; i < kNumChannelsMono * kSamplesPerChannel; ++i) {
+    EXPECT_EQ(samples1[i], frame2.data()[i]);
+  }
+  EXPECT_EQ(12345678, frame2.absolute_capture_timestamp_ms());
+  EXPECT_EQ(frame1_channel_layout, frame2.channel_layout());
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/api/audio/test/echo_canceller3_config_json_unittest.cc b/third_party/webrtc_aec3/src/api/audio/test/echo_canceller3_config_json_unittest.cc
new file mode 100644
index 0000000..d6edd07
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/test/echo_canceller3_config_json_unittest.cc
@@ -0,0 +1,77 @@
+/*
+ *  Copyright 2018 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "api/audio/echo_canceller3_config_json.h"
+
+#include "api/audio/echo_canceller3_config.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+TEST(EchoCanceller3JsonHelpers, ToStringAndParseJson) {
+  EchoCanceller3Config cfg;
+  cfg.delay.down_sampling_factor = 1u;
+  cfg.delay.log_warning_on_delay_changes = true;
+  cfg.filter.refined.error_floor = 2.f;
+  cfg.filter.coarse_initial.length_blocks = 3u;
+  cfg.filter.high_pass_filter_echo_reference =
+      !cfg.filter.high_pass_filter_echo_reference;
+  cfg.comfort_noise.noise_floor_dbfs = 100.f;
+  cfg.echo_model.model_reverb_in_nonlinear_mode = false;
+  cfg.suppressor.normal_tuning.mask_hf.enr_suppress = .5f;
+  cfg.suppressor.subband_nearend_detection.nearend_average_blocks = 3;
+  cfg.suppressor.subband_nearend_detection.subband1 = {1, 3};
+  cfg.suppressor.subband_nearend_detection.subband1 = {4, 5};
+  cfg.suppressor.subband_nearend_detection.nearend_threshold = 2.f;
+  cfg.suppressor.subband_nearend_detection.snr_threshold = 100.f;
+  std::string json_string = Aec3ConfigToJsonString(cfg);
+  EchoCanceller3Config cfg_transformed = Aec3ConfigFromJsonString(json_string);
+
+  // Expect unchanged values to remain default.
+  EXPECT_EQ(cfg.ep_strength.default_len,
+            cfg_transformed.ep_strength.default_len);
+  EXPECT_EQ(cfg.suppressor.normal_tuning.mask_lf.enr_suppress,
+            cfg_transformed.suppressor.normal_tuning.mask_lf.enr_suppress);
+
+  // Expect changed values to carry through the transformation.
+  EXPECT_EQ(cfg.delay.down_sampling_factor,
+            cfg_transformed.delay.down_sampling_factor);
+  EXPECT_EQ(cfg.delay.log_warning_on_delay_changes,
+            cfg_transformed.delay.log_warning_on_delay_changes);
+  EXPECT_EQ(cfg.filter.coarse_initial.length_blocks,
+            cfg_transformed.filter.coarse_initial.length_blocks);
+  EXPECT_EQ(cfg.filter.refined.error_floor,
+            cfg_transformed.filter.refined.error_floor);
+  EXPECT_EQ(cfg.filter.high_pass_filter_echo_reference,
+            cfg_transformed.filter.high_pass_filter_echo_reference);
+  EXPECT_EQ(cfg.comfort_noise.noise_floor_dbfs,
+            cfg_transformed.comfort_noise.noise_floor_dbfs);
+  EXPECT_EQ(cfg.echo_model.model_reverb_in_nonlinear_mode,
+            cfg_transformed.echo_model.model_reverb_in_nonlinear_mode);
+  EXPECT_EQ(cfg.suppressor.normal_tuning.mask_hf.enr_suppress,
+            cfg_transformed.suppressor.normal_tuning.mask_hf.enr_suppress);
+  EXPECT_EQ(cfg.suppressor.subband_nearend_detection.nearend_average_blocks,
+            cfg_transformed.suppressor.subband_nearend_detection
+                .nearend_average_blocks);
+  EXPECT_EQ(cfg.suppressor.subband_nearend_detection.subband1.low,
+            cfg_transformed.suppressor.subband_nearend_detection.subband1.low);
+  EXPECT_EQ(cfg.suppressor.subband_nearend_detection.subband1.high,
+            cfg_transformed.suppressor.subband_nearend_detection.subband1.high);
+  EXPECT_EQ(cfg.suppressor.subband_nearend_detection.subband2.low,
+            cfg_transformed.suppressor.subband_nearend_detection.subband2.low);
+  EXPECT_EQ(cfg.suppressor.subband_nearend_detection.subband2.high,
+            cfg_transformed.suppressor.subband_nearend_detection.subband2.high);
+  EXPECT_EQ(
+      cfg.suppressor.subband_nearend_detection.nearend_threshold,
+      cfg_transformed.suppressor.subband_nearend_detection.nearend_threshold);
+  EXPECT_EQ(cfg.suppressor.subband_nearend_detection.snr_threshold,
+            cfg_transformed.suppressor.subband_nearend_detection.snr_threshold);
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/api/audio/test/echo_canceller3_config_unittest.cc b/third_party/webrtc_aec3/src/api/audio/test/echo_canceller3_config_unittest.cc
new file mode 100644
index 0000000..91312a0
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/audio/test/echo_canceller3_config_unittest.cc
@@ -0,0 +1,46 @@
+/*
+ *  Copyright 2018 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "api/audio/echo_canceller3_config.h"
+
+#include "api/audio/echo_canceller3_config_json.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+TEST(EchoCanceller3Config, ValidConfigIsNotModified) {
+  EchoCanceller3Config config;
+  EXPECT_TRUE(EchoCanceller3Config::Validate(&config));
+  EchoCanceller3Config default_config;
+  EXPECT_EQ(Aec3ConfigToJsonString(config),
+            Aec3ConfigToJsonString(default_config));
+}
+
+TEST(EchoCanceller3Config, InvalidConfigIsCorrected) {
+  // Change a parameter and validate.
+  EchoCanceller3Config config;
+  config.echo_model.min_noise_floor_power = -1600000.f;
+  EXPECT_FALSE(EchoCanceller3Config::Validate(&config));
+  EXPECT_GE(config.echo_model.min_noise_floor_power, 0.f);
+  // Verify remaining parameters are unchanged.
+  EchoCanceller3Config default_config;
+  config.echo_model.min_noise_floor_power =
+      default_config.echo_model.min_noise_floor_power;
+  EXPECT_EQ(Aec3ConfigToJsonString(config),
+            Aec3ConfigToJsonString(default_config));
+}
+
+TEST(EchoCanceller3Config, ValidatedConfigsAreValid) {
+  EchoCanceller3Config config;
+  config.delay.down_sampling_factor = 983;
+  EXPECT_FALSE(EchoCanceller3Config::Validate(&config));
+  EXPECT_TRUE(EchoCanceller3Config::Validate(&config));
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/api/function_view.h b/third_party/webrtc_aec3/src/api/function_view.h
new file mode 100644
index 0000000..5ae1bd6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/function_view.h
@@ -0,0 +1,130 @@
+/*
+ *  Copyright 2016 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef API_FUNCTION_VIEW_H_
+#define API_FUNCTION_VIEW_H_
+
+#include <type_traits>
+#include <utility>
+
+#include "rtc_base/checks.h"
+
+// Just like std::function, FunctionView will wrap any callable and hide its
+// actual type, exposing only its signature. But unlike std::function,
+// FunctionView doesn't own its callable---it just points to it. Thus, it's a
+// good choice mainly as a function argument when the callable argument will
+// not be called again once the function has returned.
+//
+// Its constructors are implicit, so that callers won't have to convert lambdas
+// and other callables to FunctionView<Blah(Blah, Blah)> explicitly. This is
+// safe because FunctionView is only a reference to the real callable.
+//
+// Example use:
+//
+//   void SomeFunction(rtc::FunctionView<int(int)> index_transform);
+//   ...
+//   SomeFunction([](int i) { return 2 * i + 1; });
+//
+// Note: FunctionView is tiny (essentially just two pointers) and trivially
+// copyable, so it's probably cheaper to pass it by value than by const
+// reference.
+
+namespace rtc {
+
+template <typename T>
+class FunctionView;  // Undefined.
+
+template <typename RetT, typename... ArgT>
+class FunctionView<RetT(ArgT...)> final {
+ public:
+  // Constructor for lambdas and other callables; it accepts every type of
+  // argument except those noted in its enable_if call.
+  template <
+      typename F,
+      typename std::enable_if<
+          // Not for function pointers; we have another constructor for that
+          // below.
+          !std::is_function<typename std::remove_pointer<
+              typename std::remove_reference<F>::type>::type>::value &&
+
+          // Not for nullptr; we have another constructor for that below.
+          !std::is_same<std::nullptr_t,
+                        typename std::remove_cv<F>::type>::value &&
+
+          // Not for FunctionView objects; we have another constructor for that
+          // (the implicitly declared copy constructor).
+          !std::is_same<FunctionView,
+                        typename std::remove_cv<typename std::remove_reference<
+                            F>::type>::type>::value>::type* = nullptr>
+  FunctionView(F&& f)
+      : call_(CallVoidPtr<typename std::remove_reference<F>::type>) {
+    f_.void_ptr = &f;
+  }
+
+  // Constructor that accepts function pointers. If the argument is null, the
+  // result is an empty FunctionView.
+  template <
+      typename F,
+      typename std::enable_if<std::is_function<typename std::remove_pointer<
+          typename std::remove_reference<F>::type>::type>::value>::type* =
+          nullptr>
+  FunctionView(F&& f)
+      : call_(f ? CallFunPtr<typename std::remove_pointer<F>::type> : nullptr) {
+    f_.fun_ptr = reinterpret_cast<void (*)()>(f);
+  }
+
+  // Constructor that accepts nullptr. It creates an empty FunctionView.
+  template <typename F,
+            typename std::enable_if<std::is_same<
+                std::nullptr_t,
+                typename std::remove_cv<F>::type>::value>::type* = nullptr>
+  FunctionView(F&& f) : call_(nullptr) {}
+
+  // Default constructor. Creates an empty FunctionView.
+  FunctionView() : call_(nullptr) {}
+
+  RetT operator()(ArgT... args) const {
+    RTC_DCHECK(call_);
+    return call_(f_, std::forward<ArgT>(args)...);
+  }
+
+  // Returns true if we have a function, false if we don't (i.e., we're null).
+  explicit operator bool() const { return !!call_; }
+
+ private:
+  union VoidUnion {
+    void* void_ptr;
+    void (*fun_ptr)();
+  };
+
+  template <typename F>
+  static RetT CallVoidPtr(VoidUnion vu, ArgT... args) {
+    return (*static_cast<F*>(vu.void_ptr))(std::forward<ArgT>(args)...);
+  }
+  template <typename F>
+  static RetT CallFunPtr(VoidUnion vu, ArgT... args) {
+    return (reinterpret_cast<typename std::add_pointer<F>::type>(vu.fun_ptr))(
+        std::forward<ArgT>(args)...);
+  }
+
+  // A pointer to the callable thing, with type information erased. It's a
+  // union because we have to use separate types depending on if the callable
+  // thing is a function pointer or something else.
+  VoidUnion f_;
+
+  // Pointer to a dispatch function that knows the type of the callable thing
+  // that's stored in f_, and how to call it. A FunctionView object is empty
+  // (null) iff call_ is null.
+  RetT (*call_)(VoidUnion, ArgT...);
+};
+
+}  // namespace rtc
+
+#endif  // API_FUNCTION_VIEW_H_
diff --git a/third_party/webrtc_aec3/src/api/rtp_headers.cc b/third_party/webrtc_aec3/src/api/rtp_headers.cc
new file mode 100644
index 0000000..e0ad9eb
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/rtp_headers.cc
@@ -0,0 +1,54 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "api/rtp_headers.h"
+
+namespace webrtc {
+
+RTPHeaderExtension::RTPHeaderExtension()
+    : hasTransmissionTimeOffset(false),
+      transmissionTimeOffset(0),
+      hasAbsoluteSendTime(false),
+      absoluteSendTime(0),
+      hasTransportSequenceNumber(false),
+      transportSequenceNumber(0),
+      hasAudioLevel(false),
+      voiceActivity(false),
+      audioLevel(0),
+      hasVideoRotation(false),
+      videoRotation(kVideoRotation_0),
+      hasVideoContentType(false),
+      videoContentType(VideoContentType::UNSPECIFIED),
+      has_video_timing(false) {}
+
+RTPHeaderExtension::RTPHeaderExtension(const RTPHeaderExtension& other) =
+    default;
+
+RTPHeaderExtension& RTPHeaderExtension::operator=(
+    const RTPHeaderExtension& other) = default;
+
+RTPHeader::RTPHeader()
+    : markerBit(false),
+      payloadType(0),
+      sequenceNumber(0),
+      timestamp(0),
+      ssrc(0),
+      numCSRCs(0),
+      arrOfCSRCs(),
+      paddingLength(0),
+      headerLength(0),
+      payload_type_frequency(0),
+      extension() {}
+
+RTPHeader::RTPHeader(const RTPHeader& other) = default;
+
+RTPHeader& RTPHeader::operator=(const RTPHeader& other) = default;
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/api/rtp_headers.h b/third_party/webrtc_aec3/src/api/rtp_headers.h
new file mode 100644
index 0000000..cf3d909
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/rtp_headers.h
@@ -0,0 +1,189 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef API_RTP_HEADERS_H_
+#define API_RTP_HEADERS_H_
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include <string>
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "api/units/timestamp.h"
+#include "api/video/color_space.h"
+#include "api/video/video_content_type.h"
+#include "api/video/video_rotation.h"
+#include "api/video/video_timing.h"
+
+namespace webrtc {
+
+struct FeedbackRequest {
+  // Determines whether the recv delta as specified in
+  // https://tools.ietf.org/html/draft-holmer-rmcat-transport-wide-cc-extensions-01
+  // should be included.
+  bool include_timestamps;
+  // Include feedback of received packets in the range [sequence_number -
+  // sequence_count + 1, sequence_number]. That is, no feedback will be sent if
+  // sequence_count is zero.
+  int sequence_count;
+};
+
+// The Absolute Capture Time extension is used to stamp RTP packets with a NTP
+// timestamp showing when the first audio or video frame in a packet was
+// originally captured. The intent of this extension is to provide a way to
+// accomplish audio-to-video synchronization when RTCP-terminating intermediate
+// systems (e.g. mixers) are involved. See:
+// http://www.webrtc.org/experiments/rtp-hdrext/abs-capture-time
+struct AbsoluteCaptureTime {
+  // Absolute capture timestamp is the NTP timestamp of when the first frame in
+  // a packet was originally captured. This timestamp MUST be based on the same
+  // clock as the clock used to generate NTP timestamps for RTCP sender reports
+  // on the capture system.
+  //
+  // Its not always possible to do an NTP clock readout at the exact moment of
+  // when a media frame is captured. A capture system MAY postpone the readout
+  // until a more convenient time. A capture system SHOULD have known delays
+  // (e.g. from hardware buffers) subtracted from the readout to make the final
+  // timestamp as close to the actual capture time as possible.
+  //
+  // This field is encoded as a 64-bit unsigned fixed-point number with the high
+  // 32 bits for the timestamp in seconds and low 32 bits for the fractional
+  // part. This is also known as the UQ32.32 format and is what the RTP
+  // specification defines as the canonical format to represent NTP timestamps.
+  uint64_t absolute_capture_timestamp;
+
+  // Estimated capture clock offset is the senders estimate of the offset
+  // between its own NTP clock and the capture systems NTP clock. The sender is
+  // here defined as the system that owns the NTP clock used to generate the NTP
+  // timestamps for the RTCP sender reports on this stream. The sender system is
+  // typically either the capture system or a mixer.
+  //
+  // This field is encoded as a 64-bit twos complement signed fixed-point
+  // number with the high 32 bits for the seconds and low 32 bits for the
+  // fractional part. Its intended to make it easy for a receiver, that knows
+  // how to estimate the sender systems NTP clock, to also estimate the capture
+  // systems NTP clock:
+  //
+  //   Capture NTP Clock = Sender NTP Clock + Capture Clock Offset
+  absl::optional<int64_t> estimated_capture_clock_offset;
+};
+
+inline bool operator==(const AbsoluteCaptureTime& lhs,
+                       const AbsoluteCaptureTime& rhs) {
+  return (lhs.absolute_capture_timestamp == rhs.absolute_capture_timestamp) &&
+         (lhs.estimated_capture_clock_offset ==
+          rhs.estimated_capture_clock_offset);
+}
+
+inline bool operator!=(const AbsoluteCaptureTime& lhs,
+                       const AbsoluteCaptureTime& rhs) {
+  return !(lhs == rhs);
+}
+
+struct RTPHeaderExtension {
+  RTPHeaderExtension();
+  RTPHeaderExtension(const RTPHeaderExtension& other);
+  RTPHeaderExtension& operator=(const RTPHeaderExtension& other);
+
+  static constexpr int kAbsSendTimeFraction = 18;
+
+  Timestamp GetAbsoluteSendTimestamp() const {
+    RTC_DCHECK(hasAbsoluteSendTime);
+    RTC_DCHECK(absoluteSendTime < (1ul << 24));
+    return Timestamp::Micros((absoluteSendTime * 1000000ll) /
+                             (1 << kAbsSendTimeFraction));
+  }
+
+  TimeDelta GetAbsoluteSendTimeDelta(uint32_t previous_sendtime) const {
+    RTC_DCHECK(hasAbsoluteSendTime);
+    RTC_DCHECK(absoluteSendTime < (1ul << 24));
+    RTC_DCHECK(previous_sendtime < (1ul << 24));
+    int32_t delta =
+        static_cast<int32_t>((absoluteSendTime - previous_sendtime) << 8) >> 8;
+    return TimeDelta::Micros((delta * 1000000ll) / (1 << kAbsSendTimeFraction));
+  }
+
+  bool hasTransmissionTimeOffset;
+  int32_t transmissionTimeOffset;
+  bool hasAbsoluteSendTime;
+  uint32_t absoluteSendTime;
+  absl::optional<AbsoluteCaptureTime> absolute_capture_time;
+  bool hasTransportSequenceNumber;
+  uint16_t transportSequenceNumber;
+  absl::optional<FeedbackRequest> feedback_request;
+
+  // Audio Level includes both level in dBov and voiced/unvoiced bit. See:
+  // https://tools.ietf.org/html/rfc6464#section-3
+  bool hasAudioLevel;
+  bool voiceActivity;
+  uint8_t audioLevel;
+
+  // For Coordination of Video Orientation. See
+  // http://www.etsi.org/deliver/etsi_ts/126100_126199/126114/12.07.00_60/
+  // ts_126114v120700p.pdf
+  bool hasVideoRotation;
+  VideoRotation videoRotation;
+
+  // TODO(ilnik): Refactor this and one above to be absl::optional() and remove
+  // a corresponding bool flag.
+  bool hasVideoContentType;
+  VideoContentType videoContentType;
+
+  bool has_video_timing;
+  VideoSendTiming video_timing;
+
+  VideoPlayoutDelay playout_delay;
+
+  // For identification of a stream when ssrc is not signaled. See
+  // https://tools.ietf.org/html/rfc8852
+  std::string stream_id;
+  std::string repaired_stream_id;
+
+  // For identifying the media section used to interpret this RTP packet. See
+  // https://tools.ietf.org/html/rfc8843
+  std::string mid;
+
+  absl::optional<ColorSpace> color_space;
+};
+
+enum { kRtpCsrcSize = 15 };  // RFC 3550 page 13
+
+struct RTPHeader {
+  RTPHeader();
+  RTPHeader(const RTPHeader& other);
+  RTPHeader& operator=(const RTPHeader& other);
+
+  bool markerBit;
+  uint8_t payloadType;
+  uint16_t sequenceNumber;
+  uint32_t timestamp;
+  uint32_t ssrc;
+  uint8_t numCSRCs;
+  uint32_t arrOfCSRCs[kRtpCsrcSize];
+  size_t paddingLength;
+  size_t headerLength;
+  int payload_type_frequency;
+  RTPHeaderExtension extension;
+};
+
+// RTCP mode to use. Compound mode is described by RFC 4585 and reduced-size
+// RTCP mode is described by RFC 5506.
+enum class RtcpMode { kOff, kCompound, kReducedSize };
+
+enum NetworkState {
+  kNetworkUp,
+  kNetworkDown,
+};
+
+}  // namespace webrtc
+
+#endif  // API_RTP_HEADERS_H_
diff --git a/third_party/webrtc_aec3/src/api/rtp_packet_info.cc b/third_party/webrtc_aec3/src/api/rtp_packet_info.cc
new file mode 100644
index 0000000..a9ebd9d
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/rtp_packet_info.cc
@@ -0,0 +1,60 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "api/rtp_packet_info.h"
+
+#include <algorithm>
+#include <utility>
+
+namespace webrtc {
+
+RtpPacketInfo::RtpPacketInfo()
+    : ssrc_(0), rtp_timestamp_(0), receive_time_ms_(-1) {}
+
+RtpPacketInfo::RtpPacketInfo(
+    uint32_t ssrc,
+    std::vector<uint32_t> csrcs,
+    uint32_t rtp_timestamp,
+    absl::optional<uint8_t> audio_level,
+    absl::optional<AbsoluteCaptureTime> absolute_capture_time,
+    int64_t receive_time_ms)
+    : ssrc_(ssrc),
+      csrcs_(std::move(csrcs)),
+      rtp_timestamp_(rtp_timestamp),
+      audio_level_(audio_level),
+      absolute_capture_time_(absolute_capture_time),
+      receive_time_ms_(receive_time_ms) {}
+
+RtpPacketInfo::RtpPacketInfo(const RTPHeader& rtp_header,
+                             int64_t receive_time_ms)
+    : ssrc_(rtp_header.ssrc),
+      rtp_timestamp_(rtp_header.timestamp),
+      receive_time_ms_(receive_time_ms) {
+  const auto& extension = rtp_header.extension;
+  const auto csrcs_count = std::min<size_t>(rtp_header.numCSRCs, kRtpCsrcSize);
+
+  csrcs_.assign(&rtp_header.arrOfCSRCs[0], &rtp_header.arrOfCSRCs[csrcs_count]);
+
+  if (extension.hasAudioLevel) {
+    audio_level_ = extension.audioLevel;
+  }
+
+  absolute_capture_time_ = extension.absolute_capture_time;
+}
+
+bool operator==(const RtpPacketInfo& lhs, const RtpPacketInfo& rhs) {
+  return (lhs.ssrc() == rhs.ssrc()) && (lhs.csrcs() == rhs.csrcs()) &&
+         (lhs.rtp_timestamp() == rhs.rtp_timestamp()) &&
+         (lhs.audio_level() == rhs.audio_level()) &&
+         (lhs.absolute_capture_time() == rhs.absolute_capture_time()) &&
+         (lhs.receive_time_ms() == rhs.receive_time_ms());
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/api/rtp_packet_info.h b/third_party/webrtc_aec3/src/api/rtp_packet_info.h
new file mode 100644
index 0000000..639ba32
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/rtp_packet_info.h
@@ -0,0 +1,97 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef API_RTP_PACKET_INFO_H_
+#define API_RTP_PACKET_INFO_H_
+
+#include <cstdint>
+#include <utility>
+#include <vector>
+
+#include "absl/types/optional.h"
+#include "api/rtp_headers.h"
+#include "rtc_base/system/rtc_export.h"
+
+namespace webrtc {
+
+//
+// Structure to hold information about a received |RtpPacket|. It is primarily
+// used to carry per-packet information from when a packet is received until
+// the information is passed to |SourceTracker|.
+//
+class RTC_EXPORT RtpPacketInfo {
+ public:
+  RtpPacketInfo();
+
+  RtpPacketInfo(uint32_t ssrc,
+                std::vector<uint32_t> csrcs,
+                uint32_t rtp_timestamp,
+                absl::optional<uint8_t> audio_level,
+                absl::optional<AbsoluteCaptureTime> absolute_capture_time,
+                int64_t receive_time_ms);
+
+  RtpPacketInfo(const RTPHeader& rtp_header, int64_t receive_time_ms);
+
+  RtpPacketInfo(const RtpPacketInfo& other) = default;
+  RtpPacketInfo(RtpPacketInfo&& other) = default;
+  RtpPacketInfo& operator=(const RtpPacketInfo& other) = default;
+  RtpPacketInfo& operator=(RtpPacketInfo&& other) = default;
+
+  uint32_t ssrc() const { return ssrc_; }
+  void set_ssrc(uint32_t value) { ssrc_ = value; }
+
+  const std::vector<uint32_t>& csrcs() const { return csrcs_; }
+  void set_csrcs(std::vector<uint32_t> value) { csrcs_ = std::move(value); }
+
+  uint32_t rtp_timestamp() const { return rtp_timestamp_; }
+  void set_rtp_timestamp(uint32_t value) { rtp_timestamp_ = value; }
+
+  absl::optional<uint8_t> audio_level() const { return audio_level_; }
+  void set_audio_level(absl::optional<uint8_t> value) { audio_level_ = value; }
+
+  const absl::optional<AbsoluteCaptureTime>& absolute_capture_time() const {
+    return absolute_capture_time_;
+  }
+  void set_absolute_capture_time(
+      const absl::optional<AbsoluteCaptureTime>& value) {
+    absolute_capture_time_ = value;
+  }
+
+  int64_t receive_time_ms() const { return receive_time_ms_; }
+  void set_receive_time_ms(int64_t value) { receive_time_ms_ = value; }
+
+ private:
+  // Fields from the RTP header:
+  // https://tools.ietf.org/html/rfc3550#section-5.1
+  uint32_t ssrc_;
+  std::vector<uint32_t> csrcs_;
+  uint32_t rtp_timestamp_;
+
+  // Fields from the Audio Level header extension:
+  // https://tools.ietf.org/html/rfc6464#section-3
+  absl::optional<uint8_t> audio_level_;
+
+  // Fields from the Absolute Capture Time header extension:
+  // http://www.webrtc.org/experiments/rtp-hdrext/abs-capture-time
+  absl::optional<AbsoluteCaptureTime> absolute_capture_time_;
+
+  // Local |webrtc::Clock|-based timestamp of when the packet was received.
+  int64_t receive_time_ms_;
+};
+
+bool operator==(const RtpPacketInfo& lhs, const RtpPacketInfo& rhs);
+
+inline bool operator!=(const RtpPacketInfo& lhs, const RtpPacketInfo& rhs) {
+  return !(lhs == rhs);
+}
+
+}  // namespace webrtc
+
+#endif  // API_RTP_PACKET_INFO_H_
diff --git a/third_party/webrtc_aec3/src/api/scoped_refptr.h b/third_party/webrtc_aec3/src/api/scoped_refptr.h
new file mode 100644
index 0000000..4e3f0eb
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/scoped_refptr.h
@@ -0,0 +1,165 @@
+/*
+ *  Copyright 2011 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// Originally these classes are from Chromium.
+// http://src.chromium.org/viewvc/chrome/trunk/src/base/memory/ref_counted.h?view=markup
+
+//
+// A smart pointer class for reference counted objects.  Use this class instead
+// of calling AddRef and Release manually on a reference counted object to
+// avoid common memory leaks caused by forgetting to Release an object
+// reference.  Sample usage:
+//
+//   class MyFoo : public RefCounted<MyFoo> {
+//    ...
+//   };
+//
+//   void some_function() {
+//     scoped_refptr<MyFoo> foo = new MyFoo();
+//     foo->Method(param);
+//     // |foo| is released when this function returns
+//   }
+//
+//   void some_other_function() {
+//     scoped_refptr<MyFoo> foo = new MyFoo();
+//     ...
+//     foo = nullptr;  // explicitly releases |foo|
+//     ...
+//     if (foo)
+//       foo->Method(param);
+//   }
+//
+// The above examples show how scoped_refptr<T> acts like a pointer to T.
+// Given two scoped_refptr<T> classes, it is also possible to exchange
+// references between the two objects, like so:
+//
+//   {
+//     scoped_refptr<MyFoo> a = new MyFoo();
+//     scoped_refptr<MyFoo> b;
+//
+//     b.swap(a);
+//     // now, |b| references the MyFoo object, and |a| references null.
+//   }
+//
+// To make both |a| and |b| in the above example reference the same MyFoo
+// object, simply use the assignment operator:
+//
+//   {
+//     scoped_refptr<MyFoo> a = new MyFoo();
+//     scoped_refptr<MyFoo> b;
+//
+//     b = a;
+//     // now, |a| and |b| each own a reference to the same MyFoo object.
+//   }
+//
+
+#ifndef API_SCOPED_REFPTR_H_
+#define API_SCOPED_REFPTR_H_
+
+#include <memory>
+#include <utility>
+
+namespace rtc {
+
+template <class T>
+class scoped_refptr {
+ public:
+  typedef T element_type;
+
+  scoped_refptr() : ptr_(nullptr) {}
+
+  scoped_refptr(T* p) : ptr_(p) {  // NOLINT(runtime/explicit)
+    if (ptr_)
+      ptr_->AddRef();
+  }
+
+  scoped_refptr(const scoped_refptr<T>& r) : ptr_(r.ptr_) {
+    if (ptr_)
+      ptr_->AddRef();
+  }
+
+  template <typename U>
+  scoped_refptr(const scoped_refptr<U>& r) : ptr_(r.get()) {
+    if (ptr_)
+      ptr_->AddRef();
+  }
+
+  // Move constructors.
+  scoped_refptr(scoped_refptr<T>&& r) noexcept : ptr_(r.release()) {}
+
+  template <typename U>
+  scoped_refptr(scoped_refptr<U>&& r) noexcept : ptr_(r.release()) {}
+
+  ~scoped_refptr() {
+    if (ptr_)
+      ptr_->Release();
+  }
+
+  T* get() const { return ptr_; }
+  operator T*() const { return ptr_; }
+  T& operator*() const { return *ptr_; }
+  T* operator->() const { return ptr_; }
+
+  // Returns the (possibly null) raw pointer, and makes the scoped_refptr hold a
+  // null pointer, all without touching the reference count of the underlying
+  // pointed-to object. The object is still reference counted, and the caller of
+  // release() is now the proud owner of one reference, so it is responsible for
+  // calling Release() once on the object when no longer using it.
+  T* release() {
+    T* retVal = ptr_;
+    ptr_ = nullptr;
+    return retVal;
+  }
+
+  scoped_refptr<T>& operator=(T* p) {
+    // AddRef first so that self assignment should work
+    if (p)
+      p->AddRef();
+    if (ptr_)
+      ptr_->Release();
+    ptr_ = p;
+    return *this;
+  }
+
+  scoped_refptr<T>& operator=(const scoped_refptr<T>& r) {
+    return *this = r.ptr_;
+  }
+
+  template <typename U>
+  scoped_refptr<T>& operator=(const scoped_refptr<U>& r) {
+    return *this = r.get();
+  }
+
+  scoped_refptr<T>& operator=(scoped_refptr<T>&& r) noexcept {
+    scoped_refptr<T>(std::move(r)).swap(*this);
+    return *this;
+  }
+
+  template <typename U>
+  scoped_refptr<T>& operator=(scoped_refptr<U>&& r) noexcept {
+    scoped_refptr<T>(std::move(r)).swap(*this);
+    return *this;
+  }
+
+  void swap(T** pp) noexcept {
+    T* p = ptr_;
+    ptr_ = *pp;
+    *pp = p;
+  }
+
+  void swap(scoped_refptr<T>& r) noexcept { swap(&r.ptr_); }
+
+ protected:
+  T* ptr_;
+};
+
+}  // namespace rtc
+
+#endif  // API_SCOPED_REFPTR_H_
diff --git a/third_party/webrtc_aec3/src/api/units/time_delta.cc b/third_party/webrtc_aec3/src/api/units/time_delta.cc
new file mode 100644
index 0000000..31bf3e0
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/units/time_delta.cc
@@ -0,0 +1,36 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "api/units/time_delta.h"
+
+#include "api/array_view.h"
+#include "rtc_base/strings/string_builder.h"
+
+namespace webrtc {
+
+std::string ToString(TimeDelta value) {
+  char buf[64];
+  rtc::SimpleStringBuilder sb(buf);
+  if (value.IsPlusInfinity()) {
+    sb << "+inf ms";
+  } else if (value.IsMinusInfinity()) {
+    sb << "-inf ms";
+  } else {
+    if (value.us() == 0 || (value.us() % 1000) != 0)
+      sb << value.us() << " us";
+    else if (value.ms() % 1000 != 0)
+      sb << value.ms() << " ms";
+    else
+      sb << value.seconds() << " s";
+  }
+  return sb.str();
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/api/units/time_delta.h b/third_party/webrtc_aec3/src/api/units/time_delta.h
new file mode 100644
index 0000000..6f19103
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/units/time_delta.h
@@ -0,0 +1,105 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef API_UNITS_TIME_DELTA_H_
+#define API_UNITS_TIME_DELTA_H_
+
+#ifdef WEBRTC_UNIT_TEST
+#include <ostream>  // no-presubmit-check TODO(webrtc:8982)
+#endif              // WEBRTC_UNIT_TEST
+
+#include <cstdlib>
+#include <string>
+#include <type_traits>
+
+#include "rtc_base/units/unit_base.h"
+
+namespace webrtc {
+
+// TimeDelta represents the difference between two timestamps. Commonly this can
+// be a duration. However since two Timestamps are not guaranteed to have the
+// same epoch (they might come from different computers, making exact
+// synchronisation infeasible), the duration covered by a TimeDelta can be
+// undefined. To simplify usage, it can be constructed and converted to
+// different units, specifically seconds (s), milliseconds (ms) and
+// microseconds (us).
+class TimeDelta final : public rtc_units_impl::RelativeUnit<TimeDelta> {
+ public:
+  template <typename T>
+  static constexpr TimeDelta Seconds(T value) {
+    static_assert(std::is_arithmetic<T>::value, "");
+    return FromFraction(1'000'000, value);
+  }
+  template <typename T>
+  static constexpr TimeDelta Millis(T value) {
+    static_assert(std::is_arithmetic<T>::value, "");
+    return FromFraction(1'000, value);
+  }
+  template <typename T>
+  static constexpr TimeDelta Micros(T value) {
+    static_assert(std::is_arithmetic<T>::value, "");
+    return FromValue(value);
+  }
+
+  TimeDelta() = delete;
+
+  template <typename T = int64_t>
+  constexpr T seconds() const {
+    return ToFraction<1000000, T>();
+  }
+  template <typename T = int64_t>
+  constexpr T ms() const {
+    return ToFraction<1000, T>();
+  }
+  template <typename T = int64_t>
+  constexpr T us() const {
+    return ToValue<T>();
+  }
+  template <typename T = int64_t>
+  constexpr T ns() const {
+    return ToMultiple<1000, T>();
+  }
+
+  constexpr int64_t seconds_or(int64_t fallback_value) const {
+    return ToFractionOr<1000000>(fallback_value);
+  }
+  constexpr int64_t ms_or(int64_t fallback_value) const {
+    return ToFractionOr<1000>(fallback_value);
+  }
+  constexpr int64_t us_or(int64_t fallback_value) const {
+    return ToValueOr(fallback_value);
+  }
+
+  constexpr TimeDelta Abs() const {
+    return us() < 0 ? TimeDelta::Micros(-us()) : *this;
+  }
+
+ private:
+  friend class rtc_units_impl::UnitBase<TimeDelta>;
+  using RelativeUnit::RelativeUnit;
+  static constexpr bool one_sided = false;
+};
+
+std::string ToString(TimeDelta value);
+inline std::string ToLogString(TimeDelta value) {
+  return ToString(value);
+}
+
+#ifdef WEBRTC_UNIT_TEST
+inline std::ostream& operator<<(  // no-presubmit-check TODO(webrtc:8982)
+    std::ostream& stream,         // no-presubmit-check TODO(webrtc:8982)
+    TimeDelta value) {
+  return stream << ToString(value);
+}
+#endif  // WEBRTC_UNIT_TEST
+
+}  // namespace webrtc
+
+#endif  // API_UNITS_TIME_DELTA_H_
diff --git a/third_party/webrtc_aec3/src/api/units/timestamp.cc b/third_party/webrtc_aec3/src/api/units/timestamp.cc
new file mode 100644
index 0000000..fc4f419
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/units/timestamp.cc
@@ -0,0 +1,34 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "api/units/timestamp.h"
+
+#include "api/array_view.h"
+#include "rtc_base/strings/string_builder.h"
+
+namespace webrtc {
+std::string ToString(Timestamp value) {
+  char buf[64];
+  rtc::SimpleStringBuilder sb(buf);
+  if (value.IsPlusInfinity()) {
+    sb << "+inf ms";
+  } else if (value.IsMinusInfinity()) {
+    sb << "-inf ms";
+  } else {
+    if (value.us() == 0 || (value.us() % 1000) != 0)
+      sb << value.us() << " us";
+    else if (value.ms() % 1000 != 0)
+      sb << value.ms() << " ms";
+    else
+      sb << value.seconds() << " s";
+  }
+  return sb.str();
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/api/units/timestamp.h b/third_party/webrtc_aec3/src/api/units/timestamp.h
new file mode 100644
index 0000000..1e9f9d1
--- /dev/null
+++ b/third_party/webrtc_aec3/src/api/units/timestamp.h
@@ -0,0 +1,138 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef API_UNITS_TIMESTAMP_H_
+#define API_UNITS_TIMESTAMP_H_
+
+#ifdef WEBRTC_UNIT_TEST
+#include <ostream>  // no-presubmit-check TODO(webrtc:8982)
+#endif              // WEBRTC_UNIT_TEST
+
+#include <string>
+#include <type_traits>
+
+#include "api/units/time_delta.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+// Timestamp represents the time that has passed since some unspecified epoch.
+// The epoch is assumed to be before any represented timestamps, this means that
+// negative values are not valid. The most notable feature is that the
+// difference of two Timestamps results in a TimeDelta.
+class Timestamp final : public rtc_units_impl::UnitBase<Timestamp> {
+ public:
+  template <typename T>
+  static constexpr Timestamp Seconds(T value) {
+    static_assert(std::is_arithmetic<T>::value, "");
+    return FromFraction(1'000'000, value);
+  }
+  template <typename T>
+  static constexpr Timestamp Millis(T value) {
+    static_assert(std::is_arithmetic<T>::value, "");
+    return FromFraction(1'000, value);
+  }
+  template <typename T>
+  static constexpr Timestamp Micros(T value) {
+    static_assert(std::is_arithmetic<T>::value, "");
+    return FromValue(value);
+  }
+
+  Timestamp() = delete;
+
+  template <typename T = int64_t>
+  constexpr T seconds() const {
+    return ToFraction<1000000, T>();
+  }
+  template <typename T = int64_t>
+  constexpr T ms() const {
+    return ToFraction<1000, T>();
+  }
+  template <typename T = int64_t>
+  constexpr T us() const {
+    return ToValue<T>();
+  }
+
+  constexpr int64_t seconds_or(int64_t fallback_value) const {
+    return ToFractionOr<1000000>(fallback_value);
+  }
+  constexpr int64_t ms_or(int64_t fallback_value) const {
+    return ToFractionOr<1000>(fallback_value);
+  }
+  constexpr int64_t us_or(int64_t fallback_value) const {
+    return ToValueOr(fallback_value);
+  }
+
+  constexpr Timestamp operator+(const TimeDelta delta) const {
+    if (IsPlusInfinity() || delta.IsPlusInfinity()) {
+      RTC_DCHECK(!IsMinusInfinity());
+      RTC_DCHECK(!delta.IsMinusInfinity());
+      return PlusInfinity();
+    } else if (IsMinusInfinity() || delta.IsMinusInfinity()) {
+      RTC_DCHECK(!IsPlusInfinity());
+      RTC_DCHECK(!delta.IsPlusInfinity());
+      return MinusInfinity();
+    }
+    return Timestamp::Micros(us() + delta.us());
+  }
+  constexpr Timestamp operator-(const TimeDelta delta) const {
+    if (IsPlusInfinity() || delta.IsMinusInfinity()) {
+      RTC_DCHECK(!IsMinusInfinity());
+      RTC_DCHECK(!delta.IsPlusInfinity());
+      return PlusInfinity();
+    } else if (IsMinusInfinity() || delta.IsPlusInfinity()) {
+      RTC_DCHECK(!IsPlusInfinity());
+      RTC_DCHECK(!delta.IsMinusInfinity());
+      return MinusInfinity();
+    }
+    return Timestamp::Micros(us() - delta.us());
+  }
+  constexpr TimeDelta operator-(const Timestamp other) const {
+    if (IsPlusInfinity() || other.IsMinusInfinity()) {
+      RTC_DCHECK(!IsMinusInfinity());
+      RTC_DCHECK(!other.IsPlusInfinity());
+      return TimeDelta::PlusInfinity();
+    } else if (IsMinusInfinity() || other.IsPlusInfinity()) {
+      RTC_DCHECK(!IsPlusInfinity());
+      RTC_DCHECK(!other.IsMinusInfinity());
+      return TimeDelta::MinusInfinity();
+    }
+    return TimeDelta::Micros(us() - other.us());
+  }
+  constexpr Timestamp& operator-=(const TimeDelta delta) {
+    *this = *this - delta;
+    return *this;
+  }
+  constexpr Timestamp& operator+=(const TimeDelta delta) {
+    *this = *this + delta;
+    return *this;
+  }
+
+ private:
+  friend class rtc_units_impl::UnitBase<Timestamp>;
+  using UnitBase::UnitBase;
+  static constexpr bool one_sided = true;
+};
+
+std::string ToString(Timestamp value);
+inline std::string ToLogString(Timestamp value) {
+  return ToString(value);
+}
+
+#ifdef WEBRTC_UNIT_TEST
+inline std::ostream& operator<<(  // no-presubmit-check TODO(webrtc:8982)
+    std::ostream& stream,         // no-presubmit-check TODO(webrtc:8982)
+    Timestamp value) {
+  return stream << ToString(value);
+}
+#endif  // WEBRTC_UNIT_TEST
+
+}  // namespace webrtc
+
+#endif  // API_UNITS_TIMESTAMP_H_
diff --git a/third_party/webrtc_aec3/src/common_audio/audio_util.cc b/third_party/webrtc_aec3/src/common_audio/audio_util.cc
new file mode 100644
index 0000000..b1e4d9a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/audio_util.cc
@@ -0,0 +1,54 @@
+/*
+ *  Copyright (c) 2013 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "common_audio/include/audio_util.h"
+
+namespace webrtc {
+
+void FloatToS16(const float* src, size_t size, int16_t* dest) {
+  for (size_t i = 0; i < size; ++i)
+    dest[i] = FloatToS16(src[i]);
+}
+
+void S16ToFloat(const int16_t* src, size_t size, float* dest) {
+  for (size_t i = 0; i < size; ++i)
+    dest[i] = S16ToFloat(src[i]);
+}
+
+void S16ToFloatS16(const int16_t* src, size_t size, float* dest) {
+  for (size_t i = 0; i < size; ++i)
+    dest[i] = src[i];
+}
+
+void FloatS16ToS16(const float* src, size_t size, int16_t* dest) {
+  for (size_t i = 0; i < size; ++i)
+    dest[i] = FloatS16ToS16(src[i]);
+}
+
+void FloatToFloatS16(const float* src, size_t size, float* dest) {
+  for (size_t i = 0; i < size; ++i)
+    dest[i] = FloatToFloatS16(src[i]);
+}
+
+void FloatS16ToFloat(const float* src, size_t size, float* dest) {
+  for (size_t i = 0; i < size; ++i)
+    dest[i] = FloatS16ToFloat(src[i]);
+}
+
+template <>
+void DownmixInterleavedToMono<int16_t>(const int16_t* interleaved,
+                                       size_t num_frames,
+                                       int num_channels,
+                                       int16_t* deinterleaved) {
+  DownmixInterleavedToMonoImpl<int16_t, int32_t>(interleaved, num_frames,
+                                                 num_channels, deinterleaved);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/common_audio/channel_buffer.cc b/third_party/webrtc_aec3/src/common_audio/channel_buffer.cc
new file mode 100644
index 0000000..b9b8c25
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/channel_buffer.cc
@@ -0,0 +1,80 @@
+/*
+ *  Copyright (c) 2014 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "common_audio/channel_buffer.h"
+
+#include <cstdint>
+
+#include "common_audio/include/audio_util.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+IFChannelBuffer::IFChannelBuffer(size_t num_frames,
+                                 size_t num_channels,
+                                 size_t num_bands)
+    : ivalid_(true),
+      ibuf_(num_frames, num_channels, num_bands),
+      fvalid_(true),
+      fbuf_(num_frames, num_channels, num_bands) {}
+
+IFChannelBuffer::~IFChannelBuffer() = default;
+
+ChannelBuffer<int16_t>* IFChannelBuffer::ibuf() {
+  RefreshI();
+  fvalid_ = false;
+  return &ibuf_;
+}
+
+ChannelBuffer<float>* IFChannelBuffer::fbuf() {
+  RefreshF();
+  ivalid_ = false;
+  return &fbuf_;
+}
+
+const ChannelBuffer<int16_t>* IFChannelBuffer::ibuf_const() const {
+  RefreshI();
+  return &ibuf_;
+}
+
+const ChannelBuffer<float>* IFChannelBuffer::fbuf_const() const {
+  RefreshF();
+  return &fbuf_;
+}
+
+void IFChannelBuffer::RefreshF() const {
+  if (!fvalid_) {
+    RTC_DCHECK(ivalid_);
+    fbuf_.set_num_channels(ibuf_.num_channels());
+    const int16_t* const* int_channels = ibuf_.channels();
+    float* const* float_channels = fbuf_.channels();
+    for (size_t i = 0; i < ibuf_.num_channels(); ++i) {
+      for (size_t j = 0; j < ibuf_.num_frames(); ++j) {
+        float_channels[i][j] = int_channels[i][j];
+      }
+    }
+    fvalid_ = true;
+  }
+}
+
+void IFChannelBuffer::RefreshI() const {
+  if (!ivalid_) {
+    RTC_DCHECK(fvalid_);
+    int16_t* const* int_channels = ibuf_.channels();
+    ibuf_.set_num_channels(fbuf_.num_channels());
+    const float* const* float_channels = fbuf_.channels();
+    for (size_t i = 0; i < fbuf_.num_channels(); ++i) {
+      FloatS16ToS16(float_channels[i], ibuf_.num_frames(), int_channels[i]);
+    }
+    ivalid_ = true;
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/common_audio/channel_buffer.h b/third_party/webrtc_aec3/src/common_audio/channel_buffer.h
new file mode 100644
index 0000000..f027080
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/channel_buffer.h
@@ -0,0 +1,215 @@
+/*
+ *  Copyright (c) 2014 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef COMMON_AUDIO_CHANNEL_BUFFER_H_
+#define COMMON_AUDIO_CHANNEL_BUFFER_H_
+
+#include <string.h>
+
+#include <memory>
+#include <vector>
+
+#include "api/array_view.h"
+#include "common_audio/include/audio_util.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/gtest_prod_util.h"
+
+namespace webrtc {
+
+// Helper to encapsulate a contiguous data buffer, full or split into frequency
+// bands, with access to a pointer arrays of the deinterleaved channels and
+// bands. The buffer is zero initialized at creation.
+//
+// The buffer structure is showed below for a 2 channel and 2 bands case:
+//
+// |data_|:
+// { [ --- b1ch1 --- ] [ --- b2ch1 --- ] [ --- b1ch2 --- ] [ --- b2ch2 --- ] }
+//
+// The pointer arrays for the same example are as follows:
+//
+// |channels_|:
+// { [ b1ch1* ] [ b1ch2* ] [ b2ch1* ] [ b2ch2* ] }
+//
+// |bands_|:
+// { [ b1ch1* ] [ b2ch1* ] [ b1ch2* ] [ b2ch2* ] }
+template <typename T>
+class ChannelBuffer {
+ public:
+  ChannelBuffer(size_t num_frames, size_t num_channels, size_t num_bands = 1)
+      : data_(new T[num_frames * num_channels]()),
+        channels_(new T*[num_channels * num_bands]),
+        bands_(new T*[num_channels * num_bands]),
+        num_frames_(num_frames),
+        num_frames_per_band_(num_frames / num_bands),
+        num_allocated_channels_(num_channels),
+        num_channels_(num_channels),
+        num_bands_(num_bands),
+        bands_view_(num_allocated_channels_,
+                    std::vector<rtc::ArrayView<T>>(num_bands_)),
+        channels_view_(
+            num_bands_,
+            std::vector<rtc::ArrayView<T>>(num_allocated_channels_)) {
+    // Temporarily cast away const_ness to allow populating the array views.
+    auto* bands_view =
+        const_cast<std::vector<std::vector<rtc::ArrayView<T>>>*>(&bands_view_);
+    auto* channels_view =
+        const_cast<std::vector<std::vector<rtc::ArrayView<T>>>*>(
+            &channels_view_);
+
+    for (size_t ch = 0; ch < num_allocated_channels_; ++ch) {
+      for (size_t band = 0; band < num_bands_; ++band) {
+        (*channels_view)[band][ch] = rtc::ArrayView<T>(
+            &data_[ch * num_frames_ + band * num_frames_per_band_],
+            num_frames_per_band_);
+        (*bands_view)[ch][band] = channels_view_[band][ch];
+        channels_[band * num_allocated_channels_ + ch] =
+            channels_view_[band][ch].data();
+        bands_[ch * num_bands_ + band] =
+            channels_[band * num_allocated_channels_ + ch];
+      }
+    }
+  }
+
+  // Returns a pointer array to the channels.
+  // If band is explicitly specificed, the channels for a specific band are
+  // returned and the usage becomes: channels(band)[channel][sample].
+  // Where:
+  // 0 <= band < |num_bands_|
+  // 0 <= channel < |num_allocated_channels_|
+  // 0 <= sample < |num_frames_per_band_|
+
+  // If band is not explicitly specified, the full-band channels (or lower band
+  // channels) are returned and the usage becomes: channels()[channel][sample].
+  // Where:
+  // 0 <= channel < |num_allocated_channels_|
+  // 0 <= sample < |num_frames_|
+  const T* const* channels(size_t band = 0) const {
+    RTC_DCHECK_LT(band, num_bands_);
+    return &channels_[band * num_allocated_channels_];
+  }
+  T* const* channels(size_t band = 0) {
+    const ChannelBuffer<T>* t = this;
+    return const_cast<T* const*>(t->channels(band));
+  }
+  rtc::ArrayView<const rtc::ArrayView<T>> channels_view(size_t band = 0) {
+    return channels_view_[band];
+  }
+  rtc::ArrayView<const rtc::ArrayView<T>> channels_view(size_t band = 0) const {
+    return channels_view_[band];
+  }
+
+  // Returns a pointer array to the bands for a specific channel.
+  // Usage:
+  // bands(channel)[band][sample].
+  // Where:
+  // 0 <= channel < |num_channels_|
+  // 0 <= band < |num_bands_|
+  // 0 <= sample < |num_frames_per_band_|
+  const T* const* bands(size_t channel) const {
+    RTC_DCHECK_LT(channel, num_channels_);
+    RTC_DCHECK_GE(channel, 0);
+    return &bands_[channel * num_bands_];
+  }
+  T* const* bands(size_t channel) {
+    const ChannelBuffer<T>* t = this;
+    return const_cast<T* const*>(t->bands(channel));
+  }
+
+  rtc::ArrayView<const rtc::ArrayView<T>> bands_view(size_t channel) {
+    return bands_view_[channel];
+  }
+  rtc::ArrayView<const rtc::ArrayView<T>> bands_view(size_t channel) const {
+    return bands_view_[channel];
+  }
+
+  // Sets the |slice| pointers to the |start_frame| position for each channel.
+  // Returns |slice| for convenience.
+  const T* const* Slice(T** slice, size_t start_frame) const {
+    RTC_DCHECK_LT(start_frame, num_frames_);
+    for (size_t i = 0; i < num_channels_; ++i)
+      slice[i] = &channels_[i][start_frame];
+    return slice;
+  }
+  T** Slice(T** slice, size_t start_frame) {
+    const ChannelBuffer<T>* t = this;
+    return const_cast<T**>(t->Slice(slice, start_frame));
+  }
+
+  size_t num_frames() const { return num_frames_; }
+  size_t num_frames_per_band() const { return num_frames_per_band_; }
+  size_t num_channels() const { return num_channels_; }
+  size_t num_bands() const { return num_bands_; }
+  size_t size() const { return num_frames_ * num_allocated_channels_; }
+
+  void set_num_channels(size_t num_channels) {
+    RTC_DCHECK_LE(num_channels, num_allocated_channels_);
+    num_channels_ = num_channels;
+  }
+
+  void SetDataForTesting(const T* data, size_t size) {
+    RTC_CHECK_EQ(size, this->size());
+    memcpy(data_.get(), data, size * sizeof(*data));
+  }
+
+ private:
+  std::unique_ptr<T[]> data_;
+  std::unique_ptr<T*[]> channels_;
+  std::unique_ptr<T*[]> bands_;
+  const size_t num_frames_;
+  const size_t num_frames_per_band_;
+  // Number of channels the internal buffer holds.
+  const size_t num_allocated_channels_;
+  // Number of channels the user sees.
+  size_t num_channels_;
+  const size_t num_bands_;
+  const std::vector<std::vector<rtc::ArrayView<T>>> bands_view_;
+  const std::vector<std::vector<rtc::ArrayView<T>>> channels_view_;
+};
+
+// One int16_t and one float ChannelBuffer that are kept in sync. The sync is
+// broken when someone requests write access to either ChannelBuffer, and
+// reestablished when someone requests the outdated ChannelBuffer. It is
+// therefore safe to use the return value of ibuf_const() and fbuf_const()
+// until the next call to ibuf() or fbuf(), and the return value of ibuf() and
+// fbuf() until the next call to any of the other functions.
+class IFChannelBuffer {
+ public:
+  IFChannelBuffer(size_t num_frames, size_t num_channels, size_t num_bands = 1);
+  ~IFChannelBuffer();
+
+  ChannelBuffer<int16_t>* ibuf();
+  ChannelBuffer<float>* fbuf();
+  const ChannelBuffer<int16_t>* ibuf_const() const;
+  const ChannelBuffer<float>* fbuf_const() const;
+
+  size_t num_frames() const { return ibuf_.num_frames(); }
+  size_t num_frames_per_band() const { return ibuf_.num_frames_per_band(); }
+  size_t num_channels() const {
+    return ivalid_ ? ibuf_.num_channels() : fbuf_.num_channels();
+  }
+  void set_num_channels(size_t num_channels) {
+    ibuf_.set_num_channels(num_channels);
+    fbuf_.set_num_channels(num_channels);
+  }
+  size_t num_bands() const { return ibuf_.num_bands(); }
+
+ private:
+  void RefreshF() const;
+  void RefreshI() const;
+
+  mutable bool ivalid_;
+  mutable ChannelBuffer<int16_t> ibuf_;
+  mutable bool fvalid_;
+  mutable ChannelBuffer<float> fbuf_;
+};
+
+}  // namespace webrtc
+
+#endif  // COMMON_AUDIO_CHANNEL_BUFFER_H_
diff --git a/third_party/webrtc_aec3/src/common_audio/include/audio_util.h b/third_party/webrtc_aec3/src/common_audio/include/audio_util.h
new file mode 100644
index 0000000..f6b6bfd
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/include/audio_util.h
@@ -0,0 +1,214 @@
+/*
+ *  Copyright (c) 2013 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef COMMON_AUDIO_INCLUDE_AUDIO_UTIL_H_
+#define COMMON_AUDIO_INCLUDE_AUDIO_UTIL_H_
+
+#include <stdint.h>
+
+#include <algorithm>
+#include <cmath>
+#include <cstring>
+#include <limits>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+typedef std::numeric_limits<int16_t> limits_int16;
+
+// The conversion functions use the following naming convention:
+// S16:      int16_t [-32768, 32767]
+// Float:    float   [-1.0, 1.0]
+// FloatS16: float   [-32768.0, 32768.0]
+// Dbfs: float [-20.0*log(10, 32768), 0] = [-90.3, 0]
+// The ratio conversion functions use this naming convention:
+// Ratio: float (0, +inf)
+// Db: float (-inf, +inf)
+static inline float S16ToFloat(int16_t v) {
+  constexpr float kScaling = 1.f / 32768.f;
+  return v * kScaling;
+}
+
+static inline int16_t FloatS16ToS16(float v) {
+  v = std::min(v, 32767.f);
+  v = std::max(v, -32768.f);
+  return static_cast<int16_t>(v + std::copysign(0.5f, v));
+}
+
+static inline int16_t FloatToS16(float v) {
+  v *= 32768.f;
+  v = std::min(v, 32767.f);
+  v = std::max(v, -32768.f);
+  return static_cast<int16_t>(v + std::copysign(0.5f, v));
+}
+
+static inline float FloatToFloatS16(float v) {
+  v = std::min(v, 1.f);
+  v = std::max(v, -1.f);
+  return v * 32768.f;
+}
+
+static inline float FloatS16ToFloat(float v) {
+  v = std::min(v, 32768.f);
+  v = std::max(v, -32768.f);
+  constexpr float kScaling = 1.f / 32768.f;
+  return v * kScaling;
+}
+
+void FloatToS16(const float* src, size_t size, int16_t* dest);
+void S16ToFloat(const int16_t* src, size_t size, float* dest);
+void S16ToFloatS16(const int16_t* src, size_t size, float* dest);
+void FloatS16ToS16(const float* src, size_t size, int16_t* dest);
+void FloatToFloatS16(const float* src, size_t size, float* dest);
+void FloatS16ToFloat(const float* src, size_t size, float* dest);
+
+inline float DbToRatio(float v) {
+  return std::pow(10.0f, v / 20.0f);
+}
+
+inline float DbfsToFloatS16(float v) {
+  static constexpr float kMaximumAbsFloatS16 = -limits_int16::min();
+  return DbToRatio(v) * kMaximumAbsFloatS16;
+}
+
+inline float FloatS16ToDbfs(float v) {
+  RTC_DCHECK_GE(v, 0);
+
+  // kMinDbfs is equal to -20.0 * log10(-limits_int16::min())
+  static constexpr float kMinDbfs = -90.30899869919436f;
+  if (v <= 1.0f) {
+    return kMinDbfs;
+  }
+  // Equal to 20 * log10(v / (-limits_int16::min()))
+  return 20.0f * std::log10(v) + kMinDbfs;
+}
+
+// Copy audio from |src| channels to |dest| channels unless |src| and |dest|
+// point to the same address. |src| and |dest| must have the same number of
+// channels, and there must be sufficient space allocated in |dest|.
+template <typename T>
+void CopyAudioIfNeeded(const T* const* src,
+                       int num_frames,
+                       int num_channels,
+                       T* const* dest) {
+  for (int i = 0; i < num_channels; ++i) {
+    if (src[i] != dest[i]) {
+      std::copy(src[i], src[i] + num_frames, dest[i]);
+    }
+  }
+}
+
+// Deinterleave audio from |interleaved| to the channel buffers pointed to
+// by |deinterleaved|. There must be sufficient space allocated in the
+// |deinterleaved| buffers (|num_channel| buffers with |samples_per_channel|
+// per buffer).
+template <typename T>
+void Deinterleave(const T* interleaved,
+                  size_t samples_per_channel,
+                  size_t num_channels,
+                  T* const* deinterleaved) {
+  for (size_t i = 0; i < num_channels; ++i) {
+    T* channel = deinterleaved[i];
+    size_t interleaved_idx = i;
+    for (size_t j = 0; j < samples_per_channel; ++j) {
+      channel[j] = interleaved[interleaved_idx];
+      interleaved_idx += num_channels;
+    }
+  }
+}
+
+// Interleave audio from the channel buffers pointed to by |deinterleaved| to
+// |interleaved|. There must be sufficient space allocated in |interleaved|
+// (|samples_per_channel| * |num_channels|).
+template <typename T>
+void Interleave(const T* const* deinterleaved,
+                size_t samples_per_channel,
+                size_t num_channels,
+                T* interleaved) {
+  for (size_t i = 0; i < num_channels; ++i) {
+    const T* channel = deinterleaved[i];
+    size_t interleaved_idx = i;
+    for (size_t j = 0; j < samples_per_channel; ++j) {
+      interleaved[interleaved_idx] = channel[j];
+      interleaved_idx += num_channels;
+    }
+  }
+}
+
+// Copies audio from a single channel buffer pointed to by |mono| to each
+// channel of |interleaved|. There must be sufficient space allocated in
+// |interleaved| (|samples_per_channel| * |num_channels|).
+template <typename T>
+void UpmixMonoToInterleaved(const T* mono,
+                            int num_frames,
+                            int num_channels,
+                            T* interleaved) {
+  int interleaved_idx = 0;
+  for (int i = 0; i < num_frames; ++i) {
+    for (int j = 0; j < num_channels; ++j) {
+      interleaved[interleaved_idx++] = mono[i];
+    }
+  }
+}
+
+template <typename T, typename Intermediate>
+void DownmixToMono(const T* const* input_channels,
+                   size_t num_frames,
+                   int num_channels,
+                   T* out) {
+  for (size_t i = 0; i < num_frames; ++i) {
+    Intermediate value = input_channels[0][i];
+    for (int j = 1; j < num_channels; ++j) {
+      value += input_channels[j][i];
+    }
+    out[i] = value / num_channels;
+  }
+}
+
+// Downmixes an interleaved multichannel signal to a single channel by averaging
+// all channels.
+template <typename T, typename Intermediate>
+void DownmixInterleavedToMonoImpl(const T* interleaved,
+                                  size_t num_frames,
+                                  int num_channels,
+                                  T* deinterleaved) {
+  RTC_DCHECK_GT(num_channels, 0);
+  RTC_DCHECK_GT(num_frames, 0);
+
+  const T* const end = interleaved + num_frames * num_channels;
+
+  while (interleaved < end) {
+    const T* const frame_end = interleaved + num_channels;
+
+    Intermediate value = *interleaved++;
+    while (interleaved < frame_end) {
+      value += *interleaved++;
+    }
+
+    *deinterleaved++ = value / num_channels;
+  }
+}
+
+template <typename T>
+void DownmixInterleavedToMono(const T* interleaved,
+                              size_t num_frames,
+                              int num_channels,
+                              T* deinterleaved);
+
+template <>
+void DownmixInterleavedToMono<int16_t>(const int16_t* interleaved,
+                                       size_t num_frames,
+                                       int num_channels,
+                                       int16_t* deinterleaved);
+
+}  // namespace webrtc
+
+#endif  // COMMON_AUDIO_INCLUDE_AUDIO_UTIL_H_
diff --git a/third_party/webrtc_aec3/src/common_audio/resampler/include/push_resampler.h b/third_party/webrtc_aec3/src/common_audio/resampler/include/push_resampler.h
new file mode 100644
index 0000000..3da6712
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/resampler/include/push_resampler.h
@@ -0,0 +1,59 @@
+/*
+ *  Copyright (c) 2013 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef COMMON_AUDIO_RESAMPLER_INCLUDE_PUSH_RESAMPLER_H_
+#define COMMON_AUDIO_RESAMPLER_INCLUDE_PUSH_RESAMPLER_H_
+
+#include <memory>
+#include <vector>
+
+namespace webrtc {
+
+class PushSincResampler;
+
+// Wraps PushSincResampler to provide stereo support.
+// TODO(ajm): add support for an arbitrary number of channels.
+template <typename T>
+class PushResampler {
+ public:
+  PushResampler();
+  virtual ~PushResampler();
+
+  // Must be called whenever the parameters change. Free to be called at any
+  // time as it is a no-op if parameters have not changed since the last call.
+  int InitializeIfNeeded(int src_sample_rate_hz,
+                         int dst_sample_rate_hz,
+                         size_t num_channels);
+
+  // Returns the total number of samples provided in destination (e.g. 32 kHz,
+  // 2 channel audio gives 640 samples).
+  int Resample(const T* src, size_t src_length, T* dst, size_t dst_capacity);
+
+ private:
+  int src_sample_rate_hz_;
+  int dst_sample_rate_hz_;
+  size_t num_channels_;
+  // Vector that is needed to provide the proper inputs and outputs to the
+  // interleave/de-interleave methods used in Resample. This needs to be
+  // heap-allocated on the state to support an arbitrary number of channels
+  // without doing run-time heap-allocations in the Resample method.
+  std::vector<T*> channel_data_array_;
+
+  struct ChannelResampler {
+    std::unique_ptr<PushSincResampler> resampler;
+    std::vector<T> source;
+    std::vector<T> destination;
+  };
+
+  std::vector<ChannelResampler> channel_resamplers_;
+};
+}  // namespace webrtc
+
+#endif  // COMMON_AUDIO_RESAMPLER_INCLUDE_PUSH_RESAMPLER_H_
diff --git a/third_party/webrtc_aec3/src/common_audio/resampler/include/resampler.h b/third_party/webrtc_aec3/src/common_audio/resampler/include/resampler.h
new file mode 100644
index 0000000..41940f9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/resampler/include/resampler.h
@@ -0,0 +1,99 @@
+/*
+ *  Copyright (c) 2011 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+/*
+ * A wrapper for resampling a numerous amount of sampling combinations.
+ */
+
+#ifndef COMMON_AUDIO_RESAMPLER_INCLUDE_RESAMPLER_H_
+#define COMMON_AUDIO_RESAMPLER_INCLUDE_RESAMPLER_H_
+
+#include <stddef.h>
+#include <stdint.h>
+
+namespace webrtc {
+
+// All methods return 0 on success and -1 on failure.
+class Resampler {
+ public:
+  Resampler();
+  Resampler(int inFreq, int outFreq, size_t num_channels);
+  ~Resampler();
+
+  // Reset all states
+  int Reset(int inFreq, int outFreq, size_t num_channels);
+
+  // Reset all states if any parameter has changed
+  int ResetIfNeeded(int inFreq, int outFreq, size_t num_channels);
+
+  // Resample samplesIn to samplesOut.
+  int Push(const int16_t* samplesIn,
+           size_t lengthIn,
+           int16_t* samplesOut,
+           size_t maxLen,
+           size_t& outLen);  // NOLINT: to avoid changing APIs
+
+ private:
+  enum ResamplerMode {
+    kResamplerMode1To1,
+    kResamplerMode1To2,
+    kResamplerMode1To3,
+    kResamplerMode1To4,
+    kResamplerMode1To6,
+    kResamplerMode1To12,
+    kResamplerMode2To3,
+    kResamplerMode2To11,
+    kResamplerMode4To11,
+    kResamplerMode8To11,
+    kResamplerMode11To16,
+    kResamplerMode11To32,
+    kResamplerMode2To1,
+    kResamplerMode3To1,
+    kResamplerMode4To1,
+    kResamplerMode6To1,
+    kResamplerMode12To1,
+    kResamplerMode3To2,
+    kResamplerMode11To2,
+    kResamplerMode11To4,
+    kResamplerMode11To8
+  };
+
+  // Computes the resampler mode for a given sampling frequency pair.
+  // Returns -1 for unsupported frequency pairs.
+  static int ComputeResamplerMode(int in_freq_hz,
+                                  int out_freq_hz,
+                                  ResamplerMode* mode);
+
+  // Generic pointers since we don't know what states we'll need
+  void* state1_;
+  void* state2_;
+  void* state3_;
+
+  // Storage if needed
+  int16_t* in_buffer_;
+  int16_t* out_buffer_;
+  size_t in_buffer_size_;
+  size_t out_buffer_size_;
+  size_t in_buffer_size_max_;
+  size_t out_buffer_size_max_;
+
+  int my_in_frequency_khz_;
+  int my_out_frequency_khz_;
+  ResamplerMode my_mode_;
+  size_t num_channels_;
+
+  // Extra instance for stereo
+  Resampler* helper_left_;
+  Resampler* helper_right_;
+};
+
+}  // namespace webrtc
+
+#endif  // COMMON_AUDIO_RESAMPLER_INCLUDE_RESAMPLER_H_
diff --git a/third_party/webrtc_aec3/src/common_audio/resampler/push_resampler.cc b/third_party/webrtc_aec3/src/common_audio/resampler/push_resampler.cc
new file mode 100644
index 0000000..d7aa8d7
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/resampler/push_resampler.cc
@@ -0,0 +1,151 @@
+/*
+ *  Copyright (c) 2013 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "common_audio/resampler/include/push_resampler.h"
+
+#include <stdint.h>
+#include <string.h>
+
+#include <memory>
+
+#include "common_audio/include/audio_util.h"
+#include "common_audio/resampler/push_sinc_resampler.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+// These checks were factored out into a non-templatized function
+// due to problems with clang on Windows in debug builds.
+// For some reason having the DCHECKs inline in the template code
+// caused the compiler to generate code that threw off the linker.
+// TODO(tommi): Re-enable when we've figured out what the problem is.
+// http://crbug.com/615050
+void CheckValidInitParams(int src_sample_rate_hz,
+                          int dst_sample_rate_hz,
+                          size_t num_channels) {
+// The below checks are temporarily disabled on WEBRTC_WIN due to problems
+// with clang debug builds.
+#if !defined(WEBRTC_WIN) && defined(__clang__)
+  RTC_DCHECK_GT(src_sample_rate_hz, 0);
+  RTC_DCHECK_GT(dst_sample_rate_hz, 0);
+  RTC_DCHECK_GT(num_channels, 0);
+#endif
+}
+
+void CheckExpectedBufferSizes(size_t src_length,
+                              size_t dst_capacity,
+                              size_t num_channels,
+                              int src_sample_rate,
+                              int dst_sample_rate) {
+// The below checks are temporarily disabled on WEBRTC_WIN due to problems
+// with clang debug builds.
+// TODO(tommi): Re-enable when we've figured out what the problem is.
+// http://crbug.com/615050
+#if !defined(WEBRTC_WIN) && defined(__clang__)
+  const size_t src_size_10ms = src_sample_rate * num_channels / 100;
+  const size_t dst_size_10ms = dst_sample_rate * num_channels / 100;
+  RTC_DCHECK_EQ(src_length, src_size_10ms);
+  RTC_DCHECK_GE(dst_capacity, dst_size_10ms);
+#endif
+}
+}  // namespace
+
+template <typename T>
+PushResampler<T>::PushResampler()
+    : src_sample_rate_hz_(0), dst_sample_rate_hz_(0), num_channels_(0) {}
+
+template <typename T>
+PushResampler<T>::~PushResampler() {}
+
+template <typename T>
+int PushResampler<T>::InitializeIfNeeded(int src_sample_rate_hz,
+                                         int dst_sample_rate_hz,
+                                         size_t num_channels) {
+  CheckValidInitParams(src_sample_rate_hz, dst_sample_rate_hz, num_channels);
+
+  if (src_sample_rate_hz == src_sample_rate_hz_ &&
+      dst_sample_rate_hz == dst_sample_rate_hz_ &&
+      num_channels == num_channels_) {
+    // No-op if settings haven't changed.
+    return 0;
+  }
+
+  if (src_sample_rate_hz <= 0 || dst_sample_rate_hz <= 0 || num_channels <= 0) {
+    return -1;
+  }
+
+  src_sample_rate_hz_ = src_sample_rate_hz;
+  dst_sample_rate_hz_ = dst_sample_rate_hz;
+  num_channels_ = num_channels;
+
+  const size_t src_size_10ms_mono =
+      static_cast<size_t>(src_sample_rate_hz / 100);
+  const size_t dst_size_10ms_mono =
+      static_cast<size_t>(dst_sample_rate_hz / 100);
+  channel_resamplers_.clear();
+  for (size_t i = 0; i < num_channels; ++i) {
+    channel_resamplers_.push_back(ChannelResampler());
+    auto channel_resampler = channel_resamplers_.rbegin();
+    channel_resampler->resampler = std::make_unique<PushSincResampler>(
+        src_size_10ms_mono, dst_size_10ms_mono);
+    channel_resampler->source.resize(src_size_10ms_mono);
+    channel_resampler->destination.resize(dst_size_10ms_mono);
+  }
+
+  channel_data_array_.resize(num_channels_);
+
+  return 0;
+}
+
+template <typename T>
+int PushResampler<T>::Resample(const T* src,
+                               size_t src_length,
+                               T* dst,
+                               size_t dst_capacity) {
+  CheckExpectedBufferSizes(src_length, dst_capacity, num_channels_,
+                           src_sample_rate_hz_, dst_sample_rate_hz_);
+
+  if (src_sample_rate_hz_ == dst_sample_rate_hz_) {
+    // The old resampler provides this memcpy facility in the case of matching
+    // sample rates, so reproduce it here for the sinc resampler.
+    memcpy(dst, src, src_length * sizeof(T));
+    return static_cast<int>(src_length);
+  }
+
+  const size_t src_length_mono = src_length / num_channels_;
+  const size_t dst_capacity_mono = dst_capacity / num_channels_;
+
+  for (size_t ch = 0; ch < num_channels_; ++ch) {
+    channel_data_array_[ch] = channel_resamplers_[ch].source.data();
+  }
+
+  Deinterleave(src, src_length_mono, num_channels_, channel_data_array_.data());
+
+  size_t dst_length_mono = 0;
+
+  for (auto& resampler : channel_resamplers_) {
+    dst_length_mono = resampler.resampler->Resample(
+        resampler.source.data(), src_length_mono, resampler.destination.data(),
+        dst_capacity_mono);
+  }
+
+  for (size_t ch = 0; ch < num_channels_; ++ch) {
+    channel_data_array_[ch] = channel_resamplers_[ch].destination.data();
+  }
+
+  Interleave(channel_data_array_.data(), dst_length_mono, num_channels_, dst);
+  return static_cast<int>(dst_length_mono * num_channels_);
+}
+
+// Explictly generate required instantiations.
+template class PushResampler<int16_t>;
+template class PushResampler<float>;
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/common_audio/resampler/push_sinc_resampler.cc b/third_party/webrtc_aec3/src/common_audio/resampler/push_sinc_resampler.cc
new file mode 100644
index 0000000..3bfead2
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/resampler/push_sinc_resampler.cc
@@ -0,0 +1,102 @@
+/*
+ *  Copyright (c) 2013 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "common_audio/resampler/push_sinc_resampler.h"
+
+#include <cstring>
+
+#include "common_audio/include/audio_util.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+PushSincResampler::PushSincResampler(size_t source_frames,
+                                     size_t destination_frames)
+    : resampler_(new SincResampler(source_frames * 1.0 / destination_frames,
+                                   source_frames,
+                                   this)),
+      source_ptr_(nullptr),
+      source_ptr_int_(nullptr),
+      destination_frames_(destination_frames),
+      first_pass_(true),
+      source_available_(0) {}
+
+PushSincResampler::~PushSincResampler() {}
+
+size_t PushSincResampler::Resample(const int16_t* source,
+                                   size_t source_length,
+                                   int16_t* destination,
+                                   size_t destination_capacity) {
+  if (!float_buffer_.get())
+    float_buffer_.reset(new float[destination_frames_]);
+
+  source_ptr_int_ = source;
+  // Pass nullptr as the float source to have Run() read from the int16 source.
+  Resample(nullptr, source_length, float_buffer_.get(), destination_frames_);
+  FloatS16ToS16(float_buffer_.get(), destination_frames_, destination);
+  source_ptr_int_ = nullptr;
+  return destination_frames_;
+}
+
+size_t PushSincResampler::Resample(const float* source,
+                                   size_t source_length,
+                                   float* destination,
+                                   size_t destination_capacity) {
+  RTC_CHECK_EQ(source_length, resampler_->request_frames());
+  RTC_CHECK_GE(destination_capacity, destination_frames_);
+  // Cache the source pointer. Calling Resample() will immediately trigger
+  // the Run() callback whereupon we provide the cached value.
+  source_ptr_ = source;
+  source_available_ = source_length;
+
+  // On the first pass, we call Resample() twice. During the first call, we
+  // provide dummy input and discard the output. This is done to prime the
+  // SincResampler buffer with the correct delay (half the kernel size), thereby
+  // ensuring that all later Resample() calls will only result in one input
+  // request through Run().
+  //
+  // If this wasn't done, SincResampler would call Run() twice on the first
+  // pass, and we'd have to introduce an entire |source_frames| of delay, rather
+  // than the minimum half kernel.
+  //
+  // It works out that ChunkSize() is exactly the amount of output we need to
+  // request in order to prime the buffer with a single Run() request for
+  // |source_frames|.
+  if (first_pass_)
+    resampler_->Resample(resampler_->ChunkSize(), destination);
+
+  resampler_->Resample(destination_frames_, destination);
+  source_ptr_ = nullptr;
+  return destination_frames_;
+}
+
+void PushSincResampler::Run(size_t frames, float* destination) {
+  // Ensure we are only asked for the available samples. This would fail if
+  // Run() was triggered more than once per Resample() call.
+  RTC_CHECK_EQ(source_available_, frames);
+
+  if (first_pass_) {
+    // Provide dummy input on the first pass, the output of which will be
+    // discarded, as described in Resample().
+    std::memset(destination, 0, frames * sizeof(*destination));
+    first_pass_ = false;
+    return;
+  }
+
+  if (source_ptr_) {
+    std::memcpy(destination, source_ptr_, frames * sizeof(*destination));
+  } else {
+    for (size_t i = 0; i < frames; ++i)
+      destination[i] = static_cast<float>(source_ptr_int_[i]);
+  }
+  source_available_ -= frames;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/common_audio/resampler/push_sinc_resampler.h b/third_party/webrtc_aec3/src/common_audio/resampler/push_sinc_resampler.h
new file mode 100644
index 0000000..bd609c4
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/resampler/push_sinc_resampler.h
@@ -0,0 +1,81 @@
+/*
+ *  Copyright (c) 2013 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef COMMON_AUDIO_RESAMPLER_PUSH_SINC_RESAMPLER_H_
+#define COMMON_AUDIO_RESAMPLER_PUSH_SINC_RESAMPLER_H_
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include <memory>
+
+#include "common_audio/resampler/sinc_resampler.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+// A thin wrapper over SincResampler to provide a push-based interface as
+// required by WebRTC. SincResampler uses a pull-based interface, and will
+// use SincResamplerCallback::Run() to request data upon a call to Resample().
+// These Run() calls will happen on the same thread Resample() is called on.
+class PushSincResampler : public SincResamplerCallback {
+ public:
+  // Provide the size of the source and destination blocks in samples. These
+  // must correspond to the same time duration (typically 10 ms) as the sample
+  // ratio is inferred from them.
+  PushSincResampler(size_t source_frames, size_t destination_frames);
+  ~PushSincResampler() override;
+
+  // Perform the resampling. |source_frames| must always equal the
+  // |source_frames| provided at construction. |destination_capacity| must be
+  // at least as large as |destination_frames|. Returns the number of samples
+  // provided in destination (for convenience, since this will always be equal
+  // to |destination_frames|).
+  size_t Resample(const int16_t* source,
+                  size_t source_frames,
+                  int16_t* destination,
+                  size_t destination_capacity);
+  size_t Resample(const float* source,
+                  size_t source_frames,
+                  float* destination,
+                  size_t destination_capacity);
+
+  // Delay due to the filter kernel. Essentially, the time after which an input
+  // sample will appear in the resampled output.
+  static float AlgorithmicDelaySeconds(int source_rate_hz) {
+    return 1.f / source_rate_hz * SincResampler::kKernelSize / 2;
+  }
+
+ protected:
+  // Implements SincResamplerCallback.
+  void Run(size_t frames, float* destination) override;
+
+ private:
+  friend class PushSincResamplerTest;
+  SincResampler* get_resampler_for_testing() { return resampler_.get(); }
+
+  std::unique_ptr<SincResampler> resampler_;
+  std::unique_ptr<float[]> float_buffer_;
+  const float* source_ptr_;
+  const int16_t* source_ptr_int_;
+  const size_t destination_frames_;
+
+  // True on the first call to Resample(), to prime the SincResampler buffer.
+  bool first_pass_;
+
+  // Used to assert we are only requested for as much data as is available.
+  size_t source_available_;
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(PushSincResampler);
+};
+
+}  // namespace webrtc
+
+#endif  // COMMON_AUDIO_RESAMPLER_PUSH_SINC_RESAMPLER_H_
diff --git a/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler.cc b/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler.cc
new file mode 100644
index 0000000..4fa78c5
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler.cc
@@ -0,0 +1,366 @@
+/*
+ *  Copyright (c) 2013 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// Modified from the Chromium original:
+// src/media/base/sinc_resampler.cc
+
+// Initial input buffer layout, dividing into regions r0_ to r4_ (note: r0_, r3_
+// and r4_ will move after the first load):
+//
+// |----------------|-----------------------------------------|----------------|
+//
+//                                        request_frames_
+//                   <--------------------------------------------------------->
+//                                    r0_ (during first load)
+//
+//  kKernelSize / 2   kKernelSize / 2         kKernelSize / 2   kKernelSize / 2
+// <---------------> <--------------->       <---------------> <--------------->
+//        r1_               r2_                     r3_               r4_
+//
+//                             block_size_ == r4_ - r2_
+//                   <--------------------------------------->
+//
+//                                                  request_frames_
+//                                    <------------------ ... ----------------->
+//                                               r0_ (during second load)
+//
+// On the second request r0_ slides to the right by kKernelSize / 2 and r3_, r4_
+// and block_size_ are reinitialized via step (3) in the algorithm below.
+//
+// These new regions remain constant until a Flush() occurs.  While complicated,
+// this allows us to reduce jitter by always requesting the same amount from the
+// provided callback.
+//
+// The algorithm:
+//
+// 1) Allocate input_buffer of size: request_frames_ + kKernelSize; this ensures
+//    there's enough room to read request_frames_ from the callback into region
+//    r0_ (which will move between the first and subsequent passes).
+//
+// 2) Let r1_, r2_ each represent half the kernel centered around r0_:
+//
+//        r0_ = input_buffer_ + kKernelSize / 2
+//        r1_ = input_buffer_
+//        r2_ = r0_
+//
+//    r0_ is always request_frames_ in size.  r1_, r2_ are kKernelSize / 2 in
+//    size.  r1_ must be zero initialized to avoid convolution with garbage (see
+//    step (5) for why).
+//
+// 3) Let r3_, r4_ each represent half the kernel right aligned with the end of
+//    r0_ and choose block_size_ as the distance in frames between r4_ and r2_:
+//
+//        r3_ = r0_ + request_frames_ - kKernelSize
+//        r4_ = r0_ + request_frames_ - kKernelSize / 2
+//        block_size_ = r4_ - r2_ = request_frames_ - kKernelSize / 2
+//
+// 4) Consume request_frames_ frames into r0_.
+//
+// 5) Position kernel centered at start of r2_ and generate output frames until
+//    the kernel is centered at the start of r4_ or we've finished generating
+//    all the output frames.
+//
+// 6) Wrap left over data from the r3_ to r1_ and r4_ to r2_.
+//
+// 7) If we're on the second load, in order to avoid overwriting the frames we
+//    just wrapped from r4_ we need to slide r0_ to the right by the size of
+//    r4_, which is kKernelSize / 2:
+//
+//        r0_ = r0_ + kKernelSize / 2 = input_buffer_ + kKernelSize
+//
+//    r3_, r4_, and block_size_ then need to be reinitialized, so goto (3).
+//
+// 8) Else, if we're not on the second load, goto (4).
+//
+// Note: we're glossing over how the sub-sample handling works with
+// |virtual_source_idx_|, etc.
+
+// MSVC++ requires this to be set before any other includes to get M_PI.
+#define _USE_MATH_DEFINES
+
+#include "common_audio/resampler/sinc_resampler.h"
+
+#include <math.h>
+#include <stdint.h>
+#include <string.h>
+
+#include <limits>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/system/arch.h"
+#include "system_wrappers/include/cpu_features_wrapper.h"  // kSSE2, WebRtc_G...
+
+namespace webrtc {
+
+namespace {
+
+double SincScaleFactor(double io_ratio) {
+  // |sinc_scale_factor| is basically the normalized cutoff frequency of the
+  // low-pass filter.
+  double sinc_scale_factor = io_ratio > 1.0 ? 1.0 / io_ratio : 1.0;
+
+  // The sinc function is an idealized brick-wall filter, but since we're
+  // windowing it the transition from pass to stop does not happen right away.
+  // So we should adjust the low pass filter cutoff slightly downward to avoid
+  // some aliasing at the very high-end.
+  // TODO(crogers): this value is empirical and to be more exact should vary
+  // depending on kKernelSize.
+  sinc_scale_factor *= 0.9;
+
+  return sinc_scale_factor;
+}
+
+}  // namespace
+
+const size_t SincResampler::kKernelSize;
+
+// If we know the minimum architecture at compile time, avoid CPU detection.
+void SincResampler::InitializeCPUSpecificFeatures() {
+#if defined(WEBRTC_HAS_NEON)
+  convolve_proc_ = Convolve_NEON;
+#elif defined(WEBRTC_ARCH_X86_FAMILY)
+  // Using AVX2 instead of SSE2 when AVX2 supported.
+  if (GetCPUInfo(kAVX2))
+    convolve_proc_ = Convolve_AVX2;
+  else if (GetCPUInfo(kSSE2))
+    convolve_proc_ = Convolve_SSE;
+  else
+    convolve_proc_ = Convolve_C;
+#else
+  // Unknown architecture.
+  convolve_proc_ = Convolve_C;
+#endif
+}
+
+SincResampler::SincResampler(double io_sample_rate_ratio,
+                             size_t request_frames,
+                             SincResamplerCallback* read_cb)
+    : io_sample_rate_ratio_(io_sample_rate_ratio),
+      read_cb_(read_cb),
+      request_frames_(request_frames),
+      input_buffer_size_(request_frames_ + kKernelSize),
+      // Create input buffers with a 32-byte alignment for SIMD optimizations.
+      kernel_storage_(static_cast<float*>(
+          AlignedMalloc(sizeof(float) * kKernelStorageSize, 32))),
+      kernel_pre_sinc_storage_(static_cast<float*>(
+          AlignedMalloc(sizeof(float) * kKernelStorageSize, 32))),
+      kernel_window_storage_(static_cast<float*>(
+          AlignedMalloc(sizeof(float) * kKernelStorageSize, 32))),
+      input_buffer_(static_cast<float*>(
+          AlignedMalloc(sizeof(float) * input_buffer_size_, 32))),
+      convolve_proc_(nullptr),
+      r1_(input_buffer_.get()),
+      r2_(input_buffer_.get() + kKernelSize / 2) {
+  InitializeCPUSpecificFeatures();
+  RTC_DCHECK(convolve_proc_);
+  RTC_DCHECK_GT(request_frames_, 0);
+  Flush();
+  RTC_DCHECK_GT(block_size_, kKernelSize);
+
+  memset(kernel_storage_.get(), 0,
+         sizeof(*kernel_storage_.get()) * kKernelStorageSize);
+  memset(kernel_pre_sinc_storage_.get(), 0,
+         sizeof(*kernel_pre_sinc_storage_.get()) * kKernelStorageSize);
+  memset(kernel_window_storage_.get(), 0,
+         sizeof(*kernel_window_storage_.get()) * kKernelStorageSize);
+
+  InitializeKernel();
+}
+
+SincResampler::~SincResampler() {}
+
+void SincResampler::UpdateRegions(bool second_load) {
+  // Setup various region pointers in the buffer (see diagram above).  If we're
+  // on the second load we need to slide r0_ to the right by kKernelSize / 2.
+  r0_ = input_buffer_.get() + (second_load ? kKernelSize : kKernelSize / 2);
+  r3_ = r0_ + request_frames_ - kKernelSize;
+  r4_ = r0_ + request_frames_ - kKernelSize / 2;
+  block_size_ = r4_ - r2_;
+
+  // r1_ at the beginning of the buffer.
+  RTC_DCHECK_EQ(r1_, input_buffer_.get());
+  // r1_ left of r2_, r4_ left of r3_ and size correct.
+  RTC_DCHECK_EQ(r2_ - r1_, r4_ - r3_);
+  // r2_ left of r3.
+  RTC_DCHECK_LT(r2_, r3_);
+}
+
+void SincResampler::InitializeKernel() {
+  // Blackman window parameters.
+  static const double kAlpha = 0.16;
+  static const double kA0 = 0.5 * (1.0 - kAlpha);
+  static const double kA1 = 0.5;
+  static const double kA2 = 0.5 * kAlpha;
+
+  // Generates a set of windowed sinc() kernels.
+  // We generate a range of sub-sample offsets from 0.0 to 1.0.
+  const double sinc_scale_factor = SincScaleFactor(io_sample_rate_ratio_);
+  for (size_t offset_idx = 0; offset_idx <= kKernelOffsetCount; ++offset_idx) {
+    const float subsample_offset =
+        static_cast<float>(offset_idx) / kKernelOffsetCount;
+
+    for (size_t i = 0; i < kKernelSize; ++i) {
+      const size_t idx = i + offset_idx * kKernelSize;
+      const float pre_sinc = static_cast<float>(
+          M_PI * (static_cast<int>(i) - static_cast<int>(kKernelSize / 2) -
+                  subsample_offset));
+      kernel_pre_sinc_storage_[idx] = pre_sinc;
+
+      // Compute Blackman window, matching the offset of the sinc().
+      const float x = (i - subsample_offset) / kKernelSize;
+      const float window = static_cast<float>(kA0 - kA1 * cos(2.0 * M_PI * x) +
+                                              kA2 * cos(4.0 * M_PI * x));
+      kernel_window_storage_[idx] = window;
+
+      // Compute the sinc with offset, then window the sinc() function and store
+      // at the correct offset.
+      kernel_storage_[idx] = static_cast<float>(
+          window * ((pre_sinc == 0)
+                        ? sinc_scale_factor
+                        : (sin(sinc_scale_factor * pre_sinc) / pre_sinc)));
+    }
+  }
+}
+
+void SincResampler::SetRatio(double io_sample_rate_ratio) {
+  if (fabs(io_sample_rate_ratio_ - io_sample_rate_ratio) <
+      std::numeric_limits<double>::epsilon()) {
+    return;
+  }
+
+  io_sample_rate_ratio_ = io_sample_rate_ratio;
+
+  // Optimize reinitialization by reusing values which are independent of
+  // |sinc_scale_factor|.  Provides a 3x speedup.
+  const double sinc_scale_factor = SincScaleFactor(io_sample_rate_ratio_);
+  for (size_t offset_idx = 0; offset_idx <= kKernelOffsetCount; ++offset_idx) {
+    for (size_t i = 0; i < kKernelSize; ++i) {
+      const size_t idx = i + offset_idx * kKernelSize;
+      const float window = kernel_window_storage_[idx];
+      const float pre_sinc = kernel_pre_sinc_storage_[idx];
+
+      kernel_storage_[idx] = static_cast<float>(
+          window * ((pre_sinc == 0)
+                        ? sinc_scale_factor
+                        : (sin(sinc_scale_factor * pre_sinc) / pre_sinc)));
+    }
+  }
+}
+
+void SincResampler::Resample(size_t frames, float* destination) {
+  size_t remaining_frames = frames;
+
+  // Step (1) -- Prime the input buffer at the start of the input stream.
+  if (!buffer_primed_ && remaining_frames) {
+    read_cb_->Run(request_frames_, r0_);
+    buffer_primed_ = true;
+  }
+
+  // Step (2) -- Resample!  const what we can outside of the loop for speed.  It
+  // actually has an impact on ARM performance.  See inner loop comment below.
+  const double current_io_ratio = io_sample_rate_ratio_;
+  const float* const kernel_ptr = kernel_storage_.get();
+  while (remaining_frames) {
+    // |i| may be negative if the last Resample() call ended on an iteration
+    // that put |virtual_source_idx_| over the limit.
+    //
+    // Note: The loop construct here can severely impact performance on ARM
+    // or when built with clang.  See https://codereview.chromium.org/18566009/
+    for (int i = static_cast<int>(
+             ceil((block_size_ - virtual_source_idx_) / current_io_ratio));
+         i > 0; --i) {
+      RTC_DCHECK_LT(virtual_source_idx_, block_size_);
+
+      // |virtual_source_idx_| lies in between two kernel offsets so figure out
+      // what they are.
+      const int source_idx = static_cast<int>(virtual_source_idx_);
+      const double subsample_remainder = virtual_source_idx_ - source_idx;
+
+      const double virtual_offset_idx =
+          subsample_remainder * kKernelOffsetCount;
+      const int offset_idx = static_cast<int>(virtual_offset_idx);
+
+      // We'll compute "convolutions" for the two kernels which straddle
+      // |virtual_source_idx_|.
+      const float* const k1 = kernel_ptr + offset_idx * kKernelSize;
+      const float* const k2 = k1 + kKernelSize;
+
+      // Ensure |k1|, |k2| are 32-byte aligned for SIMD usage.  Should always be
+      // true so long as kKernelSize is a multiple of 32.
+      RTC_DCHECK_EQ(0, reinterpret_cast<uintptr_t>(k1) % 32);
+      RTC_DCHECK_EQ(0, reinterpret_cast<uintptr_t>(k2) % 32);
+
+      // Initialize input pointer based on quantized |virtual_source_idx_|.
+      const float* const input_ptr = r1_ + source_idx;
+
+      // Figure out how much to weight each kernel's "convolution".
+      const double kernel_interpolation_factor =
+          virtual_offset_idx - offset_idx;
+      *destination++ =
+          convolve_proc_(input_ptr, k1, k2, kernel_interpolation_factor);
+
+      // Advance the virtual index.
+      virtual_source_idx_ += current_io_ratio;
+
+      if (!--remaining_frames)
+        return;
+    }
+
+    // Wrap back around to the start.
+    virtual_source_idx_ -= block_size_;
+
+    // Step (3) -- Copy r3_, r4_ to r1_, r2_.
+    // This wraps the last input frames back to the start of the buffer.
+    memcpy(r1_, r3_, sizeof(*input_buffer_.get()) * kKernelSize);
+
+    // Step (4) -- Reinitialize regions if necessary.
+    if (r0_ == r2_)
+      UpdateRegions(true);
+
+    // Step (5) -- Refresh the buffer with more input.
+    read_cb_->Run(request_frames_, r0_);
+  }
+}
+
+#undef CONVOLVE_FUNC
+
+size_t SincResampler::ChunkSize() const {
+  return static_cast<size_t>(block_size_ / io_sample_rate_ratio_);
+}
+
+void SincResampler::Flush() {
+  virtual_source_idx_ = 0;
+  buffer_primed_ = false;
+  memset(input_buffer_.get(), 0,
+         sizeof(*input_buffer_.get()) * input_buffer_size_);
+  UpdateRegions(false);
+}
+
+float SincResampler::Convolve_C(const float* input_ptr,
+                                const float* k1,
+                                const float* k2,
+                                double kernel_interpolation_factor) {
+  float sum1 = 0;
+  float sum2 = 0;
+
+  // Generate a single output sample.  Unrolling this loop hurt performance in
+  // local testing.
+  size_t n = kKernelSize;
+  while (n--) {
+    sum1 += *input_ptr * *k1++;
+    sum2 += *input_ptr++ * *k2++;
+  }
+
+  // Linearly interpolate the two "convolutions".
+  return static_cast<float>((1.0 - kernel_interpolation_factor) * sum1 +
+                            kernel_interpolation_factor * sum2);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler.h b/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler.h
new file mode 100644
index 0000000..a72a0c6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler.h
@@ -0,0 +1,181 @@
+/*
+ *  Copyright (c) 2013 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// Modified from the Chromium original here:
+// src/media/base/sinc_resampler.h
+
+#ifndef COMMON_AUDIO_RESAMPLER_SINC_RESAMPLER_H_
+#define COMMON_AUDIO_RESAMPLER_SINC_RESAMPLER_H_
+
+#include <stddef.h>
+
+#include <memory>
+
+#include "rtc_base/constructor_magic.h"
+#include "rtc_base/gtest_prod_util.h"
+#include "rtc_base/memory/aligned_malloc.h"
+#include "rtc_base/system/arch.h"
+
+namespace webrtc {
+
+// Callback class for providing more data into the resampler.  Expects |frames|
+// of data to be rendered into |destination|; zero padded if not enough frames
+// are available to satisfy the request.
+class SincResamplerCallback {
+ public:
+  virtual ~SincResamplerCallback() {}
+  virtual void Run(size_t frames, float* destination) = 0;
+};
+
+// SincResampler is a high-quality single-channel sample-rate converter.
+class SincResampler {
+ public:
+  // The kernel size can be adjusted for quality (higher is better) at the
+  // expense of performance.  Must be a multiple of 32.
+  // TODO(dalecurtis): Test performance to see if we can jack this up to 64+.
+  static const size_t kKernelSize = 32;
+
+  // Default request size.  Affects how often and for how much SincResampler
+  // calls back for input.  Must be greater than kKernelSize.
+  static const size_t kDefaultRequestSize = 512;
+
+  // The kernel offset count is used for interpolation and is the number of
+  // sub-sample kernel shifts.  Can be adjusted for quality (higher is better)
+  // at the expense of allocating more memory.
+  static const size_t kKernelOffsetCount = 32;
+  static const size_t kKernelStorageSize =
+      kKernelSize * (kKernelOffsetCount + 1);
+
+  // Constructs a SincResampler with the specified |read_cb|, which is used to
+  // acquire audio data for resampling.  |io_sample_rate_ratio| is the ratio
+  // of input / output sample rates.  |request_frames| controls the size in
+  // frames of the buffer requested by each |read_cb| call.  The value must be
+  // greater than kKernelSize.  Specify kDefaultRequestSize if there are no
+  // request size constraints.
+  SincResampler(double io_sample_rate_ratio,
+                size_t request_frames,
+                SincResamplerCallback* read_cb);
+  virtual ~SincResampler();
+
+  // Resample |frames| of data from |read_cb_| into |destination|.
+  void Resample(size_t frames, float* destination);
+
+  // The maximum size in frames that guarantees Resample() will only make a
+  // single call to |read_cb_| for more data.
+  size_t ChunkSize() const;
+
+  size_t request_frames() const { return request_frames_; }
+
+  // Flush all buffered data and reset internal indices.  Not thread safe, do
+  // not call while Resample() is in progress.
+  void Flush();
+
+  // Update |io_sample_rate_ratio_|.  SetRatio() will cause a reconstruction of
+  // the kernels used for resampling.  Not thread safe, do not call while
+  // Resample() is in progress.
+  //
+  // TODO(ajm): Use this in PushSincResampler rather than reconstructing
+  // SincResampler.  We would also need a way to update |request_frames_|.
+  void SetRatio(double io_sample_rate_ratio);
+
+  float* get_kernel_for_testing() { return kernel_storage_.get(); }
+
+ private:
+  FRIEND_TEST_ALL_PREFIXES(SincResamplerTest, Convolve);
+  FRIEND_TEST_ALL_PREFIXES(SincResamplerTest, ConvolveBenchmark);
+
+  void InitializeKernel();
+  void UpdateRegions(bool second_load);
+
+  // Selects runtime specific CPU features like SSE.  Must be called before
+  // using SincResampler.
+  // TODO(ajm): Currently managed by the class internally. See the note with
+  // |convolve_proc_| below.
+  void InitializeCPUSpecificFeatures();
+
+  // Compute convolution of |k1| and |k2| over |input_ptr|, resultant sums are
+  // linearly interpolated using |kernel_interpolation_factor|.  On x86 and ARM
+  // the underlying implementation is chosen at run time.
+  static float Convolve_C(const float* input_ptr,
+                          const float* k1,
+                          const float* k2,
+                          double kernel_interpolation_factor);
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+  static float Convolve_SSE(const float* input_ptr,
+                            const float* k1,
+                            const float* k2,
+                            double kernel_interpolation_factor);
+  static float Convolve_AVX2(const float* input_ptr,
+                             const float* k1,
+                             const float* k2,
+                             double kernel_interpolation_factor);
+#elif defined(WEBRTC_HAS_NEON)
+  static float Convolve_NEON(const float* input_ptr,
+                             const float* k1,
+                             const float* k2,
+                             double kernel_interpolation_factor);
+#endif
+
+  // The ratio of input / output sample rates.
+  double io_sample_rate_ratio_;
+
+  // An index on the source input buffer with sub-sample precision.  It must be
+  // double precision to avoid drift.
+  double virtual_source_idx_;
+
+  // The buffer is primed once at the very beginning of processing.
+  bool buffer_primed_;
+
+  // Source of data for resampling.
+  SincResamplerCallback* read_cb_;
+
+  // The size (in samples) to request from each |read_cb_| execution.
+  const size_t request_frames_;
+
+  // The number of source frames processed per pass.
+  size_t block_size_;
+
+  // The size (in samples) of the internal buffer used by the resampler.
+  const size_t input_buffer_size_;
+
+  // Contains kKernelOffsetCount kernels back-to-back, each of size kKernelSize.
+  // The kernel offsets are sub-sample shifts of a windowed sinc shifted from
+  // 0.0 to 1.0 sample.
+  std::unique_ptr<float[], AlignedFreeDeleter> kernel_storage_;
+  std::unique_ptr<float[], AlignedFreeDeleter> kernel_pre_sinc_storage_;
+  std::unique_ptr<float[], AlignedFreeDeleter> kernel_window_storage_;
+
+  // Data from the source is copied into this buffer for each processing pass.
+  std::unique_ptr<float[], AlignedFreeDeleter> input_buffer_;
+
+// Stores the runtime selection of which Convolve function to use.
+// TODO(ajm): Move to using a global static which must only be initialized
+// once by the user. We're not doing this initially, because we don't have
+// e.g. a LazyInstance helper in webrtc.
+  typedef float (*ConvolveProc)(const float*,
+                                const float*,
+                                const float*,
+                                double);
+  ConvolveProc convolve_proc_;
+
+  // Pointers to the various regions inside |input_buffer_|.  See the diagram at
+  // the top of the .cc file for more information.
+  float* r0_;
+  float* const r1_;
+  float* const r2_;
+  float* r3_;
+  float* r4_;
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(SincResampler);
+};
+
+}  // namespace webrtc
+
+#endif  // COMMON_AUDIO_RESAMPLER_SINC_RESAMPLER_H_
diff --git a/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler_avx2.cc b/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler_avx2.cc
new file mode 100644
index 0000000..3eb5d4a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler_avx2.cc
@@ -0,0 +1,66 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include <immintrin.h>
+#include <stddef.h>
+#include <stdint.h>
+#include <xmmintrin.h>
+
+#include "common_audio/resampler/sinc_resampler.h"
+
+namespace webrtc {
+
+float SincResampler::Convolve_AVX2(const float* input_ptr,
+                                   const float* k1,
+                                   const float* k2,
+                                   double kernel_interpolation_factor) {
+  __m256 m_input;
+  __m256 m_sums1 = _mm256_setzero_ps();
+  __m256 m_sums2 = _mm256_setzero_ps();
+
+  // Based on |input_ptr| alignment, we need to use loadu or load.  Unrolling
+  // these loops has not been tested or benchmarked.
+  bool aligned_input = (reinterpret_cast<uintptr_t>(input_ptr) & 0x1F) == 0;
+  if (!aligned_input) {
+    for (size_t i = 0; i < kKernelSize; i += 8) {
+      m_input = _mm256_loadu_ps(input_ptr + i);
+      m_sums1 = _mm256_fmadd_ps(m_input, _mm256_load_ps(k1 + i), m_sums1);
+      m_sums2 = _mm256_fmadd_ps(m_input, _mm256_load_ps(k2 + i), m_sums2);
+    }
+  } else {
+    for (size_t i = 0; i < kKernelSize; i += 8) {
+      m_input = _mm256_load_ps(input_ptr + i);
+      m_sums1 = _mm256_fmadd_ps(m_input, _mm256_load_ps(k1 + i), m_sums1);
+      m_sums2 = _mm256_fmadd_ps(m_input, _mm256_load_ps(k2 + i), m_sums2);
+    }
+  }
+
+  // Linearly interpolate the two "convolutions".
+  __m128 m128_sums1 = _mm_add_ps(_mm256_extractf128_ps(m_sums1, 0),
+                                 _mm256_extractf128_ps(m_sums1, 1));
+  __m128 m128_sums2 = _mm_add_ps(_mm256_extractf128_ps(m_sums2, 0),
+                                 _mm256_extractf128_ps(m_sums2, 1));
+  m128_sums1 = _mm_mul_ps(
+      m128_sums1,
+      _mm_set_ps1(static_cast<float>(1.0 - kernel_interpolation_factor)));
+  m128_sums2 = _mm_mul_ps(
+      m128_sums2, _mm_set_ps1(static_cast<float>(kernel_interpolation_factor)));
+  m128_sums1 = _mm_add_ps(m128_sums1, m128_sums2);
+
+  // Sum components together.
+  float result;
+  m128_sums2 = _mm_add_ps(_mm_movehl_ps(m128_sums1, m128_sums1), m128_sums1);
+  _mm_store_ss(&result, _mm_add_ss(m128_sums2,
+                                   _mm_shuffle_ps(m128_sums2, m128_sums2, 1)));
+
+  return result;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler_neon.cc b/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler_neon.cc
new file mode 100644
index 0000000..9ee918b
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler_neon.cc
@@ -0,0 +1,48 @@
+/*
+ *  Copyright (c) 2013 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// Modified from the Chromium original:
+// src/media/base/sinc_resampler.cc
+
+#include <arm_neon.h>
+
+#include "common_audio/resampler/sinc_resampler.h"
+
+namespace webrtc {
+
+float SincResampler::Convolve_NEON(const float* input_ptr,
+                                   const float* k1,
+                                   const float* k2,
+                                   double kernel_interpolation_factor) {
+  float32x4_t m_input;
+  float32x4_t m_sums1 = vmovq_n_f32(0);
+  float32x4_t m_sums2 = vmovq_n_f32(0);
+
+  const float* upper = input_ptr + kKernelSize;
+  for (; input_ptr < upper;) {
+    m_input = vld1q_f32(input_ptr);
+    input_ptr += 4;
+    m_sums1 = vmlaq_f32(m_sums1, m_input, vld1q_f32(k1));
+    k1 += 4;
+    m_sums2 = vmlaq_f32(m_sums2, m_input, vld1q_f32(k2));
+    k2 += 4;
+  }
+
+  // Linearly interpolate the two "convolutions".
+  m_sums1 = vmlaq_f32(
+      vmulq_f32(m_sums1, vmovq_n_f32(1.0 - kernel_interpolation_factor)),
+      m_sums2, vmovq_n_f32(kernel_interpolation_factor));
+
+  // Sum components together.
+  float32x2_t m_half = vadd_f32(vget_high_f32(m_sums1), vget_low_f32(m_sums1));
+  return vget_lane_f32(vpadd_f32(m_half, m_half), 0);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler_sse.cc b/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler_sse.cc
new file mode 100644
index 0000000..f6a24d0
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler_sse.cc
@@ -0,0 +1,63 @@
+/*
+ *  Copyright (c) 2013 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// Modified from the Chromium original:
+// src/media/base/simd/sinc_resampler_sse.cc
+
+#include <stddef.h>
+#include <stdint.h>
+#include <xmmintrin.h>
+
+#include "common_audio/resampler/sinc_resampler.h"
+
+namespace webrtc {
+
+float SincResampler::Convolve_SSE(const float* input_ptr,
+                                  const float* k1,
+                                  const float* k2,
+                                  double kernel_interpolation_factor) {
+  __m128 m_input;
+  __m128 m_sums1 = _mm_setzero_ps();
+  __m128 m_sums2 = _mm_setzero_ps();
+
+  // Based on |input_ptr| alignment, we need to use loadu or load.  Unrolling
+  // these loops hurt performance in local testing.
+  if (reinterpret_cast<uintptr_t>(input_ptr) & 0x0F) {
+    for (size_t i = 0; i < kKernelSize; i += 4) {
+      m_input = _mm_loadu_ps(input_ptr + i);
+      m_sums1 = _mm_add_ps(m_sums1, _mm_mul_ps(m_input, _mm_load_ps(k1 + i)));
+      m_sums2 = _mm_add_ps(m_sums2, _mm_mul_ps(m_input, _mm_load_ps(k2 + i)));
+    }
+  } else {
+    for (size_t i = 0; i < kKernelSize; i += 4) {
+      m_input = _mm_load_ps(input_ptr + i);
+      m_sums1 = _mm_add_ps(m_sums1, _mm_mul_ps(m_input, _mm_load_ps(k1 + i)));
+      m_sums2 = _mm_add_ps(m_sums2, _mm_mul_ps(m_input, _mm_load_ps(k2 + i)));
+    }
+  }
+
+  // Linearly interpolate the two "convolutions".
+  m_sums1 = _mm_mul_ps(
+      m_sums1,
+      _mm_set_ps1(static_cast<float>(1.0 - kernel_interpolation_factor)));
+  m_sums2 = _mm_mul_ps(
+      m_sums2, _mm_set_ps1(static_cast<float>(kernel_interpolation_factor)));
+  m_sums1 = _mm_add_ps(m_sums1, m_sums2);
+
+  // Sum components together.
+  float result;
+  m_sums2 = _mm_add_ps(_mm_movehl_ps(m_sums1, m_sums1), m_sums1);
+  _mm_store_ss(&result,
+               _mm_add_ss(m_sums2, _mm_shuffle_ps(m_sums2, m_sums2, 1)));
+
+  return result;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler_unittest.cc b/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler_unittest.cc
new file mode 100644
index 0000000..92dff70
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/resampler/sinc_resampler_unittest.cc
@@ -0,0 +1,382 @@
+/*
+ *  Copyright (c) 2013 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// Modified from the Chromium original:
+// src/media/base/sinc_resampler_unittest.cc
+
+// MSVC++ requires this to be set before any other includes to get M_PI.
+#define _USE_MATH_DEFINES
+
+#include "common_audio/resampler/sinc_resampler.h"
+
+#include <math.h>
+
+#include <algorithm>
+#include <memory>
+#include <tuple>
+
+#include "common_audio/resampler/sinusoidal_linear_chirp_source.h"
+#include "rtc_base/system/arch.h"
+#include "rtc_base/time_utils.h"
+#include "system_wrappers/include/cpu_features_wrapper.h"
+#include "test/gmock.h"
+#include "test/gtest.h"
+
+using ::testing::_;
+
+namespace webrtc {
+
+static const double kSampleRateRatio = 192000.0 / 44100.0;
+static const double kKernelInterpolationFactor = 0.5;
+
+// Helper class to ensure ChunkedResample() functions properly.
+class MockSource : public SincResamplerCallback {
+ public:
+  MOCK_METHOD(void, Run, (size_t frames, float* destination), (override));
+};
+
+ACTION(ClearBuffer) {
+  memset(arg1, 0, arg0 * sizeof(float));
+}
+
+ACTION(FillBuffer) {
+  // Value chosen arbitrarily such that SincResampler resamples it to something
+  // easily representable on all platforms; e.g., using kSampleRateRatio this
+  // becomes 1.81219.
+  memset(arg1, 64, arg0 * sizeof(float));
+}
+
+// Test requesting multiples of ChunkSize() frames results in the proper number
+// of callbacks.
+TEST(SincResamplerTest, ChunkedResample) {
+  MockSource mock_source;
+
+  // Choose a high ratio of input to output samples which will result in quick
+  // exhaustion of SincResampler's internal buffers.
+  SincResampler resampler(kSampleRateRatio, SincResampler::kDefaultRequestSize,
+                          &mock_source);
+
+  static const int kChunks = 2;
+  size_t max_chunk_size = resampler.ChunkSize() * kChunks;
+  std::unique_ptr<float[]> resampled_destination(new float[max_chunk_size]);
+
+  // Verify requesting ChunkSize() frames causes a single callback.
+  EXPECT_CALL(mock_source, Run(_, _)).Times(1).WillOnce(ClearBuffer());
+  resampler.Resample(resampler.ChunkSize(), resampled_destination.get());
+
+  // Verify requesting kChunks * ChunkSize() frames causes kChunks callbacks.
+  ::testing::Mock::VerifyAndClear(&mock_source);
+  EXPECT_CALL(mock_source, Run(_, _))
+      .Times(kChunks)
+      .WillRepeatedly(ClearBuffer());
+  resampler.Resample(max_chunk_size, resampled_destination.get());
+}
+
+// Test flush resets the internal state properly.
+TEST(SincResamplerTest, Flush) {
+  MockSource mock_source;
+  SincResampler resampler(kSampleRateRatio, SincResampler::kDefaultRequestSize,
+                          &mock_source);
+  std::unique_ptr<float[]> resampled_destination(
+      new float[resampler.ChunkSize()]);
+
+  // Fill the resampler with junk data.
+  EXPECT_CALL(mock_source, Run(_, _)).Times(1).WillOnce(FillBuffer());
+  resampler.Resample(resampler.ChunkSize() / 2, resampled_destination.get());
+  ASSERT_NE(resampled_destination[0], 0);
+
+  // Flush and request more data, which should all be zeros now.
+  resampler.Flush();
+  ::testing::Mock::VerifyAndClear(&mock_source);
+  EXPECT_CALL(mock_source, Run(_, _)).Times(1).WillOnce(ClearBuffer());
+  resampler.Resample(resampler.ChunkSize() / 2, resampled_destination.get());
+  for (size_t i = 0; i < resampler.ChunkSize() / 2; ++i)
+    ASSERT_FLOAT_EQ(resampled_destination[i], 0);
+}
+
+// Test flush resets the internal state properly.
+TEST(SincResamplerTest, DISABLED_SetRatioBench) {
+  MockSource mock_source;
+  SincResampler resampler(kSampleRateRatio, SincResampler::kDefaultRequestSize,
+                          &mock_source);
+
+  int64_t start = rtc::TimeNanos();
+  for (int i = 1; i < 10000; ++i)
+    resampler.SetRatio(1.0 / i);
+  double total_time_c_us =
+      (rtc::TimeNanos() - start) / rtc::kNumNanosecsPerMicrosec;
+  printf("SetRatio() took %.2fms.\n", total_time_c_us / 1000);
+}
+
+// Ensure various optimized Convolve() methods return the same value.  Only run
+// this test if other optimized methods exist, otherwise the default Convolve()
+// will be tested by the parameterized SincResampler tests below.
+TEST(SincResamplerTest, Convolve) {
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+  ASSERT_TRUE(GetCPUInfo(kSSE2));
+#elif defined(WEBRTC_ARCH_ARM_V7)
+  ASSERT_TRUE(GetCPUFeaturesARM() & kCPUFeatureNEON);
+#endif
+
+  // Initialize a dummy resampler.
+  MockSource mock_source;
+  SincResampler resampler(kSampleRateRatio, SincResampler::kDefaultRequestSize,
+                          &mock_source);
+
+  // The optimized Convolve methods are slightly more precise than Convolve_C(),
+  // so comparison must be done using an epsilon.
+  static const double kEpsilon = 0.00000005;
+
+  // Use a kernel from SincResampler as input and kernel data, this has the
+  // benefit of already being properly sized and aligned for Convolve_SSE().
+  double result = resampler.Convolve_C(
+      resampler.kernel_storage_.get(), resampler.kernel_storage_.get(),
+      resampler.kernel_storage_.get(), kKernelInterpolationFactor);
+  double result2 = resampler.convolve_proc_(
+      resampler.kernel_storage_.get(), resampler.kernel_storage_.get(),
+      resampler.kernel_storage_.get(), kKernelInterpolationFactor);
+  EXPECT_NEAR(result2, result, kEpsilon);
+
+  // Test Convolve() w/ unaligned input pointer.
+  result = resampler.Convolve_C(
+      resampler.kernel_storage_.get() + 1, resampler.kernel_storage_.get(),
+      resampler.kernel_storage_.get(), kKernelInterpolationFactor);
+  result2 = resampler.convolve_proc_(
+      resampler.kernel_storage_.get() + 1, resampler.kernel_storage_.get(),
+      resampler.kernel_storage_.get(), kKernelInterpolationFactor);
+  EXPECT_NEAR(result2, result, kEpsilon);
+}
+
+// Benchmark for the various Convolve() methods.  Make sure to build with
+// branding=Chrome so that RTC_DCHECKs are compiled out when benchmarking.
+// Original benchmarks were run with --convolve-iterations=50000000.
+TEST(SincResamplerTest, ConvolveBenchmark) {
+  // Initialize a dummy resampler.
+  MockSource mock_source;
+  SincResampler resampler(kSampleRateRatio, SincResampler::kDefaultRequestSize,
+                          &mock_source);
+
+  // Retrieve benchmark iterations from command line.
+  // TODO(ajm): Reintroduce this as a command line option.
+  const int kConvolveIterations = 1000000;
+
+  printf("Benchmarking %d iterations:\n", kConvolveIterations);
+
+  // Benchmark Convolve_C().
+  int64_t start = rtc::TimeNanos();
+  for (int i = 0; i < kConvolveIterations; ++i) {
+    resampler.Convolve_C(
+        resampler.kernel_storage_.get(), resampler.kernel_storage_.get(),
+        resampler.kernel_storage_.get(), kKernelInterpolationFactor);
+  }
+  double total_time_c_us =
+      (rtc::TimeNanos() - start) / rtc::kNumNanosecsPerMicrosec;
+  printf("Convolve_C took %.2fms.\n", total_time_c_us / 1000);
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+  ASSERT_TRUE(GetCPUInfo(kSSE2));
+#elif defined(WEBRTC_ARCH_ARM_V7)
+  ASSERT_TRUE(GetCPUFeaturesARM() & kCPUFeatureNEON);
+#endif
+
+  // Benchmark with unaligned input pointer.
+  start = rtc::TimeNanos();
+  for (int j = 0; j < kConvolveIterations; ++j) {
+    resampler.convolve_proc_(
+        resampler.kernel_storage_.get() + 1, resampler.kernel_storage_.get(),
+        resampler.kernel_storage_.get(), kKernelInterpolationFactor);
+  }
+  double total_time_optimized_unaligned_us =
+      (rtc::TimeNanos() - start) / rtc::kNumNanosecsPerMicrosec;
+  printf(
+      "convolve_proc_(unaligned) took %.2fms; which is %.2fx "
+      "faster than Convolve_C.\n",
+      total_time_optimized_unaligned_us / 1000,
+      total_time_c_us / total_time_optimized_unaligned_us);
+
+  // Benchmark with aligned input pointer.
+  start = rtc::TimeNanos();
+  for (int j = 0; j < kConvolveIterations; ++j) {
+    resampler.convolve_proc_(
+        resampler.kernel_storage_.get(), resampler.kernel_storage_.get(),
+        resampler.kernel_storage_.get(), kKernelInterpolationFactor);
+  }
+  double total_time_optimized_aligned_us =
+      (rtc::TimeNanos() - start) / rtc::kNumNanosecsPerMicrosec;
+  printf(
+      "convolve_proc_ (aligned) took %.2fms; which is %.2fx "
+      "faster than Convolve_C and %.2fx faster than "
+      "convolve_proc_ (unaligned).\n",
+      total_time_optimized_aligned_us / 1000,
+      total_time_c_us / total_time_optimized_aligned_us,
+      total_time_optimized_unaligned_us / total_time_optimized_aligned_us);
+}
+
+typedef std::tuple<int, int, double, double> SincResamplerTestData;
+class SincResamplerTest
+    : public ::testing::TestWithParam<SincResamplerTestData> {
+ public:
+  SincResamplerTest()
+      : input_rate_(std::get<0>(GetParam())),
+        output_rate_(std::get<1>(GetParam())),
+        rms_error_(std::get<2>(GetParam())),
+        low_freq_error_(std::get<3>(GetParam())) {}
+
+  virtual ~SincResamplerTest() {}
+
+ protected:
+  int input_rate_;
+  int output_rate_;
+  double rms_error_;
+  double low_freq_error_;
+};
+
+// Tests resampling using a given input and output sample rate.
+TEST_P(SincResamplerTest, Resample) {
+  // Make comparisons using one second of data.
+  static const double kTestDurationSecs = 1;
+  const size_t input_samples =
+      static_cast<size_t>(kTestDurationSecs * input_rate_);
+  const size_t output_samples =
+      static_cast<size_t>(kTestDurationSecs * output_rate_);
+
+  // Nyquist frequency for the input sampling rate.
+  const double input_nyquist_freq = 0.5 * input_rate_;
+
+  // Source for data to be resampled.
+  SinusoidalLinearChirpSource resampler_source(input_rate_, input_samples,
+                                               input_nyquist_freq, 0);
+
+  const double io_ratio = input_rate_ / static_cast<double>(output_rate_);
+  SincResampler resampler(io_ratio, SincResampler::kDefaultRequestSize,
+                          &resampler_source);
+
+  // Force an update to the sample rate ratio to ensure dyanmic sample rate
+  // changes are working correctly.
+  std::unique_ptr<float[]> kernel(new float[SincResampler::kKernelStorageSize]);
+  memcpy(kernel.get(), resampler.get_kernel_for_testing(),
+         SincResampler::kKernelStorageSize);
+  resampler.SetRatio(M_PI);
+  ASSERT_NE(0, memcmp(kernel.get(), resampler.get_kernel_for_testing(),
+                      SincResampler::kKernelStorageSize));
+  resampler.SetRatio(io_ratio);
+  ASSERT_EQ(0, memcmp(kernel.get(), resampler.get_kernel_for_testing(),
+                      SincResampler::kKernelStorageSize));
+
+  // TODO(dalecurtis): If we switch to AVX/SSE optimization, we'll need to
+  // allocate these on 32-byte boundaries and ensure they're sized % 32 bytes.
+  std::unique_ptr<float[]> resampled_destination(new float[output_samples]);
+  std::unique_ptr<float[]> pure_destination(new float[output_samples]);
+
+  // Generate resampled signal.
+  resampler.Resample(output_samples, resampled_destination.get());
+
+  // Generate pure signal.
+  SinusoidalLinearChirpSource pure_source(output_rate_, output_samples,
+                                          input_nyquist_freq, 0);
+  pure_source.Run(output_samples, pure_destination.get());
+
+  // Range of the Nyquist frequency (0.5 * min(input rate, output_rate)) which
+  // we refer to as low and high.
+  static const double kLowFrequencyNyquistRange = 0.7;
+  static const double kHighFrequencyNyquistRange = 0.9;
+
+  // Calculate Root-Mean-Square-Error and maximum error for the resampling.
+  double sum_of_squares = 0;
+  double low_freq_max_error = 0;
+  double high_freq_max_error = 0;
+  int minimum_rate = std::min(input_rate_, output_rate_);
+  double low_frequency_range = kLowFrequencyNyquistRange * 0.5 * minimum_rate;
+  double high_frequency_range = kHighFrequencyNyquistRange * 0.5 * minimum_rate;
+  for (size_t i = 0; i < output_samples; ++i) {
+    double error = fabs(resampled_destination[i] - pure_destination[i]);
+
+    if (pure_source.Frequency(i) < low_frequency_range) {
+      if (error > low_freq_max_error)
+        low_freq_max_error = error;
+    } else if (pure_source.Frequency(i) < high_frequency_range) {
+      if (error > high_freq_max_error)
+        high_freq_max_error = error;
+    }
+    // TODO(dalecurtis): Sanity check frequencies > kHighFrequencyNyquistRange.
+
+    sum_of_squares += error * error;
+  }
+
+  double rms_error = sqrt(sum_of_squares / output_samples);
+
+// Convert each error to dbFS.
+#define DBFS(x) 20 * log10(x)
+  rms_error = DBFS(rms_error);
+  low_freq_max_error = DBFS(low_freq_max_error);
+  high_freq_max_error = DBFS(high_freq_max_error);
+
+  EXPECT_LE(rms_error, rms_error_);
+  EXPECT_LE(low_freq_max_error, low_freq_error_);
+
+  // All conversions currently have a high frequency error around -6 dbFS.
+  static const double kHighFrequencyMaxError = -6.02;
+  EXPECT_LE(high_freq_max_error, kHighFrequencyMaxError);
+}
+
+// Almost all conversions have an RMS error of around -14 dbFS.
+static const double kResamplingRMSError = -14.58;
+
+// Thresholds chosen arbitrarily based on what each resampling reported during
+// testing.  All thresholds are in dbFS, http://en.wikipedia.org/wiki/DBFS.
+INSTANTIATE_TEST_SUITE_P(
+    SincResamplerTest,
+    SincResamplerTest,
+    ::testing::Values(
+        // To 44.1kHz
+        std::make_tuple(8000, 44100, kResamplingRMSError, -62.73),
+        std::make_tuple(11025, 44100, kResamplingRMSError, -72.19),
+        std::make_tuple(16000, 44100, kResamplingRMSError, -62.54),
+        std::make_tuple(22050, 44100, kResamplingRMSError, -73.53),
+        std::make_tuple(32000, 44100, kResamplingRMSError, -63.32),
+        std::make_tuple(44100, 44100, kResamplingRMSError, -73.52),
+        std::make_tuple(48000, 44100, -15.01, -64.04),
+        std::make_tuple(96000, 44100, -18.49, -25.51),
+        std::make_tuple(192000, 44100, -20.50, -13.31),
+
+        // To 48kHz
+        std::make_tuple(8000, 48000, kResamplingRMSError, -63.43),
+        std::make_tuple(11025, 48000, kResamplingRMSError, -62.61),
+        std::make_tuple(16000, 48000, kResamplingRMSError, -63.95),
+        std::make_tuple(22050, 48000, kResamplingRMSError, -62.42),
+        std::make_tuple(32000, 48000, kResamplingRMSError, -64.04),
+        std::make_tuple(44100, 48000, kResamplingRMSError, -62.63),
+        std::make_tuple(48000, 48000, kResamplingRMSError, -73.52),
+        std::make_tuple(96000, 48000, -18.40, -28.44),
+        std::make_tuple(192000, 48000, -20.43, -14.11),
+
+        // To 96kHz
+        std::make_tuple(8000, 96000, kResamplingRMSError, -63.19),
+        std::make_tuple(11025, 96000, kResamplingRMSError, -62.61),
+        std::make_tuple(16000, 96000, kResamplingRMSError, -63.39),
+        std::make_tuple(22050, 96000, kResamplingRMSError, -62.42),
+        std::make_tuple(32000, 96000, kResamplingRMSError, -63.95),
+        std::make_tuple(44100, 96000, kResamplingRMSError, -62.63),
+        std::make_tuple(48000, 96000, kResamplingRMSError, -73.52),
+        std::make_tuple(96000, 96000, kResamplingRMSError, -73.52),
+        std::make_tuple(192000, 96000, kResamplingRMSError, -28.41),
+
+        // To 192kHz
+        std::make_tuple(8000, 192000, kResamplingRMSError, -63.10),
+        std::make_tuple(11025, 192000, kResamplingRMSError, -62.61),
+        std::make_tuple(16000, 192000, kResamplingRMSError, -63.14),
+        std::make_tuple(22050, 192000, kResamplingRMSError, -62.42),
+        std::make_tuple(32000, 192000, kResamplingRMSError, -63.38),
+        std::make_tuple(44100, 192000, kResamplingRMSError, -62.63),
+        std::make_tuple(48000, 192000, kResamplingRMSError, -73.44),
+        std::make_tuple(96000, 192000, kResamplingRMSError, -73.52),
+        std::make_tuple(192000, 192000, kResamplingRMSError, -73.52)));
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/common_audio/signal_processing/dot_product_with_scale.cc b/third_party/webrtc_aec3/src/common_audio/signal_processing/dot_product_with_scale.cc
new file mode 100644
index 0000000..00799da
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/signal_processing/dot_product_with_scale.cc
@@ -0,0 +1,34 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "common_audio/signal_processing/dot_product_with_scale.h"
+
+#include "rtc_base/numerics/safe_conversions.h"
+
+int32_t WebRtcSpl_DotProductWithScale(const int16_t* vector1,
+                                      const int16_t* vector2,
+                                      size_t length,
+                                      int scaling) {
+  int64_t sum = 0;
+  size_t i = 0;
+
+  /* Unroll the loop to improve performance. */
+  for (i = 0; i + 3 < length; i += 4) {
+    sum += (vector1[i + 0] * vector2[i + 0]) >> scaling;
+    sum += (vector1[i + 1] * vector2[i + 1]) >> scaling;
+    sum += (vector1[i + 2] * vector2[i + 2]) >> scaling;
+    sum += (vector1[i + 3] * vector2[i + 3]) >> scaling;
+  }
+  for (; i < length; i++) {
+    sum += (vector1[i] * vector2[i]) >> scaling;
+  }
+
+  return rtc::saturated_cast<int32_t>(sum);
+}
diff --git a/third_party/webrtc_aec3/src/common_audio/signal_processing/dot_product_with_scale.h b/third_party/webrtc_aec3/src/common_audio/signal_processing/dot_product_with_scale.h
new file mode 100644
index 0000000..bb892d4
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/signal_processing/dot_product_with_scale.h
@@ -0,0 +1,40 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef COMMON_AUDIO_SIGNAL_PROCESSING_DOT_PRODUCT_WITH_SCALE_H_
+#define COMMON_AUDIO_SIGNAL_PROCESSING_DOT_PRODUCT_WITH_SCALE_H_
+
+#include <stdint.h>
+#include <string.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// Calculates the dot product between two (int16_t) vectors.
+//
+// Input:
+//      - vector1       : Vector 1
+//      - vector2       : Vector 2
+//      - vector_length : Number of samples used in the dot product
+//      - scaling       : The number of right bit shifts to apply on each term
+//                        during calculation to avoid overflow, i.e., the
+//                        output will be in Q(-|scaling|)
+//
+// Return value         : The dot product in Q(-scaling)
+int32_t WebRtcSpl_DotProductWithScale(const int16_t* vector1,
+                                      const int16_t* vector2,
+                                      size_t length,
+                                      int scaling);
+
+#ifdef __cplusplus
+}
+#endif  // __cplusplus
+#endif  // COMMON_AUDIO_SIGNAL_PROCESSING_DOT_PRODUCT_WITH_SCALE_H_
diff --git a/third_party/webrtc_aec3/src/common_audio/signal_processing/include/signal_processing_library.h b/third_party/webrtc_aec3/src/common_audio/signal_processing/include/signal_processing_library.h
new file mode 100644
index 0000000..0c13071
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/signal_processing/include/signal_processing_library.h
@@ -0,0 +1,1635 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+/*
+ * This header file includes all of the fix point signal processing library
+ * (SPL) function descriptions and declarations. For specific function calls,
+ * see bottom of file.
+ */
+
+#ifndef COMMON_AUDIO_SIGNAL_PROCESSING_INCLUDE_SIGNAL_PROCESSING_LIBRARY_H_
+#define COMMON_AUDIO_SIGNAL_PROCESSING_INCLUDE_SIGNAL_PROCESSING_LIBRARY_H_
+
+#include <string.h>
+
+#include "common_audio/signal_processing/dot_product_with_scale.h"
+
+// Macros specific for the fixed point implementation
+#define WEBRTC_SPL_WORD16_MAX 32767
+#define WEBRTC_SPL_WORD16_MIN -32768
+#define WEBRTC_SPL_WORD32_MAX (int32_t)0x7fffffff
+#define WEBRTC_SPL_WORD32_MIN (int32_t)0x80000000
+#define WEBRTC_SPL_MAX_LPC_ORDER 14
+#define WEBRTC_SPL_MIN(A, B) (A < B ? A : B)  // Get min value
+#define WEBRTC_SPL_MAX(A, B) (A > B ? A : B)  // Get max value
+// TODO(kma/bjorn): For the next two macros, investigate how to correct the code
+// for inputs of a = WEBRTC_SPL_WORD16_MIN or WEBRTC_SPL_WORD32_MIN.
+#define WEBRTC_SPL_ABS_W16(a) (((int16_t)a >= 0) ? ((int16_t)a) : -((int16_t)a))
+#define WEBRTC_SPL_ABS_W32(a) (((int32_t)a >= 0) ? ((int32_t)a) : -((int32_t)a))
+
+#define WEBRTC_SPL_MUL(a, b) ((int32_t)((int32_t)(a) * (int32_t)(b)))
+#define WEBRTC_SPL_UMUL(a, b) ((uint32_t)((uint32_t)(a) * (uint32_t)(b)))
+#define WEBRTC_SPL_UMUL_32_16(a, b) ((uint32_t)((uint32_t)(a) * (uint16_t)(b)))
+#define WEBRTC_SPL_MUL_16_U16(a, b) ((int32_t)(int16_t)(a) * (uint16_t)(b))
+
+// clang-format off
+// clang-format would choose some identation
+// leading to presubmit error (cpplint.py)
+#ifndef WEBRTC_ARCH_ARM_V7
+// For ARMv7 platforms, these are inline functions in spl_inl_armv7.h
+#ifndef MIPS32_LE
+// For MIPS platforms, these are inline functions in spl_inl_mips.h
+#define WEBRTC_SPL_MUL_16_16(a, b) ((int32_t)(((int16_t)(a)) * ((int16_t)(b))))
+#define WEBRTC_SPL_MUL_16_32_RSFT16(a, b) \
+        (WEBRTC_SPL_MUL_16_16(a, b >> 16) +     \
+        ((WEBRTC_SPL_MUL_16_16(a, (b & 0xffff) >> 1) + 0x4000) >> 15))
+#endif
+#endif
+
+#define WEBRTC_SPL_MUL_16_32_RSFT11(a, b)          \
+        (WEBRTC_SPL_MUL_16_16(a, (b) >> 16) * (1 << 5) + \
+        (((WEBRTC_SPL_MUL_16_U16(a, (uint16_t)(b)) >> 1) + 0x0200) >> 10))
+#define WEBRTC_SPL_MUL_16_32_RSFT14(a, b)          \
+        (WEBRTC_SPL_MUL_16_16(a, (b) >> 16) * (1 << 2) + \
+        (((WEBRTC_SPL_MUL_16_U16(a, (uint16_t)(b)) >> 1) + 0x1000) >> 13))
+#define WEBRTC_SPL_MUL_16_32_RSFT15(a, b)            \
+        ((WEBRTC_SPL_MUL_16_16(a, (b) >> 16) * (1 << 1)) + \
+        (((WEBRTC_SPL_MUL_16_U16(a, (uint16_t)(b)) >> 1) + 0x2000) >> 14))
+// clang-format on
+
+#define WEBRTC_SPL_MUL_16_16_RSFT(a, b, c) (WEBRTC_SPL_MUL_16_16(a, b) >> (c))
+
+#define WEBRTC_SPL_MUL_16_16_RSFT_WITH_ROUND(a, b, c) \
+  ((WEBRTC_SPL_MUL_16_16(a, b) + ((int32_t)(((int32_t)1) << ((c)-1)))) >> (c))
+
+// C + the 32 most significant bits of A * B
+#define WEBRTC_SPL_SCALEDIFF32(A, B, C) \
+  (C + (B >> 16) * A + (((uint32_t)(B & 0x0000FFFF) * A) >> 16))
+
+#define WEBRTC_SPL_SAT(a, b, c) (b > a ? a : b < c ? c : b)
+
+// Shifting with negative numbers allowed
+// Positive means left shift
+#define WEBRTC_SPL_SHIFT_W32(x, c) ((c) >= 0 ? (x) * (1 << (c)) : (x) >> -(c))
+
+// Shifting with negative numbers not allowed
+// We cannot do casting here due to signed/unsigned problem
+#define WEBRTC_SPL_LSHIFT_W32(x, c) ((x) << (c))
+
+#define WEBRTC_SPL_RSHIFT_U32(x, c) ((uint32_t)(x) >> (c))
+
+#define WEBRTC_SPL_RAND(a) ((int16_t)((((int16_t)a * 18816) >> 7) & 0x00007fff))
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#define WEBRTC_SPL_MEMCPY_W16(v1, v2, length) \
+  memcpy(v1, v2, (length) * sizeof(int16_t))
+
+// inline functions:
+#include "common_audio/signal_processing/include/spl_inl.h"
+
+// third party math functions
+#include "common_audio/third_party/spl_sqrt_floor/spl_sqrt_floor.h"
+
+int16_t WebRtcSpl_GetScalingSquare(int16_t* in_vector,
+                                   size_t in_vector_length,
+                                   size_t times);
+
+// Copy and set operations. Implementation in copy_set_operations.c.
+// Descriptions at bottom of file.
+void WebRtcSpl_MemSetW16(int16_t* vector,
+                         int16_t set_value,
+                         size_t vector_length);
+void WebRtcSpl_MemSetW32(int32_t* vector,
+                         int32_t set_value,
+                         size_t vector_length);
+void WebRtcSpl_MemCpyReversedOrder(int16_t* out_vector,
+                                   int16_t* in_vector,
+                                   size_t vector_length);
+void WebRtcSpl_CopyFromEndW16(const int16_t* in_vector,
+                              size_t in_vector_length,
+                              size_t samples,
+                              int16_t* out_vector);
+void WebRtcSpl_ZerosArrayW16(int16_t* vector, size_t vector_length);
+void WebRtcSpl_ZerosArrayW32(int32_t* vector, size_t vector_length);
+// End: Copy and set operations.
+
+// Minimum and maximum operation functions and their pointers.
+// Implementation in min_max_operations.c.
+
+// Returns the largest absolute value in a signed 16-bit vector.
+//
+// Input:
+//      - vector : 16-bit input vector.
+//      - length : Number of samples in vector.
+//
+// Return value  : Maximum absolute value in vector.
+typedef int16_t (*MaxAbsValueW16)(const int16_t* vector, size_t length);
+extern const MaxAbsValueW16 WebRtcSpl_MaxAbsValueW16;
+int16_t WebRtcSpl_MaxAbsValueW16C(const int16_t* vector, size_t length);
+#if defined(WEBRTC_HAS_NEON)
+int16_t WebRtcSpl_MaxAbsValueW16Neon(const int16_t* vector, size_t length);
+#endif
+#if defined(MIPS32_LE)
+int16_t WebRtcSpl_MaxAbsValueW16_mips(const int16_t* vector, size_t length);
+#endif
+
+// Returns the largest absolute value in a signed 32-bit vector.
+//
+// Input:
+//      - vector : 32-bit input vector.
+//      - length : Number of samples in vector.
+//
+// Return value  : Maximum absolute value in vector.
+typedef int32_t (*MaxAbsValueW32)(const int32_t* vector, size_t length);
+extern const MaxAbsValueW32 WebRtcSpl_MaxAbsValueW32;
+int32_t WebRtcSpl_MaxAbsValueW32C(const int32_t* vector, size_t length);
+#if defined(WEBRTC_HAS_NEON)
+int32_t WebRtcSpl_MaxAbsValueW32Neon(const int32_t* vector, size_t length);
+#endif
+#if defined(MIPS_DSP_R1_LE)
+int32_t WebRtcSpl_MaxAbsValueW32_mips(const int32_t* vector, size_t length);
+#endif
+
+// Returns the maximum value of a 16-bit vector.
+//
+// Input:
+//      - vector : 16-bit input vector.
+//      - length : Number of samples in vector.
+//
+// Return value  : Maximum sample value in |vector|.
+typedef int16_t (*MaxValueW16)(const int16_t* vector, size_t length);
+extern const MaxValueW16 WebRtcSpl_MaxValueW16;
+int16_t WebRtcSpl_MaxValueW16C(const int16_t* vector, size_t length);
+#if defined(WEBRTC_HAS_NEON)
+int16_t WebRtcSpl_MaxValueW16Neon(const int16_t* vector, size_t length);
+#endif
+#if defined(MIPS32_LE)
+int16_t WebRtcSpl_MaxValueW16_mips(const int16_t* vector, size_t length);
+#endif
+
+// Returns the maximum value of a 32-bit vector.
+//
+// Input:
+//      - vector : 32-bit input vector.
+//      - length : Number of samples in vector.
+//
+// Return value  : Maximum sample value in |vector|.
+typedef int32_t (*MaxValueW32)(const int32_t* vector, size_t length);
+extern const MaxValueW32 WebRtcSpl_MaxValueW32;
+int32_t WebRtcSpl_MaxValueW32C(const int32_t* vector, size_t length);
+#if defined(WEBRTC_HAS_NEON)
+int32_t WebRtcSpl_MaxValueW32Neon(const int32_t* vector, size_t length);
+#endif
+#if defined(MIPS32_LE)
+int32_t WebRtcSpl_MaxValueW32_mips(const int32_t* vector, size_t length);
+#endif
+
+// Returns the minimum value of a 16-bit vector.
+//
+// Input:
+//      - vector : 16-bit input vector.
+//      - length : Number of samples in vector.
+//
+// Return value  : Minimum sample value in |vector|.
+typedef int16_t (*MinValueW16)(const int16_t* vector, size_t length);
+extern const MinValueW16 WebRtcSpl_MinValueW16;
+int16_t WebRtcSpl_MinValueW16C(const int16_t* vector, size_t length);
+#if defined(WEBRTC_HAS_NEON)
+int16_t WebRtcSpl_MinValueW16Neon(const int16_t* vector, size_t length);
+#endif
+#if defined(MIPS32_LE)
+int16_t WebRtcSpl_MinValueW16_mips(const int16_t* vector, size_t length);
+#endif
+
+// Returns the minimum value of a 32-bit vector.
+//
+// Input:
+//      - vector : 32-bit input vector.
+//      - length : Number of samples in vector.
+//
+// Return value  : Minimum sample value in |vector|.
+typedef int32_t (*MinValueW32)(const int32_t* vector, size_t length);
+extern const MinValueW32 WebRtcSpl_MinValueW32;
+int32_t WebRtcSpl_MinValueW32C(const int32_t* vector, size_t length);
+#if defined(WEBRTC_HAS_NEON)
+int32_t WebRtcSpl_MinValueW32Neon(const int32_t* vector, size_t length);
+#endif
+#if defined(MIPS32_LE)
+int32_t WebRtcSpl_MinValueW32_mips(const int32_t* vector, size_t length);
+#endif
+
+// Returns both the minimum and maximum values of a 16-bit vector.
+//
+// Input:
+//      - vector : 16-bit input vector.
+//      - length : Number of samples in vector.
+// Ouput:
+//      - max_val : Maximum sample value in |vector|.
+//      - min_val : Minimum sample value in |vector|.
+void WebRtcSpl_MinMaxW16(const int16_t* vector,
+                         size_t length,
+                         int16_t* min_val,
+                         int16_t* max_val);
+#if defined(WEBRTC_HAS_NEON)
+void WebRtcSpl_MinMaxW16Neon(const int16_t* vector,
+                             size_t length,
+                             int16_t* min_val,
+                             int16_t* max_val);
+#endif
+
+// Returns the vector index to the largest absolute value of a 16-bit vector.
+//
+// Input:
+//      - vector : 16-bit input vector.
+//      - length : Number of samples in vector.
+//
+// Return value  : Index to the maximum absolute value in vector.
+//                 If there are multiple equal maxima, return the index of the
+//                 first. -32768 will always have precedence over 32767 (despite
+//                 -32768 presenting an int16 absolute value of 32767).
+size_t WebRtcSpl_MaxAbsIndexW16(const int16_t* vector, size_t length);
+
+// Returns the element with the largest absolute value of a 16-bit vector. Note
+// that this function can return a negative value.
+//
+// Input:
+//      - vector : 16-bit input vector.
+//      - length : Number of samples in vector.
+//
+// Return value  : The element with the largest absolute value. Note that this
+//                 may be a negative value.
+int16_t WebRtcSpl_MaxAbsElementW16(const int16_t* vector, size_t length);
+
+// Returns the vector index to the maximum sample value of a 16-bit vector.
+//
+// Input:
+//      - vector : 16-bit input vector.
+//      - length : Number of samples in vector.
+//
+// Return value  : Index to the maximum value in vector (if multiple
+//                 indexes have the maximum, return the first).
+size_t WebRtcSpl_MaxIndexW16(const int16_t* vector, size_t length);
+
+// Returns the vector index to the maximum sample value of a 32-bit vector.
+//
+// Input:
+//      - vector : 32-bit input vector.
+//      - length : Number of samples in vector.
+//
+// Return value  : Index to the maximum value in vector (if multiple
+//                 indexes have the maximum, return the first).
+size_t WebRtcSpl_MaxIndexW32(const int32_t* vector, size_t length);
+
+// Returns the vector index to the minimum sample value of a 16-bit vector.
+//
+// Input:
+//      - vector : 16-bit input vector.
+//      - length : Number of samples in vector.
+//
+// Return value  : Index to the mimimum value in vector  (if multiple
+//                 indexes have the minimum, return the first).
+size_t WebRtcSpl_MinIndexW16(const int16_t* vector, size_t length);
+
+// Returns the vector index to the minimum sample value of a 32-bit vector.
+//
+// Input:
+//      - vector : 32-bit input vector.
+//      - length : Number of samples in vector.
+//
+// Return value  : Index to the mimimum value in vector  (if multiple
+//                 indexes have the minimum, return the first).
+size_t WebRtcSpl_MinIndexW32(const int32_t* vector, size_t length);
+
+// End: Minimum and maximum operations.
+
+// Vector scaling operations. Implementation in vector_scaling_operations.c.
+// Description at bottom of file.
+void WebRtcSpl_VectorBitShiftW16(int16_t* out_vector,
+                                 size_t vector_length,
+                                 const int16_t* in_vector,
+                                 int16_t right_shifts);
+void WebRtcSpl_VectorBitShiftW32(int32_t* out_vector,
+                                 size_t vector_length,
+                                 const int32_t* in_vector,
+                                 int16_t right_shifts);
+void WebRtcSpl_VectorBitShiftW32ToW16(int16_t* out_vector,
+                                      size_t vector_length,
+                                      const int32_t* in_vector,
+                                      int right_shifts);
+void WebRtcSpl_ScaleVector(const int16_t* in_vector,
+                           int16_t* out_vector,
+                           int16_t gain,
+                           size_t vector_length,
+                           int16_t right_shifts);
+void WebRtcSpl_ScaleVectorWithSat(const int16_t* in_vector,
+                                  int16_t* out_vector,
+                                  int16_t gain,
+                                  size_t vector_length,
+                                  int16_t right_shifts);
+void WebRtcSpl_ScaleAndAddVectors(const int16_t* in_vector1,
+                                  int16_t gain1,
+                                  int right_shifts1,
+                                  const int16_t* in_vector2,
+                                  int16_t gain2,
+                                  int right_shifts2,
+                                  int16_t* out_vector,
+                                  size_t vector_length);
+
+// The functions (with related pointer) perform the vector operation:
+//   out_vector[k] = ((scale1 * in_vector1[k]) + (scale2 * in_vector2[k])
+//        + round_value) >> right_shifts,
+//   where  round_value = (1 << right_shifts) >> 1.
+//
+// Input:
+//      - in_vector1       : Input vector 1
+//      - in_vector1_scale : Gain to be used for vector 1
+//      - in_vector2       : Input vector 2
+//      - in_vector2_scale : Gain to be used for vector 2
+//      - right_shifts     : Number of right bit shifts to be applied
+//      - length           : Number of elements in the input vectors
+//
+// Output:
+//      - out_vector       : Output vector
+// Return value            : 0 if OK, -1 if (in_vector1 == null
+//                           || in_vector2 == null || out_vector == null
+//                           || length <= 0 || right_shift < 0).
+typedef int (*ScaleAndAddVectorsWithRound)(const int16_t* in_vector1,
+                                           int16_t in_vector1_scale,
+                                           const int16_t* in_vector2,
+                                           int16_t in_vector2_scale,
+                                           int right_shifts,
+                                           int16_t* out_vector,
+                                           size_t length);
+extern const ScaleAndAddVectorsWithRound WebRtcSpl_ScaleAndAddVectorsWithRound;
+int WebRtcSpl_ScaleAndAddVectorsWithRoundC(const int16_t* in_vector1,
+                                           int16_t in_vector1_scale,
+                                           const int16_t* in_vector2,
+                                           int16_t in_vector2_scale,
+                                           int right_shifts,
+                                           int16_t* out_vector,
+                                           size_t length);
+#if defined(MIPS_DSP_R1_LE)
+int WebRtcSpl_ScaleAndAddVectorsWithRound_mips(const int16_t* in_vector1,
+                                               int16_t in_vector1_scale,
+                                               const int16_t* in_vector2,
+                                               int16_t in_vector2_scale,
+                                               int right_shifts,
+                                               int16_t* out_vector,
+                                               size_t length);
+#endif
+// End: Vector scaling operations.
+
+// iLBC specific functions. Implementations in ilbc_specific_functions.c.
+// Description at bottom of file.
+void WebRtcSpl_ReverseOrderMultArrayElements(int16_t* out_vector,
+                                             const int16_t* in_vector,
+                                             const int16_t* window,
+                                             size_t vector_length,
+                                             int16_t right_shifts);
+void WebRtcSpl_ElementwiseVectorMult(int16_t* out_vector,
+                                     const int16_t* in_vector,
+                                     const int16_t* window,
+                                     size_t vector_length,
+                                     int16_t right_shifts);
+void WebRtcSpl_AddVectorsAndShift(int16_t* out_vector,
+                                  const int16_t* in_vector1,
+                                  const int16_t* in_vector2,
+                                  size_t vector_length,
+                                  int16_t right_shifts);
+void WebRtcSpl_AddAffineVectorToVector(int16_t* out_vector,
+                                       const int16_t* in_vector,
+                                       int16_t gain,
+                                       int32_t add_constant,
+                                       int16_t right_shifts,
+                                       size_t vector_length);
+void WebRtcSpl_AffineTransformVector(int16_t* out_vector,
+                                     const int16_t* in_vector,
+                                     int16_t gain,
+                                     int32_t add_constant,
+                                     int16_t right_shifts,
+                                     size_t vector_length);
+// End: iLBC specific functions.
+
+// Signal processing operations.
+
+// A 32-bit fix-point implementation of auto-correlation computation
+//
+// Input:
+//      - in_vector        : Vector to calculate autocorrelation upon
+//      - in_vector_length : Length (in samples) of |vector|
+//      - order            : The order up to which the autocorrelation should be
+//                           calculated
+//
+// Output:
+//      - result           : auto-correlation values (values should be seen
+//                           relative to each other since the absolute values
+//                           might have been down shifted to avoid overflow)
+//
+//      - scale            : The number of left shifts required to obtain the
+//                           auto-correlation in Q0
+//
+// Return value            : Number of samples in |result|, i.e. (order+1)
+size_t WebRtcSpl_AutoCorrelation(const int16_t* in_vector,
+                                 size_t in_vector_length,
+                                 size_t order,
+                                 int32_t* result,
+                                 int* scale);
+
+// A 32-bit fix-point implementation of the Levinson-Durbin algorithm that
+// does NOT use the 64 bit class
+//
+// Input:
+//      - auto_corr : Vector with autocorrelation values of length >= |order|+1
+//      - order     : The LPC filter order (support up to order 20)
+//
+// Output:
+//      - lpc_coef  : lpc_coef[0..order] LPC coefficients in Q12
+//      - refl_coef : refl_coef[0...order-1]| Reflection coefficients in Q15
+//
+// Return value     : 1 for stable 0 for unstable
+int16_t WebRtcSpl_LevinsonDurbin(const int32_t* auto_corr,
+                                 int16_t* lpc_coef,
+                                 int16_t* refl_coef,
+                                 size_t order);
+
+// Converts reflection coefficients |refl_coef| to LPC coefficients |lpc_coef|.
+// This version is a 16 bit operation.
+//
+// NOTE: The 16 bit refl_coef -> lpc_coef conversion might result in a
+// "slightly unstable" filter (i.e., a pole just outside the unit circle) in
+// "rare" cases even if the reflection coefficients are stable.
+//
+// Input:
+//      - refl_coef : Reflection coefficients in Q15 that should be converted
+//                    to LPC coefficients
+//      - use_order : Number of coefficients in |refl_coef|
+//
+// Output:
+//      - lpc_coef  : LPC coefficients in Q12
+void WebRtcSpl_ReflCoefToLpc(const int16_t* refl_coef,
+                             int use_order,
+                             int16_t* lpc_coef);
+
+// Converts LPC coefficients |lpc_coef| to reflection coefficients |refl_coef|.
+// This version is a 16 bit operation.
+// The conversion is implemented by the step-down algorithm.
+//
+// Input:
+//      - lpc_coef  : LPC coefficients in Q12, that should be converted to
+//                    reflection coefficients
+//      - use_order : Number of coefficients in |lpc_coef|
+//
+// Output:
+//      - refl_coef : Reflection coefficients in Q15.
+void WebRtcSpl_LpcToReflCoef(int16_t* lpc_coef,
+                             int use_order,
+                             int16_t* refl_coef);
+
+// Calculates reflection coefficients (16 bit) from auto-correlation values
+//
+// Input:
+//      - auto_corr : Auto-correlation values
+//      - use_order : Number of coefficients wanted be calculated
+//
+// Output:
+//      - refl_coef : Reflection coefficients in Q15.
+void WebRtcSpl_AutoCorrToReflCoef(const int32_t* auto_corr,
+                                  int use_order,
+                                  int16_t* refl_coef);
+
+// The functions (with related pointer) calculate the cross-correlation between
+// two sequences |seq1| and |seq2|.
+// |seq1| is fixed and |seq2| slides as the pointer is increased with the
+// amount |step_seq2|. Note the arguments should obey the relationship:
+// |dim_seq| - 1 + |step_seq2| * (|dim_cross_correlation| - 1) <
+//      buffer size of |seq2|
+//
+// Input:
+//      - seq1           : First sequence (fixed throughout the correlation)
+//      - seq2           : Second sequence (slides |step_vector2| for each
+//                            new correlation)
+//      - dim_seq        : Number of samples to use in the cross-correlation
+//      - dim_cross_correlation : Number of cross-correlations to calculate (the
+//                            start position for |vector2| is updated for each
+//                            new one)
+//      - right_shifts   : Number of right bit shifts to use. This will
+//                            become the output Q-domain.
+//      - step_seq2      : How many (positive or negative) steps the
+//                            |vector2| pointer should be updated for each new
+//                            cross-correlation value.
+//
+// Output:
+//      - cross_correlation : The cross-correlation in Q(-right_shifts)
+typedef void (*CrossCorrelation)(int32_t* cross_correlation,
+                                 const int16_t* seq1,
+                                 const int16_t* seq2,
+                                 size_t dim_seq,
+                                 size_t dim_cross_correlation,
+                                 int right_shifts,
+                                 int step_seq2);
+extern const CrossCorrelation WebRtcSpl_CrossCorrelation;
+void WebRtcSpl_CrossCorrelationC(int32_t* cross_correlation,
+                                 const int16_t* seq1,
+                                 const int16_t* seq2,
+                                 size_t dim_seq,
+                                 size_t dim_cross_correlation,
+                                 int right_shifts,
+                                 int step_seq2);
+#if defined(WEBRTC_HAS_NEON)
+void WebRtcSpl_CrossCorrelationNeon(int32_t* cross_correlation,
+                                    const int16_t* seq1,
+                                    const int16_t* seq2,
+                                    size_t dim_seq,
+                                    size_t dim_cross_correlation,
+                                    int right_shifts,
+                                    int step_seq2);
+#endif
+#if defined(MIPS32_LE)
+void WebRtcSpl_CrossCorrelation_mips(int32_t* cross_correlation,
+                                     const int16_t* seq1,
+                                     const int16_t* seq2,
+                                     size_t dim_seq,
+                                     size_t dim_cross_correlation,
+                                     int right_shifts,
+                                     int step_seq2);
+#endif
+
+// Creates (the first half of) a Hanning window. Size must be at least 1 and
+// at most 512.
+//
+// Input:
+//      - size      : Length of the requested Hanning window (1 to 512)
+//
+// Output:
+//      - window    : Hanning vector in Q14.
+void WebRtcSpl_GetHanningWindow(int16_t* window, size_t size);
+
+// Calculates y[k] = sqrt(1 - x[k]^2) for each element of the input vector
+// |in_vector|. Input and output values are in Q15.
+//
+// Inputs:
+//      - in_vector     : Values to calculate sqrt(1 - x^2) of
+//      - vector_length : Length of vector |in_vector|
+//
+// Output:
+//      - out_vector    : Output values in Q15
+void WebRtcSpl_SqrtOfOneMinusXSquared(int16_t* in_vector,
+                                      size_t vector_length,
+                                      int16_t* out_vector);
+// End: Signal processing operations.
+
+// Randomization functions. Implementations collected in
+// randomization_functions.c and descriptions at bottom of this file.
+int16_t WebRtcSpl_RandU(uint32_t* seed);
+int16_t WebRtcSpl_RandN(uint32_t* seed);
+int16_t WebRtcSpl_RandUArray(int16_t* vector,
+                             int16_t vector_length,
+                             uint32_t* seed);
+// End: Randomization functions.
+
+// Math functions
+int32_t WebRtcSpl_Sqrt(int32_t value);
+
+// Divisions. Implementations collected in division_operations.c and
+// descriptions at bottom of this file.
+uint32_t WebRtcSpl_DivU32U16(uint32_t num, uint16_t den);
+int32_t WebRtcSpl_DivW32W16(int32_t num, int16_t den);
+int16_t WebRtcSpl_DivW32W16ResW16(int32_t num, int16_t den);
+int32_t WebRtcSpl_DivResultInQ31(int32_t num, int32_t den);
+int32_t WebRtcSpl_DivW32HiLow(int32_t num, int16_t den_hi, int16_t den_low);
+// End: Divisions.
+
+int32_t WebRtcSpl_Energy(int16_t* vector,
+                         size_t vector_length,
+                         int* scale_factor);
+
+// Filter operations.
+size_t WebRtcSpl_FilterAR(const int16_t* ar_coef,
+                          size_t ar_coef_length,
+                          const int16_t* in_vector,
+                          size_t in_vector_length,
+                          int16_t* filter_state,
+                          size_t filter_state_length,
+                          int16_t* filter_state_low,
+                          size_t filter_state_low_length,
+                          int16_t* out_vector,
+                          int16_t* out_vector_low,
+                          size_t out_vector_low_length);
+
+// WebRtcSpl_FilterMAFastQ12(...)
+//
+// Performs a MA filtering on a vector in Q12
+//
+// Input:
+//      - in_vector         : Input samples (state in positions
+//                            in_vector[-order] .. in_vector[-1])
+//      - ma_coef           : Filter coefficients (in Q12)
+//      - ma_coef_length    : Number of B coefficients (order+1)
+//      - vector_length     : Number of samples to be filtered
+//
+// Output:
+//      - out_vector        : Filtered samples
+//
+void WebRtcSpl_FilterMAFastQ12(const int16_t* in_vector,
+                               int16_t* out_vector,
+                               const int16_t* ma_coef,
+                               size_t ma_coef_length,
+                               size_t vector_length);
+
+// Performs a AR filtering on a vector in Q12
+// Input:
+//      - data_in            : Input samples
+//      - data_out           : State information in positions
+//                               data_out[-order] .. data_out[-1]
+//      - coefficients       : Filter coefficients (in Q12)
+//      - coefficients_length: Number of coefficients (order+1)
+//      - data_length        : Number of samples to be filtered
+// Output:
+//      - data_out           : Filtered samples
+void WebRtcSpl_FilterARFastQ12(const int16_t* data_in,
+                               int16_t* data_out,
+                               const int16_t* __restrict coefficients,
+                               size_t coefficients_length,
+                               size_t data_length);
+
+// The functions (with related pointer) perform a MA down sampling filter
+// on a vector.
+// Input:
+//      - data_in            : Input samples (state in positions
+//                               data_in[-order] .. data_in[-1])
+//      - data_in_length     : Number of samples in |data_in| to be filtered.
+//                               This must be at least
+//                               |delay| + |factor|*(|out_vector_length|-1) + 1)
+//      - data_out_length    : Number of down sampled samples desired
+//      - coefficients       : Filter coefficients (in Q12)
+//      - coefficients_length: Number of coefficients (order+1)
+//      - factor             : Decimation factor
+//      - delay              : Delay of filter (compensated for in out_vector)
+// Output:
+//      - data_out           : Filtered samples
+// Return value              : 0 if OK, -1 if |in_vector| is too short
+typedef int (*DownsampleFast)(const int16_t* data_in,
+                              size_t data_in_length,
+                              int16_t* data_out,
+                              size_t data_out_length,
+                              const int16_t* __restrict coefficients,
+                              size_t coefficients_length,
+                              int factor,
+                              size_t delay);
+extern const DownsampleFast WebRtcSpl_DownsampleFast;
+int WebRtcSpl_DownsampleFastC(const int16_t* data_in,
+                              size_t data_in_length,
+                              int16_t* data_out,
+                              size_t data_out_length,
+                              const int16_t* __restrict coefficients,
+                              size_t coefficients_length,
+                              int factor,
+                              size_t delay);
+#if defined(WEBRTC_HAS_NEON)
+int WebRtcSpl_DownsampleFastNeon(const int16_t* data_in,
+                                 size_t data_in_length,
+                                 int16_t* data_out,
+                                 size_t data_out_length,
+                                 const int16_t* __restrict coefficients,
+                                 size_t coefficients_length,
+                                 int factor,
+                                 size_t delay);
+#endif
+#if defined(MIPS32_LE)
+int WebRtcSpl_DownsampleFast_mips(const int16_t* data_in,
+                                  size_t data_in_length,
+                                  int16_t* data_out,
+                                  size_t data_out_length,
+                                  const int16_t* __restrict coefficients,
+                                  size_t coefficients_length,
+                                  int factor,
+                                  size_t delay);
+#endif
+
+// End: Filter operations.
+
+// FFT operations
+
+int WebRtcSpl_ComplexFFT(int16_t vector[], int stages, int mode);
+int WebRtcSpl_ComplexIFFT(int16_t vector[], int stages, int mode);
+
+// Treat a 16-bit complex data buffer |complex_data| as an array of 32-bit
+// values, and swap elements whose indexes are bit-reverses of each other.
+//
+// Input:
+//      - complex_data  : Complex data buffer containing 2^|stages| real
+//                        elements interleaved with 2^|stages| imaginary
+//                        elements: [Re Im Re Im Re Im....]
+//      - stages        : Number of FFT stages. Must be at least 3 and at most
+//                        10, since the table WebRtcSpl_kSinTable1024[] is 1024
+//                        elements long.
+//
+// Output:
+//      - complex_data  : The complex data buffer.
+
+void WebRtcSpl_ComplexBitReverse(int16_t* __restrict complex_data, int stages);
+
+// End: FFT operations
+
+/************************************************************
+ *
+ * RESAMPLING FUNCTIONS AND THEIR STRUCTS ARE DEFINED BELOW
+ *
+ ************************************************************/
+
+/*******************************************************************
+ * resample.c
+ *
+ * Includes the following resampling combinations
+ * 22 kHz -> 16 kHz
+ * 16 kHz -> 22 kHz
+ * 22 kHz ->  8 kHz
+ *  8 kHz -> 22 kHz
+ *
+ ******************************************************************/
+
+// state structure for 22 -> 16 resampler
+typedef struct {
+  int32_t S_22_44[8];
+  int32_t S_44_32[8];
+  int32_t S_32_16[8];
+} WebRtcSpl_State22khzTo16khz;
+
+void WebRtcSpl_Resample22khzTo16khz(const int16_t* in,
+                                    int16_t* out,
+                                    WebRtcSpl_State22khzTo16khz* state,
+                                    int32_t* tmpmem);
+
+void WebRtcSpl_ResetResample22khzTo16khz(WebRtcSpl_State22khzTo16khz* state);
+
+// state structure for 16 -> 22 resampler
+typedef struct {
+  int32_t S_16_32[8];
+  int32_t S_32_22[8];
+} WebRtcSpl_State16khzTo22khz;
+
+void WebRtcSpl_Resample16khzTo22khz(const int16_t* in,
+                                    int16_t* out,
+                                    WebRtcSpl_State16khzTo22khz* state,
+                                    int32_t* tmpmem);
+
+void WebRtcSpl_ResetResample16khzTo22khz(WebRtcSpl_State16khzTo22khz* state);
+
+// state structure for 22 -> 8 resampler
+typedef struct {
+  int32_t S_22_22[16];
+  int32_t S_22_16[8];
+  int32_t S_16_8[8];
+} WebRtcSpl_State22khzTo8khz;
+
+void WebRtcSpl_Resample22khzTo8khz(const int16_t* in,
+                                   int16_t* out,
+                                   WebRtcSpl_State22khzTo8khz* state,
+                                   int32_t* tmpmem);
+
+void WebRtcSpl_ResetResample22khzTo8khz(WebRtcSpl_State22khzTo8khz* state);
+
+// state structure for 8 -> 22 resampler
+typedef struct {
+  int32_t S_8_16[8];
+  int32_t S_16_11[8];
+  int32_t S_11_22[8];
+} WebRtcSpl_State8khzTo22khz;
+
+void WebRtcSpl_Resample8khzTo22khz(const int16_t* in,
+                                   int16_t* out,
+                                   WebRtcSpl_State8khzTo22khz* state,
+                                   int32_t* tmpmem);
+
+void WebRtcSpl_ResetResample8khzTo22khz(WebRtcSpl_State8khzTo22khz* state);
+
+/*******************************************************************
+ * resample_fractional.c
+ * Functions for internal use in the other resample functions
+ *
+ * Includes the following resampling combinations
+ * 48 kHz -> 32 kHz
+ * 32 kHz -> 24 kHz
+ * 44 kHz -> 32 kHz
+ *
+ ******************************************************************/
+
+void WebRtcSpl_Resample48khzTo32khz(const int32_t* In, int32_t* Out, size_t K);
+
+void WebRtcSpl_Resample32khzTo24khz(const int32_t* In, int32_t* Out, size_t K);
+
+void WebRtcSpl_Resample44khzTo32khz(const int32_t* In, int32_t* Out, size_t K);
+
+/*******************************************************************
+ * resample_48khz.c
+ *
+ * Includes the following resampling combinations
+ * 48 kHz -> 16 kHz
+ * 16 kHz -> 48 kHz
+ * 48 kHz ->  8 kHz
+ *  8 kHz -> 48 kHz
+ *
+ ******************************************************************/
+
+typedef struct {
+  int32_t S_48_48[16];
+  int32_t S_48_32[8];
+  int32_t S_32_16[8];
+} WebRtcSpl_State48khzTo16khz;
+
+void WebRtcSpl_Resample48khzTo16khz(const int16_t* in,
+                                    int16_t* out,
+                                    WebRtcSpl_State48khzTo16khz* state,
+                                    int32_t* tmpmem);
+
+void WebRtcSpl_ResetResample48khzTo16khz(WebRtcSpl_State48khzTo16khz* state);
+
+typedef struct {
+  int32_t S_16_32[8];
+  int32_t S_32_24[8];
+  int32_t S_24_48[8];
+} WebRtcSpl_State16khzTo48khz;
+
+void WebRtcSpl_Resample16khzTo48khz(const int16_t* in,
+                                    int16_t* out,
+                                    WebRtcSpl_State16khzTo48khz* state,
+                                    int32_t* tmpmem);
+
+void WebRtcSpl_ResetResample16khzTo48khz(WebRtcSpl_State16khzTo48khz* state);
+
+typedef struct {
+  int32_t S_48_24[8];
+  int32_t S_24_24[16];
+  int32_t S_24_16[8];
+  int32_t S_16_8[8];
+} WebRtcSpl_State48khzTo8khz;
+
+void WebRtcSpl_Resample48khzTo8khz(const int16_t* in,
+                                   int16_t* out,
+                                   WebRtcSpl_State48khzTo8khz* state,
+                                   int32_t* tmpmem);
+
+void WebRtcSpl_ResetResample48khzTo8khz(WebRtcSpl_State48khzTo8khz* state);
+
+typedef struct {
+  int32_t S_8_16[8];
+  int32_t S_16_12[8];
+  int32_t S_12_24[8];
+  int32_t S_24_48[8];
+} WebRtcSpl_State8khzTo48khz;
+
+void WebRtcSpl_Resample8khzTo48khz(const int16_t* in,
+                                   int16_t* out,
+                                   WebRtcSpl_State8khzTo48khz* state,
+                                   int32_t* tmpmem);
+
+void WebRtcSpl_ResetResample8khzTo48khz(WebRtcSpl_State8khzTo48khz* state);
+
+/*******************************************************************
+ * resample_by_2.c
+ *
+ * Includes down and up sampling by a factor of two.
+ *
+ ******************************************************************/
+
+void WebRtcSpl_DownsampleBy2(const int16_t* in,
+                             size_t len,
+                             int16_t* out,
+                             int32_t* filtState);
+
+void WebRtcSpl_UpsampleBy2(const int16_t* in,
+                           size_t len,
+                           int16_t* out,
+                           int32_t* filtState);
+
+/************************************************************
+ * END OF RESAMPLING FUNCTIONS
+ ************************************************************/
+void WebRtcSpl_AnalysisQMF(const int16_t* in_data,
+                           size_t in_data_length,
+                           int16_t* low_band,
+                           int16_t* high_band,
+                           int32_t* filter_state1,
+                           int32_t* filter_state2);
+void WebRtcSpl_SynthesisQMF(const int16_t* low_band,
+                            const int16_t* high_band,
+                            size_t band_length,
+                            int16_t* out_data,
+                            int32_t* filter_state1,
+                            int32_t* filter_state2);
+
+#ifdef __cplusplus
+}
+#endif  // __cplusplus
+#endif  // COMMON_AUDIO_SIGNAL_PROCESSING_INCLUDE_SIGNAL_PROCESSING_LIBRARY_H_
+
+//
+// WebRtcSpl_AddSatW16(...)
+// WebRtcSpl_AddSatW32(...)
+//
+// Returns the result of a saturated 16-bit, respectively 32-bit, addition of
+// the numbers specified by the |var1| and |var2| parameters.
+//
+// Input:
+//      - var1      : Input variable 1
+//      - var2      : Input variable 2
+//
+// Return value     : Added and saturated value
+//
+
+//
+// WebRtcSpl_SubSatW16(...)
+// WebRtcSpl_SubSatW32(...)
+//
+// Returns the result of a saturated 16-bit, respectively 32-bit, subtraction
+// of the numbers specified by the |var1| and |var2| parameters.
+//
+// Input:
+//      - var1      : Input variable 1
+//      - var2      : Input variable 2
+//
+// Returned value   : Subtracted and saturated value
+//
+
+//
+// WebRtcSpl_GetSizeInBits(...)
+//
+// Returns the # of bits that are needed at the most to represent the number
+// specified by the |value| parameter.
+//
+// Input:
+//      - value     : Input value
+//
+// Return value     : Number of bits needed to represent |value|
+//
+
+//
+// WebRtcSpl_NormW32(...)
+//
+// Norm returns the # of left shifts required to 32-bit normalize the 32-bit
+// signed number specified by the |value| parameter.
+//
+// Input:
+//      - value     : Input value
+//
+// Return value     : Number of bit shifts needed to 32-bit normalize |value|
+//
+
+//
+// WebRtcSpl_NormW16(...)
+//
+// Norm returns the # of left shifts required to 16-bit normalize the 16-bit
+// signed number specified by the |value| parameter.
+//
+// Input:
+//      - value     : Input value
+//
+// Return value     : Number of bit shifts needed to 32-bit normalize |value|
+//
+
+//
+// WebRtcSpl_NormU32(...)
+//
+// Norm returns the # of left shifts required to 32-bit normalize the unsigned
+// 32-bit number specified by the |value| parameter.
+//
+// Input:
+//      - value     : Input value
+//
+// Return value     : Number of bit shifts needed to 32-bit normalize |value|
+//
+
+//
+// WebRtcSpl_GetScalingSquare(...)
+//
+// Returns the # of bits required to scale the samples specified in the
+// |in_vector| parameter so that, if the squares of the samples are added the
+// # of times specified by the |times| parameter, the 32-bit addition will not
+// overflow (result in int32_t).
+//
+// Input:
+//      - in_vector         : Input vector to check scaling on
+//      - in_vector_length  : Samples in |in_vector|
+//      - times             : Number of additions to be performed
+//
+// Return value             : Number of right bit shifts needed to avoid
+//                            overflow in the addition calculation
+//
+
+//
+// WebRtcSpl_MemSetW16(...)
+//
+// Sets all the values in the int16_t vector |vector| of length
+// |vector_length| to the specified value |set_value|
+//
+// Input:
+//      - vector        : Pointer to the int16_t vector
+//      - set_value     : Value specified
+//      - vector_length : Length of vector
+//
+
+//
+// WebRtcSpl_MemSetW32(...)
+//
+// Sets all the values in the int32_t vector |vector| of length
+// |vector_length| to the specified value |set_value|
+//
+// Input:
+//      - vector        : Pointer to the int16_t vector
+//      - set_value     : Value specified
+//      - vector_length : Length of vector
+//
+
+//
+// WebRtcSpl_MemCpyReversedOrder(...)
+//
+// Copies all the values from the source int16_t vector |in_vector| to a
+// destination int16_t vector |out_vector|. It is done in reversed order,
+// meaning that the first sample of |in_vector| is copied to the last sample of
+// the |out_vector|. The procedure continues until the last sample of
+// |in_vector| has been copied to the first sample of |out_vector|. This
+// creates a reversed vector. Used in e.g. prediction in iLBC.
+//
+// Input:
+//      - in_vector     : Pointer to the first sample in a int16_t vector
+//                        of length |length|
+//      - vector_length : Number of elements to copy
+//
+// Output:
+//      - out_vector    : Pointer to the last sample in a int16_t vector
+//                        of length |length|
+//
+
+//
+// WebRtcSpl_CopyFromEndW16(...)
+//
+// Copies the rightmost |samples| of |in_vector| (of length |in_vector_length|)
+// to the vector |out_vector|.
+//
+// Input:
+//      - in_vector         : Input vector
+//      - in_vector_length  : Number of samples in |in_vector|
+//      - samples           : Number of samples to extract (from right side)
+//                            from |in_vector|
+//
+// Output:
+//      - out_vector        : Vector with the requested samples
+//
+
+//
+// WebRtcSpl_ZerosArrayW16(...)
+// WebRtcSpl_ZerosArrayW32(...)
+//
+// Inserts the value "zero" in all positions of a w16 and a w32 vector
+// respectively.
+//
+// Input:
+//      - vector_length : Number of samples in vector
+//
+// Output:
+//      - vector        : Vector containing all zeros
+//
+
+//
+// WebRtcSpl_VectorBitShiftW16(...)
+// WebRtcSpl_VectorBitShiftW32(...)
+//
+// Bit shifts all the values in a vector up or downwards. Different calls for
+// int16_t and int32_t vectors respectively.
+//
+// Input:
+//      - vector_length : Length of vector
+//      - in_vector     : Pointer to the vector that should be bit shifted
+//      - right_shifts  : Number of right bit shifts (negative value gives left
+//                        shifts)
+//
+// Output:
+//      - out_vector    : Pointer to the result vector (can be the same as
+//                        |in_vector|)
+//
+
+//
+// WebRtcSpl_VectorBitShiftW32ToW16(...)
+//
+// Bit shifts all the values in a int32_t vector up or downwards and
+// stores the result as an int16_t vector. The function will saturate the
+// signal if needed, before storing in the output vector.
+//
+// Input:
+//      - vector_length : Length of vector
+//      - in_vector     : Pointer to the vector that should be bit shifted
+//      - right_shifts  : Number of right bit shifts (negative value gives left
+//                        shifts)
+//
+// Output:
+//      - out_vector    : Pointer to the result vector (can be the same as
+//                        |in_vector|)
+//
+
+//
+// WebRtcSpl_ScaleVector(...)
+//
+// Performs the vector operation:
+//  out_vector[k] = (gain*in_vector[k])>>right_shifts
+//
+// Input:
+//      - in_vector     : Input vector
+//      - gain          : Scaling gain
+//      - vector_length : Elements in the |in_vector|
+//      - right_shifts  : Number of right bit shifts applied
+//
+// Output:
+//      - out_vector    : Output vector (can be the same as |in_vector|)
+//
+
+//
+// WebRtcSpl_ScaleVectorWithSat(...)
+//
+// Performs the vector operation:
+//  out_vector[k] = SATURATE( (gain*in_vector[k])>>right_shifts )
+//
+// Input:
+//      - in_vector     : Input vector
+//      - gain          : Scaling gain
+//      - vector_length : Elements in the |in_vector|
+//      - right_shifts  : Number of right bit shifts applied
+//
+// Output:
+//      - out_vector    : Output vector (can be the same as |in_vector|)
+//
+
+//
+// WebRtcSpl_ScaleAndAddVectors(...)
+//
+// Performs the vector operation:
+//  out_vector[k] = (gain1*in_vector1[k])>>right_shifts1
+//                  + (gain2*in_vector2[k])>>right_shifts2
+//
+// Input:
+//      - in_vector1    : Input vector 1
+//      - gain1         : Gain to be used for vector 1
+//      - right_shifts1 : Right bit shift to be used for vector 1
+//      - in_vector2    : Input vector 2
+//      - gain2         : Gain to be used for vector 2
+//      - right_shifts2 : Right bit shift to be used for vector 2
+//      - vector_length : Elements in the input vectors
+//
+// Output:
+//      - out_vector    : Output vector
+//
+
+//
+// WebRtcSpl_ReverseOrderMultArrayElements(...)
+//
+// Performs the vector operation:
+//  out_vector[n] = (in_vector[n]*window[-n])>>right_shifts
+//
+// Input:
+//      - in_vector     : Input vector
+//      - window        : Window vector (should be reversed). The pointer
+//                        should be set to the last value in the vector
+//      - right_shifts  : Number of right bit shift to be applied after the
+//                        multiplication
+//      - vector_length : Number of elements in |in_vector|
+//
+// Output:
+//      - out_vector    : Output vector (can be same as |in_vector|)
+//
+
+//
+// WebRtcSpl_ElementwiseVectorMult(...)
+//
+// Performs the vector operation:
+//  out_vector[n] = (in_vector[n]*window[n])>>right_shifts
+//
+// Input:
+//      - in_vector     : Input vector
+//      - window        : Window vector.
+//      - right_shifts  : Number of right bit shift to be applied after the
+//                        multiplication
+//      - vector_length : Number of elements in |in_vector|
+//
+// Output:
+//      - out_vector    : Output vector (can be same as |in_vector|)
+//
+
+//
+// WebRtcSpl_AddVectorsAndShift(...)
+//
+// Performs the vector operation:
+//  out_vector[k] = (in_vector1[k] + in_vector2[k])>>right_shifts
+//
+// Input:
+//      - in_vector1    : Input vector 1
+//      - in_vector2    : Input vector 2
+//      - right_shifts  : Number of right bit shift to be applied after the
+//                        multiplication
+//      - vector_length : Number of elements in |in_vector1| and |in_vector2|
+//
+// Output:
+//      - out_vector    : Output vector (can be same as |in_vector1|)
+//
+
+//
+// WebRtcSpl_AddAffineVectorToVector(...)
+//
+// Adds an affine transformed vector to another vector |out_vector|, i.e,
+// performs
+//  out_vector[k] += (in_vector[k]*gain+add_constant)>>right_shifts
+//
+// Input:
+//      - in_vector     : Input vector
+//      - gain          : Gain value, used to multiply the in vector with
+//      - add_constant  : Constant value to add (usually 1<<(right_shifts-1),
+//                        but others can be used as well
+//      - right_shifts  : Number of right bit shifts (0-16)
+//      - vector_length : Number of samples in |in_vector| and |out_vector|
+//
+// Output:
+//      - out_vector    : Vector with the output
+//
+
+//
+// WebRtcSpl_AffineTransformVector(...)
+//
+// Affine transforms a vector, i.e, performs
+//  out_vector[k] = (in_vector[k]*gain+add_constant)>>right_shifts
+//
+// Input:
+//      - in_vector     : Input vector
+//      - gain          : Gain value, used to multiply the in vector with
+//      - add_constant  : Constant value to add (usually 1<<(right_shifts-1),
+//                        but others can be used as well
+//      - right_shifts  : Number of right bit shifts (0-16)
+//      - vector_length : Number of samples in |in_vector| and |out_vector|
+//
+// Output:
+//      - out_vector    : Vector with the output
+//
+
+//
+// WebRtcSpl_IncreaseSeed(...)
+//
+// Increases the seed (and returns the new value)
+//
+// Input:
+//      - seed      : Seed for random calculation
+//
+// Output:
+//      - seed      : Updated seed value
+//
+// Return value     : The new seed value
+//
+
+//
+// WebRtcSpl_RandU(...)
+//
+// Produces a uniformly distributed value in the int16_t range
+//
+// Input:
+//      - seed      : Seed for random calculation
+//
+// Output:
+//      - seed      : Updated seed value
+//
+// Return value     : Uniformly distributed value in the range
+//                    [Word16_MIN...Word16_MAX]
+//
+
+//
+// WebRtcSpl_RandN(...)
+//
+// Produces a normal distributed value in the int16_t range
+//
+// Input:
+//      - seed      : Seed for random calculation
+//
+// Output:
+//      - seed      : Updated seed value
+//
+// Return value     : N(0,1) value in the Q13 domain
+//
+
+//
+// WebRtcSpl_RandUArray(...)
+//
+// Produces a uniformly distributed vector with elements in the int16_t
+// range
+//
+// Input:
+//      - vector_length : Samples wanted in the vector
+//      - seed          : Seed for random calculation
+//
+// Output:
+//      - vector        : Vector with the uniform values
+//      - seed          : Updated seed value
+//
+// Return value         : Number of samples in vector, i.e., |vector_length|
+//
+
+//
+// WebRtcSpl_Sqrt(...)
+//
+// Returns the square root of the input value |value|. The precision of this
+// function is integer precision, i.e., sqrt(8) gives 2 as answer.
+// If |value| is a negative number then 0 is returned.
+//
+// Algorithm:
+//
+// A sixth order Taylor Series expansion is used here to compute the square
+// root of a number y^0.5 = (1+x)^0.5
+// where
+// x = y-1
+//   = 1+(x/2)-0.5*((x/2)^2+0.5*((x/2)^3-0.625*((x/2)^4+0.875*((x/2)^5)
+// 0.5 <= x < 1
+//
+// Input:
+//      - value     : Value to calculate sqrt of
+//
+// Return value     : Result of the sqrt calculation
+//
+
+//
+// WebRtcSpl_DivU32U16(...)
+//
+// Divides a uint32_t |num| by a uint16_t |den|.
+//
+// If |den|==0, (uint32_t)0xFFFFFFFF is returned.
+//
+// Input:
+//      - num       : Numerator
+//      - den       : Denominator
+//
+// Return value     : Result of the division (as a uint32_t), i.e., the
+//                    integer part of num/den.
+//
+
+//
+// WebRtcSpl_DivW32W16(...)
+//
+// Divides a int32_t |num| by a int16_t |den|.
+//
+// If |den|==0, (int32_t)0x7FFFFFFF is returned.
+//
+// Input:
+//      - num       : Numerator
+//      - den       : Denominator
+//
+// Return value     : Result of the division (as a int32_t), i.e., the
+//                    integer part of num/den.
+//
+
+//
+// WebRtcSpl_DivW32W16ResW16(...)
+//
+// Divides a int32_t |num| by a int16_t |den|, assuming that the
+// result is less than 32768, otherwise an unpredictable result will occur.
+//
+// If |den|==0, (int16_t)0x7FFF is returned.
+//
+// Input:
+//      - num       : Numerator
+//      - den       : Denominator
+//
+// Return value     : Result of the division (as a int16_t), i.e., the
+//                    integer part of num/den.
+//
+
+//
+// WebRtcSpl_DivResultInQ31(...)
+//
+// Divides a int32_t |num| by a int16_t |den|, assuming that the
+// absolute value of the denominator is larger than the numerator, otherwise
+// an unpredictable result will occur.
+//
+// Input:
+//      - num       : Numerator
+//      - den       : Denominator
+//
+// Return value     : Result of the division in Q31.
+//
+
+//
+// WebRtcSpl_DivW32HiLow(...)
+//
+// Divides a int32_t |num| by a denominator in hi, low format. The
+// absolute value of the denominator has to be larger (or equal to) the
+// numerator.
+//
+// Input:
+//      - num       : Numerator
+//      - den_hi    : High part of denominator
+//      - den_low   : Low part of denominator
+//
+// Return value     : Divided value in Q31
+//
+
+//
+// WebRtcSpl_Energy(...)
+//
+// Calculates the energy of a vector
+//
+// Input:
+//      - vector        : Vector which the energy should be calculated on
+//      - vector_length : Number of samples in vector
+//
+// Output:
+//      - scale_factor  : Number of left bit shifts needed to get the physical
+//                        energy value, i.e, to get the Q0 value
+//
+// Return value         : Energy value in Q(-|scale_factor|)
+//
+
+//
+// WebRtcSpl_FilterAR(...)
+//
+// Performs a 32-bit AR filtering on a vector in Q12
+//
+// Input:
+//  - ar_coef                   : AR-coefficient vector (values in Q12),
+//                                ar_coef[0] must be 4096.
+//  - ar_coef_length            : Number of coefficients in |ar_coef|.
+//  - in_vector                 : Vector to be filtered.
+//  - in_vector_length          : Number of samples in |in_vector|.
+//  - filter_state              : Current state (higher part) of the filter.
+//  - filter_state_length       : Length (in samples) of |filter_state|.
+//  - filter_state_low          : Current state (lower part) of the filter.
+//  - filter_state_low_length   : Length (in samples) of |filter_state_low|.
+//  - out_vector_low_length     : Maximum length (in samples) of
+//                                |out_vector_low|.
+//
+// Output:
+//  - filter_state              : Updated state (upper part) vector.
+//  - filter_state_low          : Updated state (lower part) vector.
+//  - out_vector                : Vector containing the upper part of the
+//                                filtered values.
+//  - out_vector_low            : Vector containing the lower part of the
+//                                filtered values.
+//
+// Return value                 : Number of samples in the |out_vector|.
+//
+
+//
+// WebRtcSpl_ComplexIFFT(...)
+//
+// Complex Inverse FFT
+//
+// Computes an inverse complex 2^|stages|-point FFT on the input vector, which
+// is in bit-reversed order. The original content of the vector is destroyed in
+// the process, since the input is overwritten by the output, normal-ordered,
+// FFT vector. With X as the input complex vector, y as the output complex
+// vector and with M = 2^|stages|, the following is computed:
+//
+//        M-1
+// y(k) = sum[X(i)*[cos(2*pi*i*k/M) + j*sin(2*pi*i*k/M)]]
+//        i=0
+//
+// The implementations are optimized for speed, not for code size. It uses the
+// decimation-in-time algorithm with radix-2 butterfly technique.
+//
+// Input:
+//      - vector    : In pointer to complex vector containing 2^|stages|
+//                    real elements interleaved with 2^|stages| imaginary
+//                    elements.
+//                    [ReImReImReIm....]
+//                    The elements are in Q(-scale) domain, see more on Return
+//                    Value below.
+//
+//      - stages    : Number of FFT stages. Must be at least 3 and at most 10,
+//                    since the table WebRtcSpl_kSinTable1024[] is 1024
+//                    elements long.
+//
+//      - mode      : This parameter gives the user to choose how the FFT
+//                    should work.
+//                    mode==0: Low-complexity and Low-accuracy mode
+//                    mode==1: High-complexity and High-accuracy mode
+//
+// Output:
+//      - vector    : Out pointer to the FFT vector (the same as input).
+//
+// Return Value     : The scale value that tells the number of left bit shifts
+//                    that the elements in the |vector| should be shifted with
+//                    in order to get Q0 values, i.e. the physically correct
+//                    values. The scale parameter is always 0 or positive,
+//                    except if N>1024 (|stages|>10), which returns a scale
+//                    value of -1, indicating error.
+//
+
+//
+// WebRtcSpl_ComplexFFT(...)
+//
+// Complex FFT
+//
+// Computes a complex 2^|stages|-point FFT on the input vector, which is in
+// bit-reversed order. The original content of the vector is destroyed in
+// the process, since the input is overwritten by the output, normal-ordered,
+// FFT vector. With x as the input complex vector, Y as the output complex
+// vector and with M = 2^|stages|, the following is computed:
+//
+//              M-1
+// Y(k) = 1/M * sum[x(i)*[cos(2*pi*i*k/M) + j*sin(2*pi*i*k/M)]]
+//              i=0
+//
+// The implementations are optimized for speed, not for code size. It uses the
+// decimation-in-time algorithm with radix-2 butterfly technique.
+//
+// This routine prevents overflow by scaling by 2 before each FFT stage. This is
+// a fixed scaling, for proper normalization - there will be log2(n) passes, so
+// this results in an overall factor of 1/n, distributed to maximize arithmetic
+// accuracy.
+//
+// Input:
+//      - vector    : In pointer to complex vector containing 2^|stages| real
+//                    elements interleaved with 2^|stages| imaginary elements.
+//                    [ReImReImReIm....]
+//                    The output is in the Q0 domain.
+//
+//      - stages    : Number of FFT stages. Must be at least 3 and at most 10,
+//                    since the table WebRtcSpl_kSinTable1024[] is 1024
+//                    elements long.
+//
+//      - mode      : This parameter gives the user to choose how the FFT
+//                    should work.
+//                    mode==0: Low-complexity and Low-accuracy mode
+//                    mode==1: High-complexity and High-accuracy mode
+//
+// Output:
+//      - vector    : The output FFT vector is in the Q0 domain.
+//
+// Return value     : The scale parameter is always 0, except if N>1024,
+//                    which returns a scale value of -1, indicating error.
+//
+
+//
+// WebRtcSpl_AnalysisQMF(...)
+//
+// Splits a 0-2*F Hz signal into two sub bands: 0-F Hz and F-2*F Hz. The
+// current version has F = 8000, therefore, a super-wideband audio signal is
+// split to lower-band 0-8 kHz and upper-band 8-16 kHz.
+//
+// Input:
+//      - in_data       : Wide band speech signal, 320 samples (10 ms)
+//
+// Input & Output:
+//      - filter_state1 : Filter state for first All-pass filter
+//      - filter_state2 : Filter state for second All-pass filter
+//
+// Output:
+//      - low_band      : Lower-band signal 0-8 kHz band, 160 samples (10 ms)
+//      - high_band     : Upper-band signal 8-16 kHz band (flipped in frequency
+//                        domain), 160 samples (10 ms)
+//
+
+//
+// WebRtcSpl_SynthesisQMF(...)
+//
+// Combines the two sub bands (0-F and F-2*F Hz) into a signal of 0-2*F
+// Hz, (current version has F = 8000 Hz). So the filter combines lower-band
+// (0-8 kHz) and upper-band (8-16 kHz) channels to obtain super-wideband 0-16
+// kHz audio.
+//
+// Input:
+//      - low_band      : The signal with the 0-8 kHz band, 160 samples (10 ms)
+//      - high_band     : The signal with the 8-16 kHz band, 160 samples (10 ms)
+//
+// Input & Output:
+//      - filter_state1 : Filter state for first All-pass filter
+//      - filter_state2 : Filter state for second All-pass filter
+//
+// Output:
+//      - out_data      : Super-wideband speech signal, 0-16 kHz
+//
+
+// int16_t WebRtcSpl_SatW32ToW16(...)
+//
+// This function saturates a 32-bit word into a 16-bit word.
+//
+// Input:
+//      - value32   : The value of a 32-bit word.
+//
+// Output:
+//      - out16     : the saturated 16-bit word.
+//
+
+// int32_t WebRtc_MulAccumW16(...)
+//
+// This function multiply a 16-bit word by a 16-bit word, and accumulate this
+// value to a 32-bit integer.
+//
+// Input:
+//      - a    : The value of the first 16-bit word.
+//      - b    : The value of the second 16-bit word.
+//      - c    : The value of an 32-bit integer.
+//
+// Return Value: The value of a * b + c.
+//
diff --git a/third_party/webrtc_aec3/src/common_audio/signal_processing/include/spl_inl.h b/third_party/webrtc_aec3/src/common_audio/signal_processing/include/spl_inl.h
new file mode 100644
index 0000000..656a312
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/signal_processing/include/spl_inl.h
@@ -0,0 +1,153 @@
+/*
+ *  Copyright (c) 2011 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// This header file includes the inline functions in
+// the fix point signal processing library.
+
+#ifndef COMMON_AUDIO_SIGNAL_PROCESSING_INCLUDE_SPL_INL_H_
+#define COMMON_AUDIO_SIGNAL_PROCESSING_INCLUDE_SPL_INL_H_
+
+#include "rtc_base/compile_assert_c.h"
+
+extern const int8_t kWebRtcSpl_CountLeadingZeros32_Table[64];
+
+// Don't call this directly except in tests!
+static __inline int WebRtcSpl_CountLeadingZeros32_NotBuiltin(uint32_t n) {
+  // Normalize n by rounding up to the nearest number that is a sequence of 0
+  // bits followed by a sequence of 1 bits. This number has the same number of
+  // leading zeros as the original n. There are exactly 33 such values.
+  n |= n >> 1;
+  n |= n >> 2;
+  n |= n >> 4;
+  n |= n >> 8;
+  n |= n >> 16;
+
+  // Multiply the modified n with a constant selected (by exhaustive search)
+  // such that each of the 33 possible values of n give a product whose 6 most
+  // significant bits are unique. Then look up the answer in the table.
+  return kWebRtcSpl_CountLeadingZeros32_Table[(n * 0x8c0b2891) >> 26];
+}
+
+// Don't call this directly except in tests!
+static __inline int WebRtcSpl_CountLeadingZeros64_NotBuiltin(uint64_t n) {
+  const int leading_zeros = n >> 32 == 0 ? 32 : 0;
+  return leading_zeros + WebRtcSpl_CountLeadingZeros32_NotBuiltin(
+                             (uint32_t)(n >> (32 - leading_zeros)));
+}
+
+// Returns the number of leading zero bits in the argument.
+static __inline int WebRtcSpl_CountLeadingZeros32(uint32_t n) {
+#ifdef __GNUC__
+  RTC_COMPILE_ASSERT(sizeof(unsigned int) == sizeof(uint32_t));
+  return n == 0 ? 32 : __builtin_clz(n);
+#else
+  return WebRtcSpl_CountLeadingZeros32_NotBuiltin(n);
+#endif
+}
+
+// Returns the number of leading zero bits in the argument.
+static __inline int WebRtcSpl_CountLeadingZeros64(uint64_t n) {
+#ifdef __GNUC__
+  RTC_COMPILE_ASSERT(sizeof(unsigned long long) == sizeof(uint64_t));  // NOLINT
+  return n == 0 ? 64 : __builtin_clzll(n);
+#else
+  return WebRtcSpl_CountLeadingZeros64_NotBuiltin(n);
+#endif
+}
+
+#ifdef WEBRTC_ARCH_ARM_V7
+#include "common_audio/signal_processing/include/spl_inl_armv7.h"
+#else
+
+#if defined(MIPS32_LE)
+#include "common_audio/signal_processing/include/spl_inl_mips.h"
+#endif
+
+#if !defined(MIPS_DSP_R1_LE)
+static __inline int16_t WebRtcSpl_SatW32ToW16(int32_t value32) {
+  int16_t out16 = (int16_t)value32;
+
+  if (value32 > 32767)
+    out16 = 32767;
+  else if (value32 < -32768)
+    out16 = -32768;
+
+  return out16;
+}
+
+static __inline int32_t WebRtcSpl_AddSatW32(int32_t a, int32_t b) {
+  // Do the addition in unsigned numbers, since signed overflow is undefined
+  // behavior.
+  const int32_t sum = (int32_t)((uint32_t)a + (uint32_t)b);
+
+  // a + b can't overflow if a and b have different signs. If they have the
+  // same sign, a + b also has the same sign iff it didn't overflow.
+  if ((a < 0) == (b < 0) && (a < 0) != (sum < 0)) {
+    // The direction of the overflow is obvious from the sign of a + b.
+    return sum < 0 ? INT32_MAX : INT32_MIN;
+  }
+  return sum;
+}
+
+static __inline int32_t WebRtcSpl_SubSatW32(int32_t a, int32_t b) {
+  // Do the subtraction in unsigned numbers, since signed overflow is undefined
+  // behavior.
+  const int32_t diff = (int32_t)((uint32_t)a - (uint32_t)b);
+
+  // a - b can't overflow if a and b have the same sign. If they have different
+  // signs, a - b has the same sign as a iff it didn't overflow.
+  if ((a < 0) != (b < 0) && (a < 0) != (diff < 0)) {
+    // The direction of the overflow is obvious from the sign of a - b.
+    return diff < 0 ? INT32_MAX : INT32_MIN;
+  }
+  return diff;
+}
+
+static __inline int16_t WebRtcSpl_AddSatW16(int16_t a, int16_t b) {
+  return WebRtcSpl_SatW32ToW16((int32_t)a + (int32_t)b);
+}
+
+static __inline int16_t WebRtcSpl_SubSatW16(int16_t var1, int16_t var2) {
+  return WebRtcSpl_SatW32ToW16((int32_t)var1 - (int32_t)var2);
+}
+#endif  // #if !defined(MIPS_DSP_R1_LE)
+
+#if !defined(MIPS32_LE)
+static __inline int16_t WebRtcSpl_GetSizeInBits(uint32_t n) {
+  return 32 - WebRtcSpl_CountLeadingZeros32(n);
+}
+
+// Return the number of steps a can be left-shifted without overflow,
+// or 0 if a == 0.
+static __inline int16_t WebRtcSpl_NormW32(int32_t a) {
+  return a == 0 ? 0 : WebRtcSpl_CountLeadingZeros32(a < 0 ? ~a : a) - 1;
+}
+
+// Return the number of steps a can be left-shifted without overflow,
+// or 0 if a == 0.
+static __inline int16_t WebRtcSpl_NormU32(uint32_t a) {
+  return a == 0 ? 0 : WebRtcSpl_CountLeadingZeros32(a);
+}
+
+// Return the number of steps a can be left-shifted without overflow,
+// or 0 if a == 0.
+static __inline int16_t WebRtcSpl_NormW16(int16_t a) {
+  const int32_t a32 = a;
+  return a == 0 ? 0 : WebRtcSpl_CountLeadingZeros32(a < 0 ? ~a32 : a32) - 17;
+}
+
+static __inline int32_t WebRtc_MulAccumW16(int16_t a, int16_t b, int32_t c) {
+  return (a * b + c);
+}
+#endif  // #if !defined(MIPS32_LE)
+
+#endif  // WEBRTC_ARCH_ARM_V7
+
+#endif  // COMMON_AUDIO_SIGNAL_PROCESSING_INCLUDE_SPL_INL_H_
diff --git a/third_party/webrtc_aec3/src/common_audio/signal_processing/include/spl_inl_armv7.h b/third_party/webrtc_aec3/src/common_audio/signal_processing/include/spl_inl_armv7.h
new file mode 100644
index 0000000..930e91e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/signal_processing/include/spl_inl_armv7.h
@@ -0,0 +1,136 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+/* This header file includes the inline functions for ARM processors in
+ * the fix point signal processing library.
+ */
+
+#ifndef COMMON_AUDIO_SIGNAL_PROCESSING_INCLUDE_SPL_INL_ARMV7_H_
+#define COMMON_AUDIO_SIGNAL_PROCESSING_INCLUDE_SPL_INL_ARMV7_H_
+
+/* TODO(kma): Replace some assembly code with GCC intrinsics
+ * (e.g. __builtin_clz).
+ */
+
+/* This function produces result that is not bit exact with that by the generic
+ * C version in some cases, although the former is at least as accurate as the
+ * later.
+ */
+static __inline int32_t WEBRTC_SPL_MUL_16_32_RSFT16(int16_t a, int32_t b) {
+  int32_t tmp = 0;
+  __asm __volatile("smulwb %0, %1, %2" : "=r"(tmp) : "r"(b), "r"(a));
+  return tmp;
+}
+
+static __inline int32_t WEBRTC_SPL_MUL_16_16(int16_t a, int16_t b) {
+  int32_t tmp = 0;
+  __asm __volatile("smulbb %0, %1, %2" : "=r"(tmp) : "r"(a), "r"(b));
+  return tmp;
+}
+
+// TODO(kma): add unit test.
+static __inline int32_t WebRtc_MulAccumW16(int16_t a, int16_t b, int32_t c) {
+  int32_t tmp = 0;
+  __asm __volatile("smlabb %0, %1, %2, %3"
+                   : "=r"(tmp)
+                   : "r"(a), "r"(b), "r"(c));
+  return tmp;
+}
+
+static __inline int16_t WebRtcSpl_AddSatW16(int16_t a, int16_t b) {
+  int32_t s_sum = 0;
+
+  __asm __volatile("qadd16 %0, %1, %2" : "=r"(s_sum) : "r"(a), "r"(b));
+
+  return (int16_t)s_sum;
+}
+
+static __inline int32_t WebRtcSpl_AddSatW32(int32_t l_var1, int32_t l_var2) {
+  int32_t l_sum = 0;
+
+  __asm __volatile("qadd %0, %1, %2" : "=r"(l_sum) : "r"(l_var1), "r"(l_var2));
+
+  return l_sum;
+}
+
+static __inline int32_t WebRtcSpl_SubSatW32(int32_t l_var1, int32_t l_var2) {
+  int32_t l_sub = 0;
+
+  __asm __volatile("qsub %0, %1, %2" : "=r"(l_sub) : "r"(l_var1), "r"(l_var2));
+
+  return l_sub;
+}
+
+static __inline int16_t WebRtcSpl_SubSatW16(int16_t var1, int16_t var2) {
+  int32_t s_sub = 0;
+
+  __asm __volatile("qsub16 %0, %1, %2" : "=r"(s_sub) : "r"(var1), "r"(var2));
+
+  return (int16_t)s_sub;
+}
+
+static __inline int16_t WebRtcSpl_GetSizeInBits(uint32_t n) {
+  int32_t tmp = 0;
+
+  __asm __volatile("clz %0, %1" : "=r"(tmp) : "r"(n));
+
+  return (int16_t)(32 - tmp);
+}
+
+static __inline int16_t WebRtcSpl_NormW32(int32_t a) {
+  int32_t tmp = 0;
+
+  if (a == 0) {
+    return 0;
+  } else if (a < 0) {
+    a ^= 0xFFFFFFFF;
+  }
+
+  __asm __volatile("clz %0, %1" : "=r"(tmp) : "r"(a));
+
+  return (int16_t)(tmp - 1);
+}
+
+static __inline int16_t WebRtcSpl_NormU32(uint32_t a) {
+  int tmp = 0;
+
+  if (a == 0)
+    return 0;
+
+  __asm __volatile("clz %0, %1" : "=r"(tmp) : "r"(a));
+
+  return (int16_t)tmp;
+}
+
+static __inline int16_t WebRtcSpl_NormW16(int16_t a) {
+  int32_t tmp = 0;
+  int32_t a_32 = a;
+
+  if (a_32 == 0) {
+    return 0;
+  } else if (a_32 < 0) {
+    a_32 ^= 0xFFFFFFFF;
+  }
+
+  __asm __volatile("clz %0, %1" : "=r"(tmp) : "r"(a_32));
+
+  return (int16_t)(tmp - 17);
+}
+
+// TODO(kma): add unit test.
+static __inline int16_t WebRtcSpl_SatW32ToW16(int32_t value32) {
+  int32_t out = 0;
+
+  __asm __volatile("ssat %0, #16, %1" : "=r"(out) : "r"(value32));
+
+  return (int16_t)out;
+}
+
+#endif  // COMMON_AUDIO_SIGNAL_PROCESSING_INCLUDE_SPL_INL_ARMV7_H_
diff --git a/third_party/webrtc_aec3/src/common_audio/signal_processing/include/spl_inl_mips.h b/third_party/webrtc_aec3/src/common_audio/signal_processing/include/spl_inl_mips.h
new file mode 100644
index 0000000..1db95e8
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/signal_processing/include/spl_inl_mips.h
@@ -0,0 +1,204 @@
+/*
+ *  Copyright (c) 2013 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// This header file includes the inline functions in
+// the fix point signal processing library.
+
+#ifndef COMMON_AUDIO_SIGNAL_PROCESSING_INCLUDE_SPL_INL_MIPS_H_
+#define COMMON_AUDIO_SIGNAL_PROCESSING_INCLUDE_SPL_INL_MIPS_H_
+
+static __inline int32_t WEBRTC_SPL_MUL_16_16(int32_t a, int32_t b) {
+  int32_t value32 = 0;
+  int32_t a1 = 0, b1 = 0;
+
+  __asm __volatile(
+#if defined(MIPS32_R2_LE)
+      "seh    %[a1],          %[a]                \n\t"
+      "seh    %[b1],          %[b]                \n\t"
+#else
+      "sll    %[a1],          %[a],         16    \n\t"
+      "sll    %[b1],          %[b],         16    \n\t"
+      "sra    %[a1],          %[a1],        16    \n\t"
+      "sra    %[b1],          %[b1],        16    \n\t"
+#endif
+      "mul    %[value32],     %[a1],  %[b1]       \n\t"
+      : [value32] "=r"(value32), [a1] "=&r"(a1), [b1] "=&r"(b1)
+      : [a] "r"(a), [b] "r"(b)
+      : "hi", "lo");
+  return value32;
+}
+
+static __inline int32_t WEBRTC_SPL_MUL_16_32_RSFT16(int16_t a, int32_t b) {
+  int32_t value32 = 0, b1 = 0, b2 = 0;
+  int32_t a1 = 0;
+
+  __asm __volatile(
+#if defined(MIPS32_R2_LE)
+      "seh    %[a1],          %[a]                        \n\t"
+#else
+      "sll    %[a1],          %[a],           16          \n\t"
+      "sra    %[a1],          %[a1],          16          \n\t"
+#endif
+      "andi   %[b2],          %[b],           0xFFFF      \n\t"
+      "sra    %[b1],          %[b],           16          \n\t"
+      "sra    %[b2],          %[b2],          1           \n\t"
+      "mul    %[value32],     %[a1],          %[b1]       \n\t"
+      "mul    %[b2],          %[a1],          %[b2]       \n\t"
+      "addiu  %[b2],          %[b2],          0x4000      \n\t"
+      "sra    %[b2],          %[b2],          15          \n\t"
+      "addu   %[value32],     %[value32],     %[b2]       \n\t"
+      : [value32] "=&r"(value32), [b1] "=&r"(b1), [b2] "=&r"(b2), [a1] "=&r"(a1)
+      : [a] "r"(a), [b] "r"(b)
+      : "hi", "lo");
+  return value32;
+}
+
+#if defined(MIPS_DSP_R1_LE)
+static __inline int16_t WebRtcSpl_SatW32ToW16(int32_t value32) {
+  __asm __volatile(
+      "shll_s.w   %[value32], %[value32], 16      \n\t"
+      "sra        %[value32], %[value32], 16      \n\t"
+      : [value32] "+r"(value32)
+      :);
+  int16_t out16 = (int16_t)value32;
+  return out16;
+}
+
+static __inline int16_t WebRtcSpl_AddSatW16(int16_t a, int16_t b) {
+  int32_t value32 = 0;
+
+  __asm __volatile("addq_s.ph      %[value32],     %[a],   %[b]    \n\t"
+                   : [value32] "=r"(value32)
+                   : [a] "r"(a), [b] "r"(b));
+  return (int16_t)value32;
+}
+
+static __inline int32_t WebRtcSpl_AddSatW32(int32_t l_var1, int32_t l_var2) {
+  int32_t l_sum;
+
+  __asm __volatile(
+      "addq_s.w   %[l_sum],       %[l_var1],      %[l_var2]    \n\t"
+      : [l_sum] "=r"(l_sum)
+      : [l_var1] "r"(l_var1), [l_var2] "r"(l_var2));
+
+  return l_sum;
+}
+
+static __inline int16_t WebRtcSpl_SubSatW16(int16_t var1, int16_t var2) {
+  int32_t value32;
+
+  __asm __volatile("subq_s.ph  %[value32], %[var1],    %[var2]     \n\t"
+                   : [value32] "=r"(value32)
+                   : [var1] "r"(var1), [var2] "r"(var2));
+
+  return (int16_t)value32;
+}
+
+static __inline int32_t WebRtcSpl_SubSatW32(int32_t l_var1, int32_t l_var2) {
+  int32_t l_diff;
+
+  __asm __volatile(
+      "subq_s.w   %[l_diff],      %[l_var1],      %[l_var2]    \n\t"
+      : [l_diff] "=r"(l_diff)
+      : [l_var1] "r"(l_var1), [l_var2] "r"(l_var2));
+
+  return l_diff;
+}
+#endif
+
+static __inline int16_t WebRtcSpl_GetSizeInBits(uint32_t n) {
+  int bits = 0;
+  int i32 = 32;
+
+  __asm __volatile(
+      "clz    %[bits],    %[n]                    \n\t"
+      "subu   %[bits],    %[i32],     %[bits]     \n\t"
+      : [bits] "=&r"(bits)
+      : [n] "r"(n), [i32] "r"(i32));
+
+  return (int16_t)bits;
+}
+
+static __inline int16_t WebRtcSpl_NormW32(int32_t a) {
+  int zeros = 0;
+
+  __asm __volatile(
+      ".set       push                                \n\t"
+      ".set       noreorder                           \n\t"
+      "bnez       %[a],       1f                      \n\t"
+      " sra       %[zeros],   %[a],       31          \n\t"
+      "b          2f                                  \n\t"
+      " move      %[zeros],   $zero                   \n\t"
+      "1:                                              \n\t"
+      "xor        %[zeros],   %[a],       %[zeros]    \n\t"
+      "clz        %[zeros],   %[zeros]                \n\t"
+      "addiu      %[zeros],   %[zeros],   -1          \n\t"
+      "2:                                              \n\t"
+      ".set       pop                                 \n\t"
+      : [zeros] "=&r"(zeros)
+      : [a] "r"(a));
+
+  return (int16_t)zeros;
+}
+
+static __inline int16_t WebRtcSpl_NormU32(uint32_t a) {
+  int zeros = 0;
+
+  __asm __volatile("clz    %[zeros],   %[a]    \n\t"
+                   : [zeros] "=r"(zeros)
+                   : [a] "r"(a));
+
+  return (int16_t)(zeros & 0x1f);
+}
+
+static __inline int16_t WebRtcSpl_NormW16(int16_t a) {
+  int zeros = 0;
+  int a0 = a << 16;
+
+  __asm __volatile(
+      ".set       push                                \n\t"
+      ".set       noreorder                           \n\t"
+      "bnez       %[a0],      1f                      \n\t"
+      " sra       %[zeros],   %[a0],      31          \n\t"
+      "b          2f                                  \n\t"
+      " move      %[zeros],   $zero                   \n\t"
+      "1:                                              \n\t"
+      "xor        %[zeros],   %[a0],      %[zeros]    \n\t"
+      "clz        %[zeros],   %[zeros]                \n\t"
+      "addiu      %[zeros],   %[zeros],   -1          \n\t"
+      "2:                                              \n\t"
+      ".set       pop                                 \n\t"
+      : [zeros] "=&r"(zeros)
+      : [a0] "r"(a0));
+
+  return (int16_t)zeros;
+}
+
+static __inline int32_t WebRtc_MulAccumW16(int16_t a, int16_t b, int32_t c) {
+  int32_t res = 0, c1 = 0;
+  __asm __volatile(
+#if defined(MIPS32_R2_LE)
+      "seh    %[a],       %[a]            \n\t"
+      "seh    %[b],       %[b]            \n\t"
+#else
+      "sll    %[a],       %[a],   16      \n\t"
+      "sll    %[b],       %[b],   16      \n\t"
+      "sra    %[a],       %[a],   16      \n\t"
+      "sra    %[b],       %[b],   16      \n\t"
+#endif
+      "mul    %[res],     %[a],   %[b]    \n\t"
+      "addu   %[c1],      %[c],   %[res]  \n\t"
+      : [c1] "=r"(c1), [res] "=&r"(res)
+      : [a] "r"(a), [b] "r"(b), [c] "r"(c)
+      : "hi", "lo");
+  return (c1);
+}
+
+#endif  // COMMON_AUDIO_SIGNAL_PROCESSING_INCLUDE_SPL_INL_MIPS_H_
diff --git a/third_party/webrtc_aec3/src/common_audio/signal_processing/splitting_filter.c b/third_party/webrtc_aec3/src/common_audio/signal_processing/splitting_filter.c
new file mode 100644
index 0000000..b0d83f1
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/signal_processing/splitting_filter.c
@@ -0,0 +1,209 @@
+/*
+ *  Copyright (c) 2011 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+/*
+ * This file contains the splitting filter functions.
+ *
+ */
+
+#include "rtc_base/checks.h"
+#include "common_audio/signal_processing/include/signal_processing_library.h"
+
+// Maximum number of samples in a low/high-band frame.
+enum
+{
+    kMaxBandFrameLength = 320  // 10 ms at 64 kHz.
+};
+
+// QMF filter coefficients in Q16.
+static const uint16_t WebRtcSpl_kAllPassFilter1[3] = {6418, 36982, 57261};
+static const uint16_t WebRtcSpl_kAllPassFilter2[3] = {21333, 49062, 63010};
+
+///////////////////////////////////////////////////////////////////////////////////////////////
+// WebRtcSpl_AllPassQMF(...)
+//
+// Allpass filter used by the analysis and synthesis parts of the QMF filter.
+//
+// Input:
+//    - in_data             : Input data sequence (Q10)
+//    - data_length         : Length of data sequence (>2)
+//    - filter_coefficients : Filter coefficients (length 3, Q16)
+//
+// Input & Output:
+//    - filter_state        : Filter state (length 6, Q10).
+//
+// Output:
+//    - out_data            : Output data sequence (Q10), length equal to
+//                            |data_length|
+//
+
+static void WebRtcSpl_AllPassQMF(int32_t* in_data,
+                                 size_t data_length,
+                                 int32_t* out_data,
+                                 const uint16_t* filter_coefficients,
+                                 int32_t* filter_state)
+{
+    // The procedure is to filter the input with three first order all pass filters
+    // (cascade operations).
+    //
+    //         a_3 + q^-1    a_2 + q^-1    a_1 + q^-1
+    // y[n] =  -----------   -----------   -----------   x[n]
+    //         1 + a_3q^-1   1 + a_2q^-1   1 + a_1q^-1
+    //
+    // The input vector |filter_coefficients| includes these three filter coefficients.
+    // The filter state contains the in_data state, in_data[-1], followed by
+    // the out_data state, out_data[-1]. This is repeated for each cascade.
+    // The first cascade filter will filter the |in_data| and store the output in
+    // |out_data|. The second will the take the |out_data| as input and make an
+    // intermediate storage in |in_data|, to save memory. The third, and final, cascade
+    // filter operation takes the |in_data| (which is the output from the previous cascade
+    // filter) and store the output in |out_data|.
+    // Note that the input vector values are changed during the process.
+    size_t k;
+    int32_t diff;
+    // First all-pass cascade; filter from in_data to out_data.
+
+    // Let y_i[n] indicate the output of cascade filter i (with filter coefficient a_i) at
+    // vector position n. Then the final output will be y[n] = y_3[n]
+
+    // First loop, use the states stored in memory.
+    // "diff" should be safe from wrap around since max values are 2^25
+    // diff = (x[0] - y_1[-1])
+    diff = WebRtcSpl_SubSatW32(in_data[0], filter_state[1]);
+    // y_1[0] =  x[-1] + a_1 * (x[0] - y_1[-1])
+    out_data[0] = WEBRTC_SPL_SCALEDIFF32(filter_coefficients[0], diff, filter_state[0]);
+
+    // For the remaining loops, use previous values.
+    for (k = 1; k < data_length; k++)
+    {
+        // diff = (x[n] - y_1[n-1])
+        diff = WebRtcSpl_SubSatW32(in_data[k], out_data[k - 1]);
+        // y_1[n] =  x[n-1] + a_1 * (x[n] - y_1[n-1])
+        out_data[k] = WEBRTC_SPL_SCALEDIFF32(filter_coefficients[0], diff, in_data[k - 1]);
+    }
+
+    // Update states.
+    filter_state[0] = in_data[data_length - 1]; // x[N-1], becomes x[-1] next time
+    filter_state[1] = out_data[data_length - 1]; // y_1[N-1], becomes y_1[-1] next time
+
+    // Second all-pass cascade; filter from out_data to in_data.
+    // diff = (y_1[0] - y_2[-1])
+    diff = WebRtcSpl_SubSatW32(out_data[0], filter_state[3]);
+    // y_2[0] =  y_1[-1] + a_2 * (y_1[0] - y_2[-1])
+    in_data[0] = WEBRTC_SPL_SCALEDIFF32(filter_coefficients[1], diff, filter_state[2]);
+    for (k = 1; k < data_length; k++)
+    {
+        // diff = (y_1[n] - y_2[n-1])
+        diff = WebRtcSpl_SubSatW32(out_data[k], in_data[k - 1]);
+        // y_2[0] =  y_1[-1] + a_2 * (y_1[0] - y_2[-1])
+        in_data[k] = WEBRTC_SPL_SCALEDIFF32(filter_coefficients[1], diff, out_data[k-1]);
+    }
+
+    filter_state[2] = out_data[data_length - 1]; // y_1[N-1], becomes y_1[-1] next time
+    filter_state[3] = in_data[data_length - 1]; // y_2[N-1], becomes y_2[-1] next time
+
+    // Third all-pass cascade; filter from in_data to out_data.
+    // diff = (y_2[0] - y[-1])
+    diff = WebRtcSpl_SubSatW32(in_data[0], filter_state[5]);
+    // y[0] =  y_2[-1] + a_3 * (y_2[0] - y[-1])
+    out_data[0] = WEBRTC_SPL_SCALEDIFF32(filter_coefficients[2], diff, filter_state[4]);
+    for (k = 1; k < data_length; k++)
+    {
+        // diff = (y_2[n] - y[n-1])
+        diff = WebRtcSpl_SubSatW32(in_data[k], out_data[k - 1]);
+        // y[n] =  y_2[n-1] + a_3 * (y_2[n] - y[n-1])
+        out_data[k] = WEBRTC_SPL_SCALEDIFF32(filter_coefficients[2], diff, in_data[k-1]);
+    }
+    filter_state[4] = in_data[data_length - 1]; // y_2[N-1], becomes y_2[-1] next time
+    filter_state[5] = out_data[data_length - 1]; // y[N-1], becomes y[-1] next time
+}
+
+void WebRtcSpl_AnalysisQMF(const int16_t* in_data, size_t in_data_length,
+                           int16_t* low_band, int16_t* high_band,
+                           int32_t* filter_state1, int32_t* filter_state2)
+{
+    size_t i;
+    int16_t k;
+    int32_t tmp;
+    int32_t half_in1[kMaxBandFrameLength];
+    int32_t half_in2[kMaxBandFrameLength];
+    int32_t filter1[kMaxBandFrameLength];
+    int32_t filter2[kMaxBandFrameLength];
+    const size_t band_length = in_data_length / 2;
+    RTC_DCHECK_EQ(0, in_data_length % 2);
+    RTC_DCHECK_LE(band_length, kMaxBandFrameLength);
+
+    // Split even and odd samples. Also shift them to Q10.
+    for (i = 0, k = 0; i < band_length; i++, k += 2)
+    {
+        half_in2[i] = ((int32_t)in_data[k]) * (1 << 10);
+        half_in1[i] = ((int32_t)in_data[k + 1]) * (1 << 10);
+    }
+
+    // All pass filter even and odd samples, independently.
+    WebRtcSpl_AllPassQMF(half_in1, band_length, filter1,
+                         WebRtcSpl_kAllPassFilter1, filter_state1);
+    WebRtcSpl_AllPassQMF(half_in2, band_length, filter2,
+                         WebRtcSpl_kAllPassFilter2, filter_state2);
+
+    // Take the sum and difference of filtered version of odd and even
+    // branches to get upper & lower band.
+    for (i = 0; i < band_length; i++)
+    {
+        tmp = (filter1[i] + filter2[i] + 1024) >> 11;
+        low_band[i] = WebRtcSpl_SatW32ToW16(tmp);
+
+        tmp = (filter1[i] - filter2[i] + 1024) >> 11;
+        high_band[i] = WebRtcSpl_SatW32ToW16(tmp);
+    }
+}
+
+void WebRtcSpl_SynthesisQMF(const int16_t* low_band, const int16_t* high_band,
+                            size_t band_length, int16_t* out_data,
+                            int32_t* filter_state1, int32_t* filter_state2)
+{
+    int32_t tmp;
+    int32_t half_in1[kMaxBandFrameLength];
+    int32_t half_in2[kMaxBandFrameLength];
+    int32_t filter1[kMaxBandFrameLength];
+    int32_t filter2[kMaxBandFrameLength];
+    size_t i;
+    int16_t k;
+    RTC_DCHECK_LE(band_length, kMaxBandFrameLength);
+
+    // Obtain the sum and difference channels out of upper and lower-band channels.
+    // Also shift to Q10 domain.
+    for (i = 0; i < band_length; i++)
+    {
+        tmp = (int32_t)low_band[i] + (int32_t)high_band[i];
+        half_in1[i] = tmp * (1 << 10);
+        tmp = (int32_t)low_band[i] - (int32_t)high_band[i];
+        half_in2[i] = tmp * (1 << 10);
+    }
+
+    // all-pass filter the sum and difference channels
+    WebRtcSpl_AllPassQMF(half_in1, band_length, filter1,
+                         WebRtcSpl_kAllPassFilter2, filter_state1);
+    WebRtcSpl_AllPassQMF(half_in2, band_length, filter2,
+                         WebRtcSpl_kAllPassFilter1, filter_state2);
+
+    // The filtered signals are even and odd samples of the output. Combine
+    // them. The signals are Q10 should shift them back to Q0 and take care of
+    // saturation.
+    for (i = 0, k = 0; i < band_length; i++)
+    {
+        tmp = (filter2[i] + 512) >> 10;
+        out_data[k++] = WebRtcSpl_SatW32ToW16(tmp);
+
+        tmp = (filter1[i] + 512) >> 10;
+        out_data[k++] = WebRtcSpl_SatW32ToW16(tmp);
+    }
+
+}
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/ooura/BUILD.gn b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/BUILD.gn
new file mode 100644
index 0000000..0cdf98e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/BUILD.gn
@@ -0,0 +1,58 @@
+# Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+#
+# Use of this source code is governed by a BSD-style license
+# that can be found in the ../../../LICENSE file in the root of the source
+# tree. An additional intellectual property rights grant can be found
+# in the file PATENTS.  All contributing project authors may
+# be found in the AUTHORS file in the root of the source tree.
+
+import("../../../webrtc.gni")
+
+rtc_library("fft_size_128") {
+  sources = [
+    "fft_size_128/ooura_fft.cc",
+    "fft_size_128/ooura_fft.h",
+    "fft_size_128/ooura_fft_tables_common.h",
+  ]
+  deps = [
+    "../../../rtc_base/system:arch",
+    "../../../system_wrappers",
+  ]
+  cflags = []
+
+  if (current_cpu == "x86" || current_cpu == "x64") {
+    sources += [
+      "fft_size_128/ooura_fft_sse2.cc",
+      "fft_size_128/ooura_fft_tables_neon_sse2.h",
+    ]
+    if (is_posix || is_fuchsia) {
+      cflags += [ "-msse2" ]
+    }
+  }
+
+  if (rtc_build_with_neon) {
+    sources += [
+      "fft_size_128/ooura_fft_neon.cc",
+      "fft_size_128/ooura_fft_tables_neon_sse2.h",
+    ]
+
+    deps += [ "../../../common_audio" ]
+
+    if (current_cpu != "arm64") {
+      # Enable compilation for the NEON instruction set.
+      suppressed_configs += [ "//build/config/compiler:compiler_arm_fpu" ]
+      cflags += [ "-mfpu=neon" ]
+    }
+  }
+
+  if (current_cpu == "mipsel" && mips_float_abi == "hard") {
+    sources += [ "fft_size_128/ooura_fft_mips.cc" ]
+  }
+}
+
+rtc_library("fft_size_256") {
+  sources = [
+    "fft_size_256/fft4g.cc",
+    "fft_size_256/fft4g.h",
+  ]
+}
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/ooura/LICENSE b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/LICENSE
new file mode 100644
index 0000000..3bf870a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/LICENSE
@@ -0,0 +1,8 @@
+/*
+ * http://www.kurims.kyoto-u.ac.jp/~ooura/fft.html
+ * Copyright Takuya OOURA, 1996-2001
+ *
+ * You may use, copy, modify and distribute this code for any purpose (include
+ * commercial use) and without fee. Please refer to this package when you modify
+ * this code.
+ */
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/ooura/README.chromium b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/README.chromium
new file mode 100644
index 0000000..9df2ddb
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/README.chromium
@@ -0,0 +1,13 @@
+Name: General Purpose FFT (Fast Fourier/Cosine/Sine Transform) Package
+Short Name: fft4g
+URL: http://www.kurims.kyoto-u.ac.jp/~ooura/fft.html
+Version: 0
+Date: 2018-06-19
+License: Custome license
+License File: LICENSE
+Security Critical: yes
+
+Description:
+This is a package to calculate Discrete Fourier/Cosine/Sine Transforms of
+1-dimensional sequences of length 2^N. This package contains C and Fortran
+FFT codes.
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft.cc b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft.cc
new file mode 100644
index 0000000..6933120
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft.cc
@@ -0,0 +1,548 @@
+/*
+ * http://www.kurims.kyoto-u.ac.jp/~ooura/fft.html
+ * Copyright Takuya OOURA, 1996-2001
+ *
+ * You may use, copy, modify and distribute this code for any purpose (include
+ * commercial use) and without fee. Please refer to this package when you modify
+ * this code.
+ *
+ * Changes by the WebRTC authors:
+ *    - Trivial type modifications.
+ *    - Minimal code subset to do rdft of length 128.
+ *    - Optimizations because of known length.
+ *    - Removed the global variables by moving the code in to a class in order
+ *      to make it thread safe.
+ *
+ *  All changes are covered by the WebRTC license and IP grant:
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "common_audio/third_party/ooura/fft_size_128/ooura_fft.h"
+
+#include "common_audio/third_party/ooura/fft_size_128/ooura_fft_tables_common.h"
+#include "rtc_base/system/arch.h"
+#include "system_wrappers/include/cpu_features_wrapper.h"
+
+namespace webrtc {
+
+namespace {
+
+#if !(defined(MIPS_FPU_LE) || defined(WEBRTC_HAS_NEON))
+static void cft1st_128_C(float* a) {
+  const int n = 128;
+  int j, k1, k2;
+  float wk1r, wk1i, wk2r, wk2i, wk3r, wk3i;
+  float x0r, x0i, x1r, x1i, x2r, x2i, x3r, x3i;
+
+  // The processing of the first set of elements was simplified in C to avoid
+  // some operations (multiplication by zero or one, addition of two elements
+  // multiplied by the same weight, ...).
+  x0r = a[0] + a[2];
+  x0i = a[1] + a[3];
+  x1r = a[0] - a[2];
+  x1i = a[1] - a[3];
+  x2r = a[4] + a[6];
+  x2i = a[5] + a[7];
+  x3r = a[4] - a[6];
+  x3i = a[5] - a[7];
+  a[0] = x0r + x2r;
+  a[1] = x0i + x2i;
+  a[4] = x0r - x2r;
+  a[5] = x0i - x2i;
+  a[2] = x1r - x3i;
+  a[3] = x1i + x3r;
+  a[6] = x1r + x3i;
+  a[7] = x1i - x3r;
+  wk1r = rdft_w[2];
+  x0r = a[8] + a[10];
+  x0i = a[9] + a[11];
+  x1r = a[8] - a[10];
+  x1i = a[9] - a[11];
+  x2r = a[12] + a[14];
+  x2i = a[13] + a[15];
+  x3r = a[12] - a[14];
+  x3i = a[13] - a[15];
+  a[8] = x0r + x2r;
+  a[9] = x0i + x2i;
+  a[12] = x2i - x0i;
+  a[13] = x0r - x2r;
+  x0r = x1r - x3i;
+  x0i = x1i + x3r;
+  a[10] = wk1r * (x0r - x0i);
+  a[11] = wk1r * (x0r + x0i);
+  x0r = x3i + x1r;
+  x0i = x3r - x1i;
+  a[14] = wk1r * (x0i - x0r);
+  a[15] = wk1r * (x0i + x0r);
+  k1 = 0;
+  for (j = 16; j < n; j += 16) {
+    k1 += 2;
+    k2 = 2 * k1;
+    wk2r = rdft_w[k1 + 0];
+    wk2i = rdft_w[k1 + 1];
+    wk1r = rdft_w[k2 + 0];
+    wk1i = rdft_w[k2 + 1];
+    wk3r = rdft_wk3ri_first[k1 + 0];
+    wk3i = rdft_wk3ri_first[k1 + 1];
+    x0r = a[j + 0] + a[j + 2];
+    x0i = a[j + 1] + a[j + 3];
+    x1r = a[j + 0] - a[j + 2];
+    x1i = a[j + 1] - a[j + 3];
+    x2r = a[j + 4] + a[j + 6];
+    x2i = a[j + 5] + a[j + 7];
+    x3r = a[j + 4] - a[j + 6];
+    x3i = a[j + 5] - a[j + 7];
+    a[j + 0] = x0r + x2r;
+    a[j + 1] = x0i + x2i;
+    x0r -= x2r;
+    x0i -= x2i;
+    a[j + 4] = wk2r * x0r - wk2i * x0i;
+    a[j + 5] = wk2r * x0i + wk2i * x0r;
+    x0r = x1r - x3i;
+    x0i = x1i + x3r;
+    a[j + 2] = wk1r * x0r - wk1i * x0i;
+    a[j + 3] = wk1r * x0i + wk1i * x0r;
+    x0r = x1r + x3i;
+    x0i = x1i - x3r;
+    a[j + 6] = wk3r * x0r - wk3i * x0i;
+    a[j + 7] = wk3r * x0i + wk3i * x0r;
+    wk1r = rdft_w[k2 + 2];
+    wk1i = rdft_w[k2 + 3];
+    wk3r = rdft_wk3ri_second[k1 + 0];
+    wk3i = rdft_wk3ri_second[k1 + 1];
+    x0r = a[j + 8] + a[j + 10];
+    x0i = a[j + 9] + a[j + 11];
+    x1r = a[j + 8] - a[j + 10];
+    x1i = a[j + 9] - a[j + 11];
+    x2r = a[j + 12] + a[j + 14];
+    x2i = a[j + 13] + a[j + 15];
+    x3r = a[j + 12] - a[j + 14];
+    x3i = a[j + 13] - a[j + 15];
+    a[j + 8] = x0r + x2r;
+    a[j + 9] = x0i + x2i;
+    x0r -= x2r;
+    x0i -= x2i;
+    a[j + 12] = -wk2i * x0r - wk2r * x0i;
+    a[j + 13] = -wk2i * x0i + wk2r * x0r;
+    x0r = x1r - x3i;
+    x0i = x1i + x3r;
+    a[j + 10] = wk1r * x0r - wk1i * x0i;
+    a[j + 11] = wk1r * x0i + wk1i * x0r;
+    x0r = x1r + x3i;
+    x0i = x1i - x3r;
+    a[j + 14] = wk3r * x0r - wk3i * x0i;
+    a[j + 15] = wk3r * x0i + wk3i * x0r;
+  }
+}
+
+static void cftmdl_128_C(float* a) {
+  const int l = 8;
+  const int n = 128;
+  const int m = 32;
+  int j0, j1, j2, j3, k, k1, k2, m2;
+  float wk1r, wk1i, wk2r, wk2i, wk3r, wk3i;
+  float x0r, x0i, x1r, x1i, x2r, x2i, x3r, x3i;
+
+  for (j0 = 0; j0 < l; j0 += 2) {
+    j1 = j0 + 8;
+    j2 = j0 + 16;
+    j3 = j0 + 24;
+    x0r = a[j0 + 0] + a[j1 + 0];
+    x0i = a[j0 + 1] + a[j1 + 1];
+    x1r = a[j0 + 0] - a[j1 + 0];
+    x1i = a[j0 + 1] - a[j1 + 1];
+    x2r = a[j2 + 0] + a[j3 + 0];
+    x2i = a[j2 + 1] + a[j3 + 1];
+    x3r = a[j2 + 0] - a[j3 + 0];
+    x3i = a[j2 + 1] - a[j3 + 1];
+    a[j0 + 0] = x0r + x2r;
+    a[j0 + 1] = x0i + x2i;
+    a[j2 + 0] = x0r - x2r;
+    a[j2 + 1] = x0i - x2i;
+    a[j1 + 0] = x1r - x3i;
+    a[j1 + 1] = x1i + x3r;
+    a[j3 + 0] = x1r + x3i;
+    a[j3 + 1] = x1i - x3r;
+  }
+  wk1r = rdft_w[2];
+  for (j0 = m; j0 < l + m; j0 += 2) {
+    j1 = j0 + 8;
+    j2 = j0 + 16;
+    j3 = j0 + 24;
+    x0r = a[j0 + 0] + a[j1 + 0];
+    x0i = a[j0 + 1] + a[j1 + 1];
+    x1r = a[j0 + 0] - a[j1 + 0];
+    x1i = a[j0 + 1] - a[j1 + 1];
+    x2r = a[j2 + 0] + a[j3 + 0];
+    x2i = a[j2 + 1] + a[j3 + 1];
+    x3r = a[j2 + 0] - a[j3 + 0];
+    x3i = a[j2 + 1] - a[j3 + 1];
+    a[j0 + 0] = x0r + x2r;
+    a[j0 + 1] = x0i + x2i;
+    a[j2 + 0] = x2i - x0i;
+    a[j2 + 1] = x0r - x2r;
+    x0r = x1r - x3i;
+    x0i = x1i + x3r;
+    a[j1 + 0] = wk1r * (x0r - x0i);
+    a[j1 + 1] = wk1r * (x0r + x0i);
+    x0r = x3i + x1r;
+    x0i = x3r - x1i;
+    a[j3 + 0] = wk1r * (x0i - x0r);
+    a[j3 + 1] = wk1r * (x0i + x0r);
+  }
+  k1 = 0;
+  m2 = 2 * m;
+  for (k = m2; k < n; k += m2) {
+    k1 += 2;
+    k2 = 2 * k1;
+    wk2r = rdft_w[k1 + 0];
+    wk2i = rdft_w[k1 + 1];
+    wk1r = rdft_w[k2 + 0];
+    wk1i = rdft_w[k2 + 1];
+    wk3r = rdft_wk3ri_first[k1 + 0];
+    wk3i = rdft_wk3ri_first[k1 + 1];
+    for (j0 = k; j0 < l + k; j0 += 2) {
+      j1 = j0 + 8;
+      j2 = j0 + 16;
+      j3 = j0 + 24;
+      x0r = a[j0 + 0] + a[j1 + 0];
+      x0i = a[j0 + 1] + a[j1 + 1];
+      x1r = a[j0 + 0] - a[j1 + 0];
+      x1i = a[j0 + 1] - a[j1 + 1];
+      x2r = a[j2 + 0] + a[j3 + 0];
+      x2i = a[j2 + 1] + a[j3 + 1];
+      x3r = a[j2 + 0] - a[j3 + 0];
+      x3i = a[j2 + 1] - a[j3 + 1];
+      a[j0 + 0] = x0r + x2r;
+      a[j0 + 1] = x0i + x2i;
+      x0r -= x2r;
+      x0i -= x2i;
+      a[j2 + 0] = wk2r * x0r - wk2i * x0i;
+      a[j2 + 1] = wk2r * x0i + wk2i * x0r;
+      x0r = x1r - x3i;
+      x0i = x1i + x3r;
+      a[j1 + 0] = wk1r * x0r - wk1i * x0i;
+      a[j1 + 1] = wk1r * x0i + wk1i * x0r;
+      x0r = x1r + x3i;
+      x0i = x1i - x3r;
+      a[j3 + 0] = wk3r * x0r - wk3i * x0i;
+      a[j3 + 1] = wk3r * x0i + wk3i * x0r;
+    }
+    wk1r = rdft_w[k2 + 2];
+    wk1i = rdft_w[k2 + 3];
+    wk3r = rdft_wk3ri_second[k1 + 0];
+    wk3i = rdft_wk3ri_second[k1 + 1];
+    for (j0 = k + m; j0 < l + (k + m); j0 += 2) {
+      j1 = j0 + 8;
+      j2 = j0 + 16;
+      j3 = j0 + 24;
+      x0r = a[j0 + 0] + a[j1 + 0];
+      x0i = a[j0 + 1] + a[j1 + 1];
+      x1r = a[j0 + 0] - a[j1 + 0];
+      x1i = a[j0 + 1] - a[j1 + 1];
+      x2r = a[j2 + 0] + a[j3 + 0];
+      x2i = a[j2 + 1] + a[j3 + 1];
+      x3r = a[j2 + 0] - a[j3 + 0];
+      x3i = a[j2 + 1] - a[j3 + 1];
+      a[j0 + 0] = x0r + x2r;
+      a[j0 + 1] = x0i + x2i;
+      x0r -= x2r;
+      x0i -= x2i;
+      a[j2 + 0] = -wk2i * x0r - wk2r * x0i;
+      a[j2 + 1] = -wk2i * x0i + wk2r * x0r;
+      x0r = x1r - x3i;
+      x0i = x1i + x3r;
+      a[j1 + 0] = wk1r * x0r - wk1i * x0i;
+      a[j1 + 1] = wk1r * x0i + wk1i * x0r;
+      x0r = x1r + x3i;
+      x0i = x1i - x3r;
+      a[j3 + 0] = wk3r * x0r - wk3i * x0i;
+      a[j3 + 1] = wk3r * x0i + wk3i * x0r;
+    }
+  }
+}
+
+static void rftfsub_128_C(float* a) {
+  const float* c = rdft_w + 32;
+  int j1, j2, k1, k2;
+  float wkr, wki, xr, xi, yr, yi;
+
+  for (j1 = 1, j2 = 2; j2 < 64; j1 += 1, j2 += 2) {
+    k2 = 128 - j2;
+    k1 = 32 - j1;
+    wkr = 0.5f - c[k1];
+    wki = c[j1];
+    xr = a[j2 + 0] - a[k2 + 0];
+    xi = a[j2 + 1] + a[k2 + 1];
+    yr = wkr * xr - wki * xi;
+    yi = wkr * xi + wki * xr;
+    a[j2 + 0] -= yr;
+    a[j2 + 1] -= yi;
+    a[k2 + 0] += yr;
+    a[k2 + 1] -= yi;
+  }
+}
+
+static void rftbsub_128_C(float* a) {
+  const float* c = rdft_w + 32;
+  int j1, j2, k1, k2;
+  float wkr, wki, xr, xi, yr, yi;
+
+  a[1] = -a[1];
+  for (j1 = 1, j2 = 2; j2 < 64; j1 += 1, j2 += 2) {
+    k2 = 128 - j2;
+    k1 = 32 - j1;
+    wkr = 0.5f - c[k1];
+    wki = c[j1];
+    xr = a[j2 + 0] - a[k2 + 0];
+    xi = a[j2 + 1] + a[k2 + 1];
+    yr = wkr * xr + wki * xi;
+    yi = wkr * xi - wki * xr;
+    a[j2 + 0] = a[j2 + 0] - yr;
+    a[j2 + 1] = yi - a[j2 + 1];
+    a[k2 + 0] = yr + a[k2 + 0];
+    a[k2 + 1] = yi - a[k2 + 1];
+  }
+  a[65] = -a[65];
+}
+#endif
+
+}  // namespace
+
+OouraFft::OouraFft(bool sse2_available) {
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+  use_sse2_ = sse2_available;
+#else
+  use_sse2_ = false;
+#endif
+}
+
+OouraFft::OouraFft() {
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+  use_sse2_ = (GetCPUInfo(kSSE2) != 0);
+#else
+  use_sse2_ = false;
+#endif
+}
+
+OouraFft::~OouraFft() = default;
+
+void OouraFft::Fft(float* a) const {
+  float xi;
+  bitrv2_128(a);
+  cftfsub_128(a);
+  rftfsub_128(a);
+  xi = a[0] - a[1];
+  a[0] += a[1];
+  a[1] = xi;
+}
+void OouraFft::InverseFft(float* a) const {
+  a[1] = 0.5f * (a[0] - a[1]);
+  a[0] -= a[1];
+  rftbsub_128(a);
+  bitrv2_128(a);
+  cftbsub_128(a);
+}
+
+void OouraFft::cft1st_128(float* a) const {
+#if defined(MIPS_FPU_LE)
+  cft1st_128_mips(a);
+#elif defined(WEBRTC_HAS_NEON)
+  cft1st_128_neon(a);
+#elif defined(WEBRTC_ARCH_X86_FAMILY)
+  if (use_sse2_) {
+    cft1st_128_SSE2(a);
+  } else {
+    cft1st_128_C(a);
+  }
+#else
+  cft1st_128_C(a);
+#endif
+}
+void OouraFft::cftmdl_128(float* a) const {
+#if defined(MIPS_FPU_LE)
+  cftmdl_128_mips(a);
+#elif defined(WEBRTC_HAS_NEON)
+  cftmdl_128_neon(a);
+#elif defined(WEBRTC_ARCH_X86_FAMILY)
+  if (use_sse2_) {
+    cftmdl_128_SSE2(a);
+  } else {
+    cftmdl_128_C(a);
+  }
+#else
+  cftmdl_128_C(a);
+#endif
+}
+void OouraFft::rftfsub_128(float* a) const {
+#if defined(MIPS_FPU_LE)
+  rftfsub_128_mips(a);
+#elif defined(WEBRTC_HAS_NEON)
+  rftfsub_128_neon(a);
+#elif defined(WEBRTC_ARCH_X86_FAMILY)
+  if (use_sse2_) {
+    rftfsub_128_SSE2(a);
+  } else {
+    rftfsub_128_C(a);
+  }
+#else
+  rftfsub_128_C(a);
+#endif
+}
+
+void OouraFft::rftbsub_128(float* a) const {
+#if defined(MIPS_FPU_LE)
+  rftbsub_128_mips(a);
+#elif defined(WEBRTC_HAS_NEON)
+  rftbsub_128_neon(a);
+#elif defined(WEBRTC_ARCH_X86_FAMILY)
+  if (use_sse2_) {
+    rftbsub_128_SSE2(a);
+  } else {
+    rftbsub_128_C(a);
+  }
+#else
+  rftbsub_128_C(a);
+#endif
+}
+
+void OouraFft::cftbsub_128(float* a) const {
+  int j, j1, j2, j3, l;
+  float x0r, x0i, x1r, x1i, x2r, x2i, x3r, x3i;
+
+  cft1st_128(a);
+  cftmdl_128(a);
+  l = 32;
+
+  for (j = 0; j < l; j += 2) {
+    j1 = j + l;
+    j2 = j1 + l;
+    j3 = j2 + l;
+    x0r = a[j] + a[j1];
+    x0i = -a[j + 1] - a[j1 + 1];
+    x1r = a[j] - a[j1];
+    x1i = -a[j + 1] + a[j1 + 1];
+    x2r = a[j2] + a[j3];
+    x2i = a[j2 + 1] + a[j3 + 1];
+    x3r = a[j2] - a[j3];
+    x3i = a[j2 + 1] - a[j3 + 1];
+    a[j] = x0r + x2r;
+    a[j + 1] = x0i - x2i;
+    a[j2] = x0r - x2r;
+    a[j2 + 1] = x0i + x2i;
+    a[j1] = x1r - x3i;
+    a[j1 + 1] = x1i - x3r;
+    a[j3] = x1r + x3i;
+    a[j3 + 1] = x1i + x3r;
+  }
+}
+
+void OouraFft::cftfsub_128(float* a) const {
+  int j, j1, j2, j3, l;
+  float x0r, x0i, x1r, x1i, x2r, x2i, x3r, x3i;
+
+  cft1st_128(a);
+  cftmdl_128(a);
+  l = 32;
+  for (j = 0; j < l; j += 2) {
+    j1 = j + l;
+    j2 = j1 + l;
+    j3 = j2 + l;
+    x0r = a[j] + a[j1];
+    x0i = a[j + 1] + a[j1 + 1];
+    x1r = a[j] - a[j1];
+    x1i = a[j + 1] - a[j1 + 1];
+    x2r = a[j2] + a[j3];
+    x2i = a[j2 + 1] + a[j3 + 1];
+    x3r = a[j2] - a[j3];
+    x3i = a[j2 + 1] - a[j3 + 1];
+    a[j] = x0r + x2r;
+    a[j + 1] = x0i + x2i;
+    a[j2] = x0r - x2r;
+    a[j2 + 1] = x0i - x2i;
+    a[j1] = x1r - x3i;
+    a[j1 + 1] = x1i + x3r;
+    a[j3] = x1r + x3i;
+    a[j3 + 1] = x1i - x3r;
+  }
+}
+
+void OouraFft::bitrv2_128(float* a) const {
+  /*
+      Following things have been attempted but are no faster:
+      (a) Storing the swap indexes in a LUT (index calculations are done
+          for 'free' while waiting on memory/L1).
+      (b) Consolidate the load/store of two consecutive floats by a 64 bit
+          integer (execution is memory/L1 bound).
+      (c) Do a mix of floats and 64 bit integer to maximize register
+          utilization (execution is memory/L1 bound).
+      (d) Replacing ip[i] by ((k<<31)>>25) + ((k >> 1)<<5).
+      (e) Hard-coding of the offsets to completely eliminates index
+          calculations.
+  */
+
+  unsigned int j, j1, k, k1;
+  float xr, xi, yr, yi;
+
+  const int ip[4] = {0, 64, 32, 96};
+  for (k = 0; k < 4; k++) {
+    for (j = 0; j < k; j++) {
+      j1 = 2 * j + ip[k];
+      k1 = 2 * k + ip[j];
+      xr = a[j1 + 0];
+      xi = a[j1 + 1];
+      yr = a[k1 + 0];
+      yi = a[k1 + 1];
+      a[j1 + 0] = yr;
+      a[j1 + 1] = yi;
+      a[k1 + 0] = xr;
+      a[k1 + 1] = xi;
+      j1 += 8;
+      k1 += 16;
+      xr = a[j1 + 0];
+      xi = a[j1 + 1];
+      yr = a[k1 + 0];
+      yi = a[k1 + 1];
+      a[j1 + 0] = yr;
+      a[j1 + 1] = yi;
+      a[k1 + 0] = xr;
+      a[k1 + 1] = xi;
+      j1 += 8;
+      k1 -= 8;
+      xr = a[j1 + 0];
+      xi = a[j1 + 1];
+      yr = a[k1 + 0];
+      yi = a[k1 + 1];
+      a[j1 + 0] = yr;
+      a[j1 + 1] = yi;
+      a[k1 + 0] = xr;
+      a[k1 + 1] = xi;
+      j1 += 8;
+      k1 += 16;
+      xr = a[j1 + 0];
+      xi = a[j1 + 1];
+      yr = a[k1 + 0];
+      yi = a[k1 + 1];
+      a[j1 + 0] = yr;
+      a[j1 + 1] = yi;
+      a[k1 + 0] = xr;
+      a[k1 + 1] = xi;
+    }
+    j1 = 2 * k + 8 + ip[k];
+    k1 = j1 + 8;
+    xr = a[j1 + 0];
+    xi = a[j1 + 1];
+    yr = a[k1 + 0];
+    yi = a[k1 + 1];
+    a[j1 + 0] = yr;
+    a[j1 + 1] = yi;
+    a[k1 + 0] = xr;
+    a[k1 + 1] = xi;
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft.h b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft.h
new file mode 100644
index 0000000..8273dfe
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft.h
@@ -0,0 +1,64 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_UTILITY_OOURA_FFT_H_
+#define MODULES_AUDIO_PROCESSING_UTILITY_OOURA_FFT_H_
+
+#include "rtc_base/system/arch.h"
+
+namespace webrtc {
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+void cft1st_128_SSE2(float* a);
+void cftmdl_128_SSE2(float* a);
+void rftfsub_128_SSE2(float* a);
+void rftbsub_128_SSE2(float* a);
+#endif
+
+#if defined(MIPS_FPU_LE)
+void cft1st_128_mips(float* a);
+void cftmdl_128_mips(float* a);
+void rftfsub_128_mips(float* a);
+void rftbsub_128_mips(float* a);
+#endif
+
+#if defined(WEBRTC_HAS_NEON)
+void cft1st_128_neon(float* a);
+void cftmdl_128_neon(float* a);
+void rftfsub_128_neon(float* a);
+void rftbsub_128_neon(float* a);
+#endif
+
+class OouraFft {
+ public:
+  // Ctor allowing the availability of SSE2 support to be specified.
+  explicit OouraFft(bool sse2_available);
+
+  // Deprecated: This Ctor will soon be removed.
+  OouraFft();
+  ~OouraFft();
+  void Fft(float* a) const;
+  void InverseFft(float* a) const;
+
+ private:
+  void cft1st_128(float* a) const;
+  void cftmdl_128(float* a) const;
+  void rftfsub_128(float* a) const;
+  void rftbsub_128(float* a) const;
+
+  void cftfsub_128(float* a) const;
+  void cftbsub_128(float* a) const;
+  void bitrv2_128(float* a) const;
+  bool use_sse2_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_UTILITY_OOURA_FFT_H_
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft_mips.cc b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft_mips.cc
new file mode 100644
index 0000000..4c231e3
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft_mips.cc
@@ -0,0 +1,1245 @@
+/*
+ *  Copyright (c) 2014 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "common_audio/third_party/ooura/fft_size_128/ooura_fft.h"
+#include "common_audio/third_party/ooura/fft_size_128/ooura_fft_tables_common.h"
+
+namespace webrtc {
+
+#if defined(MIPS_FPU_LE)
+void bitrv2_128_mips(float* a) {
+  // n is 128
+  float xr, xi, yr, yi;
+
+  xr = a[8];
+  xi = a[9];
+  yr = a[16];
+  yi = a[17];
+  a[8] = yr;
+  a[9] = yi;
+  a[16] = xr;
+  a[17] = xi;
+
+  xr = a[64];
+  xi = a[65];
+  yr = a[2];
+  yi = a[3];
+  a[64] = yr;
+  a[65] = yi;
+  a[2] = xr;
+  a[3] = xi;
+
+  xr = a[72];
+  xi = a[73];
+  yr = a[18];
+  yi = a[19];
+  a[72] = yr;
+  a[73] = yi;
+  a[18] = xr;
+  a[19] = xi;
+
+  xr = a[80];
+  xi = a[81];
+  yr = a[10];
+  yi = a[11];
+  a[80] = yr;
+  a[81] = yi;
+  a[10] = xr;
+  a[11] = xi;
+
+  xr = a[88];
+  xi = a[89];
+  yr = a[26];
+  yi = a[27];
+  a[88] = yr;
+  a[89] = yi;
+  a[26] = xr;
+  a[27] = xi;
+
+  xr = a[74];
+  xi = a[75];
+  yr = a[82];
+  yi = a[83];
+  a[74] = yr;
+  a[75] = yi;
+  a[82] = xr;
+  a[83] = xi;
+
+  xr = a[32];
+  xi = a[33];
+  yr = a[4];
+  yi = a[5];
+  a[32] = yr;
+  a[33] = yi;
+  a[4] = xr;
+  a[5] = xi;
+
+  xr = a[40];
+  xi = a[41];
+  yr = a[20];
+  yi = a[21];
+  a[40] = yr;
+  a[41] = yi;
+  a[20] = xr;
+  a[21] = xi;
+
+  xr = a[48];
+  xi = a[49];
+  yr = a[12];
+  yi = a[13];
+  a[48] = yr;
+  a[49] = yi;
+  a[12] = xr;
+  a[13] = xi;
+
+  xr = a[56];
+  xi = a[57];
+  yr = a[28];
+  yi = a[29];
+  a[56] = yr;
+  a[57] = yi;
+  a[28] = xr;
+  a[29] = xi;
+
+  xr = a[34];
+  xi = a[35];
+  yr = a[68];
+  yi = a[69];
+  a[34] = yr;
+  a[35] = yi;
+  a[68] = xr;
+  a[69] = xi;
+
+  xr = a[42];
+  xi = a[43];
+  yr = a[84];
+  yi = a[85];
+  a[42] = yr;
+  a[43] = yi;
+  a[84] = xr;
+  a[85] = xi;
+
+  xr = a[50];
+  xi = a[51];
+  yr = a[76];
+  yi = a[77];
+  a[50] = yr;
+  a[51] = yi;
+  a[76] = xr;
+  a[77] = xi;
+
+  xr = a[58];
+  xi = a[59];
+  yr = a[92];
+  yi = a[93];
+  a[58] = yr;
+  a[59] = yi;
+  a[92] = xr;
+  a[93] = xi;
+
+  xr = a[44];
+  xi = a[45];
+  yr = a[52];
+  yi = a[53];
+  a[44] = yr;
+  a[45] = yi;
+  a[52] = xr;
+  a[53] = xi;
+
+  xr = a[96];
+  xi = a[97];
+  yr = a[6];
+  yi = a[7];
+  a[96] = yr;
+  a[97] = yi;
+  a[6] = xr;
+  a[7] = xi;
+
+  xr = a[104];
+  xi = a[105];
+  yr = a[22];
+  yi = a[23];
+  a[104] = yr;
+  a[105] = yi;
+  a[22] = xr;
+  a[23] = xi;
+
+  xr = a[112];
+  xi = a[113];
+  yr = a[14];
+  yi = a[15];
+  a[112] = yr;
+  a[113] = yi;
+  a[14] = xr;
+  a[15] = xi;
+
+  xr = a[120];
+  xi = a[121];
+  yr = a[30];
+  yi = a[31];
+  a[120] = yr;
+  a[121] = yi;
+  a[30] = xr;
+  a[31] = xi;
+
+  xr = a[98];
+  xi = a[99];
+  yr = a[70];
+  yi = a[71];
+  a[98] = yr;
+  a[99] = yi;
+  a[70] = xr;
+  a[71] = xi;
+
+  xr = a[106];
+  xi = a[107];
+  yr = a[86];
+  yi = a[87];
+  a[106] = yr;
+  a[107] = yi;
+  a[86] = xr;
+  a[87] = xi;
+
+  xr = a[114];
+  xi = a[115];
+  yr = a[78];
+  yi = a[79];
+  a[114] = yr;
+  a[115] = yi;
+  a[78] = xr;
+  a[79] = xi;
+
+  xr = a[122];
+  xi = a[123];
+  yr = a[94];
+  yi = a[95];
+  a[122] = yr;
+  a[123] = yi;
+  a[94] = xr;
+  a[95] = xi;
+
+  xr = a[100];
+  xi = a[101];
+  yr = a[38];
+  yi = a[39];
+  a[100] = yr;
+  a[101] = yi;
+  a[38] = xr;
+  a[39] = xi;
+
+  xr = a[108];
+  xi = a[109];
+  yr = a[54];
+  yi = a[55];
+  a[108] = yr;
+  a[109] = yi;
+  a[54] = xr;
+  a[55] = xi;
+
+  xr = a[116];
+  xi = a[117];
+  yr = a[46];
+  yi = a[47];
+  a[116] = yr;
+  a[117] = yi;
+  a[46] = xr;
+  a[47] = xi;
+
+  xr = a[124];
+  xi = a[125];
+  yr = a[62];
+  yi = a[63];
+  a[124] = yr;
+  a[125] = yi;
+  a[62] = xr;
+  a[63] = xi;
+
+  xr = a[110];
+  xi = a[111];
+  yr = a[118];
+  yi = a[119];
+  a[110] = yr;
+  a[111] = yi;
+  a[118] = xr;
+  a[119] = xi;
+}
+
+void cft1st_128_mips(float* a) {
+  float f0, f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12, f13, f14;
+  int a_ptr, p1_rdft, p2_rdft, count;
+  const float* first = rdft_wk3ri_first;
+  const float* second = rdft_wk3ri_second;
+
+  __asm __volatile(
+      ".set       push                                                    \n\t"
+      ".set       noreorder                                               \n\t"
+      // first 8
+      "lwc1       %[f0],        0(%[a])                                   \n\t"
+      "lwc1       %[f1],        4(%[a])                                   \n\t"
+      "lwc1       %[f2],        8(%[a])                                   \n\t"
+      "lwc1       %[f3],        12(%[a])                                  \n\t"
+      "lwc1       %[f4],        16(%[a])                                  \n\t"
+      "lwc1       %[f5],        20(%[a])                                  \n\t"
+      "lwc1       %[f6],        24(%[a])                                  \n\t"
+      "lwc1       %[f7],        28(%[a])                                  \n\t"
+      "add.s      %[f8],        %[f0],        %[f2]                       \n\t"
+      "sub.s      %[f0],        %[f0],        %[f2]                       \n\t"
+      "add.s      %[f2],        %[f4],        %[f6]                       \n\t"
+      "sub.s      %[f4],        %[f4],        %[f6]                       \n\t"
+      "add.s      %[f6],        %[f1],        %[f3]                       \n\t"
+      "sub.s      %[f1],        %[f1],        %[f3]                       \n\t"
+      "add.s      %[f3],        %[f5],        %[f7]                       \n\t"
+      "sub.s      %[f5],        %[f5],        %[f7]                       \n\t"
+      "add.s      %[f7],        %[f8],        %[f2]                       \n\t"
+      "sub.s      %[f8],        %[f8],        %[f2]                       \n\t"
+      "sub.s      %[f2],        %[f1],        %[f4]                       \n\t"
+      "add.s      %[f1],        %[f1],        %[f4]                       \n\t"
+      "add.s      %[f4],        %[f6],        %[f3]                       \n\t"
+      "sub.s      %[f6],        %[f6],        %[f3]                       \n\t"
+      "sub.s      %[f3],        %[f0],        %[f5]                       \n\t"
+      "add.s      %[f0],        %[f0],        %[f5]                       \n\t"
+      "swc1       %[f7],        0(%[a])                                   \n\t"
+      "swc1       %[f8],        16(%[a])                                  \n\t"
+      "swc1       %[f2],        28(%[a])                                  \n\t"
+      "swc1       %[f1],        12(%[a])                                  \n\t"
+      "swc1       %[f4],        4(%[a])                                   \n\t"
+      "swc1       %[f6],        20(%[a])                                  \n\t"
+      "swc1       %[f3],        8(%[a])                                   \n\t"
+      "swc1       %[f0],        24(%[a])                                  \n\t"
+      // second 8
+      "lwc1       %[f0],        32(%[a])                                  \n\t"
+      "lwc1       %[f1],        36(%[a])                                  \n\t"
+      "lwc1       %[f2],        40(%[a])                                  \n\t"
+      "lwc1       %[f3],        44(%[a])                                  \n\t"
+      "lwc1       %[f4],        48(%[a])                                  \n\t"
+      "lwc1       %[f5],        52(%[a])                                  \n\t"
+      "lwc1       %[f6],        56(%[a])                                  \n\t"
+      "lwc1       %[f7],        60(%[a])                                  \n\t"
+      "add.s      %[f8],        %[f4],        %[f6]                       \n\t"
+      "sub.s      %[f4],        %[f4],        %[f6]                       \n\t"
+      "add.s      %[f6],        %[f1],        %[f3]                       \n\t"
+      "sub.s      %[f1],        %[f1],        %[f3]                       \n\t"
+      "add.s      %[f3],        %[f0],        %[f2]                       \n\t"
+      "sub.s      %[f0],        %[f0],        %[f2]                       \n\t"
+      "add.s      %[f2],        %[f5],        %[f7]                       \n\t"
+      "sub.s      %[f5],        %[f5],        %[f7]                       \n\t"
+      "add.s      %[f7],        %[f4],        %[f1]                       \n\t"
+      "sub.s      %[f4],        %[f4],        %[f1]                       \n\t"
+      "add.s      %[f1],        %[f3],        %[f8]                       \n\t"
+      "sub.s      %[f3],        %[f3],        %[f8]                       \n\t"
+      "sub.s      %[f8],        %[f0],        %[f5]                       \n\t"
+      "add.s      %[f0],        %[f0],        %[f5]                       \n\t"
+      "add.s      %[f5],        %[f6],        %[f2]                       \n\t"
+      "sub.s      %[f6],        %[f2],        %[f6]                       \n\t"
+      "lwc1       %[f9],        8(%[rdft_w])                              \n\t"
+      "sub.s      %[f2],        %[f8],        %[f7]                       \n\t"
+      "add.s      %[f8],        %[f8],        %[f7]                       \n\t"
+      "sub.s      %[f7],        %[f4],        %[f0]                       \n\t"
+      "add.s      %[f4],        %[f4],        %[f0]                       \n\t"
+      // prepare for loop
+      "addiu      %[a_ptr],     %[a],         64                          \n\t"
+      "addiu      %[p1_rdft],   %[rdft_w],    8                           \n\t"
+      "addiu      %[p2_rdft],   %[rdft_w],    16                          \n\t"
+      "addiu      %[count],     $zero,        7                           \n\t"
+      // finish second 8
+      "mul.s      %[f2],        %[f9],        %[f2]                       \n\t"
+      "mul.s      %[f8],        %[f9],        %[f8]                       \n\t"
+      "mul.s      %[f7],        %[f9],        %[f7]                       \n\t"
+      "mul.s      %[f4],        %[f9],        %[f4]                       \n\t"
+      "swc1       %[f1],        32(%[a])                                  \n\t"
+      "swc1       %[f3],        52(%[a])                                  \n\t"
+      "swc1       %[f5],        36(%[a])                                  \n\t"
+      "swc1       %[f6],        48(%[a])                                  \n\t"
+      "swc1       %[f2],        40(%[a])                                  \n\t"
+      "swc1       %[f8],        44(%[a])                                  \n\t"
+      "swc1       %[f7],        56(%[a])                                  \n\t"
+      "swc1       %[f4],        60(%[a])                                  \n\t"
+      // loop
+      "1:                                                                  \n\t"
+      "lwc1       %[f0],        0(%[a_ptr])                               \n\t"
+      "lwc1       %[f1],        4(%[a_ptr])                               \n\t"
+      "lwc1       %[f2],        8(%[a_ptr])                               \n\t"
+      "lwc1       %[f3],        12(%[a_ptr])                              \n\t"
+      "lwc1       %[f4],        16(%[a_ptr])                              \n\t"
+      "lwc1       %[f5],        20(%[a_ptr])                              \n\t"
+      "lwc1       %[f6],        24(%[a_ptr])                              \n\t"
+      "lwc1       %[f7],        28(%[a_ptr])                              \n\t"
+      "add.s      %[f8],        %[f0],        %[f2]                       \n\t"
+      "sub.s      %[f0],        %[f0],        %[f2]                       \n\t"
+      "add.s      %[f2],        %[f4],        %[f6]                       \n\t"
+      "sub.s      %[f4],        %[f4],        %[f6]                       \n\t"
+      "add.s      %[f6],        %[f1],        %[f3]                       \n\t"
+      "sub.s      %[f1],        %[f1],        %[f3]                       \n\t"
+      "add.s      %[f3],        %[f5],        %[f7]                       \n\t"
+      "sub.s      %[f5],        %[f5],        %[f7]                       \n\t"
+      "lwc1       %[f10],       4(%[p1_rdft])                             \n\t"
+      "lwc1       %[f11],       0(%[p2_rdft])                             \n\t"
+      "lwc1       %[f12],       4(%[p2_rdft])                             \n\t"
+      "lwc1       %[f13],       8(%[first])                               \n\t"
+      "lwc1       %[f14],       12(%[first])                              \n\t"
+      "add.s      %[f7],        %[f8],        %[f2]                       \n\t"
+      "sub.s      %[f8],        %[f8],        %[f2]                       \n\t"
+      "add.s      %[f2],        %[f6],        %[f3]                       \n\t"
+      "sub.s      %[f6],        %[f6],        %[f3]                       \n\t"
+      "add.s      %[f3],        %[f0],        %[f5]                       \n\t"
+      "sub.s      %[f0],        %[f0],        %[f5]                       \n\t"
+      "add.s      %[f5],        %[f1],        %[f4]                       \n\t"
+      "sub.s      %[f1],        %[f1],        %[f4]                       \n\t"
+      "swc1       %[f7],        0(%[a_ptr])                               \n\t"
+      "swc1       %[f2],        4(%[a_ptr])                               \n\t"
+      "mul.s      %[f4],        %[f9],        %[f8]                       \n\t"
+#if defined(MIPS32_R2_LE)
+      "mul.s      %[f8],        %[f10],       %[f8]                       \n\t"
+      "mul.s      %[f7],        %[f11],       %[f0]                       \n\t"
+      "mul.s      %[f0],        %[f12],       %[f0]                       \n\t"
+      "mul.s      %[f2],        %[f13],       %[f3]                       \n\t"
+      "mul.s      %[f3],        %[f14],       %[f3]                       \n\t"
+      "nmsub.s    %[f4],        %[f4],        %[f10],       %[f6]         \n\t"
+      "madd.s     %[f8],        %[f8],        %[f9],        %[f6]         \n\t"
+      "nmsub.s    %[f7],        %[f7],        %[f12],       %[f5]         \n\t"
+      "madd.s     %[f0],        %[f0],        %[f11],       %[f5]         \n\t"
+      "nmsub.s    %[f2],        %[f2],        %[f14],       %[f1]         \n\t"
+      "madd.s     %[f3],        %[f3],        %[f13],       %[f1]         \n\t"
+#else
+      "mul.s      %[f7],        %[f10],       %[f6]                       \n\t"
+      "mul.s      %[f6],        %[f9],        %[f6]                       \n\t"
+      "mul.s      %[f8],        %[f10],       %[f8]                       \n\t"
+      "mul.s      %[f2],        %[f11],       %[f0]                       \n\t"
+      "mul.s      %[f11],       %[f11],       %[f5]                       \n\t"
+      "mul.s      %[f5],        %[f12],       %[f5]                       \n\t"
+      "mul.s      %[f0],        %[f12],       %[f0]                       \n\t"
+      "mul.s      %[f12],       %[f13],       %[f3]                       \n\t"
+      "mul.s      %[f13],       %[f13],       %[f1]                       \n\t"
+      "mul.s      %[f1],        %[f14],       %[f1]                       \n\t"
+      "mul.s      %[f3],        %[f14],       %[f3]                       \n\t"
+      "sub.s      %[f4],        %[f4],        %[f7]                       \n\t"
+      "add.s      %[f8],        %[f6],        %[f8]                       \n\t"
+      "sub.s      %[f7],        %[f2],        %[f5]                       \n\t"
+      "add.s      %[f0],        %[f11],       %[f0]                       \n\t"
+      "sub.s      %[f2],        %[f12],       %[f1]                       \n\t"
+      "add.s      %[f3],        %[f13],       %[f3]                       \n\t"
+#endif
+      "swc1       %[f4],        16(%[a_ptr])                              \n\t"
+      "swc1       %[f8],        20(%[a_ptr])                              \n\t"
+      "swc1       %[f7],        8(%[a_ptr])                               \n\t"
+      "swc1       %[f0],        12(%[a_ptr])                              \n\t"
+      "swc1       %[f2],        24(%[a_ptr])                              \n\t"
+      "swc1       %[f3],        28(%[a_ptr])                              \n\t"
+      "lwc1       %[f0],        32(%[a_ptr])                              \n\t"
+      "lwc1       %[f1],        36(%[a_ptr])                              \n\t"
+      "lwc1       %[f2],        40(%[a_ptr])                              \n\t"
+      "lwc1       %[f3],        44(%[a_ptr])                              \n\t"
+      "lwc1       %[f4],        48(%[a_ptr])                              \n\t"
+      "lwc1       %[f5],        52(%[a_ptr])                              \n\t"
+      "lwc1       %[f6],        56(%[a_ptr])                              \n\t"
+      "lwc1       %[f7],        60(%[a_ptr])                              \n\t"
+      "add.s      %[f8],        %[f0],        %[f2]                       \n\t"
+      "sub.s      %[f0],        %[f0],        %[f2]                       \n\t"
+      "add.s      %[f2],        %[f4],        %[f6]                       \n\t"
+      "sub.s      %[f4],        %[f4],        %[f6]                       \n\t"
+      "add.s      %[f6],        %[f1],        %[f3]                       \n\t"
+      "sub.s      %[f1],        %[f1],        %[f3]                       \n\t"
+      "add.s      %[f3],        %[f5],        %[f7]                       \n\t"
+      "sub.s      %[f5],        %[f5],        %[f7]                       \n\t"
+      "lwc1       %[f11],       8(%[p2_rdft])                             \n\t"
+      "lwc1       %[f12],       12(%[p2_rdft])                            \n\t"
+      "lwc1       %[f13],       8(%[second])                              \n\t"
+      "lwc1       %[f14],       12(%[second])                             \n\t"
+      "add.s      %[f7],        %[f8],        %[f2]                       \n\t"
+      "sub.s      %[f8],        %[f2],        %[f8]                       \n\t"
+      "add.s      %[f2],        %[f6],        %[f3]                       \n\t"
+      "sub.s      %[f6],        %[f3],        %[f6]                       \n\t"
+      "add.s      %[f3],        %[f0],        %[f5]                       \n\t"
+      "sub.s      %[f0],        %[f0],        %[f5]                       \n\t"
+      "add.s      %[f5],        %[f1],        %[f4]                       \n\t"
+      "sub.s      %[f1],        %[f1],        %[f4]                       \n\t"
+      "swc1       %[f7],        32(%[a_ptr])                              \n\t"
+      "swc1       %[f2],        36(%[a_ptr])                              \n\t"
+      "mul.s      %[f4],        %[f10],       %[f8]                       \n\t"
+#if defined(MIPS32_R2_LE)
+      "mul.s      %[f10],       %[f10],       %[f6]                       \n\t"
+      "mul.s      %[f7],        %[f11],       %[f0]                       \n\t"
+      "mul.s      %[f11],       %[f11],       %[f5]                       \n\t"
+      "mul.s      %[f2],        %[f13],       %[f3]                       \n\t"
+      "mul.s      %[f13],       %[f13],       %[f1]                       \n\t"
+      "madd.s     %[f4],        %[f4],        %[f9],        %[f6]         \n\t"
+      "nmsub.s    %[f10],       %[f10],       %[f9],        %[f8]         \n\t"
+      "nmsub.s    %[f7],        %[f7],        %[f12],       %[f5]         \n\t"
+      "madd.s     %[f11],       %[f11],       %[f12],       %[f0]         \n\t"
+      "nmsub.s    %[f2],        %[f2],        %[f14],       %[f1]         \n\t"
+      "madd.s     %[f13],       %[f13],       %[f14],       %[f3]         \n\t"
+#else
+      "mul.s      %[f2],        %[f9],        %[f6]                       \n\t"
+      "mul.s      %[f10],       %[f10],       %[f6]                       \n\t"
+      "mul.s      %[f9],        %[f9],        %[f8]                       \n\t"
+      "mul.s      %[f7],        %[f11],       %[f0]                       \n\t"
+      "mul.s      %[f8],        %[f12],       %[f5]                       \n\t"
+      "mul.s      %[f11],       %[f11],       %[f5]                       \n\t"
+      "mul.s      %[f12],       %[f12],       %[f0]                       \n\t"
+      "mul.s      %[f5],        %[f13],       %[f3]                       \n\t"
+      "mul.s      %[f0],        %[f14],       %[f1]                       \n\t"
+      "mul.s      %[f13],       %[f13],       %[f1]                       \n\t"
+      "mul.s      %[f14],       %[f14],       %[f3]                       \n\t"
+      "add.s      %[f4],        %[f4],        %[f2]                       \n\t"
+      "sub.s      %[f10],       %[f10],       %[f9]                       \n\t"
+      "sub.s      %[f7],        %[f7],        %[f8]                       \n\t"
+      "add.s      %[f11],       %[f11],       %[f12]                      \n\t"
+      "sub.s      %[f2],        %[f5],        %[f0]                       \n\t"
+      "add.s      %[f13],       %[f13],       %[f14]                      \n\t"
+#endif
+      "swc1       %[f4],        48(%[a_ptr])                              \n\t"
+      "swc1       %[f10],       52(%[a_ptr])                              \n\t"
+      "swc1       %[f7],        40(%[a_ptr])                              \n\t"
+      "swc1       %[f11],       44(%[a_ptr])                              \n\t"
+      "swc1       %[f2],        56(%[a_ptr])                              \n\t"
+      "swc1       %[f13],       60(%[a_ptr])                              \n\t"
+      "addiu      %[count],     %[count],     -1                          \n\t"
+      "lwc1       %[f9],        8(%[p1_rdft])                             \n\t"
+      "addiu      %[a_ptr],     %[a_ptr],     64                          \n\t"
+      "addiu      %[p1_rdft],   %[p1_rdft],   8                           \n\t"
+      "addiu      %[p2_rdft],   %[p2_rdft],   16                          \n\t"
+      "addiu      %[first],     %[first],     8                           \n\t"
+      "bgtz       %[count],     1b                                        \n\t"
+      " addiu     %[second],    %[second],    8                           \n\t"
+      ".set       pop                                                     \n\t"
+      : [f0] "=&f"(f0), [f1] "=&f"(f1), [f2] "=&f"(f2), [f3] "=&f"(f3),
+        [f4] "=&f"(f4), [f5] "=&f"(f5), [f6] "=&f"(f6), [f7] "=&f"(f7),
+        [f8] "=&f"(f8), [f9] "=&f"(f9), [f10] "=&f"(f10), [f11] "=&f"(f11),
+        [f12] "=&f"(f12), [f13] "=&f"(f13), [f14] "=&f"(f14),
+        [a_ptr] "=&r"(a_ptr), [p1_rdft] "=&r"(p1_rdft), [first] "+r"(first),
+        [p2_rdft] "=&r"(p2_rdft), [count] "=&r"(count), [second] "+r"(second)
+      : [a] "r"(a), [rdft_w] "r"(rdft_w)
+      : "memory");
+}
+
+void cftmdl_128_mips(float* a) {
+  float f0, f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12, f13, f14;
+  int tmp_a, count;
+  __asm __volatile(
+      ".set       push                                      \n\t"
+      ".set       noreorder                                 \n\t"
+      "addiu      %[tmp_a],   %[a],         0               \n\t"
+      "addiu      %[count],   $zero,        4               \n\t"
+      "1:                                                    \n\t"
+      "addiu      %[count],   %[count],     -1              \n\t"
+      "lwc1       %[f0],      0(%[tmp_a])                   \n\t"
+      "lwc1       %[f2],      32(%[tmp_a])                  \n\t"
+      "lwc1       %[f4],      64(%[tmp_a])                  \n\t"
+      "lwc1       %[f6],      96(%[tmp_a])                  \n\t"
+      "lwc1       %[f1],      4(%[tmp_a])                   \n\t"
+      "lwc1       %[f3],      36(%[tmp_a])                  \n\t"
+      "lwc1       %[f5],      68(%[tmp_a])                  \n\t"
+      "lwc1       %[f7],      100(%[tmp_a])                 \n\t"
+      "add.s      %[f8],      %[f0],        %[f2]           \n\t"
+      "sub.s      %[f0],      %[f0],        %[f2]           \n\t"
+      "add.s      %[f2],      %[f4],        %[f6]           \n\t"
+      "sub.s      %[f4],      %[f4],        %[f6]           \n\t"
+      "add.s      %[f6],      %[f1],        %[f3]           \n\t"
+      "sub.s      %[f1],      %[f1],        %[f3]           \n\t"
+      "add.s      %[f3],      %[f5],        %[f7]           \n\t"
+      "sub.s      %[f5],      %[f5],        %[f7]           \n\t"
+      "add.s      %[f7],      %[f8],        %[f2]           \n\t"
+      "sub.s      %[f8],      %[f8],        %[f2]           \n\t"
+      "add.s      %[f2],      %[f1],        %[f4]           \n\t"
+      "sub.s      %[f1],      %[f1],        %[f4]           \n\t"
+      "add.s      %[f4],      %[f6],        %[f3]           \n\t"
+      "sub.s      %[f6],      %[f6],        %[f3]           \n\t"
+      "sub.s      %[f3],      %[f0],        %[f5]           \n\t"
+      "add.s      %[f0],      %[f0],        %[f5]           \n\t"
+      "swc1       %[f7],      0(%[tmp_a])                   \n\t"
+      "swc1       %[f8],      64(%[tmp_a])                  \n\t"
+      "swc1       %[f2],      36(%[tmp_a])                  \n\t"
+      "swc1       %[f1],      100(%[tmp_a])                 \n\t"
+      "swc1       %[f4],      4(%[tmp_a])                   \n\t"
+      "swc1       %[f6],      68(%[tmp_a])                  \n\t"
+      "swc1       %[f3],      32(%[tmp_a])                  \n\t"
+      "swc1       %[f0],      96(%[tmp_a])                  \n\t"
+      "bgtz       %[count],   1b                            \n\t"
+      " addiu     %[tmp_a],   %[tmp_a],     8               \n\t"
+      ".set       pop                                       \n\t"
+      : [f0] "=&f"(f0), [f1] "=&f"(f1), [f2] "=&f"(f2), [f3] "=&f"(f3),
+        [f4] "=&f"(f4), [f5] "=&f"(f5), [f6] "=&f"(f6), [f7] "=&f"(f7),
+        [f8] "=&f"(f8), [tmp_a] "=&r"(tmp_a), [count] "=&r"(count)
+      : [a] "r"(a)
+      : "memory");
+  f9 = rdft_w[2];
+  __asm __volatile(
+      ".set       push                                      \n\t"
+      ".set       noreorder                                 \n\t"
+      "addiu      %[tmp_a],   %[a],         128             \n\t"
+      "addiu      %[count],   $zero,        4               \n\t"
+      "1:                                                    \n\t"
+      "addiu      %[count],   %[count],     -1              \n\t"
+      "lwc1       %[f0],      0(%[tmp_a])                   \n\t"
+      "lwc1       %[f2],      32(%[tmp_a])                  \n\t"
+      "lwc1       %[f5],      68(%[tmp_a])                  \n\t"
+      "lwc1       %[f7],      100(%[tmp_a])                 \n\t"
+      "lwc1       %[f1],      4(%[tmp_a])                   \n\t"
+      "lwc1       %[f3],      36(%[tmp_a])                  \n\t"
+      "lwc1       %[f4],      64(%[tmp_a])                  \n\t"
+      "lwc1       %[f6],      96(%[tmp_a])                  \n\t"
+      "sub.s      %[f8],      %[f0],        %[f2]           \n\t"
+      "add.s      %[f0],      %[f0],        %[f2]           \n\t"
+      "sub.s      %[f2],      %[f5],        %[f7]           \n\t"
+      "add.s      %[f5],      %[f5],        %[f7]           \n\t"
+      "sub.s      %[f7],      %[f1],        %[f3]           \n\t"
+      "add.s      %[f1],      %[f1],        %[f3]           \n\t"
+      "sub.s      %[f3],      %[f4],        %[f6]           \n\t"
+      "add.s      %[f4],      %[f4],        %[f6]           \n\t"
+      "sub.s      %[f6],      %[f8],        %[f2]           \n\t"
+      "add.s      %[f8],      %[f8],        %[f2]           \n\t"
+      "add.s      %[f2],      %[f5],        %[f1]           \n\t"
+      "sub.s      %[f5],      %[f5],        %[f1]           \n\t"
+      "add.s      %[f1],      %[f3],        %[f7]           \n\t"
+      "sub.s      %[f3],      %[f3],        %[f7]           \n\t"
+      "add.s      %[f7],      %[f0],        %[f4]           \n\t"
+      "sub.s      %[f0],      %[f0],        %[f4]           \n\t"
+      "sub.s      %[f4],      %[f6],        %[f1]           \n\t"
+      "add.s      %[f6],      %[f6],        %[f1]           \n\t"
+      "sub.s      %[f1],      %[f3],        %[f8]           \n\t"
+      "add.s      %[f3],      %[f3],        %[f8]           \n\t"
+      "mul.s      %[f4],      %[f4],        %[f9]           \n\t"
+      "mul.s      %[f6],      %[f6],        %[f9]           \n\t"
+      "mul.s      %[f1],      %[f1],        %[f9]           \n\t"
+      "mul.s      %[f3],      %[f3],        %[f9]           \n\t"
+      "swc1       %[f7],      0(%[tmp_a])                   \n\t"
+      "swc1       %[f2],      4(%[tmp_a])                   \n\t"
+      "swc1       %[f5],      64(%[tmp_a])                  \n\t"
+      "swc1       %[f0],      68(%[tmp_a])                  \n\t"
+      "swc1       %[f4],      32(%[tmp_a])                  \n\t"
+      "swc1       %[f6],      36(%[tmp_a])                  \n\t"
+      "swc1       %[f1],      96(%[tmp_a])                  \n\t"
+      "swc1       %[f3],      100(%[tmp_a])                 \n\t"
+      "bgtz       %[count],   1b                            \n\t"
+      " addiu     %[tmp_a],   %[tmp_a],     8               \n\t"
+      ".set       pop                                       \n\t"
+      : [f0] "=&f"(f0), [f1] "=&f"(f1), [f2] "=&f"(f2), [f3] "=&f"(f3),
+        [f4] "=&f"(f4), [f5] "=&f"(f5), [f6] "=&f"(f6), [f7] "=&f"(f7),
+        [f8] "=&f"(f8), [tmp_a] "=&r"(tmp_a), [count] "=&r"(count)
+      : [a] "r"(a), [f9] "f"(f9)
+      : "memory");
+  f10 = rdft_w[3];
+  f11 = rdft_w[4];
+  f12 = rdft_w[5];
+  f13 = rdft_wk3ri_first[2];
+  f14 = rdft_wk3ri_first[3];
+
+  __asm __volatile(
+      ".set       push                                                    \n\t"
+      ".set       noreorder                                               \n\t"
+      "addiu      %[tmp_a],     %[a],         256                         \n\t"
+      "addiu      %[count],     $zero,        4                           \n\t"
+      "1:                                                                  \n\t"
+      "addiu      %[count],     %[count],     -1                          \n\t"
+      "lwc1       %[f0],        0(%[tmp_a])                               \n\t"
+      "lwc1       %[f2],        32(%[tmp_a])                              \n\t"
+      "lwc1       %[f4],        64(%[tmp_a])                              \n\t"
+      "lwc1       %[f6],        96(%[tmp_a])                              \n\t"
+      "lwc1       %[f1],        4(%[tmp_a])                               \n\t"
+      "lwc1       %[f3],        36(%[tmp_a])                              \n\t"
+      "lwc1       %[f5],        68(%[tmp_a])                              \n\t"
+      "lwc1       %[f7],        100(%[tmp_a])                             \n\t"
+      "add.s      %[f8],        %[f0],        %[f2]                       \n\t"
+      "sub.s      %[f0],        %[f0],        %[f2]                       \n\t"
+      "add.s      %[f2],        %[f4],        %[f6]                       \n\t"
+      "sub.s      %[f4],        %[f4],        %[f6]                       \n\t"
+      "add.s      %[f6],        %[f1],        %[f3]                       \n\t"
+      "sub.s      %[f1],        %[f1],        %[f3]                       \n\t"
+      "add.s      %[f3],        %[f5],        %[f7]                       \n\t"
+      "sub.s      %[f5],        %[f5],        %[f7]                       \n\t"
+      "sub.s      %[f7],        %[f8],        %[f2]                       \n\t"
+      "add.s      %[f8],        %[f8],        %[f2]                       \n\t"
+      "add.s      %[f2],        %[f1],        %[f4]                       \n\t"
+      "sub.s      %[f1],        %[f1],        %[f4]                       \n\t"
+      "sub.s      %[f4],        %[f6],        %[f3]                       \n\t"
+      "add.s      %[f6],        %[f6],        %[f3]                       \n\t"
+      "sub.s      %[f3],        %[f0],        %[f5]                       \n\t"
+      "add.s      %[f0],        %[f0],        %[f5]                       \n\t"
+      "swc1       %[f8],        0(%[tmp_a])                               \n\t"
+      "swc1       %[f6],        4(%[tmp_a])                               \n\t"
+      "mul.s      %[f5],        %[f9],        %[f7]                       \n\t"
+#if defined(MIPS32_R2_LE)
+      "mul.s      %[f7],        %[f10],       %[f7]                       \n\t"
+      "mul.s      %[f8],        %[f11],       %[f3]                       \n\t"
+      "mul.s      %[f3],        %[f12],       %[f3]                       \n\t"
+      "mul.s      %[f6],        %[f13],       %[f0]                       \n\t"
+      "mul.s      %[f0],        %[f14],       %[f0]                       \n\t"
+      "nmsub.s    %[f5],        %[f5],        %[f10],       %[f4]         \n\t"
+      "madd.s     %[f7],        %[f7],        %[f9],        %[f4]         \n\t"
+      "nmsub.s    %[f8],        %[f8],        %[f12],       %[f2]         \n\t"
+      "madd.s     %[f3],        %[f3],        %[f11],       %[f2]         \n\t"
+      "nmsub.s    %[f6],        %[f6],        %[f14],       %[f1]         \n\t"
+      "madd.s     %[f0],        %[f0],        %[f13],       %[f1]         \n\t"
+      "swc1       %[f5],        64(%[tmp_a])                              \n\t"
+      "swc1       %[f7],        68(%[tmp_a])                              \n\t"
+#else
+      "mul.s      %[f8],        %[f10],       %[f4]                       \n\t"
+      "mul.s      %[f4],        %[f9],        %[f4]                       \n\t"
+      "mul.s      %[f7],        %[f10],       %[f7]                       \n\t"
+      "mul.s      %[f6],        %[f11],       %[f3]                       \n\t"
+      "mul.s      %[f3],        %[f12],       %[f3]                       \n\t"
+      "sub.s      %[f5],        %[f5],        %[f8]                       \n\t"
+      "mul.s      %[f8],        %[f12],       %[f2]                       \n\t"
+      "mul.s      %[f2],        %[f11],       %[f2]                       \n\t"
+      "add.s      %[f7],        %[f4],        %[f7]                       \n\t"
+      "mul.s      %[f4],        %[f13],       %[f0]                       \n\t"
+      "mul.s      %[f0],        %[f14],       %[f0]                       \n\t"
+      "sub.s      %[f8],        %[f6],        %[f8]                       \n\t"
+      "mul.s      %[f6],        %[f14],       %[f1]                       \n\t"
+      "mul.s      %[f1],        %[f13],       %[f1]                       \n\t"
+      "add.s      %[f3],        %[f2],        %[f3]                       \n\t"
+      "swc1       %[f5],        64(%[tmp_a])                              \n\t"
+      "swc1       %[f7],        68(%[tmp_a])                              \n\t"
+      "sub.s      %[f6],        %[f4],        %[f6]                       \n\t"
+      "add.s      %[f0],        %[f1],        %[f0]                       \n\t"
+#endif
+      "swc1       %[f8],        32(%[tmp_a])                              \n\t"
+      "swc1       %[f3],        36(%[tmp_a])                              \n\t"
+      "swc1       %[f6],        96(%[tmp_a])                              \n\t"
+      "swc1       %[f0],        100(%[tmp_a])                             \n\t"
+      "bgtz       %[count],     1b                                        \n\t"
+      " addiu     %[tmp_a],     %[tmp_a],     8                           \n\t"
+      ".set       pop                                                     \n\t"
+      : [f0] "=&f"(f0), [f1] "=&f"(f1), [f2] "=&f"(f2), [f3] "=&f"(f3),
+        [f4] "=&f"(f4), [f5] "=&f"(f5), [f6] "=&f"(f6), [f7] "=&f"(f7),
+        [f8] "=&f"(f8), [tmp_a] "=&r"(tmp_a), [count] "=&r"(count)
+      : [a] "r"(a), [f9] "f"(f9), [f10] "f"(f10), [f11] "f"(f11),
+        [f12] "f"(f12), [f13] "f"(f13), [f14] "f"(f14)
+      : "memory");
+  f11 = rdft_w[6];
+  f12 = rdft_w[7];
+  f13 = rdft_wk3ri_second[2];
+  f14 = rdft_wk3ri_second[3];
+  __asm __volatile(
+      ".set       push                                                       "
+      "\n\t"
+      ".set       noreorder                                                  "
+      "\n\t"
+      "addiu      %[tmp_a],       %[a],           384                        "
+      "\n\t"
+      "addiu      %[count],       $zero,          4                          "
+      "\n\t"
+      "1:                                                                     "
+      "\n\t"
+      "addiu      %[count],       %[count],       -1                         "
+      "\n\t"
+      "lwc1       %[f0],          0(%[tmp_a])                                "
+      "\n\t"
+      "lwc1       %[f1],          4(%[tmp_a])                                "
+      "\n\t"
+      "lwc1       %[f2],          32(%[tmp_a])                               "
+      "\n\t"
+      "lwc1       %[f3],          36(%[tmp_a])                               "
+      "\n\t"
+      "lwc1       %[f4],          64(%[tmp_a])                               "
+      "\n\t"
+      "lwc1       %[f5],          68(%[tmp_a])                               "
+      "\n\t"
+      "lwc1       %[f6],          96(%[tmp_a])                               "
+      "\n\t"
+      "lwc1       %[f7],          100(%[tmp_a])                              "
+      "\n\t"
+      "add.s      %[f8],          %[f0],          %[f2]                      "
+      "\n\t"
+      "sub.s      %[f0],          %[f0],          %[f2]                      "
+      "\n\t"
+      "add.s      %[f2],          %[f4],          %[f6]                      "
+      "\n\t"
+      "sub.s      %[f4],          %[f4],          %[f6]                      "
+      "\n\t"
+      "add.s      %[f6],          %[f1],          %[f3]                      "
+      "\n\t"
+      "sub.s      %[f1],          %[f1],          %[f3]                      "
+      "\n\t"
+      "add.s      %[f3],          %[f5],          %[f7]                      "
+      "\n\t"
+      "sub.s      %[f5],          %[f5],          %[f7]                      "
+      "\n\t"
+      "sub.s      %[f7],          %[f2],          %[f8]                      "
+      "\n\t"
+      "add.s      %[f2],          %[f2],          %[f8]                      "
+      "\n\t"
+      "add.s      %[f8],          %[f1],          %[f4]                      "
+      "\n\t"
+      "sub.s      %[f1],          %[f1],          %[f4]                      "
+      "\n\t"
+      "sub.s      %[f4],          %[f3],          %[f6]                      "
+      "\n\t"
+      "add.s      %[f3],          %[f3],          %[f6]                      "
+      "\n\t"
+      "sub.s      %[f6],          %[f0],          %[f5]                      "
+      "\n\t"
+      "add.s      %[f0],          %[f0],          %[f5]                      "
+      "\n\t"
+      "swc1       %[f2],          0(%[tmp_a])                                "
+      "\n\t"
+      "swc1       %[f3],          4(%[tmp_a])                                "
+      "\n\t"
+      "mul.s      %[f5],          %[f10],         %[f7]                      "
+      "\n\t"
+#if defined(MIPS32_R2_LE)
+      "mul.s      %[f7],          %[f9],          %[f7]                      "
+      "\n\t"
+      "mul.s      %[f2],          %[f12],         %[f8]                      "
+      "\n\t"
+      "mul.s      %[f8],          %[f11],         %[f8]                      "
+      "\n\t"
+      "mul.s      %[f3],          %[f14],         %[f1]                      "
+      "\n\t"
+      "mul.s      %[f1],          %[f13],         %[f1]                      "
+      "\n\t"
+      "madd.s     %[f5],          %[f5],          %[f9],       %[f4]         "
+      "\n\t"
+      "msub.s     %[f7],          %[f7],          %[f10],      %[f4]         "
+      "\n\t"
+      "msub.s     %[f2],          %[f2],          %[f11],      %[f6]         "
+      "\n\t"
+      "madd.s     %[f8],          %[f8],          %[f12],      %[f6]         "
+      "\n\t"
+      "msub.s     %[f3],          %[f3],          %[f13],      %[f0]         "
+      "\n\t"
+      "madd.s     %[f1],          %[f1],          %[f14],      %[f0]         "
+      "\n\t"
+      "swc1       %[f5],          64(%[tmp_a])                               "
+      "\n\t"
+      "swc1       %[f7],          68(%[tmp_a])                               "
+      "\n\t"
+#else
+      "mul.s      %[f2],          %[f9],          %[f4]                      "
+      "\n\t"
+      "mul.s      %[f4],          %[f10],         %[f4]                      "
+      "\n\t"
+      "mul.s      %[f7],          %[f9],          %[f7]                      "
+      "\n\t"
+      "mul.s      %[f3],          %[f11],         %[f6]                      "
+      "\n\t"
+      "mul.s      %[f6],          %[f12],         %[f6]                      "
+      "\n\t"
+      "add.s      %[f5],          %[f5],          %[f2]                      "
+      "\n\t"
+      "sub.s      %[f7],          %[f4],          %[f7]                      "
+      "\n\t"
+      "mul.s      %[f2],          %[f12],         %[f8]                      "
+      "\n\t"
+      "mul.s      %[f8],          %[f11],         %[f8]                      "
+      "\n\t"
+      "mul.s      %[f4],          %[f14],         %[f1]                      "
+      "\n\t"
+      "mul.s      %[f1],          %[f13],         %[f1]                      "
+      "\n\t"
+      "sub.s      %[f2],          %[f3],          %[f2]                      "
+      "\n\t"
+      "mul.s      %[f3],          %[f13],         %[f0]                      "
+      "\n\t"
+      "mul.s      %[f0],          %[f14],         %[f0]                      "
+      "\n\t"
+      "add.s      %[f8],          %[f8],          %[f6]                      "
+      "\n\t"
+      "swc1       %[f5],          64(%[tmp_a])                               "
+      "\n\t"
+      "swc1       %[f7],          68(%[tmp_a])                               "
+      "\n\t"
+      "sub.s      %[f3],          %[f3],          %[f4]                      "
+      "\n\t"
+      "add.s      %[f1],          %[f1],          %[f0]                      "
+      "\n\t"
+#endif
+      "swc1       %[f2],          32(%[tmp_a])                               "
+      "\n\t"
+      "swc1       %[f8],          36(%[tmp_a])                               "
+      "\n\t"
+      "swc1       %[f3],          96(%[tmp_a])                               "
+      "\n\t"
+      "swc1       %[f1],          100(%[tmp_a])                              "
+      "\n\t"
+      "bgtz       %[count],       1b                                         "
+      "\n\t"
+      " addiu     %[tmp_a],       %[tmp_a],       8                          "
+      "\n\t"
+      ".set       pop                                                        "
+      "\n\t"
+      : [f0] "=&f"(f0), [f1] "=&f"(f1), [f2] "=&f"(f2), [f3] "=&f"(f3),
+        [f4] "=&f"(f4), [f5] "=&f"(f5), [f6] "=&f"(f6), [f7] "=&f"(f7),
+        [f8] "=&f"(f8), [tmp_a] "=&r"(tmp_a), [count] "=&r"(count)
+      : [a] "r"(a), [f9] "f"(f9), [f10] "f"(f10), [f11] "f"(f11),
+        [f12] "f"(f12), [f13] "f"(f13), [f14] "f"(f14)
+      : "memory");
+}
+
+void cftfsub_128_mips(float* a) {
+  float f0, f1, f2, f3, f4, f5, f6, f7, f8;
+  int tmp_a, count;
+
+  cft1st_128_mips(a);
+  cftmdl_128_mips(a);
+
+  __asm __volatile(
+      ".set       push                                      \n\t"
+      ".set       noreorder                                 \n\t"
+      "addiu      %[tmp_a],       %[a],         0           \n\t"
+      "addiu      %[count],       $zero,        16          \n\t"
+      "1:                                                    \n\t"
+      "addiu      %[count],       %[count],     -1          \n\t"
+      "lwc1       %[f0],          0(%[tmp_a])               \n\t"
+      "lwc1       %[f2],          128(%[tmp_a])             \n\t"
+      "lwc1       %[f4],          256(%[tmp_a])             \n\t"
+      "lwc1       %[f6],          384(%[tmp_a])             \n\t"
+      "lwc1       %[f1],          4(%[tmp_a])               \n\t"
+      "lwc1       %[f3],          132(%[tmp_a])             \n\t"
+      "lwc1       %[f5],          260(%[tmp_a])             \n\t"
+      "lwc1       %[f7],          388(%[tmp_a])             \n\t"
+      "add.s      %[f8],          %[f0],        %[f2]       \n\t"
+      "sub.s      %[f0],          %[f0],        %[f2]       \n\t"
+      "add.s      %[f2],          %[f4],        %[f6]       \n\t"
+      "sub.s      %[f4],          %[f4],        %[f6]       \n\t"
+      "add.s      %[f6],          %[f1],        %[f3]       \n\t"
+      "sub.s      %[f1],          %[f1],        %[f3]       \n\t"
+      "add.s      %[f3],          %[f5],        %[f7]       \n\t"
+      "sub.s      %[f5],          %[f5],        %[f7]       \n\t"
+      "add.s      %[f7],          %[f8],        %[f2]       \n\t"
+      "sub.s      %[f8],          %[f8],        %[f2]       \n\t"
+      "add.s      %[f2],          %[f1],        %[f4]       \n\t"
+      "sub.s      %[f1],          %[f1],        %[f4]       \n\t"
+      "add.s      %[f4],          %[f6],        %[f3]       \n\t"
+      "sub.s      %[f6],          %[f6],        %[f3]       \n\t"
+      "sub.s      %[f3],          %[f0],        %[f5]       \n\t"
+      "add.s      %[f0],          %[f0],        %[f5]       \n\t"
+      "swc1       %[f7],          0(%[tmp_a])               \n\t"
+      "swc1       %[f8],          256(%[tmp_a])             \n\t"
+      "swc1       %[f2],          132(%[tmp_a])             \n\t"
+      "swc1       %[f1],          388(%[tmp_a])             \n\t"
+      "swc1       %[f4],          4(%[tmp_a])               \n\t"
+      "swc1       %[f6],          260(%[tmp_a])             \n\t"
+      "swc1       %[f3],          128(%[tmp_a])             \n\t"
+      "swc1       %[f0],          384(%[tmp_a])             \n\t"
+      "bgtz       %[count],       1b                        \n\t"
+      " addiu     %[tmp_a],       %[tmp_a],   8             \n\t"
+      ".set       pop                                       \n\t"
+      : [f0] "=&f"(f0), [f1] "=&f"(f1), [f2] "=&f"(f2), [f3] "=&f"(f3),
+        [f4] "=&f"(f4), [f5] "=&f"(f5), [f6] "=&f"(f6), [f7] "=&f"(f7),
+        [f8] "=&f"(f8), [tmp_a] "=&r"(tmp_a), [count] "=&r"(count)
+      : [a] "r"(a)
+      : "memory");
+}
+
+void cftbsub_128_mips(float* a) {
+  float f0, f1, f2, f3, f4, f5, f6, f7, f8;
+  int tmp_a, count;
+
+  cft1st_128_mips(a);
+  cftmdl_128_mips(a);
+
+  __asm __volatile(
+      ".set       push                                        \n\t"
+      ".set       noreorder                                   \n\t"
+      "addiu      %[tmp_a],   %[a],           0               \n\t"
+      "addiu      %[count],   $zero,          16              \n\t"
+      "1:                                                      \n\t"
+      "addiu      %[count],   %[count],       -1              \n\t"
+      "lwc1       %[f0],      0(%[tmp_a])                     \n\t"
+      "lwc1       %[f2],      128(%[tmp_a])                   \n\t"
+      "lwc1       %[f4],      256(%[tmp_a])                   \n\t"
+      "lwc1       %[f6],      384(%[tmp_a])                   \n\t"
+      "lwc1       %[f1],      4(%[tmp_a])                     \n\t"
+      "lwc1       %[f3],      132(%[tmp_a])                   \n\t"
+      "lwc1       %[f5],      260(%[tmp_a])                   \n\t"
+      "lwc1       %[f7],      388(%[tmp_a])                   \n\t"
+      "add.s      %[f8],      %[f0],          %[f2]           \n\t"
+      "sub.s      %[f0],      %[f0],          %[f2]           \n\t"
+      "add.s      %[f2],      %[f4],          %[f6]           \n\t"
+      "sub.s      %[f4],      %[f4],          %[f6]           \n\t"
+      "add.s      %[f6],      %[f1],          %[f3]           \n\t"
+      "sub.s      %[f1],      %[f3],          %[f1]           \n\t"
+      "add.s      %[f3],      %[f5],          %[f7]           \n\t"
+      "sub.s      %[f5],      %[f5],          %[f7]           \n\t"
+      "add.s      %[f7],      %[f8],          %[f2]           \n\t"
+      "sub.s      %[f8],      %[f8],          %[f2]           \n\t"
+      "sub.s      %[f2],      %[f1],          %[f4]           \n\t"
+      "add.s      %[f1],      %[f1],          %[f4]           \n\t"
+      "add.s      %[f4],      %[f3],          %[f6]           \n\t"
+      "sub.s      %[f6],      %[f3],          %[f6]           \n\t"
+      "sub.s      %[f3],      %[f0],          %[f5]           \n\t"
+      "add.s      %[f0],      %[f0],          %[f5]           \n\t"
+      "neg.s      %[f4],      %[f4]                           \n\t"
+      "swc1       %[f7],      0(%[tmp_a])                     \n\t"
+      "swc1       %[f8],      256(%[tmp_a])                   \n\t"
+      "swc1       %[f2],      132(%[tmp_a])                   \n\t"
+      "swc1       %[f1],      388(%[tmp_a])                   \n\t"
+      "swc1       %[f6],      260(%[tmp_a])                   \n\t"
+      "swc1       %[f3],      128(%[tmp_a])                   \n\t"
+      "swc1       %[f0],      384(%[tmp_a])                   \n\t"
+      "swc1       %[f4],       4(%[tmp_a])                     \n\t"
+      "bgtz       %[count],   1b                              \n\t"
+      " addiu     %[tmp_a],   %[tmp_a],       8               \n\t"
+      ".set       pop                                         \n\t"
+      : [f0] "=&f"(f0), [f1] "=&f"(f1), [f2] "=&f"(f2), [f3] "=&f"(f3),
+        [f4] "=&f"(f4), [f5] "=&f"(f5), [f6] "=&f"(f6), [f7] "=&f"(f7),
+        [f8] "=&f"(f8), [tmp_a] "=&r"(tmp_a), [count] "=&r"(count)
+      : [a] "r"(a)
+      : "memory");
+}
+
+void rftfsub_128_mips(float* a) {
+  const float* c = rdft_w + 32;
+  const float f0 = 0.5f;
+  float* a1 = &a[2];
+  float* a2 = &a[126];
+  const float* c1 = &c[1];
+  const float* c2 = &c[31];
+  float f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12, f13, f14, f15;
+  int count;
+
+  __asm __volatile(
+      ".set      push                                             \n\t"
+      ".set      noreorder                                        \n\t"
+      "lwc1      %[f6],       0(%[c2])                            \n\t"
+      "lwc1      %[f1],       0(%[a1])                            \n\t"
+      "lwc1      %[f2],       0(%[a2])                            \n\t"
+      "lwc1      %[f3],       4(%[a1])                            \n\t"
+      "lwc1      %[f4],       4(%[a2])                            \n\t"
+      "lwc1      %[f5],       0(%[c1])                            \n\t"
+      "sub.s     %[f6],       %[f0],        %[f6]                 \n\t"
+      "sub.s     %[f7],       %[f1],        %[f2]                 \n\t"
+      "add.s     %[f8],       %[f3],        %[f4]                 \n\t"
+      "addiu     %[count],    $zero,        15                    \n\t"
+      "mul.s     %[f9],       %[f6],        %[f7]                 \n\t"
+      "mul.s     %[f6],       %[f6],        %[f8]                 \n\t"
+#if !defined(MIPS32_R2_LE)
+      "mul.s     %[f8],       %[f5],        %[f8]                 \n\t"
+      "mul.s     %[f5],       %[f5],        %[f7]                 \n\t"
+      "sub.s     %[f9],       %[f9],        %[f8]                 \n\t"
+      "add.s     %[f6],       %[f6],        %[f5]                 \n\t"
+#else
+      "nmsub.s   %[f9],       %[f9],        %[f5],      %[f8]     \n\t"
+      "madd.s    %[f6],       %[f6],        %[f5],      %[f7]     \n\t"
+#endif
+      "sub.s     %[f1],       %[f1],        %[f9]                 \n\t"
+      "add.s     %[f2],       %[f2],        %[f9]                 \n\t"
+      "sub.s     %[f3],       %[f3],        %[f6]                 \n\t"
+      "sub.s     %[f4],       %[f4],        %[f6]                 \n\t"
+      "swc1      %[f1],       0(%[a1])                            \n\t"
+      "swc1      %[f2],       0(%[a2])                            \n\t"
+      "swc1      %[f3],       4(%[a1])                            \n\t"
+      "swc1      %[f4],       4(%[a2])                            \n\t"
+      "addiu     %[a1],       %[a1],        8                     \n\t"
+      "addiu     %[a2],       %[a2],        -8                    \n\t"
+      "addiu     %[c1],       %[c1],        4                     \n\t"
+      "addiu     %[c2],       %[c2],        -4                    \n\t"
+      "1:                                                          \n\t"
+      "lwc1      %[f6],       0(%[c2])                            \n\t"
+      "lwc1      %[f1],       0(%[a1])                            \n\t"
+      "lwc1      %[f2],       0(%[a2])                            \n\t"
+      "lwc1      %[f3],       4(%[a1])                            \n\t"
+      "lwc1      %[f4],       4(%[a2])                            \n\t"
+      "lwc1      %[f5],       0(%[c1])                            \n\t"
+      "sub.s     %[f6],       %[f0],        %[f6]                 \n\t"
+      "sub.s     %[f7],       %[f1],        %[f2]                 \n\t"
+      "add.s     %[f8],       %[f3],        %[f4]                 \n\t"
+      "lwc1      %[f10],      -4(%[c2])                           \n\t"
+      "lwc1      %[f11],      8(%[a1])                            \n\t"
+      "lwc1      %[f12],      -8(%[a2])                           \n\t"
+      "mul.s     %[f9],       %[f6],        %[f7]                 \n\t"
+      "mul.s     %[f6],       %[f6],        %[f8]                 \n\t"
+#if !defined(MIPS32_R2_LE)
+      "mul.s     %[f8],       %[f5],        %[f8]                 \n\t"
+      "mul.s     %[f5],       %[f5],        %[f7]                 \n\t"
+      "lwc1      %[f13],      12(%[a1])                           \n\t"
+      "lwc1      %[f14],      -4(%[a2])                           \n\t"
+      "lwc1      %[f15],      4(%[c1])                            \n\t"
+      "sub.s     %[f9],       %[f9],        %[f8]                 \n\t"
+      "add.s     %[f6],       %[f6],        %[f5]                 \n\t"
+#else
+      "lwc1      %[f13],      12(%[a1])                           \n\t"
+      "lwc1      %[f14],      -4(%[a2])                           \n\t"
+      "lwc1      %[f15],      4(%[c1])                            \n\t"
+      "nmsub.s   %[f9],       %[f9],        %[f5],      %[f8]     \n\t"
+      "madd.s    %[f6],       %[f6],        %[f5],      %[f7]     \n\t"
+#endif
+      "sub.s     %[f10],      %[f0],        %[f10]                \n\t"
+      "sub.s     %[f5],       %[f11],       %[f12]                \n\t"
+      "add.s     %[f7],       %[f13],       %[f14]                \n\t"
+      "sub.s     %[f1],       %[f1],        %[f9]                 \n\t"
+      "add.s     %[f2],       %[f2],        %[f9]                 \n\t"
+      "sub.s     %[f3],       %[f3],        %[f6]                 \n\t"
+      "mul.s     %[f8],       %[f10],       %[f5]                 \n\t"
+      "mul.s     %[f10],      %[f10],       %[f7]                 \n\t"
+#if !defined(MIPS32_R2_LE)
+      "mul.s     %[f9],       %[f15],       %[f7]                 \n\t"
+      "mul.s     %[f15],      %[f15],       %[f5]                 \n\t"
+      "sub.s     %[f4],       %[f4],        %[f6]                 \n\t"
+      "swc1      %[f1],       0(%[a1])                            \n\t"
+      "swc1      %[f2],       0(%[a2])                            \n\t"
+      "sub.s     %[f8],       %[f8],        %[f9]                 \n\t"
+      "add.s     %[f10],      %[f10],       %[f15]                \n\t"
+#else
+      "swc1      %[f1],       0(%[a1])                            \n\t"
+      "swc1      %[f2],       0(%[a2])                            \n\t"
+      "sub.s     %[f4],       %[f4],        %[f6]                 \n\t"
+      "nmsub.s   %[f8],       %[f8],        %[f15],     %[f7]     \n\t"
+      "madd.s    %[f10],      %[f10],       %[f15],     %[f5]     \n\t"
+#endif
+      "swc1      %[f3],       4(%[a1])                            \n\t"
+      "swc1      %[f4],       4(%[a2])                            \n\t"
+      "sub.s     %[f11],      %[f11],       %[f8]                 \n\t"
+      "add.s     %[f12],      %[f12],       %[f8]                 \n\t"
+      "sub.s     %[f13],      %[f13],       %[f10]                \n\t"
+      "sub.s     %[f14],      %[f14],       %[f10]                \n\t"
+      "addiu     %[c2],       %[c2],        -8                    \n\t"
+      "addiu     %[c1],       %[c1],        8                     \n\t"
+      "swc1      %[f11],      8(%[a1])                            \n\t"
+      "swc1      %[f12],      -8(%[a2])                           \n\t"
+      "swc1      %[f13],      12(%[a1])                           \n\t"
+      "swc1      %[f14],      -4(%[a2])                           \n\t"
+      "addiu     %[a1],       %[a1],        16                    \n\t"
+      "addiu     %[count],    %[count],     -1                    \n\t"
+      "bgtz      %[count],    1b                                  \n\t"
+      " addiu    %[a2],       %[a2],        -16                   \n\t"
+      ".set      pop                                              \n\t"
+      : [a1] "+r"(a1), [a2] "+r"(a2), [c1] "+r"(c1), [c2] "+r"(c2),
+        [f1] "=&f"(f1), [f2] "=&f"(f2), [f3] "=&f"(f3), [f4] "=&f"(f4),
+        [f5] "=&f"(f5), [f6] "=&f"(f6), [f7] "=&f"(f7), [f8] "=&f"(f8),
+        [f9] "=&f"(f9), [f10] "=&f"(f10), [f11] "=&f"(f11), [f12] "=&f"(f12),
+        [f13] "=&f"(f13), [f14] "=&f"(f14), [f15] "=&f"(f15),
+        [count] "=&r"(count)
+      : [f0] "f"(f0)
+      : "memory");
+}
+
+void rftbsub_128_mips(float* a) {
+  const float* c = rdft_w + 32;
+  const float f0 = 0.5f;
+  float* a1 = &a[2];
+  float* a2 = &a[126];
+  const float* c1 = &c[1];
+  const float* c2 = &c[31];
+  float f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12, f13, f14, f15;
+  int count;
+
+  a[1] = -a[1];
+  a[65] = -a[65];
+
+  __asm __volatile(
+      ".set      push                                             \n\t"
+      ".set      noreorder                                        \n\t"
+      "lwc1      %[f6],       0(%[c2])                            \n\t"
+      "lwc1      %[f1],       0(%[a1])                            \n\t"
+      "lwc1      %[f2],       0(%[a2])                            \n\t"
+      "lwc1      %[f3],       4(%[a1])                            \n\t"
+      "lwc1      %[f4],       4(%[a2])                            \n\t"
+      "lwc1      %[f5],       0(%[c1])                            \n\t"
+      "sub.s     %[f6],       %[f0],        %[f6]                 \n\t"
+      "sub.s     %[f7],       %[f1],        %[f2]                 \n\t"
+      "add.s     %[f8],       %[f3],        %[f4]                 \n\t"
+      "addiu     %[count],    $zero,        15                    \n\t"
+      "mul.s     %[f9],       %[f6],        %[f7]                 \n\t"
+      "mul.s     %[f6],       %[f6],        %[f8]                 \n\t"
+#if !defined(MIPS32_R2_LE)
+      "mul.s     %[f8],       %[f5],        %[f8]                 \n\t"
+      "mul.s     %[f5],       %[f5],        %[f7]                 \n\t"
+      "add.s     %[f9],       %[f9],        %[f8]                 \n\t"
+      "sub.s     %[f6],       %[f6],        %[f5]                 \n\t"
+#else
+      "madd.s    %[f9],       %[f9],        %[f5],      %[f8]     \n\t"
+      "nmsub.s   %[f6],       %[f6],        %[f5],      %[f7]     \n\t"
+#endif
+      "sub.s     %[f1],       %[f1],        %[f9]                 \n\t"
+      "add.s     %[f2],       %[f2],        %[f9]                 \n\t"
+      "sub.s     %[f3],       %[f6],        %[f3]                 \n\t"
+      "sub.s     %[f4],       %[f6],        %[f4]                 \n\t"
+      "swc1      %[f1],       0(%[a1])                            \n\t"
+      "swc1      %[f2],       0(%[a2])                            \n\t"
+      "swc1      %[f3],       4(%[a1])                            \n\t"
+      "swc1      %[f4],       4(%[a2])                            \n\t"
+      "addiu     %[a1],       %[a1],        8                     \n\t"
+      "addiu     %[a2],       %[a2],        -8                    \n\t"
+      "addiu     %[c1],       %[c1],        4                     \n\t"
+      "addiu     %[c2],       %[c2],        -4                    \n\t"
+      "1:                                                          \n\t"
+      "lwc1      %[f6],       0(%[c2])                            \n\t"
+      "lwc1      %[f1],       0(%[a1])                            \n\t"
+      "lwc1      %[f2],       0(%[a2])                            \n\t"
+      "lwc1      %[f3],       4(%[a1])                            \n\t"
+      "lwc1      %[f4],       4(%[a2])                            \n\t"
+      "lwc1      %[f5],       0(%[c1])                            \n\t"
+      "sub.s     %[f6],       %[f0],        %[f6]                 \n\t"
+      "sub.s     %[f7],       %[f1],        %[f2]                 \n\t"
+      "add.s     %[f8],       %[f3],        %[f4]                 \n\t"
+      "lwc1      %[f10],      -4(%[c2])                           \n\t"
+      "lwc1      %[f11],      8(%[a1])                            \n\t"
+      "lwc1      %[f12],      -8(%[a2])                           \n\t"
+      "mul.s     %[f9],       %[f6],        %[f7]                 \n\t"
+      "mul.s     %[f6],       %[f6],        %[f8]                 \n\t"
+#if !defined(MIPS32_R2_LE)
+      "mul.s     %[f8],       %[f5],        %[f8]                 \n\t"
+      "mul.s     %[f5],       %[f5],        %[f7]                 \n\t"
+      "lwc1      %[f13],      12(%[a1])                           \n\t"
+      "lwc1      %[f14],      -4(%[a2])                           \n\t"
+      "lwc1      %[f15],      4(%[c1])                            \n\t"
+      "add.s     %[f9],       %[f9],        %[f8]                 \n\t"
+      "sub.s     %[f6],       %[f6],        %[f5]                 \n\t"
+#else
+      "lwc1      %[f13],      12(%[a1])                           \n\t"
+      "lwc1      %[f14],      -4(%[a2])                           \n\t"
+      "lwc1      %[f15],      4(%[c1])                            \n\t"
+      "madd.s    %[f9],       %[f9],        %[f5],      %[f8]     \n\t"
+      "nmsub.s   %[f6],       %[f6],        %[f5],      %[f7]     \n\t"
+#endif
+      "sub.s     %[f10],      %[f0],        %[f10]                \n\t"
+      "sub.s     %[f5],       %[f11],       %[f12]                \n\t"
+      "add.s     %[f7],       %[f13],       %[f14]                \n\t"
+      "sub.s     %[f1],       %[f1],        %[f9]                 \n\t"
+      "add.s     %[f2],       %[f2],        %[f9]                 \n\t"
+      "sub.s     %[f3],       %[f6],        %[f3]                 \n\t"
+      "mul.s     %[f8],       %[f10],       %[f5]                 \n\t"
+      "mul.s     %[f10],      %[f10],       %[f7]                 \n\t"
+#if !defined(MIPS32_R2_LE)
+      "mul.s     %[f9],       %[f15],       %[f7]                 \n\t"
+      "mul.s     %[f15],      %[f15],       %[f5]                 \n\t"
+      "sub.s     %[f4],       %[f6],        %[f4]                 \n\t"
+      "swc1      %[f1],       0(%[a1])                            \n\t"
+      "swc1      %[f2],       0(%[a2])                            \n\t"
+      "add.s     %[f8],       %[f8],        %[f9]                 \n\t"
+      "sub.s     %[f10],      %[f10],       %[f15]                \n\t"
+#else
+      "swc1      %[f1],       0(%[a1])                            \n\t"
+      "swc1      %[f2],       0(%[a2])                            \n\t"
+      "sub.s     %[f4],       %[f6],        %[f4]                 \n\t"
+      "madd.s    %[f8],       %[f8],        %[f15],     %[f7]     \n\t"
+      "nmsub.s   %[f10],      %[f10],       %[f15],     %[f5]     \n\t"
+#endif
+      "swc1      %[f3],       4(%[a1])                            \n\t"
+      "swc1      %[f4],       4(%[a2])                            \n\t"
+      "sub.s     %[f11],      %[f11],       %[f8]                 \n\t"
+      "add.s     %[f12],      %[f12],       %[f8]                 \n\t"
+      "sub.s     %[f13],      %[f10],       %[f13]                \n\t"
+      "sub.s     %[f14],      %[f10],       %[f14]                \n\t"
+      "addiu     %[c2],       %[c2],        -8                    \n\t"
+      "addiu     %[c1],       %[c1],        8                     \n\t"
+      "swc1      %[f11],      8(%[a1])                            \n\t"
+      "swc1      %[f12],      -8(%[a2])                           \n\t"
+      "swc1      %[f13],      12(%[a1])                           \n\t"
+      "swc1      %[f14],      -4(%[a2])                           \n\t"
+      "addiu     %[a1],       %[a1],        16                    \n\t"
+      "addiu     %[count],    %[count],     -1                    \n\t"
+      "bgtz      %[count],    1b                                  \n\t"
+      " addiu    %[a2],       %[a2],        -16                   \n\t"
+      ".set      pop                                              \n\t"
+      : [a1] "+r"(a1), [a2] "+r"(a2), [c1] "+r"(c1), [c2] "+r"(c2),
+        [f1] "=&f"(f1), [f2] "=&f"(f2), [f3] "=&f"(f3), [f4] "=&f"(f4),
+        [f5] "=&f"(f5), [f6] "=&f"(f6), [f7] "=&f"(f7), [f8] "=&f"(f8),
+        [f9] "=&f"(f9), [f10] "=&f"(f10), [f11] "=&f"(f11), [f12] "=&f"(f12),
+        [f13] "=&f"(f13), [f14] "=&f"(f14), [f15] "=&f"(f15),
+        [count] "=&r"(count)
+      : [f0] "f"(f0)
+      : "memory");
+}
+#endif
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft_neon.cc b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft_neon.cc
new file mode 100644
index 0000000..acab972
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft_neon.cc
@@ -0,0 +1,351 @@
+/*
+ *  Copyright (c) 2014 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+/*
+ * The rdft AEC algorithm, neon version of speed-critical functions.
+ *
+ * Based on the sse2 version.
+ */
+
+#include <arm_neon.h>
+
+#include "common_audio/third_party/ooura/fft_size_128/ooura_fft.h"
+#include "common_audio/third_party/ooura/fft_size_128/ooura_fft_tables_common.h"
+#include "common_audio/third_party/ooura/fft_size_128/ooura_fft_tables_neon_sse2.h"
+
+namespace webrtc {
+
+#if defined(WEBRTC_HAS_NEON)
+void cft1st_128_neon(float* a) {
+  const float32x4_t vec_swap_sign = vld1q_f32((float32_t*)k_swap_sign);
+  int j, k2;
+
+  for (k2 = 0, j = 0; j < 128; j += 16, k2 += 4) {
+    float32x4_t a00v = vld1q_f32(&a[j + 0]);
+    float32x4_t a04v = vld1q_f32(&a[j + 4]);
+    float32x4_t a08v = vld1q_f32(&a[j + 8]);
+    float32x4_t a12v = vld1q_f32(&a[j + 12]);
+    float32x4_t a01v = vcombine_f32(vget_low_f32(a00v), vget_low_f32(a08v));
+    float32x4_t a23v = vcombine_f32(vget_high_f32(a00v), vget_high_f32(a08v));
+    float32x4_t a45v = vcombine_f32(vget_low_f32(a04v), vget_low_f32(a12v));
+    float32x4_t a67v = vcombine_f32(vget_high_f32(a04v), vget_high_f32(a12v));
+    const float32x4_t wk1rv = vld1q_f32(&rdft_wk1r[k2]);
+    const float32x4_t wk1iv = vld1q_f32(&rdft_wk1i[k2]);
+    const float32x4_t wk2rv = vld1q_f32(&rdft_wk2r[k2]);
+    const float32x4_t wk2iv = vld1q_f32(&rdft_wk2i[k2]);
+    const float32x4_t wk3rv = vld1q_f32(&rdft_wk3r[k2]);
+    const float32x4_t wk3iv = vld1q_f32(&rdft_wk3i[k2]);
+    float32x4_t x0v = vaddq_f32(a01v, a23v);
+    const float32x4_t x1v = vsubq_f32(a01v, a23v);
+    const float32x4_t x2v = vaddq_f32(a45v, a67v);
+    const float32x4_t x3v = vsubq_f32(a45v, a67v);
+    const float32x4_t x3w = vrev64q_f32(x3v);
+    float32x4_t x0w;
+    a01v = vaddq_f32(x0v, x2v);
+    x0v = vsubq_f32(x0v, x2v);
+    x0w = vrev64q_f32(x0v);
+    a45v = vmulq_f32(wk2rv, x0v);
+    a45v = vmlaq_f32(a45v, wk2iv, x0w);
+    x0v = vmlaq_f32(x1v, x3w, vec_swap_sign);
+    x0w = vrev64q_f32(x0v);
+    a23v = vmulq_f32(wk1rv, x0v);
+    a23v = vmlaq_f32(a23v, wk1iv, x0w);
+    x0v = vmlsq_f32(x1v, x3w, vec_swap_sign);
+    x0w = vrev64q_f32(x0v);
+    a67v = vmulq_f32(wk3rv, x0v);
+    a67v = vmlaq_f32(a67v, wk3iv, x0w);
+    a00v = vcombine_f32(vget_low_f32(a01v), vget_low_f32(a23v));
+    a04v = vcombine_f32(vget_low_f32(a45v), vget_low_f32(a67v));
+    a08v = vcombine_f32(vget_high_f32(a01v), vget_high_f32(a23v));
+    a12v = vcombine_f32(vget_high_f32(a45v), vget_high_f32(a67v));
+    vst1q_f32(&a[j + 0], a00v);
+    vst1q_f32(&a[j + 4], a04v);
+    vst1q_f32(&a[j + 8], a08v);
+    vst1q_f32(&a[j + 12], a12v);
+  }
+}
+
+void cftmdl_128_neon(float* a) {
+  int j;
+  const int l = 8;
+  const float32x4_t vec_swap_sign = vld1q_f32((float32_t*)k_swap_sign);
+  float32x4_t wk1rv = vld1q_f32(cftmdl_wk1r);
+
+  for (j = 0; j < l; j += 2) {
+    const float32x2_t a_00 = vld1_f32(&a[j + 0]);
+    const float32x2_t a_08 = vld1_f32(&a[j + 8]);
+    const float32x2_t a_32 = vld1_f32(&a[j + 32]);
+    const float32x2_t a_40 = vld1_f32(&a[j + 40]);
+    const float32x4_t a_00_32 = vcombine_f32(a_00, a_32);
+    const float32x4_t a_08_40 = vcombine_f32(a_08, a_40);
+    const float32x4_t x0r0_0i0_0r1_x0i1 = vaddq_f32(a_00_32, a_08_40);
+    const float32x4_t x1r0_1i0_1r1_x1i1 = vsubq_f32(a_00_32, a_08_40);
+    const float32x2_t a_16 = vld1_f32(&a[j + 16]);
+    const float32x2_t a_24 = vld1_f32(&a[j + 24]);
+    const float32x2_t a_48 = vld1_f32(&a[j + 48]);
+    const float32x2_t a_56 = vld1_f32(&a[j + 56]);
+    const float32x4_t a_16_48 = vcombine_f32(a_16, a_48);
+    const float32x4_t a_24_56 = vcombine_f32(a_24, a_56);
+    const float32x4_t x2r0_2i0_2r1_x2i1 = vaddq_f32(a_16_48, a_24_56);
+    const float32x4_t x3r0_3i0_3r1_x3i1 = vsubq_f32(a_16_48, a_24_56);
+    const float32x4_t xx0 = vaddq_f32(x0r0_0i0_0r1_x0i1, x2r0_2i0_2r1_x2i1);
+    const float32x4_t xx1 = vsubq_f32(x0r0_0i0_0r1_x0i1, x2r0_2i0_2r1_x2i1);
+    const float32x4_t x3i0_3r0_3i1_x3r1 = vrev64q_f32(x3r0_3i0_3r1_x3i1);
+    const float32x4_t x1_x3_add =
+        vmlaq_f32(x1r0_1i0_1r1_x1i1, vec_swap_sign, x3i0_3r0_3i1_x3r1);
+    const float32x4_t x1_x3_sub =
+        vmlsq_f32(x1r0_1i0_1r1_x1i1, vec_swap_sign, x3i0_3r0_3i1_x3r1);
+    const float32x2_t yy0_a = vdup_lane_f32(vget_high_f32(x1_x3_add), 0);
+    const float32x2_t yy0_s = vdup_lane_f32(vget_high_f32(x1_x3_sub), 0);
+    const float32x4_t yy0_as = vcombine_f32(yy0_a, yy0_s);
+    const float32x2_t yy1_a = vdup_lane_f32(vget_high_f32(x1_x3_add), 1);
+    const float32x2_t yy1_s = vdup_lane_f32(vget_high_f32(x1_x3_sub), 1);
+    const float32x4_t yy1_as = vcombine_f32(yy1_a, yy1_s);
+    const float32x4_t yy0 = vmlaq_f32(yy0_as, vec_swap_sign, yy1_as);
+    const float32x4_t yy4 = vmulq_f32(wk1rv, yy0);
+    const float32x4_t xx1_rev = vrev64q_f32(xx1);
+    const float32x4_t yy4_rev = vrev64q_f32(yy4);
+
+    vst1_f32(&a[j + 0], vget_low_f32(xx0));
+    vst1_f32(&a[j + 32], vget_high_f32(xx0));
+    vst1_f32(&a[j + 16], vget_low_f32(xx1));
+    vst1_f32(&a[j + 48], vget_high_f32(xx1_rev));
+
+    a[j + 48] = -a[j + 48];
+
+    vst1_f32(&a[j + 8], vget_low_f32(x1_x3_add));
+    vst1_f32(&a[j + 24], vget_low_f32(x1_x3_sub));
+    vst1_f32(&a[j + 40], vget_low_f32(yy4));
+    vst1_f32(&a[j + 56], vget_high_f32(yy4_rev));
+  }
+
+  {
+    const int k = 64;
+    const int k1 = 2;
+    const int k2 = 2 * k1;
+    const float32x4_t wk2rv = vld1q_f32(&rdft_wk2r[k2 + 0]);
+    const float32x4_t wk2iv = vld1q_f32(&rdft_wk2i[k2 + 0]);
+    const float32x4_t wk1iv = vld1q_f32(&rdft_wk1i[k2 + 0]);
+    const float32x4_t wk3rv = vld1q_f32(&rdft_wk3r[k2 + 0]);
+    const float32x4_t wk3iv = vld1q_f32(&rdft_wk3i[k2 + 0]);
+    wk1rv = vld1q_f32(&rdft_wk1r[k2 + 0]);
+    for (j = k; j < l + k; j += 2) {
+      const float32x2_t a_00 = vld1_f32(&a[j + 0]);
+      const float32x2_t a_08 = vld1_f32(&a[j + 8]);
+      const float32x2_t a_32 = vld1_f32(&a[j + 32]);
+      const float32x2_t a_40 = vld1_f32(&a[j + 40]);
+      const float32x4_t a_00_32 = vcombine_f32(a_00, a_32);
+      const float32x4_t a_08_40 = vcombine_f32(a_08, a_40);
+      const float32x4_t x0r0_0i0_0r1_x0i1 = vaddq_f32(a_00_32, a_08_40);
+      const float32x4_t x1r0_1i0_1r1_x1i1 = vsubq_f32(a_00_32, a_08_40);
+      const float32x2_t a_16 = vld1_f32(&a[j + 16]);
+      const float32x2_t a_24 = vld1_f32(&a[j + 24]);
+      const float32x2_t a_48 = vld1_f32(&a[j + 48]);
+      const float32x2_t a_56 = vld1_f32(&a[j + 56]);
+      const float32x4_t a_16_48 = vcombine_f32(a_16, a_48);
+      const float32x4_t a_24_56 = vcombine_f32(a_24, a_56);
+      const float32x4_t x2r0_2i0_2r1_x2i1 = vaddq_f32(a_16_48, a_24_56);
+      const float32x4_t x3r0_3i0_3r1_x3i1 = vsubq_f32(a_16_48, a_24_56);
+      const float32x4_t xx = vaddq_f32(x0r0_0i0_0r1_x0i1, x2r0_2i0_2r1_x2i1);
+      const float32x4_t xx1 = vsubq_f32(x0r0_0i0_0r1_x0i1, x2r0_2i0_2r1_x2i1);
+      const float32x4_t x3i0_3r0_3i1_x3r1 = vrev64q_f32(x3r0_3i0_3r1_x3i1);
+      const float32x4_t x1_x3_add =
+          vmlaq_f32(x1r0_1i0_1r1_x1i1, vec_swap_sign, x3i0_3r0_3i1_x3r1);
+      const float32x4_t x1_x3_sub =
+          vmlsq_f32(x1r0_1i0_1r1_x1i1, vec_swap_sign, x3i0_3r0_3i1_x3r1);
+      float32x4_t xx4 = vmulq_f32(wk2rv, xx1);
+      float32x4_t xx12 = vmulq_f32(wk1rv, x1_x3_add);
+      float32x4_t xx22 = vmulq_f32(wk3rv, x1_x3_sub);
+      xx4 = vmlaq_f32(xx4, wk2iv, vrev64q_f32(xx1));
+      xx12 = vmlaq_f32(xx12, wk1iv, vrev64q_f32(x1_x3_add));
+      xx22 = vmlaq_f32(xx22, wk3iv, vrev64q_f32(x1_x3_sub));
+
+      vst1_f32(&a[j + 0], vget_low_f32(xx));
+      vst1_f32(&a[j + 32], vget_high_f32(xx));
+      vst1_f32(&a[j + 16], vget_low_f32(xx4));
+      vst1_f32(&a[j + 48], vget_high_f32(xx4));
+      vst1_f32(&a[j + 8], vget_low_f32(xx12));
+      vst1_f32(&a[j + 40], vget_high_f32(xx12));
+      vst1_f32(&a[j + 24], vget_low_f32(xx22));
+      vst1_f32(&a[j + 56], vget_high_f32(xx22));
+    }
+  }
+}
+
+__inline static float32x4_t reverse_order_f32x4(float32x4_t in) {
+  // A B C D -> C D A B
+  const float32x4_t rev = vcombine_f32(vget_high_f32(in), vget_low_f32(in));
+  // C D A B -> D C B A
+  return vrev64q_f32(rev);
+}
+
+void rftfsub_128_neon(float* a) {
+  const float* c = rdft_w + 32;
+  int j1, j2;
+  const float32x4_t mm_half = vdupq_n_f32(0.5f);
+
+  // Vectorized code (four at once).
+  // Note: commented number are indexes for the first iteration of the loop.
+  for (j1 = 1, j2 = 2; j2 + 7 < 64; j1 += 4, j2 += 8) {
+    // Load 'wk'.
+    const float32x4_t c_j1 = vld1q_f32(&c[j1]);          //  1,  2,  3,  4,
+    const float32x4_t c_k1 = vld1q_f32(&c[29 - j1]);     // 28, 29, 30, 31,
+    const float32x4_t wkrt = vsubq_f32(mm_half, c_k1);   // 28, 29, 30, 31,
+    const float32x4_t wkr_ = reverse_order_f32x4(wkrt);  // 31, 30, 29, 28,
+    const float32x4_t wki_ = c_j1;                       //  1,  2,  3,  4,
+    // Load and shuffle 'a'.
+    //   2,   4,   6,   8,   3,   5,   7,   9
+    float32x4x2_t a_j2_p = vld2q_f32(&a[0 + j2]);
+    // 120, 122, 124, 126, 121, 123, 125, 127,
+    const float32x4x2_t k2_0_4 = vld2q_f32(&a[122 - j2]);
+    // 126, 124, 122, 120
+    const float32x4_t a_k2_p0 = reverse_order_f32x4(k2_0_4.val[0]);
+    // 127, 125, 123, 121
+    const float32x4_t a_k2_p1 = reverse_order_f32x4(k2_0_4.val[1]);
+    // Calculate 'x'.
+    const float32x4_t xr_ = vsubq_f32(a_j2_p.val[0], a_k2_p0);
+    // 2-126, 4-124, 6-122, 8-120,
+    const float32x4_t xi_ = vaddq_f32(a_j2_p.val[1], a_k2_p1);
+    // 3-127, 5-125, 7-123, 9-121,
+    // Calculate product into 'y'.
+    //    yr = wkr * xr - wki * xi;
+    //    yi = wkr * xi + wki * xr;
+    const float32x4_t a_ = vmulq_f32(wkr_, xr_);
+    const float32x4_t b_ = vmulq_f32(wki_, xi_);
+    const float32x4_t c_ = vmulq_f32(wkr_, xi_);
+    const float32x4_t d_ = vmulq_f32(wki_, xr_);
+    const float32x4_t yr_ = vsubq_f32(a_, b_);  // 2-126, 4-124, 6-122, 8-120,
+    const float32x4_t yi_ = vaddq_f32(c_, d_);  // 3-127, 5-125, 7-123, 9-121,
+                                                // Update 'a'.
+                                                //    a[j2 + 0] -= yr;
+                                                //    a[j2 + 1] -= yi;
+                                                //    a[k2 + 0] += yr;
+                                                //    a[k2 + 1] -= yi;
+    // 126, 124, 122, 120,
+    const float32x4_t a_k2_p0n = vaddq_f32(a_k2_p0, yr_);
+    // 127, 125, 123, 121,
+    const float32x4_t a_k2_p1n = vsubq_f32(a_k2_p1, yi_);
+    // Shuffle in right order and store.
+    const float32x4_t a_k2_p0nr = vrev64q_f32(a_k2_p0n);
+    const float32x4_t a_k2_p1nr = vrev64q_f32(a_k2_p1n);
+    // 124, 125, 126, 127, 120, 121, 122, 123
+    const float32x4x2_t a_k2_n = vzipq_f32(a_k2_p0nr, a_k2_p1nr);
+    //   2,   4,   6,   8,
+    a_j2_p.val[0] = vsubq_f32(a_j2_p.val[0], yr_);
+    //   3,   5,   7,   9,
+    a_j2_p.val[1] = vsubq_f32(a_j2_p.val[1], yi_);
+    //   2,   3,   4,   5,   6,   7,   8,   9,
+    vst2q_f32(&a[0 + j2], a_j2_p);
+
+    vst1q_f32(&a[122 - j2], a_k2_n.val[1]);
+    vst1q_f32(&a[126 - j2], a_k2_n.val[0]);
+  }
+
+  // Scalar code for the remaining items.
+  for (; j2 < 64; j1 += 1, j2 += 2) {
+    const int k2 = 128 - j2;
+    const int k1 = 32 - j1;
+    const float wkr = 0.5f - c[k1];
+    const float wki = c[j1];
+    const float xr = a[j2 + 0] - a[k2 + 0];
+    const float xi = a[j2 + 1] + a[k2 + 1];
+    const float yr = wkr * xr - wki * xi;
+    const float yi = wkr * xi + wki * xr;
+    a[j2 + 0] -= yr;
+    a[j2 + 1] -= yi;
+    a[k2 + 0] += yr;
+    a[k2 + 1] -= yi;
+  }
+}
+
+void rftbsub_128_neon(float* a) {
+  const float* c = rdft_w + 32;
+  int j1, j2;
+  const float32x4_t mm_half = vdupq_n_f32(0.5f);
+
+  a[1] = -a[1];
+  // Vectorized code (four at once).
+  //    Note: commented number are indexes for the first iteration of the loop.
+  for (j1 = 1, j2 = 2; j2 + 7 < 64; j1 += 4, j2 += 8) {
+    // Load 'wk'.
+    const float32x4_t c_j1 = vld1q_f32(&c[j1]);          //  1,  2,  3,  4,
+    const float32x4_t c_k1 = vld1q_f32(&c[29 - j1]);     // 28, 29, 30, 31,
+    const float32x4_t wkrt = vsubq_f32(mm_half, c_k1);   // 28, 29, 30, 31,
+    const float32x4_t wkr_ = reverse_order_f32x4(wkrt);  // 31, 30, 29, 28,
+    const float32x4_t wki_ = c_j1;                       //  1,  2,  3,  4,
+    // Load and shuffle 'a'.
+    //   2,   4,   6,   8,   3,   5,   7,   9
+    float32x4x2_t a_j2_p = vld2q_f32(&a[0 + j2]);
+    // 120, 122, 124, 126, 121, 123, 125, 127,
+    const float32x4x2_t k2_0_4 = vld2q_f32(&a[122 - j2]);
+    // 126, 124, 122, 120
+    const float32x4_t a_k2_p0 = reverse_order_f32x4(k2_0_4.val[0]);
+    // 127, 125, 123, 121
+    const float32x4_t a_k2_p1 = reverse_order_f32x4(k2_0_4.val[1]);
+    // Calculate 'x'.
+    const float32x4_t xr_ = vsubq_f32(a_j2_p.val[0], a_k2_p0);
+    // 2-126, 4-124, 6-122, 8-120,
+    const float32x4_t xi_ = vaddq_f32(a_j2_p.val[1], a_k2_p1);
+    // 3-127, 5-125, 7-123, 9-121,
+    // Calculate product into 'y'.
+    //    yr = wkr * xr - wki * xi;
+    //    yi = wkr * xi + wki * xr;
+    const float32x4_t a_ = vmulq_f32(wkr_, xr_);
+    const float32x4_t b_ = vmulq_f32(wki_, xi_);
+    const float32x4_t c_ = vmulq_f32(wkr_, xi_);
+    const float32x4_t d_ = vmulq_f32(wki_, xr_);
+    const float32x4_t yr_ = vaddq_f32(a_, b_);  // 2-126, 4-124, 6-122, 8-120,
+    const float32x4_t yi_ = vsubq_f32(c_, d_);  // 3-127, 5-125, 7-123, 9-121,
+                                                // Update 'a'.
+                                                //    a[j2 + 0] -= yr;
+                                                //    a[j2 + 1] -= yi;
+                                                //    a[k2 + 0] += yr;
+                                                //    a[k2 + 1] -= yi;
+    // 126, 124, 122, 120,
+    const float32x4_t a_k2_p0n = vaddq_f32(a_k2_p0, yr_);
+    // 127, 125, 123, 121,
+    const float32x4_t a_k2_p1n = vsubq_f32(yi_, a_k2_p1);
+    // Shuffle in right order and store.
+    //   2,   3,   4,   5,   6,   7,   8,   9,
+    const float32x4_t a_k2_p0nr = vrev64q_f32(a_k2_p0n);
+    const float32x4_t a_k2_p1nr = vrev64q_f32(a_k2_p1n);
+    // 124, 125, 126, 127, 120, 121, 122, 123
+    const float32x4x2_t a_k2_n = vzipq_f32(a_k2_p0nr, a_k2_p1nr);
+    //   2,   4,   6,   8,
+    a_j2_p.val[0] = vsubq_f32(a_j2_p.val[0], yr_);
+    //   3,   5,   7,   9,
+    a_j2_p.val[1] = vsubq_f32(yi_, a_j2_p.val[1]);
+    //   2,   3,   4,   5,   6,   7,   8,   9,
+    vst2q_f32(&a[0 + j2], a_j2_p);
+
+    vst1q_f32(&a[122 - j2], a_k2_n.val[1]);
+    vst1q_f32(&a[126 - j2], a_k2_n.val[0]);
+  }
+
+  // Scalar code for the remaining items.
+  for (; j2 < 64; j1 += 1, j2 += 2) {
+    const int k2 = 128 - j2;
+    const int k1 = 32 - j1;
+    const float wkr = 0.5f - c[k1];
+    const float wki = c[j1];
+    const float xr = a[j2 + 0] - a[k2 + 0];
+    const float xi = a[j2 + 1] + a[k2 + 1];
+    const float yr = wkr * xr + wki * xi;
+    const float yi = wkr * xi - wki * xr;
+    a[j2 + 0] = a[j2 + 0] - yr;
+    a[j2 + 1] = yi - a[j2 + 1];
+    a[k2 + 0] = yr + a[k2 + 0];
+    a[k2 + 1] = yi - a[k2 + 1];
+  }
+  a[65] = -a[65];
+}
+#endif
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft_sse2.cc b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft_sse2.cc
new file mode 100644
index 0000000..7f0802d
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft_sse2.cc
@@ -0,0 +1,439 @@
+/*
+ *  Copyright (c) 2011 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include <emmintrin.h>
+#include <xmmintrin.h>
+
+#include "common_audio/third_party/ooura/fft_size_128/ooura_fft.h"
+#include "common_audio/third_party/ooura/fft_size_128/ooura_fft_tables_common.h"
+#include "common_audio/third_party/ooura/fft_size_128/ooura_fft_tables_neon_sse2.h"
+#include "rtc_base/system/arch.h"
+
+namespace webrtc {
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+
+namespace {
+// These intrinsics were unavailable before VS 2008.
+// TODO(andrew): move to a common file.
+#if defined(_MSC_VER) && _MSC_VER < 1500
+static __inline __m128 _mm_castsi128_ps(__m128i a) {
+  return *(__m128*)&a;
+}
+static __inline __m128i _mm_castps_si128(__m128 a) {
+  return *(__m128i*)&a;
+}
+#endif
+
+}  // namespace
+
+void cft1st_128_SSE2(float* a) {
+  const __m128 mm_swap_sign = _mm_load_ps(k_swap_sign);
+  int j, k2;
+
+  for (k2 = 0, j = 0; j < 128; j += 16, k2 += 4) {
+    __m128 a00v = _mm_loadu_ps(&a[j + 0]);
+    __m128 a04v = _mm_loadu_ps(&a[j + 4]);
+    __m128 a08v = _mm_loadu_ps(&a[j + 8]);
+    __m128 a12v = _mm_loadu_ps(&a[j + 12]);
+    __m128 a01v = _mm_shuffle_ps(a00v, a08v, _MM_SHUFFLE(1, 0, 1, 0));
+    __m128 a23v = _mm_shuffle_ps(a00v, a08v, _MM_SHUFFLE(3, 2, 3, 2));
+    __m128 a45v = _mm_shuffle_ps(a04v, a12v, _MM_SHUFFLE(1, 0, 1, 0));
+    __m128 a67v = _mm_shuffle_ps(a04v, a12v, _MM_SHUFFLE(3, 2, 3, 2));
+
+    const __m128 wk1rv = _mm_load_ps(&rdft_wk1r[k2]);
+    const __m128 wk1iv = _mm_load_ps(&rdft_wk1i[k2]);
+    const __m128 wk2rv = _mm_load_ps(&rdft_wk2r[k2]);
+    const __m128 wk2iv = _mm_load_ps(&rdft_wk2i[k2]);
+    const __m128 wk3rv = _mm_load_ps(&rdft_wk3r[k2]);
+    const __m128 wk3iv = _mm_load_ps(&rdft_wk3i[k2]);
+    __m128 x0v = _mm_add_ps(a01v, a23v);
+    const __m128 x1v = _mm_sub_ps(a01v, a23v);
+    const __m128 x2v = _mm_add_ps(a45v, a67v);
+    const __m128 x3v = _mm_sub_ps(a45v, a67v);
+    __m128 x0w;
+    a01v = _mm_add_ps(x0v, x2v);
+    x0v = _mm_sub_ps(x0v, x2v);
+    x0w = _mm_shuffle_ps(x0v, x0v, _MM_SHUFFLE(2, 3, 0, 1));
+    {
+      const __m128 a45_0v = _mm_mul_ps(wk2rv, x0v);
+      const __m128 a45_1v = _mm_mul_ps(wk2iv, x0w);
+      a45v = _mm_add_ps(a45_0v, a45_1v);
+    }
+    {
+      __m128 a23_0v, a23_1v;
+      const __m128 x3w = _mm_shuffle_ps(x3v, x3v, _MM_SHUFFLE(2, 3, 0, 1));
+      const __m128 x3s = _mm_mul_ps(mm_swap_sign, x3w);
+      x0v = _mm_add_ps(x1v, x3s);
+      x0w = _mm_shuffle_ps(x0v, x0v, _MM_SHUFFLE(2, 3, 0, 1));
+      a23_0v = _mm_mul_ps(wk1rv, x0v);
+      a23_1v = _mm_mul_ps(wk1iv, x0w);
+      a23v = _mm_add_ps(a23_0v, a23_1v);
+
+      x0v = _mm_sub_ps(x1v, x3s);
+      x0w = _mm_shuffle_ps(x0v, x0v, _MM_SHUFFLE(2, 3, 0, 1));
+    }
+    {
+      const __m128 a67_0v = _mm_mul_ps(wk3rv, x0v);
+      const __m128 a67_1v = _mm_mul_ps(wk3iv, x0w);
+      a67v = _mm_add_ps(a67_0v, a67_1v);
+    }
+
+    a00v = _mm_shuffle_ps(a01v, a23v, _MM_SHUFFLE(1, 0, 1, 0));
+    a04v = _mm_shuffle_ps(a45v, a67v, _MM_SHUFFLE(1, 0, 1, 0));
+    a08v = _mm_shuffle_ps(a01v, a23v, _MM_SHUFFLE(3, 2, 3, 2));
+    a12v = _mm_shuffle_ps(a45v, a67v, _MM_SHUFFLE(3, 2, 3, 2));
+    _mm_storeu_ps(&a[j + 0], a00v);
+    _mm_storeu_ps(&a[j + 4], a04v);
+    _mm_storeu_ps(&a[j + 8], a08v);
+    _mm_storeu_ps(&a[j + 12], a12v);
+  }
+}
+
+void cftmdl_128_SSE2(float* a) {
+  const int l = 8;
+  const __m128 mm_swap_sign = _mm_load_ps(k_swap_sign);
+  int j0;
+
+  __m128 wk1rv = _mm_load_ps(cftmdl_wk1r);
+  for (j0 = 0; j0 < l; j0 += 2) {
+    const __m128i a_00 = _mm_loadl_epi64((__m128i*)&a[j0 + 0]);
+    const __m128i a_08 = _mm_loadl_epi64((__m128i*)&a[j0 + 8]);
+    const __m128i a_32 = _mm_loadl_epi64((__m128i*)&a[j0 + 32]);
+    const __m128i a_40 = _mm_loadl_epi64((__m128i*)&a[j0 + 40]);
+    const __m128 a_00_32 =
+        _mm_shuffle_ps(_mm_castsi128_ps(a_00), _mm_castsi128_ps(a_32),
+                       _MM_SHUFFLE(1, 0, 1, 0));
+    const __m128 a_08_40 =
+        _mm_shuffle_ps(_mm_castsi128_ps(a_08), _mm_castsi128_ps(a_40),
+                       _MM_SHUFFLE(1, 0, 1, 0));
+    __m128 x0r0_0i0_0r1_x0i1 = _mm_add_ps(a_00_32, a_08_40);
+    const __m128 x1r0_1i0_1r1_x1i1 = _mm_sub_ps(a_00_32, a_08_40);
+
+    const __m128i a_16 = _mm_loadl_epi64((__m128i*)&a[j0 + 16]);
+    const __m128i a_24 = _mm_loadl_epi64((__m128i*)&a[j0 + 24]);
+    const __m128i a_48 = _mm_loadl_epi64((__m128i*)&a[j0 + 48]);
+    const __m128i a_56 = _mm_loadl_epi64((__m128i*)&a[j0 + 56]);
+    const __m128 a_16_48 =
+        _mm_shuffle_ps(_mm_castsi128_ps(a_16), _mm_castsi128_ps(a_48),
+                       _MM_SHUFFLE(1, 0, 1, 0));
+    const __m128 a_24_56 =
+        _mm_shuffle_ps(_mm_castsi128_ps(a_24), _mm_castsi128_ps(a_56),
+                       _MM_SHUFFLE(1, 0, 1, 0));
+    const __m128 x2r0_2i0_2r1_x2i1 = _mm_add_ps(a_16_48, a_24_56);
+    const __m128 x3r0_3i0_3r1_x3i1 = _mm_sub_ps(a_16_48, a_24_56);
+
+    const __m128 xx0 = _mm_add_ps(x0r0_0i0_0r1_x0i1, x2r0_2i0_2r1_x2i1);
+    const __m128 xx1 = _mm_sub_ps(x0r0_0i0_0r1_x0i1, x2r0_2i0_2r1_x2i1);
+
+    const __m128 x3i0_3r0_3i1_x3r1 = _mm_castsi128_ps(_mm_shuffle_epi32(
+        _mm_castps_si128(x3r0_3i0_3r1_x3i1), _MM_SHUFFLE(2, 3, 0, 1)));
+    const __m128 x3_swapped = _mm_mul_ps(mm_swap_sign, x3i0_3r0_3i1_x3r1);
+    const __m128 x1_x3_add = _mm_add_ps(x1r0_1i0_1r1_x1i1, x3_swapped);
+    const __m128 x1_x3_sub = _mm_sub_ps(x1r0_1i0_1r1_x1i1, x3_swapped);
+
+    const __m128 yy0 =
+        _mm_shuffle_ps(x1_x3_add, x1_x3_sub, _MM_SHUFFLE(2, 2, 2, 2));
+    const __m128 yy1 =
+        _mm_shuffle_ps(x1_x3_add, x1_x3_sub, _MM_SHUFFLE(3, 3, 3, 3));
+    const __m128 yy2 = _mm_mul_ps(mm_swap_sign, yy1);
+    const __m128 yy3 = _mm_add_ps(yy0, yy2);
+    const __m128 yy4 = _mm_mul_ps(wk1rv, yy3);
+
+    _mm_storel_epi64((__m128i*)&a[j0 + 0], _mm_castps_si128(xx0));
+    _mm_storel_epi64(
+        (__m128i*)&a[j0 + 32],
+        _mm_shuffle_epi32(_mm_castps_si128(xx0), _MM_SHUFFLE(3, 2, 3, 2)));
+
+    _mm_storel_epi64((__m128i*)&a[j0 + 16], _mm_castps_si128(xx1));
+    _mm_storel_epi64(
+        (__m128i*)&a[j0 + 48],
+        _mm_shuffle_epi32(_mm_castps_si128(xx1), _MM_SHUFFLE(2, 3, 2, 3)));
+    a[j0 + 48] = -a[j0 + 48];
+
+    _mm_storel_epi64((__m128i*)&a[j0 + 8], _mm_castps_si128(x1_x3_add));
+    _mm_storel_epi64((__m128i*)&a[j0 + 24], _mm_castps_si128(x1_x3_sub));
+
+    _mm_storel_epi64((__m128i*)&a[j0 + 40], _mm_castps_si128(yy4));
+    _mm_storel_epi64(
+        (__m128i*)&a[j0 + 56],
+        _mm_shuffle_epi32(_mm_castps_si128(yy4), _MM_SHUFFLE(2, 3, 2, 3)));
+  }
+
+  {
+    int k = 64;
+    int k1 = 2;
+    int k2 = 2 * k1;
+    const __m128 wk2rv = _mm_load_ps(&rdft_wk2r[k2 + 0]);
+    const __m128 wk2iv = _mm_load_ps(&rdft_wk2i[k2 + 0]);
+    const __m128 wk1iv = _mm_load_ps(&rdft_wk1i[k2 + 0]);
+    const __m128 wk3rv = _mm_load_ps(&rdft_wk3r[k2 + 0]);
+    const __m128 wk3iv = _mm_load_ps(&rdft_wk3i[k2 + 0]);
+    wk1rv = _mm_load_ps(&rdft_wk1r[k2 + 0]);
+    for (j0 = k; j0 < l + k; j0 += 2) {
+      const __m128i a_00 = _mm_loadl_epi64((__m128i*)&a[j0 + 0]);
+      const __m128i a_08 = _mm_loadl_epi64((__m128i*)&a[j0 + 8]);
+      const __m128i a_32 = _mm_loadl_epi64((__m128i*)&a[j0 + 32]);
+      const __m128i a_40 = _mm_loadl_epi64((__m128i*)&a[j0 + 40]);
+      const __m128 a_00_32 =
+          _mm_shuffle_ps(_mm_castsi128_ps(a_00), _mm_castsi128_ps(a_32),
+                         _MM_SHUFFLE(1, 0, 1, 0));
+      const __m128 a_08_40 =
+          _mm_shuffle_ps(_mm_castsi128_ps(a_08), _mm_castsi128_ps(a_40),
+                         _MM_SHUFFLE(1, 0, 1, 0));
+      __m128 x0r0_0i0_0r1_x0i1 = _mm_add_ps(a_00_32, a_08_40);
+      const __m128 x1r0_1i0_1r1_x1i1 = _mm_sub_ps(a_00_32, a_08_40);
+
+      const __m128i a_16 = _mm_loadl_epi64((__m128i*)&a[j0 + 16]);
+      const __m128i a_24 = _mm_loadl_epi64((__m128i*)&a[j0 + 24]);
+      const __m128i a_48 = _mm_loadl_epi64((__m128i*)&a[j0 + 48]);
+      const __m128i a_56 = _mm_loadl_epi64((__m128i*)&a[j0 + 56]);
+      const __m128 a_16_48 =
+          _mm_shuffle_ps(_mm_castsi128_ps(a_16), _mm_castsi128_ps(a_48),
+                         _MM_SHUFFLE(1, 0, 1, 0));
+      const __m128 a_24_56 =
+          _mm_shuffle_ps(_mm_castsi128_ps(a_24), _mm_castsi128_ps(a_56),
+                         _MM_SHUFFLE(1, 0, 1, 0));
+      const __m128 x2r0_2i0_2r1_x2i1 = _mm_add_ps(a_16_48, a_24_56);
+      const __m128 x3r0_3i0_3r1_x3i1 = _mm_sub_ps(a_16_48, a_24_56);
+
+      const __m128 xx = _mm_add_ps(x0r0_0i0_0r1_x0i1, x2r0_2i0_2r1_x2i1);
+      const __m128 xx1 = _mm_sub_ps(x0r0_0i0_0r1_x0i1, x2r0_2i0_2r1_x2i1);
+      const __m128 xx2 = _mm_mul_ps(xx1, wk2rv);
+      const __m128 xx3 = _mm_mul_ps(
+          wk2iv, _mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(xx1),
+                                                    _MM_SHUFFLE(2, 3, 0, 1))));
+      const __m128 xx4 = _mm_add_ps(xx2, xx3);
+
+      const __m128 x3i0_3r0_3i1_x3r1 = _mm_castsi128_ps(_mm_shuffle_epi32(
+          _mm_castps_si128(x3r0_3i0_3r1_x3i1), _MM_SHUFFLE(2, 3, 0, 1)));
+      const __m128 x3_swapped = _mm_mul_ps(mm_swap_sign, x3i0_3r0_3i1_x3r1);
+      const __m128 x1_x3_add = _mm_add_ps(x1r0_1i0_1r1_x1i1, x3_swapped);
+      const __m128 x1_x3_sub = _mm_sub_ps(x1r0_1i0_1r1_x1i1, x3_swapped);
+
+      const __m128 xx10 = _mm_mul_ps(x1_x3_add, wk1rv);
+      const __m128 xx11 = _mm_mul_ps(
+          wk1iv, _mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(x1_x3_add),
+                                                    _MM_SHUFFLE(2, 3, 0, 1))));
+      const __m128 xx12 = _mm_add_ps(xx10, xx11);
+
+      const __m128 xx20 = _mm_mul_ps(x1_x3_sub, wk3rv);
+      const __m128 xx21 = _mm_mul_ps(
+          wk3iv, _mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(x1_x3_sub),
+                                                    _MM_SHUFFLE(2, 3, 0, 1))));
+      const __m128 xx22 = _mm_add_ps(xx20, xx21);
+
+      _mm_storel_epi64((__m128i*)&a[j0 + 0], _mm_castps_si128(xx));
+      _mm_storel_epi64(
+          (__m128i*)&a[j0 + 32],
+          _mm_shuffle_epi32(_mm_castps_si128(xx), _MM_SHUFFLE(3, 2, 3, 2)));
+
+      _mm_storel_epi64((__m128i*)&a[j0 + 16], _mm_castps_si128(xx4));
+      _mm_storel_epi64(
+          (__m128i*)&a[j0 + 48],
+          _mm_shuffle_epi32(_mm_castps_si128(xx4), _MM_SHUFFLE(3, 2, 3, 2)));
+
+      _mm_storel_epi64((__m128i*)&a[j0 + 8], _mm_castps_si128(xx12));
+      _mm_storel_epi64(
+          (__m128i*)&a[j0 + 40],
+          _mm_shuffle_epi32(_mm_castps_si128(xx12), _MM_SHUFFLE(3, 2, 3, 2)));
+
+      _mm_storel_epi64((__m128i*)&a[j0 + 24], _mm_castps_si128(xx22));
+      _mm_storel_epi64(
+          (__m128i*)&a[j0 + 56],
+          _mm_shuffle_epi32(_mm_castps_si128(xx22), _MM_SHUFFLE(3, 2, 3, 2)));
+    }
+  }
+}
+
+void rftfsub_128_SSE2(float* a) {
+  const float* c = rdft_w + 32;
+  int j1, j2, k1, k2;
+  float wkr, wki, xr, xi, yr, yi;
+
+  static const ALIGN16_BEG float ALIGN16_END k_half[4] = {0.5f, 0.5f, 0.5f,
+                                                          0.5f};
+  const __m128 mm_half = _mm_load_ps(k_half);
+
+  // Vectorized code (four at once).
+  //    Note: commented number are indexes for the first iteration of the loop.
+  for (j1 = 1, j2 = 2; j2 + 7 < 64; j1 += 4, j2 += 8) {
+    // Load 'wk'.
+    const __m128 c_j1 = _mm_loadu_ps(&c[j1]);       //  1,  2,  3,  4,
+    const __m128 c_k1 = _mm_loadu_ps(&c[29 - j1]);  // 28, 29, 30, 31,
+    const __m128 wkrt = _mm_sub_ps(mm_half, c_k1);  // 28, 29, 30, 31,
+    const __m128 wkr_ =
+        _mm_shuffle_ps(wkrt, wkrt, _MM_SHUFFLE(0, 1, 2, 3));  // 31, 30, 29, 28,
+    const __m128 wki_ = c_j1;                                 //  1,  2,  3,  4,
+    // Load and shuffle 'a'.
+    const __m128 a_j2_0 = _mm_loadu_ps(&a[0 + j2]);    //   2,   3,   4,   5,
+    const __m128 a_j2_4 = _mm_loadu_ps(&a[4 + j2]);    //   6,   7,   8,   9,
+    const __m128 a_k2_0 = _mm_loadu_ps(&a[122 - j2]);  // 120, 121, 122, 123,
+    const __m128 a_k2_4 = _mm_loadu_ps(&a[126 - j2]);  // 124, 125, 126, 127,
+    const __m128 a_j2_p0 = _mm_shuffle_ps(
+        a_j2_0, a_j2_4, _MM_SHUFFLE(2, 0, 2, 0));  //   2,   4,   6,   8,
+    const __m128 a_j2_p1 = _mm_shuffle_ps(
+        a_j2_0, a_j2_4, _MM_SHUFFLE(3, 1, 3, 1));  //   3,   5,   7,   9,
+    const __m128 a_k2_p0 = _mm_shuffle_ps(
+        a_k2_4, a_k2_0, _MM_SHUFFLE(0, 2, 0, 2));  // 126, 124, 122, 120,
+    const __m128 a_k2_p1 = _mm_shuffle_ps(
+        a_k2_4, a_k2_0, _MM_SHUFFLE(1, 3, 1, 3));  // 127, 125, 123, 121,
+    // Calculate 'x'.
+    const __m128 xr_ = _mm_sub_ps(a_j2_p0, a_k2_p0);
+    // 2-126, 4-124, 6-122, 8-120,
+    const __m128 xi_ = _mm_add_ps(a_j2_p1, a_k2_p1);
+    // 3-127, 5-125, 7-123, 9-121,
+    // Calculate product into 'y'.
+    //    yr = wkr * xr - wki * xi;
+    //    yi = wkr * xi + wki * xr;
+    const __m128 a_ = _mm_mul_ps(wkr_, xr_);
+    const __m128 b_ = _mm_mul_ps(wki_, xi_);
+    const __m128 c_ = _mm_mul_ps(wkr_, xi_);
+    const __m128 d_ = _mm_mul_ps(wki_, xr_);
+    const __m128 yr_ = _mm_sub_ps(a_, b_);  // 2-126, 4-124, 6-122, 8-120,
+    const __m128 yi_ = _mm_add_ps(c_, d_);  // 3-127, 5-125, 7-123, 9-121,
+                                            // Update 'a'.
+                                            //    a[j2 + 0] -= yr;
+                                            //    a[j2 + 1] -= yi;
+                                            //    a[k2 + 0] += yr;
+    //    a[k2 + 1] -= yi;
+    const __m128 a_j2_p0n = _mm_sub_ps(a_j2_p0, yr_);  //   2,   4,   6,   8,
+    const __m128 a_j2_p1n = _mm_sub_ps(a_j2_p1, yi_);  //   3,   5,   7,   9,
+    const __m128 a_k2_p0n = _mm_add_ps(a_k2_p0, yr_);  // 126, 124, 122, 120,
+    const __m128 a_k2_p1n = _mm_sub_ps(a_k2_p1, yi_);  // 127, 125, 123, 121,
+    // Shuffle in right order and store.
+    const __m128 a_j2_0n = _mm_unpacklo_ps(a_j2_p0n, a_j2_p1n);
+    //   2,   3,   4,   5,
+    const __m128 a_j2_4n = _mm_unpackhi_ps(a_j2_p0n, a_j2_p1n);
+    //   6,   7,   8,   9,
+    const __m128 a_k2_0nt = _mm_unpackhi_ps(a_k2_p0n, a_k2_p1n);
+    // 122, 123, 120, 121,
+    const __m128 a_k2_4nt = _mm_unpacklo_ps(a_k2_p0n, a_k2_p1n);
+    // 126, 127, 124, 125,
+    const __m128 a_k2_0n = _mm_shuffle_ps(
+        a_k2_0nt, a_k2_0nt, _MM_SHUFFLE(1, 0, 3, 2));  // 120, 121, 122, 123,
+    const __m128 a_k2_4n = _mm_shuffle_ps(
+        a_k2_4nt, a_k2_4nt, _MM_SHUFFLE(1, 0, 3, 2));  // 124, 125, 126, 127,
+    _mm_storeu_ps(&a[0 + j2], a_j2_0n);
+    _mm_storeu_ps(&a[4 + j2], a_j2_4n);
+    _mm_storeu_ps(&a[122 - j2], a_k2_0n);
+    _mm_storeu_ps(&a[126 - j2], a_k2_4n);
+  }
+  // Scalar code for the remaining items.
+  for (; j2 < 64; j1 += 1, j2 += 2) {
+    k2 = 128 - j2;
+    k1 = 32 - j1;
+    wkr = 0.5f - c[k1];
+    wki = c[j1];
+    xr = a[j2 + 0] - a[k2 + 0];
+    xi = a[j2 + 1] + a[k2 + 1];
+    yr = wkr * xr - wki * xi;
+    yi = wkr * xi + wki * xr;
+    a[j2 + 0] -= yr;
+    a[j2 + 1] -= yi;
+    a[k2 + 0] += yr;
+    a[k2 + 1] -= yi;
+  }
+}
+
+void rftbsub_128_SSE2(float* a) {
+  const float* c = rdft_w + 32;
+  int j1, j2, k1, k2;
+  float wkr, wki, xr, xi, yr, yi;
+
+  static const ALIGN16_BEG float ALIGN16_END k_half[4] = {0.5f, 0.5f, 0.5f,
+                                                          0.5f};
+  const __m128 mm_half = _mm_load_ps(k_half);
+
+  a[1] = -a[1];
+  // Vectorized code (four at once).
+  //    Note: commented number are indexes for the first iteration of the loop.
+  for (j1 = 1, j2 = 2; j2 + 7 < 64; j1 += 4, j2 += 8) {
+    // Load 'wk'.
+    const __m128 c_j1 = _mm_loadu_ps(&c[j1]);       //  1,  2,  3,  4,
+    const __m128 c_k1 = _mm_loadu_ps(&c[29 - j1]);  // 28, 29, 30, 31,
+    const __m128 wkrt = _mm_sub_ps(mm_half, c_k1);  // 28, 29, 30, 31,
+    const __m128 wkr_ =
+        _mm_shuffle_ps(wkrt, wkrt, _MM_SHUFFLE(0, 1, 2, 3));  // 31, 30, 29, 28,
+    const __m128 wki_ = c_j1;                                 //  1,  2,  3,  4,
+    // Load and shuffle 'a'.
+    const __m128 a_j2_0 = _mm_loadu_ps(&a[0 + j2]);    //   2,   3,   4,   5,
+    const __m128 a_j2_4 = _mm_loadu_ps(&a[4 + j2]);    //   6,   7,   8,   9,
+    const __m128 a_k2_0 = _mm_loadu_ps(&a[122 - j2]);  // 120, 121, 122, 123,
+    const __m128 a_k2_4 = _mm_loadu_ps(&a[126 - j2]);  // 124, 125, 126, 127,
+    const __m128 a_j2_p0 = _mm_shuffle_ps(
+        a_j2_0, a_j2_4, _MM_SHUFFLE(2, 0, 2, 0));  //   2,   4,   6,   8,
+    const __m128 a_j2_p1 = _mm_shuffle_ps(
+        a_j2_0, a_j2_4, _MM_SHUFFLE(3, 1, 3, 1));  //   3,   5,   7,   9,
+    const __m128 a_k2_p0 = _mm_shuffle_ps(
+        a_k2_4, a_k2_0, _MM_SHUFFLE(0, 2, 0, 2));  // 126, 124, 122, 120,
+    const __m128 a_k2_p1 = _mm_shuffle_ps(
+        a_k2_4, a_k2_0, _MM_SHUFFLE(1, 3, 1, 3));  // 127, 125, 123, 121,
+    // Calculate 'x'.
+    const __m128 xr_ = _mm_sub_ps(a_j2_p0, a_k2_p0);
+    // 2-126, 4-124, 6-122, 8-120,
+    const __m128 xi_ = _mm_add_ps(a_j2_p1, a_k2_p1);
+    // 3-127, 5-125, 7-123, 9-121,
+    // Calculate product into 'y'.
+    //    yr = wkr * xr + wki * xi;
+    //    yi = wkr * xi - wki * xr;
+    const __m128 a_ = _mm_mul_ps(wkr_, xr_);
+    const __m128 b_ = _mm_mul_ps(wki_, xi_);
+    const __m128 c_ = _mm_mul_ps(wkr_, xi_);
+    const __m128 d_ = _mm_mul_ps(wki_, xr_);
+    const __m128 yr_ = _mm_add_ps(a_, b_);  // 2-126, 4-124, 6-122, 8-120,
+    const __m128 yi_ = _mm_sub_ps(c_, d_);  // 3-127, 5-125, 7-123, 9-121,
+                                            // Update 'a'.
+                                            //    a[j2 + 0] = a[j2 + 0] - yr;
+                                            //    a[j2 + 1] = yi - a[j2 + 1];
+                                            //    a[k2 + 0] = yr + a[k2 + 0];
+    //    a[k2 + 1] = yi - a[k2 + 1];
+    const __m128 a_j2_p0n = _mm_sub_ps(a_j2_p0, yr_);  //   2,   4,   6,   8,
+    const __m128 a_j2_p1n = _mm_sub_ps(yi_, a_j2_p1);  //   3,   5,   7,   9,
+    const __m128 a_k2_p0n = _mm_add_ps(a_k2_p0, yr_);  // 126, 124, 122, 120,
+    const __m128 a_k2_p1n = _mm_sub_ps(yi_, a_k2_p1);  // 127, 125, 123, 121,
+    // Shuffle in right order and store.
+    const __m128 a_j2_0n = _mm_unpacklo_ps(a_j2_p0n, a_j2_p1n);
+    //   2,   3,   4,   5,
+    const __m128 a_j2_4n = _mm_unpackhi_ps(a_j2_p0n, a_j2_p1n);
+    //   6,   7,   8,   9,
+    const __m128 a_k2_0nt = _mm_unpackhi_ps(a_k2_p0n, a_k2_p1n);
+    // 122, 123, 120, 121,
+    const __m128 a_k2_4nt = _mm_unpacklo_ps(a_k2_p0n, a_k2_p1n);
+    // 126, 127, 124, 125,
+    const __m128 a_k2_0n = _mm_shuffle_ps(
+        a_k2_0nt, a_k2_0nt, _MM_SHUFFLE(1, 0, 3, 2));  // 120, 121, 122, 123,
+    const __m128 a_k2_4n = _mm_shuffle_ps(
+        a_k2_4nt, a_k2_4nt, _MM_SHUFFLE(1, 0, 3, 2));  // 124, 125, 126, 127,
+    _mm_storeu_ps(&a[0 + j2], a_j2_0n);
+    _mm_storeu_ps(&a[4 + j2], a_j2_4n);
+    _mm_storeu_ps(&a[122 - j2], a_k2_0n);
+    _mm_storeu_ps(&a[126 - j2], a_k2_4n);
+  }
+  // Scalar code for the remaining items.
+  for (; j2 < 64; j1 += 1, j2 += 2) {
+    k2 = 128 - j2;
+    k1 = 32 - j1;
+    wkr = 0.5f - c[k1];
+    wki = c[j1];
+    xr = a[j2 + 0] - a[k2 + 0];
+    xi = a[j2 + 1] + a[k2 + 1];
+    yr = wkr * xr + wki * xi;
+    yi = wkr * xi - wki * xr;
+    a[j2 + 0] = a[j2 + 0] - yr;
+    a[j2 + 1] = yi - a[j2 + 1];
+    a[k2 + 0] = yr + a[k2 + 0];
+    a[k2 + 1] = yi - a[k2 + 1];
+  }
+  a[65] = -a[65];
+}
+#endif
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft_tables_common.h b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft_tables_common.h
new file mode 100644
index 0000000..6db1dd9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft_tables_common.h
@@ -0,0 +1,54 @@
+/*
+ *  Copyright (c) 2011 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_UTILITY_OOURA_FFT_TABLES_COMMON_H_
+#define MODULES_AUDIO_PROCESSING_UTILITY_OOURA_FFT_TABLES_COMMON_H_
+
+#include "common_audio/third_party/ooura/fft_size_128/ooura_fft.h"
+
+namespace webrtc {
+
+// This tables used to be computed at run-time. For example, refer to:
+// https://code.google.com/p/webrtc/source/browse/trunk/webrtc/modules/audio_processing/utility/apm_rdft.c?r=6564
+// to see the initialization code.
+// Constants shared by all paths (C, SSE2, NEON).
+const float rdft_w[64] = {
+    1.0000000000f, 0.0000000000f, 0.7071067691f, 0.7071067691f, 0.9238795638f,
+    0.3826834559f, 0.3826834559f, 0.9238795638f, 0.9807852507f, 0.1950903237f,
+    0.5555702448f, 0.8314695954f, 0.8314695954f, 0.5555702448f, 0.1950903237f,
+    0.9807852507f, 0.9951847196f, 0.0980171412f, 0.6343933344f, 0.7730104327f,
+    0.8819212914f, 0.4713967443f, 0.2902846634f, 0.9569403529f, 0.9569403529f,
+    0.2902846634f, 0.4713967443f, 0.8819212914f, 0.7730104327f, 0.6343933344f,
+    0.0980171412f, 0.9951847196f, 0.7071067691f, 0.4993977249f, 0.4975923598f,
+    0.4945882559f, 0.4903926253f, 0.4850156307f, 0.4784701765f, 0.4707720280f,
+    0.4619397819f, 0.4519946277f, 0.4409606457f, 0.4288643003f, 0.4157347977f,
+    0.4016037583f, 0.3865052164f, 0.3704755902f, 0.3535533845f, 0.3357794881f,
+    0.3171966672f, 0.2978496552f, 0.2777851224f, 0.2570513785f, 0.2356983721f,
+    0.2137775421f, 0.1913417280f, 0.1684449315f, 0.1451423317f, 0.1214900985f,
+    0.0975451618f, 0.0733652338f, 0.0490085706f, 0.0245338380f,
+};
+
+// Constants used by the C and MIPS paths.
+const float rdft_wk3ri_first[16] = {
+    1.000000000f, 0.000000000f, 0.382683456f,  0.923879564f,
+    0.831469536f, 0.555570245f, -0.195090353f, 0.980785251f,
+    0.956940353f, 0.290284693f, 0.098017156f,  0.995184720f,
+    0.634393334f, 0.773010492f, -0.471396863f, 0.881921172f,
+};
+const float rdft_wk3ri_second[16] = {
+    -0.707106769f, 0.707106769f,  -0.923879564f, -0.382683456f,
+    -0.980785251f, 0.195090353f,  -0.555570245f, -0.831469536f,
+    -0.881921172f, 0.471396863f,  -0.773010492f, -0.634393334f,
+    -0.995184720f, -0.098017156f, -0.290284693f, -0.956940353f,
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_UTILITY_OOURA_FFT_TABLES_COMMON_H_
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft_tables_neon_sse2.h b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft_tables_neon_sse2.h
new file mode 100644
index 0000000..a63d187
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_128/ooura_fft_tables_neon_sse2.h
@@ -0,0 +1,98 @@
+/*
+ *  Copyright (c) 2011 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_UTILITY_OOURA_FFT_TABLES_NEON_SSE2_H_
+#define MODULES_AUDIO_PROCESSING_UTILITY_OOURA_FFT_TABLES_NEON_SSE2_H_
+
+#include "common_audio/third_party/ooura/fft_size_128/ooura_fft.h"
+#include "rtc_base/system/arch.h"
+
+#ifdef _MSC_VER /* visual c++ */
+#define ALIGN16_BEG __declspec(align(16))
+#define ALIGN16_END
+#else /* gcc or icc */
+#define ALIGN16_BEG
+#define ALIGN16_END __attribute__((aligned(16)))
+#endif
+
+namespace webrtc {
+
+// These tables used to be computed at run-time. For example, refer to:
+// https://code.google.com/p/webrtc/source/browse/trunk/webrtc/modules/audio_processing/utility/apm_rdft.c?r=6564
+// to see the initialization code.
+#if defined(WEBRTC_ARCH_X86_FAMILY) || defined(WEBRTC_HAS_NEON)
+// Constants used by SSE2 and NEON but initialized in the C path.
+const ALIGN16_BEG float ALIGN16_END k_swap_sign[4] = {-1.f, 1.f, -1.f, 1.f};
+
+ALIGN16_BEG const float ALIGN16_END rdft_wk1r[32] = {
+    1.000000000f, 1.000000000f, 0.707106769f, 0.707106769f, 0.923879564f,
+    0.923879564f, 0.382683456f, 0.382683456f, 0.980785251f, 0.980785251f,
+    0.555570245f, 0.555570245f, 0.831469595f, 0.831469595f, 0.195090324f,
+    0.195090324f, 0.995184720f, 0.995184720f, 0.634393334f, 0.634393334f,
+    0.881921291f, 0.881921291f, 0.290284663f, 0.290284663f, 0.956940353f,
+    0.956940353f, 0.471396744f, 0.471396744f, 0.773010433f, 0.773010433f,
+    0.098017141f, 0.098017141f,
+};
+ALIGN16_BEG const float ALIGN16_END rdft_wk2r[32] = {
+    1.000000000f,  1.000000000f,  -0.000000000f, -0.000000000f, 0.707106769f,
+    0.707106769f,  -0.707106769f, -0.707106769f, 0.923879564f,  0.923879564f,
+    -0.382683456f, -0.382683456f, 0.382683456f,  0.382683456f,  -0.923879564f,
+    -0.923879564f, 0.980785251f,  0.980785251f,  -0.195090324f, -0.195090324f,
+    0.555570245f,  0.555570245f,  -0.831469595f, -0.831469595f, 0.831469595f,
+    0.831469595f,  -0.555570245f, -0.555570245f, 0.195090324f,  0.195090324f,
+    -0.980785251f, -0.980785251f,
+};
+ALIGN16_BEG const float ALIGN16_END rdft_wk3r[32] = {
+    1.000000000f,  1.000000000f,  -0.707106769f, -0.707106769f, 0.382683456f,
+    0.382683456f,  -0.923879564f, -0.923879564f, 0.831469536f,  0.831469536f,
+    -0.980785251f, -0.980785251f, -0.195090353f, -0.195090353f, -0.555570245f,
+    -0.555570245f, 0.956940353f,  0.956940353f,  -0.881921172f, -0.881921172f,
+    0.098017156f,  0.098017156f,  -0.773010492f, -0.773010492f, 0.634393334f,
+    0.634393334f,  -0.995184720f, -0.995184720f, -0.471396863f, -0.471396863f,
+    -0.290284693f, -0.290284693f,
+};
+ALIGN16_BEG const float ALIGN16_END rdft_wk1i[32] = {
+    -0.000000000f, 0.000000000f,  -0.707106769f, 0.707106769f,  -0.382683456f,
+    0.382683456f,  -0.923879564f, 0.923879564f,  -0.195090324f, 0.195090324f,
+    -0.831469595f, 0.831469595f,  -0.555570245f, 0.555570245f,  -0.980785251f,
+    0.980785251f,  -0.098017141f, 0.098017141f,  -0.773010433f, 0.773010433f,
+    -0.471396744f, 0.471396744f,  -0.956940353f, 0.956940353f,  -0.290284663f,
+    0.290284663f,  -0.881921291f, 0.881921291f,  -0.634393334f, 0.634393334f,
+    -0.995184720f, 0.995184720f,
+};
+ALIGN16_BEG const float ALIGN16_END rdft_wk2i[32] = {
+    -0.000000000f, 0.000000000f,  -1.000000000f, 1.000000000f,  -0.707106769f,
+    0.707106769f,  -0.707106769f, 0.707106769f,  -0.382683456f, 0.382683456f,
+    -0.923879564f, 0.923879564f,  -0.923879564f, 0.923879564f,  -0.382683456f,
+    0.382683456f,  -0.195090324f, 0.195090324f,  -0.980785251f, 0.980785251f,
+    -0.831469595f, 0.831469595f,  -0.555570245f, 0.555570245f,  -0.555570245f,
+    0.555570245f,  -0.831469595f, 0.831469595f,  -0.980785251f, 0.980785251f,
+    -0.195090324f, 0.195090324f,
+};
+ALIGN16_BEG const float ALIGN16_END rdft_wk3i[32] = {
+    -0.000000000f, 0.000000000f,  -0.707106769f, 0.707106769f,  -0.923879564f,
+    0.923879564f,  0.382683456f,  -0.382683456f, -0.555570245f, 0.555570245f,
+    -0.195090353f, 0.195090353f,  -0.980785251f, 0.980785251f,  0.831469536f,
+    -0.831469536f, -0.290284693f, 0.290284693f,  -0.471396863f, 0.471396863f,
+    -0.995184720f, 0.995184720f,  0.634393334f,  -0.634393334f, -0.773010492f,
+    0.773010492f,  0.098017156f,  -0.098017156f, -0.881921172f, 0.881921172f,
+    0.956940353f,  -0.956940353f,
+};
+ALIGN16_BEG const float ALIGN16_END cftmdl_wk1r[4] = {
+    0.707106769f,
+    0.707106769f,
+    0.707106769f,
+    -0.707106769f,
+};
+#endif
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_UTILITY_OOURA_FFT_TABLES_NEON_SSE2_H_
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_256/fft4g.cc b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_256/fft4g.cc
new file mode 100644
index 0000000..d2f7c1c
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_256/fft4g.cc
@@ -0,0 +1,866 @@
+/*
+ * http://www.kurims.kyoto-u.ac.jp/~ooura/fft.html
+ * Copyright Takuya OOURA, 1996-2001
+ *
+ * You may use, copy, modify and distribute this code for any purpose (include
+ * commercial use) and without fee. Please refer to this package when you modify
+ * this code.
+ *
+ * Changes:
+ * Trivial type modifications by the WebRTC authors.
+ */
+
+/*
+Fast Fourier/Cosine/Sine Transform
+    dimension   :one
+    data length :power of 2
+    decimation  :frequency
+    radix       :4, 2
+    data        :inplace
+    table       :use
+functions
+    cdft: Complex Discrete Fourier Transform
+    rdft: Real Discrete Fourier Transform
+    ddct: Discrete Cosine Transform
+    ddst: Discrete Sine Transform
+    dfct: Cosine Transform of RDFT (Real Symmetric DFT)
+    dfst: Sine Transform of RDFT (Real Anti-symmetric DFT)
+function prototypes
+    void cdft(int, int, float *, int *, float *);
+    void rdft(size_t, int, float *, size_t *, float *);
+    void ddct(int, int, float *, int *, float *);
+    void ddst(int, int, float *, int *, float *);
+    void dfct(int, float *, float *, int *, float *);
+    void dfst(int, float *, float *, int *, float *);
+
+
+-------- Complex DFT (Discrete Fourier Transform) --------
+    [definition]
+        <case1>
+            X[k] = sum_j=0^n-1 x[j]*exp(2*pi*i*j*k/n), 0<=k<n
+        <case2>
+            X[k] = sum_j=0^n-1 x[j]*exp(-2*pi*i*j*k/n), 0<=k<n
+        (notes: sum_j=0^n-1 is a summation from j=0 to n-1)
+    [usage]
+        <case1>
+            ip[0] = 0; // first time only
+            cdft(2*n, 1, a, ip, w);
+        <case2>
+            ip[0] = 0; // first time only
+            cdft(2*n, -1, a, ip, w);
+    [parameters]
+        2*n            :data length (int)
+                        n >= 1, n = power of 2
+        a[0...2*n-1]   :input/output data (float *)
+                        input data
+                            a[2*j] = Re(x[j]),
+                            a[2*j+1] = Im(x[j]), 0<=j<n
+                        output data
+                            a[2*k] = Re(X[k]),
+                            a[2*k+1] = Im(X[k]), 0<=k<n
+        ip[0...*]      :work area for bit reversal (int *)
+                        length of ip >= 2+sqrt(n)
+                        strictly,
+                        length of ip >=
+                            2+(1<<(int)(log(n+0.5)/log(2))/2).
+                        ip[0],ip[1] are pointers of the cos/sin table.
+        w[0...n/2-1]   :cos/sin table (float *)
+                        w[],ip[] are initialized if ip[0] == 0.
+    [remark]
+        Inverse of
+            cdft(2*n, -1, a, ip, w);
+        is
+            cdft(2*n, 1, a, ip, w);
+            for (j = 0; j <= 2 * n - 1; j++) {
+                a[j] *= 1.0 / n;
+            }
+        .
+
+
+-------- Real DFT / Inverse of Real DFT --------
+    [definition]
+        <case1> RDFT
+            R[k] = sum_j=0^n-1 a[j]*cos(2*pi*j*k/n), 0<=k<=n/2
+            I[k] = sum_j=0^n-1 a[j]*sin(2*pi*j*k/n), 0<k<n/2
+        <case2> IRDFT (excluding scale)
+            a[k] = (R[0] + R[n/2]*cos(pi*k))/2 +
+                   sum_j=1^n/2-1 R[j]*cos(2*pi*j*k/n) +
+                   sum_j=1^n/2-1 I[j]*sin(2*pi*j*k/n), 0<=k<n
+    [usage]
+        <case1>
+            ip[0] = 0; // first time only
+            rdft(n, 1, a, ip, w);
+        <case2>
+            ip[0] = 0; // first time only
+            rdft(n, -1, a, ip, w);
+    [parameters]
+        n              :data length (size_t)
+                        n >= 2, n = power of 2
+        a[0...n-1]     :input/output data (float *)
+                        <case1>
+                            output data
+                                a[2*k] = R[k], 0<=k<n/2
+                                a[2*k+1] = I[k], 0<k<n/2
+                                a[1] = R[n/2]
+                        <case2>
+                            input data
+                                a[2*j] = R[j], 0<=j<n/2
+                                a[2*j+1] = I[j], 0<j<n/2
+                                a[1] = R[n/2]
+        ip[0...*]      :work area for bit reversal (size_t *)
+                        length of ip >= 2+sqrt(n/2)
+                        strictly,
+                        length of ip >=
+                            2+(1<<(int)(log(n/2+0.5)/log(2))/2).
+                        ip[0],ip[1] are pointers of the cos/sin table.
+        w[0...n/2-1]   :cos/sin table (float *)
+                        w[],ip[] are initialized if ip[0] == 0.
+    [remark]
+        Inverse of
+            rdft(n, 1, a, ip, w);
+        is
+            rdft(n, -1, a, ip, w);
+            for (j = 0; j <= n - 1; j++) {
+                a[j] *= 2.0 / n;
+            }
+        .
+
+
+-------- DCT (Discrete Cosine Transform) / Inverse of DCT --------
+    [definition]
+        <case1> IDCT (excluding scale)
+            C[k] = sum_j=0^n-1 a[j]*cos(pi*j*(k+1/2)/n), 0<=k<n
+        <case2> DCT
+            C[k] = sum_j=0^n-1 a[j]*cos(pi*(j+1/2)*k/n), 0<=k<n
+    [usage]
+        <case1>
+            ip[0] = 0; // first time only
+            ddct(n, 1, a, ip, w);
+        <case2>
+            ip[0] = 0; // first time only
+            ddct(n, -1, a, ip, w);
+    [parameters]
+        n              :data length (int)
+                        n >= 2, n = power of 2
+        a[0...n-1]     :input/output data (float *)
+                        output data
+                            a[k] = C[k], 0<=k<n
+        ip[0...*]      :work area for bit reversal (int *)
+                        length of ip >= 2+sqrt(n/2)
+                        strictly,
+                        length of ip >=
+                            2+(1<<(int)(log(n/2+0.5)/log(2))/2).
+                        ip[0],ip[1] are pointers of the cos/sin table.
+        w[0...n*5/4-1] :cos/sin table (float *)
+                        w[],ip[] are initialized if ip[0] == 0.
+    [remark]
+        Inverse of
+            ddct(n, -1, a, ip, w);
+        is
+            a[0] *= 0.5;
+            ddct(n, 1, a, ip, w);
+            for (j = 0; j <= n - 1; j++) {
+                a[j] *= 2.0 / n;
+            }
+        .
+
+
+-------- DST (Discrete Sine Transform) / Inverse of DST --------
+    [definition]
+        <case1> IDST (excluding scale)
+            S[k] = sum_j=1^n A[j]*sin(pi*j*(k+1/2)/n), 0<=k<n
+        <case2> DST
+            S[k] = sum_j=0^n-1 a[j]*sin(pi*(j+1/2)*k/n), 0<k<=n
+    [usage]
+        <case1>
+            ip[0] = 0; // first time only
+            ddst(n, 1, a, ip, w);
+        <case2>
+            ip[0] = 0; // first time only
+            ddst(n, -1, a, ip, w);
+    [parameters]
+        n              :data length (int)
+                        n >= 2, n = power of 2
+        a[0...n-1]     :input/output data (float *)
+                        <case1>
+                            input data
+                                a[j] = A[j], 0<j<n
+                                a[0] = A[n]
+                            output data
+                                a[k] = S[k], 0<=k<n
+                        <case2>
+                            output data
+                                a[k] = S[k], 0<k<n
+                                a[0] = S[n]
+        ip[0...*]      :work area for bit reversal (int *)
+                        length of ip >= 2+sqrt(n/2)
+                        strictly,
+                        length of ip >=
+                            2+(1<<(int)(log(n/2+0.5)/log(2))/2).
+                        ip[0],ip[1] are pointers of the cos/sin table.
+        w[0...n*5/4-1] :cos/sin table (float *)
+                        w[],ip[] are initialized if ip[0] == 0.
+    [remark]
+        Inverse of
+            ddst(n, -1, a, ip, w);
+        is
+            a[0] *= 0.5;
+            ddst(n, 1, a, ip, w);
+            for (j = 0; j <= n - 1; j++) {
+                a[j] *= 2.0 / n;
+            }
+        .
+
+
+-------- Cosine Transform of RDFT (Real Symmetric DFT) --------
+    [definition]
+        C[k] = sum_j=0^n a[j]*cos(pi*j*k/n), 0<=k<=n
+    [usage]
+        ip[0] = 0; // first time only
+        dfct(n, a, t, ip, w);
+    [parameters]
+        n              :data length - 1 (int)
+                        n >= 2, n = power of 2
+        a[0...n]       :input/output data (float *)
+                        output data
+                            a[k] = C[k], 0<=k<=n
+        t[0...n/2]     :work area (float *)
+        ip[0...*]      :work area for bit reversal (int *)
+                        length of ip >= 2+sqrt(n/4)
+                        strictly,
+                        length of ip >=
+                            2+(1<<(int)(log(n/4+0.5)/log(2))/2).
+                        ip[0],ip[1] are pointers of the cos/sin table.
+        w[0...n*5/8-1] :cos/sin table (float *)
+                        w[],ip[] are initialized if ip[0] == 0.
+    [remark]
+        Inverse of
+            a[0] *= 0.5;
+            a[n] *= 0.5;
+            dfct(n, a, t, ip, w);
+        is
+            a[0] *= 0.5;
+            a[n] *= 0.5;
+            dfct(n, a, t, ip, w);
+            for (j = 0; j <= n; j++) {
+                a[j] *= 2.0 / n;
+            }
+        .
+
+
+-------- Sine Transform of RDFT (Real Anti-symmetric DFT) --------
+    [definition]
+        S[k] = sum_j=1^n-1 a[j]*sin(pi*j*k/n), 0<k<n
+    [usage]
+        ip[0] = 0; // first time only
+        dfst(n, a, t, ip, w);
+    [parameters]
+        n              :data length + 1 (int)
+                        n >= 2, n = power of 2
+        a[0...n-1]     :input/output data (float *)
+                        output data
+                            a[k] = S[k], 0<k<n
+                        (a[0] is used for work area)
+        t[0...n/2-1]   :work area (float *)
+        ip[0...*]      :work area for bit reversal (int *)
+                        length of ip >= 2+sqrt(n/4)
+                        strictly,
+                        length of ip >=
+                            2+(1<<(int)(log(n/4+0.5)/log(2))/2).
+                        ip[0],ip[1] are pointers of the cos/sin table.
+        w[0...n*5/8-1] :cos/sin table (float *)
+                        w[],ip[] are initialized if ip[0] == 0.
+    [remark]
+        Inverse of
+            dfst(n, a, t, ip, w);
+        is
+            dfst(n, a, t, ip, w);
+            for (j = 1; j <= n - 1; j++) {
+                a[j] *= 2.0 / n;
+            }
+        .
+
+
+Appendix :
+    The cos/sin table is recalculated when the larger table required.
+    w[] and ip[] are compatible with all routines.
+*/
+
+#include <math.h>
+#include <stddef.h>
+
+#include "common_audio/third_party/ooura/fft_size_256/fft4g.h"
+
+namespace webrtc {
+
+namespace {
+
+void makewt(size_t nw, size_t* ip, float* w);
+void makect(size_t nc, size_t* ip, float* c);
+void bitrv2(size_t n, size_t* ip, float* a);
+void cftfsub(size_t n, float* a, float* w);
+void cftbsub(size_t n, float* a, float* w);
+void cft1st(size_t n, float* a, float* w);
+void cftmdl(size_t n, size_t l, float* a, float* w);
+void rftfsub(size_t n, float* a, size_t nc, float* c);
+void rftbsub(size_t n, float* a, size_t nc, float* c);
+
+/* -------- initializing routines -------- */
+
+void makewt(size_t nw, size_t* ip, float* w) {
+  size_t j, nwh;
+  float delta, x, y;
+
+  ip[0] = nw;
+  ip[1] = 1;
+  if (nw > 2) {
+    nwh = nw >> 1;
+    delta = atanf(1.0f) / nwh;
+    w[0] = 1;
+    w[1] = 0;
+    w[nwh] = (float)cos(delta * nwh);
+    w[nwh + 1] = w[nwh];
+    if (nwh > 2) {
+      for (j = 2; j < nwh; j += 2) {
+        x = (float)cos(delta * j);
+        y = (float)sin(delta * j);
+        w[j] = x;
+        w[j + 1] = y;
+        w[nw - j] = y;
+        w[nw - j + 1] = x;
+      }
+      bitrv2(nw, ip + 2, w);
+    }
+  }
+}
+
+void makect(size_t nc, size_t* ip, float* c) {
+  size_t j, nch;
+  float delta;
+
+  ip[1] = nc;
+  if (nc > 1) {
+    nch = nc >> 1;
+    delta = atanf(1.0f) / nch;
+    c[0] = (float)cos(delta * nch);
+    c[nch] = 0.5f * c[0];
+    for (j = 1; j < nch; j++) {
+      c[j] = 0.5f * (float)cos(delta * j);
+      c[nc - j] = 0.5f * (float)sin(delta * j);
+    }
+  }
+}
+
+/* -------- child routines -------- */
+
+void bitrv2(size_t n, size_t* ip, float* a) {
+  size_t j, j1, k, k1, l, m, m2;
+  float xr, xi, yr, yi;
+
+  ip[0] = 0;
+  l = n;
+  m = 1;
+  while ((m << 3) < l) {
+    l >>= 1;
+    for (j = 0; j < m; j++) {
+      ip[m + j] = ip[j] + l;
+    }
+    m <<= 1;
+  }
+  m2 = 2 * m;
+  if ((m << 3) == l) {
+    for (k = 0; k < m; k++) {
+      for (j = 0; j < k; j++) {
+        j1 = 2 * j + ip[k];
+        k1 = 2 * k + ip[j];
+        xr = a[j1];
+        xi = a[j1 + 1];
+        yr = a[k1];
+        yi = a[k1 + 1];
+        a[j1] = yr;
+        a[j1 + 1] = yi;
+        a[k1] = xr;
+        a[k1 + 1] = xi;
+        j1 += m2;
+        k1 += 2 * m2;
+        xr = a[j1];
+        xi = a[j1 + 1];
+        yr = a[k1];
+        yi = a[k1 + 1];
+        a[j1] = yr;
+        a[j1 + 1] = yi;
+        a[k1] = xr;
+        a[k1 + 1] = xi;
+        j1 += m2;
+        k1 -= m2;
+        xr = a[j1];
+        xi = a[j1 + 1];
+        yr = a[k1];
+        yi = a[k1 + 1];
+        a[j1] = yr;
+        a[j1 + 1] = yi;
+        a[k1] = xr;
+        a[k1 + 1] = xi;
+        j1 += m2;
+        k1 += 2 * m2;
+        xr = a[j1];
+        xi = a[j1 + 1];
+        yr = a[k1];
+        yi = a[k1 + 1];
+        a[j1] = yr;
+        a[j1 + 1] = yi;
+        a[k1] = xr;
+        a[k1 + 1] = xi;
+      }
+      j1 = 2 * k + m2 + ip[k];
+      k1 = j1 + m2;
+      xr = a[j1];
+      xi = a[j1 + 1];
+      yr = a[k1];
+      yi = a[k1 + 1];
+      a[j1] = yr;
+      a[j1 + 1] = yi;
+      a[k1] = xr;
+      a[k1 + 1] = xi;
+    }
+  } else {
+    for (k = 1; k < m; k++) {
+      for (j = 0; j < k; j++) {
+        j1 = 2 * j + ip[k];
+        k1 = 2 * k + ip[j];
+        xr = a[j1];
+        xi = a[j1 + 1];
+        yr = a[k1];
+        yi = a[k1 + 1];
+        a[j1] = yr;
+        a[j1 + 1] = yi;
+        a[k1] = xr;
+        a[k1 + 1] = xi;
+        j1 += m2;
+        k1 += m2;
+        xr = a[j1];
+        xi = a[j1 + 1];
+        yr = a[k1];
+        yi = a[k1 + 1];
+        a[j1] = yr;
+        a[j1 + 1] = yi;
+        a[k1] = xr;
+        a[k1 + 1] = xi;
+      }
+    }
+  }
+}
+
+void cftfsub(size_t n, float* a, float* w) {
+  size_t j, j1, j2, j3, l;
+  float x0r, x0i, x1r, x1i, x2r, x2i, x3r, x3i;
+
+  l = 2;
+  if (n > 8) {
+    cft1st(n, a, w);
+    l = 8;
+    while ((l << 2) < n) {
+      cftmdl(n, l, a, w);
+      l <<= 2;
+    }
+  }
+  if ((l << 2) == n) {
+    for (j = 0; j < l; j += 2) {
+      j1 = j + l;
+      j2 = j1 + l;
+      j3 = j2 + l;
+      x0r = a[j] + a[j1];
+      x0i = a[j + 1] + a[j1 + 1];
+      x1r = a[j] - a[j1];
+      x1i = a[j + 1] - a[j1 + 1];
+      x2r = a[j2] + a[j3];
+      x2i = a[j2 + 1] + a[j3 + 1];
+      x3r = a[j2] - a[j3];
+      x3i = a[j2 + 1] - a[j3 + 1];
+      a[j] = x0r + x2r;
+      a[j + 1] = x0i + x2i;
+      a[j2] = x0r - x2r;
+      a[j2 + 1] = x0i - x2i;
+      a[j1] = x1r - x3i;
+      a[j1 + 1] = x1i + x3r;
+      a[j3] = x1r + x3i;
+      a[j3 + 1] = x1i - x3r;
+    }
+  } else {
+    for (j = 0; j < l; j += 2) {
+      j1 = j + l;
+      x0r = a[j] - a[j1];
+      x0i = a[j + 1] - a[j1 + 1];
+      a[j] += a[j1];
+      a[j + 1] += a[j1 + 1];
+      a[j1] = x0r;
+      a[j1 + 1] = x0i;
+    }
+  }
+}
+
+void cftbsub(size_t n, float* a, float* w) {
+  size_t j, j1, j2, j3, l;
+  float x0r, x0i, x1r, x1i, x2r, x2i, x3r, x3i;
+
+  l = 2;
+  if (n > 8) {
+    cft1st(n, a, w);
+    l = 8;
+    while ((l << 2) < n) {
+      cftmdl(n, l, a, w);
+      l <<= 2;
+    }
+  }
+  if ((l << 2) == n) {
+    for (j = 0; j < l; j += 2) {
+      j1 = j + l;
+      j2 = j1 + l;
+      j3 = j2 + l;
+      x0r = a[j] + a[j1];
+      x0i = -a[j + 1] - a[j1 + 1];
+      x1r = a[j] - a[j1];
+      x1i = -a[j + 1] + a[j1 + 1];
+      x2r = a[j2] + a[j3];
+      x2i = a[j2 + 1] + a[j3 + 1];
+      x3r = a[j2] - a[j3];
+      x3i = a[j2 + 1] - a[j3 + 1];
+      a[j] = x0r + x2r;
+      a[j + 1] = x0i - x2i;
+      a[j2] = x0r - x2r;
+      a[j2 + 1] = x0i + x2i;
+      a[j1] = x1r - x3i;
+      a[j1 + 1] = x1i - x3r;
+      a[j3] = x1r + x3i;
+      a[j3 + 1] = x1i + x3r;
+    }
+  } else {
+    for (j = 0; j < l; j += 2) {
+      j1 = j + l;
+      x0r = a[j] - a[j1];
+      x0i = -a[j + 1] + a[j1 + 1];
+      a[j] += a[j1];
+      a[j + 1] = -a[j + 1] - a[j1 + 1];
+      a[j1] = x0r;
+      a[j1 + 1] = x0i;
+    }
+  }
+}
+
+void cft1st(size_t n, float* a, float* w) {
+  size_t j, k1, k2;
+  float wk1r, wk1i, wk2r, wk2i, wk3r, wk3i;
+  float x0r, x0i, x1r, x1i, x2r, x2i, x3r, x3i;
+
+  x0r = a[0] + a[2];
+  x0i = a[1] + a[3];
+  x1r = a[0] - a[2];
+  x1i = a[1] - a[3];
+  x2r = a[4] + a[6];
+  x2i = a[5] + a[7];
+  x3r = a[4] - a[6];
+  x3i = a[5] - a[7];
+  a[0] = x0r + x2r;
+  a[1] = x0i + x2i;
+  a[4] = x0r - x2r;
+  a[5] = x0i - x2i;
+  a[2] = x1r - x3i;
+  a[3] = x1i + x3r;
+  a[6] = x1r + x3i;
+  a[7] = x1i - x3r;
+  wk1r = w[2];
+  x0r = a[8] + a[10];
+  x0i = a[9] + a[11];
+  x1r = a[8] - a[10];
+  x1i = a[9] - a[11];
+  x2r = a[12] + a[14];
+  x2i = a[13] + a[15];
+  x3r = a[12] - a[14];
+  x3i = a[13] - a[15];
+  a[8] = x0r + x2r;
+  a[9] = x0i + x2i;
+  a[12] = x2i - x0i;
+  a[13] = x0r - x2r;
+  x0r = x1r - x3i;
+  x0i = x1i + x3r;
+  a[10] = wk1r * (x0r - x0i);
+  a[11] = wk1r * (x0r + x0i);
+  x0r = x3i + x1r;
+  x0i = x3r - x1i;
+  a[14] = wk1r * (x0i - x0r);
+  a[15] = wk1r * (x0i + x0r);
+  k1 = 0;
+  for (j = 16; j < n; j += 16) {
+    k1 += 2;
+    k2 = 2 * k1;
+    wk2r = w[k1];
+    wk2i = w[k1 + 1];
+    wk1r = w[k2];
+    wk1i = w[k2 + 1];
+    wk3r = wk1r - 2 * wk2i * wk1i;
+    wk3i = 2 * wk2i * wk1r - wk1i;
+    x0r = a[j] + a[j + 2];
+    x0i = a[j + 1] + a[j + 3];
+    x1r = a[j] - a[j + 2];
+    x1i = a[j + 1] - a[j + 3];
+    x2r = a[j + 4] + a[j + 6];
+    x2i = a[j + 5] + a[j + 7];
+    x3r = a[j + 4] - a[j + 6];
+    x3i = a[j + 5] - a[j + 7];
+    a[j] = x0r + x2r;
+    a[j + 1] = x0i + x2i;
+    x0r -= x2r;
+    x0i -= x2i;
+    a[j + 4] = wk2r * x0r - wk2i * x0i;
+    a[j + 5] = wk2r * x0i + wk2i * x0r;
+    x0r = x1r - x3i;
+    x0i = x1i + x3r;
+    a[j + 2] = wk1r * x0r - wk1i * x0i;
+    a[j + 3] = wk1r * x0i + wk1i * x0r;
+    x0r = x1r + x3i;
+    x0i = x1i - x3r;
+    a[j + 6] = wk3r * x0r - wk3i * x0i;
+    a[j + 7] = wk3r * x0i + wk3i * x0r;
+    wk1r = w[k2 + 2];
+    wk1i = w[k2 + 3];
+    wk3r = wk1r - 2 * wk2r * wk1i;
+    wk3i = 2 * wk2r * wk1r - wk1i;
+    x0r = a[j + 8] + a[j + 10];
+    x0i = a[j + 9] + a[j + 11];
+    x1r = a[j + 8] - a[j + 10];
+    x1i = a[j + 9] - a[j + 11];
+    x2r = a[j + 12] + a[j + 14];
+    x2i = a[j + 13] + a[j + 15];
+    x3r = a[j + 12] - a[j + 14];
+    x3i = a[j + 13] - a[j + 15];
+    a[j + 8] = x0r + x2r;
+    a[j + 9] = x0i + x2i;
+    x0r -= x2r;
+    x0i -= x2i;
+    a[j + 12] = -wk2i * x0r - wk2r * x0i;
+    a[j + 13] = -wk2i * x0i + wk2r * x0r;
+    x0r = x1r - x3i;
+    x0i = x1i + x3r;
+    a[j + 10] = wk1r * x0r - wk1i * x0i;
+    a[j + 11] = wk1r * x0i + wk1i * x0r;
+    x0r = x1r + x3i;
+    x0i = x1i - x3r;
+    a[j + 14] = wk3r * x0r - wk3i * x0i;
+    a[j + 15] = wk3r * x0i + wk3i * x0r;
+  }
+}
+
+void cftmdl(size_t n, size_t l, float* a, float* w) {
+  size_t j, j1, j2, j3, k, k1, k2, m, m2;
+  float wk1r, wk1i, wk2r, wk2i, wk3r, wk3i;
+  float x0r, x0i, x1r, x1i, x2r, x2i, x3r, x3i;
+
+  m = l << 2;
+  for (j = 0; j < l; j += 2) {
+    j1 = j + l;
+    j2 = j1 + l;
+    j3 = j2 + l;
+    x0r = a[j] + a[j1];
+    x0i = a[j + 1] + a[j1 + 1];
+    x1r = a[j] - a[j1];
+    x1i = a[j + 1] - a[j1 + 1];
+    x2r = a[j2] + a[j3];
+    x2i = a[j2 + 1] + a[j3 + 1];
+    x3r = a[j2] - a[j3];
+    x3i = a[j2 + 1] - a[j3 + 1];
+    a[j] = x0r + x2r;
+    a[j + 1] = x0i + x2i;
+    a[j2] = x0r - x2r;
+    a[j2 + 1] = x0i - x2i;
+    a[j1] = x1r - x3i;
+    a[j1 + 1] = x1i + x3r;
+    a[j3] = x1r + x3i;
+    a[j3 + 1] = x1i - x3r;
+  }
+  wk1r = w[2];
+  for (j = m; j < l + m; j += 2) {
+    j1 = j + l;
+    j2 = j1 + l;
+    j3 = j2 + l;
+    x0r = a[j] + a[j1];
+    x0i = a[j + 1] + a[j1 + 1];
+    x1r = a[j] - a[j1];
+    x1i = a[j + 1] - a[j1 + 1];
+    x2r = a[j2] + a[j3];
+    x2i = a[j2 + 1] + a[j3 + 1];
+    x3r = a[j2] - a[j3];
+    x3i = a[j2 + 1] - a[j3 + 1];
+    a[j] = x0r + x2r;
+    a[j + 1] = x0i + x2i;
+    a[j2] = x2i - x0i;
+    a[j2 + 1] = x0r - x2r;
+    x0r = x1r - x3i;
+    x0i = x1i + x3r;
+    a[j1] = wk1r * (x0r - x0i);
+    a[j1 + 1] = wk1r * (x0r + x0i);
+    x0r = x3i + x1r;
+    x0i = x3r - x1i;
+    a[j3] = wk1r * (x0i - x0r);
+    a[j3 + 1] = wk1r * (x0i + x0r);
+  }
+  k1 = 0;
+  m2 = 2 * m;
+  for (k = m2; k < n; k += m2) {
+    k1 += 2;
+    k2 = 2 * k1;
+    wk2r = w[k1];
+    wk2i = w[k1 + 1];
+    wk1r = w[k2];
+    wk1i = w[k2 + 1];
+    wk3r = wk1r - 2 * wk2i * wk1i;
+    wk3i = 2 * wk2i * wk1r - wk1i;
+    for (j = k; j < l + k; j += 2) {
+      j1 = j + l;
+      j2 = j1 + l;
+      j3 = j2 + l;
+      x0r = a[j] + a[j1];
+      x0i = a[j + 1] + a[j1 + 1];
+      x1r = a[j] - a[j1];
+      x1i = a[j + 1] - a[j1 + 1];
+      x2r = a[j2] + a[j3];
+      x2i = a[j2 + 1] + a[j3 + 1];
+      x3r = a[j2] - a[j3];
+      x3i = a[j2 + 1] - a[j3 + 1];
+      a[j] = x0r + x2r;
+      a[j + 1] = x0i + x2i;
+      x0r -= x2r;
+      x0i -= x2i;
+      a[j2] = wk2r * x0r - wk2i * x0i;
+      a[j2 + 1] = wk2r * x0i + wk2i * x0r;
+      x0r = x1r - x3i;
+      x0i = x1i + x3r;
+      a[j1] = wk1r * x0r - wk1i * x0i;
+      a[j1 + 1] = wk1r * x0i + wk1i * x0r;
+      x0r = x1r + x3i;
+      x0i = x1i - x3r;
+      a[j3] = wk3r * x0r - wk3i * x0i;
+      a[j3 + 1] = wk3r * x0i + wk3i * x0r;
+    }
+    wk1r = w[k2 + 2];
+    wk1i = w[k2 + 3];
+    wk3r = wk1r - 2 * wk2r * wk1i;
+    wk3i = 2 * wk2r * wk1r - wk1i;
+    for (j = k + m; j < l + (k + m); j += 2) {
+      j1 = j + l;
+      j2 = j1 + l;
+      j3 = j2 + l;
+      x0r = a[j] + a[j1];
+      x0i = a[j + 1] + a[j1 + 1];
+      x1r = a[j] - a[j1];
+      x1i = a[j + 1] - a[j1 + 1];
+      x2r = a[j2] + a[j3];
+      x2i = a[j2 + 1] + a[j3 + 1];
+      x3r = a[j2] - a[j3];
+      x3i = a[j2 + 1] - a[j3 + 1];
+      a[j] = x0r + x2r;
+      a[j + 1] = x0i + x2i;
+      x0r -= x2r;
+      x0i -= x2i;
+      a[j2] = -wk2i * x0r - wk2r * x0i;
+      a[j2 + 1] = -wk2i * x0i + wk2r * x0r;
+      x0r = x1r - x3i;
+      x0i = x1i + x3r;
+      a[j1] = wk1r * x0r - wk1i * x0i;
+      a[j1 + 1] = wk1r * x0i + wk1i * x0r;
+      x0r = x1r + x3i;
+      x0i = x1i - x3r;
+      a[j3] = wk3r * x0r - wk3i * x0i;
+      a[j3 + 1] = wk3r * x0i + wk3i * x0r;
+    }
+  }
+}
+
+void rftfsub(size_t n, float* a, size_t nc, float* c) {
+  size_t j, k, kk, ks, m;
+  float wkr, wki, xr, xi, yr, yi;
+
+  m = n >> 1;
+  ks = 2 * nc / m;
+  kk = 0;
+  for (j = 2; j < m; j += 2) {
+    k = n - j;
+    kk += ks;
+    wkr = 0.5f - c[nc - kk];
+    wki = c[kk];
+    xr = a[j] - a[k];
+    xi = a[j + 1] + a[k + 1];
+    yr = wkr * xr - wki * xi;
+    yi = wkr * xi + wki * xr;
+    a[j] -= yr;
+    a[j + 1] -= yi;
+    a[k] += yr;
+    a[k + 1] -= yi;
+  }
+}
+
+void rftbsub(size_t n, float* a, size_t nc, float* c) {
+  size_t j, k, kk, ks, m;
+  float wkr, wki, xr, xi, yr, yi;
+
+  a[1] = -a[1];
+  m = n >> 1;
+  ks = 2 * nc / m;
+  kk = 0;
+  for (j = 2; j < m; j += 2) {
+    k = n - j;
+    kk += ks;
+    wkr = 0.5f - c[nc - kk];
+    wki = c[kk];
+    xr = a[j] - a[k];
+    xi = a[j + 1] + a[k + 1];
+    yr = wkr * xr + wki * xi;
+    yi = wkr * xi - wki * xr;
+    a[j] -= yr;
+    a[j + 1] = yi - a[j + 1];
+    a[k] += yr;
+    a[k + 1] = yi - a[k + 1];
+  }
+  a[m + 1] = -a[m + 1];
+}
+
+}  // namespace
+
+void WebRtc_rdft(size_t n, int isgn, float* a, size_t* ip, float* w) {
+  size_t nw, nc;
+  float xi;
+
+  nw = ip[0];
+  if (n > (nw << 2)) {
+    nw = n >> 2;
+    makewt(nw, ip, w);
+  }
+  nc = ip[1];
+  if (n > (nc << 2)) {
+    nc = n >> 2;
+    makect(nc, ip, w + nw);
+  }
+  if (isgn >= 0) {
+    if (n > 4) {
+      bitrv2(n, ip + 2, a);
+      cftfsub(n, a, w);
+      rftfsub(n, a, nc, w + nw);
+    } else if (n == 4) {
+      cftfsub(n, a, w);
+    }
+    xi = a[0] - a[1];
+    a[0] += a[1];
+    a[1] = xi;
+  } else {
+    a[1] = 0.5f * (a[0] - a[1]);
+    a[0] -= a[1];
+    if (n > 4) {
+      rftbsub(n, a, nc, w + nw);
+      bitrv2(n, ip + 2, a);
+      cftbsub(n, a, w);
+    } else if (n == 4) {
+      cftfsub(n, a, w);
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_256/fft4g.h b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_256/fft4g.h
new file mode 100644
index 0000000..d41d2c6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/ooura/fft_size_256/fft4g.h
@@ -0,0 +1,21 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the ../../../LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef COMMON_AUDIO_THIRD_PARTY_OOURA_FFT_SIZE_256_FFT4G_H_
+#define COMMON_AUDIO_THIRD_PARTY_OOURA_FFT_SIZE_256_FFT4G_H_
+
+namespace webrtc {
+
+// Refer to fft4g.c for documentation.
+void WebRtc_rdft(size_t n, int isgn, float* a, size_t* ip, float* w);
+
+}  // namespace webrtc
+
+#endif  // COMMON_AUDIO_THIRD_PARTY_OOURA_FFT_SIZE_256_FFT4G_H_
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/BUILD.gn b/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/BUILD.gn
new file mode 100644
index 0000000..ac862c6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/BUILD.gn
@@ -0,0 +1,24 @@
+# Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+#
+# Use of this source code is governed by a BSD-style license
+# that can be found in the ../../../LICENSE file in the root of the source
+# tree. An additional intellectual property rights grant can be found
+# in the file PATENTS.  All contributing project authors may
+# be found in the AUTHORS file in the root of the source tree.
+
+import("../../../webrtc.gni")
+
+rtc_library("spl_sqrt_floor") {
+  visibility = [ "../..:common_audio_c" ]
+  sources = [ "spl_sqrt_floor.h" ]
+  deps = []
+  if (current_cpu == "arm") {
+    sources += [ "spl_sqrt_floor_arm.S" ]
+
+    deps += [ "../../../rtc_base/system:asm_defines" ]
+  } else if (current_cpu == "mipsel") {
+    sources += [ "spl_sqrt_floor_mips.c" ]
+  } else {
+    sources += [ "spl_sqrt_floor.c" ]
+  }
+}
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/LICENSE b/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/LICENSE
new file mode 100644
index 0000000..fdf17a2
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/LICENSE
@@ -0,0 +1,27 @@
+/*
+ * Written by Wilco Dijkstra, 1996. The following email exchange establishes the
+ * license.
+ *
+ * From: Wilco Dijkstra <Wilco.Dijkstra@ntlworld.com>
+ * Date: Fri, Jun 24, 2011 at 3:20 AM
+ * Subject: Re: sqrt routine
+ * To: Kevin Ma <kma@google.com>
+ * Hi Kevin,
+ * Thanks for asking. Those routines are public domain (originally posted to
+ * comp.sys.arm a long time ago), so you can use them freely for any purpose.
+ * Cheers,
+ * Wilco
+ *
+ * ----- Original Message -----
+ * From: "Kevin Ma" <kma@google.com>
+ * To: <Wilco.Dijkstra@ntlworld.com>
+ * Sent: Thursday, June 23, 2011 11:44 PM
+ * Subject: Fwd: sqrt routine
+ * Hi Wilco,
+ * I saw your sqrt routine from several web sites, including
+ * http://www.finesse.demon.co.uk/steven/sqrt.html.
+ * Just wonder if there's any copyright information with your Successive
+ * approximation routines, or if I can freely use it for any purpose.
+ * Thanks.
+ * Kevin
+ */
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/README.chromium b/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/README.chromium
new file mode 100644
index 0000000..b226490
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/README.chromium
@@ -0,0 +1,12 @@
+Name: sql sqrt floor
+Short Name: sql_sqrt_floor
+URL: http://www.pertinentdetail.org/sqrt
+Version: 0
+Date: 2018-03-22
+License: Custom license
+License File: LICENSE
+Security Critical: yes
+
+Description:
+Sqrt routine, originally was posted to the USENET group comp.sys.arm on
+20 Jun 1996.
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/spl_sqrt_floor.c b/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/spl_sqrt_floor.c
new file mode 100644
index 0000000..b478a41
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/spl_sqrt_floor.c
@@ -0,0 +1,77 @@
+/*
+ * Written by Wilco Dijkstra, 1996. The following email exchange establishes the
+ * license.
+ *
+ * From: Wilco Dijkstra <Wilco.Dijkstra@ntlworld.com>
+ * Date: Fri, Jun 24, 2011 at 3:20 AM
+ * Subject: Re: sqrt routine
+ * To: Kevin Ma <kma@google.com>
+ * Hi Kevin,
+ * Thanks for asking. Those routines are public domain (originally posted to
+ * comp.sys.arm a long time ago), so you can use them freely for any purpose.
+ * Cheers,
+ * Wilco
+ *
+ * ----- Original Message -----
+ * From: "Kevin Ma" <kma@google.com>
+ * To: <Wilco.Dijkstra@ntlworld.com>
+ * Sent: Thursday, June 23, 2011 11:44 PM
+ * Subject: Fwd: sqrt routine
+ * Hi Wilco,
+ * I saw your sqrt routine from several web sites, including
+ * http://www.finesse.demon.co.uk/steven/sqrt.html.
+ * Just wonder if there's any copyright information with your Successive
+ * approximation routines, or if I can freely use it for any purpose.
+ * Thanks.
+ * Kevin
+ */
+
+// Minor modifications in code style for WebRTC, 2012.
+
+#include "common_audio/third_party/spl_sqrt_floor/spl_sqrt_floor.h"
+
+/*
+ * Algorithm:
+ * Successive approximation of the equation (root + delta) ^ 2 = N
+ * until delta < 1. If delta < 1 we have the integer part of SQRT (N).
+ * Use delta = 2^i for i = 15 .. 0.
+ *
+ * Output precision is 16 bits. Note for large input values (close to
+ * 0x7FFFFFFF), bit 15 (the highest bit of the low 16-bit half word)
+ * contains the MSB information (a non-sign value). Do with caution
+ * if you need to cast the output to int16_t type.
+ *
+ * If the input value is negative, it returns 0.
+ */
+
+#define WEBRTC_SPL_SQRT_ITER(N)                 \
+  try1 = root + (1 << (N));                     \
+  if (value >= try1 << (N))                     \
+  {                                             \
+    value -= try1 << (N);                       \
+    root |= 2 << (N);                           \
+  }
+
+int32_t WebRtcSpl_SqrtFloor(int32_t value)
+{
+  int32_t root = 0, try1;
+
+  WEBRTC_SPL_SQRT_ITER (15);
+  WEBRTC_SPL_SQRT_ITER (14);
+  WEBRTC_SPL_SQRT_ITER (13);
+  WEBRTC_SPL_SQRT_ITER (12);
+  WEBRTC_SPL_SQRT_ITER (11);
+  WEBRTC_SPL_SQRT_ITER (10);
+  WEBRTC_SPL_SQRT_ITER ( 9);
+  WEBRTC_SPL_SQRT_ITER ( 8);
+  WEBRTC_SPL_SQRT_ITER ( 7);
+  WEBRTC_SPL_SQRT_ITER ( 6);
+  WEBRTC_SPL_SQRT_ITER ( 5);
+  WEBRTC_SPL_SQRT_ITER ( 4);
+  WEBRTC_SPL_SQRT_ITER ( 3);
+  WEBRTC_SPL_SQRT_ITER ( 2);
+  WEBRTC_SPL_SQRT_ITER ( 1);
+  WEBRTC_SPL_SQRT_ITER ( 0);
+
+  return root >> 1;
+}
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/spl_sqrt_floor.h b/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/spl_sqrt_floor.h
new file mode 100644
index 0000000..eaa58e3
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/spl_sqrt_floor.h
@@ -0,0 +1,29 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include <stdint.h>
+
+//
+// WebRtcSpl_SqrtFloor(...)
+//
+// Returns the square root of the input value |value|. The precision of this
+// function is rounding down integer precision, i.e., sqrt(8) gives 2 as answer.
+// If |value| is a negative number then 0 is returned.
+//
+// Algorithm:
+//
+// An iterative 4 cylce/bit routine
+//
+// Input:
+//      - value     : Value to calculate sqrt of
+//
+// Return value     : Result of the sqrt calculation
+//
+int32_t WebRtcSpl_SqrtFloor(int32_t value);
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/spl_sqrt_floor_arm.S b/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/spl_sqrt_floor_arm.S
new file mode 100644
index 0000000..228e68e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/spl_sqrt_floor_arm.S
@@ -0,0 +1,110 @@
+@
+@ Written by Wilco Dijkstra, 1996. The following email exchange establishes the
+@ license.
+@
+@ From: Wilco Dijkstra <Wilco.Dijkstra@ntlworld.com>
+@ Date: Fri, Jun 24, 2011 at 3:20 AM
+@ Subject: Re: sqrt routine
+@ To: Kevin Ma <kma@google.com>
+@ Hi Kevin,
+@ Thanks for asking. Those routines are public domain (originally posted to
+@ comp.sys.arm a long time ago), so you can use them freely for any purpose.
+@ Cheers,
+@ Wilco
+@
+@ ----- Original Message -----
+@ From: "Kevin Ma" <kma@google.com>
+@ To: <Wilco.Dijkstra@ntlworld.com>
+@ Sent: Thursday, June 23, 2011 11:44 PM
+@ Subject: Fwd: sqrt routine
+@ Hi Wilco,
+@ I saw your sqrt routine from several web sites, including
+@ http://www.finesse.demon.co.uk/steven/sqrt.html.
+@ Just wonder if there's any copyright information with your Successive
+@ approximation routines, or if I can freely use it for any purpose.
+@ Thanks.
+@ Kevin
+
+@ Minor modifications in code style for WebRTC, 2012.
+@ Output is bit-exact with the reference C code in spl_sqrt_floor.c.
+
+@ Input :             r0 32 bit unsigned integer
+@ Output:             r0 = INT (SQRT (r0)), precision is 16 bits
+@ Registers touched:  r1, r2
+
+#include "rtc_base/system/asm_defines.h"
+
+GLOBAL_FUNCTION WebRtcSpl_SqrtFloor
+.align  2
+DEFINE_FUNCTION WebRtcSpl_SqrtFloor
+  mov    r1, #3 << 30
+  mov    r2, #1 << 30
+
+  @ unroll for i = 0 .. 15
+
+  cmp    r0, r2, ror #2 * 0
+  subhs  r0, r0, r2, ror #2 * 0
+  adc    r2, r1, r2, lsl #1
+
+  cmp    r0, r2, ror #2 * 1
+  subhs  r0, r0, r2, ror #2 * 1
+  adc    r2, r1, r2, lsl #1
+
+  cmp    r0, r2, ror #2 * 2
+  subhs  r0, r0, r2, ror #2 * 2
+  adc    r2, r1, r2, lsl #1
+
+  cmp    r0, r2, ror #2 * 3
+  subhs  r0, r0, r2, ror #2 * 3
+  adc    r2, r1, r2, lsl #1
+
+  cmp    r0, r2, ror #2 * 4
+  subhs  r0, r0, r2, ror #2 * 4
+  adc    r2, r1, r2, lsl #1
+
+  cmp    r0, r2, ror #2 * 5
+  subhs  r0, r0, r2, ror #2 * 5
+  adc    r2, r1, r2, lsl #1
+
+  cmp    r0, r2, ror #2 * 6
+  subhs  r0, r0, r2, ror #2 * 6
+  adc    r2, r1, r2, lsl #1
+
+  cmp    r0, r2, ror #2 * 7
+  subhs  r0, r0, r2, ror #2 * 7
+  adc    r2, r1, r2, lsl #1
+
+  cmp    r0, r2, ror #2 * 8
+  subhs  r0, r0, r2, ror #2 * 8
+  adc    r2, r1, r2, lsl #1
+
+  cmp    r0, r2, ror #2 * 9
+  subhs  r0, r0, r2, ror #2 * 9
+  adc    r2, r1, r2, lsl #1
+
+  cmp    r0, r2, ror #2 * 10
+  subhs  r0, r0, r2, ror #2 * 10
+  adc    r2, r1, r2, lsl #1
+
+  cmp    r0, r2, ror #2 * 11
+  subhs  r0, r0, r2, ror #2 * 11
+  adc    r2, r1, r2, lsl #1
+
+  cmp    r0, r2, ror #2 * 12
+  subhs  r0, r0, r2, ror #2 * 12
+  adc    r2, r1, r2, lsl #1
+
+  cmp    r0, r2, ror #2 * 13
+  subhs  r0, r0, r2, ror #2 * 13
+  adc    r2, r1, r2, lsl #1
+
+  cmp    r0, r2, ror #2 * 14
+  subhs  r0, r0, r2, ror #2 * 14
+  adc    r2, r1, r2, lsl #1
+
+  cmp    r0, r2, ror #2 * 15
+  subhs  r0, r0, r2, ror #2 * 15
+  adc    r2, r1, r2, lsl #1
+
+  bic    r0, r2, #3 << 30  @ for rounding add: cmp r0, r2  adc r2, #1
+  bx lr
diff --git a/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/spl_sqrt_floor_mips.c b/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/spl_sqrt_floor_mips.c
new file mode 100644
index 0000000..04033c1
--- /dev/null
+++ b/third_party/webrtc_aec3/src/common_audio/third_party/spl_sqrt_floor/spl_sqrt_floor_mips.c
@@ -0,0 +1,207 @@
+/*
+ * Written by Wilco Dijkstra, 1996. The following email exchange establishes the
+ * license.
+ *
+ * From: Wilco Dijkstra <Wilco.Dijkstra@ntlworld.com>
+ * Date: Fri, Jun 24, 2011 at 3:20 AM
+ * Subject: Re: sqrt routine
+ * To: Kevin Ma <kma@google.com>
+ * Hi Kevin,
+ * Thanks for asking. Those routines are public domain (originally posted to
+ * comp.sys.arm a long time ago), so you can use them freely for any purpose.
+ * Cheers,
+ * Wilco
+ *
+ * ----- Original Message -----
+ * From: "Kevin Ma" <kma@google.com>
+ * To: <Wilco.Dijkstra@ntlworld.com>
+ * Sent: Thursday, June 23, 2011 11:44 PM
+ * Subject: Fwd: sqrt routine
+ * Hi Wilco,
+ * I saw your sqrt routine from several web sites, including
+ * http://www.finesse.demon.co.uk/steven/sqrt.html.
+ * Just wonder if there's any copyright information with your Successive
+ * approximation routines, or if I can freely use it for any purpose.
+ * Thanks.
+ * Kevin
+ */
+
+// Minor modifications in code style for WebRTC, 2012.
+// Code optimizations for MIPS, 2013.
+
+#include "common_audio/third_party/spl_sqrt_floor/spl_sqrt_floor.h"
+
+/*
+ * Algorithm:
+ * Successive approximation of the equation (root + delta) ^ 2 = N
+ * until delta < 1. If delta < 1 we have the integer part of SQRT (N).
+ * Use delta = 2^i for i = 15 .. 0.
+ *
+ * Output precision is 16 bits. Note for large input values (close to
+ * 0x7FFFFFFF), bit 15 (the highest bit of the low 16-bit half word)
+ * contains the MSB information (a non-sign value). Do with caution
+ * if you need to cast the output to int16_t type.
+ *
+ * If the input value is negative, it returns 0.
+ */
+
+
+int32_t WebRtcSpl_SqrtFloor(int32_t value)
+{
+  int32_t root = 0, tmp1, tmp2, tmp3, tmp4;
+
+  __asm __volatile(
+    ".set   push                                       \n\t"
+    ".set   noreorder                                  \n\t"
+
+    "lui    %[tmp1],      0x4000                       \n\t"
+    "slt    %[tmp2],      %[value],     %[tmp1]        \n\t"
+    "sub    %[tmp3],      %[value],     %[tmp1]        \n\t"
+    "lui    %[tmp1],      0x1                          \n\t"
+    "or     %[tmp4],      %[root],      %[tmp1]        \n\t"
+    "movz   %[value],     %[tmp3],      %[tmp2]        \n\t"
+    "movz   %[root],      %[tmp4],      %[tmp2]        \n\t"
+
+    "addiu  %[tmp1],      $0,           0x4000         \n\t"
+    "addu   %[tmp1],      %[tmp1],      %[root]        \n\t"
+    "sll    %[tmp1],      14                           \n\t"
+    "slt    %[tmp2],      %[value],     %[tmp1]        \n\t"
+    "subu   %[tmp3],      %[value],     %[tmp1]        \n\t"
+    "ori    %[tmp4],      %[root],      0x8000         \n\t"
+    "movz   %[value],     %[tmp3],      %[tmp2]        \n\t"
+    "movz   %[root],      %[tmp4],      %[tmp2]        \n\t"
+
+    "addiu  %[tmp1],      $0,           0x2000         \n\t"
+    "addu   %[tmp1],      %[tmp1],      %[root]        \n\t"
+    "sll    %[tmp1],      13                           \n\t"
+    "slt    %[tmp2],      %[value],     %[tmp1]        \n\t"
+    "subu   %[tmp3],      %[value],     %[tmp1]        \n\t"
+    "ori    %[tmp4],      %[root],      0x4000         \n\t"
+    "movz   %[value],     %[tmp3],      %[tmp2]        \n\t"
+    "movz   %[root],      %[tmp4],      %[tmp2]        \n\t"
+
+    "addiu  %[tmp1],      $0,           0x1000         \n\t"
+    "addu   %[tmp1],      %[tmp1],      %[root]        \n\t"
+    "sll    %[tmp1],      12                           \n\t"
+    "slt    %[tmp2],      %[value],     %[tmp1]        \n\t"
+    "subu   %[tmp3],      %[value],     %[tmp1]        \n\t"
+    "ori    %[tmp4],      %[root],      0x2000         \n\t"
+    "movz   %[value],     %[tmp3],      %[tmp2]        \n\t"
+    "movz   %[root],      %[tmp4],      %[tmp2]        \n\t"
+
+    "addiu  %[tmp1],      $0,           0x800          \n\t"
+    "addu   %[tmp1],      %[tmp1],      %[root]        \n\t"
+    "sll    %[tmp1],      11                           \n\t"
+    "slt    %[tmp2],      %[value],     %[tmp1]        \n\t"
+    "subu   %[tmp3],      %[value],     %[tmp1]        \n\t"
+    "ori    %[tmp4],      %[root],      0x1000         \n\t"
+    "movz   %[value],     %[tmp3],      %[tmp2]        \n\t"
+    "movz   %[root],      %[tmp4],      %[tmp2]        \n\t"
+
+    "addiu  %[tmp1],      $0,           0x400          \n\t"
+    "addu   %[tmp1],      %[tmp1],      %[root]        \n\t"
+    "sll    %[tmp1],      10                           \n\t"
+    "slt    %[tmp2],      %[value],     %[tmp1]        \n\t"
+    "subu   %[tmp3],      %[value],     %[tmp1]        \n\t"
+    "ori    %[tmp4],      %[root],      0x800          \n\t"
+    "movz   %[value],     %[tmp3],      %[tmp2]        \n\t"
+    "movz   %[root],      %[tmp4],      %[tmp2]        \n\t"
+
+    "addiu  %[tmp1],      $0,           0x200          \n\t"
+    "addu   %[tmp1],      %[tmp1],      %[root]        \n\t"
+    "sll    %[tmp1],      9                            \n\t"
+    "slt    %[tmp2],      %[value],     %[tmp1]        \n\t"
+    "subu   %[tmp3],      %[value],     %[tmp1]        \n\t"
+    "ori    %[tmp4],      %[root],       0x400         \n\t"
+    "movz   %[value],     %[tmp3],      %[tmp2]        \n\t"
+    "movz   %[root],      %[tmp4],      %[tmp2]        \n\t"
+
+    "addiu  %[tmp1],      $0,           0x100          \n\t"
+    "addu   %[tmp1],      %[tmp1],      %[root]        \n\t"
+    "sll    %[tmp1],      8                            \n\t"
+    "slt    %[tmp2],      %[value],     %[tmp1]        \n\t"
+    "subu   %[tmp3],      %[value],     %[tmp1]        \n\t"
+    "ori    %[tmp4],      %[root],      0x200          \n\t"
+    "movz   %[value],     %[tmp3],      %[tmp2]        \n\t"
+    "movz   %[root],      %[tmp4],      %[tmp2]        \n\t"
+
+    "addiu  %[tmp1],      $0,           0x80           \n\t"
+    "addu   %[tmp1],      %[tmp1],      %[root]        \n\t"
+    "sll    %[tmp1],      7                            \n\t"
+    "slt    %[tmp2],      %[value],     %[tmp1]        \n\t"
+    "subu   %[tmp3],      %[value],     %[tmp1]        \n\t"
+    "ori    %[tmp4],      %[root],      0x100          \n\t"
+    "movz   %[value],     %[tmp3],      %[tmp2]        \n\t"
+    "movz   %[root],      %[tmp4],      %[tmp2]        \n\t"
+
+    "addiu  %[tmp1],      $0,           0x40           \n\t"
+    "addu   %[tmp1],      %[tmp1],      %[root]        \n\t"
+    "sll    %[tmp1],      6                            \n\t"
+    "slt    %[tmp2],      %[value],     %[tmp1]        \n\t"
+    "subu   %[tmp3],      %[value],     %[tmp1]        \n\t"
+    "ori    %[tmp4],      %[root],      0x80           \n\t"
+    "movz   %[value],     %[tmp3],      %[tmp2]        \n\t"
+    "movz   %[root],      %[tmp4],      %[tmp2]        \n\t"
+
+    "addiu  %[tmp1],      $0,           0x20           \n\t"
+    "addu   %[tmp1],      %[tmp1],      %[root]        \n\t"
+    "sll    %[tmp1],      5                            \n\t"
+    "slt    %[tmp2],      %[value],     %[tmp1]        \n\t"
+    "subu   %[tmp3],      %[value],     %[tmp1]        \n\t"
+    "ori    %[tmp4],      %[root],      0x40           \n\t"
+    "movz   %[value],     %[tmp3],      %[tmp2]        \n\t"
+    "movz   %[root],      %[tmp4],      %[tmp2]        \n\t"
+
+    "addiu  %[tmp1],      $0,           0x10           \n\t"
+    "addu   %[tmp1],      %[tmp1],      %[root]        \n\t"
+    "sll    %[tmp1],      4                            \n\t"
+    "slt    %[tmp2],      %[value],     %[tmp1]        \n\t"
+    "subu   %[tmp3],      %[value],     %[tmp1]        \n\t"
+    "ori    %[tmp4],      %[root],      0x20           \n\t"
+    "movz   %[value],     %[tmp3],      %[tmp2]        \n\t"
+    "movz   %[root],      %[tmp4],      %[tmp2]        \n\t"
+
+    "addiu  %[tmp1],      $0,           0x8            \n\t"
+    "addu   %[tmp1],      %[tmp1],      %[root]        \n\t"
+    "sll    %[tmp1],      3                            \n\t"
+    "slt    %[tmp2],      %[value],     %[tmp1]        \n\t"
+    "subu   %[tmp3],      %[value],     %[tmp1]        \n\t"
+    "ori    %[tmp4],      %[root],      0x10           \n\t"
+    "movz   %[value],     %[tmp3],      %[tmp2]        \n\t"
+    "movz   %[root],      %[tmp4],      %[tmp2]        \n\t"
+
+    "addiu  %[tmp1],      $0,           0x4            \n\t"
+    "addu   %[tmp1],      %[tmp1],      %[root]        \n\t"
+    "sll    %[tmp1],      2                            \n\t"
+    "slt    %[tmp2],      %[value],     %[tmp1]        \n\t"
+    "subu   %[tmp3],      %[value],     %[tmp1]        \n\t"
+    "ori    %[tmp4],      %[root],      0x8            \n\t"
+    "movz   %[value],     %[tmp3],      %[tmp2]        \n\t"
+    "movz   %[root],      %[tmp4],      %[tmp2]        \n\t"
+
+    "addiu  %[tmp1],      $0,           0x2            \n\t"
+    "addu   %[tmp1],      %[tmp1],      %[root]        \n\t"
+    "sll    %[tmp1],      1                            \n\t"
+    "slt    %[tmp2],      %[value],     %[tmp1]        \n\t"
+    "subu   %[tmp3],      %[value],     %[tmp1]        \n\t"
+    "ori    %[tmp4],      %[root],      0x4            \n\t"
+    "movz   %[value],     %[tmp3],      %[tmp2]        \n\t"
+    "movz   %[root],      %[tmp4],      %[tmp2]        \n\t"
+
+    "addiu  %[tmp1],      $0,           0x1            \n\t"
+    "addu   %[tmp1],      %[tmp1],      %[root]        \n\t"
+    "slt    %[tmp2],      %[value],     %[tmp1]        \n\t"
+    "ori    %[tmp4],      %[root],      0x2            \n\t"
+    "movz   %[root],      %[tmp4],      %[tmp2]        \n\t"
+
+    ".set   pop                                        \n\t"
+
+    : [root] "+r" (root), [value] "+r" (value),
+      [tmp1] "=&r" (tmp1), [tmp2] "=&r" (tmp2),
+      [tmp3] "=&r" (tmp3), [tmp4] "=&r" (tmp4)
+    :
+  );
+
+  return root >> 1;
+}
+
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/BUILD.gn b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/BUILD.gn
new file mode 100644
index 0000000..3ce4943
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/BUILD.gn
@@ -0,0 +1,370 @@
+# Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+#
+# Use of this source code is governed by a BSD-style license
+# that can be found in the LICENSE file in the root of the source
+# tree. An additional intellectual property rights grant can be found
+# in the file PATENTS.  All contributing project authors may
+# be found in the AUTHORS file in the root of the source tree.
+
+import("../../../webrtc.gni")
+
+rtc_library("aec3") {
+  visibility = [ "*" ]
+  configs += [ "..:apm_debug_dump" ]
+  sources = [
+    "adaptive_fir_filter.cc",
+    "adaptive_fir_filter_erl.cc",
+    "aec3_common.cc",
+    "aec3_fft.cc",
+    "aec_state.cc",
+    "aec_state.h",
+    "alignment_mixer.cc",
+    "alignment_mixer.h",
+    "api_call_jitter_metrics.cc",
+    "api_call_jitter_metrics.h",
+    "block_buffer.cc",
+    "block_delay_buffer.cc",
+    "block_delay_buffer.h",
+    "block_framer.cc",
+    "block_framer.h",
+    "block_processor.cc",
+    "block_processor.h",
+    "block_processor_metrics.cc",
+    "block_processor_metrics.h",
+    "clockdrift_detector.cc",
+    "clockdrift_detector.h",
+    "coarse_filter_update_gain.cc",
+    "coarse_filter_update_gain.h",
+    "comfort_noise_generator.cc",
+    "comfort_noise_generator.h",
+    "decimator.cc",
+    "decimator.h",
+    "delay_estimate.h",
+    "dominant_nearend_detector.cc",
+    "dominant_nearend_detector.h",
+    "downsampled_render_buffer.cc",
+    "downsampled_render_buffer.h",
+    "echo_audibility.cc",
+    "echo_audibility.h",
+    "echo_canceller3.cc",
+    "echo_canceller3.h",
+    "echo_path_delay_estimator.cc",
+    "echo_path_delay_estimator.h",
+    "echo_path_variability.cc",
+    "echo_path_variability.h",
+    "echo_remover.cc",
+    "echo_remover.h",
+    "echo_remover_metrics.cc",
+    "echo_remover_metrics.h",
+    "erl_estimator.cc",
+    "erl_estimator.h",
+    "erle_estimator.cc",
+    "erle_estimator.h",
+    "fft_buffer.cc",
+    "filter_analyzer.cc",
+    "filter_analyzer.h",
+    "frame_blocker.cc",
+    "frame_blocker.h",
+    "fullband_erle_estimator.cc",
+    "fullband_erle_estimator.h",
+    "matched_filter.cc",
+    "matched_filter_lag_aggregator.cc",
+    "matched_filter_lag_aggregator.h",
+    "moving_average.cc",
+    "moving_average.h",
+    "nearend_detector.h",
+    "refined_filter_update_gain.cc",
+    "refined_filter_update_gain.h",
+    "render_buffer.cc",
+    "render_delay_buffer.cc",
+    "render_delay_buffer.h",
+    "render_delay_controller.cc",
+    "render_delay_controller.h",
+    "render_delay_controller_metrics.cc",
+    "render_delay_controller_metrics.h",
+    "render_signal_analyzer.cc",
+    "render_signal_analyzer.h",
+    "residual_echo_estimator.cc",
+    "residual_echo_estimator.h",
+    "reverb_decay_estimator.cc",
+    "reverb_decay_estimator.h",
+    "reverb_frequency_response.cc",
+    "reverb_frequency_response.h",
+    "reverb_model.cc",
+    "reverb_model.h",
+    "reverb_model_estimator.cc",
+    "reverb_model_estimator.h",
+    "signal_dependent_erle_estimator.cc",
+    "signal_dependent_erle_estimator.h",
+    "spectrum_buffer.cc",
+    "stationarity_estimator.cc",
+    "stationarity_estimator.h",
+    "subband_erle_estimator.cc",
+    "subband_erle_estimator.h",
+    "subband_nearend_detector.cc",
+    "subband_nearend_detector.h",
+    "subtractor.cc",
+    "subtractor.h",
+    "subtractor_output.cc",
+    "subtractor_output.h",
+    "subtractor_output_analyzer.cc",
+    "subtractor_output_analyzer.h",
+    "suppression_filter.cc",
+    "suppression_filter.h",
+    "suppression_gain.cc",
+    "suppression_gain.h",
+    "transparent_mode.cc",
+    "transparent_mode.h",
+  ]
+
+  defines = []
+  if (rtc_build_with_neon && current_cpu != "arm64") {
+    suppressed_configs += [ "//build/config/compiler:compiler_arm_fpu" ]
+    cflags = [ "-mfpu=neon" ]
+  }
+
+  deps = [
+    ":adaptive_fir_filter",
+    ":adaptive_fir_filter_erl",
+    ":aec3_common",
+    ":aec3_fft",
+    ":fft_data",
+    ":matched_filter",
+    ":render_buffer",
+    ":vector_math",
+    "..:apm_logging",
+    "..:audio_buffer",
+    "..:high_pass_filter",
+    "../../../api:array_view",
+    "../../../api/audio:aec3_config",
+    "../../../api/audio:echo_control",
+    "../../../common_audio:common_audio_c",
+    "../../../rtc_base:checks",
+    "../../../rtc_base:rtc_base_approved",
+    "../../../rtc_base:safe_minmax",
+    "../../../rtc_base/experiments:field_trial_parser",
+    "../../../rtc_base/system:arch",
+    "../../../system_wrappers",
+    "../../../system_wrappers:field_trial",
+    "../../../system_wrappers:metrics",
+    "../utility:cascaded_biquad_filter",
+  ]
+  absl_deps = [ "//third_party/abseil-cpp/absl/types:optional" ]
+
+  if (current_cpu == "x86" || current_cpu == "x64") {
+    deps += [ ":aec3_avx2" ]
+  }
+}
+
+rtc_source_set("aec3_common") {
+  sources = [ "aec3_common.h" ]
+}
+
+rtc_source_set("aec3_fft") {
+  sources = [ "aec3_fft.h" ]
+  deps = [
+    ":aec3_common",
+    ":fft_data",
+    "../../../api:array_view",
+    "../../../common_audio/third_party/ooura:fft_size_128",
+    "../../../rtc_base:checks",
+    "../../../rtc_base:rtc_base_approved",
+    "../../../rtc_base/system:arch",
+  ]
+}
+
+rtc_source_set("render_buffer") {
+  sources = [
+    "block_buffer.h",
+    "fft_buffer.h",
+    "render_buffer.h",
+    "spectrum_buffer.h",
+  ]
+  deps = [
+    ":aec3_common",
+    ":fft_data",
+    "../../../api:array_view",
+    "../../../rtc_base:checks",
+    "../../../rtc_base:rtc_base_approved",
+    "../../../rtc_base/system:arch",
+  ]
+}
+
+rtc_source_set("adaptive_fir_filter") {
+  sources = [ "adaptive_fir_filter.h" ]
+  deps = [
+    ":aec3_common",
+    ":aec3_fft",
+    ":fft_data",
+    ":render_buffer",
+    "..:apm_logging",
+    "../../../api:array_view",
+    "../../../rtc_base/system:arch",
+  ]
+}
+
+rtc_source_set("adaptive_fir_filter_erl") {
+  sources = [ "adaptive_fir_filter_erl.h" ]
+  deps = [
+    ":aec3_common",
+    "../../../api:array_view",
+    "../../../rtc_base/system:arch",
+  ]
+}
+
+rtc_source_set("matched_filter") {
+  sources = [ "matched_filter.h" ]
+  deps = [
+    ":aec3_common",
+    "../../../api:array_view",
+    "../../../rtc_base:rtc_base_approved",
+    "../../../rtc_base/system:arch",
+  ]
+}
+
+rtc_source_set("vector_math") {
+  sources = [ "vector_math.h" ]
+  deps = [
+    ":aec3_common",
+    "../../../api:array_view",
+    "../../../rtc_base:checks",
+    "../../../rtc_base/system:arch",
+  ]
+}
+
+rtc_source_set("fft_data") {
+  sources = [ "fft_data.h" ]
+  deps = [
+    ":aec3_common",
+    "../../../api:array_view",
+    "../../../rtc_base/system:arch",
+  ]
+}
+
+if (current_cpu == "x86" || current_cpu == "x64") {
+  rtc_library("aec3_avx2") {
+    configs += [ "..:apm_debug_dump" ]
+    sources = [
+      "adaptive_fir_filter_avx2.cc",
+      "adaptive_fir_filter_erl_avx2.cc",
+      "fft_data_avx2.cc",
+      "matched_filter_avx2.cc",
+      "vector_math_avx2.cc",
+    ]
+
+    if (is_win) {
+      cflags = [ "/arch:AVX2" ]
+    } else {
+      cflags = [
+        "-mavx2",
+        "-mfma",
+      ]
+    }
+
+    deps = [
+      ":adaptive_fir_filter",
+      ":adaptive_fir_filter_erl",
+      ":fft_data",
+      ":matched_filter",
+      ":vector_math",
+      "../../../api:array_view",
+      "../../../rtc_base:checks",
+    ]
+  }
+}
+
+if (rtc_include_tests) {
+  rtc_library("aec3_unittests") {
+    testonly = true
+
+    configs += [ "..:apm_debug_dump" ]
+    sources = [
+      "mock/mock_block_processor.cc",
+      "mock/mock_block_processor.h",
+      "mock/mock_echo_remover.cc",
+      "mock/mock_echo_remover.h",
+      "mock/mock_render_delay_buffer.cc",
+      "mock/mock_render_delay_buffer.h",
+      "mock/mock_render_delay_controller.cc",
+      "mock/mock_render_delay_controller.h",
+    ]
+
+    deps = [
+      ":adaptive_fir_filter",
+      ":adaptive_fir_filter_erl",
+      ":aec3",
+      ":aec3_common",
+      ":aec3_fft",
+      ":fft_data",
+      ":matched_filter",
+      ":render_buffer",
+      ":vector_math",
+      "..:apm_logging",
+      "..:audio_buffer",
+      "..:audio_processing",
+      "..:high_pass_filter",
+      "../../../api:array_view",
+      "../../../api/audio:aec3_config",
+      "../../../rtc_base:checks",
+      "../../../rtc_base:rtc_base_approved",
+      "../../../rtc_base:safe_minmax",
+      "../../../rtc_base/system:arch",
+      "../../../system_wrappers",
+      "../../../test:field_trial",
+      "../../../test:test_support",
+      "../utility:cascaded_biquad_filter",
+    ]
+    absl_deps = [ "//third_party/abseil-cpp/absl/types:optional" ]
+
+    defines = []
+
+    if (rtc_enable_protobuf) {
+      sources += [
+        "adaptive_fir_filter_erl_unittest.cc",
+        "adaptive_fir_filter_unittest.cc",
+        "aec3_fft_unittest.cc",
+        "aec_state_unittest.cc",
+        "alignment_mixer_unittest.cc",
+        "api_call_jitter_metrics_unittest.cc",
+        "block_delay_buffer_unittest.cc",
+        "block_framer_unittest.cc",
+        "block_processor_metrics_unittest.cc",
+        "block_processor_unittest.cc",
+        "clockdrift_detector_unittest.cc",
+        "coarse_filter_update_gain_unittest.cc",
+        "comfort_noise_generator_unittest.cc",
+        "decimator_unittest.cc",
+        "echo_canceller3_unittest.cc",
+        "echo_path_delay_estimator_unittest.cc",
+        "echo_path_variability_unittest.cc",
+        "echo_remover_metrics_unittest.cc",
+        "echo_remover_unittest.cc",
+        "erl_estimator_unittest.cc",
+        "erle_estimator_unittest.cc",
+        "fft_data_unittest.cc",
+        "filter_analyzer_unittest.cc",
+        "frame_blocker_unittest.cc",
+        "matched_filter_lag_aggregator_unittest.cc",
+        "matched_filter_unittest.cc",
+        "moving_average_unittest.cc",
+        "refined_filter_update_gain_unittest.cc",
+        "render_buffer_unittest.cc",
+        "render_delay_buffer_unittest.cc",
+        "render_delay_controller_metrics_unittest.cc",
+        "render_delay_controller_unittest.cc",
+        "render_signal_analyzer_unittest.cc",
+        "residual_echo_estimator_unittest.cc",
+        "reverb_model_estimator_unittest.cc",
+        "signal_dependent_erle_estimator_unittest.cc",
+        "subtractor_unittest.cc",
+        "suppression_filter_unittest.cc",
+        "suppression_gain_unittest.cc",
+        "vector_math_unittest.cc",
+      ]
+    }
+
+    if (!build_with_chromium) {
+      deps += [ "..:audio_processing_unittests" ]
+    }
+  }
+}
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter.cc
new file mode 100644
index 0000000..bf3a780
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter.cc
@@ -0,0 +1,740 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/adaptive_fir_filter.h"
+
+// Defines WEBRTC_ARCH_X86_FAMILY, used below.
+#include "rtc_base/system/arch.h"
+
+#if defined(WEBRTC_HAS_NEON)
+#include <arm_neon.h>
+#endif
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+#include <emmintrin.h>
+#endif
+#include <math.h>
+
+#include <algorithm>
+#include <functional>
+
+#include "modules/audio_processing/aec3/fft_data.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+namespace aec3 {
+
+// Computes and stores the frequency response of the filter.
+void ComputeFrequencyResponse(
+    size_t num_partitions,
+    const std::vector<std::vector<FftData>>& H,
+    std::vector<std::array<float, kFftLengthBy2Plus1>>* H2) {
+  for (auto& H2_ch : *H2) {
+    H2_ch.fill(0.f);
+  }
+
+  const size_t num_render_channels = H[0].size();
+  RTC_DCHECK_EQ(H.size(), H2->capacity());
+  for (size_t p = 0; p < num_partitions; ++p) {
+    RTC_DCHECK_EQ(kFftLengthBy2Plus1, (*H2)[p].size());
+    for (size_t ch = 0; ch < num_render_channels; ++ch) {
+      for (size_t j = 0; j < kFftLengthBy2Plus1; ++j) {
+        float tmp =
+            H[p][ch].re[j] * H[p][ch].re[j] + H[p][ch].im[j] * H[p][ch].im[j];
+        (*H2)[p][j] = std::max((*H2)[p][j], tmp);
+      }
+    }
+  }
+}
+
+#if defined(WEBRTC_HAS_NEON)
+// Computes and stores the frequency response of the filter.
+void ComputeFrequencyResponse_Neon(
+    size_t num_partitions,
+    const std::vector<std::vector<FftData>>& H,
+    std::vector<std::array<float, kFftLengthBy2Plus1>>* H2) {
+  for (auto& H2_ch : *H2) {
+    H2_ch.fill(0.f);
+  }
+
+  const size_t num_render_channels = H[0].size();
+  RTC_DCHECK_EQ(H.size(), H2->capacity());
+  for (size_t p = 0; p < num_partitions; ++p) {
+    RTC_DCHECK_EQ(kFftLengthBy2Plus1, (*H2)[p].size());
+    for (size_t ch = 0; ch < num_render_channels; ++ch) {
+      for (size_t j = 0; j < kFftLengthBy2; j += 4) {
+        const float32x4_t re = vld1q_f32(&H[p][ch].re[j]);
+        const float32x4_t im = vld1q_f32(&H[p][ch].im[j]);
+        float32x4_t H2_new = vmulq_f32(re, re);
+        H2_new = vmlaq_f32(H2_new, im, im);
+        float32x4_t H2_p_j = vld1q_f32(&(*H2)[p][j]);
+        H2_p_j = vmaxq_f32(H2_p_j, H2_new);
+        vst1q_f32(&(*H2)[p][j], H2_p_j);
+      }
+      float H2_new = H[p][ch].re[kFftLengthBy2] * H[p][ch].re[kFftLengthBy2] +
+                     H[p][ch].im[kFftLengthBy2] * H[p][ch].im[kFftLengthBy2];
+      (*H2)[p][kFftLengthBy2] = std::max((*H2)[p][kFftLengthBy2], H2_new);
+    }
+  }
+}
+#endif
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+// Computes and stores the frequency response of the filter.
+void ComputeFrequencyResponse_Sse2(
+    size_t num_partitions,
+    const std::vector<std::vector<FftData>>& H,
+    std::vector<std::array<float, kFftLengthBy2Plus1>>* H2) {
+  for (auto& H2_ch : *H2) {
+    H2_ch.fill(0.f);
+  }
+
+  const size_t num_render_channels = H[0].size();
+  RTC_DCHECK_EQ(H.size(), H2->capacity());
+  // constexpr __mmmask8 kMaxMask = static_cast<__mmmask8>(256u);
+  for (size_t p = 0; p < num_partitions; ++p) {
+    RTC_DCHECK_EQ(kFftLengthBy2Plus1, (*H2)[p].size());
+    for (size_t ch = 0; ch < num_render_channels; ++ch) {
+      for (size_t j = 0; j < kFftLengthBy2; j += 4) {
+        const __m128 re = _mm_loadu_ps(&H[p][ch].re[j]);
+        const __m128 re2 = _mm_mul_ps(re, re);
+        const __m128 im = _mm_loadu_ps(&H[p][ch].im[j]);
+        const __m128 im2 = _mm_mul_ps(im, im);
+        const __m128 H2_new = _mm_add_ps(re2, im2);
+        __m128 H2_k_j = _mm_loadu_ps(&(*H2)[p][j]);
+        H2_k_j = _mm_max_ps(H2_k_j, H2_new);
+        _mm_storeu_ps(&(*H2)[p][j], H2_k_j);
+      }
+      float H2_new = H[p][ch].re[kFftLengthBy2] * H[p][ch].re[kFftLengthBy2] +
+                     H[p][ch].im[kFftLengthBy2] * H[p][ch].im[kFftLengthBy2];
+      (*H2)[p][kFftLengthBy2] = std::max((*H2)[p][kFftLengthBy2], H2_new);
+    }
+  }
+}
+#endif
+
+// Adapts the filter partitions as H(t+1)=H(t)+G(t)*conj(X(t)).
+void AdaptPartitions(const RenderBuffer& render_buffer,
+                     const FftData& G,
+                     size_t num_partitions,
+                     std::vector<std::vector<FftData>>* H) {
+  rtc::ArrayView<const std::vector<FftData>> render_buffer_data =
+      render_buffer.GetFftBuffer();
+  size_t index = render_buffer.Position();
+  const size_t num_render_channels = render_buffer_data[index].size();
+  for (size_t p = 0; p < num_partitions; ++p) {
+    for (size_t ch = 0; ch < num_render_channels; ++ch) {
+      const FftData& X_p_ch = render_buffer_data[index][ch];
+      FftData& H_p_ch = (*H)[p][ch];
+      for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+        H_p_ch.re[k] += X_p_ch.re[k] * G.re[k] + X_p_ch.im[k] * G.im[k];
+        H_p_ch.im[k] += X_p_ch.re[k] * G.im[k] - X_p_ch.im[k] * G.re[k];
+      }
+    }
+    index = index < (render_buffer_data.size() - 1) ? index + 1 : 0;
+  }
+}
+
+#if defined(WEBRTC_HAS_NEON)
+// Adapts the filter partitions. (Neon variant)
+void AdaptPartitions_Neon(const RenderBuffer& render_buffer,
+                          const FftData& G,
+                          size_t num_partitions,
+                          std::vector<std::vector<FftData>>* H) {
+  rtc::ArrayView<const std::vector<FftData>> render_buffer_data =
+      render_buffer.GetFftBuffer();
+  const size_t num_render_channels = render_buffer_data[0].size();
+  const size_t lim1 = std::min(
+      render_buffer_data.size() - render_buffer.Position(), num_partitions);
+  const size_t lim2 = num_partitions;
+  constexpr size_t kNumFourBinBands = kFftLengthBy2 / 4;
+
+  size_t X_partition = render_buffer.Position();
+  size_t limit = lim1;
+  size_t p = 0;
+  do {
+    for (; p < limit; ++p, ++X_partition) {
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        FftData& H_p_ch = (*H)[p][ch];
+        const FftData& X = render_buffer_data[X_partition][ch];
+        for (size_t k = 0, n = 0; n < kNumFourBinBands; ++n, k += 4) {
+          const float32x4_t G_re = vld1q_f32(&G.re[k]);
+          const float32x4_t G_im = vld1q_f32(&G.im[k]);
+          const float32x4_t X_re = vld1q_f32(&X.re[k]);
+          const float32x4_t X_im = vld1q_f32(&X.im[k]);
+          const float32x4_t H_re = vld1q_f32(&H_p_ch.re[k]);
+          const float32x4_t H_im = vld1q_f32(&H_p_ch.im[k]);
+          const float32x4_t a = vmulq_f32(X_re, G_re);
+          const float32x4_t e = vmlaq_f32(a, X_im, G_im);
+          const float32x4_t c = vmulq_f32(X_re, G_im);
+          const float32x4_t f = vmlsq_f32(c, X_im, G_re);
+          const float32x4_t g = vaddq_f32(H_re, e);
+          const float32x4_t h = vaddq_f32(H_im, f);
+          vst1q_f32(&H_p_ch.re[k], g);
+          vst1q_f32(&H_p_ch.im[k], h);
+        }
+      }
+    }
+
+    X_partition = 0;
+    limit = lim2;
+  } while (p < lim2);
+
+  X_partition = render_buffer.Position();
+  limit = lim1;
+  p = 0;
+  do {
+    for (; p < limit; ++p, ++X_partition) {
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        FftData& H_p_ch = (*H)[p][ch];
+        const FftData& X = render_buffer_data[X_partition][ch];
+
+        H_p_ch.re[kFftLengthBy2] += X.re[kFftLengthBy2] * G.re[kFftLengthBy2] +
+                                    X.im[kFftLengthBy2] * G.im[kFftLengthBy2];
+        H_p_ch.im[kFftLengthBy2] += X.re[kFftLengthBy2] * G.im[kFftLengthBy2] -
+                                    X.im[kFftLengthBy2] * G.re[kFftLengthBy2];
+      }
+    }
+    X_partition = 0;
+    limit = lim2;
+  } while (p < lim2);
+}
+#endif
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+// Adapts the filter partitions. (SSE2 variant)
+void AdaptPartitions_Sse2(const RenderBuffer& render_buffer,
+                          const FftData& G,
+                          size_t num_partitions,
+                          std::vector<std::vector<FftData>>* H) {
+  rtc::ArrayView<const std::vector<FftData>> render_buffer_data =
+      render_buffer.GetFftBuffer();
+  const size_t num_render_channels = render_buffer_data[0].size();
+  const size_t lim1 = std::min(
+      render_buffer_data.size() - render_buffer.Position(), num_partitions);
+  const size_t lim2 = num_partitions;
+  constexpr size_t kNumFourBinBands = kFftLengthBy2 / 4;
+
+  size_t X_partition = render_buffer.Position();
+  size_t limit = lim1;
+  size_t p = 0;
+  do {
+    for (; p < limit; ++p, ++X_partition) {
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        FftData& H_p_ch = (*H)[p][ch];
+        const FftData& X = render_buffer_data[X_partition][ch];
+
+        for (size_t k = 0, n = 0; n < kNumFourBinBands; ++n, k += 4) {
+          const __m128 G_re = _mm_loadu_ps(&G.re[k]);
+          const __m128 G_im = _mm_loadu_ps(&G.im[k]);
+          const __m128 X_re = _mm_loadu_ps(&X.re[k]);
+          const __m128 X_im = _mm_loadu_ps(&X.im[k]);
+          const __m128 H_re = _mm_loadu_ps(&H_p_ch.re[k]);
+          const __m128 H_im = _mm_loadu_ps(&H_p_ch.im[k]);
+          const __m128 a = _mm_mul_ps(X_re, G_re);
+          const __m128 b = _mm_mul_ps(X_im, G_im);
+          const __m128 c = _mm_mul_ps(X_re, G_im);
+          const __m128 d = _mm_mul_ps(X_im, G_re);
+          const __m128 e = _mm_add_ps(a, b);
+          const __m128 f = _mm_sub_ps(c, d);
+          const __m128 g = _mm_add_ps(H_re, e);
+          const __m128 h = _mm_add_ps(H_im, f);
+          _mm_storeu_ps(&H_p_ch.re[k], g);
+          _mm_storeu_ps(&H_p_ch.im[k], h);
+        }
+      }
+    }
+    X_partition = 0;
+    limit = lim2;
+  } while (p < lim2);
+
+  X_partition = render_buffer.Position();
+  limit = lim1;
+  p = 0;
+  do {
+    for (; p < limit; ++p, ++X_partition) {
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        FftData& H_p_ch = (*H)[p][ch];
+        const FftData& X = render_buffer_data[X_partition][ch];
+
+        H_p_ch.re[kFftLengthBy2] += X.re[kFftLengthBy2] * G.re[kFftLengthBy2] +
+                                    X.im[kFftLengthBy2] * G.im[kFftLengthBy2];
+        H_p_ch.im[kFftLengthBy2] += X.re[kFftLengthBy2] * G.im[kFftLengthBy2] -
+                                    X.im[kFftLengthBy2] * G.re[kFftLengthBy2];
+      }
+    }
+
+    X_partition = 0;
+    limit = lim2;
+  } while (p < lim2);
+}
+#endif
+
+// Produces the filter output.
+void ApplyFilter(const RenderBuffer& render_buffer,
+                 size_t num_partitions,
+                 const std::vector<std::vector<FftData>>& H,
+                 FftData* S) {
+  S->re.fill(0.f);
+  S->im.fill(0.f);
+
+  rtc::ArrayView<const std::vector<FftData>> render_buffer_data =
+      render_buffer.GetFftBuffer();
+  size_t index = render_buffer.Position();
+  const size_t num_render_channels = render_buffer_data[index].size();
+  for (size_t p = 0; p < num_partitions; ++p) {
+    RTC_DCHECK_EQ(num_render_channels, H[p].size());
+    for (size_t ch = 0; ch < num_render_channels; ++ch) {
+      const FftData& X_p_ch = render_buffer_data[index][ch];
+      const FftData& H_p_ch = H[p][ch];
+      for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+        S->re[k] += X_p_ch.re[k] * H_p_ch.re[k] - X_p_ch.im[k] * H_p_ch.im[k];
+        S->im[k] += X_p_ch.re[k] * H_p_ch.im[k] + X_p_ch.im[k] * H_p_ch.re[k];
+      }
+    }
+    index = index < (render_buffer_data.size() - 1) ? index + 1 : 0;
+  }
+}
+
+#if defined(WEBRTC_HAS_NEON)
+// Produces the filter output (Neon variant).
+void ApplyFilter_Neon(const RenderBuffer& render_buffer,
+                      size_t num_partitions,
+                      const std::vector<std::vector<FftData>>& H,
+                      FftData* S) {
+  // const RenderBuffer& render_buffer,
+  //                     rtc::ArrayView<const FftData> H,
+  //                     FftData* S) {
+  RTC_DCHECK_GE(H.size(), H.size() - 1);
+  S->Clear();
+
+  rtc::ArrayView<const std::vector<FftData>> render_buffer_data =
+      render_buffer.GetFftBuffer();
+  const size_t num_render_channels = render_buffer_data[0].size();
+  const size_t lim1 = std::min(
+      render_buffer_data.size() - render_buffer.Position(), num_partitions);
+  const size_t lim2 = num_partitions;
+  constexpr size_t kNumFourBinBands = kFftLengthBy2 / 4;
+
+  size_t X_partition = render_buffer.Position();
+  size_t p = 0;
+  size_t limit = lim1;
+  do {
+    for (; p < limit; ++p, ++X_partition) {
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        const FftData& H_p_ch = H[p][ch];
+        const FftData& X = render_buffer_data[X_partition][ch];
+        for (size_t k = 0, n = 0; n < kNumFourBinBands; ++n, k += 4) {
+          const float32x4_t X_re = vld1q_f32(&X.re[k]);
+          const float32x4_t X_im = vld1q_f32(&X.im[k]);
+          const float32x4_t H_re = vld1q_f32(&H_p_ch.re[k]);
+          const float32x4_t H_im = vld1q_f32(&H_p_ch.im[k]);
+          const float32x4_t S_re = vld1q_f32(&S->re[k]);
+          const float32x4_t S_im = vld1q_f32(&S->im[k]);
+          const float32x4_t a = vmulq_f32(X_re, H_re);
+          const float32x4_t e = vmlsq_f32(a, X_im, H_im);
+          const float32x4_t c = vmulq_f32(X_re, H_im);
+          const float32x4_t f = vmlaq_f32(c, X_im, H_re);
+          const float32x4_t g = vaddq_f32(S_re, e);
+          const float32x4_t h = vaddq_f32(S_im, f);
+          vst1q_f32(&S->re[k], g);
+          vst1q_f32(&S->im[k], h);
+        }
+      }
+    }
+    limit = lim2;
+    X_partition = 0;
+  } while (p < lim2);
+
+  X_partition = render_buffer.Position();
+  p = 0;
+  limit = lim1;
+  do {
+    for (; p < limit; ++p, ++X_partition) {
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        const FftData& H_p_ch = H[p][ch];
+        const FftData& X = render_buffer_data[X_partition][ch];
+        S->re[kFftLengthBy2] += X.re[kFftLengthBy2] * H_p_ch.re[kFftLengthBy2] -
+                                X.im[kFftLengthBy2] * H_p_ch.im[kFftLengthBy2];
+        S->im[kFftLengthBy2] += X.re[kFftLengthBy2] * H_p_ch.im[kFftLengthBy2] +
+                                X.im[kFftLengthBy2] * H_p_ch.re[kFftLengthBy2];
+      }
+    }
+    limit = lim2;
+    X_partition = 0;
+  } while (p < lim2);
+}
+#endif
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+// Produces the filter output (SSE2 variant).
+void ApplyFilter_Sse2(const RenderBuffer& render_buffer,
+                      size_t num_partitions,
+                      const std::vector<std::vector<FftData>>& H,
+                      FftData* S) {
+  // const RenderBuffer& render_buffer,
+  //                     rtc::ArrayView<const FftData> H,
+  //                     FftData* S) {
+  RTC_DCHECK_GE(H.size(), H.size() - 1);
+  S->re.fill(0.f);
+  S->im.fill(0.f);
+
+  rtc::ArrayView<const std::vector<FftData>> render_buffer_data =
+      render_buffer.GetFftBuffer();
+  const size_t num_render_channels = render_buffer_data[0].size();
+  const size_t lim1 = std::min(
+      render_buffer_data.size() - render_buffer.Position(), num_partitions);
+  const size_t lim2 = num_partitions;
+  constexpr size_t kNumFourBinBands = kFftLengthBy2 / 4;
+
+  size_t X_partition = render_buffer.Position();
+  size_t p = 0;
+  size_t limit = lim1;
+  do {
+    for (; p < limit; ++p, ++X_partition) {
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        const FftData& H_p_ch = H[p][ch];
+        const FftData& X = render_buffer_data[X_partition][ch];
+        for (size_t k = 0, n = 0; n < kNumFourBinBands; ++n, k += 4) {
+          const __m128 X_re = _mm_loadu_ps(&X.re[k]);
+          const __m128 X_im = _mm_loadu_ps(&X.im[k]);
+          const __m128 H_re = _mm_loadu_ps(&H_p_ch.re[k]);
+          const __m128 H_im = _mm_loadu_ps(&H_p_ch.im[k]);
+          const __m128 S_re = _mm_loadu_ps(&S->re[k]);
+          const __m128 S_im = _mm_loadu_ps(&S->im[k]);
+          const __m128 a = _mm_mul_ps(X_re, H_re);
+          const __m128 b = _mm_mul_ps(X_im, H_im);
+          const __m128 c = _mm_mul_ps(X_re, H_im);
+          const __m128 d = _mm_mul_ps(X_im, H_re);
+          const __m128 e = _mm_sub_ps(a, b);
+          const __m128 f = _mm_add_ps(c, d);
+          const __m128 g = _mm_add_ps(S_re, e);
+          const __m128 h = _mm_add_ps(S_im, f);
+          _mm_storeu_ps(&S->re[k], g);
+          _mm_storeu_ps(&S->im[k], h);
+        }
+      }
+    }
+    limit = lim2;
+    X_partition = 0;
+  } while (p < lim2);
+
+  X_partition = render_buffer.Position();
+  p = 0;
+  limit = lim1;
+  do {
+    for (; p < limit; ++p, ++X_partition) {
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        const FftData& H_p_ch = H[p][ch];
+        const FftData& X = render_buffer_data[X_partition][ch];
+        S->re[kFftLengthBy2] += X.re[kFftLengthBy2] * H_p_ch.re[kFftLengthBy2] -
+                                X.im[kFftLengthBy2] * H_p_ch.im[kFftLengthBy2];
+        S->im[kFftLengthBy2] += X.re[kFftLengthBy2] * H_p_ch.im[kFftLengthBy2] +
+                                X.im[kFftLengthBy2] * H_p_ch.re[kFftLengthBy2];
+      }
+    }
+    limit = lim2;
+    X_partition = 0;
+  } while (p < lim2);
+}
+#endif
+
+}  // namespace aec3
+
+namespace {
+
+// Ensures that the newly added filter partitions after a size increase are set
+// to zero.
+void ZeroFilter(size_t old_size,
+                size_t new_size,
+                std::vector<std::vector<FftData>>* H) {
+  RTC_DCHECK_GE(H->size(), old_size);
+  RTC_DCHECK_GE(H->size(), new_size);
+
+  for (size_t p = old_size; p < new_size; ++p) {
+    RTC_DCHECK_EQ((*H)[p].size(), (*H)[0].size());
+    for (size_t ch = 0; ch < (*H)[0].size(); ++ch) {
+      (*H)[p][ch].Clear();
+    }
+  }
+}
+
+}  // namespace
+
+AdaptiveFirFilter::AdaptiveFirFilter(size_t max_size_partitions,
+                                     size_t initial_size_partitions,
+                                     size_t size_change_duration_blocks,
+                                     size_t num_render_channels,
+                                     Aec3Optimization optimization,
+                                     ApmDataDumper* data_dumper)
+    : data_dumper_(data_dumper),
+      fft_(),
+      optimization_(optimization),
+      num_render_channels_(num_render_channels),
+      max_size_partitions_(max_size_partitions),
+      size_change_duration_blocks_(
+          static_cast<int>(size_change_duration_blocks)),
+      current_size_partitions_(initial_size_partitions),
+      target_size_partitions_(initial_size_partitions),
+      old_target_size_partitions_(initial_size_partitions),
+      H_(max_size_partitions_, std::vector<FftData>(num_render_channels_)) {
+  RTC_DCHECK(data_dumper_);
+  RTC_DCHECK_GE(max_size_partitions, initial_size_partitions);
+
+  RTC_DCHECK_LT(0, size_change_duration_blocks_);
+  one_by_size_change_duration_blocks_ = 1.f / size_change_duration_blocks_;
+
+  ZeroFilter(0, max_size_partitions_, &H_);
+
+  SetSizePartitions(current_size_partitions_, true);
+}
+
+AdaptiveFirFilter::~AdaptiveFirFilter() = default;
+
+void AdaptiveFirFilter::HandleEchoPathChange() {
+  // TODO(peah): Check the value and purpose of the code below.
+  ZeroFilter(current_size_partitions_, max_size_partitions_, &H_);
+}
+
+void AdaptiveFirFilter::SetSizePartitions(size_t size, bool immediate_effect) {
+  RTC_DCHECK_EQ(max_size_partitions_, H_.capacity());
+  RTC_DCHECK_LE(size, max_size_partitions_);
+
+  target_size_partitions_ = std::min(max_size_partitions_, size);
+  if (immediate_effect) {
+    size_t old_size_partitions_ = current_size_partitions_;
+    current_size_partitions_ = old_target_size_partitions_ =
+        target_size_partitions_;
+    ZeroFilter(old_size_partitions_, current_size_partitions_, &H_);
+
+    partition_to_constrain_ =
+        std::min(partition_to_constrain_, current_size_partitions_ - 1);
+    size_change_counter_ = 0;
+  } else {
+    size_change_counter_ = size_change_duration_blocks_;
+  }
+}
+
+void AdaptiveFirFilter::UpdateSize() {
+  RTC_DCHECK_GE(size_change_duration_blocks_, size_change_counter_);
+  size_t old_size_partitions_ = current_size_partitions_;
+  if (size_change_counter_ > 0) {
+    --size_change_counter_;
+
+    auto average = [](float from, float to, float from_weight) {
+      return from * from_weight + to * (1.f - from_weight);
+    };
+
+    float change_factor =
+        size_change_counter_ * one_by_size_change_duration_blocks_;
+
+    current_size_partitions_ = average(old_target_size_partitions_,
+                                       target_size_partitions_, change_factor);
+
+    partition_to_constrain_ =
+        std::min(partition_to_constrain_, current_size_partitions_ - 1);
+  } else {
+    current_size_partitions_ = old_target_size_partitions_ =
+        target_size_partitions_;
+  }
+  ZeroFilter(old_size_partitions_, current_size_partitions_, &H_);
+  RTC_DCHECK_LE(0, size_change_counter_);
+}
+
+void AdaptiveFirFilter::Filter(const RenderBuffer& render_buffer,
+                               FftData* S) const {
+  RTC_DCHECK(S);
+  switch (optimization_) {
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+    case Aec3Optimization::kSse2:
+      aec3::ApplyFilter_Sse2(render_buffer, current_size_partitions_, H_, S);
+      break;
+    case Aec3Optimization::kAvx2:
+      aec3::ApplyFilter_Avx2(render_buffer, current_size_partitions_, H_, S);
+      break;
+#endif
+#if defined(WEBRTC_HAS_NEON)
+    case Aec3Optimization::kNeon:
+      aec3::ApplyFilter_Neon(render_buffer, current_size_partitions_, H_, S);
+      break;
+#endif
+    default:
+      aec3::ApplyFilter(render_buffer, current_size_partitions_, H_, S);
+  }
+}
+
+void AdaptiveFirFilter::Adapt(const RenderBuffer& render_buffer,
+                              const FftData& G) {
+  // Adapt the filter and update the filter size.
+  AdaptAndUpdateSize(render_buffer, G);
+
+  // Constrain the filter partitions in a cyclic manner.
+  Constrain();
+}
+
+void AdaptiveFirFilter::Adapt(const RenderBuffer& render_buffer,
+                              const FftData& G,
+                              std::vector<float>* impulse_response) {
+  // Adapt the filter and update the filter size.
+  AdaptAndUpdateSize(render_buffer, G);
+
+  // Constrain the filter partitions in a cyclic manner.
+  ConstrainAndUpdateImpulseResponse(impulse_response);
+}
+
+void AdaptiveFirFilter::ComputeFrequencyResponse(
+    std::vector<std::array<float, kFftLengthBy2Plus1>>* H2) const {
+  RTC_DCHECK_GE(max_size_partitions_, H2->capacity());
+
+  H2->resize(current_size_partitions_);
+
+  switch (optimization_) {
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+    case Aec3Optimization::kSse2:
+      aec3::ComputeFrequencyResponse_Sse2(current_size_partitions_, H_, H2);
+      break;
+    case Aec3Optimization::kAvx2:
+      aec3::ComputeFrequencyResponse_Avx2(current_size_partitions_, H_, H2);
+      break;
+#endif
+#if defined(WEBRTC_HAS_NEON)
+    case Aec3Optimization::kNeon:
+      aec3::ComputeFrequencyResponse_Neon(current_size_partitions_, H_, H2);
+      break;
+#endif
+    default:
+      aec3::ComputeFrequencyResponse(current_size_partitions_, H_, H2);
+  }
+}
+
+void AdaptiveFirFilter::AdaptAndUpdateSize(const RenderBuffer& render_buffer,
+                                           const FftData& G) {
+  // Update the filter size if needed.
+  UpdateSize();
+
+  // Adapt the filter.
+  switch (optimization_) {
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+    case Aec3Optimization::kSse2:
+      aec3::AdaptPartitions_Sse2(render_buffer, G, current_size_partitions_,
+                                 &H_);
+      break;
+    case Aec3Optimization::kAvx2:
+      aec3::AdaptPartitions_Avx2(render_buffer, G, current_size_partitions_,
+                                 &H_);
+      break;
+#endif
+#if defined(WEBRTC_HAS_NEON)
+    case Aec3Optimization::kNeon:
+      aec3::AdaptPartitions_Neon(render_buffer, G, current_size_partitions_,
+                                 &H_);
+      break;
+#endif
+    default:
+      aec3::AdaptPartitions(render_buffer, G, current_size_partitions_, &H_);
+  }
+}
+
+// Constrains the partition of the frequency domain filter to be limited in
+// time via setting the relevant time-domain coefficients to zero and updates
+// the corresponding values in an externally stored impulse response estimate.
+void AdaptiveFirFilter::ConstrainAndUpdateImpulseResponse(
+    std::vector<float>* impulse_response) {
+  RTC_DCHECK_EQ(GetTimeDomainLength(max_size_partitions_),
+                impulse_response->capacity());
+  impulse_response->resize(GetTimeDomainLength(current_size_partitions_));
+  std::array<float, kFftLength> h;
+  impulse_response->resize(GetTimeDomainLength(current_size_partitions_));
+  std::fill(
+      impulse_response->begin() + partition_to_constrain_ * kFftLengthBy2,
+      impulse_response->begin() + (partition_to_constrain_ + 1) * kFftLengthBy2,
+      0.f);
+
+  for (size_t ch = 0; ch < num_render_channels_; ++ch) {
+    fft_.Ifft(H_[partition_to_constrain_][ch], &h);
+
+    static constexpr float kScale = 1.0f / kFftLengthBy2;
+    std::for_each(h.begin(), h.begin() + kFftLengthBy2,
+                  [](float& a) { a *= kScale; });
+    std::fill(h.begin() + kFftLengthBy2, h.end(), 0.f);
+
+    if (ch == 0) {
+      std::copy(
+          h.begin(), h.begin() + kFftLengthBy2,
+          impulse_response->begin() + partition_to_constrain_ * kFftLengthBy2);
+    } else {
+      for (size_t k = 0, j = partition_to_constrain_ * kFftLengthBy2;
+           k < kFftLengthBy2; ++k, ++j) {
+        if (fabsf((*impulse_response)[j]) < fabsf(h[k])) {
+          (*impulse_response)[j] = h[k];
+        }
+      }
+    }
+
+    fft_.Fft(&h, &H_[partition_to_constrain_][ch]);
+  }
+
+  partition_to_constrain_ =
+      partition_to_constrain_ < (current_size_partitions_ - 1)
+          ? partition_to_constrain_ + 1
+          : 0;
+}
+
+// Constrains the a partiton of the frequency domain filter to be limited in
+// time via setting the relevant time-domain coefficients to zero.
+void AdaptiveFirFilter::Constrain() {
+  std::array<float, kFftLength> h;
+  for (size_t ch = 0; ch < num_render_channels_; ++ch) {
+    fft_.Ifft(H_[partition_to_constrain_][ch], &h);
+
+    static constexpr float kScale = 1.0f / kFftLengthBy2;
+    std::for_each(h.begin(), h.begin() + kFftLengthBy2,
+                  [](float& a) { a *= kScale; });
+    std::fill(h.begin() + kFftLengthBy2, h.end(), 0.f);
+
+    fft_.Fft(&h, &H_[partition_to_constrain_][ch]);
+  }
+
+  partition_to_constrain_ =
+      partition_to_constrain_ < (current_size_partitions_ - 1)
+          ? partition_to_constrain_ + 1
+          : 0;
+}
+
+void AdaptiveFirFilter::ScaleFilter(float factor) {
+  for (auto& H_p : H_) {
+    for (auto& H_p_ch : H_p) {
+      for (auto& re : H_p_ch.re) {
+        re *= factor;
+      }
+      for (auto& im : H_p_ch.im) {
+        im *= factor;
+      }
+    }
+  }
+}
+
+// Set the filter coefficients.
+void AdaptiveFirFilter::SetFilter(size_t num_partitions,
+                                  const std::vector<std::vector<FftData>>& H) {
+  const size_t min_num_partitions =
+      std::min(current_size_partitions_, num_partitions);
+  for (size_t p = 0; p < min_num_partitions; ++p) {
+    RTC_DCHECK_EQ(H_[p].size(), H[p].size());
+    RTC_DCHECK_EQ(num_render_channels_, H_[p].size());
+
+    for (size_t ch = 0; ch < num_render_channels_; ++ch) {
+      std::copy(H[p][ch].re.begin(), H[p][ch].re.end(), H_[p][ch].re.begin());
+      std::copy(H[p][ch].im.begin(), H[p][ch].im.end(), H_[p][ch].im.begin());
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter.h
new file mode 100644
index 0000000..7597709
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter.h
@@ -0,0 +1,191 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_ADAPTIVE_FIR_FILTER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_ADAPTIVE_FIR_FILTER_H_
+
+#include <stddef.h>
+
+#include <array>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/aec3_fft.h"
+#include "modules/audio_processing/aec3/fft_data.h"
+#include "modules/audio_processing/aec3/render_buffer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/system/arch.h"
+
+namespace webrtc {
+namespace aec3 {
+// Computes and stores the frequency response of the filter.
+void ComputeFrequencyResponse(
+    size_t num_partitions,
+    const std::vector<std::vector<FftData>>& H,
+    std::vector<std::array<float, kFftLengthBy2Plus1>>* H2);
+#if defined(WEBRTC_HAS_NEON)
+void ComputeFrequencyResponse_Neon(
+    size_t num_partitions,
+    const std::vector<std::vector<FftData>>& H,
+    std::vector<std::array<float, kFftLengthBy2Plus1>>* H2);
+#endif
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+void ComputeFrequencyResponse_Sse2(
+    size_t num_partitions,
+    const std::vector<std::vector<FftData>>& H,
+    std::vector<std::array<float, kFftLengthBy2Plus1>>* H2);
+
+void ComputeFrequencyResponse_Avx2(
+    size_t num_partitions,
+    const std::vector<std::vector<FftData>>& H,
+    std::vector<std::array<float, kFftLengthBy2Plus1>>* H2);
+#endif
+
+// Adapts the filter partitions.
+void AdaptPartitions(const RenderBuffer& render_buffer,
+                     const FftData& G,
+                     size_t num_partitions,
+                     std::vector<std::vector<FftData>>* H);
+#if defined(WEBRTC_HAS_NEON)
+void AdaptPartitions_Neon(const RenderBuffer& render_buffer,
+                          const FftData& G,
+                          size_t num_partitions,
+                          std::vector<std::vector<FftData>>* H);
+#endif
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+void AdaptPartitions_Sse2(const RenderBuffer& render_buffer,
+                          const FftData& G,
+                          size_t num_partitions,
+                          std::vector<std::vector<FftData>>* H);
+
+void AdaptPartitions_Avx2(const RenderBuffer& render_buffer,
+                          const FftData& G,
+                          size_t num_partitions,
+                          std::vector<std::vector<FftData>>* H);
+#endif
+
+// Produces the filter output.
+void ApplyFilter(const RenderBuffer& render_buffer,
+                 size_t num_partitions,
+                 const std::vector<std::vector<FftData>>& H,
+                 FftData* S);
+#if defined(WEBRTC_HAS_NEON)
+void ApplyFilter_Neon(const RenderBuffer& render_buffer,
+                      size_t num_partitions,
+                      const std::vector<std::vector<FftData>>& H,
+                      FftData* S);
+#endif
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+void ApplyFilter_Sse2(const RenderBuffer& render_buffer,
+                      size_t num_partitions,
+                      const std::vector<std::vector<FftData>>& H,
+                      FftData* S);
+
+void ApplyFilter_Avx2(const RenderBuffer& render_buffer,
+                      size_t num_partitions,
+                      const std::vector<std::vector<FftData>>& H,
+                      FftData* S);
+#endif
+
+}  // namespace aec3
+
+// Provides a frequency domain adaptive filter functionality.
+class AdaptiveFirFilter {
+ public:
+  AdaptiveFirFilter(size_t max_size_partitions,
+                    size_t initial_size_partitions,
+                    size_t size_change_duration_blocks,
+                    size_t num_render_channels,
+                    Aec3Optimization optimization,
+                    ApmDataDumper* data_dumper);
+
+  ~AdaptiveFirFilter();
+
+  AdaptiveFirFilter(const AdaptiveFirFilter&) = delete;
+  AdaptiveFirFilter& operator=(const AdaptiveFirFilter&) = delete;
+
+  // Produces the output of the filter.
+  void Filter(const RenderBuffer& render_buffer, FftData* S) const;
+
+  // Adapts the filter and updates an externally stored impulse response
+  // estimate.
+  void Adapt(const RenderBuffer& render_buffer,
+             const FftData& G,
+             std::vector<float>* impulse_response);
+
+  // Adapts the filter.
+  void Adapt(const RenderBuffer& render_buffer, const FftData& G);
+
+  // Receives reports that known echo path changes have occured and adjusts
+  // the filter adaptation accordingly.
+  void HandleEchoPathChange();
+
+  // Returns the filter size.
+  size_t SizePartitions() const { return current_size_partitions_; }
+
+  // Sets the filter size.
+  void SetSizePartitions(size_t size, bool immediate_effect);
+
+  // Computes the frequency responses for the filter partitions.
+  void ComputeFrequencyResponse(
+      std::vector<std::array<float, kFftLengthBy2Plus1>>* H2) const;
+
+  // Returns the maximum number of partitions for the filter.
+  size_t max_filter_size_partitions() const { return max_size_partitions_; }
+
+  void DumpFilter(const char* name_frequency_domain) {
+    for (size_t p = 0; p < max_size_partitions_; ++p) {
+      data_dumper_->DumpRaw(name_frequency_domain, H_[p][0].re);
+      data_dumper_->DumpRaw(name_frequency_domain, H_[p][0].im);
+    }
+  }
+
+  // Scale the filter impulse response and spectrum by a factor.
+  void ScaleFilter(float factor);
+
+  // Set the filter coefficients.
+  void SetFilter(size_t num_partitions,
+                 const std::vector<std::vector<FftData>>& H);
+
+  // Gets the filter coefficients.
+  const std::vector<std::vector<FftData>>& GetFilter() const { return H_; }
+
+ private:
+  // Adapts the filter and updates the filter size.
+  void AdaptAndUpdateSize(const RenderBuffer& render_buffer, const FftData& G);
+
+  // Constrain the filter partitions in a cyclic manner.
+  void Constrain();
+  // Constrains the filter in a cyclic manner and updates the corresponding
+  // values in the supplied impulse response.
+  void ConstrainAndUpdateImpulseResponse(std::vector<float>* impulse_response);
+
+  // Gradually Updates the current filter size towards the target size.
+  void UpdateSize();
+
+  ApmDataDumper* const data_dumper_;
+  const Aec3Fft fft_;
+  const Aec3Optimization optimization_;
+  const size_t num_render_channels_;
+  const size_t max_size_partitions_;
+  const int size_change_duration_blocks_;
+  float one_by_size_change_duration_blocks_;
+  size_t current_size_partitions_;
+  size_t target_size_partitions_;
+  size_t old_target_size_partitions_;
+  int size_change_counter_ = 0;
+  std::vector<std::vector<FftData>> H_;
+  size_t partition_to_constrain_ = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_ADAPTIVE_FIR_FILTER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_avx2.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_avx2.cc
new file mode 100644
index 0000000..245b45a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_avx2.cc
@@ -0,0 +1,187 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/adaptive_fir_filter.h"
+
+#include <immintrin.h>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+namespace aec3 {
+
+// Computes and stores the frequency response of the filter.
+void ComputeFrequencyResponse_Avx2(
+    size_t num_partitions,
+    const std::vector<std::vector<FftData>>& H,
+    std::vector<std::array<float, kFftLengthBy2Plus1>>* H2) {
+  for (auto& H2_ch : *H2) {
+    H2_ch.fill(0.f);
+  }
+
+  const size_t num_render_channels = H[0].size();
+  RTC_DCHECK_EQ(H.size(), H2->capacity());
+  for (size_t p = 0; p < num_partitions; ++p) {
+    RTC_DCHECK_EQ(kFftLengthBy2Plus1, (*H2)[p].size());
+    for (size_t ch = 0; ch < num_render_channels; ++ch) {
+      for (size_t j = 0; j < kFftLengthBy2; j += 8) {
+        __m256 re = _mm256_loadu_ps(&H[p][ch].re[j]);
+        __m256 re2 = _mm256_mul_ps(re, re);
+        __m256 im = _mm256_loadu_ps(&H[p][ch].im[j]);
+        re2 = _mm256_fmadd_ps(im, im, re2);
+        __m256 H2_k_j = _mm256_loadu_ps(&(*H2)[p][j]);
+        H2_k_j = _mm256_max_ps(H2_k_j, re2);
+        _mm256_storeu_ps(&(*H2)[p][j], H2_k_j);
+      }
+      float H2_new = H[p][ch].re[kFftLengthBy2] * H[p][ch].re[kFftLengthBy2] +
+                     H[p][ch].im[kFftLengthBy2] * H[p][ch].im[kFftLengthBy2];
+      (*H2)[p][kFftLengthBy2] = std::max((*H2)[p][kFftLengthBy2], H2_new);
+    }
+  }
+}
+
+// Adapts the filter partitions.
+void AdaptPartitions_Avx2(const RenderBuffer& render_buffer,
+                          const FftData& G,
+                          size_t num_partitions,
+                          std::vector<std::vector<FftData>>* H) {
+  rtc::ArrayView<const std::vector<FftData>> render_buffer_data =
+      render_buffer.GetFftBuffer();
+  const size_t num_render_channels = render_buffer_data[0].size();
+  const size_t lim1 = std::min(
+      render_buffer_data.size() - render_buffer.Position(), num_partitions);
+  const size_t lim2 = num_partitions;
+  constexpr size_t kNumEightBinBands = kFftLengthBy2 / 8;
+
+  size_t X_partition = render_buffer.Position();
+  size_t limit = lim1;
+  size_t p = 0;
+  do {
+    for (; p < limit; ++p, ++X_partition) {
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        FftData& H_p_ch = (*H)[p][ch];
+        const FftData& X = render_buffer_data[X_partition][ch];
+
+        for (size_t k = 0, n = 0; n < kNumEightBinBands; ++n, k += 8) {
+          const __m256 G_re = _mm256_loadu_ps(&G.re[k]);
+          const __m256 G_im = _mm256_loadu_ps(&G.im[k]);
+          const __m256 X_re = _mm256_loadu_ps(&X.re[k]);
+          const __m256 X_im = _mm256_loadu_ps(&X.im[k]);
+          const __m256 H_re = _mm256_loadu_ps(&H_p_ch.re[k]);
+          const __m256 H_im = _mm256_loadu_ps(&H_p_ch.im[k]);
+          const __m256 a = _mm256_mul_ps(X_re, G_re);
+          const __m256 b = _mm256_mul_ps(X_im, G_im);
+          const __m256 c = _mm256_mul_ps(X_re, G_im);
+          const __m256 d = _mm256_mul_ps(X_im, G_re);
+          const __m256 e = _mm256_add_ps(a, b);
+          const __m256 f = _mm256_sub_ps(c, d);
+          const __m256 g = _mm256_add_ps(H_re, e);
+          const __m256 h = _mm256_add_ps(H_im, f);
+          _mm256_storeu_ps(&H_p_ch.re[k], g);
+          _mm256_storeu_ps(&H_p_ch.im[k], h);
+        }
+      }
+    }
+    X_partition = 0;
+    limit = lim2;
+  } while (p < lim2);
+
+  X_partition = render_buffer.Position();
+  limit = lim1;
+  p = 0;
+  do {
+    for (; p < limit; ++p, ++X_partition) {
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        FftData& H_p_ch = (*H)[p][ch];
+        const FftData& X = render_buffer_data[X_partition][ch];
+
+        H_p_ch.re[kFftLengthBy2] += X.re[kFftLengthBy2] * G.re[kFftLengthBy2] +
+                                    X.im[kFftLengthBy2] * G.im[kFftLengthBy2];
+        H_p_ch.im[kFftLengthBy2] += X.re[kFftLengthBy2] * G.im[kFftLengthBy2] -
+                                    X.im[kFftLengthBy2] * G.re[kFftLengthBy2];
+      }
+    }
+
+    X_partition = 0;
+    limit = lim2;
+  } while (p < lim2);
+}
+
+// Produces the filter output (AVX2 variant).
+void ApplyFilter_Avx2(const RenderBuffer& render_buffer,
+                      size_t num_partitions,
+                      const std::vector<std::vector<FftData>>& H,
+                      FftData* S) {
+  RTC_DCHECK_GE(H.size(), H.size() - 1);
+  S->re.fill(0.f);
+  S->im.fill(0.f);
+
+  rtc::ArrayView<const std::vector<FftData>> render_buffer_data =
+      render_buffer.GetFftBuffer();
+  const size_t num_render_channels = render_buffer_data[0].size();
+  const size_t lim1 = std::min(
+      render_buffer_data.size() - render_buffer.Position(), num_partitions);
+  const size_t lim2 = num_partitions;
+  constexpr size_t kNumEightBinBands = kFftLengthBy2 / 8;
+
+  size_t X_partition = render_buffer.Position();
+  size_t p = 0;
+  size_t limit = lim1;
+  do {
+    for (; p < limit; ++p, ++X_partition) {
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        const FftData& H_p_ch = H[p][ch];
+        const FftData& X = render_buffer_data[X_partition][ch];
+        for (size_t k = 0, n = 0; n < kNumEightBinBands; ++n, k += 8) {
+          const __m256 X_re = _mm256_loadu_ps(&X.re[k]);
+          const __m256 X_im = _mm256_loadu_ps(&X.im[k]);
+          const __m256 H_re = _mm256_loadu_ps(&H_p_ch.re[k]);
+          const __m256 H_im = _mm256_loadu_ps(&H_p_ch.im[k]);
+          const __m256 S_re = _mm256_loadu_ps(&S->re[k]);
+          const __m256 S_im = _mm256_loadu_ps(&S->im[k]);
+          const __m256 a = _mm256_mul_ps(X_re, H_re);
+          const __m256 b = _mm256_mul_ps(X_im, H_im);
+          const __m256 c = _mm256_mul_ps(X_re, H_im);
+          const __m256 d = _mm256_mul_ps(X_im, H_re);
+          const __m256 e = _mm256_sub_ps(a, b);
+          const __m256 f = _mm256_add_ps(c, d);
+          const __m256 g = _mm256_add_ps(S_re, e);
+          const __m256 h = _mm256_add_ps(S_im, f);
+          _mm256_storeu_ps(&S->re[k], g);
+          _mm256_storeu_ps(&S->im[k], h);
+        }
+      }
+    }
+    limit = lim2;
+    X_partition = 0;
+  } while (p < lim2);
+
+  X_partition = render_buffer.Position();
+  p = 0;
+  limit = lim1;
+  do {
+    for (; p < limit; ++p, ++X_partition) {
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        const FftData& H_p_ch = H[p][ch];
+        const FftData& X = render_buffer_data[X_partition][ch];
+        S->re[kFftLengthBy2] += X.re[kFftLengthBy2] * H_p_ch.re[kFftLengthBy2] -
+                                X.im[kFftLengthBy2] * H_p_ch.im[kFftLengthBy2];
+        S->im[kFftLengthBy2] += X.re[kFftLengthBy2] * H_p_ch.im[kFftLengthBy2] +
+                                X.im[kFftLengthBy2] * H_p_ch.re[kFftLengthBy2];
+      }
+    }
+    limit = lim2;
+    X_partition = 0;
+  } while (p < lim2);
+}
+
+}  // namespace aec3
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_erl.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_erl.cc
new file mode 100644
index 0000000..45b8813
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_erl.cc
@@ -0,0 +1,102 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/adaptive_fir_filter_erl.h"
+
+#include <algorithm>
+#include <functional>
+
+#if defined(WEBRTC_HAS_NEON)
+#include <arm_neon.h>
+#endif
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+#include <emmintrin.h>
+#endif
+
+namespace webrtc {
+
+namespace aec3 {
+
+// Computes and stores the echo return loss estimate of the filter, which is the
+// sum of the partition frequency responses.
+void ErlComputer(const std::vector<std::array<float, kFftLengthBy2Plus1>>& H2,
+                 rtc::ArrayView<float> erl) {
+  std::fill(erl.begin(), erl.end(), 0.f);
+  for (auto& H2_j : H2) {
+    std::transform(H2_j.begin(), H2_j.end(), erl.begin(), erl.begin(),
+                   std::plus<float>());
+  }
+}
+
+#if defined(WEBRTC_HAS_NEON)
+// Computes and stores the echo return loss estimate of the filter, which is the
+// sum of the partition frequency responses.
+void ErlComputer_NEON(
+    const std::vector<std::array<float, kFftLengthBy2Plus1>>& H2,
+    rtc::ArrayView<float> erl) {
+  std::fill(erl.begin(), erl.end(), 0.f);
+  for (auto& H2_j : H2) {
+    for (size_t k = 0; k < kFftLengthBy2; k += 4) {
+      const float32x4_t H2_j_k = vld1q_f32(&H2_j[k]);
+      float32x4_t erl_k = vld1q_f32(&erl[k]);
+      erl_k = vaddq_f32(erl_k, H2_j_k);
+      vst1q_f32(&erl[k], erl_k);
+    }
+    erl[kFftLengthBy2] += H2_j[kFftLengthBy2];
+  }
+}
+#endif
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+// Computes and stores the echo return loss estimate of the filter, which is the
+// sum of the partition frequency responses.
+void ErlComputer_SSE2(
+    const std::vector<std::array<float, kFftLengthBy2Plus1>>& H2,
+    rtc::ArrayView<float> erl) {
+  std::fill(erl.begin(), erl.end(), 0.f);
+  for (auto& H2_j : H2) {
+    for (size_t k = 0; k < kFftLengthBy2; k += 4) {
+      const __m128 H2_j_k = _mm_loadu_ps(&H2_j[k]);
+      __m128 erl_k = _mm_loadu_ps(&erl[k]);
+      erl_k = _mm_add_ps(erl_k, H2_j_k);
+      _mm_storeu_ps(&erl[k], erl_k);
+    }
+    erl[kFftLengthBy2] += H2_j[kFftLengthBy2];
+  }
+}
+#endif
+
+}  // namespace aec3
+
+void ComputeErl(const Aec3Optimization& optimization,
+                const std::vector<std::array<float, kFftLengthBy2Plus1>>& H2,
+                rtc::ArrayView<float> erl) {
+  RTC_DCHECK_EQ(kFftLengthBy2Plus1, erl.size());
+  // Update the frequency response and echo return loss for the filter.
+  switch (optimization) {
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+    case Aec3Optimization::kSse2:
+      aec3::ErlComputer_SSE2(H2, erl);
+      break;
+    case Aec3Optimization::kAvx2:
+      aec3::ErlComputer_AVX2(H2, erl);
+      break;
+#endif
+#if defined(WEBRTC_HAS_NEON)
+    case Aec3Optimization::kNeon:
+      aec3::ErlComputer_NEON(H2, erl);
+      break;
+#endif
+    default:
+      aec3::ErlComputer(H2, erl);
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_erl.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_erl.h
new file mode 100644
index 0000000..4ac13b1
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_erl.h
@@ -0,0 +1,54 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_ADAPTIVE_FIR_FILTER_ERL_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_ADAPTIVE_FIR_FILTER_ERL_H_
+
+#include <stddef.h>
+
+#include <array>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "rtc_base/system/arch.h"
+
+namespace webrtc {
+namespace aec3 {
+
+// Computes and stores the echo return loss estimate of the filter, which is the
+// sum of the partition frequency responses.
+void ErlComputer(const std::vector<std::array<float, kFftLengthBy2Plus1>>& H2,
+                 rtc::ArrayView<float> erl);
+#if defined(WEBRTC_HAS_NEON)
+void ErlComputer_NEON(
+    const std::vector<std::array<float, kFftLengthBy2Plus1>>& H2,
+    rtc::ArrayView<float> erl);
+#endif
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+void ErlComputer_SSE2(
+    const std::vector<std::array<float, kFftLengthBy2Plus1>>& H2,
+    rtc::ArrayView<float> erl);
+
+void ErlComputer_AVX2(
+    const std::vector<std::array<float, kFftLengthBy2Plus1>>& H2,
+    rtc::ArrayView<float> erl);
+#endif
+
+}  // namespace aec3
+
+// Computes the echo return loss based on a frequency response.
+void ComputeErl(const Aec3Optimization& optimization,
+                const std::vector<std::array<float, kFftLengthBy2Plus1>>& H2,
+                rtc::ArrayView<float> erl);
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_ADAPTIVE_FIR_FILTER_ERL_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_erl_avx2.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_erl_avx2.cc
new file mode 100644
index 0000000..5fe7514
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_erl_avx2.cc
@@ -0,0 +1,37 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/adaptive_fir_filter_erl.h"
+
+#include <immintrin.h>
+
+namespace webrtc {
+
+namespace aec3 {
+
+// Computes and stores the echo return loss estimate of the filter, which is the
+// sum of the partition frequency responses.
+void ErlComputer_AVX2(
+    const std::vector<std::array<float, kFftLengthBy2Plus1>>& H2,
+    rtc::ArrayView<float> erl) {
+  std::fill(erl.begin(), erl.end(), 0.f);
+  for (auto& H2_j : H2) {
+    for (size_t k = 0; k < kFftLengthBy2; k += 8) {
+      const __m256 H2_j_k = _mm256_loadu_ps(&H2_j[k]);
+      __m256 erl_k = _mm256_loadu_ps(&erl[k]);
+      erl_k = _mm256_add_ps(erl_k, H2_j_k);
+      _mm256_storeu_ps(&erl[k], erl_k);
+    }
+    erl[kFftLengthBy2] += H2_j[kFftLengthBy2];
+  }
+}
+
+}  // namespace aec3
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_erl_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_erl_unittest.cc
new file mode 100644
index 0000000..d2af70a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_erl_unittest.cc
@@ -0,0 +1,106 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/adaptive_fir_filter_erl.h"
+
+#include <array>
+#include <vector>
+
+#include "rtc_base/system/arch.h"
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+#include <emmintrin.h>
+#endif
+
+#include "system_wrappers/include/cpu_features_wrapper.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace aec3 {
+
+#if defined(WEBRTC_HAS_NEON)
+// Verifies that the optimized method for echo return loss computation is
+// bitexact to the reference counterpart.
+TEST(AdaptiveFirFilter, UpdateErlNeonOptimization) {
+  const size_t kNumPartitions = 12;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> H2(kNumPartitions);
+  std::array<float, kFftLengthBy2Plus1> erl;
+  std::array<float, kFftLengthBy2Plus1> erl_NEON;
+
+  for (size_t j = 0; j < H2.size(); ++j) {
+    for (size_t k = 0; k < H2[j].size(); ++k) {
+      H2[j][k] = k + j / 3.f;
+    }
+  }
+
+  ErlComputer(H2, erl);
+  ErlComputer_NEON(H2, erl_NEON);
+
+  for (size_t j = 0; j < erl.size(); ++j) {
+    EXPECT_FLOAT_EQ(erl[j], erl_NEON[j]);
+  }
+}
+
+#endif
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+// Verifies that the optimized method for echo return loss computation is
+// bitexact to the reference counterpart.
+TEST(AdaptiveFirFilter, UpdateErlSse2Optimization) {
+  bool use_sse2 = (GetCPUInfo(kSSE2) != 0);
+  if (use_sse2) {
+    const size_t kNumPartitions = 12;
+    std::vector<std::array<float, kFftLengthBy2Plus1>> H2(kNumPartitions);
+    std::array<float, kFftLengthBy2Plus1> erl;
+    std::array<float, kFftLengthBy2Plus1> erl_SSE2;
+
+    for (size_t j = 0; j < H2.size(); ++j) {
+      for (size_t k = 0; k < H2[j].size(); ++k) {
+        H2[j][k] = k + j / 3.f;
+      }
+    }
+
+    ErlComputer(H2, erl);
+    ErlComputer_SSE2(H2, erl_SSE2);
+
+    for (size_t j = 0; j < erl.size(); ++j) {
+      EXPECT_FLOAT_EQ(erl[j], erl_SSE2[j]);
+    }
+  }
+}
+
+// Verifies that the optimized method for echo return loss computation is
+// bitexact to the reference counterpart.
+TEST(AdaptiveFirFilter, UpdateErlAvx2Optimization) {
+  bool use_avx2 = (GetCPUInfo(kAVX2) != 0);
+  if (use_avx2) {
+    const size_t kNumPartitions = 12;
+    std::vector<std::array<float, kFftLengthBy2Plus1>> H2(kNumPartitions);
+    std::array<float, kFftLengthBy2Plus1> erl;
+    std::array<float, kFftLengthBy2Plus1> erl_AVX2;
+
+    for (size_t j = 0; j < H2.size(); ++j) {
+      for (size_t k = 0; k < H2[j].size(); ++k) {
+        H2[j][k] = k + j / 3.f;
+      }
+    }
+
+    ErlComputer(H2, erl);
+    ErlComputer_AVX2(H2, erl_AVX2);
+
+    for (size_t j = 0; j < erl.size(); ++j) {
+      EXPECT_FLOAT_EQ(erl[j], erl_AVX2[j]);
+    }
+  }
+}
+
+#endif
+
+}  // namespace aec3
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_unittest.cc
new file mode 100644
index 0000000..af7ea1d
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/adaptive_fir_filter_unittest.cc
@@ -0,0 +1,605 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/adaptive_fir_filter.h"
+
+// Defines WEBRTC_ARCH_X86_FAMILY, used below.
+#include <math.h>
+
+#include <algorithm>
+#include <numeric>
+#include <string>
+
+#include "rtc_base/system/arch.h"
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+#include <emmintrin.h>
+#endif
+
+#include "modules/audio_processing/aec3/adaptive_fir_filter_erl.h"
+#include "modules/audio_processing/aec3/aec3_fft.h"
+#include "modules/audio_processing/aec3/aec_state.h"
+#include "modules/audio_processing/aec3/coarse_filter_update_gain.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "modules/audio_processing/aec3/render_signal_analyzer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "modules/audio_processing/test/echo_canceller_test_tools.h"
+#include "modules/audio_processing/utility/cascaded_biquad_filter.h"
+#include "rtc_base/arraysize.h"
+#include "rtc_base/numerics/safe_minmax.h"
+#include "rtc_base/random.h"
+#include "rtc_base/strings/string_builder.h"
+#include "system_wrappers/include/cpu_features_wrapper.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace aec3 {
+namespace {
+
+std::string ProduceDebugText(size_t num_render_channels, size_t delay) {
+  rtc::StringBuilder ss;
+  ss << "delay: " << delay << ", ";
+  ss << "num_render_channels:" << num_render_channels;
+  return ss.Release();
+}
+
+}  // namespace
+
+class AdaptiveFirFilterOneTwoFourEightRenderChannels
+    : public ::testing::Test,
+      public ::testing::WithParamInterface<size_t> {};
+
+INSTANTIATE_TEST_SUITE_P(MultiChannel,
+                         AdaptiveFirFilterOneTwoFourEightRenderChannels,
+                         ::testing::Values(1, 2, 4, 8));
+
+#if defined(WEBRTC_HAS_NEON)
+// Verifies that the optimized methods for filter adaptation are similar to
+// their reference counterparts.
+TEST_P(AdaptiveFirFilterOneTwoFourEightRenderChannels,
+       FilterAdaptationNeonOptimizations) {
+  const size_t num_render_channels = GetParam();
+  for (size_t num_partitions : {2, 5, 12, 30, 50}) {
+    constexpr int kSampleRateHz = 48000;
+    constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+
+    std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+        RenderDelayBuffer::Create(EchoCanceller3Config(), kSampleRateHz,
+                                  num_render_channels));
+    Random random_generator(42U);
+    std::vector<std::vector<std::vector<float>>> x(
+        kNumBands,
+        std::vector<std::vector<float>>(num_render_channels,
+                                        std::vector<float>(kBlockSize, 0.f)));
+    FftData S_C;
+    FftData S_Neon;
+    FftData G;
+    Aec3Fft fft;
+    std::vector<std::vector<FftData>> H_C(
+        num_partitions, std::vector<FftData>(num_render_channels));
+    std::vector<std::vector<FftData>> H_Neon(
+        num_partitions, std::vector<FftData>(num_render_channels));
+    for (size_t p = 0; p < num_partitions; ++p) {
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        H_C[p][ch].Clear();
+        H_Neon[p][ch].Clear();
+      }
+    }
+
+    for (size_t k = 0; k < 30; ++k) {
+      for (size_t band = 0; band < x.size(); ++band) {
+        for (size_t ch = 0; ch < x[band].size(); ++ch) {
+          RandomizeSampleVector(&random_generator, x[band][ch]);
+        }
+      }
+      render_delay_buffer->Insert(x);
+      if (k == 0) {
+        render_delay_buffer->Reset();
+      }
+      render_delay_buffer->PrepareCaptureProcessing();
+    }
+    auto* const render_buffer = render_delay_buffer->GetRenderBuffer();
+
+    for (size_t j = 0; j < G.re.size(); ++j) {
+      G.re[j] = j / 10001.f;
+    }
+    for (size_t j = 1; j < G.im.size() - 1; ++j) {
+      G.im[j] = j / 20001.f;
+    }
+    G.im[0] = 0.f;
+    G.im[G.im.size() - 1] = 0.f;
+
+    AdaptPartitions_Neon(*render_buffer, G, num_partitions, &H_Neon);
+    AdaptPartitions(*render_buffer, G, num_partitions, &H_C);
+    AdaptPartitions_Neon(*render_buffer, G, num_partitions, &H_Neon);
+    AdaptPartitions(*render_buffer, G, num_partitions, &H_C);
+
+    for (size_t p = 0; p < num_partitions; ++p) {
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        for (size_t j = 0; j < H_C[p][ch].re.size(); ++j) {
+          EXPECT_FLOAT_EQ(H_C[p][ch].re[j], H_Neon[p][ch].re[j]);
+          EXPECT_FLOAT_EQ(H_C[p][ch].im[j], H_Neon[p][ch].im[j]);
+        }
+      }
+    }
+
+    ApplyFilter_Neon(*render_buffer, num_partitions, H_Neon, &S_Neon);
+    ApplyFilter(*render_buffer, num_partitions, H_C, &S_C);
+    for (size_t j = 0; j < S_C.re.size(); ++j) {
+      EXPECT_NEAR(S_C.re[j], S_Neon.re[j], fabs(S_C.re[j] * 0.00001f));
+      EXPECT_NEAR(S_C.im[j], S_Neon.im[j], fabs(S_C.re[j] * 0.00001f));
+    }
+  }
+}
+
+// Verifies that the optimized method for frequency response computation is
+// bitexact to the reference counterpart.
+TEST_P(AdaptiveFirFilterOneTwoFourEightRenderChannels,
+       ComputeFrequencyResponseNeonOptimization) {
+  const size_t num_render_channels = GetParam();
+  for (size_t num_partitions : {2, 5, 12, 30, 50}) {
+    std::vector<std::vector<FftData>> H(
+        num_partitions, std::vector<FftData>(num_render_channels));
+    std::vector<std::array<float, kFftLengthBy2Plus1>> H2(num_partitions);
+    std::vector<std::array<float, kFftLengthBy2Plus1>> H2_Neon(num_partitions);
+
+    for (size_t p = 0; p < num_partitions; ++p) {
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        for (size_t k = 0; k < H[p][ch].re.size(); ++k) {
+          H[p][ch].re[k] = k + p / 3.f + ch;
+          H[p][ch].im[k] = p + k / 7.f - ch;
+        }
+      }
+    }
+
+    ComputeFrequencyResponse(num_partitions, H, &H2);
+    ComputeFrequencyResponse_Neon(num_partitions, H, &H2_Neon);
+
+    for (size_t p = 0; p < num_partitions; ++p) {
+      for (size_t k = 0; k < H2[p].size(); ++k) {
+        EXPECT_FLOAT_EQ(H2[p][k], H2_Neon[p][k]);
+      }
+    }
+  }
+}
+#endif
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+// Verifies that the optimized methods for filter adaptation are bitexact to
+// their reference counterparts.
+TEST_P(AdaptiveFirFilterOneTwoFourEightRenderChannels,
+       FilterAdaptationSse2Optimizations) {
+  const size_t num_render_channels = GetParam();
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+
+  bool use_sse2 = (GetCPUInfo(kSSE2) != 0);
+  if (use_sse2) {
+    for (size_t num_partitions : {2, 5, 12, 30, 50}) {
+      std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+          RenderDelayBuffer::Create(EchoCanceller3Config(), kSampleRateHz,
+                                    num_render_channels));
+      Random random_generator(42U);
+      std::vector<std::vector<std::vector<float>>> x(
+          kNumBands,
+          std::vector<std::vector<float>>(num_render_channels,
+                                          std::vector<float>(kBlockSize, 0.f)));
+      FftData S_C;
+      FftData S_Sse2;
+      FftData G;
+      Aec3Fft fft;
+      std::vector<std::vector<FftData>> H_C(
+          num_partitions, std::vector<FftData>(num_render_channels));
+      std::vector<std::vector<FftData>> H_Sse2(
+          num_partitions, std::vector<FftData>(num_render_channels));
+      for (size_t p = 0; p < num_partitions; ++p) {
+        for (size_t ch = 0; ch < num_render_channels; ++ch) {
+          H_C[p][ch].Clear();
+          H_Sse2[p][ch].Clear();
+        }
+      }
+
+      for (size_t k = 0; k < 500; ++k) {
+        for (size_t band = 0; band < x.size(); ++band) {
+          for (size_t ch = 0; ch < x[band].size(); ++ch) {
+            RandomizeSampleVector(&random_generator, x[band][ch]);
+          }
+        }
+        render_delay_buffer->Insert(x);
+        if (k == 0) {
+          render_delay_buffer->Reset();
+        }
+        render_delay_buffer->PrepareCaptureProcessing();
+        auto* const render_buffer = render_delay_buffer->GetRenderBuffer();
+
+        ApplyFilter_Sse2(*render_buffer, num_partitions, H_Sse2, &S_Sse2);
+        ApplyFilter(*render_buffer, num_partitions, H_C, &S_C);
+        for (size_t j = 0; j < S_C.re.size(); ++j) {
+          EXPECT_FLOAT_EQ(S_C.re[j], S_Sse2.re[j]);
+          EXPECT_FLOAT_EQ(S_C.im[j], S_Sse2.im[j]);
+        }
+
+        std::for_each(G.re.begin(), G.re.end(),
+                      [&](float& a) { a = random_generator.Rand<float>(); });
+        std::for_each(G.im.begin(), G.im.end(),
+                      [&](float& a) { a = random_generator.Rand<float>(); });
+
+        AdaptPartitions_Sse2(*render_buffer, G, num_partitions, &H_Sse2);
+        AdaptPartitions(*render_buffer, G, num_partitions, &H_C);
+
+        for (size_t p = 0; p < num_partitions; ++p) {
+          for (size_t ch = 0; ch < num_render_channels; ++ch) {
+            for (size_t j = 0; j < H_C[p][ch].re.size(); ++j) {
+              EXPECT_FLOAT_EQ(H_C[p][ch].re[j], H_Sse2[p][ch].re[j]);
+              EXPECT_FLOAT_EQ(H_C[p][ch].im[j], H_Sse2[p][ch].im[j]);
+            }
+          }
+        }
+      }
+    }
+  }
+}
+
+// Verifies that the optimized methods for filter adaptation are bitexact to
+// their reference counterparts.
+TEST_P(AdaptiveFirFilterOneTwoFourEightRenderChannels,
+       FilterAdaptationAvx2Optimizations) {
+  const size_t num_render_channels = GetParam();
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+
+  bool use_avx2 = (GetCPUInfo(kAVX2) != 0);
+  if (use_avx2) {
+    for (size_t num_partitions : {2, 5, 12, 30, 50}) {
+      std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+          RenderDelayBuffer::Create(EchoCanceller3Config(), kSampleRateHz,
+                                    num_render_channels));
+      Random random_generator(42U);
+      std::vector<std::vector<std::vector<float>>> x(
+          kNumBands,
+          std::vector<std::vector<float>>(num_render_channels,
+                                          std::vector<float>(kBlockSize, 0.f)));
+      FftData S_C;
+      FftData S_Avx2;
+      FftData G;
+      Aec3Fft fft;
+      std::vector<std::vector<FftData>> H_C(
+          num_partitions, std::vector<FftData>(num_render_channels));
+      std::vector<std::vector<FftData>> H_Avx2(
+          num_partitions, std::vector<FftData>(num_render_channels));
+      for (size_t p = 0; p < num_partitions; ++p) {
+        for (size_t ch = 0; ch < num_render_channels; ++ch) {
+          H_C[p][ch].Clear();
+          H_Avx2[p][ch].Clear();
+        }
+      }
+
+      for (size_t k = 0; k < 500; ++k) {
+        for (size_t band = 0; band < x.size(); ++band) {
+          for (size_t ch = 0; ch < x[band].size(); ++ch) {
+            RandomizeSampleVector(&random_generator, x[band][ch]);
+          }
+        }
+        render_delay_buffer->Insert(x);
+        if (k == 0) {
+          render_delay_buffer->Reset();
+        }
+        render_delay_buffer->PrepareCaptureProcessing();
+        auto* const render_buffer = render_delay_buffer->GetRenderBuffer();
+
+        ApplyFilter_Avx2(*render_buffer, num_partitions, H_Avx2, &S_Avx2);
+        ApplyFilter(*render_buffer, num_partitions, H_C, &S_C);
+        for (size_t j = 0; j < S_C.re.size(); ++j) {
+          EXPECT_FLOAT_EQ(S_C.re[j], S_Avx2.re[j]);
+          EXPECT_FLOAT_EQ(S_C.im[j], S_Avx2.im[j]);
+        }
+
+        std::for_each(G.re.begin(), G.re.end(),
+                      [&](float& a) { a = random_generator.Rand<float>(); });
+        std::for_each(G.im.begin(), G.im.end(),
+                      [&](float& a) { a = random_generator.Rand<float>(); });
+
+        AdaptPartitions_Avx2(*render_buffer, G, num_partitions, &H_Avx2);
+        AdaptPartitions(*render_buffer, G, num_partitions, &H_C);
+
+        for (size_t p = 0; p < num_partitions; ++p) {
+          for (size_t ch = 0; ch < num_render_channels; ++ch) {
+            for (size_t j = 0; j < H_C[p][ch].re.size(); ++j) {
+              EXPECT_FLOAT_EQ(H_C[p][ch].re[j], H_Avx2[p][ch].re[j]);
+              EXPECT_FLOAT_EQ(H_C[p][ch].im[j], H_Avx2[p][ch].im[j]);
+            }
+          }
+        }
+      }
+    }
+  }
+}
+
+// Verifies that the optimized method for frequency response computation is
+// bitexact to the reference counterpart.
+TEST_P(AdaptiveFirFilterOneTwoFourEightRenderChannels,
+       ComputeFrequencyResponseSse2Optimization) {
+  const size_t num_render_channels = GetParam();
+  bool use_sse2 = (GetCPUInfo(kSSE2) != 0);
+  if (use_sse2) {
+    for (size_t num_partitions : {2, 5, 12, 30, 50}) {
+      std::vector<std::vector<FftData>> H(
+          num_partitions, std::vector<FftData>(num_render_channels));
+      std::vector<std::array<float, kFftLengthBy2Plus1>> H2(num_partitions);
+      std::vector<std::array<float, kFftLengthBy2Plus1>> H2_Sse2(
+          num_partitions);
+
+      for (size_t p = 0; p < num_partitions; ++p) {
+        for (size_t ch = 0; ch < num_render_channels; ++ch) {
+          for (size_t k = 0; k < H[p][ch].re.size(); ++k) {
+            H[p][ch].re[k] = k + p / 3.f + ch;
+            H[p][ch].im[k] = p + k / 7.f - ch;
+          }
+        }
+      }
+
+      ComputeFrequencyResponse(num_partitions, H, &H2);
+      ComputeFrequencyResponse_Sse2(num_partitions, H, &H2_Sse2);
+
+      for (size_t p = 0; p < num_partitions; ++p) {
+        for (size_t k = 0; k < H2[p].size(); ++k) {
+          EXPECT_FLOAT_EQ(H2[p][k], H2_Sse2[p][k]);
+        }
+      }
+    }
+  }
+}
+
+// Verifies that the optimized method for frequency response computation is
+// bitexact to the reference counterpart.
+TEST_P(AdaptiveFirFilterOneTwoFourEightRenderChannels,
+       ComputeFrequencyResponseAvx2Optimization) {
+  const size_t num_render_channels = GetParam();
+  bool use_avx2 = (GetCPUInfo(kAVX2) != 0);
+  if (use_avx2) {
+    for (size_t num_partitions : {2, 5, 12, 30, 50}) {
+      std::vector<std::vector<FftData>> H(
+          num_partitions, std::vector<FftData>(num_render_channels));
+      std::vector<std::array<float, kFftLengthBy2Plus1>> H2(num_partitions);
+      std::vector<std::array<float, kFftLengthBy2Plus1>> H2_Avx2(
+          num_partitions);
+
+      for (size_t p = 0; p < num_partitions; ++p) {
+        for (size_t ch = 0; ch < num_render_channels; ++ch) {
+          for (size_t k = 0; k < H[p][ch].re.size(); ++k) {
+            H[p][ch].re[k] = k + p / 3.f + ch;
+            H[p][ch].im[k] = p + k / 7.f - ch;
+          }
+        }
+      }
+
+      ComputeFrequencyResponse(num_partitions, H, &H2);
+      ComputeFrequencyResponse_Avx2(num_partitions, H, &H2_Avx2);
+
+      for (size_t p = 0; p < num_partitions; ++p) {
+        for (size_t k = 0; k < H2[p].size(); ++k) {
+          EXPECT_FLOAT_EQ(H2[p][k], H2_Avx2[p][k]);
+        }
+      }
+    }
+  }
+}
+
+#endif
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+// Verifies that the check for non-null data dumper works.
+TEST(AdaptiveFirFilterDeathTest, NullDataDumper) {
+  EXPECT_DEATH(AdaptiveFirFilter(9, 9, 250, 1, DetectOptimization(), nullptr),
+               "");
+}
+
+// Verifies that the check for non-null filter output works.
+TEST(AdaptiveFirFilterDeathTest, NullFilterOutput) {
+  ApmDataDumper data_dumper(42);
+  AdaptiveFirFilter filter(9, 9, 250, 1, DetectOptimization(), &data_dumper);
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+      RenderDelayBuffer::Create(EchoCanceller3Config(), 48000, 1));
+  EXPECT_DEATH(filter.Filter(*render_delay_buffer->GetRenderBuffer(), nullptr),
+               "");
+}
+
+#endif
+
+// Verifies that the filter statistics can be accessed when filter statistics
+// are turned on.
+TEST(AdaptiveFirFilterTest, FilterStatisticsAccess) {
+  ApmDataDumper data_dumper(42);
+  Aec3Optimization optimization = DetectOptimization();
+  AdaptiveFirFilter filter(9, 9, 250, 1, optimization, &data_dumper);
+  std::vector<std::array<float, kFftLengthBy2Plus1>> H2(
+      filter.max_filter_size_partitions(),
+      std::array<float, kFftLengthBy2Plus1>());
+  for (auto& H2_k : H2) {
+    H2_k.fill(0.f);
+  }
+
+  std::array<float, kFftLengthBy2Plus1> erl;
+  ComputeErl(optimization, H2, erl);
+  filter.ComputeFrequencyResponse(&H2);
+}
+
+// Verifies that the filter size if correctly repported.
+TEST(AdaptiveFirFilterTest, FilterSize) {
+  ApmDataDumper data_dumper(42);
+  for (size_t filter_size = 1; filter_size < 5; ++filter_size) {
+    AdaptiveFirFilter filter(filter_size, filter_size, 250, 1,
+                             DetectOptimization(), &data_dumper);
+    EXPECT_EQ(filter_size, filter.SizePartitions());
+  }
+}
+
+class AdaptiveFirFilterMultiChannel
+    : public ::testing::Test,
+      public ::testing::WithParamInterface<std::tuple<size_t, size_t>> {};
+
+INSTANTIATE_TEST_SUITE_P(MultiChannel,
+                         AdaptiveFirFilterMultiChannel,
+                         ::testing::Combine(::testing::Values(1, 4),
+                                            ::testing::Values(1, 8)));
+
+// Verifies that the filter is being able to properly filter a signal and to
+// adapt its coefficients.
+TEST_P(AdaptiveFirFilterMultiChannel, FilterAndAdapt) {
+  const size_t num_render_channels = std::get<0>(GetParam());
+  const size_t num_capture_channels = std::get<1>(GetParam());
+
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+  constexpr size_t kNumBlocksToProcessPerRenderChannel = 1000;
+
+  ApmDataDumper data_dumper(42);
+  EchoCanceller3Config config;
+
+  if (num_render_channels == 33) {
+    config.filter.refined = {13, 0.00005f, 0.0005f, 0.0001f, 2.f, 20075344.f};
+    config.filter.coarse = {13, 0.1f, 20075344.f};
+    config.filter.refined_initial = {12, 0.005f, 0.5f, 0.001f, 2.f, 20075344.f};
+    config.filter.coarse_initial = {12, 0.7f, 20075344.f};
+  }
+
+  AdaptiveFirFilter filter(
+      config.filter.refined.length_blocks, config.filter.refined.length_blocks,
+      config.filter.config_change_duration_blocks, num_render_channels,
+      DetectOptimization(), &data_dumper);
+  std::vector<std::vector<std::array<float, kFftLengthBy2Plus1>>> H2(
+      num_capture_channels, std::vector<std::array<float, kFftLengthBy2Plus1>>(
+                                filter.max_filter_size_partitions(),
+                                std::array<float, kFftLengthBy2Plus1>()));
+  std::vector<std::vector<float>> h(
+      num_capture_channels,
+      std::vector<float>(
+          GetTimeDomainLength(filter.max_filter_size_partitions()), 0.f));
+  Aec3Fft fft;
+  config.delay.default_delay = 1;
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+      RenderDelayBuffer::Create(config, kSampleRateHz, num_render_channels));
+  CoarseFilterUpdateGain gain(config.filter.coarse,
+                              config.filter.config_change_duration_blocks);
+  Random random_generator(42U);
+  std::vector<std::vector<std::vector<float>>> x(
+      kNumBands, std::vector<std::vector<float>>(
+                     num_render_channels, std::vector<float>(kBlockSize, 0.f)));
+  std::vector<float> n(kBlockSize, 0.f);
+  std::vector<float> y(kBlockSize, 0.f);
+  AecState aec_state(EchoCanceller3Config{}, num_capture_channels);
+  RenderSignalAnalyzer render_signal_analyzer(config);
+  absl::optional<DelayEstimate> delay_estimate;
+  std::vector<float> e(kBlockSize, 0.f);
+  std::array<float, kFftLength> s_scratch;
+  std::vector<SubtractorOutput> output(num_capture_channels);
+  FftData S;
+  FftData G;
+  FftData E;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> Y2(num_capture_channels);
+  std::vector<std::array<float, kFftLengthBy2Plus1>> E2_refined(
+      num_capture_channels);
+  std::array<float, kFftLengthBy2Plus1> E2_coarse;
+  // [B,A] = butter(2,100/8000,'high')
+  constexpr CascadedBiQuadFilter::BiQuadCoefficients
+      kHighPassFilterCoefficients = {{0.97261f, -1.94523f, 0.97261f},
+                                     {-1.94448f, 0.94598f}};
+  for (auto& Y2_ch : Y2) {
+    Y2_ch.fill(0.f);
+  }
+  for (auto& E2_refined_ch : E2_refined) {
+    E2_refined_ch.fill(0.f);
+  }
+  E2_coarse.fill(0.f);
+  for (auto& subtractor_output : output) {
+    subtractor_output.Reset();
+  }
+
+  constexpr float kScale = 1.0f / kFftLengthBy2;
+
+  for (size_t delay_samples : {0, 64, 150, 200, 301}) {
+    std::vector<DelayBuffer<float>> delay_buffer(
+        num_render_channels, DelayBuffer<float>(delay_samples));
+    std::vector<std::unique_ptr<CascadedBiQuadFilter>> x_hp_filter(
+        num_render_channels);
+    for (size_t ch = 0; ch < num_render_channels; ++ch) {
+      x_hp_filter[ch] = std::make_unique<CascadedBiQuadFilter>(
+          kHighPassFilterCoefficients, 1);
+    }
+    CascadedBiQuadFilter y_hp_filter(kHighPassFilterCoefficients, 1);
+
+    SCOPED_TRACE(ProduceDebugText(num_render_channels, delay_samples));
+    const size_t num_blocks_to_process =
+        kNumBlocksToProcessPerRenderChannel * num_render_channels;
+    for (size_t j = 0; j < num_blocks_to_process; ++j) {
+      std::fill(y.begin(), y.end(), 0.f);
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        RandomizeSampleVector(&random_generator, x[0][ch]);
+        std::array<float, kBlockSize> y_channel;
+        delay_buffer[ch].Delay(x[0][ch], y_channel);
+        for (size_t k = 0; k < y.size(); ++k) {
+          y[k] += y_channel[k] / num_render_channels;
+        }
+      }
+
+      RandomizeSampleVector(&random_generator, n);
+      const float noise_scaling = 1.f / 100.f / num_render_channels;
+      for (size_t k = 0; k < y.size(); ++k) {
+        y[k] += n[k] * noise_scaling;
+      }
+
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        x_hp_filter[ch]->Process(x[0][ch]);
+      }
+      y_hp_filter.Process(y);
+
+      render_delay_buffer->Insert(x);
+      if (j == 0) {
+        render_delay_buffer->Reset();
+      }
+      render_delay_buffer->PrepareCaptureProcessing();
+      auto* const render_buffer = render_delay_buffer->GetRenderBuffer();
+
+      render_signal_analyzer.Update(*render_buffer,
+                                    aec_state.MinDirectPathFilterDelay());
+
+      filter.Filter(*render_buffer, &S);
+      fft.Ifft(S, &s_scratch);
+      std::transform(y.begin(), y.end(), s_scratch.begin() + kFftLengthBy2,
+                     e.begin(),
+                     [&](float a, float b) { return a - b * kScale; });
+      std::for_each(e.begin(), e.end(),
+                    [](float& a) { a = rtc::SafeClamp(a, -32768.f, 32767.f); });
+      fft.ZeroPaddedFft(e, Aec3Fft::Window::kRectangular, &E);
+      for (auto& o : output) {
+        for (size_t k = 0; k < kBlockSize; ++k) {
+          o.s_refined[k] = kScale * s_scratch[k + kFftLengthBy2];
+        }
+      }
+
+      std::array<float, kFftLengthBy2Plus1> render_power;
+      render_buffer->SpectralSum(filter.SizePartitions(), &render_power);
+      gain.Compute(render_power, render_signal_analyzer, E,
+                   filter.SizePartitions(), false, &G);
+      filter.Adapt(*render_buffer, G, &h[0]);
+      aec_state.HandleEchoPathChange(EchoPathVariability(
+          false, EchoPathVariability::DelayAdjustment::kNone, false));
+
+      filter.ComputeFrequencyResponse(&H2[0]);
+      aec_state.Update(delay_estimate, H2, h, *render_buffer, E2_refined, Y2,
+                       output);
+    }
+    // Verify that the filter is able to perform well.
+    EXPECT_LT(1000 * std::inner_product(e.begin(), e.end(), e.begin(), 0.f),
+              std::inner_product(y.begin(), y.end(), y.begin(), 0.f));
+  }
+}
+
+}  // namespace aec3
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec3_common.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec3_common.cc
new file mode 100644
index 0000000..7bd8d62
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec3_common.cc
@@ -0,0 +1,58 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+
+#include <stdint.h>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/system/arch.h"
+#include "system_wrappers/include/cpu_features_wrapper.h"
+
+namespace webrtc {
+
+Aec3Optimization DetectOptimization() {
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+  if (GetCPUInfo(kAVX2) != 0) {
+    return Aec3Optimization::kAvx2;
+  } else if (GetCPUInfo(kSSE2) != 0) {
+    return Aec3Optimization::kSse2;
+  }
+#endif
+
+#if defined(WEBRTC_HAS_NEON)
+  return Aec3Optimization::kNeon;
+#endif
+
+  return Aec3Optimization::kNone;
+}
+
+float FastApproxLog2f(const float in) {
+  RTC_DCHECK_GT(in, .0f);
+  // Read and interpret float as uint32_t and then cast to float.
+  // This is done to extract the exponent (bits 30 - 23).
+  // "Right shift" of the exponent is then performed by multiplying
+  // with the constant (1/2^23). Finally, we subtract a constant to
+  // remove the bias (https://en.wikipedia.org/wiki/Exponent_bias).
+  union {
+    float dummy;
+    uint32_t a;
+  } x = {in};
+  float out = x.a;
+  out *= 1.1920929e-7f;  // 1/2^23
+  out -= 126.942695f;    // Remove bias.
+  return out;
+}
+
+float Log2TodB(const float in_log2) {
+  return 3.0102999566398121 * in_log2;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec3_common.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec3_common.h
new file mode 100644
index 0000000..3bfff96
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec3_common.h
@@ -0,0 +1,114 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_AEC3_COMMON_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_AEC3_COMMON_H_
+
+#include <stddef.h>
+
+namespace webrtc {
+
+#ifdef _MSC_VER /* visual c++ */
+#define ALIGN16_BEG __declspec(align(16))
+#define ALIGN16_END
+#else /* gcc or icc */
+#define ALIGN16_BEG
+#define ALIGN16_END __attribute__((aligned(16)))
+#endif
+
+enum class Aec3Optimization { kNone, kSse2, kAvx2, kNeon };
+
+constexpr int kNumBlocksPerSecond = 250;
+
+constexpr int kMetricsReportingIntervalBlocks = 10 * kNumBlocksPerSecond;
+constexpr int kMetricsComputationBlocks = 3;
+constexpr int kMetricsCollectionBlocks =
+    kMetricsReportingIntervalBlocks - kMetricsComputationBlocks;
+
+constexpr size_t kFftLengthBy2 = 64;
+constexpr size_t kFftLengthBy2Plus1 = kFftLengthBy2 + 1;
+constexpr size_t kFftLengthBy2Minus1 = kFftLengthBy2 - 1;
+constexpr size_t kFftLength = 2 * kFftLengthBy2;
+constexpr size_t kFftLengthBy2Log2 = 6;
+
+constexpr int kRenderTransferQueueSizeFrames = 100;
+
+constexpr size_t kMaxNumBands = 3;
+constexpr size_t kFrameSize = 160;
+constexpr size_t kSubFrameLength = kFrameSize / 2;
+
+constexpr size_t kBlockSize = kFftLengthBy2;
+constexpr size_t kBlockSizeLog2 = kFftLengthBy2Log2;
+
+constexpr size_t kExtendedBlockSize = 2 * kFftLengthBy2;
+constexpr size_t kMatchedFilterWindowSizeSubBlocks = 32;
+constexpr size_t kMatchedFilterAlignmentShiftSizeSubBlocks =
+    kMatchedFilterWindowSizeSubBlocks * 3 / 4;
+
+// TODO(peah): Integrate this with how it is done inside audio_processing_impl.
+constexpr size_t NumBandsForRate(int sample_rate_hz) {
+  return static_cast<size_t>(sample_rate_hz / 16000);
+}
+
+constexpr bool ValidFullBandRate(int sample_rate_hz) {
+  return sample_rate_hz == 16000 || sample_rate_hz == 32000 ||
+         sample_rate_hz == 48000;
+}
+
+constexpr int GetTimeDomainLength(int filter_length_blocks) {
+  return filter_length_blocks * kFftLengthBy2;
+}
+
+constexpr size_t GetDownSampledBufferSize(size_t down_sampling_factor,
+                                          size_t num_matched_filters) {
+  return kBlockSize / down_sampling_factor *
+         (kMatchedFilterAlignmentShiftSizeSubBlocks * num_matched_filters +
+          kMatchedFilterWindowSizeSubBlocks + 1);
+}
+
+constexpr size_t GetRenderDelayBufferSize(size_t down_sampling_factor,
+                                          size_t num_matched_filters,
+                                          size_t filter_length_blocks) {
+  return GetDownSampledBufferSize(down_sampling_factor, num_matched_filters) /
+             (kBlockSize / down_sampling_factor) +
+         filter_length_blocks + 1;
+}
+
+// Detects what kind of optimizations to use for the code.
+Aec3Optimization DetectOptimization();
+
+// Computes the log2 of the input in a fast an approximate manner.
+float FastApproxLog2f(const float in);
+
+// Returns dB from a power quantity expressed in log2.
+float Log2TodB(const float in_log2);
+
+static_assert(1 << kBlockSizeLog2 == kBlockSize,
+              "Proper number of shifts for blocksize");
+
+static_assert(1 << kFftLengthBy2Log2 == kFftLengthBy2,
+              "Proper number of shifts for the fft length");
+
+static_assert(1 == NumBandsForRate(16000), "Number of bands for 16 kHz");
+static_assert(2 == NumBandsForRate(32000), "Number of bands for 32 kHz");
+static_assert(3 == NumBandsForRate(48000), "Number of bands for 48 kHz");
+
+static_assert(ValidFullBandRate(16000),
+              "Test that 16 kHz is a valid sample rate");
+static_assert(ValidFullBandRate(32000),
+              "Test that 32 kHz is a valid sample rate");
+static_assert(ValidFullBandRate(48000),
+              "Test that 48 kHz is a valid sample rate");
+static_assert(!ValidFullBandRate(8001),
+              "Test that 8001 Hz is not a valid sample rate");
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_AEC3_COMMON_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec3_fft.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec3_fft.cc
new file mode 100644
index 0000000..8dfa183
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec3_fft.cc
@@ -0,0 +1,144 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/aec3_fft.h"
+
+#include <algorithm>
+#include <functional>
+#include <iterator>
+
+#include "rtc_base/checks.h"
+#include "system_wrappers/include/cpu_features_wrapper.h"
+
+namespace webrtc {
+
+namespace {
+
+const float kHanning64[kFftLengthBy2] = {
+    0.f,         0.00248461f, 0.00991376f, 0.0222136f,  0.03926189f,
+    0.06088921f, 0.08688061f, 0.11697778f, 0.15088159f, 0.1882551f,
+    0.22872687f, 0.27189467f, 0.31732949f, 0.36457977f, 0.41317591f,
+    0.46263495f, 0.51246535f, 0.56217185f, 0.61126047f, 0.65924333f,
+    0.70564355f, 0.75f,       0.79187184f, 0.83084292f, 0.86652594f,
+    0.89856625f, 0.92664544f, 0.95048443f, 0.96984631f, 0.98453864f,
+    0.99441541f, 0.99937846f, 0.99937846f, 0.99441541f, 0.98453864f,
+    0.96984631f, 0.95048443f, 0.92664544f, 0.89856625f, 0.86652594f,
+    0.83084292f, 0.79187184f, 0.75f,       0.70564355f, 0.65924333f,
+    0.61126047f, 0.56217185f, 0.51246535f, 0.46263495f, 0.41317591f,
+    0.36457977f, 0.31732949f, 0.27189467f, 0.22872687f, 0.1882551f,
+    0.15088159f, 0.11697778f, 0.08688061f, 0.06088921f, 0.03926189f,
+    0.0222136f,  0.00991376f, 0.00248461f, 0.f};
+
+// Hanning window from Matlab command win = sqrt(hanning(128)).
+const float kSqrtHanning128[kFftLength] = {
+    0.00000000000000f, 0.02454122852291f, 0.04906767432742f, 0.07356456359967f,
+    0.09801714032956f, 0.12241067519922f, 0.14673047445536f, 0.17096188876030f,
+    0.19509032201613f, 0.21910124015687f, 0.24298017990326f, 0.26671275747490f,
+    0.29028467725446f, 0.31368174039889f, 0.33688985339222f, 0.35989503653499f,
+    0.38268343236509f, 0.40524131400499f, 0.42755509343028f, 0.44961132965461f,
+    0.47139673682600f, 0.49289819222978f, 0.51410274419322f, 0.53499761988710f,
+    0.55557023301960f, 0.57580819141785f, 0.59569930449243f, 0.61523159058063f,
+    0.63439328416365f, 0.65317284295378f, 0.67155895484702f, 0.68954054473707f,
+    0.70710678118655f, 0.72424708295147f, 0.74095112535496f, 0.75720884650648f,
+    0.77301045336274f, 0.78834642762661f, 0.80320753148064f, 0.81758481315158f,
+    0.83146961230255f, 0.84485356524971f, 0.85772861000027f, 0.87008699110871f,
+    0.88192126434835f, 0.89322430119552f, 0.90398929312344f, 0.91420975570353f,
+    0.92387953251129f, 0.93299279883474f, 0.94154406518302f, 0.94952818059304f,
+    0.95694033573221f, 0.96377606579544f, 0.97003125319454f, 0.97570213003853f,
+    0.98078528040323f, 0.98527764238894f, 0.98917650996478f, 0.99247953459871f,
+    0.99518472667220f, 0.99729045667869f, 0.99879545620517f, 0.99969881869620f,
+    1.00000000000000f, 0.99969881869620f, 0.99879545620517f, 0.99729045667869f,
+    0.99518472667220f, 0.99247953459871f, 0.98917650996478f, 0.98527764238894f,
+    0.98078528040323f, 0.97570213003853f, 0.97003125319454f, 0.96377606579544f,
+    0.95694033573221f, 0.94952818059304f, 0.94154406518302f, 0.93299279883474f,
+    0.92387953251129f, 0.91420975570353f, 0.90398929312344f, 0.89322430119552f,
+    0.88192126434835f, 0.87008699110871f, 0.85772861000027f, 0.84485356524971f,
+    0.83146961230255f, 0.81758481315158f, 0.80320753148064f, 0.78834642762661f,
+    0.77301045336274f, 0.75720884650648f, 0.74095112535496f, 0.72424708295147f,
+    0.70710678118655f, 0.68954054473707f, 0.67155895484702f, 0.65317284295378f,
+    0.63439328416365f, 0.61523159058063f, 0.59569930449243f, 0.57580819141785f,
+    0.55557023301960f, 0.53499761988710f, 0.51410274419322f, 0.49289819222978f,
+    0.47139673682600f, 0.44961132965461f, 0.42755509343028f, 0.40524131400499f,
+    0.38268343236509f, 0.35989503653499f, 0.33688985339222f, 0.31368174039889f,
+    0.29028467725446f, 0.26671275747490f, 0.24298017990326f, 0.21910124015687f,
+    0.19509032201613f, 0.17096188876030f, 0.14673047445536f, 0.12241067519922f,
+    0.09801714032956f, 0.07356456359967f, 0.04906767432742f, 0.02454122852291f};
+
+bool IsSse2Available() {
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+  return GetCPUInfo(kSSE2) != 0;
+#else
+  return false;
+#endif
+}
+
+}  // namespace
+
+Aec3Fft::Aec3Fft() : ooura_fft_(IsSse2Available()) {}
+
+// TODO(peah): Change x to be std::array once the rest of the code allows this.
+void Aec3Fft::ZeroPaddedFft(rtc::ArrayView<const float> x,
+                            Window window,
+                            FftData* X) const {
+  RTC_DCHECK(X);
+  RTC_DCHECK_EQ(kFftLengthBy2, x.size());
+  std::array<float, kFftLength> fft;
+  std::fill(fft.begin(), fft.begin() + kFftLengthBy2, 0.f);
+  switch (window) {
+    case Window::kRectangular:
+      std::copy(x.begin(), x.end(), fft.begin() + kFftLengthBy2);
+      break;
+    case Window::kHanning:
+      std::transform(x.begin(), x.end(), std::begin(kHanning64),
+                     fft.begin() + kFftLengthBy2,
+                     [](float a, float b) { return a * b; });
+      break;
+    case Window::kSqrtHanning:
+      RTC_NOTREACHED();
+      break;
+    default:
+      RTC_NOTREACHED();
+  }
+
+  Fft(&fft, X);
+}
+
+void Aec3Fft::PaddedFft(rtc::ArrayView<const float> x,
+                        rtc::ArrayView<const float> x_old,
+                        Window window,
+                        FftData* X) const {
+  RTC_DCHECK(X);
+  RTC_DCHECK_EQ(kFftLengthBy2, x.size());
+  RTC_DCHECK_EQ(kFftLengthBy2, x_old.size());
+  std::array<float, kFftLength> fft;
+
+  switch (window) {
+    case Window::kRectangular:
+      std::copy(x_old.begin(), x_old.end(), fft.begin());
+      std::copy(x.begin(), x.end(), fft.begin() + x_old.size());
+      break;
+    case Window::kHanning:
+      RTC_NOTREACHED();
+      break;
+    case Window::kSqrtHanning:
+      std::transform(x_old.begin(), x_old.end(), std::begin(kSqrtHanning128),
+                     fft.begin(), std::multiplies<float>());
+      std::transform(x.begin(), x.end(),
+                     std::begin(kSqrtHanning128) + x_old.size(),
+                     fft.begin() + x_old.size(), std::multiplies<float>());
+      break;
+    default:
+      RTC_NOTREACHED();
+  }
+
+  Fft(&fft, X);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec3_fft.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec3_fft.h
new file mode 100644
index 0000000..6f7fbe4
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec3_fft.h
@@ -0,0 +1,75 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_AEC3_FFT_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_AEC3_FFT_H_
+
+#include <array>
+
+#include "api/array_view.h"
+#include "common_audio/third_party/ooura/fft_size_128/ooura_fft.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/fft_data.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+// Wrapper class that provides 128 point real valued FFT functionality with the
+// FftData type.
+class Aec3Fft {
+ public:
+  enum class Window { kRectangular, kHanning, kSqrtHanning };
+
+  Aec3Fft();
+
+  // Computes the FFT. Note that both the input and output are modified.
+  void Fft(std::array<float, kFftLength>* x, FftData* X) const {
+    RTC_DCHECK(x);
+    RTC_DCHECK(X);
+    ooura_fft_.Fft(x->data());
+    X->CopyFromPackedArray(*x);
+  }
+  // Computes the inverse Fft.
+  void Ifft(const FftData& X, std::array<float, kFftLength>* x) const {
+    RTC_DCHECK(x);
+    X.CopyToPackedArray(x);
+    ooura_fft_.InverseFft(x->data());
+  }
+
+  // Windows the input using a Hanning window, and then adds padding of
+  // kFftLengthBy2 initial zeros before computing the Fft.
+  void ZeroPaddedFft(rtc::ArrayView<const float> x,
+                     Window window,
+                     FftData* X) const;
+
+  // Concatenates the kFftLengthBy2 values long x and x_old before computing the
+  // Fft. After that, x is copied to x_old.
+  void PaddedFft(rtc::ArrayView<const float> x,
+                 rtc::ArrayView<const float> x_old,
+                 FftData* X) const {
+    PaddedFft(x, x_old, Window::kRectangular, X);
+  }
+
+  // Padded Fft using a time-domain window.
+  void PaddedFft(rtc::ArrayView<const float> x,
+                 rtc::ArrayView<const float> x_old,
+                 Window window,
+                 FftData* X) const;
+
+ private:
+  const OouraFft ooura_fft_;
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(Aec3Fft);
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_AEC3_FFT_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec3_fft_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec3_fft_unittest.cc
new file mode 100644
index 0000000..e60ef5b
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec3_fft_unittest.cc
@@ -0,0 +1,213 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/aec3_fft.h"
+
+#include <algorithm>
+
+#include "test/gmock.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+// Verifies that the check for non-null input in Fft works.
+TEST(Aec3FftDeathTest, NullFftInput) {
+  Aec3Fft fft;
+  FftData X;
+  EXPECT_DEATH(fft.Fft(nullptr, &X), "");
+}
+
+// Verifies that the check for non-null input in Fft works.
+TEST(Aec3FftDeathTest, NullFftOutput) {
+  Aec3Fft fft;
+  std::array<float, kFftLength> x;
+  EXPECT_DEATH(fft.Fft(&x, nullptr), "");
+}
+
+// Verifies that the check for non-null output in Ifft works.
+TEST(Aec3FftDeathTest, NullIfftOutput) {
+  Aec3Fft fft;
+  FftData X;
+  EXPECT_DEATH(fft.Ifft(X, nullptr), "");
+}
+
+// Verifies that the check for non-null output in ZeroPaddedFft works.
+TEST(Aec3FftDeathTest, NullZeroPaddedFftOutput) {
+  Aec3Fft fft;
+  std::array<float, kFftLengthBy2> x;
+  EXPECT_DEATH(fft.ZeroPaddedFft(x, Aec3Fft::Window::kRectangular, nullptr),
+               "");
+}
+
+// Verifies that the check for input length in ZeroPaddedFft works.
+TEST(Aec3FftDeathTest, ZeroPaddedFftWrongInputLength) {
+  Aec3Fft fft;
+  FftData X;
+  std::array<float, kFftLengthBy2 - 1> x;
+  EXPECT_DEATH(fft.ZeroPaddedFft(x, Aec3Fft::Window::kRectangular, &X), "");
+}
+
+// Verifies that the check for non-null output in PaddedFft works.
+TEST(Aec3FftDeathTest, NullPaddedFftOutput) {
+  Aec3Fft fft;
+  std::array<float, kFftLengthBy2> x;
+  std::array<float, kFftLengthBy2> x_old;
+  EXPECT_DEATH(fft.PaddedFft(x, x_old, nullptr), "");
+}
+
+// Verifies that the check for input length in PaddedFft works.
+TEST(Aec3FftDeathTest, PaddedFftWrongInputLength) {
+  Aec3Fft fft;
+  FftData X;
+  std::array<float, kFftLengthBy2 - 1> x;
+  std::array<float, kFftLengthBy2> x_old;
+  EXPECT_DEATH(fft.PaddedFft(x, x_old, &X), "");
+}
+
+// Verifies that the check for length in the old value in PaddedFft works.
+TEST(Aec3FftDeathTest, PaddedFftWrongOldValuesLength) {
+  Aec3Fft fft;
+  FftData X;
+  std::array<float, kFftLengthBy2> x;
+  std::array<float, kFftLengthBy2 - 1> x_old;
+  EXPECT_DEATH(fft.PaddedFft(x, x_old, &X), "");
+}
+
+#endif
+
+// Verifies that Fft works as intended.
+TEST(Aec3Fft, Fft) {
+  Aec3Fft fft;
+  FftData X;
+  std::array<float, kFftLength> x;
+  x.fill(0.f);
+  fft.Fft(&x, &X);
+  EXPECT_THAT(X.re, ::testing::Each(0.f));
+  EXPECT_THAT(X.im, ::testing::Each(0.f));
+
+  x.fill(0.f);
+  x[0] = 1.f;
+  fft.Fft(&x, &X);
+  EXPECT_THAT(X.re, ::testing::Each(1.f));
+  EXPECT_THAT(X.im, ::testing::Each(0.f));
+
+  x.fill(1.f);
+  fft.Fft(&x, &X);
+  EXPECT_EQ(128.f, X.re[0]);
+  std::for_each(X.re.begin() + 1, X.re.end(),
+                [](float a) { EXPECT_EQ(0.f, a); });
+  EXPECT_THAT(X.im, ::testing::Each(0.f));
+}
+
+// Verifies that InverseFft works as intended.
+TEST(Aec3Fft, Ifft) {
+  Aec3Fft fft;
+  FftData X;
+  std::array<float, kFftLength> x;
+
+  X.re.fill(0.f);
+  X.im.fill(0.f);
+  fft.Ifft(X, &x);
+  EXPECT_THAT(x, ::testing::Each(0.f));
+
+  X.re.fill(1.f);
+  X.im.fill(0.f);
+  fft.Ifft(X, &x);
+  EXPECT_EQ(64.f, x[0]);
+  std::for_each(x.begin() + 1, x.end(), [](float a) { EXPECT_EQ(0.f, a); });
+
+  X.re.fill(0.f);
+  X.re[0] = 128;
+  X.im.fill(0.f);
+  fft.Ifft(X, &x);
+  EXPECT_THAT(x, ::testing::Each(64.f));
+}
+
+// Verifies that InverseFft and Fft work as intended.
+TEST(Aec3Fft, FftAndIfft) {
+  Aec3Fft fft;
+  FftData X;
+  std::array<float, kFftLength> x;
+  std::array<float, kFftLength> x_ref;
+
+  int v = 0;
+  for (int k = 0; k < 20; ++k) {
+    for (size_t j = 0; j < x.size(); ++j) {
+      x[j] = v++;
+      x_ref[j] = x[j] * 64.f;
+    }
+    fft.Fft(&x, &X);
+    fft.Ifft(X, &x);
+    for (size_t j = 0; j < x.size(); ++j) {
+      EXPECT_NEAR(x_ref[j], x[j], 0.001f);
+    }
+  }
+}
+
+// Verifies that ZeroPaddedFft work as intended.
+TEST(Aec3Fft, ZeroPaddedFft) {
+  Aec3Fft fft;
+  FftData X;
+  std::array<float, kFftLengthBy2> x_in;
+  std::array<float, kFftLength> x_ref;
+  std::array<float, kFftLength> x_out;
+
+  int v = 0;
+  x_ref.fill(0.f);
+  for (int k = 0; k < 20; ++k) {
+    for (size_t j = 0; j < x_in.size(); ++j) {
+      x_in[j] = v++;
+      x_ref[j + kFftLengthBy2] = x_in[j] * 64.f;
+    }
+    fft.ZeroPaddedFft(x_in, Aec3Fft::Window::kRectangular, &X);
+    fft.Ifft(X, &x_out);
+    for (size_t j = 0; j < x_out.size(); ++j) {
+      EXPECT_NEAR(x_ref[j], x_out[j], 0.1f);
+    }
+  }
+}
+
+// Verifies that ZeroPaddedFft work as intended.
+TEST(Aec3Fft, PaddedFft) {
+  Aec3Fft fft;
+  FftData X;
+  std::array<float, kFftLengthBy2> x_in;
+  std::array<float, kFftLength> x_out;
+  std::array<float, kFftLengthBy2> x_old;
+  std::array<float, kFftLengthBy2> x_old_ref;
+  std::array<float, kFftLength> x_ref;
+
+  int v = 0;
+  x_old.fill(0.f);
+  for (int k = 0; k < 20; ++k) {
+    for (size_t j = 0; j < x_in.size(); ++j) {
+      x_in[j] = v++;
+    }
+
+    std::copy(x_old.begin(), x_old.end(), x_ref.begin());
+    std::copy(x_in.begin(), x_in.end(), x_ref.begin() + kFftLengthBy2);
+    std::copy(x_in.begin(), x_in.end(), x_old_ref.begin());
+    std::for_each(x_ref.begin(), x_ref.end(), [](float& a) { a *= 64.f; });
+
+    fft.PaddedFft(x_in, x_old, &X);
+    std::copy(x_in.begin(), x_in.end(), x_old.begin());
+    fft.Ifft(X, &x_out);
+
+    for (size_t j = 0; j < x_out.size(); ++j) {
+      EXPECT_NEAR(x_ref[j], x_out[j], 0.1f);
+    }
+
+    EXPECT_EQ(x_old_ref, x_old);
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec_state.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec_state.cc
new file mode 100644
index 0000000..21cad21
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec_state.cc
@@ -0,0 +1,480 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/aec_state.h"
+
+#include <math.h>
+
+#include <algorithm>
+#include <numeric>
+#include <vector>
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/atomic_ops.h"
+#include "rtc_base/checks.h"
+#include "system_wrappers/include/field_trial.h"
+
+namespace webrtc {
+namespace {
+
+bool DeactivateInitialStateResetAtEchoPathChange() {
+  return field_trial::IsEnabled(
+      "WebRTC-Aec3DeactivateInitialStateResetKillSwitch");
+}
+
+bool FullResetAtEchoPathChange() {
+  return !field_trial::IsEnabled("WebRTC-Aec3AecStateFullResetKillSwitch");
+}
+
+bool SubtractorAnalyzerResetAtEchoPathChange() {
+  return !field_trial::IsEnabled(
+      "WebRTC-Aec3AecStateSubtractorAnalyzerResetKillSwitch");
+}
+
+void ComputeAvgRenderReverb(
+    const SpectrumBuffer& spectrum_buffer,
+    int delay_blocks,
+    float reverb_decay,
+    ReverbModel* reverb_model,
+    rtc::ArrayView<float, kFftLengthBy2Plus1> reverb_power_spectrum) {
+  RTC_DCHECK(reverb_model);
+  const size_t num_render_channels = spectrum_buffer.buffer[0].size();
+  int idx_at_delay =
+      spectrum_buffer.OffsetIndex(spectrum_buffer.read, delay_blocks);
+  int idx_past = spectrum_buffer.IncIndex(idx_at_delay);
+
+  std::array<float, kFftLengthBy2Plus1> X2_data;
+  rtc::ArrayView<const float> X2;
+  if (num_render_channels > 1) {
+    auto average_channels =
+        [](size_t num_render_channels,
+           rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+               spectrum_band_0,
+           rtc::ArrayView<float, kFftLengthBy2Plus1> render_power) {
+          std::fill(render_power.begin(), render_power.end(), 0.f);
+          for (size_t ch = 0; ch < num_render_channels; ++ch) {
+            for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+              render_power[k] += spectrum_band_0[ch][k];
+            }
+          }
+          const float normalizer = 1.f / num_render_channels;
+          for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+            render_power[k] *= normalizer;
+          }
+        };
+    average_channels(num_render_channels, spectrum_buffer.buffer[idx_past],
+                     X2_data);
+    reverb_model->UpdateReverbNoFreqShaping(
+        X2_data, /*power_spectrum_scaling=*/1.0f, reverb_decay);
+
+    average_channels(num_render_channels, spectrum_buffer.buffer[idx_at_delay],
+                     X2_data);
+    X2 = X2_data;
+  } else {
+    reverb_model->UpdateReverbNoFreqShaping(
+        spectrum_buffer.buffer[idx_past][/*channel=*/0],
+        /*power_spectrum_scaling=*/1.0f, reverb_decay);
+
+    X2 = spectrum_buffer.buffer[idx_at_delay][/*channel=*/0];
+  }
+
+  rtc::ArrayView<const float, kFftLengthBy2Plus1> reverb_power =
+      reverb_model->reverb();
+  for (size_t k = 0; k < X2.size(); ++k) {
+    reverb_power_spectrum[k] = X2[k] + reverb_power[k];
+  }
+}
+
+}  // namespace
+
+int AecState::instance_count_ = 0;
+
+void AecState::GetResidualEchoScaling(
+    rtc::ArrayView<float> residual_scaling) const {
+  bool filter_has_had_time_to_converge;
+  if (config_.filter.conservative_initial_phase) {
+    filter_has_had_time_to_converge =
+        strong_not_saturated_render_blocks_ >= 1.5f * kNumBlocksPerSecond;
+  } else {
+    filter_has_had_time_to_converge =
+        strong_not_saturated_render_blocks_ >= 0.8f * kNumBlocksPerSecond;
+  }
+  echo_audibility_.GetResidualEchoScaling(filter_has_had_time_to_converge,
+                                          residual_scaling);
+}
+
+AecState::AecState(const EchoCanceller3Config& config,
+                   size_t num_capture_channels)
+    : data_dumper_(
+          new ApmDataDumper(rtc::AtomicOps::Increment(&instance_count_))),
+      config_(config),
+      num_capture_channels_(num_capture_channels),
+      deactivate_initial_state_reset_at_echo_path_change_(
+          DeactivateInitialStateResetAtEchoPathChange()),
+      full_reset_at_echo_path_change_(FullResetAtEchoPathChange()),
+      subtractor_analyzer_reset_at_echo_path_change_(
+          SubtractorAnalyzerResetAtEchoPathChange()),
+      initial_state_(config_),
+      delay_state_(config_, num_capture_channels_),
+      transparent_state_(TransparentMode::Create(config_)),
+      filter_quality_state_(config_, num_capture_channels_),
+      erl_estimator_(2 * kNumBlocksPerSecond),
+      erle_estimator_(2 * kNumBlocksPerSecond, config_, num_capture_channels_),
+      filter_analyzer_(config_, num_capture_channels_),
+      echo_audibility_(
+          config_.echo_audibility.use_stationarity_properties_at_init),
+      reverb_model_estimator_(config_, num_capture_channels_),
+      subtractor_output_analyzer_(num_capture_channels_) {}
+
+AecState::~AecState() = default;
+
+void AecState::HandleEchoPathChange(
+    const EchoPathVariability& echo_path_variability) {
+  const auto full_reset = [&]() {
+    filter_analyzer_.Reset();
+    capture_signal_saturation_ = false;
+    strong_not_saturated_render_blocks_ = 0;
+    blocks_with_active_render_ = 0;
+    if (!deactivate_initial_state_reset_at_echo_path_change_) {
+      initial_state_.Reset();
+    }
+    if (transparent_state_) {
+      transparent_state_->Reset();
+    }
+    erle_estimator_.Reset(true);
+    erl_estimator_.Reset();
+    filter_quality_state_.Reset();
+  };
+
+  // TODO(peah): Refine the reset scheme according to the type of gain and
+  // delay adjustment.
+
+  if (full_reset_at_echo_path_change_ &&
+      echo_path_variability.delay_change !=
+          EchoPathVariability::DelayAdjustment::kNone) {
+    full_reset();
+  } else if (echo_path_variability.gain_change) {
+    erle_estimator_.Reset(false);
+  }
+  if (subtractor_analyzer_reset_at_echo_path_change_) {
+    subtractor_output_analyzer_.HandleEchoPathChange();
+  }
+}
+
+void AecState::Update(
+    const absl::optional<DelayEstimate>& external_delay,
+    rtc::ArrayView<const std::vector<std::array<float, kFftLengthBy2Plus1>>>
+        adaptive_filter_frequency_responses,
+    rtc::ArrayView<const std::vector<float>> adaptive_filter_impulse_responses,
+    const RenderBuffer& render_buffer,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> E2_refined,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Y2,
+    rtc::ArrayView<const SubtractorOutput> subtractor_output) {
+  RTC_DCHECK_EQ(num_capture_channels_, Y2.size());
+  RTC_DCHECK_EQ(num_capture_channels_, subtractor_output.size());
+  RTC_DCHECK_EQ(num_capture_channels_,
+                adaptive_filter_frequency_responses.size());
+  RTC_DCHECK_EQ(num_capture_channels_,
+                adaptive_filter_impulse_responses.size());
+
+  // Analyze the filter outputs and filters.
+  bool any_filter_converged;
+  bool any_coarse_filter_converged;
+  bool all_filters_diverged;
+  subtractor_output_analyzer_.Update(subtractor_output, &any_filter_converged,
+                                     &any_coarse_filter_converged,
+                                     &all_filters_diverged);
+
+  bool any_filter_consistent;
+  float max_echo_path_gain;
+  filter_analyzer_.Update(adaptive_filter_impulse_responses, render_buffer,
+                          &any_filter_consistent, &max_echo_path_gain);
+
+  // Estimate the direct path delay of the filter.
+  if (config_.filter.use_linear_filter) {
+    delay_state_.Update(filter_analyzer_.FilterDelaysBlocks(), external_delay,
+                        strong_not_saturated_render_blocks_);
+  }
+
+  const std::vector<std::vector<float>>& aligned_render_block =
+      render_buffer.Block(-delay_state_.MinDirectPathFilterDelay())[0];
+
+  // Update render counters.
+  bool active_render = false;
+  for (size_t ch = 0; ch < aligned_render_block.size(); ++ch) {
+    const float render_energy = std::inner_product(
+        aligned_render_block[ch].begin(), aligned_render_block[ch].end(),
+        aligned_render_block[ch].begin(), 0.f);
+    if (render_energy > (config_.render_levels.active_render_limit *
+                         config_.render_levels.active_render_limit) *
+                            kFftLengthBy2) {
+      active_render = true;
+      break;
+    }
+  }
+  blocks_with_active_render_ += active_render ? 1 : 0;
+  strong_not_saturated_render_blocks_ +=
+      active_render && !SaturatedCapture() ? 1 : 0;
+
+  std::array<float, kFftLengthBy2Plus1> avg_render_spectrum_with_reverb;
+
+  ComputeAvgRenderReverb(render_buffer.GetSpectrumBuffer(),
+                         delay_state_.MinDirectPathFilterDelay(), ReverbDecay(),
+                         &avg_render_reverb_, avg_render_spectrum_with_reverb);
+
+  if (config_.echo_audibility.use_stationarity_properties) {
+    // Update the echo audibility evaluator.
+    echo_audibility_.Update(render_buffer, avg_render_reverb_.reverb(),
+                            delay_state_.MinDirectPathFilterDelay(),
+                            delay_state_.ExternalDelayReported());
+  }
+
+  // Update the ERL and ERLE measures.
+  if (initial_state_.TransitionTriggered()) {
+    erle_estimator_.Reset(false);
+  }
+
+  erle_estimator_.Update(render_buffer, adaptive_filter_frequency_responses,
+                         avg_render_spectrum_with_reverb, Y2, E2_refined,
+                         subtractor_output_analyzer_.ConvergedFilters());
+
+  erl_estimator_.Update(
+      subtractor_output_analyzer_.ConvergedFilters(),
+      render_buffer.Spectrum(delay_state_.MinDirectPathFilterDelay()), Y2);
+
+  // Detect and flag echo saturation.
+  if (config_.ep_strength.echo_can_saturate) {
+    saturation_detector_.Update(aligned_render_block, SaturatedCapture(),
+                                UsableLinearEstimate(), subtractor_output,
+                                max_echo_path_gain);
+  } else {
+    RTC_DCHECK(!saturation_detector_.SaturatedEcho());
+  }
+
+  // Update the decision on whether to use the initial state parameter set.
+  initial_state_.Update(active_render, SaturatedCapture());
+
+  // Detect whether the transparent mode should be activated.
+  if (transparent_state_) {
+    transparent_state_->Update(
+        delay_state_.MinDirectPathFilterDelay(), any_filter_consistent,
+        any_filter_converged, any_coarse_filter_converged, all_filters_diverged,
+        active_render, SaturatedCapture());
+  }
+
+  // Analyze the quality of the filter.
+  filter_quality_state_.Update(active_render, TransparentModeActive(),
+                               SaturatedCapture(), external_delay,
+                               any_filter_converged);
+
+  // Update the reverb estimate.
+  const bool stationary_block =
+      config_.echo_audibility.use_stationarity_properties &&
+      echo_audibility_.IsBlockStationary();
+
+  reverb_model_estimator_.Update(
+      filter_analyzer_.GetAdjustedFilters(),
+      adaptive_filter_frequency_responses,
+      erle_estimator_.GetInstLinearQualityEstimates(),
+      delay_state_.DirectPathFilterDelays(),
+      filter_quality_state_.UsableLinearFilterOutputs(), stationary_block);
+
+  erle_estimator_.Dump(data_dumper_);
+  reverb_model_estimator_.Dump(data_dumper_.get());
+  data_dumper_->DumpRaw("aec3_active_render", active_render);
+  data_dumper_->DumpRaw("aec3_erl", Erl());
+  data_dumper_->DumpRaw("aec3_erl_time_domain", ErlTimeDomain());
+  data_dumper_->DumpRaw("aec3_erle", Erle(/*onset_compensated=*/false)[0]);
+  data_dumper_->DumpRaw("aec3_erle_onset_compensated",
+                        Erle(/*onset_compensated=*/true)[0]);
+  data_dumper_->DumpRaw("aec3_usable_linear_estimate", UsableLinearEstimate());
+  data_dumper_->DumpRaw("aec3_transparent_mode", TransparentModeActive());
+  data_dumper_->DumpRaw("aec3_filter_delay",
+                        filter_analyzer_.MinFilterDelayBlocks());
+
+  data_dumper_->DumpRaw("aec3_any_filter_consistent", any_filter_consistent);
+  data_dumper_->DumpRaw("aec3_initial_state",
+                        initial_state_.InitialStateActive());
+  data_dumper_->DumpRaw("aec3_capture_saturation", SaturatedCapture());
+  data_dumper_->DumpRaw("aec3_echo_saturation", SaturatedEcho());
+  data_dumper_->DumpRaw("aec3_any_filter_converged", any_filter_converged);
+  data_dumper_->DumpRaw("aec3_any_coarse_filter_converged",
+                        any_coarse_filter_converged);
+  data_dumper_->DumpRaw("aec3_all_filters_diverged", all_filters_diverged);
+
+  data_dumper_->DumpRaw("aec3_external_delay_avaliable",
+                        external_delay ? 1 : 0);
+  data_dumper_->DumpRaw("aec3_filter_tail_freq_resp_est",
+                        GetReverbFrequencyResponse());
+  data_dumper_->DumpRaw("aec3_subtractor_y2", subtractor_output[0].y2);
+  data_dumper_->DumpRaw("aec3_subtractor_e2_coarse",
+                        subtractor_output[0].e2_coarse);
+  data_dumper_->DumpRaw("aec3_subtractor_e2_refined",
+                        subtractor_output[0].e2_refined);
+}
+
+AecState::InitialState::InitialState(const EchoCanceller3Config& config)
+    : conservative_initial_phase_(config.filter.conservative_initial_phase),
+      initial_state_seconds_(config.filter.initial_state_seconds) {
+  Reset();
+}
+void AecState::InitialState::InitialState::Reset() {
+  initial_state_ = true;
+  strong_not_saturated_render_blocks_ = 0;
+}
+void AecState::InitialState::InitialState::Update(bool active_render,
+                                                  bool saturated_capture) {
+  strong_not_saturated_render_blocks_ +=
+      active_render && !saturated_capture ? 1 : 0;
+
+  // Flag whether the initial state is still active.
+  bool prev_initial_state = initial_state_;
+  if (conservative_initial_phase_) {
+    initial_state_ =
+        strong_not_saturated_render_blocks_ < 5 * kNumBlocksPerSecond;
+  } else {
+    initial_state_ = strong_not_saturated_render_blocks_ <
+                     initial_state_seconds_ * kNumBlocksPerSecond;
+  }
+
+  // Flag whether the transition from the initial state has started.
+  transition_triggered_ = !initial_state_ && prev_initial_state;
+}
+
+AecState::FilterDelay::FilterDelay(const EchoCanceller3Config& config,
+                                   size_t num_capture_channels)
+    : delay_headroom_blocks_(config.delay.delay_headroom_samples / kBlockSize),
+      filter_delays_blocks_(num_capture_channels, delay_headroom_blocks_),
+      min_filter_delay_(delay_headroom_blocks_) {}
+
+void AecState::FilterDelay::Update(
+    rtc::ArrayView<const int> analyzer_filter_delay_estimates_blocks,
+    const absl::optional<DelayEstimate>& external_delay,
+    size_t blocks_with_proper_filter_adaptation) {
+  // Update the delay based on the external delay.
+  if (external_delay &&
+      (!external_delay_ || external_delay_->delay != external_delay->delay)) {
+    external_delay_ = external_delay;
+    external_delay_reported_ = true;
+  }
+
+  // Override the estimated delay if it is not certain that the filter has had
+  // time to converge.
+  const bool delay_estimator_may_not_have_converged =
+      blocks_with_proper_filter_adaptation < 2 * kNumBlocksPerSecond;
+  if (delay_estimator_may_not_have_converged && external_delay_) {
+    const int delay_guess = delay_headroom_blocks_;
+    std::fill(filter_delays_blocks_.begin(), filter_delays_blocks_.end(),
+              delay_guess);
+  } else {
+    RTC_DCHECK_EQ(filter_delays_blocks_.size(),
+                  analyzer_filter_delay_estimates_blocks.size());
+    std::copy(analyzer_filter_delay_estimates_blocks.begin(),
+              analyzer_filter_delay_estimates_blocks.end(),
+              filter_delays_blocks_.begin());
+  }
+
+  min_filter_delay_ = *std::min_element(filter_delays_blocks_.begin(),
+                                        filter_delays_blocks_.end());
+}
+
+AecState::FilteringQualityAnalyzer::FilteringQualityAnalyzer(
+    const EchoCanceller3Config& config,
+    size_t num_capture_channels)
+    : use_linear_filter_(config.filter.use_linear_filter),
+      usable_linear_filter_estimates_(num_capture_channels, false) {}
+
+void AecState::FilteringQualityAnalyzer::Reset() {
+  std::fill(usable_linear_filter_estimates_.begin(),
+            usable_linear_filter_estimates_.end(), false);
+  overall_usable_linear_estimates_ = false;
+  filter_update_blocks_since_reset_ = 0;
+}
+
+void AecState::FilteringQualityAnalyzer::Update(
+    bool active_render,
+    bool transparent_mode,
+    bool saturated_capture,
+    const absl::optional<DelayEstimate>& external_delay,
+    bool any_filter_converged) {
+  // Update blocks counter.
+  const bool filter_update = active_render && !saturated_capture;
+  filter_update_blocks_since_reset_ += filter_update ? 1 : 0;
+  filter_update_blocks_since_start_ += filter_update ? 1 : 0;
+
+  // Store convergence flag when observed.
+  convergence_seen_ = convergence_seen_ || any_filter_converged;
+
+  // Verify requirements for achieving a decent filter. The requirements for
+  // filter adaptation at call startup are more restrictive than after an
+  // in-call reset.
+  const bool sufficient_data_to_converge_at_startup =
+      filter_update_blocks_since_start_ > kNumBlocksPerSecond * 0.4f;
+  const bool sufficient_data_to_converge_at_reset =
+      sufficient_data_to_converge_at_startup &&
+      filter_update_blocks_since_reset_ > kNumBlocksPerSecond * 0.2f;
+
+  // The linear filter can only be used if it has had time to converge.
+  overall_usable_linear_estimates_ = sufficient_data_to_converge_at_startup &&
+                                     sufficient_data_to_converge_at_reset;
+
+  // The linear filter can only be used if an external delay or convergence have
+  // been identified
+  overall_usable_linear_estimates_ =
+      overall_usable_linear_estimates_ && (external_delay || convergence_seen_);
+
+  // If transparent mode is on, deactivate usign the linear filter.
+  overall_usable_linear_estimates_ =
+      overall_usable_linear_estimates_ && !transparent_mode;
+
+  if (use_linear_filter_) {
+    std::fill(usable_linear_filter_estimates_.begin(),
+              usable_linear_filter_estimates_.end(),
+              overall_usable_linear_estimates_);
+  }
+}
+
+void AecState::SaturationDetector::Update(
+    rtc::ArrayView<const std::vector<float>> x,
+    bool saturated_capture,
+    bool usable_linear_estimate,
+    rtc::ArrayView<const SubtractorOutput> subtractor_output,
+    float echo_path_gain) {
+  saturated_echo_ = false;
+  if (!saturated_capture) {
+    return;
+  }
+
+  if (usable_linear_estimate) {
+    constexpr float kSaturationThreshold = 20000.f;
+    for (size_t ch = 0; ch < subtractor_output.size(); ++ch) {
+      saturated_echo_ =
+          saturated_echo_ ||
+          (subtractor_output[ch].s_refined_max_abs > kSaturationThreshold ||
+           subtractor_output[ch].s_coarse_max_abs > kSaturationThreshold);
+    }
+  } else {
+    float max_sample = 0.f;
+    for (auto& channel : x) {
+      for (float sample : channel) {
+        max_sample = std::max(max_sample, fabsf(sample));
+      }
+    }
+
+    const float kMargin = 10.f;
+    float peak_echo_amplitude = max_sample * echo_path_gain * kMargin;
+    saturated_echo_ = saturated_echo_ || peak_echo_amplitude > 32000;
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec_state.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec_state.h
new file mode 100644
index 0000000..125ae83
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec_state.h
@@ -0,0 +1,289 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_AEC_STATE_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_AEC_STATE_H_
+
+#include <stddef.h>
+
+#include <array>
+#include <memory>
+#include <vector>
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/delay_estimate.h"
+#include "modules/audio_processing/aec3/echo_audibility.h"
+#include "modules/audio_processing/aec3/echo_path_variability.h"
+#include "modules/audio_processing/aec3/erl_estimator.h"
+#include "modules/audio_processing/aec3/erle_estimator.h"
+#include "modules/audio_processing/aec3/filter_analyzer.h"
+#include "modules/audio_processing/aec3/render_buffer.h"
+#include "modules/audio_processing/aec3/reverb_model_estimator.h"
+#include "modules/audio_processing/aec3/subtractor_output.h"
+#include "modules/audio_processing/aec3/subtractor_output_analyzer.h"
+#include "modules/audio_processing/aec3/transparent_mode.h"
+
+namespace webrtc {
+
+class ApmDataDumper;
+
+// Handles the state and the conditions for the echo removal functionality.
+class AecState {
+ public:
+  AecState(const EchoCanceller3Config& config, size_t num_capture_channels);
+  ~AecState();
+
+  // Returns whether the echo subtractor can be used to determine the residual
+  // echo.
+  bool UsableLinearEstimate() const {
+    return filter_quality_state_.LinearFilterUsable() &&
+           config_.filter.use_linear_filter;
+  }
+
+  // Returns whether the echo subtractor output should be used as output.
+  bool UseLinearFilterOutput() const {
+    return filter_quality_state_.LinearFilterUsable() &&
+           config_.filter.use_linear_filter;
+  }
+
+  // Returns whether the render signal is currently active.
+  bool ActiveRender() const { return blocks_with_active_render_ > 200; }
+
+  // Returns the appropriate scaling of the residual echo to match the
+  // audibility.
+  void GetResidualEchoScaling(rtc::ArrayView<float> residual_scaling) const;
+
+  // Returns whether the stationary properties of the signals are used in the
+  // aec.
+  bool UseStationarityProperties() const {
+    return config_.echo_audibility.use_stationarity_properties;
+  }
+
+  // Returns the ERLE.
+  rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Erle(
+      bool onset_compensated) const {
+    return erle_estimator_.Erle(onset_compensated);
+  }
+
+  // Returns the fullband ERLE estimate in log2 units.
+  float FullBandErleLog2() const { return erle_estimator_.FullbandErleLog2(); }
+
+  // Returns the ERL.
+  const std::array<float, kFftLengthBy2Plus1>& Erl() const {
+    return erl_estimator_.Erl();
+  }
+
+  // Returns the time-domain ERL.
+  float ErlTimeDomain() const { return erl_estimator_.ErlTimeDomain(); }
+
+  // Returns the delay estimate based on the linear filter.
+  int MinDirectPathFilterDelay() const {
+    return delay_state_.MinDirectPathFilterDelay();
+  }
+
+  // Returns whether the capture signal is saturated.
+  bool SaturatedCapture() const { return capture_signal_saturation_; }
+
+  // Returns whether the echo signal is saturated.
+  bool SaturatedEcho() const { return saturation_detector_.SaturatedEcho(); }
+
+  // Updates the capture signal saturation.
+  void UpdateCaptureSaturation(bool capture_signal_saturation) {
+    capture_signal_saturation_ = capture_signal_saturation;
+  }
+
+  // Returns whether the transparent mode is active
+  bool TransparentModeActive() const {
+    return transparent_state_ && transparent_state_->Active();
+  }
+
+  // Takes appropriate action at an echo path change.
+  void HandleEchoPathChange(const EchoPathVariability& echo_path_variability);
+
+  // Returns the decay factor for the echo reverberation.
+  float ReverbDecay() const { return reverb_model_estimator_.ReverbDecay(); }
+
+  // Return the frequency response of the reverberant echo.
+  rtc::ArrayView<const float> GetReverbFrequencyResponse() const {
+    return reverb_model_estimator_.GetReverbFrequencyResponse();
+  }
+
+  // Returns whether the transition for going out of the initial stated has
+  // been triggered.
+  bool TransitionTriggered() const {
+    return initial_state_.TransitionTriggered();
+  }
+
+  // Updates the aec state.
+  // TODO(bugs.webrtc.org/10913): Compute multi-channel ERL.
+  void Update(
+      const absl::optional<DelayEstimate>& external_delay,
+      rtc::ArrayView<const std::vector<std::array<float, kFftLengthBy2Plus1>>>
+          adaptive_filter_frequency_responses,
+      rtc::ArrayView<const std::vector<float>>
+          adaptive_filter_impulse_responses,
+      const RenderBuffer& render_buffer,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> E2_refined,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Y2,
+      rtc::ArrayView<const SubtractorOutput> subtractor_output);
+
+  // Returns filter length in blocks.
+  int FilterLengthBlocks() const {
+    // All filters have the same length, so arbitrarily return channel 0 length.
+    return filter_analyzer_.FilterLengthBlocks();
+  }
+
+ private:
+  static int instance_count_;
+  std::unique_ptr<ApmDataDumper> data_dumper_;
+  const EchoCanceller3Config config_;
+  const size_t num_capture_channels_;
+  const bool deactivate_initial_state_reset_at_echo_path_change_;
+  const bool full_reset_at_echo_path_change_;
+  const bool subtractor_analyzer_reset_at_echo_path_change_;
+
+  // Class for controlling the transition from the intial state, which in turn
+  // controls when the filter parameters for the initial state should be used.
+  class InitialState {
+   public:
+    explicit InitialState(const EchoCanceller3Config& config);
+    // Resets the state to again begin in the initial state.
+    void Reset();
+
+    // Updates the state based on new data.
+    void Update(bool active_render, bool saturated_capture);
+
+    // Returns whether the initial state is active or not.
+    bool InitialStateActive() const { return initial_state_; }
+
+    // Returns that the transition from the initial state has was started.
+    bool TransitionTriggered() const { return transition_triggered_; }
+
+   private:
+    const bool conservative_initial_phase_;
+    const float initial_state_seconds_;
+    bool transition_triggered_ = false;
+    bool initial_state_ = true;
+    size_t strong_not_saturated_render_blocks_ = 0;
+  } initial_state_;
+
+  // Class for choosing the direct-path delay relative to the beginning of the
+  // filter, as well as any other data related to the delay used within
+  // AecState.
+  class FilterDelay {
+   public:
+    FilterDelay(const EchoCanceller3Config& config,
+                size_t num_capture_channels);
+
+    // Returns whether an external delay has been reported to the AecState (from
+    // the delay estimator).
+    bool ExternalDelayReported() const { return external_delay_reported_; }
+
+    // Returns the delay in blocks relative to the beginning of the filter that
+    // corresponds to the direct path of the echo.
+    rtc::ArrayView<const int> DirectPathFilterDelays() const {
+      return filter_delays_blocks_;
+    }
+
+    // Returns the minimum delay among the direct path delays relative to the
+    // beginning of the filter
+    int MinDirectPathFilterDelay() const { return min_filter_delay_; }
+
+    // Updates the delay estimates based on new data.
+    void Update(
+        rtc::ArrayView<const int> analyzer_filter_delay_estimates_blocks,
+        const absl::optional<DelayEstimate>& external_delay,
+        size_t blocks_with_proper_filter_adaptation);
+
+   private:
+    const int delay_headroom_blocks_;
+    bool external_delay_reported_ = false;
+    std::vector<int> filter_delays_blocks_;
+    int min_filter_delay_;
+    absl::optional<DelayEstimate> external_delay_;
+  } delay_state_;
+
+  // Classifier for toggling transparent mode when there is no echo.
+  std::unique_ptr<TransparentMode> transparent_state_;
+
+  // Class for analyzing how well the linear filter is, and can be expected to,
+  // perform on the current signals. The purpose of this is for using to
+  // select the echo suppression functionality as well as the input to the echo
+  // suppressor.
+  class FilteringQualityAnalyzer {
+   public:
+    FilteringQualityAnalyzer(const EchoCanceller3Config& config,
+                             size_t num_capture_channels);
+
+    // Returns whether the linear filter can be used for the echo
+    // canceller output.
+    bool LinearFilterUsable() const { return overall_usable_linear_estimates_; }
+
+    // Returns whether an individual filter output can be used for the echo
+    // canceller output.
+    const std::vector<bool>& UsableLinearFilterOutputs() const {
+      return usable_linear_filter_estimates_;
+    }
+
+    // Resets the state of the analyzer.
+    void Reset();
+
+    // Updates the analysis based on new data.
+    void Update(bool active_render,
+                bool transparent_mode,
+                bool saturated_capture,
+                const absl::optional<DelayEstimate>& external_delay,
+                bool any_filter_converged);
+
+   private:
+    const bool use_linear_filter_;
+    bool overall_usable_linear_estimates_ = false;
+    size_t filter_update_blocks_since_reset_ = 0;
+    size_t filter_update_blocks_since_start_ = 0;
+    bool convergence_seen_ = false;
+    std::vector<bool> usable_linear_filter_estimates_;
+  } filter_quality_state_;
+
+  // Class for detecting whether the echo is to be considered to be
+  // saturated.
+  class SaturationDetector {
+   public:
+    // Returns whether the echo is to be considered saturated.
+    bool SaturatedEcho() const { return saturated_echo_; }
+
+    // Updates the detection decision based on new data.
+    void Update(rtc::ArrayView<const std::vector<float>> x,
+                bool saturated_capture,
+                bool usable_linear_estimate,
+                rtc::ArrayView<const SubtractorOutput> subtractor_output,
+                float echo_path_gain);
+
+   private:
+    bool saturated_echo_ = false;
+  } saturation_detector_;
+
+  ErlEstimator erl_estimator_;
+  ErleEstimator erle_estimator_;
+  size_t strong_not_saturated_render_blocks_ = 0;
+  size_t blocks_with_active_render_ = 0;
+  bool capture_signal_saturation_ = false;
+  FilterAnalyzer filter_analyzer_;
+  EchoAudibility echo_audibility_;
+  ReverbModelEstimator reverb_model_estimator_;
+  ReverbModel avg_render_reverb_;
+  SubtractorOutputAnalyzer subtractor_output_analyzer_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_AEC_STATE_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec_state_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec_state_unittest.cc
new file mode 100644
index 0000000..6e62a58
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/aec_state_unittest.cc
@@ -0,0 +1,299 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/aec_state.h"
+
+#include "modules/audio_processing/aec3/aec3_fft.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace {
+
+void RunNormalUsageTest(size_t num_render_channels,
+                        size_t num_capture_channels) {
+  // TODO(bugs.webrtc.org/10913): Test with different content in different
+  // channels.
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+  ApmDataDumper data_dumper(42);
+  EchoCanceller3Config config;
+  AecState state(config, num_capture_channels);
+  absl::optional<DelayEstimate> delay_estimate =
+      DelayEstimate(DelayEstimate::Quality::kRefined, 10);
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+      RenderDelayBuffer::Create(config, kSampleRateHz, num_render_channels));
+  std::vector<std::array<float, kFftLengthBy2Plus1>> E2_refined(
+      num_capture_channels);
+  std::vector<std::array<float, kFftLengthBy2Plus1>> Y2(num_capture_channels);
+  std::vector<std::vector<std::vector<float>>> x(
+      kNumBands, std::vector<std::vector<float>>(
+                     num_render_channels, std::vector<float>(kBlockSize, 0.f)));
+  EchoPathVariability echo_path_variability(
+      false, EchoPathVariability::DelayAdjustment::kNone, false);
+  std::vector<std::array<float, kBlockSize>> y(num_capture_channels);
+  std::vector<SubtractorOutput> subtractor_output(num_capture_channels);
+  for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+    subtractor_output[ch].Reset();
+    subtractor_output[ch].s_refined.fill(100.f);
+    subtractor_output[ch].e_refined.fill(100.f);
+    y[ch].fill(1000.f);
+    E2_refined[ch].fill(0.f);
+    Y2[ch].fill(0.f);
+  }
+  Aec3Fft fft;
+  std::vector<std::vector<std::array<float, kFftLengthBy2Plus1>>>
+  converged_filter_frequency_response(
+      num_capture_channels,
+      std::vector<std::array<float, kFftLengthBy2Plus1>>(10));
+  for (auto& v_ch : converged_filter_frequency_response) {
+    for (auto& v : v_ch) {
+      v.fill(0.01f);
+    }
+  }
+  std::vector<std::vector<std::array<float, kFftLengthBy2Plus1>>>
+      diverged_filter_frequency_response = converged_filter_frequency_response;
+  converged_filter_frequency_response[0][2].fill(100.f);
+  converged_filter_frequency_response[0][2][0] = 1.f;
+  std::vector<std::vector<float>> impulse_response(
+      num_capture_channels,
+      std::vector<float>(
+          GetTimeDomainLength(config.filter.refined.length_blocks), 0.f));
+
+  // Verify that linear AEC usability is true when the filter is converged
+  for (size_t band = 0; band < kNumBands; ++band) {
+    for (size_t ch = 0; ch < num_render_channels; ++ch) {
+      std::fill(x[band][ch].begin(), x[band][ch].end(), 101.f);
+    }
+  }
+  for (int k = 0; k < 3000; ++k) {
+    render_delay_buffer->Insert(x);
+    for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+      subtractor_output[ch].ComputeMetrics(y[ch]);
+    }
+    state.Update(delay_estimate, converged_filter_frequency_response,
+                 impulse_response, *render_delay_buffer->GetRenderBuffer(),
+                 E2_refined, Y2, subtractor_output);
+  }
+  EXPECT_TRUE(state.UsableLinearEstimate());
+
+  // Verify that linear AEC usability becomes false after an echo path
+  // change is reported
+  for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+    subtractor_output[ch].ComputeMetrics(y[ch]);
+  }
+  state.HandleEchoPathChange(EchoPathVariability(
+      false, EchoPathVariability::DelayAdjustment::kNewDetectedDelay, false));
+  state.Update(delay_estimate, converged_filter_frequency_response,
+               impulse_response, *render_delay_buffer->GetRenderBuffer(),
+               E2_refined, Y2, subtractor_output);
+  EXPECT_FALSE(state.UsableLinearEstimate());
+
+  // Verify that the active render detection works as intended.
+  for (size_t ch = 0; ch < num_render_channels; ++ch) {
+    std::fill(x[0][ch].begin(), x[0][ch].end(), 101.f);
+  }
+  render_delay_buffer->Insert(x);
+  for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+    subtractor_output[ch].ComputeMetrics(y[ch]);
+  }
+  state.HandleEchoPathChange(EchoPathVariability(
+      true, EchoPathVariability::DelayAdjustment::kNewDetectedDelay, false));
+  state.Update(delay_estimate, converged_filter_frequency_response,
+               impulse_response, *render_delay_buffer->GetRenderBuffer(),
+               E2_refined, Y2, subtractor_output);
+  EXPECT_FALSE(state.ActiveRender());
+
+  for (int k = 0; k < 1000; ++k) {
+    render_delay_buffer->Insert(x);
+    for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+      subtractor_output[ch].ComputeMetrics(y[ch]);
+    }
+    state.Update(delay_estimate, converged_filter_frequency_response,
+                 impulse_response, *render_delay_buffer->GetRenderBuffer(),
+                 E2_refined, Y2, subtractor_output);
+  }
+  EXPECT_TRUE(state.ActiveRender());
+
+  // Verify that the ERL is properly estimated
+  for (auto& band : x) {
+    for (auto& channel : band) {
+      channel = std::vector<float>(kBlockSize, 0.f);
+    }
+  }
+
+  for (size_t ch = 0; ch < num_render_channels; ++ch) {
+    x[0][ch][0] = 5000.f;
+  }
+  for (size_t k = 0;
+       k < render_delay_buffer->GetRenderBuffer()->GetFftBuffer().size(); ++k) {
+    render_delay_buffer->Insert(x);
+    if (k == 0) {
+      render_delay_buffer->Reset();
+    }
+    render_delay_buffer->PrepareCaptureProcessing();
+  }
+
+  for (auto& Y2_ch : Y2) {
+    Y2_ch.fill(10.f * 10000.f * 10000.f);
+  }
+  for (size_t k = 0; k < 1000; ++k) {
+    for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+      subtractor_output[ch].ComputeMetrics(y[ch]);
+    }
+    state.Update(delay_estimate, converged_filter_frequency_response,
+                 impulse_response, *render_delay_buffer->GetRenderBuffer(),
+                 E2_refined, Y2, subtractor_output);
+  }
+
+  ASSERT_TRUE(state.UsableLinearEstimate());
+  const std::array<float, kFftLengthBy2Plus1>& erl = state.Erl();
+  EXPECT_EQ(erl[0], erl[1]);
+  for (size_t k = 1; k < erl.size() - 1; ++k) {
+    EXPECT_NEAR(k % 2 == 0 ? 10.f : 1000.f, erl[k], 0.1);
+  }
+  EXPECT_EQ(erl[erl.size() - 2], erl[erl.size() - 1]);
+
+  // Verify that the ERLE is properly estimated
+  for (auto& E2_refined_ch : E2_refined) {
+    E2_refined_ch.fill(1.f * 10000.f * 10000.f);
+  }
+  for (auto& Y2_ch : Y2) {
+    Y2_ch.fill(10.f * E2_refined[0][0]);
+  }
+  for (size_t k = 0; k < 1000; ++k) {
+    for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+      subtractor_output[ch].ComputeMetrics(y[ch]);
+    }
+    state.Update(delay_estimate, converged_filter_frequency_response,
+                 impulse_response, *render_delay_buffer->GetRenderBuffer(),
+                 E2_refined, Y2, subtractor_output);
+  }
+  ASSERT_TRUE(state.UsableLinearEstimate());
+  {
+    // Note that the render spectrum is built so it does not have energy in
+    // the odd bands but just in the even bands.
+    const auto& erle = state.Erle(/*onset_compensated=*/true)[0];
+    EXPECT_EQ(erle[0], erle[1]);
+    constexpr size_t kLowFrequencyLimit = 32;
+    for (size_t k = 2; k < kLowFrequencyLimit; k = k + 2) {
+      EXPECT_NEAR(4.f, erle[k], 0.1);
+    }
+    for (size_t k = kLowFrequencyLimit; k < erle.size() - 1; k = k + 2) {
+      EXPECT_NEAR(1.5f, erle[k], 0.1);
+    }
+    EXPECT_EQ(erle[erle.size() - 2], erle[erle.size() - 1]);
+  }
+  for (auto& E2_refined_ch : E2_refined) {
+    E2_refined_ch.fill(1.f * 10000.f * 10000.f);
+  }
+  for (auto& Y2_ch : Y2) {
+    Y2_ch.fill(5.f * E2_refined[0][0]);
+  }
+  for (size_t k = 0; k < 1000; ++k) {
+    for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+      subtractor_output[ch].ComputeMetrics(y[ch]);
+    }
+    state.Update(delay_estimate, converged_filter_frequency_response,
+                 impulse_response, *render_delay_buffer->GetRenderBuffer(),
+                 E2_refined, Y2, subtractor_output);
+  }
+
+  ASSERT_TRUE(state.UsableLinearEstimate());
+  {
+    const auto& erle = state.Erle(/*onset_compensated=*/true)[0];
+    EXPECT_EQ(erle[0], erle[1]);
+    constexpr size_t kLowFrequencyLimit = 32;
+    for (size_t k = 1; k < kLowFrequencyLimit; ++k) {
+      EXPECT_NEAR(k % 2 == 0 ? 4.f : 1.f, erle[k], 0.1);
+    }
+    for (size_t k = kLowFrequencyLimit; k < erle.size() - 1; ++k) {
+      EXPECT_NEAR(k % 2 == 0 ? 1.5f : 1.f, erle[k], 0.1);
+    }
+    EXPECT_EQ(erle[erle.size() - 2], erle[erle.size() - 1]);
+  }
+}
+
+}  // namespace
+
+class AecStateMultiChannel
+    : public ::testing::Test,
+      public ::testing::WithParamInterface<std::tuple<size_t, size_t>> {};
+
+INSTANTIATE_TEST_SUITE_P(MultiChannel,
+                         AecStateMultiChannel,
+                         ::testing::Combine(::testing::Values(1, 2, 8),
+                                            ::testing::Values(1, 2, 8)));
+
+// Verify the general functionality of AecState
+TEST_P(AecStateMultiChannel, NormalUsage) {
+  const size_t num_render_channels = std::get<0>(GetParam());
+  const size_t num_capture_channels = std::get<1>(GetParam());
+  RunNormalUsageTest(num_render_channels, num_capture_channels);
+}
+
+// Verifies the delay for a converged filter is correctly identified.
+TEST(AecState, ConvergedFilterDelay) {
+  constexpr int kFilterLengthBlocks = 10;
+  constexpr size_t kNumCaptureChannels = 1;
+  EchoCanceller3Config config;
+  AecState state(config, kNumCaptureChannels);
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+      RenderDelayBuffer::Create(config, 48000, 1));
+  absl::optional<DelayEstimate> delay_estimate;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> E2_refined(
+      kNumCaptureChannels);
+  std::vector<std::array<float, kFftLengthBy2Plus1>> Y2(kNumCaptureChannels);
+  std::array<float, kBlockSize> x;
+  EchoPathVariability echo_path_variability(
+      false, EchoPathVariability::DelayAdjustment::kNone, false);
+  std::vector<SubtractorOutput> subtractor_output(kNumCaptureChannels);
+  for (auto& output : subtractor_output) {
+    output.Reset();
+    output.s_refined.fill(100.f);
+  }
+  std::array<float, kBlockSize> y;
+  x.fill(0.f);
+  y.fill(0.f);
+
+  std::vector<std::vector<std::array<float, kFftLengthBy2Plus1>>>
+  frequency_response(
+      kNumCaptureChannels,
+      std::vector<std::array<float, kFftLengthBy2Plus1>>(kFilterLengthBlocks));
+  for (auto& v_ch : frequency_response) {
+    for (auto& v : v_ch) {
+      v.fill(0.01f);
+    }
+  }
+
+  std::vector<std::vector<float>> impulse_response(
+      kNumCaptureChannels,
+      std::vector<float>(
+          GetTimeDomainLength(config.filter.refined.length_blocks), 0.f));
+
+  // Verify that the filter delay for a converged filter is properly
+  // identified.
+  for (int k = 0; k < kFilterLengthBlocks; ++k) {
+    for (auto& ir : impulse_response) {
+      std::fill(ir.begin(), ir.end(), 0.f);
+      ir[k * kBlockSize + 1] = 1.f;
+    }
+
+    state.HandleEchoPathChange(echo_path_variability);
+    subtractor_output[0].ComputeMetrics(y);
+    state.Update(delay_estimate, frequency_response, impulse_response,
+                 *render_delay_buffer->GetRenderBuffer(), E2_refined, Y2,
+                 subtractor_output);
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/alignment_mixer.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/alignment_mixer.cc
new file mode 100644
index 0000000..87488d2
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/alignment_mixer.cc
@@ -0,0 +1,160 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "modules/audio_processing/aec3/alignment_mixer.h"
+
+#include <algorithm>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+
+AlignmentMixer::MixingVariant ChooseMixingVariant(bool downmix,
+                                                  bool adaptive_selection,
+                                                  int num_channels) {
+  RTC_DCHECK(!(adaptive_selection && downmix));
+  RTC_DCHECK_LT(0, num_channels);
+
+  if (num_channels == 1) {
+    return AlignmentMixer::MixingVariant::kFixed;
+  }
+  if (downmix) {
+    return AlignmentMixer::MixingVariant::kDownmix;
+  }
+  if (adaptive_selection) {
+    return AlignmentMixer::MixingVariant::kAdaptive;
+  }
+  return AlignmentMixer::MixingVariant::kFixed;
+}
+
+}  // namespace
+
+AlignmentMixer::AlignmentMixer(
+    size_t num_channels,
+    const EchoCanceller3Config::Delay::AlignmentMixing& config)
+    : AlignmentMixer(num_channels,
+                     config.downmix,
+                     config.adaptive_selection,
+                     config.activity_power_threshold,
+                     config.prefer_first_two_channels) {}
+
+AlignmentMixer::AlignmentMixer(size_t num_channels,
+                               bool downmix,
+                               bool adaptive_selection,
+                               float activity_power_threshold,
+                               bool prefer_first_two_channels)
+    : num_channels_(num_channels),
+      one_by_num_channels_(1.f / num_channels_),
+      excitation_energy_threshold_(kBlockSize * activity_power_threshold),
+      prefer_first_two_channels_(prefer_first_two_channels),
+      selection_variant_(
+          ChooseMixingVariant(downmix, adaptive_selection, num_channels_)) {
+  if (selection_variant_ == MixingVariant::kAdaptive) {
+    std::fill(strong_block_counters_.begin(), strong_block_counters_.end(), 0);
+    cumulative_energies_.resize(num_channels_);
+    std::fill(cumulative_energies_.begin(), cumulative_energies_.end(), 0.f);
+  }
+}
+
+void AlignmentMixer::ProduceOutput(rtc::ArrayView<const std::vector<float>> x,
+                                   rtc::ArrayView<float, kBlockSize> y) {
+  RTC_DCHECK_EQ(x.size(), num_channels_);
+  if (selection_variant_ == MixingVariant::kDownmix) {
+    Downmix(x, y);
+    return;
+  }
+
+  int ch = selection_variant_ == MixingVariant::kFixed ? 0 : SelectChannel(x);
+
+  RTC_DCHECK_GE(x.size(), ch);
+  std::copy(x[ch].begin(), x[ch].end(), y.begin());
+}
+
+void AlignmentMixer::Downmix(rtc::ArrayView<const std::vector<float>> x,
+                             rtc::ArrayView<float, kBlockSize> y) const {
+  RTC_DCHECK_EQ(x.size(), num_channels_);
+  RTC_DCHECK_GE(num_channels_, 2);
+  std::copy(x[0].begin(), x[0].end(), y.begin());
+  for (size_t ch = 1; ch < num_channels_; ++ch) {
+    for (size_t i = 0; i < kBlockSize; ++i) {
+      y[i] += x[ch][i];
+    }
+  }
+
+  for (size_t i = 0; i < kBlockSize; ++i) {
+    y[i] *= one_by_num_channels_;
+  }
+}
+
+int AlignmentMixer::SelectChannel(rtc::ArrayView<const std::vector<float>> x) {
+  RTC_DCHECK_EQ(x.size(), num_channels_);
+  RTC_DCHECK_GE(num_channels_, 2);
+  RTC_DCHECK_EQ(cumulative_energies_.size(), num_channels_);
+
+  constexpr size_t kBlocksToChooseLeftOrRight =
+      static_cast<size_t>(0.5f * kNumBlocksPerSecond);
+  const bool good_signal_in_left_or_right =
+      prefer_first_two_channels_ &&
+      (strong_block_counters_[0] > kBlocksToChooseLeftOrRight ||
+       strong_block_counters_[1] > kBlocksToChooseLeftOrRight);
+
+  const int num_ch_to_analyze =
+      good_signal_in_left_or_right ? 2 : num_channels_;
+
+  constexpr int kNumBlocksBeforeEnergySmoothing = 60 * kNumBlocksPerSecond;
+  ++block_counter_;
+
+  for (int ch = 0; ch < num_ch_to_analyze; ++ch) {
+    RTC_DCHECK_EQ(x[ch].size(), kBlockSize);
+    float x2_sum = 0.f;
+    for (size_t i = 0; i < kBlockSize; ++i) {
+      x2_sum += x[ch][i] * x[ch][i];
+    }
+
+    if (ch < 2 && x2_sum > excitation_energy_threshold_) {
+      ++strong_block_counters_[ch];
+    }
+
+    if (block_counter_ <= kNumBlocksBeforeEnergySmoothing) {
+      cumulative_energies_[ch] += x2_sum;
+    } else {
+      constexpr float kSmoothing = 1.f / (10 * kNumBlocksPerSecond);
+      cumulative_energies_[ch] +=
+          kSmoothing * (x2_sum - cumulative_energies_[ch]);
+    }
+  }
+
+  // Normalize the energies to allow the energy computations to from now be
+  // based on smoothing.
+  if (block_counter_ == kNumBlocksBeforeEnergySmoothing) {
+    constexpr float kOneByNumBlocksBeforeEnergySmoothing =
+        1.f / kNumBlocksBeforeEnergySmoothing;
+    for (int ch = 0; ch < num_ch_to_analyze; ++ch) {
+      cumulative_energies_[ch] *= kOneByNumBlocksBeforeEnergySmoothing;
+    }
+  }
+
+  int strongest_ch = 0;
+  for (int ch = 0; ch < num_ch_to_analyze; ++ch) {
+    if (cumulative_energies_[ch] > cumulative_energies_[strongest_ch]) {
+      strongest_ch = ch;
+    }
+  }
+
+  if ((good_signal_in_left_or_right && selected_channel_ > 1) ||
+      cumulative_energies_[strongest_ch] >
+          2.f * cumulative_energies_[selected_channel_]) {
+    selected_channel_ = strongest_ch;
+  }
+
+  return selected_channel_;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/alignment_mixer.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/alignment_mixer.h
new file mode 100644
index 0000000..682aec9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/alignment_mixer.h
@@ -0,0 +1,58 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_ALIGNMENT_MIXER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_ALIGNMENT_MIXER_H_
+
+#include <vector>
+
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+
+namespace webrtc {
+
+// Performs channel conversion to mono for the purpose of providing a decent
+// mono input for the delay estimation. This is achieved by analyzing all
+// incoming channels and produce one single channel output.
+class AlignmentMixer {
+ public:
+  AlignmentMixer(size_t num_channels,
+                 const EchoCanceller3Config::Delay::AlignmentMixing& config);
+
+  AlignmentMixer(size_t num_channels,
+                 bool downmix,
+                 bool adaptive_selection,
+                 float excitation_limit,
+                 bool prefer_first_two_channels);
+
+  void ProduceOutput(rtc::ArrayView<const std::vector<float>> x,
+                     rtc::ArrayView<float, kBlockSize> y);
+
+  enum class MixingVariant { kDownmix, kAdaptive, kFixed };
+
+ private:
+  const size_t num_channels_;
+  const float one_by_num_channels_;
+  const float excitation_energy_threshold_;
+  const bool prefer_first_two_channels_;
+  const MixingVariant selection_variant_;
+  std::array<size_t, 2> strong_block_counters_;
+  std::vector<float> cumulative_energies_;
+  int selected_channel_ = 0;
+  size_t block_counter_ = 0;
+
+  void Downmix(const rtc::ArrayView<const std::vector<float>> x,
+               rtc::ArrayView<float, kBlockSize> y) const;
+  int SelectChannel(rtc::ArrayView<const std::vector<float>> x);
+};
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_ALIGNMENT_MIXER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/alignment_mixer_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/alignment_mixer_unittest.cc
new file mode 100644
index 0000000..03ef066
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/alignment_mixer_unittest.cc
@@ -0,0 +1,196 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/alignment_mixer.h"
+
+#include <string>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gmock.h"
+#include "test/gtest.h"
+
+using ::testing::AllOf;
+using ::testing::Each;
+
+namespace webrtc {
+namespace {
+std::string ProduceDebugText(bool initial_silence,
+                             bool huge_activity_threshold,
+                             bool prefer_first_two_channels,
+                             int num_channels,
+                             int strongest_ch) {
+  rtc::StringBuilder ss;
+  ss << ", Initial silence: " << initial_silence;
+  ss << ", Huge activity threshold: " << huge_activity_threshold;
+  ss << ", Prefer first two channels: " << prefer_first_two_channels;
+  ss << ", Number of channels: " << num_channels;
+  ss << ", Strongest channel: " << strongest_ch;
+  return ss.Release();
+}
+
+}  // namespace
+
+TEST(AlignmentMixer, GeneralAdaptiveMode) {
+  constexpr int kChannelOffset = 100;
+  constexpr int kMaxChannelsToTest = 8;
+  constexpr float kStrongestSignalScaling =
+      kMaxChannelsToTest * kChannelOffset * 100;
+
+  for (bool initial_silence : {false, true}) {
+    for (bool huge_activity_threshold : {false, true}) {
+      for (bool prefer_first_two_channels : {false, true}) {
+        for (int num_channels = 2; num_channels < 8; ++num_channels) {
+          for (int strongest_ch = 0; strongest_ch < num_channels;
+               ++strongest_ch) {
+            SCOPED_TRACE(ProduceDebugText(
+                initial_silence, huge_activity_threshold,
+                prefer_first_two_channels, num_channels, strongest_ch));
+            const float excitation_limit =
+                huge_activity_threshold ? 1000000000.f : 0.001f;
+            AlignmentMixer am(num_channels, /*downmix*/ false,
+                              /*adaptive_selection*/ true, excitation_limit,
+                              prefer_first_two_channels);
+
+            std::vector<std::vector<float>> x(
+                num_channels, std::vector<float>(kBlockSize, 0.f));
+            if (initial_silence) {
+              for (int ch = 0; ch < num_channels; ++ch) {
+                std::fill(x[ch].begin(), x[ch].end(), 0.f);
+              }
+              std::array<float, kBlockSize> y;
+              for (int frame = 0; frame < 10 * kNumBlocksPerSecond; ++frame) {
+                am.ProduceOutput(x, y);
+              }
+            }
+
+            for (int frame = 0; frame < 2 * kNumBlocksPerSecond; ++frame) {
+              const auto channel_value = [&](int frame_index,
+                                             int channel_index) {
+                return static_cast<float>(frame_index +
+                                          channel_index * kChannelOffset);
+              };
+
+              for (int ch = 0; ch < num_channels; ++ch) {
+                float scaling =
+                    ch == strongest_ch ? kStrongestSignalScaling : 1.f;
+                std::fill(x[ch].begin(), x[ch].end(),
+                          channel_value(frame, ch) * scaling);
+              }
+
+              std::array<float, kBlockSize> y;
+              y.fill(-1.f);
+              am.ProduceOutput(x, y);
+
+              if (frame > 1 * kNumBlocksPerSecond) {
+                if (!prefer_first_two_channels || huge_activity_threshold) {
+                  EXPECT_THAT(y, AllOf(Each(x[strongest_ch][0])));
+                } else {
+                  bool left_or_right_chosen;
+                  for (int ch = 0; ch < 2; ++ch) {
+                    left_or_right_chosen = true;
+                    for (size_t k = 0; k < kBlockSize; ++k) {
+                      if (y[k] != x[ch][k]) {
+                        left_or_right_chosen = false;
+                        break;
+                      }
+                    }
+                    if (left_or_right_chosen) {
+                      break;
+                    }
+                  }
+                  EXPECT_TRUE(left_or_right_chosen);
+                }
+              }
+            }
+          }
+        }
+      }
+    }
+  }
+}
+
+TEST(AlignmentMixer, DownmixMode) {
+  for (int num_channels = 1; num_channels < 8; ++num_channels) {
+    AlignmentMixer am(num_channels, /*downmix*/ true,
+                      /*adaptive_selection*/ false, /*excitation_limit*/ 1.f,
+                      /*prefer_first_two_channels*/ false);
+
+    std::vector<std::vector<float>> x(num_channels,
+                                      std::vector<float>(kBlockSize, 0.f));
+    const auto channel_value = [](int frame_index, int channel_index) {
+      return static_cast<float>(frame_index + channel_index);
+    };
+    for (int frame = 0; frame < 10; ++frame) {
+      for (int ch = 0; ch < num_channels; ++ch) {
+        std::fill(x[ch].begin(), x[ch].end(), channel_value(frame, ch));
+      }
+
+      std::array<float, kBlockSize> y;
+      y.fill(-1.f);
+      am.ProduceOutput(x, y);
+
+      float expected_mixed_value = 0.f;
+      for (int ch = 0; ch < num_channels; ++ch) {
+        expected_mixed_value += channel_value(frame, ch);
+      }
+      expected_mixed_value *= 1.f / num_channels;
+
+      EXPECT_THAT(y, AllOf(Each(expected_mixed_value)));
+    }
+  }
+}
+
+TEST(AlignmentMixer, FixedMode) {
+  for (int num_channels = 1; num_channels < 8; ++num_channels) {
+    AlignmentMixer am(num_channels, /*downmix*/ false,
+                      /*adaptive_selection*/ false, /*excitation_limit*/ 1.f,
+                      /*prefer_first_two_channels*/ false);
+
+    std::vector<std::vector<float>> x(num_channels,
+                                      std::vector<float>(kBlockSize, 0.f));
+    const auto channel_value = [](int frame_index, int channel_index) {
+      return static_cast<float>(frame_index + channel_index);
+    };
+    for (int frame = 0; frame < 10; ++frame) {
+      for (int ch = 0; ch < num_channels; ++ch) {
+        std::fill(x[ch].begin(), x[ch].end(), channel_value(frame, ch));
+      }
+
+      std::array<float, kBlockSize> y;
+      y.fill(-1.f);
+      am.ProduceOutput(x, y);
+      EXPECT_THAT(y, AllOf(Each(x[0][0])));
+    }
+  }
+}
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+TEST(AlignmentMixerDeathTest, ZeroNumChannels) {
+  EXPECT_DEATH(
+      AlignmentMixer(/*num_channels*/ 0, /*downmix*/ false,
+                     /*adaptive_selection*/ false, /*excitation_limit*/ 1.f,
+                     /*prefer_first_two_channels*/ false);
+      , "");
+}
+
+TEST(AlignmentMixerDeathTest, IncorrectVariant) {
+  EXPECT_DEATH(
+      AlignmentMixer(/*num_channels*/ 1, /*downmix*/ true,
+                     /*adaptive_selection*/ true, /*excitation_limit*/ 1.f,
+                     /*prefer_first_two_channels*/ false);
+      , "");
+}
+
+#endif
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/api_call_jitter_metrics.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/api_call_jitter_metrics.cc
new file mode 100644
index 0000000..45f56a5
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/api_call_jitter_metrics.cc
@@ -0,0 +1,121 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/api_call_jitter_metrics.h"
+
+#include <algorithm>
+#include <limits>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "system_wrappers/include/metrics.h"
+
+namespace webrtc {
+namespace {
+
+bool TimeToReportMetrics(int frames_since_last_report) {
+  constexpr int kNumFramesPerSecond = 100;
+  constexpr int kReportingIntervalFrames = 10 * kNumFramesPerSecond;
+  return frames_since_last_report == kReportingIntervalFrames;
+}
+
+}  // namespace
+
+ApiCallJitterMetrics::Jitter::Jitter()
+    : max_(0), min_(std::numeric_limits<int>::max()) {}
+
+void ApiCallJitterMetrics::Jitter::Update(int num_api_calls_in_a_row) {
+  min_ = std::min(min_, num_api_calls_in_a_row);
+  max_ = std::max(max_, num_api_calls_in_a_row);
+}
+
+void ApiCallJitterMetrics::Jitter::Reset() {
+  min_ = std::numeric_limits<int>::max();
+  max_ = 0;
+}
+
+void ApiCallJitterMetrics::Reset() {
+  render_jitter_.Reset();
+  capture_jitter_.Reset();
+  num_api_calls_in_a_row_ = 0;
+  frames_since_last_report_ = 0;
+  last_call_was_render_ = false;
+  proper_call_observed_ = false;
+}
+
+void ApiCallJitterMetrics::ReportRenderCall() {
+  if (!last_call_was_render_) {
+    // If the previous call was a capture and a proper call has been observed
+    // (containing both render and capture data), storing the last number of
+    // capture calls into the metrics.
+    if (proper_call_observed_) {
+      capture_jitter_.Update(num_api_calls_in_a_row_);
+    }
+
+    // Reset the call counter to start counting render calls.
+    num_api_calls_in_a_row_ = 0;
+  }
+  ++num_api_calls_in_a_row_;
+  last_call_was_render_ = true;
+}
+
+void ApiCallJitterMetrics::ReportCaptureCall() {
+  if (last_call_was_render_) {
+    // If the previous call was a render and a proper call has been observed
+    // (containing both render and capture data), storing the last number of
+    // render calls into the metrics.
+    if (proper_call_observed_) {
+      render_jitter_.Update(num_api_calls_in_a_row_);
+    }
+    // Reset the call counter to start counting capture calls.
+    num_api_calls_in_a_row_ = 0;
+
+    // If this statement is reached, at least one render and one capture call
+    // have been observed.
+    proper_call_observed_ = true;
+  }
+  ++num_api_calls_in_a_row_;
+  last_call_was_render_ = false;
+
+  // Only report and update jitter metrics for when a proper call, containing
+  // both render and capture data, has been observed.
+  if (proper_call_observed_ &&
+      TimeToReportMetrics(++frames_since_last_report_)) {
+    // Report jitter, where the base basic unit is frames.
+    constexpr int kMaxJitterToReport = 50;
+
+    // Report max and min jitter for render and capture, in units of 20 ms.
+    RTC_HISTOGRAM_COUNTS_LINEAR(
+        "WebRTC.Audio.EchoCanceller.MaxRenderJitter",
+        std::min(kMaxJitterToReport, render_jitter().max()), 1,
+        kMaxJitterToReport, kMaxJitterToReport);
+    RTC_HISTOGRAM_COUNTS_LINEAR(
+        "WebRTC.Audio.EchoCanceller.MinRenderJitter",
+        std::min(kMaxJitterToReport, render_jitter().min()), 1,
+        kMaxJitterToReport, kMaxJitterToReport);
+
+    RTC_HISTOGRAM_COUNTS_LINEAR(
+        "WebRTC.Audio.EchoCanceller.MaxCaptureJitter",
+        std::min(kMaxJitterToReport, capture_jitter().max()), 1,
+        kMaxJitterToReport, kMaxJitterToReport);
+    RTC_HISTOGRAM_COUNTS_LINEAR(
+        "WebRTC.Audio.EchoCanceller.MinCaptureJitter",
+        std::min(kMaxJitterToReport, capture_jitter().min()), 1,
+        kMaxJitterToReport, kMaxJitterToReport);
+
+    frames_since_last_report_ = 0;
+    Reset();
+  }
+}
+
+bool ApiCallJitterMetrics::WillReportMetricsAtNextCapture() const {
+  return TimeToReportMetrics(frames_since_last_report_ + 1);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/api_call_jitter_metrics.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/api_call_jitter_metrics.h
new file mode 100644
index 0000000..dd1fa82
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/api_call_jitter_metrics.h
@@ -0,0 +1,60 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_API_CALL_JITTER_METRICS_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_API_CALL_JITTER_METRICS_H_
+
+namespace webrtc {
+
+// Stores data for reporting metrics on the API call jitter.
+class ApiCallJitterMetrics {
+ public:
+  class Jitter {
+   public:
+    Jitter();
+    void Update(int num_api_calls_in_a_row);
+    void Reset();
+
+    int min() const { return min_; }
+    int max() const { return max_; }
+
+   private:
+    int max_;
+    int min_;
+  };
+
+  ApiCallJitterMetrics() { Reset(); }
+
+  // Update metrics for render API call.
+  void ReportRenderCall();
+
+  // Update and periodically report metrics for capture API call.
+  void ReportCaptureCall();
+
+  // Methods used only for testing.
+  const Jitter& render_jitter() const { return render_jitter_; }
+  const Jitter& capture_jitter() const { return capture_jitter_; }
+  bool WillReportMetricsAtNextCapture() const;
+
+ private:
+  void Reset();
+
+  Jitter render_jitter_;
+  Jitter capture_jitter_;
+
+  int num_api_calls_in_a_row_ = 0;
+  int frames_since_last_report_ = 0;
+  bool last_call_was_render_ = false;
+  bool proper_call_observed_ = false;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_API_CALL_JITTER_METRICS_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/api_call_jitter_metrics_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/api_call_jitter_metrics_unittest.cc
new file mode 100644
index 0000000..b902487
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/api_call_jitter_metrics_unittest.cc
@@ -0,0 +1,109 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/api_call_jitter_metrics.h"
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+// Verify constant jitter.
+TEST(ApiCallJitterMetrics, ConstantJitter) {
+  for (int jitter = 1; jitter < 20; ++jitter) {
+    ApiCallJitterMetrics metrics;
+    for (size_t k = 0; k < 30 * kNumBlocksPerSecond; ++k) {
+      for (int j = 0; j < jitter; ++j) {
+        metrics.ReportRenderCall();
+      }
+
+      for (int j = 0; j < jitter; ++j) {
+        metrics.ReportCaptureCall();
+
+        if (metrics.WillReportMetricsAtNextCapture()) {
+          EXPECT_EQ(jitter, metrics.render_jitter().min());
+          EXPECT_EQ(jitter, metrics.render_jitter().max());
+          EXPECT_EQ(jitter, metrics.capture_jitter().min());
+          EXPECT_EQ(jitter, metrics.capture_jitter().max());
+        }
+      }
+    }
+  }
+}
+
+// Verify peaky jitter for the render.
+TEST(ApiCallJitterMetrics, JitterPeakRender) {
+  constexpr int kMinJitter = 2;
+  constexpr int kJitterPeak = 10;
+  constexpr int kPeakInterval = 100;
+
+  ApiCallJitterMetrics metrics;
+  int render_surplus = 0;
+
+  for (size_t k = 0; k < 30 * kNumBlocksPerSecond; ++k) {
+    const int num_render_calls =
+        k % kPeakInterval == 0 ? kJitterPeak : kMinJitter;
+    for (int j = 0; j < num_render_calls; ++j) {
+      metrics.ReportRenderCall();
+      ++render_surplus;
+    }
+
+    ASSERT_LE(kMinJitter, render_surplus);
+    const int num_capture_calls =
+        render_surplus == kMinJitter ? kMinJitter : kMinJitter + 1;
+    for (int j = 0; j < num_capture_calls; ++j) {
+      metrics.ReportCaptureCall();
+
+      if (metrics.WillReportMetricsAtNextCapture()) {
+        EXPECT_EQ(kMinJitter, metrics.render_jitter().min());
+        EXPECT_EQ(kJitterPeak, metrics.render_jitter().max());
+        EXPECT_EQ(kMinJitter, metrics.capture_jitter().min());
+        EXPECT_EQ(kMinJitter + 1, metrics.capture_jitter().max());
+      }
+      --render_surplus;
+    }
+  }
+}
+
+// Verify peaky jitter for the capture.
+TEST(ApiCallJitterMetrics, JitterPeakCapture) {
+  constexpr int kMinJitter = 2;
+  constexpr int kJitterPeak = 10;
+  constexpr int kPeakInterval = 100;
+
+  ApiCallJitterMetrics metrics;
+  int capture_surplus = kMinJitter;
+
+  for (size_t k = 0; k < 30 * kNumBlocksPerSecond; ++k) {
+    ASSERT_LE(kMinJitter, capture_surplus);
+    const int num_render_calls =
+        capture_surplus == kMinJitter ? kMinJitter : kMinJitter + 1;
+    for (int j = 0; j < num_render_calls; ++j) {
+      metrics.ReportRenderCall();
+      --capture_surplus;
+    }
+
+    const int num_capture_calls =
+        k % kPeakInterval == 0 ? kJitterPeak : kMinJitter;
+    for (int j = 0; j < num_capture_calls; ++j) {
+      metrics.ReportCaptureCall();
+
+      if (metrics.WillReportMetricsAtNextCapture()) {
+        EXPECT_EQ(kMinJitter, metrics.render_jitter().min());
+        EXPECT_EQ(kMinJitter + 1, metrics.render_jitter().max());
+        EXPECT_EQ(kMinJitter, metrics.capture_jitter().min());
+        EXPECT_EQ(kJitterPeak, metrics.capture_jitter().max());
+      }
+      ++capture_surplus;
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_buffer.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_buffer.cc
new file mode 100644
index 0000000..77ce3de
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_buffer.cc
@@ -0,0 +1,39 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/block_buffer.h"
+
+#include <algorithm>
+
+namespace webrtc {
+
+BlockBuffer::BlockBuffer(size_t size,
+                         size_t num_bands,
+                         size_t num_channels,
+                         size_t frame_length)
+    : size(static_cast<int>(size)),
+      buffer(size,
+             std::vector<std::vector<std::vector<float>>>(
+                 num_bands,
+                 std::vector<std::vector<float>>(
+                     num_channels,
+                     std::vector<float>(frame_length, 0.f)))) {
+  for (auto& block : buffer) {
+    for (auto& band : block) {
+      for (auto& channel : band) {
+        std::fill(channel.begin(), channel.end(), 0.f);
+      }
+    }
+  }
+}
+
+BlockBuffer::~BlockBuffer() = default;
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_buffer.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_buffer.h
new file mode 100644
index 0000000..b28d659
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_buffer.h
@@ -0,0 +1,62 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_BLOCK_BUFFER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_BLOCK_BUFFER_H_
+
+#include <stddef.h>
+
+#include <vector>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+// Struct for bundling a circular buffer of two dimensional vector objects
+// together with the read and write indices.
+struct BlockBuffer {
+  BlockBuffer(size_t size,
+              size_t num_bands,
+              size_t num_channels,
+              size_t frame_length);
+  ~BlockBuffer();
+
+  int IncIndex(int index) const {
+    RTC_DCHECK_EQ(buffer.size(), static_cast<size_t>(size));
+    return index < size - 1 ? index + 1 : 0;
+  }
+
+  int DecIndex(int index) const {
+    RTC_DCHECK_EQ(buffer.size(), static_cast<size_t>(size));
+    return index > 0 ? index - 1 : size - 1;
+  }
+
+  int OffsetIndex(int index, int offset) const {
+    RTC_DCHECK_EQ(buffer.size(), static_cast<size_t>(size));
+    RTC_DCHECK_GE(size, offset);
+    return (size + index + offset) % size;
+  }
+
+  void UpdateWriteIndex(int offset) { write = OffsetIndex(write, offset); }
+  void IncWriteIndex() { write = IncIndex(write); }
+  void DecWriteIndex() { write = DecIndex(write); }
+  void UpdateReadIndex(int offset) { read = OffsetIndex(read, offset); }
+  void IncReadIndex() { read = IncIndex(read); }
+  void DecReadIndex() { read = DecIndex(read); }
+
+  const int size;
+  std::vector<std::vector<std::vector<std::vector<float>>>> buffer;
+  int write = 0;
+  int read = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_BLOCK_BUFFER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_delay_buffer.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_delay_buffer.cc
new file mode 100644
index 0000000..b9eb3c9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_delay_buffer.cc
@@ -0,0 +1,62 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "modules/audio_processing/aec3/block_delay_buffer.h"
+
+#include "api/array_view.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+BlockDelayBuffer::BlockDelayBuffer(size_t num_channels,
+                                   size_t num_bands,
+                                   size_t frame_length,
+                                   size_t delay_samples)
+    : frame_length_(frame_length),
+      delay_(delay_samples),
+      buf_(num_channels,
+           std::vector<std::vector<float>>(num_bands,
+                                           std::vector<float>(delay_, 0.f))) {}
+
+BlockDelayBuffer::~BlockDelayBuffer() = default;
+
+void BlockDelayBuffer::DelaySignal(AudioBuffer* frame) {
+  RTC_DCHECK_EQ(buf_.size(), frame->num_channels());
+  if (delay_ == 0) {
+    return;
+  }
+
+  const size_t num_bands = buf_[0].size();
+  const size_t num_channels = buf_.size();
+
+  const size_t i_start = last_insert_;
+  size_t i = 0;
+  for (size_t ch = 0; ch < num_channels; ++ch) {
+    RTC_DCHECK_EQ(buf_[ch].size(), frame->num_bands());
+    RTC_DCHECK_EQ(buf_[ch].size(), num_bands);
+    rtc::ArrayView<float* const> frame_ch(frame->split_bands(ch), num_bands);
+
+    for (size_t band = 0; band < num_bands; ++band) {
+      RTC_DCHECK_EQ(delay_, buf_[ch][band].size());
+      i = i_start;
+
+      for (size_t k = 0; k < frame_length_; ++k) {
+        const float tmp = buf_[ch][band][i];
+        buf_[ch][band][i] = frame_ch[band][k];
+        frame_ch[band][k] = tmp;
+
+        i = i < delay_ - 1 ? i + 1 : 0;
+      }
+    }
+  }
+
+  last_insert_ = i;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_delay_buffer.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_delay_buffer.h
new file mode 100644
index 0000000..711a790
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_delay_buffer.h
@@ -0,0 +1,43 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_BLOCK_DELAY_BUFFER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_BLOCK_DELAY_BUFFER_H_
+
+#include <stddef.h>
+
+#include <vector>
+
+#include "modules/audio_processing/audio_buffer.h"
+
+namespace webrtc {
+
+// Class for applying a fixed delay to the samples in a signal partitioned using
+// the audiobuffer band-splitting scheme.
+class BlockDelayBuffer {
+ public:
+  BlockDelayBuffer(size_t num_channels,
+                   size_t num_bands,
+                   size_t frame_length,
+                   size_t delay_samples);
+  ~BlockDelayBuffer();
+
+  // Delays the samples by the specified delay.
+  void DelaySignal(AudioBuffer* frame);
+
+ private:
+  const size_t frame_length_;
+  const size_t delay_;
+  std::vector<std::vector<std::vector<float>>> buf_;
+  size_t last_insert_ = 0;
+};
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_BLOCK_DELAY_BUFFER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_delay_buffer_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_delay_buffer_unittest.cc
new file mode 100644
index 0000000..011ab49
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_delay_buffer_unittest.cc
@@ -0,0 +1,105 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/block_delay_buffer.h"
+
+#include <string>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/audio_buffer.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+namespace {
+
+float SampleValue(size_t sample_index) {
+  return sample_index % 32768;
+}
+
+// Populates the frame with linearly increasing sample values for each band.
+void PopulateInputFrame(size_t frame_length,
+                        size_t num_bands,
+                        size_t first_sample_index,
+                        float* const* frame) {
+  for (size_t k = 0; k < num_bands; ++k) {
+    for (size_t i = 0; i < frame_length; ++i) {
+      frame[k][i] = SampleValue(first_sample_index + i);
+    }
+  }
+}
+
+std::string ProduceDebugText(int sample_rate_hz, size_t delay) {
+  char log_stream_buffer[8 * 1024];
+  rtc::SimpleStringBuilder ss(log_stream_buffer);
+  ss << "Sample rate: " << sample_rate_hz;
+  ss << ", Delay: " << delay;
+  return ss.str();
+}
+
+}  // namespace
+
+class BlockDelayBufferTest
+    : public ::testing::Test,
+      public ::testing::WithParamInterface<std::tuple<size_t, int, size_t>> {};
+
+INSTANTIATE_TEST_SUITE_P(
+    ParameterCombinations,
+    BlockDelayBufferTest,
+    ::testing::Combine(::testing::Values(0, 1, 27, 160, 4321, 7021),
+                       ::testing::Values(16000, 32000, 48000),
+                       ::testing::Values(1, 2, 4)));
+
+// Verifies that the correct signal delay is achived.
+TEST_P(BlockDelayBufferTest, CorrectDelayApplied) {
+  const size_t delay = std::get<0>(GetParam());
+  const int rate = std::get<1>(GetParam());
+  const size_t num_channels = std::get<2>(GetParam());
+
+  SCOPED_TRACE(ProduceDebugText(rate, delay));
+  size_t num_bands = NumBandsForRate(rate);
+  size_t subband_frame_length = 160;
+
+  BlockDelayBuffer delay_buffer(num_channels, num_bands, subband_frame_length,
+                                delay);
+
+  static constexpr size_t kNumFramesToProcess = 20;
+  for (size_t frame_index = 0; frame_index < kNumFramesToProcess;
+       ++frame_index) {
+    AudioBuffer audio_buffer(rate, num_channels, rate, num_channels, rate,
+                             num_channels);
+    if (rate > 16000) {
+      audio_buffer.SplitIntoFrequencyBands();
+    }
+    size_t first_sample_index = frame_index * subband_frame_length;
+    for (size_t ch = 0; ch < num_channels; ++ch) {
+      PopulateInputFrame(subband_frame_length, num_bands, first_sample_index,
+                         &audio_buffer.split_bands(ch)[0]);
+    }
+    delay_buffer.DelaySignal(&audio_buffer);
+
+    for (size_t ch = 0; ch < num_channels; ++ch) {
+      for (size_t band = 0; band < num_bands; ++band) {
+        size_t sample_index = first_sample_index;
+        for (size_t i = 0; i < subband_frame_length; ++i, ++sample_index) {
+          if (sample_index < delay) {
+            EXPECT_EQ(0.f, audio_buffer.split_bands(ch)[band][i]);
+          } else {
+            EXPECT_EQ(SampleValue(sample_index - delay),
+                      audio_buffer.split_bands(ch)[band][i]);
+          }
+        }
+      }
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_framer.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_framer.cc
new file mode 100644
index 0000000..8241ce6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_framer.cc
@@ -0,0 +1,86 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/block_framer.h"
+
+#include <algorithm>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+BlockFramer::BlockFramer(size_t num_bands, size_t num_channels)
+    : num_bands_(num_bands),
+      num_channels_(num_channels),
+      buffer_(num_bands_,
+              std::vector<std::vector<float>>(
+                  num_channels,
+                  std::vector<float>(kBlockSize, 0.f))) {
+  RTC_DCHECK_LT(0, num_bands);
+  RTC_DCHECK_LT(0, num_channels);
+}
+
+BlockFramer::~BlockFramer() = default;
+
+// All the constants are chosen so that the buffer is either empty or has enough
+// samples for InsertBlockAndExtractSubFrame to produce a frame. In order to
+// achieve this, the InsertBlockAndExtractSubFrame and InsertBlock methods need
+// to be called in the correct order.
+void BlockFramer::InsertBlock(
+    const std::vector<std::vector<std::vector<float>>>& block) {
+  RTC_DCHECK_EQ(num_bands_, block.size());
+  for (size_t band = 0; band < num_bands_; ++band) {
+    RTC_DCHECK_EQ(num_channels_, block[band].size());
+    for (size_t channel = 0; channel < num_channels_; ++channel) {
+      RTC_DCHECK_EQ(kBlockSize, block[band][channel].size());
+      RTC_DCHECK_EQ(0, buffer_[band][channel].size());
+
+      buffer_[band][channel].insert(buffer_[band][channel].begin(),
+                                    block[band][channel].begin(),
+                                    block[band][channel].end());
+    }
+  }
+}
+
+void BlockFramer::InsertBlockAndExtractSubFrame(
+    const std::vector<std::vector<std::vector<float>>>& block,
+    std::vector<std::vector<rtc::ArrayView<float>>>* sub_frame) {
+  RTC_DCHECK(sub_frame);
+  RTC_DCHECK_EQ(num_bands_, block.size());
+  RTC_DCHECK_EQ(num_bands_, sub_frame->size());
+  for (size_t band = 0; band < num_bands_; ++band) {
+    RTC_DCHECK_EQ(num_channels_, block[band].size());
+    RTC_DCHECK_EQ(num_channels_, (*sub_frame)[0].size());
+    for (size_t channel = 0; channel < num_channels_; ++channel) {
+      RTC_DCHECK_LE(kSubFrameLength,
+                    buffer_[band][channel].size() + kBlockSize);
+      RTC_DCHECK_EQ(kBlockSize, block[band][channel].size());
+      RTC_DCHECK_GE(kBlockSize, buffer_[band][channel].size());
+      RTC_DCHECK_EQ(kSubFrameLength, (*sub_frame)[band][channel].size());
+
+      const int samples_to_frame =
+          kSubFrameLength - buffer_[band][channel].size();
+      std::copy(buffer_[band][channel].begin(), buffer_[band][channel].end(),
+                (*sub_frame)[band][channel].begin());
+      std::copy(
+          block[band][channel].begin(),
+          block[band][channel].begin() + samples_to_frame,
+          (*sub_frame)[band][channel].begin() + buffer_[band][channel].size());
+      buffer_[band][channel].clear();
+      buffer_[band][channel].insert(
+          buffer_[band][channel].begin(),
+          block[band][channel].begin() + samples_to_frame,
+          block[band][channel].end());
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_framer.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_framer.h
new file mode 100644
index 0000000..1d37866
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_framer.h
@@ -0,0 +1,48 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_BLOCK_FRAMER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_BLOCK_FRAMER_H_
+
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+
+namespace webrtc {
+
+// Class for producing frames consisting of 2 subframes of 80 samples each
+// from 64 sample blocks. The class is designed to work together with the
+// FrameBlocker class which performs the reverse conversion. Used together with
+// that, this class produces output frames are the same rate as frames are
+// received by the FrameBlocker class. Note that the internal buffers will
+// overrun if any other rate of packets insertion is used.
+class BlockFramer {
+ public:
+  BlockFramer(size_t num_bands, size_t num_channels);
+  ~BlockFramer();
+  BlockFramer(const BlockFramer&) = delete;
+  BlockFramer& operator=(const BlockFramer&) = delete;
+
+  // Adds a 64 sample block into the data that will form the next output frame.
+  void InsertBlock(const std::vector<std::vector<std::vector<float>>>& block);
+  // Adds a 64 sample block and extracts an 80 sample subframe.
+  void InsertBlockAndExtractSubFrame(
+      const std::vector<std::vector<std::vector<float>>>& block,
+      std::vector<std::vector<rtc::ArrayView<float>>>* sub_frame);
+
+ private:
+  const size_t num_bands_;
+  const size_t num_channels_;
+  std::vector<std::vector<std::vector<float>>> buffer_;
+};
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_BLOCK_FRAMER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_framer_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_framer_unittest.cc
new file mode 100644
index 0000000..d67967b
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_framer_unittest.cc
@@ -0,0 +1,386 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/block_framer.h"
+
+#include <string>
+#include <vector>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace {
+
+void SetupSubFrameView(
+    std::vector<std::vector<std::vector<float>>>* sub_frame,
+    std::vector<std::vector<rtc::ArrayView<float>>>* sub_frame_view) {
+  for (size_t band = 0; band < sub_frame_view->size(); ++band) {
+    for (size_t channel = 0; channel < (*sub_frame_view)[band].size();
+         ++channel) {
+      (*sub_frame_view)[band][channel] =
+          rtc::ArrayView<float>((*sub_frame)[band][channel].data(),
+                                (*sub_frame)[band][channel].size());
+    }
+  }
+}
+
+float ComputeSampleValue(size_t chunk_counter,
+                         size_t chunk_size,
+                         size_t band,
+                         size_t channel,
+                         size_t sample_index,
+                         int offset) {
+  float value = static_cast<int>(100 + chunk_counter * chunk_size +
+                                 sample_index + channel) +
+                offset;
+  return 5000 * band + value;
+}
+
+bool VerifySubFrame(
+    size_t sub_frame_counter,
+    int offset,
+    const std::vector<std::vector<rtc::ArrayView<float>>>& sub_frame_view) {
+  for (size_t band = 0; band < sub_frame_view.size(); ++band) {
+    for (size_t channel = 0; channel < sub_frame_view[band].size(); ++channel) {
+      for (size_t sample = 0; sample < sub_frame_view[band][channel].size();
+           ++sample) {
+        const float reference_value = ComputeSampleValue(
+            sub_frame_counter, kSubFrameLength, band, channel, sample, offset);
+        if (reference_value != sub_frame_view[band][channel][sample]) {
+          return false;
+        }
+      }
+    }
+  }
+  return true;
+}
+
+void FillBlock(size_t block_counter,
+               std::vector<std::vector<std::vector<float>>>* block) {
+  for (size_t band = 0; band < block->size(); ++band) {
+    for (size_t channel = 0; channel < (*block)[band].size(); ++channel) {
+      for (size_t sample = 0; sample < (*block)[band][channel].size();
+           ++sample) {
+        (*block)[band][channel][sample] = ComputeSampleValue(
+            block_counter, kBlockSize, band, channel, sample, 0);
+      }
+    }
+  }
+}
+
+// Verifies that the BlockFramer is able to produce the expected frame content.
+void RunFramerTest(int sample_rate_hz, size_t num_channels) {
+  constexpr size_t kNumSubFramesToProcess = 10;
+  const size_t num_bands = NumBandsForRate(sample_rate_hz);
+
+  std::vector<std::vector<std::vector<float>>> block(
+      num_bands, std::vector<std::vector<float>>(
+                     num_channels, std::vector<float>(kBlockSize, 0.f)));
+  std::vector<std::vector<std::vector<float>>> output_sub_frame(
+      num_bands, std::vector<std::vector<float>>(
+                     num_channels, std::vector<float>(kSubFrameLength, 0.f)));
+  std::vector<std::vector<rtc::ArrayView<float>>> output_sub_frame_view(
+      num_bands, std::vector<rtc::ArrayView<float>>(num_channels));
+  SetupSubFrameView(&output_sub_frame, &output_sub_frame_view);
+  BlockFramer framer(num_bands, num_channels);
+
+  size_t block_index = 0;
+  for (size_t sub_frame_index = 0; sub_frame_index < kNumSubFramesToProcess;
+       ++sub_frame_index) {
+    FillBlock(block_index++, &block);
+    framer.InsertBlockAndExtractSubFrame(block, &output_sub_frame_view);
+    if (sub_frame_index > 1) {
+      EXPECT_TRUE(VerifySubFrame(sub_frame_index, -64, output_sub_frame_view));
+    }
+
+    if ((sub_frame_index + 1) % 4 == 0) {
+      FillBlock(block_index++, &block);
+      framer.InsertBlock(block);
+    }
+  }
+}
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+// Verifies that the BlockFramer crashes if the InsertBlockAndExtractSubFrame
+// method is called for inputs with the wrong number of bands or band lengths.
+void RunWronglySizedInsertAndExtractParametersTest(
+    int sample_rate_hz,
+    size_t correct_num_channels,
+    size_t num_block_bands,
+    size_t num_block_channels,
+    size_t block_length,
+    size_t num_sub_frame_bands,
+    size_t num_sub_frame_channels,
+    size_t sub_frame_length) {
+  const size_t correct_num_bands = NumBandsForRate(sample_rate_hz);
+
+  std::vector<std::vector<std::vector<float>>> block(
+      num_block_bands,
+      std::vector<std::vector<float>>(num_block_channels,
+                                      std::vector<float>(block_length, 0.f)));
+  std::vector<std::vector<std::vector<float>>> output_sub_frame(
+      num_sub_frame_bands,
+      std::vector<std::vector<float>>(
+          num_sub_frame_channels, std::vector<float>(sub_frame_length, 0.f)));
+  std::vector<std::vector<rtc::ArrayView<float>>> output_sub_frame_view(
+      output_sub_frame.size(),
+      std::vector<rtc::ArrayView<float>>(num_sub_frame_channels));
+  SetupSubFrameView(&output_sub_frame, &output_sub_frame_view);
+  BlockFramer framer(correct_num_bands, correct_num_channels);
+  EXPECT_DEATH(
+      framer.InsertBlockAndExtractSubFrame(block, &output_sub_frame_view), "");
+}
+
+// Verifies that the BlockFramer crashes if the InsertBlock method is called for
+// inputs with the wrong number of bands or band lengths.
+void RunWronglySizedInsertParameterTest(int sample_rate_hz,
+                                        size_t correct_num_channels,
+                                        size_t num_block_bands,
+                                        size_t num_block_channels,
+                                        size_t block_length) {
+  const size_t correct_num_bands = NumBandsForRate(sample_rate_hz);
+
+  std::vector<std::vector<std::vector<float>>> correct_block(
+      correct_num_bands,
+      std::vector<std::vector<float>>(correct_num_channels,
+                                      std::vector<float>(kBlockSize, 0.f)));
+  std::vector<std::vector<std::vector<float>>> wrong_block(
+      num_block_bands,
+      std::vector<std::vector<float>>(num_block_channels,
+                                      std::vector<float>(block_length, 0.f)));
+  std::vector<std::vector<std::vector<float>>> output_sub_frame(
+      correct_num_bands,
+      std::vector<std::vector<float>>(
+          correct_num_channels, std::vector<float>(kSubFrameLength, 0.f)));
+  std::vector<std::vector<rtc::ArrayView<float>>> output_sub_frame_view(
+      output_sub_frame.size(),
+      std::vector<rtc::ArrayView<float>>(correct_num_channels));
+  SetupSubFrameView(&output_sub_frame, &output_sub_frame_view);
+  BlockFramer framer(correct_num_bands, correct_num_channels);
+  framer.InsertBlockAndExtractSubFrame(correct_block, &output_sub_frame_view);
+  framer.InsertBlockAndExtractSubFrame(correct_block, &output_sub_frame_view);
+  framer.InsertBlockAndExtractSubFrame(correct_block, &output_sub_frame_view);
+  framer.InsertBlockAndExtractSubFrame(correct_block, &output_sub_frame_view);
+
+  EXPECT_DEATH(framer.InsertBlock(wrong_block), "");
+}
+
+// Verifies that the BlockFramer crashes if the InsertBlock method is called
+// after a wrong number of previous InsertBlockAndExtractSubFrame method calls
+// have been made.
+
+void RunWronglyInsertOrderTest(int sample_rate_hz,
+                               size_t num_channels,
+                               size_t num_preceeding_api_calls) {
+  const size_t correct_num_bands = NumBandsForRate(sample_rate_hz);
+
+  std::vector<std::vector<std::vector<float>>> block(
+      correct_num_bands,
+      std::vector<std::vector<float>>(num_channels,
+                                      std::vector<float>(kBlockSize, 0.f)));
+  std::vector<std::vector<std::vector<float>>> output_sub_frame(
+      correct_num_bands,
+      std::vector<std::vector<float>>(
+          num_channels, std::vector<float>(kSubFrameLength, 0.f)));
+  std::vector<std::vector<rtc::ArrayView<float>>> output_sub_frame_view(
+      output_sub_frame.size(),
+      std::vector<rtc::ArrayView<float>>(num_channels));
+  SetupSubFrameView(&output_sub_frame, &output_sub_frame_view);
+  BlockFramer framer(correct_num_bands, num_channels);
+  for (size_t k = 0; k < num_preceeding_api_calls; ++k) {
+    framer.InsertBlockAndExtractSubFrame(block, &output_sub_frame_view);
+  }
+
+  EXPECT_DEATH(framer.InsertBlock(block), "");
+}
+#endif
+
+std::string ProduceDebugText(int sample_rate_hz, size_t num_channels) {
+  rtc::StringBuilder ss;
+  ss << "Sample rate: " << sample_rate_hz;
+  ss << ", number of channels: " << num_channels;
+  return ss.Release();
+}
+
+}  // namespace
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+TEST(BlockFramerDeathTest,
+     WrongNumberOfBandsInBlockForInsertBlockAndExtractSubFrame) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (auto correct_num_channels : {1, 2, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+      const size_t correct_num_bands = NumBandsForRate(rate);
+      const size_t wrong_num_bands = (correct_num_bands % 3) + 1;
+      RunWronglySizedInsertAndExtractParametersTest(
+          rate, correct_num_channels, wrong_num_bands, correct_num_channels,
+          kBlockSize, correct_num_bands, correct_num_channels, kSubFrameLength);
+    }
+  }
+}
+
+TEST(BlockFramerDeathTest,
+     WrongNumberOfChannelsInBlockForInsertBlockAndExtractSubFrame) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (auto correct_num_channels : {1, 2, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+      const size_t correct_num_bands = NumBandsForRate(rate);
+      const size_t wrong_num_channels = correct_num_channels + 1;
+      RunWronglySizedInsertAndExtractParametersTest(
+          rate, correct_num_channels, correct_num_bands, wrong_num_channels,
+          kBlockSize, correct_num_bands, correct_num_channels, kSubFrameLength);
+    }
+  }
+}
+
+TEST(BlockFramerDeathTest,
+     WrongNumberOfBandsInSubFrameForInsertBlockAndExtractSubFrame) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (auto correct_num_channels : {1, 2, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+      const size_t correct_num_bands = NumBandsForRate(rate);
+      const size_t wrong_num_bands = (correct_num_bands % 3) + 1;
+      RunWronglySizedInsertAndExtractParametersTest(
+          rate, correct_num_channels, correct_num_bands, correct_num_channels,
+          kBlockSize, wrong_num_bands, correct_num_channels, kSubFrameLength);
+    }
+  }
+}
+
+TEST(BlockFramerDeathTest,
+     WrongNumberOfChannelsInSubFrameForInsertBlockAndExtractSubFrame) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (auto correct_num_channels : {1, 2, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+      const size_t correct_num_bands = NumBandsForRate(rate);
+      const size_t wrong_num_channels = correct_num_channels + 1;
+      RunWronglySizedInsertAndExtractParametersTest(
+          rate, correct_num_channels, correct_num_bands, correct_num_channels,
+          kBlockSize, correct_num_bands, wrong_num_channels, kSubFrameLength);
+    }
+  }
+}
+
+TEST(BlockFramerDeathTest,
+     WrongNumberOfSamplesInBlockForInsertBlockAndExtractSubFrame) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (auto correct_num_channels : {1, 2, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+      const size_t correct_num_bands = NumBandsForRate(rate);
+      RunWronglySizedInsertAndExtractParametersTest(
+          rate, correct_num_channels, correct_num_bands, correct_num_channels,
+          kBlockSize - 1, correct_num_bands, correct_num_channels,
+          kSubFrameLength);
+    }
+  }
+}
+
+TEST(BlockFramerDeathTest,
+     WrongNumberOfSamplesInSubFrameForInsertBlockAndExtractSubFrame) {
+  const size_t correct_num_channels = 1;
+  for (auto rate : {16000, 32000, 48000}) {
+    SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+    const size_t correct_num_bands = NumBandsForRate(rate);
+    RunWronglySizedInsertAndExtractParametersTest(
+        rate, correct_num_channels, correct_num_bands, correct_num_channels,
+        kBlockSize, correct_num_bands, correct_num_channels,
+        kSubFrameLength - 1);
+  }
+}
+
+TEST(BlockFramerDeathTest, WrongNumberOfBandsInBlockForInsertBlock) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (auto correct_num_channels : {1, 2, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+      const size_t correct_num_bands = NumBandsForRate(rate);
+      const size_t wrong_num_bands = (correct_num_bands % 3) + 1;
+      RunWronglySizedInsertParameterTest(rate, correct_num_channels,
+                                         wrong_num_bands, correct_num_channels,
+                                         kBlockSize);
+    }
+  }
+}
+
+TEST(BlockFramerDeathTest, WrongNumberOfChannelsInBlockForInsertBlock) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (auto correct_num_channels : {1, 2, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+      const size_t correct_num_bands = NumBandsForRate(rate);
+      const size_t wrong_num_channels = correct_num_channels + 1;
+      RunWronglySizedInsertParameterTest(rate, correct_num_channels,
+                                         correct_num_bands, wrong_num_channels,
+                                         kBlockSize);
+    }
+  }
+}
+
+TEST(BlockFramerDeathTest, WrongNumberOfSamplesInBlockForInsertBlock) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (auto correct_num_channels : {1, 2, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+      const size_t correct_num_bands = NumBandsForRate(rate);
+      RunWronglySizedInsertParameterTest(rate, correct_num_channels,
+                                         correct_num_bands,
+                                         correct_num_channels, kBlockSize - 1);
+    }
+  }
+}
+
+TEST(BlockFramerDeathTest, WrongNumberOfPreceedingApiCallsForInsertBlock) {
+  for (size_t num_channels : {1, 2, 8}) {
+    for (auto rate : {16000, 32000, 48000}) {
+      for (size_t num_calls = 0; num_calls < 4; ++num_calls) {
+        rtc::StringBuilder ss;
+        ss << "Sample rate: " << rate;
+        ss << ", Num channels: " << num_channels;
+        ss << ", Num preceeding InsertBlockAndExtractSubFrame calls: "
+           << num_calls;
+
+        SCOPED_TRACE(ss.str());
+        RunWronglyInsertOrderTest(rate, num_channels, num_calls);
+      }
+    }
+  }
+}
+
+// Verifies that the verification for 0 number of channels works.
+TEST(BlockFramerDeathTest, ZeroNumberOfChannelsParameter) {
+  EXPECT_DEATH(BlockFramer(16000, 0), "");
+}
+
+// Verifies that the verification for 0 number of bands works.
+TEST(BlockFramerDeathTest, ZeroNumberOfBandsParameter) {
+  EXPECT_DEATH(BlockFramer(0, 1), "");
+}
+
+// Verifies that the verification for null sub_frame pointer works.
+TEST(BlockFramerDeathTest, NullSubFrameParameter) {
+  EXPECT_DEATH(BlockFramer(1, 1).InsertBlockAndExtractSubFrame(
+                   std::vector<std::vector<std::vector<float>>>(
+                       1, std::vector<std::vector<float>>(
+                              1, std::vector<float>(kBlockSize, 0.f))),
+                   nullptr),
+               "");
+}
+
+#endif
+
+TEST(BlockFramer, FrameBitexactness) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (auto num_channels : {1, 2, 4, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, num_channels));
+      RunFramerTest(rate, num_channels);
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor.cc
new file mode 100644
index 0000000..2ee32b8
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor.cc
@@ -0,0 +1,297 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "modules/audio_processing/aec3/block_processor.h"
+
+#include <stddef.h>
+
+#include <memory>
+#include <utility>
+#include <vector>
+
+#include "absl/types/optional.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "api/audio/echo_control.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/block_processor_metrics.h"
+#include "modules/audio_processing/aec3/delay_estimate.h"
+#include "modules/audio_processing/aec3/echo_path_variability.h"
+#include "modules/audio_processing/aec3/echo_remover.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "modules/audio_processing/aec3/render_delay_controller.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/atomic_ops.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+
+namespace webrtc {
+namespace {
+
+enum class BlockProcessorApiCall { kCapture, kRender };
+
+class BlockProcessorImpl final : public BlockProcessor {
+ public:
+  BlockProcessorImpl(const EchoCanceller3Config& config,
+                     int sample_rate_hz,
+                     size_t num_render_channels,
+                     size_t num_capture_channels,
+                     std::unique_ptr<RenderDelayBuffer> render_buffer,
+                     std::unique_ptr<RenderDelayController> delay_controller,
+                     std::unique_ptr<EchoRemover> echo_remover);
+
+  BlockProcessorImpl() = delete;
+
+  ~BlockProcessorImpl() override;
+
+  void ProcessCapture(
+      bool echo_path_gain_change,
+      bool capture_signal_saturation,
+      std::vector<std::vector<std::vector<float>>>* linear_output,
+      std::vector<std::vector<std::vector<float>>>* capture_block) override;
+
+  void BufferRender(
+      const std::vector<std::vector<std::vector<float>>>& block) override;
+
+  void UpdateEchoLeakageStatus(bool leakage_detected) override;
+
+  void GetMetrics(EchoControl::Metrics* metrics) const override;
+
+  void SetAudioBufferDelay(int delay_ms) override;
+  void SetCaptureOutputUsage(bool capture_output_used) override;
+
+ private:
+  static int instance_count_;
+  std::unique_ptr<ApmDataDumper> data_dumper_;
+  const EchoCanceller3Config config_;
+  bool capture_properly_started_ = false;
+  bool render_properly_started_ = false;
+  const size_t sample_rate_hz_;
+  std::unique_ptr<RenderDelayBuffer> render_buffer_;
+  std::unique_ptr<RenderDelayController> delay_controller_;
+  std::unique_ptr<EchoRemover> echo_remover_;
+  BlockProcessorMetrics metrics_;
+  RenderDelayBuffer::BufferingEvent render_event_;
+  size_t capture_call_counter_ = 0;
+  absl::optional<DelayEstimate> estimated_delay_;
+};
+
+int BlockProcessorImpl::instance_count_ = 0;
+
+BlockProcessorImpl::BlockProcessorImpl(
+    const EchoCanceller3Config& config,
+    int sample_rate_hz,
+    size_t num_render_channels,
+    size_t num_capture_channels,
+    std::unique_ptr<RenderDelayBuffer> render_buffer,
+    std::unique_ptr<RenderDelayController> delay_controller,
+    std::unique_ptr<EchoRemover> echo_remover)
+    : data_dumper_(
+          new ApmDataDumper(rtc::AtomicOps::Increment(&instance_count_))),
+      config_(config),
+      sample_rate_hz_(sample_rate_hz),
+      render_buffer_(std::move(render_buffer)),
+      delay_controller_(std::move(delay_controller)),
+      echo_remover_(std::move(echo_remover)),
+      render_event_(RenderDelayBuffer::BufferingEvent::kNone) {
+  RTC_DCHECK(ValidFullBandRate(sample_rate_hz_));
+}
+
+BlockProcessorImpl::~BlockProcessorImpl() = default;
+
+void BlockProcessorImpl::ProcessCapture(
+    bool echo_path_gain_change,
+    bool capture_signal_saturation,
+    std::vector<std::vector<std::vector<float>>>* linear_output,
+    std::vector<std::vector<std::vector<float>>>* capture_block) {
+  RTC_DCHECK(capture_block);
+  RTC_DCHECK_EQ(NumBandsForRate(sample_rate_hz_), capture_block->size());
+  RTC_DCHECK_EQ(kBlockSize, (*capture_block)[0][0].size());
+
+  capture_call_counter_++;
+
+  data_dumper_->DumpRaw("aec3_processblock_call_order",
+                        static_cast<int>(BlockProcessorApiCall::kCapture));
+  data_dumper_->DumpWav("aec3_processblock_capture_input", kBlockSize,
+                        &(*capture_block)[0][0][0], 16000, 1);
+
+  if (render_properly_started_) {
+    if (!capture_properly_started_) {
+      capture_properly_started_ = true;
+      render_buffer_->Reset();
+      if (delay_controller_)
+        delay_controller_->Reset(true);
+    }
+  } else {
+    // If no render data has yet arrived, do not process the capture signal.
+    render_buffer_->HandleSkippedCaptureProcessing();
+    return;
+  }
+
+  EchoPathVariability echo_path_variability(
+      echo_path_gain_change, EchoPathVariability::DelayAdjustment::kNone,
+      false);
+
+  if (render_event_ == RenderDelayBuffer::BufferingEvent::kRenderOverrun &&
+      render_properly_started_) {
+    echo_path_variability.delay_change =
+        EchoPathVariability::DelayAdjustment::kBufferFlush;
+    if (delay_controller_)
+      delay_controller_->Reset(true);
+    RTC_LOG(LS_WARNING) << "Reset due to render buffer overrun at block  "
+                        << capture_call_counter_;
+  }
+  render_event_ = RenderDelayBuffer::BufferingEvent::kNone;
+
+  // Update the render buffers with any newly arrived render blocks and prepare
+  // the render buffers for reading the render data corresponding to the current
+  // capture block.
+  RenderDelayBuffer::BufferingEvent buffer_event =
+      render_buffer_->PrepareCaptureProcessing();
+  // Reset the delay controller at render buffer underrun.
+  if (buffer_event == RenderDelayBuffer::BufferingEvent::kRenderUnderrun) {
+    if (delay_controller_)
+      delay_controller_->Reset(false);
+  }
+
+  data_dumper_->DumpWav("aec3_processblock_capture_input2", kBlockSize,
+                        &(*capture_block)[0][0][0], 16000, 1);
+
+  bool has_delay_estimator = !config_.delay.use_external_delay_estimator;
+  if (has_delay_estimator) {
+    RTC_DCHECK(delay_controller_);
+    // Compute and apply the render delay required to achieve proper signal
+    // alignment.
+    estimated_delay_ = delay_controller_->GetDelay(
+        render_buffer_->GetDownsampledRenderBuffer(), render_buffer_->Delay(),
+        (*capture_block)[0]);
+
+    if (estimated_delay_) {
+      bool delay_change =
+          render_buffer_->AlignFromDelay(estimated_delay_->delay);
+      if (delay_change) {
+        rtc::LoggingSeverity log_level =
+            config_.delay.log_warning_on_delay_changes ? rtc::LS_WARNING
+                                                       : rtc::LS_INFO;
+        RTC_LOG_V(log_level) << "Delay changed to " << estimated_delay_->delay
+                             << " at block " << capture_call_counter_;
+        echo_path_variability.delay_change =
+            EchoPathVariability::DelayAdjustment::kNewDetectedDelay;
+      }
+    }
+
+    echo_path_variability.clock_drift = delay_controller_->HasClockdrift();
+
+  } else {
+    render_buffer_->AlignFromExternalDelay();
+  }
+
+  // Remove the echo from the capture signal.
+  if (has_delay_estimator || render_buffer_->HasReceivedBufferDelay()) {
+    echo_remover_->ProcessCapture(
+        echo_path_variability, capture_signal_saturation, estimated_delay_,
+        render_buffer_->GetRenderBuffer(), linear_output, capture_block);
+  }
+
+  // Update the metrics.
+  metrics_.UpdateCapture(false);
+}
+
+void BlockProcessorImpl::BufferRender(
+    const std::vector<std::vector<std::vector<float>>>& block) {
+  RTC_DCHECK_EQ(NumBandsForRate(sample_rate_hz_), block.size());
+  RTC_DCHECK_EQ(kBlockSize, block[0][0].size());
+  data_dumper_->DumpRaw("aec3_processblock_call_order",
+                        static_cast<int>(BlockProcessorApiCall::kRender));
+  data_dumper_->DumpWav("aec3_processblock_render_input", kBlockSize,
+                        &block[0][0][0], 16000, 1);
+  data_dumper_->DumpWav("aec3_processblock_render_input2", kBlockSize,
+                        &block[0][0][0], 16000, 1);
+
+  render_event_ = render_buffer_->Insert(block);
+
+  metrics_.UpdateRender(render_event_ !=
+                        RenderDelayBuffer::BufferingEvent::kNone);
+
+  render_properly_started_ = true;
+  if (delay_controller_)
+    delay_controller_->LogRenderCall();
+}
+
+void BlockProcessorImpl::UpdateEchoLeakageStatus(bool leakage_detected) {
+  echo_remover_->UpdateEchoLeakageStatus(leakage_detected);
+}
+
+void BlockProcessorImpl::GetMetrics(EchoControl::Metrics* metrics) const {
+  echo_remover_->GetMetrics(metrics);
+  constexpr int block_size_ms = 4;
+  absl::optional<size_t> delay = render_buffer_->Delay();
+  metrics->delay_ms = delay ? static_cast<int>(*delay) * block_size_ms : 0;
+}
+
+void BlockProcessorImpl::SetAudioBufferDelay(int delay_ms) {
+  render_buffer_->SetAudioBufferDelay(delay_ms);
+}
+
+void BlockProcessorImpl::SetCaptureOutputUsage(bool capture_output_used) {
+  echo_remover_->SetCaptureOutputUsage(capture_output_used);
+}
+
+}  // namespace
+
+BlockProcessor* BlockProcessor::Create(const EchoCanceller3Config& config,
+                                       int sample_rate_hz,
+                                       size_t num_render_channels,
+                                       size_t num_capture_channels) {
+  std::unique_ptr<RenderDelayBuffer> render_buffer(
+      RenderDelayBuffer::Create(config, sample_rate_hz, num_render_channels));
+  std::unique_ptr<RenderDelayController> delay_controller;
+  if (!config.delay.use_external_delay_estimator) {
+    delay_controller.reset(RenderDelayController::Create(config, sample_rate_hz,
+                                                         num_capture_channels));
+  }
+  std::unique_ptr<EchoRemover> echo_remover(EchoRemover::Create(
+      config, sample_rate_hz, num_render_channels, num_capture_channels));
+  return Create(config, sample_rate_hz, num_render_channels,
+                num_capture_channels, std::move(render_buffer),
+                std::move(delay_controller), std::move(echo_remover));
+}
+
+BlockProcessor* BlockProcessor::Create(
+    const EchoCanceller3Config& config,
+    int sample_rate_hz,
+    size_t num_render_channels,
+    size_t num_capture_channels,
+    std::unique_ptr<RenderDelayBuffer> render_buffer) {
+  std::unique_ptr<RenderDelayController> delay_controller;
+  if (!config.delay.use_external_delay_estimator) {
+    delay_controller.reset(RenderDelayController::Create(config, sample_rate_hz,
+                                                         num_capture_channels));
+  }
+  std::unique_ptr<EchoRemover> echo_remover(EchoRemover::Create(
+      config, sample_rate_hz, num_render_channels, num_capture_channels));
+  return Create(config, sample_rate_hz, num_render_channels,
+                num_capture_channels, std::move(render_buffer),
+                std::move(delay_controller), std::move(echo_remover));
+}
+
+BlockProcessor* BlockProcessor::Create(
+    const EchoCanceller3Config& config,
+    int sample_rate_hz,
+    size_t num_render_channels,
+    size_t num_capture_channels,
+    std::unique_ptr<RenderDelayBuffer> render_buffer,
+    std::unique_ptr<RenderDelayController> delay_controller,
+    std::unique_ptr<EchoRemover> echo_remover) {
+  return new BlockProcessorImpl(config, sample_rate_hz, num_render_channels,
+                                num_capture_channels, std::move(render_buffer),
+                                std::move(delay_controller),
+                                std::move(echo_remover));
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor.h
new file mode 100644
index 0000000..41ce016
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor.h
@@ -0,0 +1,82 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_BLOCK_PROCESSOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_BLOCK_PROCESSOR_H_
+
+#include <stddef.h>
+
+#include <memory>
+#include <vector>
+
+#include "api/audio/echo_canceller3_config.h"
+#include "api/audio/echo_control.h"
+#include "modules/audio_processing/aec3/echo_remover.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "modules/audio_processing/aec3/render_delay_controller.h"
+
+namespace webrtc {
+
+// Class for performing echo cancellation on 64 sample blocks of audio data.
+class BlockProcessor {
+ public:
+  static BlockProcessor* Create(const EchoCanceller3Config& config,
+                                int sample_rate_hz,
+                                size_t num_render_channels,
+                                size_t num_capture_channels);
+  // Only used for testing purposes.
+  static BlockProcessor* Create(
+      const EchoCanceller3Config& config,
+      int sample_rate_hz,
+      size_t num_render_channels,
+      size_t num_capture_channels,
+      std::unique_ptr<RenderDelayBuffer> render_buffer);
+  static BlockProcessor* Create(
+      const EchoCanceller3Config& config,
+      int sample_rate_hz,
+      size_t num_render_channels,
+      size_t num_capture_channels,
+      std::unique_ptr<RenderDelayBuffer> render_buffer,
+      std::unique_ptr<RenderDelayController> delay_controller,
+      std::unique_ptr<EchoRemover> echo_remover);
+
+  virtual ~BlockProcessor() = default;
+
+  // Get current metrics.
+  virtual void GetMetrics(EchoControl::Metrics* metrics) const = 0;
+
+  // Provides an optional external estimate of the audio buffer delay.
+  virtual void SetAudioBufferDelay(int delay_ms) = 0;
+
+  // Processes a block of capture data.
+  virtual void ProcessCapture(
+      bool echo_path_gain_change,
+      bool capture_signal_saturation,
+      std::vector<std::vector<std::vector<float>>>* linear_output,
+      std::vector<std::vector<std::vector<float>>>* capture_block) = 0;
+
+  // Buffers a block of render data supplied by a FrameBlocker object.
+  virtual void BufferRender(
+      const std::vector<std::vector<std::vector<float>>>& render_block) = 0;
+
+  // Reports whether echo leakage has been detected in the echo canceller
+  // output.
+  virtual void UpdateEchoLeakageStatus(bool leakage_detected) = 0;
+
+  // Specifies whether the capture output will be used. The purpose of this is
+  // to allow the block processor to deactivate some of the processing when the
+  // resulting output is anyway not used, for instance when the endpoint is
+  // muted.
+  virtual void SetCaptureOutputUsage(bool capture_output_used) = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_BLOCK_PROCESSOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor_metrics.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor_metrics.cc
new file mode 100644
index 0000000..deac1fc
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor_metrics.cc
@@ -0,0 +1,104 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/block_processor_metrics.h"
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "rtc_base/checks.h"
+#include "system_wrappers/include/metrics.h"
+
+namespace webrtc {
+
+namespace {
+
+enum class RenderUnderrunCategory {
+  kNone,
+  kFew,
+  kSeveral,
+  kMany,
+  kConstant,
+  kNumCategories
+};
+
+enum class RenderOverrunCategory {
+  kNone,
+  kFew,
+  kSeveral,
+  kMany,
+  kConstant,
+  kNumCategories
+};
+
+}  // namespace
+
+void BlockProcessorMetrics::UpdateCapture(bool underrun) {
+  ++capture_block_counter_;
+  if (underrun) {
+    ++render_buffer_underruns_;
+  }
+
+  if (capture_block_counter_ == kMetricsReportingIntervalBlocks) {
+    metrics_reported_ = true;
+
+    RenderUnderrunCategory underrun_category;
+    if (render_buffer_underruns_ == 0) {
+      underrun_category = RenderUnderrunCategory::kNone;
+    } else if (render_buffer_underruns_ > (capture_block_counter_ >> 1)) {
+      underrun_category = RenderUnderrunCategory::kConstant;
+    } else if (render_buffer_underruns_ > 100) {
+      underrun_category = RenderUnderrunCategory::kMany;
+    } else if (render_buffer_underruns_ > 10) {
+      underrun_category = RenderUnderrunCategory::kSeveral;
+    } else {
+      underrun_category = RenderUnderrunCategory::kFew;
+    }
+    RTC_HISTOGRAM_ENUMERATION(
+        "WebRTC.Audio.EchoCanceller.RenderUnderruns",
+        static_cast<int>(underrun_category),
+        static_cast<int>(RenderUnderrunCategory::kNumCategories));
+
+    RenderOverrunCategory overrun_category;
+    if (render_buffer_overruns_ == 0) {
+      overrun_category = RenderOverrunCategory::kNone;
+    } else if (render_buffer_overruns_ > (buffer_render_calls_ >> 1)) {
+      overrun_category = RenderOverrunCategory::kConstant;
+    } else if (render_buffer_overruns_ > 100) {
+      overrun_category = RenderOverrunCategory::kMany;
+    } else if (render_buffer_overruns_ > 10) {
+      overrun_category = RenderOverrunCategory::kSeveral;
+    } else {
+      overrun_category = RenderOverrunCategory::kFew;
+    }
+    RTC_HISTOGRAM_ENUMERATION(
+        "WebRTC.Audio.EchoCanceller.RenderOverruns",
+        static_cast<int>(overrun_category),
+        static_cast<int>(RenderOverrunCategory::kNumCategories));
+
+    ResetMetrics();
+    capture_block_counter_ = 0;
+  } else {
+    metrics_reported_ = false;
+  }
+}
+
+void BlockProcessorMetrics::UpdateRender(bool overrun) {
+  ++buffer_render_calls_;
+  if (overrun) {
+    ++render_buffer_overruns_;
+  }
+}
+
+void BlockProcessorMetrics::ResetMetrics() {
+  render_buffer_underruns_ = 0;
+  render_buffer_overruns_ = 0;
+  buffer_render_calls_ = 0;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor_metrics.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor_metrics.h
new file mode 100644
index 0000000..4ba0536
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor_metrics.h
@@ -0,0 +1,47 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_BLOCK_PROCESSOR_METRICS_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_BLOCK_PROCESSOR_METRICS_H_
+
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+// Handles the reporting of metrics for the block_processor.
+class BlockProcessorMetrics {
+ public:
+  BlockProcessorMetrics() = default;
+
+  // Updates the metric with new capture data.
+  void UpdateCapture(bool underrun);
+
+  // Updates the metric with new render data.
+  void UpdateRender(bool overrun);
+
+  // Returns true if the metrics have just been reported, otherwise false.
+  bool MetricsReported() { return metrics_reported_; }
+
+ private:
+  // Resets the metrics.
+  void ResetMetrics();
+
+  int capture_block_counter_ = 0;
+  bool metrics_reported_ = false;
+  int render_buffer_underruns_ = 0;
+  int render_buffer_overruns_ = 0;
+  int buffer_render_calls_ = 0;
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(BlockProcessorMetrics);
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_BLOCK_PROCESSOR_METRICS_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor_metrics_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor_metrics_unittest.cc
new file mode 100644
index 0000000..3e23c24
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor_metrics_unittest.cc
@@ -0,0 +1,34 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/block_processor_metrics.h"
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+// Verify the general functionality of BlockProcessorMetrics.
+TEST(BlockProcessorMetrics, NormalUsage) {
+  BlockProcessorMetrics metrics;
+
+  for (int j = 0; j < 3; ++j) {
+    for (int k = 0; k < kMetricsReportingIntervalBlocks - 1; ++k) {
+      metrics.UpdateRender(false);
+      metrics.UpdateRender(false);
+      metrics.UpdateCapture(false);
+      EXPECT_FALSE(metrics.MetricsReported());
+    }
+    metrics.UpdateCapture(false);
+    EXPECT_TRUE(metrics.MetricsReported());
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor_unittest.cc
new file mode 100644
index 0000000..d87e27a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/block_processor_unittest.cc
@@ -0,0 +1,386 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/block_processor.h"
+
+#include <memory>
+#include <string>
+#include <vector>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/mock/mock_echo_remover.h"
+#include "modules/audio_processing/aec3/mock/mock_render_delay_buffer.h"
+#include "modules/audio_processing/aec3/mock/mock_render_delay_controller.h"
+#include "modules/audio_processing/test/echo_canceller_test_tools.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/random.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gmock.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace {
+
+using ::testing::_;
+using ::testing::AtLeast;
+using ::testing::NiceMock;
+using ::testing::Return;
+using ::testing::StrictMock;
+
+// Verifies that the basic BlockProcessor functionality works and that the API
+// methods are callable.
+void RunBasicSetupAndApiCallTest(int sample_rate_hz, int num_iterations) {
+  constexpr size_t kNumRenderChannels = 1;
+  constexpr size_t kNumCaptureChannels = 1;
+
+  std::unique_ptr<BlockProcessor> block_processor(
+      BlockProcessor::Create(EchoCanceller3Config(), sample_rate_hz,
+                             kNumRenderChannels, kNumCaptureChannels));
+  std::vector<std::vector<std::vector<float>>> block(
+      NumBandsForRate(sample_rate_hz),
+      std::vector<std::vector<float>>(kNumRenderChannels,
+                                      std::vector<float>(kBlockSize, 1000.f)));
+  for (int k = 0; k < num_iterations; ++k) {
+    block_processor->BufferRender(block);
+    block_processor->ProcessCapture(false, false, nullptr, &block);
+    block_processor->UpdateEchoLeakageStatus(false);
+  }
+}
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+void RunRenderBlockSizeVerificationTest(int sample_rate_hz) {
+  constexpr size_t kNumRenderChannels = 1;
+  constexpr size_t kNumCaptureChannels = 1;
+
+  std::unique_ptr<BlockProcessor> block_processor(
+      BlockProcessor::Create(EchoCanceller3Config(), sample_rate_hz,
+                             kNumRenderChannels, kNumCaptureChannels));
+  std::vector<std::vector<std::vector<float>>> block(
+      NumBandsForRate(sample_rate_hz),
+      std::vector<std::vector<float>>(kNumRenderChannels,
+                                      std::vector<float>(kBlockSize - 1, 0.f)));
+
+  EXPECT_DEATH(block_processor->BufferRender(block), "");
+}
+
+void RunCaptureBlockSizeVerificationTest(int sample_rate_hz) {
+  constexpr size_t kNumRenderChannels = 1;
+  constexpr size_t kNumCaptureChannels = 1;
+
+  std::unique_ptr<BlockProcessor> block_processor(
+      BlockProcessor::Create(EchoCanceller3Config(), sample_rate_hz,
+                             kNumRenderChannels, kNumCaptureChannels));
+  std::vector<std::vector<std::vector<float>>> block(
+      NumBandsForRate(sample_rate_hz),
+      std::vector<std::vector<float>>(kNumRenderChannels,
+                                      std::vector<float>(kBlockSize - 1, 0.f)));
+
+  EXPECT_DEATH(block_processor->ProcessCapture(false, false, nullptr, &block),
+               "");
+}
+
+void RunRenderNumBandsVerificationTest(int sample_rate_hz) {
+  constexpr size_t kNumRenderChannels = 1;
+  constexpr size_t kNumCaptureChannels = 1;
+
+  const size_t wrong_num_bands = NumBandsForRate(sample_rate_hz) < 3
+                                     ? NumBandsForRate(sample_rate_hz) + 1
+                                     : 1;
+  std::unique_ptr<BlockProcessor> block_processor(
+      BlockProcessor::Create(EchoCanceller3Config(), sample_rate_hz,
+                             kNumRenderChannels, kNumCaptureChannels));
+  std::vector<std::vector<std::vector<float>>> block(
+      wrong_num_bands,
+      std::vector<std::vector<float>>(kNumRenderChannels,
+                                      std::vector<float>(kBlockSize, 0.f)));
+
+  EXPECT_DEATH(block_processor->BufferRender(block), "");
+}
+
+void RunCaptureNumBandsVerificationTest(int sample_rate_hz) {
+  constexpr size_t kNumRenderChannels = 1;
+  constexpr size_t kNumCaptureChannels = 1;
+
+  const size_t wrong_num_bands = NumBandsForRate(sample_rate_hz) < 3
+                                     ? NumBandsForRate(sample_rate_hz) + 1
+                                     : 1;
+  std::unique_ptr<BlockProcessor> block_processor(
+      BlockProcessor::Create(EchoCanceller3Config(), sample_rate_hz,
+                             kNumRenderChannels, kNumCaptureChannels));
+  std::vector<std::vector<std::vector<float>>> block(
+      wrong_num_bands,
+      std::vector<std::vector<float>>(kNumRenderChannels,
+                                      std::vector<float>(kBlockSize, 0.f)));
+
+  EXPECT_DEATH(block_processor->ProcessCapture(false, false, nullptr, &block),
+               "");
+}
+#endif
+
+std::string ProduceDebugText(int sample_rate_hz) {
+  rtc::StringBuilder ss;
+  ss << "Sample rate: " << sample_rate_hz;
+  return ss.Release();
+}
+
+void FillSampleVector(int call_counter,
+                      int delay,
+                      rtc::ArrayView<float> samples) {
+  for (size_t i = 0; i < samples.size(); ++i) {
+    samples[i] = (call_counter - delay) * 10000.0f + i;
+  }
+}
+
+}  // namespace
+
+// Verifies that the delay controller functionality is properly integrated with
+// the render delay buffer inside block processor.
+// TODO(peah): Activate the unittest once the required code has been landed.
+TEST(BlockProcessor, DISABLED_DelayControllerIntegration) {
+  constexpr size_t kNumRenderChannels = 1;
+  constexpr size_t kNumCaptureChannels = 1;
+  constexpr size_t kNumBlocks = 310;
+  constexpr size_t kDelayInSamples = 640;
+  constexpr size_t kDelayHeadroom = 1;
+  constexpr size_t kDelayInBlocks =
+      kDelayInSamples / kBlockSize - kDelayHeadroom;
+  Random random_generator(42U);
+  for (auto rate : {16000, 32000, 48000}) {
+    SCOPED_TRACE(ProduceDebugText(rate));
+    std::unique_ptr<testing::StrictMock<webrtc::test::MockRenderDelayBuffer>>
+        render_delay_buffer_mock(
+            new StrictMock<webrtc::test::MockRenderDelayBuffer>(rate, 1));
+    EXPECT_CALL(*render_delay_buffer_mock, Insert(_))
+        .Times(kNumBlocks)
+        .WillRepeatedly(Return(RenderDelayBuffer::BufferingEvent::kNone));
+    EXPECT_CALL(*render_delay_buffer_mock, AlignFromDelay(kDelayInBlocks))
+        .Times(AtLeast(1));
+    EXPECT_CALL(*render_delay_buffer_mock, MaxDelay()).WillOnce(Return(30));
+    EXPECT_CALL(*render_delay_buffer_mock, Delay())
+        .Times(kNumBlocks + 1)
+        .WillRepeatedly(Return(0));
+    std::unique_ptr<BlockProcessor> block_processor(BlockProcessor::Create(
+        EchoCanceller3Config(), rate, kNumRenderChannels, kNumCaptureChannels,
+        std::move(render_delay_buffer_mock)));
+
+    std::vector<std::vector<std::vector<float>>> render_block(
+        NumBandsForRate(rate),
+        std::vector<std::vector<float>>(kNumRenderChannels,
+                                        std::vector<float>(kBlockSize, 0.f)));
+    std::vector<std::vector<std::vector<float>>> capture_block(
+        NumBandsForRate(rate),
+        std::vector<std::vector<float>>(kNumCaptureChannels,
+                                        std::vector<float>(kBlockSize, 0.f)));
+    DelayBuffer<float> signal_delay_buffer(kDelayInSamples);
+    for (size_t k = 0; k < kNumBlocks; ++k) {
+      RandomizeSampleVector(&random_generator, render_block[0][0]);
+      signal_delay_buffer.Delay(render_block[0][0], capture_block[0][0]);
+      block_processor->BufferRender(render_block);
+      block_processor->ProcessCapture(false, false, nullptr, &capture_block);
+    }
+  }
+}
+
+// Verifies that BlockProcessor submodules are called in a proper manner.
+TEST(BlockProcessor, DISABLED_SubmoduleIntegration) {
+  constexpr size_t kNumBlocks = 310;
+  constexpr size_t kNumRenderChannels = 1;
+  constexpr size_t kNumCaptureChannels = 1;
+
+  Random random_generator(42U);
+  for (auto rate : {16000, 32000, 48000}) {
+    SCOPED_TRACE(ProduceDebugText(rate));
+    std::unique_ptr<testing::StrictMock<webrtc::test::MockRenderDelayBuffer>>
+        render_delay_buffer_mock(
+            new StrictMock<webrtc::test::MockRenderDelayBuffer>(rate, 1));
+    std::unique_ptr<
+        ::testing::StrictMock<webrtc::test::MockRenderDelayController>>
+        render_delay_controller_mock(
+            new StrictMock<webrtc::test::MockRenderDelayController>());
+    std::unique_ptr<testing::StrictMock<webrtc::test::MockEchoRemover>>
+        echo_remover_mock(new StrictMock<webrtc::test::MockEchoRemover>());
+
+    EXPECT_CALL(*render_delay_buffer_mock, Insert(_))
+        .Times(kNumBlocks - 1)
+        .WillRepeatedly(Return(RenderDelayBuffer::BufferingEvent::kNone));
+    EXPECT_CALL(*render_delay_buffer_mock, PrepareCaptureProcessing())
+        .Times(kNumBlocks);
+    EXPECT_CALL(*render_delay_buffer_mock, AlignFromDelay(9)).Times(AtLeast(1));
+    EXPECT_CALL(*render_delay_buffer_mock, Delay())
+        .Times(kNumBlocks)
+        .WillRepeatedly(Return(0));
+    EXPECT_CALL(*render_delay_controller_mock, GetDelay(_, _, _))
+        .Times(kNumBlocks);
+    EXPECT_CALL(*echo_remover_mock, ProcessCapture(_, _, _, _, _, _))
+        .Times(kNumBlocks);
+    EXPECT_CALL(*echo_remover_mock, UpdateEchoLeakageStatus(_))
+        .Times(kNumBlocks);
+
+    std::unique_ptr<BlockProcessor> block_processor(BlockProcessor::Create(
+        EchoCanceller3Config(), rate, kNumRenderChannels, kNumCaptureChannels,
+        std::move(render_delay_buffer_mock),
+        std::move(render_delay_controller_mock), std::move(echo_remover_mock)));
+
+    std::vector<std::vector<std::vector<float>>> render_block(
+        NumBandsForRate(rate),
+        std::vector<std::vector<float>>(kNumRenderChannels,
+                                        std::vector<float>(kBlockSize, 0.f)));
+    std::vector<std::vector<std::vector<float>>> capture_block(
+        NumBandsForRate(rate),
+        std::vector<std::vector<float>>(kNumCaptureChannels,
+                                        std::vector<float>(kBlockSize, 0.f)));
+    DelayBuffer<float> signal_delay_buffer(640);
+    for (size_t k = 0; k < kNumBlocks; ++k) {
+      RandomizeSampleVector(&random_generator, render_block[0][0]);
+      signal_delay_buffer.Delay(render_block[0][0], capture_block[0][0]);
+      block_processor->BufferRender(render_block);
+      block_processor->ProcessCapture(false, false, nullptr, &capture_block);
+      block_processor->UpdateEchoLeakageStatus(false);
+    }
+  }
+}
+
+TEST(BlockProcessor, BasicSetupAndApiCalls) {
+  for (auto rate : {16000, 32000, 48000}) {
+    SCOPED_TRACE(ProduceDebugText(rate));
+    RunBasicSetupAndApiCallTest(rate, 1);
+  }
+}
+
+TEST(BlockProcessor, TestLongerCall) {
+  RunBasicSetupAndApiCallTest(16000, 20 * kNumBlocksPerSecond);
+}
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+// TODO(gustaf): Re-enable the test once the issue with memory leaks during
+// DEATH tests on test bots has been fixed.
+TEST(BlockProcessorDeathTest, DISABLED_VerifyRenderBlockSizeCheck) {
+  for (auto rate : {16000, 32000, 48000}) {
+    SCOPED_TRACE(ProduceDebugText(rate));
+    RunRenderBlockSizeVerificationTest(rate);
+  }
+}
+
+TEST(BlockProcessorDeathTest, VerifyCaptureBlockSizeCheck) {
+  for (auto rate : {16000, 32000, 48000}) {
+    SCOPED_TRACE(ProduceDebugText(rate));
+    RunCaptureBlockSizeVerificationTest(rate);
+  }
+}
+
+TEST(BlockProcessorDeathTest, VerifyRenderNumBandsCheck) {
+  for (auto rate : {16000, 32000, 48000}) {
+    SCOPED_TRACE(ProduceDebugText(rate));
+    RunRenderNumBandsVerificationTest(rate);
+  }
+}
+
+// TODO(peah): Verify the check for correct number of bands in the capture
+// signal.
+TEST(BlockProcessorDeathTest, VerifyCaptureNumBandsCheck) {
+  for (auto rate : {16000, 32000, 48000}) {
+    SCOPED_TRACE(ProduceDebugText(rate));
+    RunCaptureNumBandsVerificationTest(rate);
+  }
+}
+
+// Verifiers that the verification for null ProcessCapture input works.
+TEST(BlockProcessorDeathTest, NullProcessCaptureParameter) {
+  EXPECT_DEATH(std::unique_ptr<BlockProcessor>(
+                   BlockProcessor::Create(EchoCanceller3Config(), 16000, 1, 1))
+                   ->ProcessCapture(false, false, nullptr, nullptr),
+               "");
+}
+
+// Verifies the check for correct sample rate.
+// TODO(peah): Re-enable the test once the issue with memory leaks during DEATH
+// tests on test bots has been fixed.
+TEST(BlockProcessor, DISABLED_WrongSampleRate) {
+  EXPECT_DEATH(std::unique_ptr<BlockProcessor>(
+                   BlockProcessor::Create(EchoCanceller3Config(), 8001, 1, 1)),
+               "");
+}
+
+#endif
+
+// Verifies that external delay estimator delays are applied correctly when a
+// call begins with a sequence of capture blocks.
+TEST(BlockProcessor, ExternalDelayAppliedCorrectlyWithInitialCaptureCalls) {
+  constexpr int kNumRenderChannels = 1;
+  constexpr int kNumCaptureChannels = 1;
+  constexpr int kSampleRateHz = 16000;
+
+  EchoCanceller3Config config;
+  config.delay.use_external_delay_estimator = true;
+
+  std::unique_ptr<RenderDelayBuffer> delay_buffer(
+      RenderDelayBuffer::Create(config, kSampleRateHz, kNumRenderChannels));
+
+  std::unique_ptr<testing::NiceMock<webrtc::test::MockEchoRemover>>
+      echo_remover_mock(new NiceMock<webrtc::test::MockEchoRemover>());
+  webrtc::test::MockEchoRemover* echo_remover_mock_pointer =
+      echo_remover_mock.get();
+
+  std::unique_ptr<BlockProcessor> block_processor(BlockProcessor::Create(
+      config, kSampleRateHz, kNumRenderChannels, kNumCaptureChannels,
+      std::move(delay_buffer), /*delay_controller=*/nullptr,
+      std::move(echo_remover_mock)));
+
+  std::vector<std::vector<std::vector<float>>> render_block(
+      NumBandsForRate(kSampleRateHz),
+      std::vector<std::vector<float>>(kNumRenderChannels,
+                                      std::vector<float>(kBlockSize, 0.f)));
+  std::vector<std::vector<std::vector<float>>> capture_block(
+      NumBandsForRate(kSampleRateHz),
+      std::vector<std::vector<float>>(kNumCaptureChannels,
+                                      std::vector<float>(kBlockSize, 0.f)));
+
+  // Process...
+  // - 10 capture calls, where no render data is available,
+  // - 10 render calls, populating the buffer,
+  // - 2 capture calls, verifying that the delay was applied correctly.
+  constexpr int kDelayInBlocks = 5;
+  constexpr int kDelayInMs = 20;
+  block_processor->SetAudioBufferDelay(kDelayInMs);
+
+  int capture_call_counter = 0;
+  int render_call_counter = 0;
+  for (size_t k = 0; k < 10; ++k) {
+    FillSampleVector(++capture_call_counter, kDelayInBlocks,
+                     capture_block[0][0]);
+    block_processor->ProcessCapture(false, false, nullptr, &capture_block);
+  }
+  for (size_t k = 0; k < 10; ++k) {
+    FillSampleVector(++render_call_counter, 0, render_block[0][0]);
+    block_processor->BufferRender(render_block);
+  }
+
+  EXPECT_CALL(*echo_remover_mock_pointer, ProcessCapture)
+      .WillRepeatedly(
+          [](EchoPathVariability /*echo_path_variability*/,
+             bool /*capture_signal_saturation*/,
+             const absl::optional<DelayEstimate>& /*external_delay*/,
+             RenderBuffer* render_buffer,
+             std::vector<std::vector<std::vector<float>>>* /*linear_output*/,
+             std::vector<std::vector<std::vector<float>>>* capture) {
+            const auto& render = render_buffer->Block(0);
+            for (size_t i = 0; i < kBlockSize; ++i) {
+              EXPECT_FLOAT_EQ(render[0][0][i], (*capture)[0][0][i]);
+            }
+          });
+
+  FillSampleVector(++capture_call_counter, kDelayInBlocks, capture_block[0][0]);
+  block_processor->ProcessCapture(false, false, nullptr, &capture_block);
+
+  FillSampleVector(++capture_call_counter, kDelayInBlocks, capture_block[0][0]);
+  block_processor->ProcessCapture(false, false, nullptr, &capture_block);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/clockdrift_detector.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/clockdrift_detector.cc
new file mode 100644
index 0000000..2c49b79
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/clockdrift_detector.cc
@@ -0,0 +1,61 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "modules/audio_processing/aec3/clockdrift_detector.h"
+
+namespace webrtc {
+
+ClockdriftDetector::ClockdriftDetector()
+    : level_(Level::kNone), stability_counter_(0) {
+  delay_history_.fill(0);
+}
+
+ClockdriftDetector::~ClockdriftDetector() = default;
+
+void ClockdriftDetector::Update(int delay_estimate) {
+  if (delay_estimate == delay_history_[0]) {
+    // Reset clockdrift level if delay estimate is stable for 7500 blocks (30
+    // seconds).
+    if (++stability_counter_ > 7500)
+      level_ = Level::kNone;
+    return;
+  }
+
+  stability_counter_ = 0;
+  const int d1 = delay_history_[0] - delay_estimate;
+  const int d2 = delay_history_[1] - delay_estimate;
+  const int d3 = delay_history_[2] - delay_estimate;
+
+  // Patterns recognized as positive clockdrift:
+  // [x-3], x-2, x-1, x.
+  // [x-3], x-1, x-2, x.
+  const bool probable_drift_up =
+      (d1 == -1 && d2 == -2) || (d1 == -2 && d2 == -1);
+  const bool drift_up = probable_drift_up && d3 == -3;
+
+  // Patterns recognized as negative clockdrift:
+  // [x+3], x+2, x+1, x.
+  // [x+3], x+1, x+2, x.
+  const bool probable_drift_down = (d1 == 1 && d2 == 2) || (d1 == 2 && d2 == 1);
+  const bool drift_down = probable_drift_down && d3 == 3;
+
+  // Set clockdrift level.
+  if (drift_up || drift_down) {
+    level_ = Level::kVerified;
+  } else if ((probable_drift_up || probable_drift_down) &&
+             level_ == Level::kNone) {
+    level_ = Level::kProbable;
+  }
+
+  // Shift delay history one step.
+  delay_history_[2] = delay_history_[1];
+  delay_history_[1] = delay_history_[0];
+  delay_history_[0] = delay_estimate;
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/clockdrift_detector.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/clockdrift_detector.h
new file mode 100644
index 0000000..2ba90bb
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/clockdrift_detector.h
@@ -0,0 +1,40 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_CLOCKDRIFT_DETECTOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_CLOCKDRIFT_DETECTOR_H_
+
+#include <stddef.h>
+
+#include <array>
+
+namespace webrtc {
+
+class ApmDataDumper;
+struct DownsampledRenderBuffer;
+struct EchoCanceller3Config;
+
+// Detects clockdrift by analyzing the estimated delay.
+class ClockdriftDetector {
+ public:
+  enum class Level { kNone, kProbable, kVerified, kNumCategories };
+  ClockdriftDetector();
+  ~ClockdriftDetector();
+  void Update(int delay_estimate);
+  Level ClockdriftLevel() const { return level_; }
+
+ private:
+  std::array<int, 3> delay_history_;
+  Level level_;
+  size_t stability_counter_;
+};
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_CLOCKDRIFT_DETECTOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/clockdrift_detector_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/clockdrift_detector_unittest.cc
new file mode 100644
index 0000000..0f98b01
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/clockdrift_detector_unittest.cc
@@ -0,0 +1,57 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/clockdrift_detector.h"
+
+#include "test/gtest.h"
+
+namespace webrtc {
+TEST(ClockdriftDetector, ClockdriftDetector) {
+  ClockdriftDetector c;
+  // No clockdrift at start.
+  EXPECT_TRUE(c.ClockdriftLevel() == ClockdriftDetector::Level::kNone);
+
+  // Monotonically increasing delay.
+  for (int i = 0; i < 100; i++)
+    c.Update(1000);
+  EXPECT_TRUE(c.ClockdriftLevel() == ClockdriftDetector::Level::kNone);
+  for (int i = 0; i < 100; i++)
+    c.Update(1001);
+  EXPECT_TRUE(c.ClockdriftLevel() == ClockdriftDetector::Level::kNone);
+  for (int i = 0; i < 100; i++)
+    c.Update(1002);
+  // Probable clockdrift.
+  EXPECT_TRUE(c.ClockdriftLevel() == ClockdriftDetector::Level::kProbable);
+  for (int i = 0; i < 100; i++)
+    c.Update(1003);
+  // Verified clockdrift.
+  EXPECT_TRUE(c.ClockdriftLevel() == ClockdriftDetector::Level::kVerified);
+
+  // Stable delay.
+  for (int i = 0; i < 10000; i++)
+    c.Update(1003);
+  // No clockdrift.
+  EXPECT_TRUE(c.ClockdriftLevel() == ClockdriftDetector::Level::kNone);
+
+  // Decreasing delay.
+  for (int i = 0; i < 100; i++)
+    c.Update(1001);
+  for (int i = 0; i < 100; i++)
+    c.Update(999);
+  // Probable clockdrift.
+  EXPECT_TRUE(c.ClockdriftLevel() == ClockdriftDetector::Level::kProbable);
+  for (int i = 0; i < 100; i++)
+    c.Update(1000);
+  for (int i = 0; i < 100; i++)
+    c.Update(998);
+  // Verified clockdrift.
+  EXPECT_TRUE(c.ClockdriftLevel() == ClockdriftDetector::Level::kVerified);
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/coarse_filter_update_gain.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/coarse_filter_update_gain.cc
new file mode 100644
index 0000000..f4fb74d
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/coarse_filter_update_gain.cc
@@ -0,0 +1,103 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/coarse_filter_update_gain.h"
+
+#include <algorithm>
+#include <functional>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+CoarseFilterUpdateGain::CoarseFilterUpdateGain(
+    const EchoCanceller3Config::Filter::CoarseConfiguration& config,
+    size_t config_change_duration_blocks)
+    : config_change_duration_blocks_(
+          static_cast<int>(config_change_duration_blocks)) {
+  SetConfig(config, true);
+  RTC_DCHECK_LT(0, config_change_duration_blocks_);
+  one_by_config_change_duration_blocks_ = 1.f / config_change_duration_blocks_;
+}
+
+void CoarseFilterUpdateGain::HandleEchoPathChange() {
+  poor_signal_excitation_counter_ = 0;
+  call_counter_ = 0;
+}
+
+void CoarseFilterUpdateGain::Compute(
+    const std::array<float, kFftLengthBy2Plus1>& render_power,
+    const RenderSignalAnalyzer& render_signal_analyzer,
+    const FftData& E_coarse,
+    size_t size_partitions,
+    bool saturated_capture_signal,
+    FftData* G) {
+  RTC_DCHECK(G);
+  ++call_counter_;
+
+  UpdateCurrentConfig();
+
+  if (render_signal_analyzer.PoorSignalExcitation()) {
+    poor_signal_excitation_counter_ = 0;
+  }
+
+  // Do not update the filter if the render is not sufficiently excited.
+  if (++poor_signal_excitation_counter_ < size_partitions ||
+      saturated_capture_signal || call_counter_ <= size_partitions) {
+    G->re.fill(0.f);
+    G->im.fill(0.f);
+    return;
+  }
+
+  // Compute mu.
+  std::array<float, kFftLengthBy2Plus1> mu;
+  const auto& X2 = render_power;
+  for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+    if (X2[k] > current_config_.noise_gate) {
+      mu[k] = current_config_.rate / X2[k];
+    } else {
+      mu[k] = 0.f;
+    }
+  }
+
+  // Avoid updating the filter close to narrow bands in the render signals.
+  render_signal_analyzer.MaskRegionsAroundNarrowBands(&mu);
+
+  // G = mu * E * X2.
+  for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+    G->re[k] = mu[k] * E_coarse.re[k];
+    G->im[k] = mu[k] * E_coarse.im[k];
+  }
+}
+
+void CoarseFilterUpdateGain::UpdateCurrentConfig() {
+  RTC_DCHECK_GE(config_change_duration_blocks_, config_change_counter_);
+  if (config_change_counter_ > 0) {
+    if (--config_change_counter_ > 0) {
+      auto average = [](float from, float to, float from_weight) {
+        return from * from_weight + to * (1.f - from_weight);
+      };
+
+      float change_factor =
+          config_change_counter_ * one_by_config_change_duration_blocks_;
+
+      current_config_.rate =
+          average(old_target_config_.rate, target_config_.rate, change_factor);
+      current_config_.noise_gate =
+          average(old_target_config_.noise_gate, target_config_.noise_gate,
+                  change_factor);
+    } else {
+      current_config_ = old_target_config_ = target_config_;
+    }
+  }
+  RTC_DCHECK_LE(0, config_change_counter_);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/coarse_filter_update_gain.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/coarse_filter_update_gain.h
new file mode 100644
index 0000000..a1a1399
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/coarse_filter_update_gain.h
@@ -0,0 +1,74 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_COARSE_FILTER_UPDATE_GAIN_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_COARSE_FILTER_UPDATE_GAIN_H_
+
+#include <stddef.h>
+
+#include <array>
+
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/fft_data.h"
+#include "modules/audio_processing/aec3/render_signal_analyzer.h"
+
+namespace webrtc {
+
+// Provides functionality for computing the fixed gain for the coarse filter.
+class CoarseFilterUpdateGain {
+ public:
+  explicit CoarseFilterUpdateGain(
+      const EchoCanceller3Config::Filter::CoarseConfiguration& config,
+      size_t config_change_duration_blocks);
+
+  // Takes action in the case of a known echo path change.
+  void HandleEchoPathChange();
+
+  // Computes the gain.
+  void Compute(const std::array<float, kFftLengthBy2Plus1>& render_power,
+               const RenderSignalAnalyzer& render_signal_analyzer,
+               const FftData& E_coarse,
+               size_t size_partitions,
+               bool saturated_capture_signal,
+               FftData* G);
+
+  // Sets a new config.
+  void SetConfig(
+      const EchoCanceller3Config::Filter::CoarseConfiguration& config,
+      bool immediate_effect) {
+    if (immediate_effect) {
+      old_target_config_ = current_config_ = target_config_ = config;
+      config_change_counter_ = 0;
+    } else {
+      old_target_config_ = current_config_;
+      target_config_ = config;
+      config_change_counter_ = config_change_duration_blocks_;
+    }
+  }
+
+ private:
+  EchoCanceller3Config::Filter::CoarseConfiguration current_config_;
+  EchoCanceller3Config::Filter::CoarseConfiguration target_config_;
+  EchoCanceller3Config::Filter::CoarseConfiguration old_target_config_;
+  const int config_change_duration_blocks_;
+  float one_by_config_change_duration_blocks_;
+  // TODO(peah): Check whether this counter should instead be initialized to a
+  // large value.
+  size_t poor_signal_excitation_counter_ = 0;
+  size_t call_counter_ = 0;
+  int config_change_counter_ = 0;
+
+  void UpdateCurrentConfig();
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_COARSE_FILTER_UPDATE_GAIN_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/coarse_filter_update_gain_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/coarse_filter_update_gain_unittest.cc
new file mode 100644
index 0000000..92775cf
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/coarse_filter_update_gain_unittest.cc
@@ -0,0 +1,271 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/coarse_filter_update_gain.h"
+
+#include <algorithm>
+#include <memory>
+#include <numeric>
+#include <string>
+#include <vector>
+
+#include "modules/audio_processing/aec3/adaptive_fir_filter.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/aec_state.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "modules/audio_processing/test/echo_canceller_test_tools.h"
+#include "rtc_base/numerics/safe_minmax.h"
+#include "rtc_base/random.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace {
+// Method for performing the simulations needed to test the refined filter
+// update gain functionality.
+void RunFilterUpdateTest(int num_blocks_to_process,
+                         size_t delay_samples,
+                         size_t num_render_channels,
+                         int filter_length_blocks,
+                         const std::vector<int>& blocks_with_saturation,
+                         std::array<float, kBlockSize>* e_last_block,
+                         std::array<float, kBlockSize>* y_last_block,
+                         FftData* G_last_block) {
+  ApmDataDumper data_dumper(42);
+  EchoCanceller3Config config;
+  config.filter.refined.length_blocks = filter_length_blocks;
+  AdaptiveFirFilter refined_filter(
+      config.filter.refined.length_blocks, config.filter.refined.length_blocks,
+      config.filter.config_change_duration_blocks, num_render_channels,
+      DetectOptimization(), &data_dumper);
+  AdaptiveFirFilter coarse_filter(
+      config.filter.coarse.length_blocks, config.filter.coarse.length_blocks,
+      config.filter.config_change_duration_blocks, num_render_channels,
+      DetectOptimization(), &data_dumper);
+  Aec3Fft fft;
+
+  constexpr int kSampleRateHz = 48000;
+  config.delay.default_delay = 1;
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+      RenderDelayBuffer::Create(config, kSampleRateHz, num_render_channels));
+
+  CoarseFilterUpdateGain coarse_gain(
+      config.filter.coarse, config.filter.config_change_duration_blocks);
+  Random random_generator(42U);
+  std::vector<std::vector<std::vector<float>>> x(
+      NumBandsForRate(kSampleRateHz),
+      std::vector<std::vector<float>>(num_render_channels,
+                                      std::vector<float>(kBlockSize, 0.f)));
+  std::array<float, kBlockSize> y;
+  RenderSignalAnalyzer render_signal_analyzer(config);
+  std::array<float, kFftLength> s;
+  FftData S;
+  FftData G;
+  FftData E_coarse;
+  std::array<float, kBlockSize> e_coarse;
+
+  constexpr float kScale = 1.0f / kFftLengthBy2;
+
+  DelayBuffer<float> delay_buffer(delay_samples);
+  for (int k = 0; k < num_blocks_to_process; ++k) {
+    // Handle saturation.
+    bool saturation =
+        std::find(blocks_with_saturation.begin(), blocks_with_saturation.end(),
+                  k) != blocks_with_saturation.end();
+
+    // Create the render signal.
+    for (size_t band = 0; band < x.size(); ++band) {
+      for (size_t channel = 0; channel < x[band].size(); ++channel) {
+        RandomizeSampleVector(&random_generator, x[band][channel]);
+      }
+    }
+    delay_buffer.Delay(x[0][0], y);
+
+    render_delay_buffer->Insert(x);
+    if (k == 0) {
+      render_delay_buffer->Reset();
+    }
+    render_delay_buffer->PrepareCaptureProcessing();
+
+    render_signal_analyzer.Update(*render_delay_buffer->GetRenderBuffer(),
+                                  delay_samples / kBlockSize);
+
+    coarse_filter.Filter(*render_delay_buffer->GetRenderBuffer(), &S);
+    fft.Ifft(S, &s);
+    std::transform(y.begin(), y.end(), s.begin() + kFftLengthBy2,
+                   e_coarse.begin(),
+                   [&](float a, float b) { return a - b * kScale; });
+    std::for_each(e_coarse.begin(), e_coarse.end(),
+                  [](float& a) { a = rtc::SafeClamp(a, -32768.f, 32767.f); });
+    fft.ZeroPaddedFft(e_coarse, Aec3Fft::Window::kRectangular, &E_coarse);
+
+    std::array<float, kFftLengthBy2Plus1> render_power;
+    render_delay_buffer->GetRenderBuffer()->SpectralSum(
+        coarse_filter.SizePartitions(), &render_power);
+    coarse_gain.Compute(render_power, render_signal_analyzer, E_coarse,
+                        coarse_filter.SizePartitions(), saturation, &G);
+    coarse_filter.Adapt(*render_delay_buffer->GetRenderBuffer(), G);
+  }
+
+  std::copy(e_coarse.begin(), e_coarse.end(), e_last_block->begin());
+  std::copy(y.begin(), y.end(), y_last_block->begin());
+  std::copy(G.re.begin(), G.re.end(), G_last_block->re.begin());
+  std::copy(G.im.begin(), G.im.end(), G_last_block->im.begin());
+}
+
+std::string ProduceDebugText(int filter_length_blocks) {
+  rtc::StringBuilder ss;
+  ss << "Length: " << filter_length_blocks;
+  return ss.Release();
+}
+
+std::string ProduceDebugText(size_t delay, int filter_length_blocks) {
+  rtc::StringBuilder ss;
+  ss << "Delay: " << delay << ", ";
+  ss << ProduceDebugText(filter_length_blocks);
+  return ss.Release();
+}
+
+}  // namespace
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+// Verifies that the check for non-null output gain parameter works.
+TEST(CoarseFilterUpdateGainDeathTest, NullDataOutputGain) {
+  ApmDataDumper data_dumper(42);
+  FftBuffer fft_buffer(1, 1);
+  RenderSignalAnalyzer analyzer(EchoCanceller3Config{});
+  FftData E;
+  const EchoCanceller3Config::Filter::CoarseConfiguration& config = {
+      12, 0.5f, 220075344.f};
+  CoarseFilterUpdateGain gain(config, 250);
+  std::array<float, kFftLengthBy2Plus1> render_power;
+  render_power.fill(0.f);
+  EXPECT_DEATH(gain.Compute(render_power, analyzer, E, 1, false, nullptr), "");
+}
+
+#endif
+
+class CoarseFilterUpdateGainOneTwoEightRenderChannels
+    : public ::testing::Test,
+      public ::testing::WithParamInterface<size_t> {};
+
+INSTANTIATE_TEST_SUITE_P(MultiChannel,
+                         CoarseFilterUpdateGainOneTwoEightRenderChannels,
+                         ::testing::Values(1, 2, 8));
+
+// Verifies that the gain formed causes the filter using it to converge.
+TEST_P(CoarseFilterUpdateGainOneTwoEightRenderChannels,
+       GainCausesFilterToConverge) {
+  const size_t num_render_channels = GetParam();
+  std::vector<int> blocks_with_echo_path_changes;
+  std::vector<int> blocks_with_saturation;
+
+  for (size_t filter_length_blocks : {12, 20, 30}) {
+    for (size_t delay_samples : {0, 64, 150, 200, 301}) {
+      SCOPED_TRACE(ProduceDebugText(delay_samples, filter_length_blocks));
+
+      std::array<float, kBlockSize> e;
+      std::array<float, kBlockSize> y;
+      FftData G;
+
+      RunFilterUpdateTest(5000, delay_samples, num_render_channels,
+                          filter_length_blocks, blocks_with_saturation, &e, &y,
+                          &G);
+
+      // Verify that the refined filter is able to perform well.
+      // Use different criteria to take overmodelling into account.
+      if (filter_length_blocks == 12) {
+        EXPECT_LT(1000 * std::inner_product(e.begin(), e.end(), e.begin(), 0.f),
+                  std::inner_product(y.begin(), y.end(), y.begin(), 0.f));
+      } else {
+        EXPECT_LT(std::inner_product(e.begin(), e.end(), e.begin(), 0.f),
+                  std::inner_product(y.begin(), y.end(), y.begin(), 0.f));
+      }
+    }
+  }
+}
+
+// Verifies that the gain is zero when there is saturation.
+TEST_P(CoarseFilterUpdateGainOneTwoEightRenderChannels, SaturationBehavior) {
+  const size_t num_render_channels = GetParam();
+  std::vector<int> blocks_with_echo_path_changes;
+  std::vector<int> blocks_with_saturation;
+  for (int k = 99; k < 200; ++k) {
+    blocks_with_saturation.push_back(k);
+  }
+  for (size_t filter_length_blocks : {12, 20, 30}) {
+    SCOPED_TRACE(ProduceDebugText(filter_length_blocks));
+
+    std::array<float, kBlockSize> e;
+    std::array<float, kBlockSize> y;
+    FftData G_a;
+    FftData G_a_ref;
+    G_a_ref.re.fill(0.f);
+    G_a_ref.im.fill(0.f);
+
+    RunFilterUpdateTest(100, 65, num_render_channels, filter_length_blocks,
+                        blocks_with_saturation, &e, &y, &G_a);
+
+    EXPECT_EQ(G_a_ref.re, G_a.re);
+    EXPECT_EQ(G_a_ref.im, G_a.im);
+  }
+}
+
+class CoarseFilterUpdateGainOneTwoFourRenderChannels
+    : public ::testing::Test,
+      public ::testing::WithParamInterface<size_t> {};
+
+INSTANTIATE_TEST_SUITE_P(
+    MultiChannel,
+    CoarseFilterUpdateGainOneTwoFourRenderChannels,
+    ::testing::Values(1, 2, 4),
+    [](const ::testing::TestParamInfo<
+        CoarseFilterUpdateGainOneTwoFourRenderChannels::ParamType>& info) {
+      return (rtc::StringBuilder() << "Render" << info.param).str();
+    });
+
+// Verifies that the magnitude of the gain on average decreases for a
+// persistently exciting signal.
+TEST_P(CoarseFilterUpdateGainOneTwoFourRenderChannels, DecreasingGain) {
+  const size_t num_render_channels = GetParam();
+  for (size_t filter_length_blocks : {12, 20, 30}) {
+    SCOPED_TRACE(ProduceDebugText(filter_length_blocks));
+    std::vector<int> blocks_with_echo_path_changes;
+    std::vector<int> blocks_with_saturation;
+
+    std::array<float, kBlockSize> e;
+    std::array<float, kBlockSize> y;
+    FftData G_a;
+    FftData G_b;
+    FftData G_c;
+    std::array<float, kFftLengthBy2Plus1> G_a_power;
+    std::array<float, kFftLengthBy2Plus1> G_b_power;
+    std::array<float, kFftLengthBy2Plus1> G_c_power;
+
+    RunFilterUpdateTest(100, 65, num_render_channels, filter_length_blocks,
+                        blocks_with_saturation, &e, &y, &G_a);
+    RunFilterUpdateTest(200, 65, num_render_channels, filter_length_blocks,
+                        blocks_with_saturation, &e, &y, &G_b);
+    RunFilterUpdateTest(300, 65, num_render_channels, filter_length_blocks,
+                        blocks_with_saturation, &e, &y, &G_c);
+
+    G_a.Spectrum(Aec3Optimization::kNone, G_a_power);
+    G_b.Spectrum(Aec3Optimization::kNone, G_b_power);
+    G_c.Spectrum(Aec3Optimization::kNone, G_c_power);
+
+    EXPECT_GT(std::accumulate(G_a_power.begin(), G_a_power.end(), 0.),
+              std::accumulate(G_b_power.begin(), G_b_power.end(), 0.));
+
+    EXPECT_GT(std::accumulate(G_b_power.begin(), G_b_power.end(), 0.),
+              std::accumulate(G_c_power.begin(), G_c_power.end(), 0.));
+  }
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/comfort_noise_generator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/comfort_noise_generator.cc
new file mode 100644
index 0000000..de5227c
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/comfort_noise_generator.cc
@@ -0,0 +1,186 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/comfort_noise_generator.h"
+
+// Defines WEBRTC_ARCH_X86_FAMILY, used below.
+#include "rtc_base/system/arch.h"
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+#include <emmintrin.h>
+#endif
+#include <algorithm>
+#include <array>
+#include <cmath>
+#include <cstdint>
+#include <functional>
+#include <numeric>
+
+#include "common_audio/signal_processing/include/signal_processing_library.h"
+#include "modules/audio_processing/aec3/vector_math.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+namespace {
+
+// Computes the noise floor value that matches a WGN input of noise_floor_dbfs.
+float GetNoiseFloorFactor(float noise_floor_dbfs) {
+  // kdBfsNormalization = 20.f*log10(32768.f).
+  constexpr float kdBfsNormalization = 90.30899869919436f;
+  return 64.f * powf(10.f, (kdBfsNormalization + noise_floor_dbfs) * 0.1f);
+}
+
+// Table of sqrt(2) * sin(2*pi*i/32).
+constexpr float kSqrt2Sin[32] = {
+    +0.0000000f, +0.2758994f, +0.5411961f, +0.7856950f, +1.0000000f,
+    +1.1758756f, +1.3065630f, +1.3870398f, +1.4142136f, +1.3870398f,
+    +1.3065630f, +1.1758756f, +1.0000000f, +0.7856950f, +0.5411961f,
+    +0.2758994f, +0.0000000f, -0.2758994f, -0.5411961f, -0.7856950f,
+    -1.0000000f, -1.1758756f, -1.3065630f, -1.3870398f, -1.4142136f,
+    -1.3870398f, -1.3065630f, -1.1758756f, -1.0000000f, -0.7856950f,
+    -0.5411961f, -0.2758994f};
+
+void GenerateComfortNoise(Aec3Optimization optimization,
+                          const std::array<float, kFftLengthBy2Plus1>& N2,
+                          uint32_t* seed,
+                          FftData* lower_band_noise,
+                          FftData* upper_band_noise) {
+  FftData* N_low = lower_band_noise;
+  FftData* N_high = upper_band_noise;
+
+  // Compute square root spectrum.
+  std::array<float, kFftLengthBy2Plus1> N;
+  std::copy(N2.begin(), N2.end(), N.begin());
+  aec3::VectorMath(optimization).Sqrt(N);
+
+  // Compute the noise level for the upper bands.
+  constexpr float kOneByNumBands = 1.f / (kFftLengthBy2Plus1 / 2 + 1);
+  constexpr int kFftLengthBy2Plus1By2 = kFftLengthBy2Plus1 / 2;
+  const float high_band_noise_level =
+      std::accumulate(N.begin() + kFftLengthBy2Plus1By2, N.end(), 0.f) *
+      kOneByNumBands;
+
+  // The analysis and synthesis windowing cause loss of power when
+  // cross-fading the noise where frames are completely uncorrelated
+  // (generated with random phase), hence the factor sqrt(2).
+  // This is not the case for the speech signal where the input is overlapping
+  // (strong correlation).
+  N_low->re[0] = N_low->re[kFftLengthBy2] = N_high->re[0] =
+      N_high->re[kFftLengthBy2] = 0.f;
+  for (size_t k = 1; k < kFftLengthBy2; k++) {
+    constexpr int kIndexMask = 32 - 1;
+    // Generate a random 31-bit integer.
+    seed[0] = (seed[0] * 69069 + 1) & (0x80000000 - 1);
+    // Convert to a 5-bit index.
+    int i = seed[0] >> 26;
+
+    // y = sqrt(2) * sin(a)
+    const float x = kSqrt2Sin[i];
+    // x = sqrt(2) * cos(a) = sqrt(2) * sin(a + pi/2)
+    const float y = kSqrt2Sin[(i + 8) & kIndexMask];
+
+    // Form low-frequency noise via spectral shaping.
+    N_low->re[k] = N[k] * x;
+    N_low->im[k] = N[k] * y;
+
+    // Form the high-frequency noise via simple levelling.
+    N_high->re[k] = high_band_noise_level * x;
+    N_high->im[k] = high_band_noise_level * y;
+  }
+}
+
+}  // namespace
+
+ComfortNoiseGenerator::ComfortNoiseGenerator(const EchoCanceller3Config& config,
+                                             Aec3Optimization optimization,
+                                             size_t num_capture_channels)
+    : optimization_(optimization),
+      seed_(42),
+      num_capture_channels_(num_capture_channels),
+      noise_floor_(GetNoiseFloorFactor(config.comfort_noise.noise_floor_dbfs)),
+      N2_initial_(
+          std::make_unique<std::vector<std::array<float, kFftLengthBy2Plus1>>>(
+              num_capture_channels_)),
+      Y2_smoothed_(num_capture_channels_),
+      N2_(num_capture_channels_) {
+  for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+    (*N2_initial_)[ch].fill(0.f);
+    Y2_smoothed_[ch].fill(0.f);
+    N2_[ch].fill(1.0e6f);
+  }
+}
+
+ComfortNoiseGenerator::~ComfortNoiseGenerator() = default;
+
+void ComfortNoiseGenerator::Compute(
+    bool saturated_capture,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+        capture_spectrum,
+    rtc::ArrayView<FftData> lower_band_noise,
+    rtc::ArrayView<FftData> upper_band_noise) {
+  const auto& Y2 = capture_spectrum;
+
+  if (!saturated_capture) {
+    // Smooth Y2.
+    for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+      std::transform(Y2_smoothed_[ch].begin(), Y2_smoothed_[ch].end(),
+                     Y2[ch].begin(), Y2_smoothed_[ch].begin(),
+                     [](float a, float b) { return a + 0.1f * (b - a); });
+    }
+
+    if (N2_counter_ > 50) {
+      // Update N2 from Y2_smoothed.
+      for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+        std::transform(N2_[ch].begin(), N2_[ch].end(), Y2_smoothed_[ch].begin(),
+                       N2_[ch].begin(), [](float a, float b) {
+                         return b < a ? (0.9f * b + 0.1f * a) * 1.0002f
+                                      : a * 1.0002f;
+                       });
+      }
+    }
+
+    if (N2_initial_) {
+      if (++N2_counter_ == 1000) {
+        N2_initial_.reset();
+      } else {
+        // Compute the N2_initial from N2.
+        for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+          std::transform(N2_[ch].begin(), N2_[ch].end(),
+                         (*N2_initial_)[ch].begin(), (*N2_initial_)[ch].begin(),
+                         [](float a, float b) {
+                           return a > b ? b + 0.001f * (a - b) : a;
+                         });
+        }
+      }
+    }
+
+    for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+      for (auto& n : N2_[ch]) {
+        n = std::max(n, noise_floor_);
+      }
+      if (N2_initial_) {
+        for (auto& n : (*N2_initial_)[ch]) {
+          n = std::max(n, noise_floor_);
+        }
+      }
+    }
+  }
+
+  // Choose N2 estimate to use.
+  const auto& N2 = N2_initial_ ? (*N2_initial_) : N2_;
+
+  for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+    GenerateComfortNoise(optimization_, N2[ch], &seed_, &lower_band_noise[ch],
+                         &upper_band_noise[ch]);
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/comfort_noise_generator.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/comfort_noise_generator.h
new file mode 100644
index 0000000..16eaf35
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/comfort_noise_generator.h
@@ -0,0 +1,78 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_COMFORT_NOISE_GENERATOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_COMFORT_NOISE_GENERATOR_H_
+
+#include <stdint.h>
+
+#include <array>
+#include <memory>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/aec_state.h"
+#include "modules/audio_processing/aec3/fft_data.h"
+#include "rtc_base/constructor_magic.h"
+#include "rtc_base/system/arch.h"
+
+namespace webrtc {
+namespace aec3 {
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+
+void EstimateComfortNoise_SSE2(const std::array<float, kFftLengthBy2Plus1>& N2,
+                               uint32_t* seed,
+                               FftData* lower_band_noise,
+                               FftData* upper_band_noise);
+#endif
+void EstimateComfortNoise(const std::array<float, kFftLengthBy2Plus1>& N2,
+                          uint32_t* seed,
+                          FftData* lower_band_noise,
+                          FftData* upper_band_noise);
+
+}  // namespace aec3
+
+// Generates the comfort noise.
+class ComfortNoiseGenerator {
+ public:
+  ComfortNoiseGenerator(const EchoCanceller3Config& config,
+                        Aec3Optimization optimization,
+                        size_t num_capture_channels);
+  ComfortNoiseGenerator() = delete;
+  ~ComfortNoiseGenerator();
+  ComfortNoiseGenerator(const ComfortNoiseGenerator&) = delete;
+
+  // Computes the comfort noise.
+  void Compute(bool saturated_capture,
+               rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+                   capture_spectrum,
+               rtc::ArrayView<FftData> lower_band_noise,
+               rtc::ArrayView<FftData> upper_band_noise);
+
+  // Returns the estimate of the background noise spectrum.
+  rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> NoiseSpectrum()
+      const {
+    return N2_;
+  }
+
+ private:
+  const Aec3Optimization optimization_;
+  uint32_t seed_;
+  const size_t num_capture_channels_;
+  const float noise_floor_;
+  std::unique_ptr<std::vector<std::array<float, kFftLengthBy2Plus1>>>
+      N2_initial_;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> Y2_smoothed_;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> N2_;
+  int N2_counter_ = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_COMFORT_NOISE_GENERATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/comfort_noise_generator_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/comfort_noise_generator_unittest.cc
new file mode 100644
index 0000000..a9da175
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/comfort_noise_generator_unittest.cc
@@ -0,0 +1,72 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/comfort_noise_generator.h"
+
+#include <algorithm>
+#include <numeric>
+
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec_state.h"
+#include "rtc_base/random.h"
+#include "rtc_base/system/arch.h"
+#include "system_wrappers/include/cpu_features_wrapper.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace aec3 {
+namespace {
+
+float Power(const FftData& N) {
+  std::array<float, kFftLengthBy2Plus1> N2;
+  N.Spectrum(Aec3Optimization::kNone, N2);
+  return std::accumulate(N2.begin(), N2.end(), 0.f) / N2.size();
+}
+
+}  // namespace
+
+TEST(ComfortNoiseGenerator, CorrectLevel) {
+  constexpr size_t kNumChannels = 5;
+  EchoCanceller3Config config;
+  ComfortNoiseGenerator cng(config, DetectOptimization(), kNumChannels);
+  AecState aec_state(config, kNumChannels);
+
+  std::vector<std::array<float, kFftLengthBy2Plus1>> N2(kNumChannels);
+  std::vector<FftData> n_lower(kNumChannels);
+  std::vector<FftData> n_upper(kNumChannels);
+
+  for (size_t ch = 0; ch < kNumChannels; ++ch) {
+    N2[ch].fill(1000.f * 1000.f / (ch + 1));
+    n_lower[ch].re.fill(0.f);
+    n_lower[ch].im.fill(0.f);
+    n_upper[ch].re.fill(0.f);
+    n_upper[ch].im.fill(0.f);
+  }
+
+  // Ensure instantaneous updata to nonzero noise.
+  cng.Compute(false, N2, n_lower, n_upper);
+
+  for (size_t ch = 0; ch < kNumChannels; ++ch) {
+    EXPECT_LT(0.f, Power(n_lower[ch]));
+    EXPECT_LT(0.f, Power(n_upper[ch]));
+  }
+
+  for (int k = 0; k < 10000; ++k) {
+    cng.Compute(false, N2, n_lower, n_upper);
+  }
+
+  for (size_t ch = 0; ch < kNumChannels; ++ch) {
+    EXPECT_NEAR(2.f * N2[ch][0], Power(n_lower[ch]), N2[ch][0] / 10.f);
+    EXPECT_NEAR(2.f * N2[ch][0], Power(n_upper[ch]), N2[ch][0] / 10.f);
+  }
+}
+
+}  // namespace aec3
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/decimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/decimator.cc
new file mode 100644
index 0000000..bd03237
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/decimator.cc
@@ -0,0 +1,91 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "modules/audio_processing/aec3/decimator.h"
+
+#include <array>
+#include <vector>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+
+// signal.butter(2, 3400/8000.0, 'lowpass', analog=False)
+const std::vector<CascadedBiQuadFilter::BiQuadParam> GetLowPassFilterDS2() {
+  return std::vector<CascadedBiQuadFilter::BiQuadParam>{
+      {{-1.f, 0.f}, {0.13833231f, 0.40743176f}, 0.22711796393486466f},
+      {{-1.f, 0.f}, {0.13833231f, 0.40743176f}, 0.22711796393486466f},
+      {{-1.f, 0.f}, {0.13833231f, 0.40743176f}, 0.22711796393486466f}};
+}
+
+// signal.ellip(6, 1, 40, 1800/8000, btype='lowpass', analog=False)
+const std::vector<CascadedBiQuadFilter::BiQuadParam> GetLowPassFilterDS4() {
+  return std::vector<CascadedBiQuadFilter::BiQuadParam>{
+      {{-0.08873842f, 0.99605496f}, {0.75916227f, 0.23841065f}, 0.26250696827f},
+      {{0.62273832f, 0.78243018f}, {0.74892112f, 0.5410152f}, 0.26250696827f},
+      {{0.71107693f, 0.70311421f}, {0.74895534f, 0.63924616f}, 0.26250696827f}};
+}
+
+// signal.cheby1(1, 6, [1000/8000, 2000/8000], btype='bandpass', analog=False)
+const std::vector<CascadedBiQuadFilter::BiQuadParam> GetBandPassFilterDS8() {
+  return std::vector<CascadedBiQuadFilter::BiQuadParam>{
+      {{1.f, 0.f}, {0.7601815f, 0.46423542f}, 0.10330478266505948f, true},
+      {{1.f, 0.f}, {0.7601815f, 0.46423542f}, 0.10330478266505948f, true},
+      {{1.f, 0.f}, {0.7601815f, 0.46423542f}, 0.10330478266505948f, true},
+      {{1.f, 0.f}, {0.7601815f, 0.46423542f}, 0.10330478266505948f, true},
+      {{1.f, 0.f}, {0.7601815f, 0.46423542f}, 0.10330478266505948f, true}};
+}
+
+// signal.butter(2, 1000/8000.0, 'highpass', analog=False)
+const std::vector<CascadedBiQuadFilter::BiQuadParam> GetHighPassFilter() {
+  return std::vector<CascadedBiQuadFilter::BiQuadParam>{
+      {{1.f, 0.f}, {0.72712179f, 0.21296904f}, 0.7570763753338849f}};
+}
+
+const std::vector<CascadedBiQuadFilter::BiQuadParam> GetPassThroughFilter() {
+  return std::vector<CascadedBiQuadFilter::BiQuadParam>{};
+}
+}  // namespace
+
+Decimator::Decimator(size_t down_sampling_factor)
+    : down_sampling_factor_(down_sampling_factor),
+      anti_aliasing_filter_(down_sampling_factor_ == 4
+                                ? GetLowPassFilterDS4()
+                                : (down_sampling_factor_ == 8
+                                       ? GetBandPassFilterDS8()
+                                       : GetLowPassFilterDS2())),
+      noise_reduction_filter_(down_sampling_factor_ == 8
+                                  ? GetPassThroughFilter()
+                                  : GetHighPassFilter()) {
+  RTC_DCHECK(down_sampling_factor_ == 2 || down_sampling_factor_ == 4 ||
+             down_sampling_factor_ == 8);
+}
+
+void Decimator::Decimate(rtc::ArrayView<const float> in,
+                         rtc::ArrayView<float> out) {
+  RTC_DCHECK_EQ(kBlockSize, in.size());
+  RTC_DCHECK_EQ(kBlockSize / down_sampling_factor_, out.size());
+  std::array<float, kBlockSize> x;
+
+  // Limit the frequency content of the signal to avoid aliasing.
+  anti_aliasing_filter_.Process(in, x);
+
+  // Reduce the impact of near-end noise.
+  noise_reduction_filter_.Process(x);
+
+  // Downsample the signal.
+  for (size_t j = 0, k = 0; j < out.size(); ++j, k += down_sampling_factor_) {
+    RTC_DCHECK_GT(kBlockSize, k);
+    out[j] = x[k];
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/decimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/decimator.h
new file mode 100644
index 0000000..3ccd292
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/decimator.h
@@ -0,0 +1,41 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_DECIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_DECIMATOR_H_
+
+#include <array>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/utility/cascaded_biquad_filter.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+// Provides functionality for decimating a signal.
+class Decimator {
+ public:
+  explicit Decimator(size_t down_sampling_factor);
+
+  // Downsamples the signal.
+  void Decimate(rtc::ArrayView<const float> in, rtc::ArrayView<float> out);
+
+ private:
+  const size_t down_sampling_factor_;
+  CascadedBiQuadFilter anti_aliasing_filter_;
+  CascadedBiQuadFilter noise_reduction_filter_;
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(Decimator);
+};
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_DECIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/decimator_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/decimator_unittest.cc
new file mode 100644
index 0000000..e6f5ea0
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/decimator_unittest.cc
@@ -0,0 +1,135 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/decimator.h"
+
+#include <math.h>
+
+#include <algorithm>
+#include <array>
+#include <cmath>
+#include <cstring>
+#include <numeric>
+#include <string>
+#include <vector>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+namespace {
+
+std::string ProduceDebugText(int sample_rate_hz) {
+  rtc::StringBuilder ss;
+  ss << "Sample rate: " << sample_rate_hz;
+  return ss.Release();
+}
+
+constexpr size_t kDownSamplingFactors[] = {2, 4, 8};
+constexpr float kPi = 3.141592f;
+constexpr size_t kNumStartupBlocks = 50;
+constexpr size_t kNumBlocks = 1000;
+
+void ProduceDecimatedSinusoidalOutputPower(int sample_rate_hz,
+                                           size_t down_sampling_factor,
+                                           float sinusoidal_frequency_hz,
+                                           float* input_power,
+                                           float* output_power) {
+  float input[kBlockSize * kNumBlocks];
+  const size_t sub_block_size = kBlockSize / down_sampling_factor;
+
+  // Produce a sinusoid of the specified frequency.
+  for (size_t k = 0; k < kBlockSize * kNumBlocks; ++k) {
+    input[k] = 32767.f * std::sin(2.f * kPi * sinusoidal_frequency_hz * k /
+                                  sample_rate_hz);
+  }
+
+  Decimator decimator(down_sampling_factor);
+  std::vector<float> output(sub_block_size * kNumBlocks);
+
+  for (size_t k = 0; k < kNumBlocks; ++k) {
+    std::vector<float> sub_block(sub_block_size);
+    decimator.Decimate(
+        rtc::ArrayView<const float>(&input[k * kBlockSize], kBlockSize),
+        sub_block);
+
+    std::copy(sub_block.begin(), sub_block.end(),
+              output.begin() + k * sub_block_size);
+  }
+
+  ASSERT_GT(kNumBlocks, kNumStartupBlocks);
+  rtc::ArrayView<const float> input_to_evaluate(
+      &input[kNumStartupBlocks * kBlockSize],
+      (kNumBlocks - kNumStartupBlocks) * kBlockSize);
+  rtc::ArrayView<const float> output_to_evaluate(
+      &output[kNumStartupBlocks * sub_block_size],
+      (kNumBlocks - kNumStartupBlocks) * sub_block_size);
+  *input_power =
+      std::inner_product(input_to_evaluate.begin(), input_to_evaluate.end(),
+                         input_to_evaluate.begin(), 0.f) /
+      input_to_evaluate.size();
+  *output_power =
+      std::inner_product(output_to_evaluate.begin(), output_to_evaluate.end(),
+                         output_to_evaluate.begin(), 0.f) /
+      output_to_evaluate.size();
+}
+
+}  // namespace
+
+// Verifies that there is little aliasing from upper frequencies in the
+// downsampling.
+TEST(Decimator, NoLeakageFromUpperFrequencies) {
+  float input_power;
+  float output_power;
+  for (auto rate : {16000, 32000, 48000}) {
+    for (auto down_sampling_factor : kDownSamplingFactors) {
+      ProduceDebugText(rate);
+      ProduceDecimatedSinusoidalOutputPower(rate, down_sampling_factor,
+                                            3.f / 8.f * rate, &input_power,
+                                            &output_power);
+      EXPECT_GT(0.0001f * input_power, output_power);
+    }
+  }
+}
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+// Verifies the check for the input size.
+TEST(DecimatorDeathTest, WrongInputSize) {
+  Decimator decimator(4);
+  std::vector<float> x(kBlockSize - 1, 0.f);
+  std::array<float, kBlockSize / 4> x_downsampled;
+  EXPECT_DEATH(decimator.Decimate(x, x_downsampled), "");
+}
+
+// Verifies the check for non-null output parameter.
+TEST(DecimatorDeathTest, NullOutput) {
+  Decimator decimator(4);
+  std::vector<float> x(kBlockSize, 0.f);
+  EXPECT_DEATH(decimator.Decimate(x, nullptr), "");
+}
+
+// Verifies the check for the output size.
+TEST(DecimatorDeathTest, WrongOutputSize) {
+  Decimator decimator(4);
+  std::vector<float> x(kBlockSize, 0.f);
+  std::array<float, kBlockSize / 4 - 1> x_downsampled;
+  EXPECT_DEATH(decimator.Decimate(x, x_downsampled), "");
+}
+
+// Verifies the check for the correct downsampling factor.
+TEST(DecimatorDeathTest, CorrectDownSamplingFactor) {
+  EXPECT_DEATH(Decimator(3), "");
+}
+
+#endif
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/delay_estimate.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/delay_estimate.h
new file mode 100644
index 0000000..ea5dd27
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/delay_estimate.h
@@ -0,0 +1,31 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_DELAY_ESTIMATE_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_DELAY_ESTIMATE_H_
+
+namespace webrtc {
+
+// Stores delay_estimates.
+struct DelayEstimate {
+  enum class Quality { kCoarse, kRefined };
+
+  DelayEstimate(Quality quality, size_t delay)
+      : quality(quality), delay(delay) {}
+
+  Quality quality;
+  size_t delay;
+  size_t blocks_since_last_change = 0;
+  size_t blocks_since_last_update = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_DELAY_ESTIMATE_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/dominant_nearend_detector.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/dominant_nearend_detector.cc
new file mode 100644
index 0000000..40073cf
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/dominant_nearend_detector.cc
@@ -0,0 +1,75 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/dominant_nearend_detector.h"
+
+#include <numeric>
+
+namespace webrtc {
+DominantNearendDetector::DominantNearendDetector(
+    const EchoCanceller3Config::Suppressor::DominantNearendDetection& config,
+    size_t num_capture_channels)
+    : enr_threshold_(config.enr_threshold),
+      enr_exit_threshold_(config.enr_exit_threshold),
+      snr_threshold_(config.snr_threshold),
+      hold_duration_(config.hold_duration),
+      trigger_threshold_(config.trigger_threshold),
+      use_during_initial_phase_(config.use_during_initial_phase),
+      num_capture_channels_(num_capture_channels),
+      trigger_counters_(num_capture_channels_),
+      hold_counters_(num_capture_channels_) {}
+
+void DominantNearendDetector::Update(
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+        nearend_spectrum,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+        residual_echo_spectrum,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+        comfort_noise_spectrum,
+    bool initial_state) {
+  nearend_state_ = false;
+
+  auto low_frequency_energy = [](rtc::ArrayView<const float> spectrum) {
+    RTC_DCHECK_LE(16, spectrum.size());
+    return std::accumulate(spectrum.begin() + 1, spectrum.begin() + 16, 0.f);
+  };
+
+  for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+    const float ne_sum = low_frequency_energy(nearend_spectrum[ch]);
+    const float echo_sum = low_frequency_energy(residual_echo_spectrum[ch]);
+    const float noise_sum = low_frequency_energy(comfort_noise_spectrum[ch]);
+
+    // Detect strong active nearend if the nearend is sufficiently stronger than
+    // the echo and the nearend noise.
+    if ((!initial_state || use_during_initial_phase_) &&
+        echo_sum < enr_threshold_ * ne_sum &&
+        ne_sum > snr_threshold_ * noise_sum) {
+      if (++trigger_counters_[ch] >= trigger_threshold_) {
+        // After a period of strong active nearend activity, flag nearend mode.
+        hold_counters_[ch] = hold_duration_;
+        trigger_counters_[ch] = trigger_threshold_;
+      }
+    } else {
+      // Forget previously detected strong active nearend activity.
+      trigger_counters_[ch] = std::max(0, trigger_counters_[ch] - 1);
+    }
+
+    // Exit nearend-state early at strong echo.
+    if (echo_sum > enr_exit_threshold_ * ne_sum &&
+        echo_sum > snr_threshold_ * noise_sum) {
+      hold_counters_[ch] = 0;
+    }
+
+    // Remain in any nearend mode for a certain duration.
+    hold_counters_[ch] = std::max(0, hold_counters_[ch] - 1);
+    nearend_state_ = nearend_state_ || hold_counters_[ch] > 0;
+  }
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/dominant_nearend_detector.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/dominant_nearend_detector.h
new file mode 100644
index 0000000..046d148
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/dominant_nearend_detector.h
@@ -0,0 +1,56 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_DOMINANT_NEAREND_DETECTOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_DOMINANT_NEAREND_DETECTOR_H_
+
+#include <vector>
+
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/nearend_detector.h"
+
+namespace webrtc {
+// Class for selecting whether the suppressor is in the nearend or echo state.
+class DominantNearendDetector : public NearendDetector {
+ public:
+  DominantNearendDetector(
+      const EchoCanceller3Config::Suppressor::DominantNearendDetection& config,
+      size_t num_capture_channels);
+
+  // Returns whether the current state is the nearend state.
+  bool IsNearendState() const override { return nearend_state_; }
+
+  // Updates the state selection based on latest spectral estimates.
+  void Update(rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+                  nearend_spectrum,
+              rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+                  residual_echo_spectrum,
+              rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+                  comfort_noise_spectrum,
+              bool initial_state) override;
+
+ private:
+  const float enr_threshold_;
+  const float enr_exit_threshold_;
+  const float snr_threshold_;
+  const int hold_duration_;
+  const int trigger_threshold_;
+  const bool use_during_initial_phase_;
+  const size_t num_capture_channels_;
+
+  bool nearend_state_ = false;
+  std::vector<int> trigger_counters_;
+  std::vector<int> hold_counters_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_DOMINANT_NEAREND_DETECTOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/downsampled_render_buffer.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/downsampled_render_buffer.cc
new file mode 100644
index 0000000..c105911
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/downsampled_render_buffer.cc
@@ -0,0 +1,25 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/downsampled_render_buffer.h"
+
+#include <algorithm>
+
+namespace webrtc {
+
+DownsampledRenderBuffer::DownsampledRenderBuffer(size_t downsampled_buffer_size)
+    : size(static_cast<int>(downsampled_buffer_size)),
+      buffer(downsampled_buffer_size, 0.f) {
+  std::fill(buffer.begin(), buffer.end(), 0.f);
+}
+
+DownsampledRenderBuffer::~DownsampledRenderBuffer() = default;
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/downsampled_render_buffer.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/downsampled_render_buffer.h
new file mode 100644
index 0000000..fbdc9b4
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/downsampled_render_buffer.h
@@ -0,0 +1,58 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_DOWNSAMPLED_RENDER_BUFFER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_DOWNSAMPLED_RENDER_BUFFER_H_
+
+#include <stddef.h>
+
+#include <vector>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+// Holds the circular buffer of the downsampled render data.
+struct DownsampledRenderBuffer {
+  explicit DownsampledRenderBuffer(size_t downsampled_buffer_size);
+  ~DownsampledRenderBuffer();
+
+  int IncIndex(int index) const {
+    RTC_DCHECK_EQ(buffer.size(), static_cast<size_t>(size));
+    return index < size - 1 ? index + 1 : 0;
+  }
+
+  int DecIndex(int index) const {
+    RTC_DCHECK_EQ(buffer.size(), static_cast<size_t>(size));
+    return index > 0 ? index - 1 : size - 1;
+  }
+
+  int OffsetIndex(int index, int offset) const {
+    RTC_DCHECK_GE(buffer.size(), offset);
+    RTC_DCHECK_EQ(buffer.size(), static_cast<size_t>(size));
+    return (size + index + offset) % size;
+  }
+
+  void UpdateWriteIndex(int offset) { write = OffsetIndex(write, offset); }
+  void IncWriteIndex() { write = IncIndex(write); }
+  void DecWriteIndex() { write = DecIndex(write); }
+  void UpdateReadIndex(int offset) { read = OffsetIndex(read, offset); }
+  void IncReadIndex() { read = IncIndex(read); }
+  void DecReadIndex() { read = DecIndex(read); }
+
+  const int size;
+  std::vector<float> buffer;
+  int write = 0;
+  int read = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_DOWNSAMPLED_RENDER_BUFFER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_audibility.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_audibility.cc
new file mode 100644
index 0000000..6ae414e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_audibility.cc
@@ -0,0 +1,118 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/echo_audibility.h"
+
+#include <algorithm>
+#include <cmath>
+#include <utility>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/block_buffer.h"
+#include "modules/audio_processing/aec3/spectrum_buffer.h"
+#include "modules/audio_processing/aec3/stationarity_estimator.h"
+
+namespace webrtc {
+
+EchoAudibility::EchoAudibility(bool use_render_stationarity_at_init)
+    : use_render_stationarity_at_init_(use_render_stationarity_at_init) {
+  Reset();
+}
+
+EchoAudibility::~EchoAudibility() = default;
+
+void EchoAudibility::Update(const RenderBuffer& render_buffer,
+                            rtc::ArrayView<const float> average_reverb,
+                            int delay_blocks,
+                            bool external_delay_seen) {
+  UpdateRenderNoiseEstimator(render_buffer.GetSpectrumBuffer(),
+                             render_buffer.GetBlockBuffer(),
+                             external_delay_seen);
+
+  if (external_delay_seen || use_render_stationarity_at_init_) {
+    UpdateRenderStationarityFlags(render_buffer, average_reverb, delay_blocks);
+  }
+}
+
+void EchoAudibility::Reset() {
+  render_stationarity_.Reset();
+  non_zero_render_seen_ = false;
+  render_spectrum_write_prev_ = absl::nullopt;
+}
+
+void EchoAudibility::UpdateRenderStationarityFlags(
+    const RenderBuffer& render_buffer,
+    rtc::ArrayView<const float> average_reverb,
+    int min_channel_delay_blocks) {
+  const SpectrumBuffer& spectrum_buffer = render_buffer.GetSpectrumBuffer();
+  int idx_at_delay = spectrum_buffer.OffsetIndex(spectrum_buffer.read,
+                                                 min_channel_delay_blocks);
+
+  int num_lookahead = render_buffer.Headroom() - min_channel_delay_blocks + 1;
+  num_lookahead = std::max(0, num_lookahead);
+
+  render_stationarity_.UpdateStationarityFlags(spectrum_buffer, average_reverb,
+                                               idx_at_delay, num_lookahead);
+}
+
+void EchoAudibility::UpdateRenderNoiseEstimator(
+    const SpectrumBuffer& spectrum_buffer,
+    const BlockBuffer& block_buffer,
+    bool external_delay_seen) {
+  if (!render_spectrum_write_prev_) {
+    render_spectrum_write_prev_ = spectrum_buffer.write;
+    render_block_write_prev_ = block_buffer.write;
+    return;
+  }
+  int render_spectrum_write_current = spectrum_buffer.write;
+  if (!non_zero_render_seen_ && !external_delay_seen) {
+    non_zero_render_seen_ = !IsRenderTooLow(block_buffer);
+  }
+  if (non_zero_render_seen_) {
+    for (int idx = render_spectrum_write_prev_.value();
+         idx != render_spectrum_write_current;
+         idx = spectrum_buffer.DecIndex(idx)) {
+      render_stationarity_.UpdateNoiseEstimator(spectrum_buffer.buffer[idx]);
+    }
+  }
+  render_spectrum_write_prev_ = render_spectrum_write_current;
+}
+
+bool EchoAudibility::IsRenderTooLow(const BlockBuffer& block_buffer) {
+  const int num_render_channels =
+      static_cast<int>(block_buffer.buffer[0][0].size());
+  bool too_low = false;
+  const int render_block_write_current = block_buffer.write;
+  if (render_block_write_current == render_block_write_prev_) {
+    too_low = true;
+  } else {
+    for (int idx = render_block_write_prev_; idx != render_block_write_current;
+         idx = block_buffer.IncIndex(idx)) {
+      float max_abs_over_channels = 0.f;
+      for (int ch = 0; ch < num_render_channels; ++ch) {
+        auto block = block_buffer.buffer[idx][0][ch];
+        auto r = std::minmax_element(block.cbegin(), block.cend());
+        float max_abs_channel =
+            std::max(std::fabs(*r.first), std::fabs(*r.second));
+        max_abs_over_channels =
+            std::max(max_abs_over_channels, max_abs_channel);
+      }
+      if (max_abs_over_channels < 10.f) {
+        too_low = true;  // Discards all blocks if one of them is too low.
+        break;
+      }
+    }
+  }
+  render_block_write_prev_ = render_block_write_current;
+  return too_low;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_audibility.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_audibility.h
new file mode 100644
index 0000000..1ffc017
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_audibility.h
@@ -0,0 +1,86 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_ECHO_AUDIBILITY_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_ECHO_AUDIBILITY_H_
+
+#include <stddef.h>
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/block_buffer.h"
+#include "modules/audio_processing/aec3/render_buffer.h"
+#include "modules/audio_processing/aec3/spectrum_buffer.h"
+#include "modules/audio_processing/aec3/stationarity_estimator.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+class EchoAudibility {
+ public:
+  explicit EchoAudibility(bool use_render_stationarity_at_init);
+  ~EchoAudibility();
+
+  EchoAudibility(const EchoAudibility&) = delete;
+  EchoAudibility& operator=(const EchoAudibility&) = delete;
+
+  // Feed new render data to the echo audibility estimator.
+  void Update(const RenderBuffer& render_buffer,
+              rtc::ArrayView<const float> average_reverb,
+              int min_channel_delay_blocks,
+              bool external_delay_seen);
+  // Get the residual echo scaling.
+  void GetResidualEchoScaling(bool filter_has_had_time_to_converge,
+                              rtc::ArrayView<float> residual_scaling) const {
+    for (size_t band = 0; band < residual_scaling.size(); ++band) {
+      if (render_stationarity_.IsBandStationary(band) &&
+          (filter_has_had_time_to_converge ||
+           use_render_stationarity_at_init_)) {
+        residual_scaling[band] = 0.f;
+      } else {
+        residual_scaling[band] = 1.0f;
+      }
+    }
+  }
+
+  // Returns true if the current render block is estimated as stationary.
+  bool IsBlockStationary() const {
+    return render_stationarity_.IsBlockStationary();
+  }
+
+ private:
+  // Reset the EchoAudibility class.
+  void Reset();
+
+  // Updates the render stationarity flags for the current frame.
+  void UpdateRenderStationarityFlags(const RenderBuffer& render_buffer,
+                                     rtc::ArrayView<const float> average_reverb,
+                                     int delay_blocks);
+
+  // Updates the noise estimator with the new render data since the previous
+  // call to this method.
+  void UpdateRenderNoiseEstimator(const SpectrumBuffer& spectrum_buffer,
+                                  const BlockBuffer& block_buffer,
+                                  bool external_delay_seen);
+
+  // Returns a bool being true if the render signal contains just close to zero
+  // values.
+  bool IsRenderTooLow(const BlockBuffer& block_buffer);
+
+  absl::optional<int> render_spectrum_write_prev_;
+  int render_block_write_prev_;
+  bool non_zero_render_seen_;
+  const bool use_render_stationarity_at_init_;
+  StationarityEstimator render_stationarity_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_ECHO_AUDIBILITY_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_canceller3.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_canceller3.cc
new file mode 100644
index 0000000..35a2cff
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_canceller3.cc
@@ -0,0 +1,887 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "modules/audio_processing/aec3/echo_canceller3.h"
+
+#include <algorithm>
+#include <utility>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/high_pass_filter.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/atomic_ops.h"
+#include "rtc_base/experiments/field_trial_parser.h"
+#include "rtc_base/logging.h"
+#include "system_wrappers/include/field_trial.h"
+
+namespace webrtc {
+
+namespace {
+
+enum class EchoCanceller3ApiCall { kCapture, kRender };
+
+bool DetectSaturation(rtc::ArrayView<const float> y) {
+  for (auto y_k : y) {
+    if (y_k >= 32700.0f || y_k <= -32700.0f) {
+      return true;
+    }
+  }
+  return false;
+}
+
+// Retrieves a value from a field trial if it is available. If no value is
+// present, the default value is returned. If the retrieved value is beyond the
+// specified limits, the default value is returned instead.
+void RetrieveFieldTrialValue(const char* trial_name,
+                             float min,
+                             float max,
+                             float* value_to_update) {
+  const std::string field_trial_str = field_trial::FindFullName(trial_name);
+
+  FieldTrialParameter<double> field_trial_param(/*key=*/"", *value_to_update);
+
+  ParseFieldTrial({&field_trial_param}, field_trial_str);
+  float field_trial_value = static_cast<float>(field_trial_param.Get());
+
+  if (field_trial_value >= min && field_trial_value <= max) {
+    *value_to_update = field_trial_value;
+  }
+}
+
+void RetrieveFieldTrialValue(const char* trial_name,
+                             int min,
+                             int max,
+                             int* value_to_update) {
+  const std::string field_trial_str = field_trial::FindFullName(trial_name);
+
+  FieldTrialParameter<int> field_trial_param(/*key=*/"", *value_to_update);
+
+  ParseFieldTrial({&field_trial_param}, field_trial_str);
+  float field_trial_value = field_trial_param.Get();
+
+  if (field_trial_value >= min && field_trial_value <= max) {
+    *value_to_update = field_trial_value;
+  }
+}
+
+void FillSubFrameView(
+    AudioBuffer* frame,
+    size_t sub_frame_index,
+    std::vector<std::vector<rtc::ArrayView<float>>>* sub_frame_view) {
+  RTC_DCHECK_GE(1, sub_frame_index);
+  RTC_DCHECK_LE(0, sub_frame_index);
+  RTC_DCHECK_EQ(frame->num_bands(), sub_frame_view->size());
+  RTC_DCHECK_EQ(frame->num_channels(), (*sub_frame_view)[0].size());
+  for (size_t band = 0; band < sub_frame_view->size(); ++band) {
+    for (size_t channel = 0; channel < (*sub_frame_view)[0].size(); ++channel) {
+      (*sub_frame_view)[band][channel] = rtc::ArrayView<float>(
+          &frame->split_bands(channel)[band][sub_frame_index * kSubFrameLength],
+          kSubFrameLength);
+    }
+  }
+}
+
+void FillSubFrameView(
+    std::vector<std::vector<std::vector<float>>>* frame,
+    size_t sub_frame_index,
+    std::vector<std::vector<rtc::ArrayView<float>>>* sub_frame_view) {
+  RTC_DCHECK_GE(1, sub_frame_index);
+  RTC_DCHECK_EQ(frame->size(), sub_frame_view->size());
+  RTC_DCHECK_EQ((*frame)[0].size(), (*sub_frame_view)[0].size());
+  for (size_t band = 0; band < frame->size(); ++band) {
+    for (size_t channel = 0; channel < (*frame)[band].size(); ++channel) {
+      (*sub_frame_view)[band][channel] = rtc::ArrayView<float>(
+          &(*frame)[band][channel][sub_frame_index * kSubFrameLength],
+          kSubFrameLength);
+    }
+  }
+}
+
+void ProcessCaptureFrameContent(
+    AudioBuffer* linear_output,
+    AudioBuffer* capture,
+    bool level_change,
+    bool saturated_microphone_signal,
+    size_t sub_frame_index,
+    FrameBlocker* capture_blocker,
+    BlockFramer* linear_output_framer,
+    BlockFramer* output_framer,
+    BlockProcessor* block_processor,
+    std::vector<std::vector<std::vector<float>>>* linear_output_block,
+    std::vector<std::vector<rtc::ArrayView<float>>>*
+        linear_output_sub_frame_view,
+    std::vector<std::vector<std::vector<float>>>* capture_block,
+    std::vector<std::vector<rtc::ArrayView<float>>>* capture_sub_frame_view) {
+  FillSubFrameView(capture, sub_frame_index, capture_sub_frame_view);
+
+  if (linear_output) {
+    RTC_DCHECK(linear_output_framer);
+    RTC_DCHECK(linear_output_block);
+    RTC_DCHECK(linear_output_sub_frame_view);
+    FillSubFrameView(linear_output, sub_frame_index,
+                     linear_output_sub_frame_view);
+  }
+
+  capture_blocker->InsertSubFrameAndExtractBlock(*capture_sub_frame_view,
+                                                 capture_block);
+  block_processor->ProcessCapture(level_change, saturated_microphone_signal,
+                                  linear_output_block, capture_block);
+  output_framer->InsertBlockAndExtractSubFrame(*capture_block,
+                                               capture_sub_frame_view);
+
+  if (linear_output) {
+    RTC_DCHECK(linear_output_framer);
+    linear_output_framer->InsertBlockAndExtractSubFrame(
+        *linear_output_block, linear_output_sub_frame_view);
+  }
+}
+
+void ProcessRemainingCaptureFrameContent(
+    bool level_change,
+    bool saturated_microphone_signal,
+    FrameBlocker* capture_blocker,
+    BlockFramer* linear_output_framer,
+    BlockFramer* output_framer,
+    BlockProcessor* block_processor,
+    std::vector<std::vector<std::vector<float>>>* linear_output_block,
+    std::vector<std::vector<std::vector<float>>>* block) {
+  if (!capture_blocker->IsBlockAvailable()) {
+    return;
+  }
+
+  capture_blocker->ExtractBlock(block);
+  block_processor->ProcessCapture(level_change, saturated_microphone_signal,
+                                  linear_output_block, block);
+  output_framer->InsertBlock(*block);
+
+  if (linear_output_framer) {
+    RTC_DCHECK(linear_output_block);
+    linear_output_framer->InsertBlock(*linear_output_block);
+  }
+}
+
+void BufferRenderFrameContent(
+    std::vector<std::vector<std::vector<float>>>* render_frame,
+    size_t sub_frame_index,
+    FrameBlocker* render_blocker,
+    BlockProcessor* block_processor,
+    std::vector<std::vector<std::vector<float>>>* block,
+    std::vector<std::vector<rtc::ArrayView<float>>>* sub_frame_view) {
+  FillSubFrameView(render_frame, sub_frame_index, sub_frame_view);
+  render_blocker->InsertSubFrameAndExtractBlock(*sub_frame_view, block);
+  block_processor->BufferRender(*block);
+}
+
+void BufferRemainingRenderFrameContent(
+    FrameBlocker* render_blocker,
+    BlockProcessor* block_processor,
+    std::vector<std::vector<std::vector<float>>>* block) {
+  if (!render_blocker->IsBlockAvailable()) {
+    return;
+  }
+  render_blocker->ExtractBlock(block);
+  block_processor->BufferRender(*block);
+}
+
+void CopyBufferIntoFrame(const AudioBuffer& buffer,
+                         size_t num_bands,
+                         size_t num_channels,
+                         std::vector<std::vector<std::vector<float>>>* frame) {
+  RTC_DCHECK_EQ(num_bands, frame->size());
+  RTC_DCHECK_EQ(num_channels, (*frame)[0].size());
+  RTC_DCHECK_EQ(AudioBuffer::kSplitBandSize, (*frame)[0][0].size());
+  for (size_t band = 0; band < num_bands; ++band) {
+    for (size_t channel = 0; channel < num_channels; ++channel) {
+      rtc::ArrayView<const float> buffer_view(
+          &buffer.split_bands_const(channel)[band][0],
+          AudioBuffer::kSplitBandSize);
+      std::copy(buffer_view.begin(), buffer_view.end(),
+                (*frame)[band][channel].begin());
+    }
+  }
+}
+
+}  // namespace
+
+// TODO(webrtc:5298): Move this to a separate file.
+EchoCanceller3Config AdjustConfig(const EchoCanceller3Config& config) {
+  EchoCanceller3Config adjusted_cfg = config;
+
+  if (field_trial::IsEnabled("WebRTC-Aec3AntiHowlingMinimizationKillSwitch")) {
+    adjusted_cfg.suppressor.high_bands_suppression
+        .anti_howling_activation_threshold = 25.f;
+    adjusted_cfg.suppressor.high_bands_suppression.anti_howling_gain = 0.01f;
+  }
+
+  if (field_trial::IsEnabled("WebRTC-Aec3UseShortConfigChangeDuration")) {
+    adjusted_cfg.filter.config_change_duration_blocks = 10;
+  }
+
+  if (field_trial::IsEnabled("WebRTC-Aec3UseZeroInitialStateDuration")) {
+    adjusted_cfg.filter.initial_state_seconds = 0.f;
+  } else if (field_trial::IsEnabled(
+                 "WebRTC-Aec3UseDot1SecondsInitialStateDuration")) {
+    adjusted_cfg.filter.initial_state_seconds = .1f;
+  } else if (field_trial::IsEnabled(
+                 "WebRTC-Aec3UseDot2SecondsInitialStateDuration")) {
+    adjusted_cfg.filter.initial_state_seconds = .2f;
+  } else if (field_trial::IsEnabled(
+                 "WebRTC-Aec3UseDot3SecondsInitialStateDuration")) {
+    adjusted_cfg.filter.initial_state_seconds = .3f;
+  } else if (field_trial::IsEnabled(
+                 "WebRTC-Aec3UseDot6SecondsInitialStateDuration")) {
+    adjusted_cfg.filter.initial_state_seconds = .6f;
+  } else if (field_trial::IsEnabled(
+                 "WebRTC-Aec3UseDot9SecondsInitialStateDuration")) {
+    adjusted_cfg.filter.initial_state_seconds = .9f;
+  } else if (field_trial::IsEnabled(
+                 "WebRTC-Aec3Use1Dot2SecondsInitialStateDuration")) {
+    adjusted_cfg.filter.initial_state_seconds = 1.2f;
+  } else if (field_trial::IsEnabled(
+                 "WebRTC-Aec3Use1Dot6SecondsInitialStateDuration")) {
+    adjusted_cfg.filter.initial_state_seconds = 1.6f;
+  } else if (field_trial::IsEnabled(
+                 "WebRTC-Aec3Use2Dot0SecondsInitialStateDuration")) {
+    adjusted_cfg.filter.initial_state_seconds = 2.0f;
+  }
+
+  if (field_trial::IsEnabled("WebRTC-Aec3HighPassFilterEchoReference")) {
+    adjusted_cfg.filter.high_pass_filter_echo_reference = true;
+  }
+
+  if (field_trial::IsEnabled("WebRTC-Aec3EchoSaturationDetectionKillSwitch")) {
+    adjusted_cfg.ep_strength.echo_can_saturate = false;
+  }
+
+  if (field_trial::IsEnabled("WebRTC-Aec3UseDot2ReverbDefaultLen")) {
+    adjusted_cfg.ep_strength.default_len = 0.2f;
+  } else if (field_trial::IsEnabled("WebRTC-Aec3UseDot3ReverbDefaultLen")) {
+    adjusted_cfg.ep_strength.default_len = 0.3f;
+  } else if (field_trial::IsEnabled("WebRTC-Aec3UseDot4ReverbDefaultLen")) {
+    adjusted_cfg.ep_strength.default_len = 0.4f;
+  } else if (field_trial::IsEnabled("WebRTC-Aec3UseDot5ReverbDefaultLen")) {
+    adjusted_cfg.ep_strength.default_len = 0.5f;
+  } else if (field_trial::IsEnabled("WebRTC-Aec3UseDot6ReverbDefaultLen")) {
+    adjusted_cfg.ep_strength.default_len = 0.6f;
+  } else if (field_trial::IsEnabled("WebRTC-Aec3UseDot7ReverbDefaultLen")) {
+    adjusted_cfg.ep_strength.default_len = 0.7f;
+  } else if (field_trial::IsEnabled("WebRTC-Aec3UseDot8ReverbDefaultLen")) {
+    adjusted_cfg.ep_strength.default_len = 0.8f;
+  }
+
+  if (field_trial::IsEnabled("WebRTC-Aec3ShortHeadroomKillSwitch")) {
+    // Two blocks headroom.
+    adjusted_cfg.delay.delay_headroom_samples = kBlockSize * 2;
+  }
+
+  if (field_trial::IsEnabled("WebRTC-Aec3ClampInstQualityToZeroKillSwitch")) {
+    adjusted_cfg.erle.clamp_quality_estimate_to_zero = false;
+  }
+
+  if (field_trial::IsEnabled("WebRTC-Aec3ClampInstQualityToOneKillSwitch")) {
+    adjusted_cfg.erle.clamp_quality_estimate_to_one = false;
+  }
+
+  if (field_trial::IsEnabled("WebRTC-Aec3OnsetDetectionKillSwitch")) {
+    adjusted_cfg.erle.onset_detection = false;
+  }
+
+  if (field_trial::IsEnabled(
+          "WebRTC-Aec3EnforceRenderDelayEstimationDownmixing")) {
+    adjusted_cfg.delay.render_alignment_mixing.downmix = true;
+    adjusted_cfg.delay.render_alignment_mixing.adaptive_selection = false;
+  }
+
+  if (field_trial::IsEnabled(
+          "WebRTC-Aec3EnforceCaptureDelayEstimationDownmixing")) {
+    adjusted_cfg.delay.capture_alignment_mixing.downmix = true;
+    adjusted_cfg.delay.capture_alignment_mixing.adaptive_selection = false;
+  }
+
+  if (field_trial::IsEnabled(
+          "WebRTC-Aec3EnforceCaptureDelayEstimationLeftRightPrioritization")) {
+    adjusted_cfg.delay.capture_alignment_mixing.prefer_first_two_channels =
+        true;
+  }
+
+  if (field_trial::IsEnabled(
+          "WebRTC-"
+          "Aec3RenderDelayEstimationLeftRightPrioritizationKillSwitch")) {
+    adjusted_cfg.delay.capture_alignment_mixing.prefer_first_two_channels =
+        false;
+  }
+
+  if (field_trial::IsEnabled("WebRTC-Aec3SensitiveDominantNearendActivation")) {
+    adjusted_cfg.suppressor.dominant_nearend_detection.enr_threshold = 0.5f;
+  } else if (field_trial::IsEnabled(
+                 "WebRTC-Aec3VerySensitiveDominantNearendActivation")) {
+    adjusted_cfg.suppressor.dominant_nearend_detection.enr_threshold = 0.75f;
+  }
+
+  if (field_trial::IsEnabled("WebRTC-Aec3TransparentAntiHowlingGain")) {
+    adjusted_cfg.suppressor.high_bands_suppression.anti_howling_gain = 1.f;
+  }
+
+  if (field_trial::IsEnabled(
+          "WebRTC-Aec3EnforceMoreTransparentNormalSuppressorTuning")) {
+    adjusted_cfg.suppressor.normal_tuning.mask_lf.enr_transparent = 0.4f;
+    adjusted_cfg.suppressor.normal_tuning.mask_lf.enr_suppress = 0.5f;
+  }
+
+  if (field_trial::IsEnabled(
+          "WebRTC-Aec3EnforceMoreTransparentNearendSuppressorTuning")) {
+    adjusted_cfg.suppressor.nearend_tuning.mask_lf.enr_transparent = 1.29f;
+    adjusted_cfg.suppressor.nearend_tuning.mask_lf.enr_suppress = 1.3f;
+  }
+
+  if (field_trial::IsEnabled(
+          "WebRTC-Aec3EnforceMoreTransparentNormalSuppressorHfTuning")) {
+    adjusted_cfg.suppressor.normal_tuning.mask_hf.enr_transparent = 0.3f;
+    adjusted_cfg.suppressor.normal_tuning.mask_hf.enr_suppress = 0.4f;
+  }
+
+  if (field_trial::IsEnabled(
+          "WebRTC-Aec3EnforceMoreTransparentNearendSuppressorHfTuning")) {
+    adjusted_cfg.suppressor.nearend_tuning.mask_hf.enr_transparent = 1.09f;
+    adjusted_cfg.suppressor.nearend_tuning.mask_hf.enr_suppress = 1.1f;
+  }
+
+  if (field_trial::IsEnabled(
+          "WebRTC-Aec3EnforceRapidlyAdjustingNormalSuppressorTunings")) {
+    adjusted_cfg.suppressor.normal_tuning.max_inc_factor = 2.5f;
+  }
+
+  if (field_trial::IsEnabled(
+          "WebRTC-Aec3EnforceRapidlyAdjustingNearendSuppressorTunings")) {
+    adjusted_cfg.suppressor.nearend_tuning.max_inc_factor = 2.5f;
+  }
+
+  if (field_trial::IsEnabled(
+          "WebRTC-Aec3EnforceSlowlyAdjustingNormalSuppressorTunings")) {
+    adjusted_cfg.suppressor.normal_tuning.max_dec_factor_lf = .2f;
+  }
+
+  if (field_trial::IsEnabled(
+          "WebRTC-Aec3EnforceSlowlyAdjustingNearendSuppressorTunings")) {
+    adjusted_cfg.suppressor.nearend_tuning.max_dec_factor_lf = .2f;
+  }
+
+  if (field_trial::IsEnabled("WebRTC-Aec3EnforceConservativeHfSuppression")) {
+    adjusted_cfg.suppressor.conservative_hf_suppression = true;
+  }
+
+  if (field_trial::IsEnabled("WebRTC-Aec3EnforceStationarityProperties")) {
+    adjusted_cfg.echo_audibility.use_stationarity_properties = true;
+  }
+
+  if (field_trial::IsEnabled(
+          "WebRTC-Aec3EnforceStationarityPropertiesAtInit")) {
+    adjusted_cfg.echo_audibility.use_stationarity_properties_at_init = true;
+  }
+
+  if (field_trial::IsEnabled("WebRTC-Aec3EnforceLowActiveRenderLimit")) {
+    adjusted_cfg.render_levels.active_render_limit = 50.f;
+  } else if (field_trial::IsEnabled(
+                 "WebRTC-Aec3EnforceVeryLowActiveRenderLimit")) {
+    adjusted_cfg.render_levels.active_render_limit = 30.f;
+  }
+
+  if (field_trial::IsEnabled("WebRTC-Aec3NonlinearModeReverbKillSwitch")) {
+    adjusted_cfg.echo_model.model_reverb_in_nonlinear_mode = false;
+  }
+
+  // Field-trial based override for the whole suppressor tuning.
+  const std::string suppressor_tuning_override_trial_name =
+      field_trial::FindFullName("WebRTC-Aec3SuppressorTuningOverride");
+
+  FieldTrialParameter<double> nearend_tuning_mask_lf_enr_transparent(
+      "nearend_tuning_mask_lf_enr_transparent",
+      adjusted_cfg.suppressor.nearend_tuning.mask_lf.enr_transparent);
+  FieldTrialParameter<double> nearend_tuning_mask_lf_enr_suppress(
+      "nearend_tuning_mask_lf_enr_suppress",
+      adjusted_cfg.suppressor.nearend_tuning.mask_lf.enr_suppress);
+  FieldTrialParameter<double> nearend_tuning_mask_hf_enr_transparent(
+      "nearend_tuning_mask_hf_enr_transparent",
+      adjusted_cfg.suppressor.nearend_tuning.mask_hf.enr_transparent);
+  FieldTrialParameter<double> nearend_tuning_mask_hf_enr_suppress(
+      "nearend_tuning_mask_hf_enr_suppress",
+      adjusted_cfg.suppressor.nearend_tuning.mask_hf.enr_suppress);
+  FieldTrialParameter<double> nearend_tuning_max_inc_factor(
+      "nearend_tuning_max_inc_factor",
+      adjusted_cfg.suppressor.nearend_tuning.max_inc_factor);
+  FieldTrialParameter<double> nearend_tuning_max_dec_factor_lf(
+      "nearend_tuning_max_dec_factor_lf",
+      adjusted_cfg.suppressor.nearend_tuning.max_dec_factor_lf);
+  FieldTrialParameter<double> normal_tuning_mask_lf_enr_transparent(
+      "normal_tuning_mask_lf_enr_transparent",
+      adjusted_cfg.suppressor.normal_tuning.mask_lf.enr_transparent);
+  FieldTrialParameter<double> normal_tuning_mask_lf_enr_suppress(
+      "normal_tuning_mask_lf_enr_suppress",
+      adjusted_cfg.suppressor.normal_tuning.mask_lf.enr_suppress);
+  FieldTrialParameter<double> normal_tuning_mask_hf_enr_transparent(
+      "normal_tuning_mask_hf_enr_transparent",
+      adjusted_cfg.suppressor.normal_tuning.mask_hf.enr_transparent);
+  FieldTrialParameter<double> normal_tuning_mask_hf_enr_suppress(
+      "normal_tuning_mask_hf_enr_suppress",
+      adjusted_cfg.suppressor.normal_tuning.mask_hf.enr_suppress);
+  FieldTrialParameter<double> normal_tuning_max_inc_factor(
+      "normal_tuning_max_inc_factor",
+      adjusted_cfg.suppressor.normal_tuning.max_inc_factor);
+  FieldTrialParameter<double> normal_tuning_max_dec_factor_lf(
+      "normal_tuning_max_dec_factor_lf",
+      adjusted_cfg.suppressor.normal_tuning.max_dec_factor_lf);
+  FieldTrialParameter<double> dominant_nearend_detection_enr_threshold(
+      "dominant_nearend_detection_enr_threshold",
+      adjusted_cfg.suppressor.dominant_nearend_detection.enr_threshold);
+  FieldTrialParameter<double> dominant_nearend_detection_enr_exit_threshold(
+      "dominant_nearend_detection_enr_exit_threshold",
+      adjusted_cfg.suppressor.dominant_nearend_detection.enr_exit_threshold);
+  FieldTrialParameter<double> dominant_nearend_detection_snr_threshold(
+      "dominant_nearend_detection_snr_threshold",
+      adjusted_cfg.suppressor.dominant_nearend_detection.snr_threshold);
+  FieldTrialParameter<int> dominant_nearend_detection_hold_duration(
+      "dominant_nearend_detection_hold_duration",
+      adjusted_cfg.suppressor.dominant_nearend_detection.hold_duration);
+  FieldTrialParameter<int> dominant_nearend_detection_trigger_threshold(
+      "dominant_nearend_detection_trigger_threshold",
+      adjusted_cfg.suppressor.dominant_nearend_detection.trigger_threshold);
+  FieldTrialParameter<double> ep_strength_default_len(
+      "ep_strength_default_len", adjusted_cfg.ep_strength.default_len);
+
+  ParseFieldTrial(
+      {&nearend_tuning_mask_lf_enr_transparent,
+       &nearend_tuning_mask_lf_enr_suppress,
+       &nearend_tuning_mask_hf_enr_transparent,
+       &nearend_tuning_mask_hf_enr_suppress, &nearend_tuning_max_inc_factor,
+       &nearend_tuning_max_dec_factor_lf,
+       &normal_tuning_mask_lf_enr_transparent,
+       &normal_tuning_mask_lf_enr_suppress,
+       &normal_tuning_mask_hf_enr_transparent,
+       &normal_tuning_mask_hf_enr_suppress, &normal_tuning_max_inc_factor,
+       &normal_tuning_max_dec_factor_lf,
+       &dominant_nearend_detection_enr_threshold,
+       &dominant_nearend_detection_enr_exit_threshold,
+       &dominant_nearend_detection_snr_threshold,
+       &dominant_nearend_detection_hold_duration,
+       &dominant_nearend_detection_trigger_threshold, &ep_strength_default_len},
+      suppressor_tuning_override_trial_name);
+
+  adjusted_cfg.suppressor.nearend_tuning.mask_lf.enr_transparent =
+      static_cast<float>(nearend_tuning_mask_lf_enr_transparent.Get());
+  adjusted_cfg.suppressor.nearend_tuning.mask_lf.enr_suppress =
+      static_cast<float>(nearend_tuning_mask_lf_enr_suppress.Get());
+  adjusted_cfg.suppressor.nearend_tuning.mask_hf.enr_transparent =
+      static_cast<float>(nearend_tuning_mask_hf_enr_transparent.Get());
+  adjusted_cfg.suppressor.nearend_tuning.mask_hf.enr_suppress =
+      static_cast<float>(nearend_tuning_mask_hf_enr_suppress.Get());
+  adjusted_cfg.suppressor.nearend_tuning.max_inc_factor =
+      static_cast<float>(nearend_tuning_max_inc_factor.Get());
+  adjusted_cfg.suppressor.nearend_tuning.max_dec_factor_lf =
+      static_cast<float>(nearend_tuning_max_dec_factor_lf.Get());
+  adjusted_cfg.suppressor.normal_tuning.mask_lf.enr_transparent =
+      static_cast<float>(normal_tuning_mask_lf_enr_transparent.Get());
+  adjusted_cfg.suppressor.normal_tuning.mask_lf.enr_suppress =
+      static_cast<float>(normal_tuning_mask_lf_enr_suppress.Get());
+  adjusted_cfg.suppressor.normal_tuning.mask_hf.enr_transparent =
+      static_cast<float>(normal_tuning_mask_hf_enr_transparent.Get());
+  adjusted_cfg.suppressor.normal_tuning.mask_hf.enr_suppress =
+      static_cast<float>(normal_tuning_mask_hf_enr_suppress.Get());
+  adjusted_cfg.suppressor.normal_tuning.max_inc_factor =
+      static_cast<float>(normal_tuning_max_inc_factor.Get());
+  adjusted_cfg.suppressor.normal_tuning.max_dec_factor_lf =
+      static_cast<float>(normal_tuning_max_dec_factor_lf.Get());
+  adjusted_cfg.suppressor.dominant_nearend_detection.enr_threshold =
+      static_cast<float>(dominant_nearend_detection_enr_threshold.Get());
+  adjusted_cfg.suppressor.dominant_nearend_detection.enr_exit_threshold =
+      static_cast<float>(dominant_nearend_detection_enr_exit_threshold.Get());
+  adjusted_cfg.suppressor.dominant_nearend_detection.snr_threshold =
+      static_cast<float>(dominant_nearend_detection_snr_threshold.Get());
+  adjusted_cfg.suppressor.dominant_nearend_detection.hold_duration =
+      dominant_nearend_detection_hold_duration.Get();
+  adjusted_cfg.suppressor.dominant_nearend_detection.trigger_threshold =
+      dominant_nearend_detection_trigger_threshold.Get();
+  adjusted_cfg.ep_strength.default_len =
+      static_cast<float>(ep_strength_default_len.Get());
+
+  // Field trial-based overrides of individual suppressor parameters.
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorNearendLfMaskTransparentOverride", 0.f, 10.f,
+      &adjusted_cfg.suppressor.nearend_tuning.mask_lf.enr_transparent);
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorNearendLfMaskSuppressOverride", 0.f, 10.f,
+      &adjusted_cfg.suppressor.nearend_tuning.mask_lf.enr_suppress);
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorNearendHfMaskTransparentOverride", 0.f, 10.f,
+      &adjusted_cfg.suppressor.nearend_tuning.mask_hf.enr_transparent);
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorNearendHfMaskSuppressOverride", 0.f, 10.f,
+      &adjusted_cfg.suppressor.nearend_tuning.mask_hf.enr_suppress);
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorNearendMaxIncFactorOverride", 0.f, 10.f,
+      &adjusted_cfg.suppressor.nearend_tuning.max_inc_factor);
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorNearendMaxDecFactorLfOverride", 0.f, 10.f,
+      &adjusted_cfg.suppressor.nearend_tuning.max_dec_factor_lf);
+
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorNormalLfMaskTransparentOverride", 0.f, 10.f,
+      &adjusted_cfg.suppressor.normal_tuning.mask_lf.enr_transparent);
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorNormalLfMaskSuppressOverride", 0.f, 10.f,
+      &adjusted_cfg.suppressor.normal_tuning.mask_lf.enr_suppress);
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorNormalHfMaskTransparentOverride", 0.f, 10.f,
+      &adjusted_cfg.suppressor.normal_tuning.mask_hf.enr_transparent);
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorNormalHfMaskSuppressOverride", 0.f, 10.f,
+      &adjusted_cfg.suppressor.normal_tuning.mask_hf.enr_suppress);
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorNormalMaxIncFactorOverride", 0.f, 10.f,
+      &adjusted_cfg.suppressor.normal_tuning.max_inc_factor);
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorNormalMaxDecFactorLfOverride", 0.f, 10.f,
+      &adjusted_cfg.suppressor.normal_tuning.max_dec_factor_lf);
+
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorDominantNearendEnrThresholdOverride", 0.f, 100.f,
+      &adjusted_cfg.suppressor.dominant_nearend_detection.enr_threshold);
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorDominantNearendEnrExitThresholdOverride", 0.f,
+      100.f,
+      &adjusted_cfg.suppressor.dominant_nearend_detection.enr_exit_threshold);
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorDominantNearendSnrThresholdOverride", 0.f, 100.f,
+      &adjusted_cfg.suppressor.dominant_nearend_detection.snr_threshold);
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorDominantNearendHoldDurationOverride", 0, 1000,
+      &adjusted_cfg.suppressor.dominant_nearend_detection.hold_duration);
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorDominantNearendTriggerThresholdOverride", 0, 1000,
+      &adjusted_cfg.suppressor.dominant_nearend_detection.trigger_threshold);
+
+  RetrieveFieldTrialValue(
+      "WebRTC-Aec3SuppressorAntiHowlingGainOverride", 0.f, 10.f,
+      &adjusted_cfg.suppressor.high_bands_suppression.anti_howling_gain);
+
+  RetrieveFieldTrialValue("WebRTC-Aec3SuppressorEpStrengthDefaultLenOverride",
+                          -1.f, 1.f, &adjusted_cfg.ep_strength.default_len);
+
+  return adjusted_cfg;
+}
+
+class EchoCanceller3::RenderWriter {
+ public:
+  RenderWriter(ApmDataDumper* data_dumper,
+               const EchoCanceller3Config& config,
+               SwapQueue<std::vector<std::vector<std::vector<float>>>,
+                         Aec3RenderQueueItemVerifier>* render_transfer_queue,
+               size_t num_bands,
+               size_t num_channels);
+
+  RenderWriter() = delete;
+  RenderWriter(const RenderWriter&) = delete;
+  RenderWriter& operator=(const RenderWriter&) = delete;
+
+  ~RenderWriter();
+  void Insert(const AudioBuffer& input);
+
+ private:
+  ApmDataDumper* data_dumper_;
+  const size_t num_bands_;
+  const size_t num_channels_;
+  std::unique_ptr<HighPassFilter> high_pass_filter_;
+  std::vector<std::vector<std::vector<float>>> render_queue_input_frame_;
+  SwapQueue<std::vector<std::vector<std::vector<float>>>,
+            Aec3RenderQueueItemVerifier>* render_transfer_queue_;
+};
+
+EchoCanceller3::RenderWriter::RenderWriter(
+    ApmDataDumper* data_dumper,
+    const EchoCanceller3Config& config,
+    SwapQueue<std::vector<std::vector<std::vector<float>>>,
+              Aec3RenderQueueItemVerifier>* render_transfer_queue,
+    size_t num_bands,
+    size_t num_channels)
+    : data_dumper_(data_dumper),
+      num_bands_(num_bands),
+      num_channels_(num_channels),
+      render_queue_input_frame_(
+          num_bands_,
+          std::vector<std::vector<float>>(
+              num_channels_,
+              std::vector<float>(AudioBuffer::kSplitBandSize, 0.f))),
+      render_transfer_queue_(render_transfer_queue) {
+  RTC_DCHECK(data_dumper);
+  if (config.filter.high_pass_filter_echo_reference) {
+    high_pass_filter_ = std::make_unique<HighPassFilter>(16000, num_channels);
+  }
+}
+
+EchoCanceller3::RenderWriter::~RenderWriter() = default;
+
+void EchoCanceller3::RenderWriter::Insert(const AudioBuffer& input) {
+  RTC_DCHECK_EQ(AudioBuffer::kSplitBandSize, input.num_frames_per_band());
+  RTC_DCHECK_EQ(num_bands_, input.num_bands());
+  RTC_DCHECK_EQ(num_channels_, input.num_channels());
+
+  // TODO(bugs.webrtc.org/8759) Temporary work-around.
+  if (num_bands_ != input.num_bands())
+    return;
+
+  data_dumper_->DumpWav("aec3_render_input", AudioBuffer::kSplitBandSize,
+                        &input.split_bands_const(0)[0][0], 16000, 1);
+
+  CopyBufferIntoFrame(input, num_bands_, num_channels_,
+                      &render_queue_input_frame_);
+  if (high_pass_filter_) {
+    high_pass_filter_->Process(&render_queue_input_frame_[0]);
+  }
+
+  static_cast<void>(render_transfer_queue_->Insert(&render_queue_input_frame_));
+}
+
+int EchoCanceller3::instance_count_ = 0;
+
+EchoCanceller3::EchoCanceller3(const EchoCanceller3Config& config,
+                               int sample_rate_hz,
+                               size_t num_render_channels,
+                               size_t num_capture_channels)
+    : EchoCanceller3(AdjustConfig(config),
+                     sample_rate_hz,
+                     num_render_channels,
+                     num_capture_channels,
+                     std::unique_ptr<BlockProcessor>(
+                         BlockProcessor::Create(AdjustConfig(config),
+                                                sample_rate_hz,
+                                                num_render_channels,
+                                                num_capture_channels))) {}
+EchoCanceller3::EchoCanceller3(const EchoCanceller3Config& config,
+                               int sample_rate_hz,
+                               size_t num_render_channels,
+                               size_t num_capture_channels,
+                               std::unique_ptr<BlockProcessor> block_processor)
+    : data_dumper_(
+          new ApmDataDumper(rtc::AtomicOps::Increment(&instance_count_))),
+      config_(config),
+      sample_rate_hz_(sample_rate_hz),
+      num_bands_(NumBandsForRate(sample_rate_hz_)),
+      num_render_channels_(num_render_channels),
+      num_capture_channels_(num_capture_channels),
+      output_framer_(num_bands_, num_capture_channels_),
+      capture_blocker_(num_bands_, num_capture_channels_),
+      render_blocker_(num_bands_, num_render_channels_),
+      render_transfer_queue_(
+          kRenderTransferQueueSizeFrames,
+          std::vector<std::vector<std::vector<float>>>(
+              num_bands_,
+              std::vector<std::vector<float>>(
+                  num_render_channels_,
+                  std::vector<float>(AudioBuffer::kSplitBandSize, 0.f))),
+          Aec3RenderQueueItemVerifier(num_bands_,
+                                      num_render_channels_,
+                                      AudioBuffer::kSplitBandSize)),
+      block_processor_(std::move(block_processor)),
+      render_queue_output_frame_(
+          num_bands_,
+          std::vector<std::vector<float>>(
+              num_render_channels_,
+              std::vector<float>(AudioBuffer::kSplitBandSize, 0.f))),
+      render_block_(
+          num_bands_,
+          std::vector<std::vector<float>>(num_render_channels_,
+                                          std::vector<float>(kBlockSize, 0.f))),
+      capture_block_(
+          num_bands_,
+          std::vector<std::vector<float>>(num_capture_channels_,
+                                          std::vector<float>(kBlockSize, 0.f))),
+      render_sub_frame_view_(
+          num_bands_,
+          std::vector<rtc::ArrayView<float>>(num_render_channels_)),
+      capture_sub_frame_view_(
+          num_bands_,
+          std::vector<rtc::ArrayView<float>>(num_capture_channels_)) {
+  RTC_DCHECK(ValidFullBandRate(sample_rate_hz_));
+
+  if (config_.delay.fixed_capture_delay_samples > 0) {
+    block_delay_buffer_.reset(new BlockDelayBuffer(
+        num_capture_channels_, num_bands_, AudioBuffer::kSplitBandSize,
+        config_.delay.fixed_capture_delay_samples));
+  }
+
+  render_writer_.reset(new RenderWriter(data_dumper_.get(), config_,
+                                        &render_transfer_queue_, num_bands_,
+                                        num_render_channels_));
+
+  RTC_DCHECK_EQ(num_bands_, std::max(sample_rate_hz_, 16000) / 16000);
+  RTC_DCHECK_GE(kMaxNumBands, num_bands_);
+
+  if (config_.filter.export_linear_aec_output) {
+    linear_output_framer_.reset(new BlockFramer(1, num_capture_channels_));
+    linear_output_block_ =
+        std::make_unique<std::vector<std::vector<std::vector<float>>>>(
+            1, std::vector<std::vector<float>>(
+                   num_capture_channels_, std::vector<float>(kBlockSize, 0.f)));
+    linear_output_sub_frame_view_ =
+        std::vector<std::vector<rtc::ArrayView<float>>>(
+            1, std::vector<rtc::ArrayView<float>>(num_capture_channels_));
+  }
+}
+
+EchoCanceller3::~EchoCanceller3() = default;
+
+void EchoCanceller3::AnalyzeRender(const AudioBuffer& render) {
+  RTC_DCHECK_RUNS_SERIALIZED(&render_race_checker_);
+
+  RTC_DCHECK_EQ(render.num_channels(), num_render_channels_);
+  data_dumper_->DumpRaw("aec3_call_order",
+                        static_cast<int>(EchoCanceller3ApiCall::kRender));
+
+  return render_writer_->Insert(render);
+}
+
+void EchoCanceller3::AnalyzeCapture(const AudioBuffer& capture) {
+  RTC_DCHECK_RUNS_SERIALIZED(&capture_race_checker_);
+  data_dumper_->DumpWav("aec3_capture_analyze_input", capture.num_frames(),
+                        capture.channels_const()[0], sample_rate_hz_, 1);
+  saturated_microphone_signal_ = false;
+  for (size_t channel = 0; channel < capture.num_channels(); ++channel) {
+    saturated_microphone_signal_ |=
+        DetectSaturation(rtc::ArrayView<const float>(
+            capture.channels_const()[channel], capture.num_frames()));
+    if (saturated_microphone_signal_) {
+      break;
+    }
+  }
+}
+
+void EchoCanceller3::ProcessCapture(AudioBuffer* capture, bool level_change) {
+  ProcessCapture(capture, nullptr, level_change);
+}
+
+void EchoCanceller3::ProcessCapture(AudioBuffer* capture,
+                                    AudioBuffer* linear_output,
+                                    bool level_change) {
+  RTC_DCHECK_RUNS_SERIALIZED(&capture_race_checker_);
+  RTC_DCHECK(capture);
+  RTC_DCHECK_EQ(num_bands_, capture->num_bands());
+  RTC_DCHECK_EQ(AudioBuffer::kSplitBandSize, capture->num_frames_per_band());
+  RTC_DCHECK_EQ(capture->num_channels(), num_capture_channels_);
+  data_dumper_->DumpRaw("aec3_call_order",
+                        static_cast<int>(EchoCanceller3ApiCall::kCapture));
+
+  if (linear_output && !linear_output_framer_) {
+    RTC_LOG(LS_ERROR) << "Trying to retrieve the linear AEC output without "
+                         "properly configuring AEC3.";
+    RTC_NOTREACHED();
+  }
+
+  // Report capture call in the metrics and periodically update API call
+  // metrics.
+  api_call_metrics_.ReportCaptureCall();
+
+  // Optionally delay the capture signal.
+  if (config_.delay.fixed_capture_delay_samples > 0) {
+    RTC_DCHECK(block_delay_buffer_);
+    block_delay_buffer_->DelaySignal(capture);
+  }
+
+  rtc::ArrayView<float> capture_lower_band = rtc::ArrayView<float>(
+      &capture->split_bands(0)[0][0], AudioBuffer::kSplitBandSize);
+
+  data_dumper_->DumpWav("aec3_capture_input", capture_lower_band, 16000, 1);
+
+  EmptyRenderQueue();
+
+  ProcessCaptureFrameContent(linear_output, capture, level_change,
+                             saturated_microphone_signal_, 0, &capture_blocker_,
+                             linear_output_framer_.get(), &output_framer_,
+                             block_processor_.get(), linear_output_block_.get(),
+                             &linear_output_sub_frame_view_, &capture_block_,
+                             &capture_sub_frame_view_);
+
+  ProcessCaptureFrameContent(linear_output, capture, level_change,
+                             saturated_microphone_signal_, 1, &capture_blocker_,
+                             linear_output_framer_.get(), &output_framer_,
+                             block_processor_.get(), linear_output_block_.get(),
+                             &linear_output_sub_frame_view_, &capture_block_,
+                             &capture_sub_frame_view_);
+
+  ProcessRemainingCaptureFrameContent(
+      level_change, saturated_microphone_signal_, &capture_blocker_,
+      linear_output_framer_.get(), &output_framer_, block_processor_.get(),
+      linear_output_block_.get(), &capture_block_);
+
+  data_dumper_->DumpWav("aec3_capture_output", AudioBuffer::kSplitBandSize,
+                        &capture->split_bands(0)[0][0], 16000, 1);
+}
+
+EchoControl::Metrics EchoCanceller3::GetMetrics() const {
+  RTC_DCHECK_RUNS_SERIALIZED(&capture_race_checker_);
+  Metrics metrics;
+  block_processor_->GetMetrics(&metrics);
+  return metrics;
+}
+
+void EchoCanceller3::SetAudioBufferDelay(int delay_ms) {
+  RTC_DCHECK_RUNS_SERIALIZED(&capture_race_checker_);
+  block_processor_->SetAudioBufferDelay(delay_ms);
+}
+
+void EchoCanceller3::SetCaptureOutputUsage(bool capture_output_used) {
+  RTC_DCHECK_RUNS_SERIALIZED(&capture_race_checker_);
+  block_processor_->SetCaptureOutputUsage(capture_output_used);
+}
+
+bool EchoCanceller3::ActiveProcessing() const {
+  return true;
+}
+
+EchoCanceller3Config EchoCanceller3::CreateDefaultConfig(
+    size_t num_render_channels,
+    size_t num_capture_channels) {
+  EchoCanceller3Config cfg;
+  if (num_render_channels > 1) {
+    // Use shorter and more rapidly adapting coarse filter to compensate for
+    // thge increased number of total filter parameters to adapt.
+    cfg.filter.coarse.length_blocks = 11;
+    cfg.filter.coarse.rate = 0.95f;
+    cfg.filter.coarse_initial.length_blocks = 11;
+    cfg.filter.coarse_initial.rate = 0.95f;
+
+    // Use more concervative suppressor behavior for non-nearend speech.
+    cfg.suppressor.normal_tuning.max_dec_factor_lf = 0.35f;
+    cfg.suppressor.normal_tuning.max_inc_factor = 1.5f;
+  }
+  return cfg;
+}
+
+void EchoCanceller3::EmptyRenderQueue() {
+  RTC_DCHECK_RUNS_SERIALIZED(&capture_race_checker_);
+  bool frame_to_buffer =
+      render_transfer_queue_.Remove(&render_queue_output_frame_);
+  while (frame_to_buffer) {
+    // Report render call in the metrics.
+    api_call_metrics_.ReportRenderCall();
+
+    BufferRenderFrameContent(&render_queue_output_frame_, 0, &render_blocker_,
+                             block_processor_.get(), &render_block_,
+                             &render_sub_frame_view_);
+
+    BufferRenderFrameContent(&render_queue_output_frame_, 1, &render_blocker_,
+                             block_processor_.get(), &render_block_,
+                             &render_sub_frame_view_);
+
+    BufferRemainingRenderFrameContent(&render_blocker_, block_processor_.get(),
+                                      &render_block_);
+
+    frame_to_buffer =
+        render_transfer_queue_.Remove(&render_queue_output_frame_);
+  }
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_canceller3.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_canceller3.h
new file mode 100644
index 0000000..a4aab49
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_canceller3.h
@@ -0,0 +1,202 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_ECHO_CANCELLER3_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_ECHO_CANCELLER3_H_
+
+#include <stddef.h>
+
+#include <memory>
+#include <vector>
+
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "api/audio/echo_control.h"
+#include "modules/audio_processing/aec3/api_call_jitter_metrics.h"
+#include "modules/audio_processing/aec3/block_delay_buffer.h"
+#include "modules/audio_processing/aec3/block_framer.h"
+#include "modules/audio_processing/aec3/block_processor.h"
+#include "modules/audio_processing/aec3/frame_blocker.h"
+#include "modules/audio_processing/audio_buffer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/race_checker.h"
+#include "rtc_base/swap_queue.h"
+#include "rtc_base/thread_annotations.h"
+
+namespace webrtc {
+
+// Method for adjusting config parameter dependencies.
+// Only to be used externally to AEC3 for testing purposes.
+// TODO(webrtc:5298): Move this to a separate file.
+EchoCanceller3Config AdjustConfig(const EchoCanceller3Config& config);
+
+// Functor for verifying the invariance of the frames being put into the render
+// queue.
+class Aec3RenderQueueItemVerifier {
+ public:
+  Aec3RenderQueueItemVerifier(size_t num_bands,
+                              size_t num_channels,
+                              size_t frame_length)
+      : num_bands_(num_bands),
+        num_channels_(num_channels),
+        frame_length_(frame_length) {}
+
+  bool operator()(const std::vector<std::vector<std::vector<float>>>& v) const {
+    if (v.size() != num_bands_) {
+      return false;
+    }
+    for (const auto& band : v) {
+      if (band.size() != num_channels_) {
+        return false;
+      }
+      for (const auto& channel : band) {
+        if (channel.size() != frame_length_) {
+          return false;
+        }
+      }
+    }
+    return true;
+  }
+
+ private:
+  const size_t num_bands_;
+  const size_t num_channels_;
+  const size_t frame_length_;
+};
+
+// Main class for the echo canceller3.
+// It does 4 things:
+// -Receives 10 ms frames of band-split audio.
+// -Provides the lower level echo canceller functionality with
+// blocks of 64 samples of audio data.
+// -Partially handles the jitter in the render and capture API
+// call sequence.
+//
+// The class is supposed to be used in a non-concurrent manner apart from the
+// AnalyzeRender call which can be called concurrently with the other methods.
+class EchoCanceller3 : public EchoControl {
+ public:
+  // Normal c-tor to use.
+  EchoCanceller3(const EchoCanceller3Config& config,
+                 int sample_rate_hz,
+                 size_t num_render_channels,
+                 size_t num_capture_channels);
+  // Testing c-tor that is used only for testing purposes.
+  EchoCanceller3(const EchoCanceller3Config& config,
+                 int sample_rate_hz,
+                 size_t num_render_channels,
+                 size_t num_capture_channels,
+                 std::unique_ptr<BlockProcessor> block_processor);
+  ~EchoCanceller3() override;
+  EchoCanceller3(const EchoCanceller3&) = delete;
+  EchoCanceller3& operator=(const EchoCanceller3&) = delete;
+
+  // Analyzes and stores an internal copy of the split-band domain render
+  // signal.
+  void AnalyzeRender(AudioBuffer* render) override { AnalyzeRender(*render); }
+  // Analyzes the full-band domain capture signal to detect signal saturation.
+  void AnalyzeCapture(AudioBuffer* capture) override {
+    AnalyzeCapture(*capture);
+  }
+  // Processes the split-band domain capture signal in order to remove any echo
+  // present in the signal.
+  void ProcessCapture(AudioBuffer* capture, bool level_change) override;
+  // As above, but also returns the linear filter output.
+  void ProcessCapture(AudioBuffer* capture,
+                      AudioBuffer* linear_output,
+                      bool level_change) override;
+  // Collect current metrics from the echo canceller.
+  Metrics GetMetrics() const override;
+  // Provides an optional external estimate of the audio buffer delay.
+  void SetAudioBufferDelay(int delay_ms) override;
+
+  // Specifies whether the capture output will be used. The purpose of this is
+  // to allow the echo controller to deactivate some of the processing when the
+  // resulting output is anyway not used, for instance when the endpoint is
+  // muted.
+  void SetCaptureOutputUsage(bool capture_output_used) override;
+
+  bool ActiveProcessing() const override;
+
+  // Signals whether an external detector has detected echo leakage from the
+  // echo canceller.
+  // Note that in the case echo leakage has been flagged, it should be unflagged
+  // once it is no longer occurring.
+  void UpdateEchoLeakageStatus(bool leakage_detected) {
+    RTC_DCHECK_RUNS_SERIALIZED(&capture_race_checker_);
+    block_processor_->UpdateEchoLeakageStatus(leakage_detected);
+  }
+
+  // Produces a default configuration that is suitable for a certain combination
+  // of render and capture channels.
+  static EchoCanceller3Config CreateDefaultConfig(size_t num_render_channels,
+                                                  size_t num_capture_channels);
+
+ private:
+  class RenderWriter;
+
+  // Empties the render SwapQueue.
+  void EmptyRenderQueue();
+
+  // Analyzes and stores an internal copy of the split-band domain render
+  // signal.
+  void AnalyzeRender(const AudioBuffer& render);
+  // Analyzes the full-band domain capture signal to detect signal saturation.
+  void AnalyzeCapture(const AudioBuffer& capture);
+
+  rtc::RaceChecker capture_race_checker_;
+  rtc::RaceChecker render_race_checker_;
+
+  // State that is accessed by the AnalyzeRender call.
+  std::unique_ptr<RenderWriter> render_writer_
+      RTC_GUARDED_BY(render_race_checker_);
+
+  // State that may be accessed by the capture thread.
+  static int instance_count_;
+  std::unique_ptr<ApmDataDumper> data_dumper_;
+  const EchoCanceller3Config config_;
+  const int sample_rate_hz_;
+  const int num_bands_;
+  const size_t num_render_channels_;
+  const size_t num_capture_channels_;
+  std::unique_ptr<BlockFramer> linear_output_framer_
+      RTC_GUARDED_BY(capture_race_checker_);
+  BlockFramer output_framer_ RTC_GUARDED_BY(capture_race_checker_);
+  FrameBlocker capture_blocker_ RTC_GUARDED_BY(capture_race_checker_);
+  FrameBlocker render_blocker_ RTC_GUARDED_BY(capture_race_checker_);
+  SwapQueue<std::vector<std::vector<std::vector<float>>>,
+            Aec3RenderQueueItemVerifier>
+      render_transfer_queue_;
+  std::unique_ptr<BlockProcessor> block_processor_
+      RTC_GUARDED_BY(capture_race_checker_);
+  std::vector<std::vector<std::vector<float>>> render_queue_output_frame_
+      RTC_GUARDED_BY(capture_race_checker_);
+  bool saturated_microphone_signal_ RTC_GUARDED_BY(capture_race_checker_) =
+      false;
+  std::vector<std::vector<std::vector<float>>> render_block_
+      RTC_GUARDED_BY(capture_race_checker_);
+  std::unique_ptr<std::vector<std::vector<std::vector<float>>>>
+      linear_output_block_ RTC_GUARDED_BY(capture_race_checker_);
+  std::vector<std::vector<std::vector<float>>> capture_block_
+      RTC_GUARDED_BY(capture_race_checker_);
+  std::vector<std::vector<rtc::ArrayView<float>>> render_sub_frame_view_
+      RTC_GUARDED_BY(capture_race_checker_);
+  std::vector<std::vector<rtc::ArrayView<float>>> linear_output_sub_frame_view_
+      RTC_GUARDED_BY(capture_race_checker_);
+  std::vector<std::vector<rtc::ArrayView<float>>> capture_sub_frame_view_
+      RTC_GUARDED_BY(capture_race_checker_);
+  std::unique_ptr<BlockDelayBuffer> block_delay_buffer_
+      RTC_GUARDED_BY(capture_race_checker_);
+  ApiCallJitterMetrics api_call_metrics_ RTC_GUARDED_BY(capture_race_checker_);
+};
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_ECHO_CANCELLER3_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_canceller3_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_canceller3_unittest.cc
new file mode 100644
index 0000000..4a3c466
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_canceller3_unittest.cc
@@ -0,0 +1,930 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/echo_canceller3.h"
+
+#include <deque>
+#include <memory>
+#include <string>
+#include <utility>
+#include <vector>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/block_processor.h"
+#include "modules/audio_processing/aec3/frame_blocker.h"
+#include "modules/audio_processing/aec3/mock/mock_block_processor.h"
+#include "modules/audio_processing/audio_buffer.h"
+#include "modules/audio_processing/high_pass_filter.h"
+#include "modules/audio_processing/utility/cascaded_biquad_filter.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/field_trial.h"
+#include "test/gmock.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace {
+
+using ::testing::_;
+using ::testing::StrictMock;
+
+// Populates the frame with linearly increasing sample values for each band,
+// with a band-specific offset, in order to allow simple bitexactness
+// verification for each band.
+void PopulateInputFrame(size_t frame_length,
+                        size_t num_bands,
+                        size_t frame_index,
+                        float* const* frame,
+                        int offset) {
+  for (size_t k = 0; k < num_bands; ++k) {
+    for (size_t i = 0; i < frame_length; ++i) {
+      float value = static_cast<int>(frame_index * frame_length + i) + offset;
+      frame[k][i] = (value > 0 ? 5000 * k + value : 0);
+    }
+  }
+}
+
+// Populates the frame with linearly increasing sample values.
+void PopulateInputFrame(size_t frame_length,
+                        size_t frame_index,
+                        float* frame,
+                        int offset) {
+  for (size_t i = 0; i < frame_length; ++i) {
+    float value = static_cast<int>(frame_index * frame_length + i) + offset;
+    frame[i] = std::max(value, 0.f);
+  }
+}
+
+// Verifies the that samples in the output frame are identical to the samples
+// that were produced for the input frame, with an offset in order to compensate
+// for buffering delays.
+bool VerifyOutputFrameBitexactness(size_t frame_length,
+                                   size_t num_bands,
+                                   size_t frame_index,
+                                   const float* const* frame,
+                                   int offset) {
+  float reference_frame_data[kMaxNumBands][2 * kSubFrameLength];
+  float* reference_frame[kMaxNumBands];
+  for (size_t k = 0; k < num_bands; ++k) {
+    reference_frame[k] = &reference_frame_data[k][0];
+  }
+
+  PopulateInputFrame(frame_length, num_bands, frame_index, reference_frame,
+                     offset);
+  for (size_t k = 0; k < num_bands; ++k) {
+    for (size_t i = 0; i < frame_length; ++i) {
+      if (reference_frame[k][i] != frame[k][i]) {
+        return false;
+      }
+    }
+  }
+
+  return true;
+}
+
+bool VerifyOutputFrameBitexactness(rtc::ArrayView<const float> reference,
+                                   rtc::ArrayView<const float> frame,
+                                   int offset) {
+  for (size_t k = 0; k < frame.size(); ++k) {
+    int reference_index = static_cast<int>(k) + offset;
+    if (reference_index >= 0) {
+      if (reference[reference_index] != frame[k]) {
+        return false;
+      }
+    }
+  }
+  return true;
+}
+
+// Class for testing that the capture data is properly received by the block
+// processor and that the processor data is properly passed to the
+// EchoCanceller3 output.
+class CaptureTransportVerificationProcessor : public BlockProcessor {
+ public:
+  explicit CaptureTransportVerificationProcessor(size_t num_bands) {}
+
+  CaptureTransportVerificationProcessor() = delete;
+  CaptureTransportVerificationProcessor(
+      const CaptureTransportVerificationProcessor&) = delete;
+  CaptureTransportVerificationProcessor& operator=(
+      const CaptureTransportVerificationProcessor&) = delete;
+
+  ~CaptureTransportVerificationProcessor() override = default;
+
+  void ProcessCapture(
+      bool level_change,
+      bool saturated_microphone_signal,
+      std::vector<std::vector<std::vector<float>>>* linear_output,
+      std::vector<std::vector<std::vector<float>>>* capture_block) override {}
+
+  void BufferRender(
+      const std::vector<std::vector<std::vector<float>>>& block) override {}
+
+  void UpdateEchoLeakageStatus(bool leakage_detected) override {}
+
+  void GetMetrics(EchoControl::Metrics* metrics) const override {}
+
+  void SetAudioBufferDelay(int delay_ms) override {}
+
+  void SetCaptureOutputUsage(bool capture_output_used) {}
+};
+
+// Class for testing that the render data is properly received by the block
+// processor.
+class RenderTransportVerificationProcessor : public BlockProcessor {
+ public:
+  explicit RenderTransportVerificationProcessor(size_t num_bands) {}
+
+  RenderTransportVerificationProcessor() = delete;
+  RenderTransportVerificationProcessor(
+      const RenderTransportVerificationProcessor&) = delete;
+  RenderTransportVerificationProcessor& operator=(
+      const RenderTransportVerificationProcessor&) = delete;
+
+  ~RenderTransportVerificationProcessor() override = default;
+
+  void ProcessCapture(
+      bool level_change,
+      bool saturated_microphone_signal,
+      std::vector<std::vector<std::vector<float>>>* linear_output,
+      std::vector<std::vector<std::vector<float>>>* capture_block) override {
+    std::vector<std::vector<std::vector<float>>> render_block =
+        received_render_blocks_.front();
+    received_render_blocks_.pop_front();
+    capture_block->swap(render_block);
+  }
+
+  void BufferRender(
+      const std::vector<std::vector<std::vector<float>>>& block) override {
+    received_render_blocks_.push_back(block);
+  }
+
+  void UpdateEchoLeakageStatus(bool leakage_detected) override {}
+
+  void GetMetrics(EchoControl::Metrics* metrics) const override {}
+
+  void SetAudioBufferDelay(int delay_ms) override {}
+
+  void SetCaptureOutputUsage(bool capture_output_used) {}
+
+ private:
+  std::deque<std::vector<std::vector<std::vector<float>>>>
+      received_render_blocks_;
+};
+
+class EchoCanceller3Tester {
+ public:
+  explicit EchoCanceller3Tester(int sample_rate_hz)
+      : sample_rate_hz_(sample_rate_hz),
+        num_bands_(NumBandsForRate(sample_rate_hz_)),
+        frame_length_(160),
+        fullband_frame_length_(rtc::CheckedDivExact(sample_rate_hz_, 100)),
+        capture_buffer_(fullband_frame_length_ * 100,
+                        1,
+                        fullband_frame_length_ * 100,
+                        1,
+                        fullband_frame_length_ * 100,
+                        1),
+        render_buffer_(fullband_frame_length_ * 100,
+                       1,
+                       fullband_frame_length_ * 100,
+                       1,
+                       fullband_frame_length_ * 100,
+                       1) {}
+
+  EchoCanceller3Tester() = delete;
+  EchoCanceller3Tester(const EchoCanceller3Tester&) = delete;
+  EchoCanceller3Tester& operator=(const EchoCanceller3Tester&) = delete;
+
+  // Verifies that the capture data is properly received by the block processor
+  // and that the processor data is properly passed to the EchoCanceller3
+  // output.
+  void RunCaptureTransportVerificationTest() {
+    EchoCanceller3 aec3(
+        EchoCanceller3Config(), sample_rate_hz_, 1, 1,
+        std::unique_ptr<BlockProcessor>(
+            new CaptureTransportVerificationProcessor(num_bands_)));
+
+    for (size_t frame_index = 0; frame_index < kNumFramesToProcess;
+         ++frame_index) {
+      aec3.AnalyzeCapture(&capture_buffer_);
+      OptionalBandSplit();
+      PopulateInputFrame(frame_length_, num_bands_, frame_index,
+                         &capture_buffer_.split_bands(0)[0], 0);
+      PopulateInputFrame(frame_length_, frame_index,
+                         &render_buffer_.channels()[0][0], 0);
+
+      aec3.AnalyzeRender(&render_buffer_);
+      aec3.ProcessCapture(&capture_buffer_, false);
+      EXPECT_TRUE(VerifyOutputFrameBitexactness(
+          frame_length_, num_bands_, frame_index,
+          &capture_buffer_.split_bands(0)[0], -64));
+    }
+  }
+
+  // Test method for testing that the render data is properly received by the
+  // block processor.
+  void RunRenderTransportVerificationTest() {
+    EchoCanceller3 aec3(
+        EchoCanceller3Config(), sample_rate_hz_, 1, 1,
+        std::unique_ptr<BlockProcessor>(
+            new RenderTransportVerificationProcessor(num_bands_)));
+
+    std::vector<std::vector<float>> render_input(1);
+    std::vector<float> capture_output;
+    for (size_t frame_index = 0; frame_index < kNumFramesToProcess;
+         ++frame_index) {
+      aec3.AnalyzeCapture(&capture_buffer_);
+      OptionalBandSplit();
+      PopulateInputFrame(frame_length_, num_bands_, frame_index,
+                         &capture_buffer_.split_bands(0)[0], 100);
+      PopulateInputFrame(frame_length_, num_bands_, frame_index,
+                         &render_buffer_.split_bands(0)[0], 0);
+
+      for (size_t k = 0; k < frame_length_; ++k) {
+        render_input[0].push_back(render_buffer_.split_bands(0)[0][k]);
+      }
+      aec3.AnalyzeRender(&render_buffer_);
+      aec3.ProcessCapture(&capture_buffer_, false);
+      for (size_t k = 0; k < frame_length_; ++k) {
+        capture_output.push_back(capture_buffer_.split_bands(0)[0][k]);
+      }
+    }
+
+    EXPECT_TRUE(
+        VerifyOutputFrameBitexactness(render_input[0], capture_output, -64));
+  }
+
+  // Verifies that information about echo path changes are properly propagated
+  // to the block processor.
+  // The cases tested are:
+  // -That no set echo path change flags are received when there is no echo path
+  // change.
+  // -That set echo path change flags are received and continues to be received
+  // as long as echo path changes are flagged.
+  // -That set echo path change flags are no longer received when echo path
+  // change events stop being flagged.
+  enum class EchoPathChangeTestVariant { kNone, kOneSticky, kOneNonSticky };
+
+  void RunEchoPathChangeVerificationTest(
+      EchoPathChangeTestVariant echo_path_change_test_variant) {
+    constexpr size_t kNumFullBlocksPerFrame = 160 / kBlockSize;
+    constexpr size_t kExpectedNumBlocksToProcess =
+        (kNumFramesToProcess * 160) / kBlockSize;
+    std::unique_ptr<testing::StrictMock<webrtc::test::MockBlockProcessor>>
+        block_processor_mock(
+            new StrictMock<webrtc::test::MockBlockProcessor>());
+    EXPECT_CALL(*block_processor_mock, BufferRender(_))
+        .Times(kExpectedNumBlocksToProcess);
+    EXPECT_CALL(*block_processor_mock, UpdateEchoLeakageStatus(_)).Times(0);
+
+    switch (echo_path_change_test_variant) {
+      case EchoPathChangeTestVariant::kNone:
+        EXPECT_CALL(*block_processor_mock, ProcessCapture(false, _, _, _))
+            .Times(kExpectedNumBlocksToProcess);
+        break;
+      case EchoPathChangeTestVariant::kOneSticky:
+        EXPECT_CALL(*block_processor_mock, ProcessCapture(true, _, _, _))
+            .Times(kExpectedNumBlocksToProcess);
+        break;
+      case EchoPathChangeTestVariant::kOneNonSticky:
+        EXPECT_CALL(*block_processor_mock, ProcessCapture(true, _, _, _))
+            .Times(kNumFullBlocksPerFrame);
+        EXPECT_CALL(*block_processor_mock, ProcessCapture(false, _, _, _))
+            .Times(kExpectedNumBlocksToProcess - kNumFullBlocksPerFrame);
+        break;
+    }
+
+    EchoCanceller3 aec3(EchoCanceller3Config(), sample_rate_hz_, 1, 1,
+                        std::move(block_processor_mock));
+
+    for (size_t frame_index = 0; frame_index < kNumFramesToProcess;
+         ++frame_index) {
+      bool echo_path_change = false;
+      switch (echo_path_change_test_variant) {
+        case EchoPathChangeTestVariant::kNone:
+          break;
+        case EchoPathChangeTestVariant::kOneSticky:
+          echo_path_change = true;
+          break;
+        case EchoPathChangeTestVariant::kOneNonSticky:
+          if (frame_index == 0) {
+            echo_path_change = true;
+          }
+          break;
+      }
+
+      aec3.AnalyzeCapture(&capture_buffer_);
+      OptionalBandSplit();
+
+      PopulateInputFrame(frame_length_, num_bands_, frame_index,
+                         &capture_buffer_.split_bands(0)[0], 0);
+      PopulateInputFrame(frame_length_, frame_index,
+                         &render_buffer_.channels()[0][0], 0);
+
+      aec3.AnalyzeRender(&render_buffer_);
+      aec3.ProcessCapture(&capture_buffer_, echo_path_change);
+    }
+  }
+
+  // Test for verifying that echo leakage information is being properly passed
+  // to the processor.
+  // The cases tested are:
+  // -That no method calls are received when they should not.
+  // -That false values are received each time they are flagged.
+  // -That true values are received each time they are flagged.
+  // -That a false value is received when flagged after a true value has been
+  // flagged.
+  enum class EchoLeakageTestVariant {
+    kNone,
+    kFalseSticky,
+    kTrueSticky,
+    kTrueNonSticky
+  };
+
+  void RunEchoLeakageVerificationTest(
+      EchoLeakageTestVariant leakage_report_variant) {
+    constexpr size_t kExpectedNumBlocksToProcess =
+        (kNumFramesToProcess * 160) / kBlockSize;
+    std::unique_ptr<testing::StrictMock<webrtc::test::MockBlockProcessor>>
+        block_processor_mock(
+            new StrictMock<webrtc::test::MockBlockProcessor>());
+    EXPECT_CALL(*block_processor_mock, BufferRender(_))
+        .Times(kExpectedNumBlocksToProcess);
+    EXPECT_CALL(*block_processor_mock, ProcessCapture(_, _, _, _))
+        .Times(kExpectedNumBlocksToProcess);
+
+    switch (leakage_report_variant) {
+      case EchoLeakageTestVariant::kNone:
+        EXPECT_CALL(*block_processor_mock, UpdateEchoLeakageStatus(_)).Times(0);
+        break;
+      case EchoLeakageTestVariant::kFalseSticky:
+        EXPECT_CALL(*block_processor_mock, UpdateEchoLeakageStatus(false))
+            .Times(1);
+        break;
+      case EchoLeakageTestVariant::kTrueSticky:
+        EXPECT_CALL(*block_processor_mock, UpdateEchoLeakageStatus(true))
+            .Times(1);
+        break;
+      case EchoLeakageTestVariant::kTrueNonSticky: {
+        ::testing::InSequence s;
+        EXPECT_CALL(*block_processor_mock, UpdateEchoLeakageStatus(true))
+            .Times(1);
+        EXPECT_CALL(*block_processor_mock, UpdateEchoLeakageStatus(false))
+            .Times(kNumFramesToProcess - 1);
+      } break;
+    }
+
+    EchoCanceller3 aec3(EchoCanceller3Config(), sample_rate_hz_, 1, 1,
+                        std::move(block_processor_mock));
+
+    for (size_t frame_index = 0; frame_index < kNumFramesToProcess;
+         ++frame_index) {
+      switch (leakage_report_variant) {
+        case EchoLeakageTestVariant::kNone:
+          break;
+        case EchoLeakageTestVariant::kFalseSticky:
+          if (frame_index == 0) {
+            aec3.UpdateEchoLeakageStatus(false);
+          }
+          break;
+        case EchoLeakageTestVariant::kTrueSticky:
+          if (frame_index == 0) {
+            aec3.UpdateEchoLeakageStatus(true);
+          }
+          break;
+        case EchoLeakageTestVariant::kTrueNonSticky:
+          if (frame_index == 0) {
+            aec3.UpdateEchoLeakageStatus(true);
+          } else {
+            aec3.UpdateEchoLeakageStatus(false);
+          }
+          break;
+      }
+
+      aec3.AnalyzeCapture(&capture_buffer_);
+      OptionalBandSplit();
+
+      PopulateInputFrame(frame_length_, num_bands_, frame_index,
+                         &capture_buffer_.split_bands(0)[0], 0);
+      PopulateInputFrame(frame_length_, frame_index,
+                         &render_buffer_.channels()[0][0], 0);
+
+      aec3.AnalyzeRender(&render_buffer_);
+      aec3.ProcessCapture(&capture_buffer_, false);
+    }
+  }
+
+  // This verifies that saturation information is properly passed to the
+  // BlockProcessor.
+  // The cases tested are:
+  // -That no saturation event is passed to the processor if there is no
+  // saturation.
+  // -That one frame with one negative saturated sample value is reported to be
+  // saturated and that following non-saturated frames are properly reported as
+  // not being saturated.
+  // -That one frame with one positive saturated sample value is reported to be
+  // saturated and that following non-saturated frames are properly reported as
+  // not being saturated.
+  enum class SaturationTestVariant { kNone, kOneNegative, kOnePositive };
+
+  void RunCaptureSaturationVerificationTest(
+      SaturationTestVariant saturation_variant) {
+    const size_t kNumFullBlocksPerFrame = 160 / kBlockSize;
+    const size_t kExpectedNumBlocksToProcess =
+        (kNumFramesToProcess * 160) / kBlockSize;
+    std::unique_ptr<testing::StrictMock<webrtc::test::MockBlockProcessor>>
+        block_processor_mock(
+            new StrictMock<webrtc::test::MockBlockProcessor>());
+    EXPECT_CALL(*block_processor_mock, BufferRender(_))
+        .Times(kExpectedNumBlocksToProcess);
+    EXPECT_CALL(*block_processor_mock, UpdateEchoLeakageStatus(_)).Times(0);
+
+    switch (saturation_variant) {
+      case SaturationTestVariant::kNone:
+        EXPECT_CALL(*block_processor_mock, ProcessCapture(_, false, _, _))
+            .Times(kExpectedNumBlocksToProcess);
+        break;
+      case SaturationTestVariant::kOneNegative: {
+        ::testing::InSequence s;
+        EXPECT_CALL(*block_processor_mock, ProcessCapture(_, true, _, _))
+            .Times(kNumFullBlocksPerFrame);
+        EXPECT_CALL(*block_processor_mock, ProcessCapture(_, false, _, _))
+            .Times(kExpectedNumBlocksToProcess - kNumFullBlocksPerFrame);
+      } break;
+      case SaturationTestVariant::kOnePositive: {
+        ::testing::InSequence s;
+        EXPECT_CALL(*block_processor_mock, ProcessCapture(_, true, _, _))
+            .Times(kNumFullBlocksPerFrame);
+        EXPECT_CALL(*block_processor_mock, ProcessCapture(_, false, _, _))
+            .Times(kExpectedNumBlocksToProcess - kNumFullBlocksPerFrame);
+      } break;
+    }
+
+    EchoCanceller3 aec3(EchoCanceller3Config(), sample_rate_hz_, 1, 1,
+                        std::move(block_processor_mock));
+    for (size_t frame_index = 0; frame_index < kNumFramesToProcess;
+         ++frame_index) {
+      for (int k = 0; k < fullband_frame_length_; ++k) {
+        capture_buffer_.channels()[0][k] = 0.f;
+      }
+      switch (saturation_variant) {
+        case SaturationTestVariant::kNone:
+          break;
+        case SaturationTestVariant::kOneNegative:
+          if (frame_index == 0) {
+            capture_buffer_.channels()[0][10] = -32768.f;
+          }
+          break;
+        case SaturationTestVariant::kOnePositive:
+          if (frame_index == 0) {
+            capture_buffer_.channels()[0][10] = 32767.f;
+          }
+          break;
+      }
+
+      aec3.AnalyzeCapture(&capture_buffer_);
+      OptionalBandSplit();
+
+      PopulateInputFrame(frame_length_, num_bands_, frame_index,
+                         &capture_buffer_.split_bands(0)[0], 0);
+      PopulateInputFrame(frame_length_, num_bands_, frame_index,
+                         &render_buffer_.split_bands(0)[0], 0);
+
+      aec3.AnalyzeRender(&render_buffer_);
+      aec3.ProcessCapture(&capture_buffer_, false);
+    }
+  }
+
+  // This test verifies that the swapqueue is able to handle jitter in the
+  // capture and render API calls.
+  void RunRenderSwapQueueVerificationTest() {
+    const EchoCanceller3Config config;
+    EchoCanceller3 aec3(
+        config, sample_rate_hz_, 1, 1,
+        std::unique_ptr<BlockProcessor>(
+            new RenderTransportVerificationProcessor(num_bands_)));
+
+    std::vector<std::vector<float>> render_input(1);
+    std::vector<float> capture_output;
+
+    for (size_t frame_index = 0; frame_index < kRenderTransferQueueSizeFrames;
+         ++frame_index) {
+      if (sample_rate_hz_ > 16000) {
+        render_buffer_.SplitIntoFrequencyBands();
+      }
+      PopulateInputFrame(frame_length_, num_bands_, frame_index,
+                         &render_buffer_.split_bands(0)[0], 0);
+
+      if (sample_rate_hz_ > 16000) {
+        render_buffer_.SplitIntoFrequencyBands();
+      }
+
+      for (size_t k = 0; k < frame_length_; ++k) {
+        render_input[0].push_back(render_buffer_.split_bands(0)[0][k]);
+      }
+      aec3.AnalyzeRender(&render_buffer_);
+    }
+
+    for (size_t frame_index = 0; frame_index < kRenderTransferQueueSizeFrames;
+         ++frame_index) {
+      aec3.AnalyzeCapture(&capture_buffer_);
+      if (sample_rate_hz_ > 16000) {
+        capture_buffer_.SplitIntoFrequencyBands();
+      }
+
+      PopulateInputFrame(frame_length_, num_bands_, frame_index,
+                         &capture_buffer_.split_bands(0)[0], 0);
+
+      aec3.ProcessCapture(&capture_buffer_, false);
+      for (size_t k = 0; k < frame_length_; ++k) {
+        capture_output.push_back(capture_buffer_.split_bands(0)[0][k]);
+      }
+    }
+
+    EXPECT_TRUE(
+        VerifyOutputFrameBitexactness(render_input[0], capture_output, -64));
+  }
+
+  // This test verifies that a buffer overrun in the render swapqueue is
+  // properly reported.
+  void RunRenderPipelineSwapQueueOverrunReturnValueTest() {
+    EchoCanceller3 aec3(EchoCanceller3Config(), sample_rate_hz_, 1, 1);
+
+    constexpr size_t kRenderTransferQueueSize = 30;
+    for (size_t k = 0; k < 2; ++k) {
+      for (size_t frame_index = 0; frame_index < kRenderTransferQueueSize;
+           ++frame_index) {
+        if (sample_rate_hz_ > 16000) {
+          render_buffer_.SplitIntoFrequencyBands();
+        }
+        PopulateInputFrame(frame_length_, frame_index,
+                           &render_buffer_.channels()[0][0], 0);
+
+        aec3.AnalyzeRender(&render_buffer_);
+      }
+    }
+  }
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+  // Verifies the that the check for the number of bands in the AnalyzeRender
+  // input is correct by adjusting the sample rates of EchoCanceller3 and the
+  // input AudioBuffer to have a different number of bands.
+  void RunAnalyzeRenderNumBandsCheckVerification() {
+    // Set aec3_sample_rate_hz to be different from sample_rate_hz_ in such a
+    // way that the number of bands for the rates are different.
+    const int aec3_sample_rate_hz = sample_rate_hz_ == 48000 ? 32000 : 48000;
+    EchoCanceller3 aec3(EchoCanceller3Config(), aec3_sample_rate_hz, 1, 1);
+    PopulateInputFrame(frame_length_, 0, &render_buffer_.channels_f()[0][0], 0);
+
+    EXPECT_DEATH(aec3.AnalyzeRender(&render_buffer_), "");
+  }
+
+  // Verifies the that the check for the number of bands in the ProcessCapture
+  // input is correct by adjusting the sample rates of EchoCanceller3 and the
+  // input AudioBuffer to have a different number of bands.
+  void RunProcessCaptureNumBandsCheckVerification() {
+    // Set aec3_sample_rate_hz to be different from sample_rate_hz_ in such a
+    // way that the number of bands for the rates are different.
+    const int aec3_sample_rate_hz = sample_rate_hz_ == 48000 ? 32000 : 48000;
+    EchoCanceller3 aec3(EchoCanceller3Config(), aec3_sample_rate_hz, 1, 1);
+    PopulateInputFrame(frame_length_, num_bands_, 0,
+                       &capture_buffer_.split_bands_f(0)[0], 100);
+    EXPECT_DEATH(aec3.ProcessCapture(&capture_buffer_, false), "");
+  }
+
+#endif
+
+ private:
+  void OptionalBandSplit() {
+    if (sample_rate_hz_ > 16000) {
+      capture_buffer_.SplitIntoFrequencyBands();
+      render_buffer_.SplitIntoFrequencyBands();
+    }
+  }
+
+  static constexpr size_t kNumFramesToProcess = 20;
+  const int sample_rate_hz_;
+  const size_t num_bands_;
+  const size_t frame_length_;
+  const int fullband_frame_length_;
+  AudioBuffer capture_buffer_;
+  AudioBuffer render_buffer_;
+};
+
+std::string ProduceDebugText(int sample_rate_hz) {
+  rtc::StringBuilder ss;
+  ss << "Sample rate: " << sample_rate_hz;
+  return ss.Release();
+}
+
+std::string ProduceDebugText(int sample_rate_hz, int variant) {
+  rtc::StringBuilder ss;
+  ss << "Sample rate: " << sample_rate_hz << ", variant: " << variant;
+  return ss.Release();
+}
+
+}  // namespace
+
+TEST(EchoCanceller3Buffering, CaptureBitexactness) {
+  for (auto rate : {16000, 32000, 48000}) {
+    SCOPED_TRACE(ProduceDebugText(rate));
+    EchoCanceller3Tester(rate).RunCaptureTransportVerificationTest();
+  }
+}
+
+TEST(EchoCanceller3Buffering, RenderBitexactness) {
+  for (auto rate : {16000, 32000, 48000}) {
+    SCOPED_TRACE(ProduceDebugText(rate));
+    EchoCanceller3Tester(rate).RunRenderTransportVerificationTest();
+  }
+}
+
+TEST(EchoCanceller3Buffering, RenderSwapQueue) {
+  EchoCanceller3Tester(16000).RunRenderSwapQueueVerificationTest();
+}
+
+TEST(EchoCanceller3Buffering, RenderSwapQueueOverrunReturnValue) {
+  for (auto rate : {16000, 32000, 48000}) {
+    SCOPED_TRACE(ProduceDebugText(rate));
+    EchoCanceller3Tester(rate)
+        .RunRenderPipelineSwapQueueOverrunReturnValueTest();
+  }
+}
+
+TEST(EchoCanceller3Messaging, CaptureSaturation) {
+  auto variants = {EchoCanceller3Tester::SaturationTestVariant::kNone,
+                   EchoCanceller3Tester::SaturationTestVariant::kOneNegative,
+                   EchoCanceller3Tester::SaturationTestVariant::kOnePositive};
+  for (auto rate : {16000, 32000, 48000}) {
+    for (auto variant : variants) {
+      SCOPED_TRACE(ProduceDebugText(rate, static_cast<int>(variant)));
+      EchoCanceller3Tester(rate).RunCaptureSaturationVerificationTest(variant);
+    }
+  }
+}
+
+TEST(EchoCanceller3Messaging, EchoPathChange) {
+  auto variants = {
+      EchoCanceller3Tester::EchoPathChangeTestVariant::kNone,
+      EchoCanceller3Tester::EchoPathChangeTestVariant::kOneSticky,
+      EchoCanceller3Tester::EchoPathChangeTestVariant::kOneNonSticky};
+  for (auto rate : {16000, 32000, 48000}) {
+    for (auto variant : variants) {
+      SCOPED_TRACE(ProduceDebugText(rate, static_cast<int>(variant)));
+      EchoCanceller3Tester(rate).RunEchoPathChangeVerificationTest(variant);
+    }
+  }
+}
+
+TEST(EchoCanceller3Messaging, EchoLeakage) {
+  auto variants = {
+      EchoCanceller3Tester::EchoLeakageTestVariant::kNone,
+      EchoCanceller3Tester::EchoLeakageTestVariant::kFalseSticky,
+      EchoCanceller3Tester::EchoLeakageTestVariant::kTrueSticky,
+      EchoCanceller3Tester::EchoLeakageTestVariant::kTrueNonSticky};
+  for (auto rate : {16000, 32000, 48000}) {
+    for (auto variant : variants) {
+      SCOPED_TRACE(ProduceDebugText(rate, static_cast<int>(variant)));
+      EchoCanceller3Tester(rate).RunEchoLeakageVerificationTest(variant);
+    }
+  }
+}
+
+// Tests the parameter functionality for the field trial override for the
+// default_len parameter.
+TEST(EchoCanceller3FieldTrials, Aec3SuppressorEpStrengthDefaultLenOverride) {
+  EchoCanceller3Config default_config;
+  EchoCanceller3Config adjusted_config = AdjustConfig(default_config);
+  ASSERT_EQ(default_config.ep_strength.default_len,
+            adjusted_config.ep_strength.default_len);
+
+  webrtc::test::ScopedFieldTrials field_trials(
+      "WebRTC-Aec3SuppressorEpStrengthDefaultLenOverride/-0.02/");
+  adjusted_config = AdjustConfig(default_config);
+
+  ASSERT_NE(default_config.ep_strength.default_len,
+            adjusted_config.ep_strength.default_len);
+  EXPECT_FLOAT_EQ(-0.02f, adjusted_config.ep_strength.default_len);
+}
+
+// Tests the parameter functionality for the field trial override for the
+// anti-howling gain.
+TEST(EchoCanceller3FieldTrials, Aec3SuppressorAntiHowlingGainOverride) {
+  EchoCanceller3Config default_config;
+  EchoCanceller3Config adjusted_config = AdjustConfig(default_config);
+  ASSERT_EQ(
+      default_config.suppressor.high_bands_suppression.anti_howling_gain,
+      adjusted_config.suppressor.high_bands_suppression.anti_howling_gain);
+
+  webrtc::test::ScopedFieldTrials field_trials(
+      "WebRTC-Aec3SuppressorAntiHowlingGainOverride/0.02/");
+  adjusted_config = AdjustConfig(default_config);
+
+  ASSERT_NE(
+      default_config.suppressor.high_bands_suppression.anti_howling_gain,
+      adjusted_config.suppressor.high_bands_suppression.anti_howling_gain);
+  EXPECT_FLOAT_EQ(
+      0.02f,
+      adjusted_config.suppressor.high_bands_suppression.anti_howling_gain);
+}
+
+// Tests the field trial override for the enforcement of a low active render
+// limit.
+TEST(EchoCanceller3FieldTrials, Aec3EnforceLowActiveRenderLimit) {
+  EchoCanceller3Config default_config;
+  EchoCanceller3Config adjusted_config = AdjustConfig(default_config);
+  ASSERT_EQ(default_config.render_levels.active_render_limit,
+            adjusted_config.render_levels.active_render_limit);
+
+  webrtc::test::ScopedFieldTrials field_trials(
+      "WebRTC-Aec3EnforceLowActiveRenderLimit/Enabled/");
+  adjusted_config = AdjustConfig(default_config);
+
+  ASSERT_NE(default_config.render_levels.active_render_limit,
+            adjusted_config.render_levels.active_render_limit);
+  EXPECT_FLOAT_EQ(50.f, adjusted_config.render_levels.active_render_limit);
+}
+
+// Testing the field trial-based override of the suppressor parameters for a
+// joint passing of all parameters.
+TEST(EchoCanceller3FieldTrials, Aec3SuppressorTuningOverrideAllParams) {
+  webrtc::test::ScopedFieldTrials field_trials(
+      "WebRTC-Aec3SuppressorTuningOverride/"
+      "nearend_tuning_mask_lf_enr_transparent:0.1,nearend_tuning_mask_lf_enr_"
+      "suppress:0.2,nearend_tuning_mask_hf_enr_transparent:0.3,nearend_tuning_"
+      "mask_hf_enr_suppress:0.4,nearend_tuning_max_inc_factor:0.5,nearend_"
+      "tuning_max_dec_factor_lf:0.6,normal_tuning_mask_lf_enr_transparent:0.7,"
+      "normal_tuning_mask_lf_enr_suppress:0.8,normal_tuning_mask_hf_enr_"
+      "transparent:0.9,normal_tuning_mask_hf_enr_suppress:1.0,normal_tuning_"
+      "max_inc_factor:1.1,normal_tuning_max_dec_factor_lf:1.2,dominant_nearend_"
+      "detection_enr_threshold:1.3,dominant_nearend_detection_enr_exit_"
+      "threshold:1.4,dominant_nearend_detection_snr_threshold:1.5,dominant_"
+      "nearend_detection_hold_duration:10,dominant_nearend_detection_trigger_"
+      "threshold:11,ep_strength_default_len:1.6/");
+
+  EchoCanceller3Config default_config;
+  EchoCanceller3Config adjusted_config = AdjustConfig(default_config);
+
+  ASSERT_NE(adjusted_config.suppressor.nearend_tuning.mask_lf.enr_transparent,
+            default_config.suppressor.nearend_tuning.mask_lf.enr_transparent);
+  ASSERT_NE(adjusted_config.suppressor.nearend_tuning.mask_lf.enr_suppress,
+            default_config.suppressor.nearend_tuning.mask_lf.enr_suppress);
+  ASSERT_NE(adjusted_config.suppressor.nearend_tuning.mask_hf.enr_transparent,
+            default_config.suppressor.nearend_tuning.mask_hf.enr_transparent);
+  ASSERT_NE(adjusted_config.suppressor.nearend_tuning.mask_hf.enr_suppress,
+            default_config.suppressor.nearend_tuning.mask_hf.enr_suppress);
+  ASSERT_NE(adjusted_config.suppressor.nearend_tuning.max_inc_factor,
+            default_config.suppressor.nearend_tuning.max_inc_factor);
+  ASSERT_NE(adjusted_config.suppressor.nearend_tuning.max_dec_factor_lf,
+            default_config.suppressor.nearend_tuning.max_dec_factor_lf);
+  ASSERT_NE(adjusted_config.suppressor.normal_tuning.mask_lf.enr_transparent,
+            default_config.suppressor.normal_tuning.mask_lf.enr_transparent);
+  ASSERT_NE(adjusted_config.suppressor.normal_tuning.mask_lf.enr_suppress,
+            default_config.suppressor.normal_tuning.mask_lf.enr_suppress);
+  ASSERT_NE(adjusted_config.suppressor.normal_tuning.mask_hf.enr_transparent,
+            default_config.suppressor.normal_tuning.mask_hf.enr_transparent);
+  ASSERT_NE(adjusted_config.suppressor.normal_tuning.mask_hf.enr_suppress,
+            default_config.suppressor.normal_tuning.mask_hf.enr_suppress);
+  ASSERT_NE(adjusted_config.suppressor.normal_tuning.max_inc_factor,
+            default_config.suppressor.normal_tuning.max_inc_factor);
+  ASSERT_NE(adjusted_config.suppressor.normal_tuning.max_dec_factor_lf,
+            default_config.suppressor.normal_tuning.max_dec_factor_lf);
+  ASSERT_NE(adjusted_config.suppressor.dominant_nearend_detection.enr_threshold,
+            default_config.suppressor.dominant_nearend_detection.enr_threshold);
+  ASSERT_NE(
+      adjusted_config.suppressor.dominant_nearend_detection.enr_exit_threshold,
+      default_config.suppressor.dominant_nearend_detection.enr_exit_threshold);
+  ASSERT_NE(adjusted_config.suppressor.dominant_nearend_detection.snr_threshold,
+            default_config.suppressor.dominant_nearend_detection.snr_threshold);
+  ASSERT_NE(adjusted_config.suppressor.dominant_nearend_detection.hold_duration,
+            default_config.suppressor.dominant_nearend_detection.hold_duration);
+  ASSERT_NE(
+      adjusted_config.suppressor.dominant_nearend_detection.trigger_threshold,
+      default_config.suppressor.dominant_nearend_detection.trigger_threshold);
+  ASSERT_NE(adjusted_config.ep_strength.default_len,
+            default_config.ep_strength.default_len);
+
+  EXPECT_FLOAT_EQ(
+      adjusted_config.suppressor.nearend_tuning.mask_lf.enr_transparent, 0.1);
+  EXPECT_FLOAT_EQ(
+      adjusted_config.suppressor.nearend_tuning.mask_lf.enr_suppress, 0.2);
+  EXPECT_FLOAT_EQ(
+      adjusted_config.suppressor.nearend_tuning.mask_hf.enr_transparent, 0.3);
+  EXPECT_FLOAT_EQ(
+      adjusted_config.suppressor.nearend_tuning.mask_hf.enr_suppress, 0.4);
+  EXPECT_FLOAT_EQ(adjusted_config.suppressor.nearend_tuning.max_inc_factor,
+                  0.5);
+  EXPECT_FLOAT_EQ(adjusted_config.suppressor.nearend_tuning.max_dec_factor_lf,
+                  0.6);
+  EXPECT_FLOAT_EQ(
+      adjusted_config.suppressor.normal_tuning.mask_lf.enr_transparent, 0.7);
+  EXPECT_FLOAT_EQ(adjusted_config.suppressor.normal_tuning.mask_lf.enr_suppress,
+                  0.8);
+  EXPECT_FLOAT_EQ(
+      adjusted_config.suppressor.normal_tuning.mask_hf.enr_transparent, 0.9);
+  EXPECT_FLOAT_EQ(adjusted_config.suppressor.normal_tuning.mask_hf.enr_suppress,
+                  1.0);
+  EXPECT_FLOAT_EQ(adjusted_config.suppressor.normal_tuning.max_inc_factor, 1.1);
+  EXPECT_FLOAT_EQ(adjusted_config.suppressor.normal_tuning.max_dec_factor_lf,
+                  1.2);
+  EXPECT_FLOAT_EQ(
+      adjusted_config.suppressor.dominant_nearend_detection.enr_threshold, 1.3);
+  EXPECT_FLOAT_EQ(
+      adjusted_config.suppressor.dominant_nearend_detection.enr_exit_threshold,
+      1.4);
+  EXPECT_FLOAT_EQ(
+      adjusted_config.suppressor.dominant_nearend_detection.snr_threshold, 1.5);
+  EXPECT_EQ(adjusted_config.suppressor.dominant_nearend_detection.hold_duration,
+            10);
+  EXPECT_EQ(
+      adjusted_config.suppressor.dominant_nearend_detection.trigger_threshold,
+      11);
+  EXPECT_FLOAT_EQ(adjusted_config.ep_strength.default_len, 1.6);
+}
+
+// Testing the field trial-based override of the suppressor parameters for
+// passing one parameter.
+TEST(EchoCanceller3FieldTrials, Aec3SuppressorTuningOverrideOneParam) {
+  webrtc::test::ScopedFieldTrials field_trials(
+      "WebRTC-Aec3SuppressorTuningOverride/nearend_tuning_max_inc_factor:0.5/");
+
+  EchoCanceller3Config default_config;
+  EchoCanceller3Config adjusted_config = AdjustConfig(default_config);
+
+  ASSERT_EQ(adjusted_config.suppressor.nearend_tuning.mask_lf.enr_transparent,
+            default_config.suppressor.nearend_tuning.mask_lf.enr_transparent);
+  ASSERT_EQ(adjusted_config.suppressor.nearend_tuning.mask_lf.enr_suppress,
+            default_config.suppressor.nearend_tuning.mask_lf.enr_suppress);
+  ASSERT_EQ(adjusted_config.suppressor.nearend_tuning.mask_hf.enr_transparent,
+            default_config.suppressor.nearend_tuning.mask_hf.enr_transparent);
+  ASSERT_EQ(adjusted_config.suppressor.nearend_tuning.mask_hf.enr_suppress,
+            default_config.suppressor.nearend_tuning.mask_hf.enr_suppress);
+  ASSERT_EQ(adjusted_config.suppressor.nearend_tuning.max_dec_factor_lf,
+            default_config.suppressor.nearend_tuning.max_dec_factor_lf);
+  ASSERT_EQ(adjusted_config.suppressor.normal_tuning.mask_lf.enr_transparent,
+            default_config.suppressor.normal_tuning.mask_lf.enr_transparent);
+  ASSERT_EQ(adjusted_config.suppressor.normal_tuning.mask_lf.enr_suppress,
+            default_config.suppressor.normal_tuning.mask_lf.enr_suppress);
+  ASSERT_EQ(adjusted_config.suppressor.normal_tuning.mask_hf.enr_transparent,
+            default_config.suppressor.normal_tuning.mask_hf.enr_transparent);
+  ASSERT_EQ(adjusted_config.suppressor.normal_tuning.mask_hf.enr_suppress,
+            default_config.suppressor.normal_tuning.mask_hf.enr_suppress);
+  ASSERT_EQ(adjusted_config.suppressor.normal_tuning.max_inc_factor,
+            default_config.suppressor.normal_tuning.max_inc_factor);
+  ASSERT_EQ(adjusted_config.suppressor.normal_tuning.max_dec_factor_lf,
+            default_config.suppressor.normal_tuning.max_dec_factor_lf);
+  ASSERT_EQ(adjusted_config.suppressor.dominant_nearend_detection.enr_threshold,
+            default_config.suppressor.dominant_nearend_detection.enr_threshold);
+  ASSERT_EQ(
+      adjusted_config.suppressor.dominant_nearend_detection.enr_exit_threshold,
+      default_config.suppressor.dominant_nearend_detection.enr_exit_threshold);
+  ASSERT_EQ(adjusted_config.suppressor.dominant_nearend_detection.snr_threshold,
+            default_config.suppressor.dominant_nearend_detection.snr_threshold);
+  ASSERT_EQ(adjusted_config.suppressor.dominant_nearend_detection.hold_duration,
+            default_config.suppressor.dominant_nearend_detection.hold_duration);
+  ASSERT_EQ(
+      adjusted_config.suppressor.dominant_nearend_detection.trigger_threshold,
+      default_config.suppressor.dominant_nearend_detection.trigger_threshold);
+
+  ASSERT_NE(adjusted_config.suppressor.nearend_tuning.max_inc_factor,
+            default_config.suppressor.nearend_tuning.max_inc_factor);
+
+  EXPECT_FLOAT_EQ(adjusted_config.suppressor.nearend_tuning.max_inc_factor,
+                  0.5);
+}
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+TEST(EchoCanceller3InputCheckDeathTest, WrongCaptureNumBandsCheckVerification) {
+  for (auto rate : {16000, 32000, 48000}) {
+    SCOPED_TRACE(ProduceDebugText(rate));
+    EchoCanceller3Tester(rate).RunProcessCaptureNumBandsCheckVerification();
+  }
+}
+
+// Verifiers that the verification for null input to the capture processing api
+// call works.
+TEST(EchoCanceller3InputCheckDeathTest, NullCaptureProcessingParameter) {
+  EXPECT_DEATH(EchoCanceller3(EchoCanceller3Config(), 16000, 1, 1)
+                   .ProcessCapture(nullptr, false),
+               "");
+}
+
+// Verifies the check for correct sample rate.
+// TODO(peah): Re-enable the test once the issue with memory leaks during DEATH
+// tests on test bots has been fixed.
+TEST(EchoCanceller3InputCheckDeathTest, DISABLED_WrongSampleRate) {
+  ApmDataDumper data_dumper(0);
+  EXPECT_DEATH(EchoCanceller3(EchoCanceller3Config(), 8001, 1, 1), "");
+}
+
+#endif
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_delay_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_delay_estimator.cc
new file mode 100644
index 0000000..2c987f9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_delay_estimator.cc
@@ -0,0 +1,125 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "modules/audio_processing/aec3/echo_path_delay_estimator.h"
+
+#include <array>
+
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/downsampled_render_buffer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+EchoPathDelayEstimator::EchoPathDelayEstimator(
+    ApmDataDumper* data_dumper,
+    const EchoCanceller3Config& config,
+    size_t num_capture_channels)
+    : data_dumper_(data_dumper),
+      down_sampling_factor_(config.delay.down_sampling_factor),
+      sub_block_size_(down_sampling_factor_ != 0
+                          ? kBlockSize / down_sampling_factor_
+                          : kBlockSize),
+      capture_mixer_(num_capture_channels,
+                     config.delay.capture_alignment_mixing),
+      capture_decimator_(down_sampling_factor_),
+      matched_filter_(
+          data_dumper_,
+          DetectOptimization(),
+          sub_block_size_,
+          kMatchedFilterWindowSizeSubBlocks,
+          config.delay.num_filters,
+          kMatchedFilterAlignmentShiftSizeSubBlocks,
+          config.delay.down_sampling_factor == 8
+              ? config.render_levels.poor_excitation_render_limit_ds8
+              : config.render_levels.poor_excitation_render_limit,
+          config.delay.delay_estimate_smoothing,
+          config.delay.delay_candidate_detection_threshold),
+      matched_filter_lag_aggregator_(data_dumper_,
+                                     matched_filter_.GetMaxFilterLag(),
+                                     config.delay.delay_selection_thresholds) {
+  RTC_DCHECK(data_dumper);
+  RTC_DCHECK(down_sampling_factor_ > 0);
+}
+
+EchoPathDelayEstimator::~EchoPathDelayEstimator() = default;
+
+void EchoPathDelayEstimator::Reset(bool reset_delay_confidence) {
+  Reset(true, reset_delay_confidence);
+}
+
+absl::optional<DelayEstimate> EchoPathDelayEstimator::EstimateDelay(
+    const DownsampledRenderBuffer& render_buffer,
+    const std::vector<std::vector<float>>& capture) {
+  RTC_DCHECK_EQ(kBlockSize, capture[0].size());
+
+  std::array<float, kBlockSize> downsampled_capture_data;
+  rtc::ArrayView<float> downsampled_capture(downsampled_capture_data.data(),
+                                            sub_block_size_);
+
+  std::array<float, kBlockSize> downmixed_capture;
+  capture_mixer_.ProduceOutput(capture, downmixed_capture);
+  capture_decimator_.Decimate(downmixed_capture, downsampled_capture);
+  data_dumper_->DumpWav("aec3_capture_decimator_output",
+                        downsampled_capture.size(), downsampled_capture.data(),
+                        16000 / down_sampling_factor_, 1);
+  matched_filter_.Update(render_buffer, downsampled_capture);
+
+  absl::optional<DelayEstimate> aggregated_matched_filter_lag =
+      matched_filter_lag_aggregator_.Aggregate(
+          matched_filter_.GetLagEstimates());
+
+  // Run clockdrift detection.
+  if (aggregated_matched_filter_lag &&
+      (*aggregated_matched_filter_lag).quality ==
+          DelayEstimate::Quality::kRefined)
+    clockdrift_detector_.Update((*aggregated_matched_filter_lag).delay);
+
+  // TODO(peah): Move this logging outside of this class once EchoCanceller3
+  // development is done.
+  data_dumper_->DumpRaw(
+      "aec3_echo_path_delay_estimator_delay",
+      aggregated_matched_filter_lag
+          ? static_cast<int>(aggregated_matched_filter_lag->delay *
+                             down_sampling_factor_)
+          : -1);
+
+  // Return the detected delay in samples as the aggregated matched filter lag
+  // compensated by the down sampling factor for the signal being correlated.
+  if (aggregated_matched_filter_lag) {
+    aggregated_matched_filter_lag->delay *= down_sampling_factor_;
+  }
+
+  if (old_aggregated_lag_ && aggregated_matched_filter_lag &&
+      old_aggregated_lag_->delay == aggregated_matched_filter_lag->delay) {
+    ++consistent_estimate_counter_;
+  } else {
+    consistent_estimate_counter_ = 0;
+  }
+  old_aggregated_lag_ = aggregated_matched_filter_lag;
+  constexpr size_t kNumBlocksPerSecondBy2 = kNumBlocksPerSecond / 2;
+  if (consistent_estimate_counter_ > kNumBlocksPerSecondBy2) {
+    Reset(false, false);
+  }
+
+  return aggregated_matched_filter_lag;
+}
+
+void EchoPathDelayEstimator::Reset(bool reset_lag_aggregator,
+                                   bool reset_delay_confidence) {
+  if (reset_lag_aggregator) {
+    matched_filter_lag_aggregator_.Reset(reset_delay_confidence);
+  }
+  matched_filter_.Reset();
+  old_aggregated_lag_ = absl::nullopt;
+  consistent_estimate_counter_ = 0;
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_delay_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_delay_estimator.h
new file mode 100644
index 0000000..6c8c212
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_delay_estimator.h
@@ -0,0 +1,79 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_ECHO_PATH_DELAY_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_ECHO_PATH_DELAY_ESTIMATOR_H_
+
+#include <stddef.h>
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/alignment_mixer.h"
+#include "modules/audio_processing/aec3/clockdrift_detector.h"
+#include "modules/audio_processing/aec3/decimator.h"
+#include "modules/audio_processing/aec3/delay_estimate.h"
+#include "modules/audio_processing/aec3/matched_filter.h"
+#include "modules/audio_processing/aec3/matched_filter_lag_aggregator.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+class ApmDataDumper;
+struct DownsampledRenderBuffer;
+struct EchoCanceller3Config;
+
+// Estimates the delay of the echo path.
+class EchoPathDelayEstimator {
+ public:
+  EchoPathDelayEstimator(ApmDataDumper* data_dumper,
+                         const EchoCanceller3Config& config,
+                         size_t num_capture_channels);
+  ~EchoPathDelayEstimator();
+
+  // Resets the estimation. If the delay confidence is reset, the reset behavior
+  // is as if the call is restarted.
+  void Reset(bool reset_delay_confidence);
+
+  // Produce a delay estimate if such is avaliable.
+  absl::optional<DelayEstimate> EstimateDelay(
+      const DownsampledRenderBuffer& render_buffer,
+      const std::vector<std::vector<float>>& capture);
+
+  // Log delay estimator properties.
+  void LogDelayEstimationProperties(int sample_rate_hz, size_t shift) const {
+    matched_filter_.LogFilterProperties(sample_rate_hz, shift,
+                                        down_sampling_factor_);
+  }
+
+  // Returns the level of detected clockdrift.
+  ClockdriftDetector::Level Clockdrift() const {
+    return clockdrift_detector_.ClockdriftLevel();
+  }
+
+ private:
+  ApmDataDumper* const data_dumper_;
+  const size_t down_sampling_factor_;
+  const size_t sub_block_size_;
+  AlignmentMixer capture_mixer_;
+  Decimator capture_decimator_;
+  MatchedFilter matched_filter_;
+  MatchedFilterLagAggregator matched_filter_lag_aggregator_;
+  absl::optional<DelayEstimate> old_aggregated_lag_;
+  size_t consistent_estimate_counter_ = 0;
+  ClockdriftDetector clockdrift_detector_;
+
+  // Internal reset method with more granularity.
+  void Reset(bool reset_lag_aggregator, bool reset_delay_confidence);
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(EchoPathDelayEstimator);
+};
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_ECHO_PATH_DELAY_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_delay_estimator_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_delay_estimator_unittest.cc
new file mode 100644
index 0000000..6ba4cdd
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_delay_estimator_unittest.cc
@@ -0,0 +1,203 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/echo_path_delay_estimator.h"
+
+#include <algorithm>
+#include <string>
+
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "modules/audio_processing/test/echo_canceller_test_tools.h"
+#include "rtc_base/random.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace {
+
+std::string ProduceDebugText(size_t delay, size_t down_sampling_factor) {
+  rtc::StringBuilder ss;
+  ss << "Delay: " << delay;
+  ss << ", Down sampling factor: " << down_sampling_factor;
+  return ss.Release();
+}
+
+}  // namespace
+
+class EchoPathDelayEstimatorMultiChannel
+    : public ::testing::Test,
+      public ::testing::WithParamInterface<std::tuple<size_t, size_t>> {};
+
+INSTANTIATE_TEST_SUITE_P(MultiChannel,
+                         EchoPathDelayEstimatorMultiChannel,
+                         ::testing::Combine(::testing::Values(1, 2, 3, 6, 8),
+                                            ::testing::Values(1, 2, 4)));
+
+// Verifies that the basic API calls work.
+TEST_P(EchoPathDelayEstimatorMultiChannel, BasicApiCalls) {
+  const size_t num_render_channels = std::get<0>(GetParam());
+  const size_t num_capture_channels = std::get<1>(GetParam());
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+  ApmDataDumper data_dumper(0);
+  EchoCanceller3Config config;
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+      RenderDelayBuffer::Create(config, kSampleRateHz, num_render_channels));
+  EchoPathDelayEstimator estimator(&data_dumper, config, num_capture_channels);
+  std::vector<std::vector<std::vector<float>>> render(
+      kNumBands, std::vector<std::vector<float>>(
+                     num_render_channels, std::vector<float>(kBlockSize)));
+  std::vector<std::vector<float>> capture(num_capture_channels,
+                                          std::vector<float>(kBlockSize));
+  for (size_t k = 0; k < 100; ++k) {
+    render_delay_buffer->Insert(render);
+    estimator.EstimateDelay(render_delay_buffer->GetDownsampledRenderBuffer(),
+                            capture);
+  }
+}
+
+// Verifies that the delay estimator produces correct delay for artificially
+// delayed signals.
+TEST(EchoPathDelayEstimator, DelayEstimation) {
+  constexpr size_t kNumRenderChannels = 1;
+  constexpr size_t kNumCaptureChannels = 1;
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+
+  Random random_generator(42U);
+  std::vector<std::vector<std::vector<float>>> render(
+      kNumBands, std::vector<std::vector<float>>(
+                     kNumRenderChannels, std::vector<float>(kBlockSize)));
+  std::vector<std::vector<float>> capture(kNumCaptureChannels,
+                                          std::vector<float>(kBlockSize));
+  ApmDataDumper data_dumper(0);
+  constexpr size_t kDownSamplingFactors[] = {2, 4, 8};
+  for (auto down_sampling_factor : kDownSamplingFactors) {
+    EchoCanceller3Config config;
+    config.delay.down_sampling_factor = down_sampling_factor;
+    config.delay.num_filters = 10;
+    for (size_t delay_samples : {30, 64, 150, 200, 800, 4000}) {
+      SCOPED_TRACE(ProduceDebugText(delay_samples, down_sampling_factor));
+      std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+          RenderDelayBuffer::Create(config, kSampleRateHz, kNumRenderChannels));
+      DelayBuffer<float> signal_delay_buffer(delay_samples);
+      EchoPathDelayEstimator estimator(&data_dumper, config,
+                                       kNumCaptureChannels);
+
+      absl::optional<DelayEstimate> estimated_delay_samples;
+      for (size_t k = 0; k < (500 + (delay_samples) / kBlockSize); ++k) {
+        RandomizeSampleVector(&random_generator, render[0][0]);
+        signal_delay_buffer.Delay(render[0][0], capture[0]);
+        render_delay_buffer->Insert(render);
+
+        if (k == 0) {
+          render_delay_buffer->Reset();
+        }
+
+        render_delay_buffer->PrepareCaptureProcessing();
+
+        auto estimate = estimator.EstimateDelay(
+            render_delay_buffer->GetDownsampledRenderBuffer(), capture);
+
+        if (estimate) {
+          estimated_delay_samples = estimate;
+        }
+      }
+
+      if (estimated_delay_samples) {
+        // Allow estimated delay to be off by one sample in the down-sampled
+        // domain.
+        size_t delay_ds = delay_samples / down_sampling_factor;
+        size_t estimated_delay_ds =
+            estimated_delay_samples->delay / down_sampling_factor;
+        EXPECT_NEAR(delay_ds, estimated_delay_ds, 1);
+      } else {
+        ADD_FAILURE();
+      }
+    }
+  }
+}
+
+// Verifies that the delay estimator does not produce delay estimates for render
+// signals of low level.
+TEST(EchoPathDelayEstimator, NoDelayEstimatesForLowLevelRenderSignals) {
+  constexpr size_t kNumRenderChannels = 1;
+  constexpr size_t kNumCaptureChannels = 1;
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+  Random random_generator(42U);
+  EchoCanceller3Config config;
+  std::vector<std::vector<std::vector<float>>> render(
+      kNumBands, std::vector<std::vector<float>>(
+                     kNumRenderChannels, std::vector<float>(kBlockSize)));
+  std::vector<std::vector<float>> capture(kNumCaptureChannels,
+                                          std::vector<float>(kBlockSize));
+  ApmDataDumper data_dumper(0);
+  EchoPathDelayEstimator estimator(&data_dumper, config, kNumCaptureChannels);
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+      RenderDelayBuffer::Create(EchoCanceller3Config(), kSampleRateHz,
+                                kNumRenderChannels));
+  for (size_t k = 0; k < 100; ++k) {
+    RandomizeSampleVector(&random_generator, render[0][0]);
+    for (auto& render_k : render[0][0]) {
+      render_k *= 100.f / 32767.f;
+    }
+    std::copy(render[0][0].begin(), render[0][0].end(), capture[0].begin());
+    render_delay_buffer->Insert(render);
+    render_delay_buffer->PrepareCaptureProcessing();
+    EXPECT_FALSE(estimator.EstimateDelay(
+        render_delay_buffer->GetDownsampledRenderBuffer(), capture));
+  }
+}
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+// Verifies the check for the render blocksize.
+// TODO(peah): Re-enable the test once the issue with memory leaks during DEATH
+// tests on test bots has been fixed.
+TEST(EchoPathDelayEstimatorDeathTest, DISABLED_WrongRenderBlockSize) {
+  ApmDataDumper data_dumper(0);
+  EchoCanceller3Config config;
+  EchoPathDelayEstimator estimator(&data_dumper, config, 1);
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+      RenderDelayBuffer::Create(config, 48000, 1));
+  std::vector<std::vector<float>> capture(1, std::vector<float>(kBlockSize));
+  EXPECT_DEATH(estimator.EstimateDelay(
+                   render_delay_buffer->GetDownsampledRenderBuffer(), capture),
+               "");
+}
+
+// Verifies the check for the capture blocksize.
+// TODO(peah): Re-enable the test once the issue with memory leaks during DEATH
+// tests on test bots has been fixed.
+TEST(EchoPathDelayEstimatorDeathTest, WrongCaptureBlockSize) {
+  ApmDataDumper data_dumper(0);
+  EchoCanceller3Config config;
+  EchoPathDelayEstimator estimator(&data_dumper, config, 1);
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+      RenderDelayBuffer::Create(config, 48000, 1));
+  std::vector<std::vector<float>> capture(1,
+                                          std::vector<float>(kBlockSize - 1));
+  EXPECT_DEATH(estimator.EstimateDelay(
+                   render_delay_buffer->GetDownsampledRenderBuffer(), capture),
+               "");
+}
+
+// Verifies the check for non-null data dumper.
+TEST(EchoPathDelayEstimatorDeathTest, NullDataDumper) {
+  EXPECT_DEATH(EchoPathDelayEstimator(nullptr, EchoCanceller3Config(), 1), "");
+}
+
+#endif
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_variability.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_variability.cc
new file mode 100644
index 0000000..0ae9cff
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_variability.cc
@@ -0,0 +1,22 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/echo_path_variability.h"
+
+namespace webrtc {
+
+EchoPathVariability::EchoPathVariability(bool gain_change,
+                                         DelayAdjustment delay_change,
+                                         bool clock_drift)
+    : gain_change(gain_change),
+      delay_change(delay_change),
+      clock_drift(clock_drift) {}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_variability.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_variability.h
new file mode 100644
index 0000000..78e4f64
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_variability.h
@@ -0,0 +1,37 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_ECHO_PATH_VARIABILITY_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_ECHO_PATH_VARIABILITY_H_
+
+namespace webrtc {
+
+struct EchoPathVariability {
+  enum class DelayAdjustment {
+    kNone,
+    kBufferFlush,
+    kNewDetectedDelay
+  };
+
+  EchoPathVariability(bool gain_change,
+                      DelayAdjustment delay_change,
+                      bool clock_drift);
+
+  bool AudioPathChanged() const {
+    return gain_change || delay_change != DelayAdjustment::kNone;
+  }
+  bool gain_change;
+  DelayAdjustment delay_change;
+  bool clock_drift;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_ECHO_PATH_VARIABILITY_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_variability_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_variability_unittest.cc
new file mode 100644
index 0000000..0f10f95
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_path_variability_unittest.cc
@@ -0,0 +1,50 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/echo_path_variability.h"
+
+#include "test/gtest.h"
+
+namespace webrtc {
+
+TEST(EchoPathVariability, CorrectBehavior) {
+  // Test correct passing and reporting of the gain change information.
+  EchoPathVariability v(
+      true, EchoPathVariability::DelayAdjustment::kNewDetectedDelay, false);
+  EXPECT_TRUE(v.gain_change);
+  EXPECT_TRUE(v.delay_change ==
+              EchoPathVariability::DelayAdjustment::kNewDetectedDelay);
+  EXPECT_TRUE(v.AudioPathChanged());
+  EXPECT_FALSE(v.clock_drift);
+
+  v = EchoPathVariability(true, EchoPathVariability::DelayAdjustment::kNone,
+                          false);
+  EXPECT_TRUE(v.gain_change);
+  EXPECT_TRUE(v.delay_change == EchoPathVariability::DelayAdjustment::kNone);
+  EXPECT_TRUE(v.AudioPathChanged());
+  EXPECT_FALSE(v.clock_drift);
+
+  v = EchoPathVariability(
+      false, EchoPathVariability::DelayAdjustment::kNewDetectedDelay, false);
+  EXPECT_FALSE(v.gain_change);
+  EXPECT_TRUE(v.delay_change ==
+              EchoPathVariability::DelayAdjustment::kNewDetectedDelay);
+  EXPECT_TRUE(v.AudioPathChanged());
+  EXPECT_FALSE(v.clock_drift);
+
+  v = EchoPathVariability(false, EchoPathVariability::DelayAdjustment::kNone,
+                          false);
+  EXPECT_FALSE(v.gain_change);
+  EXPECT_TRUE(v.delay_change == EchoPathVariability::DelayAdjustment::kNone);
+  EXPECT_FALSE(v.AudioPathChanged());
+  EXPECT_FALSE(v.clock_drift);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover.cc
new file mode 100644
index 0000000..6c177c9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover.cc
@@ -0,0 +1,517 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "modules/audio_processing/aec3/echo_remover.h"
+
+#include <math.h>
+#include <stddef.h>
+
+#include <algorithm>
+#include <array>
+#include <cmath>
+#include <memory>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/aec3_fft.h"
+#include "modules/audio_processing/aec3/aec_state.h"
+#include "modules/audio_processing/aec3/comfort_noise_generator.h"
+#include "modules/audio_processing/aec3/echo_path_variability.h"
+#include "modules/audio_processing/aec3/echo_remover_metrics.h"
+#include "modules/audio_processing/aec3/fft_data.h"
+#include "modules/audio_processing/aec3/render_buffer.h"
+#include "modules/audio_processing/aec3/render_signal_analyzer.h"
+#include "modules/audio_processing/aec3/residual_echo_estimator.h"
+#include "modules/audio_processing/aec3/subtractor.h"
+#include "modules/audio_processing/aec3/subtractor_output.h"
+#include "modules/audio_processing/aec3/suppression_filter.h"
+#include "modules/audio_processing/aec3/suppression_gain.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/atomic_ops.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+
+namespace webrtc {
+
+namespace {
+
+// Maximum number of channels for which the capture channel data is stored on
+// the stack. If the number of channels are larger than this, they are stored
+// using scratch memory that is pre-allocated on the heap. The reason for this
+// partitioning is not to waste heap space for handling the more common numbers
+// of channels, while at the same time not limiting the support for higher
+// numbers of channels by enforcing the capture channel data to be stored on the
+// stack using a fixed maximum value.
+constexpr size_t kMaxNumChannelsOnStack = 2;
+
+// Chooses the number of channels to store on the heap when that is required due
+// to the number of capture channels being larger than the pre-defined number
+// of channels to store on the stack.
+size_t NumChannelsOnHeap(size_t num_capture_channels) {
+  return num_capture_channels > kMaxNumChannelsOnStack ? num_capture_channels
+                                                       : 0;
+}
+
+void LinearEchoPower(const FftData& E,
+                     const FftData& Y,
+                     std::array<float, kFftLengthBy2Plus1>* S2) {
+  for (size_t k = 0; k < E.re.size(); ++k) {
+    (*S2)[k] = (Y.re[k] - E.re[k]) * (Y.re[k] - E.re[k]) +
+               (Y.im[k] - E.im[k]) * (Y.im[k] - E.im[k]);
+  }
+}
+
+// Fades between two input signals using a fix-sized transition.
+void SignalTransition(rtc::ArrayView<const float> from,
+                      rtc::ArrayView<const float> to,
+                      rtc::ArrayView<float> out) {
+  if (from == to) {
+    RTC_DCHECK_EQ(to.size(), out.size());
+    std::copy(to.begin(), to.end(), out.begin());
+  } else {
+    constexpr size_t kTransitionSize = 30;
+    constexpr float kOneByTransitionSizePlusOne = 1.f / (kTransitionSize + 1);
+
+    RTC_DCHECK_EQ(from.size(), to.size());
+    RTC_DCHECK_EQ(from.size(), out.size());
+    RTC_DCHECK_LE(kTransitionSize, out.size());
+
+    for (size_t k = 0; k < kTransitionSize; ++k) {
+      float a = (k + 1) * kOneByTransitionSizePlusOne;
+      out[k] = a * to[k] + (1.f - a) * from[k];
+    }
+
+    std::copy(to.begin() + kTransitionSize, to.end(),
+              out.begin() + kTransitionSize);
+  }
+}
+
+// Computes a windowed (square root Hanning) padded FFT and updates the related
+// memory.
+void WindowedPaddedFft(const Aec3Fft& fft,
+                       rtc::ArrayView<const float> v,
+                       rtc::ArrayView<float> v_old,
+                       FftData* V) {
+  fft.PaddedFft(v, v_old, Aec3Fft::Window::kSqrtHanning, V);
+  std::copy(v.begin(), v.end(), v_old.begin());
+}
+
+// Class for removing the echo from the capture signal.
+class EchoRemoverImpl final : public EchoRemover {
+ public:
+  EchoRemoverImpl(const EchoCanceller3Config& config,
+                  int sample_rate_hz,
+                  size_t num_render_channels,
+                  size_t num_capture_channels);
+  ~EchoRemoverImpl() override;
+  EchoRemoverImpl(const EchoRemoverImpl&) = delete;
+  EchoRemoverImpl& operator=(const EchoRemoverImpl&) = delete;
+
+  void GetMetrics(EchoControl::Metrics* metrics) const override;
+
+  // Removes the echo from a block of samples from the capture signal. The
+  // supplied render signal is assumed to be pre-aligned with the capture
+  // signal.
+  void ProcessCapture(
+      EchoPathVariability echo_path_variability,
+      bool capture_signal_saturation,
+      const absl::optional<DelayEstimate>& external_delay,
+      RenderBuffer* render_buffer,
+      std::vector<std::vector<std::vector<float>>>* linear_output,
+      std::vector<std::vector<std::vector<float>>>* capture) override;
+
+  // Updates the status on whether echo leakage is detected in the output of the
+  // echo remover.
+  void UpdateEchoLeakageStatus(bool leakage_detected) override {
+    echo_leakage_detected_ = leakage_detected;
+  }
+
+  void SetCaptureOutputUsage(bool capture_output_used) override {
+    capture_output_used_ = capture_output_used;
+  }
+
+ private:
+  // Selects which of the coarse and refined linear filter outputs that is most
+  // appropriate to pass to the suppressor and forms the linear filter output by
+  // smoothly transition between those.
+  void FormLinearFilterOutput(const SubtractorOutput& subtractor_output,
+                              rtc::ArrayView<float> output);
+
+  static int instance_count_;
+  const EchoCanceller3Config config_;
+  const Aec3Fft fft_;
+  std::unique_ptr<ApmDataDumper> data_dumper_;
+  const Aec3Optimization optimization_;
+  const int sample_rate_hz_;
+  const size_t num_render_channels_;
+  const size_t num_capture_channels_;
+  const bool use_coarse_filter_output_;
+  Subtractor subtractor_;
+  SuppressionGain suppression_gain_;
+  ComfortNoiseGenerator cng_;
+  SuppressionFilter suppression_filter_;
+  RenderSignalAnalyzer render_signal_analyzer_;
+  ResidualEchoEstimator residual_echo_estimator_;
+  bool echo_leakage_detected_ = false;
+  bool capture_output_used_ = true;
+  AecState aec_state_;
+  EchoRemoverMetrics metrics_;
+  std::vector<std::array<float, kFftLengthBy2>> e_old_;
+  std::vector<std::array<float, kFftLengthBy2>> y_old_;
+  size_t block_counter_ = 0;
+  int gain_change_hangover_ = 0;
+  bool refined_filter_output_last_selected_ = true;
+
+  std::vector<std::array<float, kFftLengthBy2>> e_heap_;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> Y2_heap_;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> E2_heap_;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> R2_heap_;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> S2_linear_heap_;
+  std::vector<FftData> Y_heap_;
+  std::vector<FftData> E_heap_;
+  std::vector<FftData> comfort_noise_heap_;
+  std::vector<FftData> high_band_comfort_noise_heap_;
+  std::vector<SubtractorOutput> subtractor_output_heap_;
+};
+
+int EchoRemoverImpl::instance_count_ = 0;
+
+EchoRemoverImpl::EchoRemoverImpl(const EchoCanceller3Config& config,
+                                 int sample_rate_hz,
+                                 size_t num_render_channels,
+                                 size_t num_capture_channels)
+    : config_(config),
+      fft_(),
+      data_dumper_(
+          new ApmDataDumper(rtc::AtomicOps::Increment(&instance_count_))),
+      optimization_(DetectOptimization()),
+      sample_rate_hz_(sample_rate_hz),
+      num_render_channels_(num_render_channels),
+      num_capture_channels_(num_capture_channels),
+      use_coarse_filter_output_(
+          config_.filter.enable_coarse_filter_output_usage),
+      subtractor_(config,
+                  num_render_channels_,
+                  num_capture_channels_,
+                  data_dumper_.get(),
+                  optimization_),
+      suppression_gain_(config_,
+                        optimization_,
+                        sample_rate_hz,
+                        num_capture_channels),
+      cng_(config_, optimization_, num_capture_channels_),
+      suppression_filter_(optimization_,
+                          sample_rate_hz_,
+                          num_capture_channels_),
+      render_signal_analyzer_(config_),
+      residual_echo_estimator_(config_, num_render_channels),
+      aec_state_(config_, num_capture_channels_),
+      e_old_(num_capture_channels_, {0.f}),
+      y_old_(num_capture_channels_, {0.f}),
+      e_heap_(NumChannelsOnHeap(num_capture_channels_), {0.f}),
+      Y2_heap_(NumChannelsOnHeap(num_capture_channels_)),
+      E2_heap_(NumChannelsOnHeap(num_capture_channels_)),
+      R2_heap_(NumChannelsOnHeap(num_capture_channels_)),
+      S2_linear_heap_(NumChannelsOnHeap(num_capture_channels_)),
+      Y_heap_(NumChannelsOnHeap(num_capture_channels_)),
+      E_heap_(NumChannelsOnHeap(num_capture_channels_)),
+      comfort_noise_heap_(NumChannelsOnHeap(num_capture_channels_)),
+      high_band_comfort_noise_heap_(NumChannelsOnHeap(num_capture_channels_)),
+      subtractor_output_heap_(NumChannelsOnHeap(num_capture_channels_)) {
+  RTC_DCHECK(ValidFullBandRate(sample_rate_hz));
+}
+
+EchoRemoverImpl::~EchoRemoverImpl() = default;
+
+void EchoRemoverImpl::GetMetrics(EchoControl::Metrics* metrics) const {
+  // Echo return loss (ERL) is inverted to go from gain to attenuation.
+  metrics->echo_return_loss = -10.0 * std::log10(aec_state_.ErlTimeDomain());
+  metrics->echo_return_loss_enhancement =
+      Log2TodB(aec_state_.FullBandErleLog2());
+}
+
+void EchoRemoverImpl::ProcessCapture(
+    EchoPathVariability echo_path_variability,
+    bool capture_signal_saturation,
+    const absl::optional<DelayEstimate>& external_delay,
+    RenderBuffer* render_buffer,
+    std::vector<std::vector<std::vector<float>>>* linear_output,
+    std::vector<std::vector<std::vector<float>>>* capture) {
+  ++block_counter_;
+  const std::vector<std::vector<std::vector<float>>>& x =
+      render_buffer->Block(0);
+  std::vector<std::vector<std::vector<float>>>* y = capture;
+  RTC_DCHECK(render_buffer);
+  RTC_DCHECK(y);
+  RTC_DCHECK_EQ(x.size(), NumBandsForRate(sample_rate_hz_));
+  RTC_DCHECK_EQ(y->size(), NumBandsForRate(sample_rate_hz_));
+  RTC_DCHECK_EQ(x[0].size(), num_render_channels_);
+  RTC_DCHECK_EQ((*y)[0].size(), num_capture_channels_);
+  RTC_DCHECK_EQ(x[0][0].size(), kBlockSize);
+  RTC_DCHECK_EQ((*y)[0][0].size(), kBlockSize);
+
+  // Stack allocated data to use when the number of channels is low.
+  std::array<std::array<float, kFftLengthBy2>, kMaxNumChannelsOnStack> e_stack;
+  std::array<std::array<float, kFftLengthBy2Plus1>, kMaxNumChannelsOnStack>
+      Y2_stack;
+  std::array<std::array<float, kFftLengthBy2Plus1>, kMaxNumChannelsOnStack>
+      E2_stack;
+  std::array<std::array<float, kFftLengthBy2Plus1>, kMaxNumChannelsOnStack>
+      R2_stack;
+  std::array<std::array<float, kFftLengthBy2Plus1>, kMaxNumChannelsOnStack>
+      S2_linear_stack;
+  std::array<FftData, kMaxNumChannelsOnStack> Y_stack;
+  std::array<FftData, kMaxNumChannelsOnStack> E_stack;
+  std::array<FftData, kMaxNumChannelsOnStack> comfort_noise_stack;
+  std::array<FftData, kMaxNumChannelsOnStack> high_band_comfort_noise_stack;
+  std::array<SubtractorOutput, kMaxNumChannelsOnStack> subtractor_output_stack;
+
+  rtc::ArrayView<std::array<float, kFftLengthBy2>> e(e_stack.data(),
+                                                     num_capture_channels_);
+  rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>> Y2(
+      Y2_stack.data(), num_capture_channels_);
+  rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>> E2(
+      E2_stack.data(), num_capture_channels_);
+  rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>> R2(
+      R2_stack.data(), num_capture_channels_);
+  rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>> S2_linear(
+      S2_linear_stack.data(), num_capture_channels_);
+  rtc::ArrayView<FftData> Y(Y_stack.data(), num_capture_channels_);
+  rtc::ArrayView<FftData> E(E_stack.data(), num_capture_channels_);
+  rtc::ArrayView<FftData> comfort_noise(comfort_noise_stack.data(),
+                                        num_capture_channels_);
+  rtc::ArrayView<FftData> high_band_comfort_noise(
+      high_band_comfort_noise_stack.data(), num_capture_channels_);
+  rtc::ArrayView<SubtractorOutput> subtractor_output(
+      subtractor_output_stack.data(), num_capture_channels_);
+  if (NumChannelsOnHeap(num_capture_channels_) > 0) {
+    // If the stack-allocated space is too small, use the heap for storing the
+    // microphone data.
+    e = rtc::ArrayView<std::array<float, kFftLengthBy2>>(e_heap_.data(),
+                                                         num_capture_channels_);
+    Y2 = rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>>(
+        Y2_heap_.data(), num_capture_channels_);
+    E2 = rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>>(
+        E2_heap_.data(), num_capture_channels_);
+    R2 = rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>>(
+        R2_heap_.data(), num_capture_channels_);
+    S2_linear = rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>>(
+        S2_linear_heap_.data(), num_capture_channels_);
+    Y = rtc::ArrayView<FftData>(Y_heap_.data(), num_capture_channels_);
+    E = rtc::ArrayView<FftData>(E_heap_.data(), num_capture_channels_);
+    comfort_noise = rtc::ArrayView<FftData>(comfort_noise_heap_.data(),
+                                            num_capture_channels_);
+    high_band_comfort_noise = rtc::ArrayView<FftData>(
+        high_band_comfort_noise_heap_.data(), num_capture_channels_);
+    subtractor_output = rtc::ArrayView<SubtractorOutput>(
+        subtractor_output_heap_.data(), num_capture_channels_);
+  }
+
+  data_dumper_->DumpWav("aec3_echo_remover_capture_input", kBlockSize,
+                        &(*y)[0][0][0], 16000, 1);
+  data_dumper_->DumpWav("aec3_echo_remover_render_input", kBlockSize,
+                        &x[0][0][0], 16000, 1);
+  data_dumper_->DumpRaw("aec3_echo_remover_capture_input", (*y)[0][0]);
+  data_dumper_->DumpRaw("aec3_echo_remover_render_input", x[0][0]);
+
+  aec_state_.UpdateCaptureSaturation(capture_signal_saturation);
+
+  if (echo_path_variability.AudioPathChanged()) {
+    // Ensure that the gain change is only acted on once per frame.
+    if (echo_path_variability.gain_change) {
+      if (gain_change_hangover_ == 0) {
+        constexpr int kMaxBlocksPerFrame = 3;
+        gain_change_hangover_ = kMaxBlocksPerFrame;
+        rtc::LoggingSeverity log_level =
+            config_.delay.log_warning_on_delay_changes ? rtc::LS_WARNING
+                                                       : rtc::LS_VERBOSE;
+        RTC_LOG_V(log_level)
+            << "Gain change detected at block " << block_counter_;
+      } else {
+        echo_path_variability.gain_change = false;
+      }
+    }
+
+    subtractor_.HandleEchoPathChange(echo_path_variability);
+    aec_state_.HandleEchoPathChange(echo_path_variability);
+
+    if (echo_path_variability.delay_change !=
+        EchoPathVariability::DelayAdjustment::kNone) {
+      suppression_gain_.SetInitialState(true);
+    }
+  }
+  if (gain_change_hangover_ > 0) {
+    --gain_change_hangover_;
+  }
+
+  // Analyze the render signal.
+  render_signal_analyzer_.Update(*render_buffer,
+                                 aec_state_.MinDirectPathFilterDelay());
+
+  // State transition.
+  if (aec_state_.TransitionTriggered()) {
+    subtractor_.ExitInitialState();
+    suppression_gain_.SetInitialState(false);
+  }
+
+  // Perform linear echo cancellation.
+  subtractor_.Process(*render_buffer, (*y)[0], render_signal_analyzer_,
+                      aec_state_, subtractor_output);
+
+  // Compute spectra.
+  for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+    FormLinearFilterOutput(subtractor_output[ch], e[ch]);
+    WindowedPaddedFft(fft_, (*y)[0][ch], y_old_[ch], &Y[ch]);
+    WindowedPaddedFft(fft_, e[ch], e_old_[ch], &E[ch]);
+    LinearEchoPower(E[ch], Y[ch], &S2_linear[ch]);
+    Y[ch].Spectrum(optimization_, Y2[ch]);
+    E[ch].Spectrum(optimization_, E2[ch]);
+  }
+
+  // Optionally return the linear filter output.
+  if (linear_output) {
+    RTC_DCHECK_GE(1, linear_output->size());
+    RTC_DCHECK_EQ(num_capture_channels_, linear_output[0].size());
+    for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+      RTC_DCHECK_EQ(kBlockSize, (*linear_output)[0][ch].size());
+      std::copy(e[ch].begin(), e[ch].end(), (*linear_output)[0][ch].begin());
+    }
+  }
+
+  // Update the AEC state information.
+  aec_state_.Update(external_delay, subtractor_.FilterFrequencyResponses(),
+                    subtractor_.FilterImpulseResponses(), *render_buffer, E2,
+                    Y2, subtractor_output);
+
+  // Choose the linear output.
+  const auto& Y_fft = aec_state_.UseLinearFilterOutput() ? E : Y;
+
+  data_dumper_->DumpWav("aec3_output_linear", kBlockSize, &(*y)[0][0][0], 16000,
+                        1);
+  data_dumper_->DumpWav("aec3_output_linear2", kBlockSize, &e[0][0], 16000, 1);
+
+  // Estimate the comfort noise.
+  cng_.Compute(aec_state_.SaturatedCapture(), Y2, comfort_noise,
+               high_band_comfort_noise);
+
+  // Only do the below processing if the output of the audio processing module
+  // is used.
+  std::array<float, kFftLengthBy2Plus1> G;
+  if (capture_output_used_) {
+    // Estimate the residual echo power.
+    residual_echo_estimator_.Estimate(aec_state_, *render_buffer, S2_linear, Y2,
+                                      suppression_gain_.IsDominantNearend(),
+                                      R2);
+
+    // Suppressor nearend estimate.
+    if (aec_state_.UsableLinearEstimate()) {
+      // E2 is bound by Y2.
+      for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+        std::transform(E2[ch].begin(), E2[ch].end(), Y2[ch].begin(),
+                       E2[ch].begin(),
+                       [](float a, float b) { return std::min(a, b); });
+      }
+    }
+    const auto& nearend_spectrum = aec_state_.UsableLinearEstimate() ? E2 : Y2;
+
+    // Suppressor echo estimate.
+    const auto& echo_spectrum =
+        aec_state_.UsableLinearEstimate() ? S2_linear : R2;
+
+    // Determine if the suppressor should assume clock drift.
+    const bool clock_drift = config_.echo_removal_control.has_clock_drift ||
+                             echo_path_variability.clock_drift;
+
+    // Compute preferred gains.
+    float high_bands_gain;
+    suppression_gain_.GetGain(nearend_spectrum, echo_spectrum, R2,
+                              cng_.NoiseSpectrum(), render_signal_analyzer_,
+                              aec_state_, x, clock_drift, &high_bands_gain, &G);
+
+    suppression_filter_.ApplyGain(comfort_noise, high_band_comfort_noise, G,
+                                  high_bands_gain, Y_fft, y);
+
+  } else {
+    G.fill(0.f);
+  }
+
+  // Update the metrics.
+  metrics_.Update(aec_state_, cng_.NoiseSpectrum()[0], G);
+
+  // Debug outputs for the purpose of development and analysis.
+  data_dumper_->DumpWav("aec3_echo_estimate", kBlockSize,
+                        &subtractor_output[0].s_refined[0], 16000, 1);
+  data_dumper_->DumpRaw("aec3_output", (*y)[0][0]);
+  data_dumper_->DumpRaw("aec3_narrow_render",
+                        render_signal_analyzer_.NarrowPeakBand() ? 1 : 0);
+  data_dumper_->DumpRaw("aec3_N2", cng_.NoiseSpectrum()[0]);
+  data_dumper_->DumpRaw("aec3_suppressor_gain", G);
+  data_dumper_->DumpWav("aec3_output",
+                        rtc::ArrayView<const float>(&(*y)[0][0][0], kBlockSize),
+                        16000, 1);
+  data_dumper_->DumpRaw("aec3_using_subtractor_output[0]",
+                        aec_state_.UseLinearFilterOutput() ? 1 : 0);
+  data_dumper_->DumpRaw("aec3_E2", E2[0]);
+  data_dumper_->DumpRaw("aec3_S2_linear", S2_linear[0]);
+  data_dumper_->DumpRaw("aec3_Y2", Y2[0]);
+  data_dumper_->DumpRaw(
+      "aec3_X2", render_buffer->Spectrum(
+                     aec_state_.MinDirectPathFilterDelay())[/*channel=*/0]);
+  data_dumper_->DumpRaw("aec3_R2", R2[0]);
+  data_dumper_->DumpRaw("aec3_filter_delay",
+                        aec_state_.MinDirectPathFilterDelay());
+  data_dumper_->DumpRaw("aec3_capture_saturation",
+                        aec_state_.SaturatedCapture() ? 1 : 0);
+}
+
+void EchoRemoverImpl::FormLinearFilterOutput(
+    const SubtractorOutput& subtractor_output,
+    rtc::ArrayView<float> output) {
+  RTC_DCHECK_EQ(subtractor_output.e_refined.size(), output.size());
+  RTC_DCHECK_EQ(subtractor_output.e_coarse.size(), output.size());
+  bool use_refined_output = true;
+  if (use_coarse_filter_output_) {
+    // As the output of the refined adaptive filter generally should be better
+    // than the coarse filter output, add a margin and threshold for when
+    // choosing the coarse filter output.
+    if (subtractor_output.e2_coarse < 0.9f * subtractor_output.e2_refined &&
+        subtractor_output.y2 > 30.f * 30.f * kBlockSize &&
+        (subtractor_output.s2_refined > 60.f * 60.f * kBlockSize ||
+         subtractor_output.s2_coarse > 60.f * 60.f * kBlockSize)) {
+      use_refined_output = false;
+    } else {
+      // If the refined filter is diverged, choose the filter output that has
+      // the lowest power.
+      if (subtractor_output.e2_coarse < subtractor_output.e2_refined &&
+          subtractor_output.y2 < subtractor_output.e2_refined) {
+        use_refined_output = false;
+      }
+    }
+  }
+
+  SignalTransition(refined_filter_output_last_selected_
+                       ? subtractor_output.e_refined
+                       : subtractor_output.e_coarse,
+                   use_refined_output ? subtractor_output.e_refined
+                                      : subtractor_output.e_coarse,
+                   output);
+  refined_filter_output_last_selected_ = use_refined_output;
+}
+
+}  // namespace
+
+EchoRemover* EchoRemover::Create(const EchoCanceller3Config& config,
+                                 int sample_rate_hz,
+                                 size_t num_render_channels,
+                                 size_t num_capture_channels) {
+  return new EchoRemoverImpl(config, sample_rate_hz, num_render_channels,
+                             num_capture_channels);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover.h
new file mode 100644
index 0000000..486a9a7
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover.h
@@ -0,0 +1,61 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_ECHO_REMOVER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_ECHO_REMOVER_H_
+
+#include <vector>
+
+#include "absl/types/optional.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "api/audio/echo_control.h"
+#include "modules/audio_processing/aec3/delay_estimate.h"
+#include "modules/audio_processing/aec3/echo_path_variability.h"
+#include "modules/audio_processing/aec3/render_buffer.h"
+
+namespace webrtc {
+
+// Class for removing the echo from the capture signal.
+class EchoRemover {
+ public:
+  static EchoRemover* Create(const EchoCanceller3Config& config,
+                             int sample_rate_hz,
+                             size_t num_render_channels,
+                             size_t num_capture_channels);
+  virtual ~EchoRemover() = default;
+
+  // Get current metrics.
+  virtual void GetMetrics(EchoControl::Metrics* metrics) const = 0;
+
+  // Removes the echo from a block of samples from the capture signal. The
+  // supplied render signal is assumed to be pre-aligned with the capture
+  // signal.
+  virtual void ProcessCapture(
+      EchoPathVariability echo_path_variability,
+      bool capture_signal_saturation,
+      const absl::optional<DelayEstimate>& external_delay,
+      RenderBuffer* render_buffer,
+      std::vector<std::vector<std::vector<float>>>* linear_output,
+      std::vector<std::vector<std::vector<float>>>* capture) = 0;
+
+  // Updates the status on whether echo leakage is detected in the output of the
+  // echo remover.
+  virtual void UpdateEchoLeakageStatus(bool leakage_detected) = 0;
+
+  // Specifies whether the capture output will be used. The purpose of this is
+  // to allow the echo remover to deactivate some of the processing when the
+  // resulting output is anyway not used, for instance when the endpoint is
+  // muted.
+  virtual void SetCaptureOutputUsage(bool capture_output_used) = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_ECHO_REMOVER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover_metrics.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover_metrics.cc
new file mode 100644
index 0000000..1ceb329
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover_metrics.cc
@@ -0,0 +1,157 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/echo_remover_metrics.h"
+
+#include <math.h>
+#include <stddef.h>
+
+#include <algorithm>
+#include <cmath>
+#include <numeric>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_minmax.h"
+#include "system_wrappers/include/metrics.h"
+
+namespace webrtc {
+
+EchoRemoverMetrics::DbMetric::DbMetric() : DbMetric(0.f, 0.f, 0.f) {}
+EchoRemoverMetrics::DbMetric::DbMetric(float sum_value,
+                                       float floor_value,
+                                       float ceil_value)
+    : sum_value(sum_value), floor_value(floor_value), ceil_value(ceil_value) {}
+
+void EchoRemoverMetrics::DbMetric::Update(float value) {
+  sum_value += value;
+  floor_value = std::min(floor_value, value);
+  ceil_value = std::max(ceil_value, value);
+}
+
+void EchoRemoverMetrics::DbMetric::UpdateInstant(float value) {
+  sum_value = value;
+  floor_value = std::min(floor_value, value);
+  ceil_value = std::max(ceil_value, value);
+}
+
+EchoRemoverMetrics::EchoRemoverMetrics() {
+  ResetMetrics();
+}
+
+void EchoRemoverMetrics::ResetMetrics() {
+  erl_time_domain_ = DbMetric(0.f, 10000.f, 0.000f);
+  erle_time_domain_ = DbMetric(0.f, 0.f, 1000.f);
+  saturated_capture_ = false;
+}
+
+void EchoRemoverMetrics::Update(
+    const AecState& aec_state,
+    const std::array<float, kFftLengthBy2Plus1>& comfort_noise_spectrum,
+    const std::array<float, kFftLengthBy2Plus1>& suppressor_gain) {
+  metrics_reported_ = false;
+  if (++block_counter_ <= kMetricsCollectionBlocks) {
+    erl_time_domain_.UpdateInstant(aec_state.ErlTimeDomain());
+    erle_time_domain_.UpdateInstant(aec_state.FullBandErleLog2());
+    saturated_capture_ = saturated_capture_ || aec_state.SaturatedCapture();
+  } else {
+    // Report the metrics over several frames in order to lower the impact of
+    // the logarithms involved on the computational complexity.
+    switch (block_counter_) {
+      case kMetricsCollectionBlocks + 1:
+        RTC_HISTOGRAM_BOOLEAN(
+            "WebRTC.Audio.EchoCanceller.UsableLinearEstimate",
+            static_cast<int>(aec_state.UsableLinearEstimate() ? 1 : 0));
+        RTC_HISTOGRAM_COUNTS_LINEAR("WebRTC.Audio.EchoCanceller.FilterDelay",
+                                    aec_state.MinDirectPathFilterDelay(), 0, 30,
+                                    31);
+        RTC_HISTOGRAM_BOOLEAN("WebRTC.Audio.EchoCanceller.CaptureSaturation",
+                              static_cast<int>(saturated_capture_ ? 1 : 0));
+        break;
+      case kMetricsCollectionBlocks + 2:
+        RTC_HISTOGRAM_COUNTS_LINEAR(
+            "WebRTC.Audio.EchoCanceller.Erl.Value",
+            aec3::TransformDbMetricForReporting(true, 0.f, 59.f, 30.f, 1.f,
+                                                erl_time_domain_.sum_value),
+            0, 59, 30);
+        RTC_HISTOGRAM_COUNTS_LINEAR(
+            "WebRTC.Audio.EchoCanceller.Erl.Max",
+            aec3::TransformDbMetricForReporting(true, 0.f, 59.f, 30.f, 1.f,
+                                                erl_time_domain_.ceil_value),
+            0, 59, 30);
+        RTC_HISTOGRAM_COUNTS_LINEAR(
+            "WebRTC.Audio.EchoCanceller.Erl.Min",
+            aec3::TransformDbMetricForReporting(true, 0.f, 59.f, 30.f, 1.f,
+                                                erl_time_domain_.floor_value),
+            0, 59, 30);
+        break;
+      case kMetricsCollectionBlocks + 3:
+        RTC_HISTOGRAM_COUNTS_LINEAR(
+            "WebRTC.Audio.EchoCanceller.Erle.Value",
+            aec3::TransformDbMetricForReporting(false, 0.f, 19.f, 0.f, 1.f,
+                                                erle_time_domain_.sum_value),
+            0, 19, 20);
+        RTC_HISTOGRAM_COUNTS_LINEAR(
+            "WebRTC.Audio.EchoCanceller.Erle.Max",
+            aec3::TransformDbMetricForReporting(false, 0.f, 19.f, 0.f, 1.f,
+                                                erle_time_domain_.ceil_value),
+            0, 19, 20);
+        RTC_HISTOGRAM_COUNTS_LINEAR(
+            "WebRTC.Audio.EchoCanceller.Erle.Min",
+            aec3::TransformDbMetricForReporting(false, 0.f, 19.f, 0.f, 1.f,
+                                                erle_time_domain_.floor_value),
+            0, 19, 20);
+        metrics_reported_ = true;
+        RTC_DCHECK_EQ(kMetricsReportingIntervalBlocks, block_counter_);
+        block_counter_ = 0;
+        ResetMetrics();
+        break;
+      default:
+        RTC_NOTREACHED();
+        break;
+    }
+  }
+}
+
+namespace aec3 {
+
+void UpdateDbMetric(const std::array<float, kFftLengthBy2Plus1>& value,
+                    std::array<EchoRemoverMetrics::DbMetric, 2>* statistic) {
+  RTC_DCHECK(statistic);
+  // Truncation is intended in the band width computation.
+  constexpr int kNumBands = 2;
+  constexpr int kBandWidth = 65 / kNumBands;
+  constexpr float kOneByBandWidth = 1.f / kBandWidth;
+  RTC_DCHECK_EQ(kNumBands, statistic->size());
+  RTC_DCHECK_EQ(65, value.size());
+  for (size_t k = 0; k < statistic->size(); ++k) {
+    float average_band =
+        std::accumulate(value.begin() + kBandWidth * k,
+                        value.begin() + kBandWidth * (k + 1), 0.f) *
+        kOneByBandWidth;
+    (*statistic)[k].Update(average_band);
+  }
+}
+
+int TransformDbMetricForReporting(bool negate,
+                                  float min_value,
+                                  float max_value,
+                                  float offset,
+                                  float scaling,
+                                  float value) {
+  float new_value = 10.f * std::log10(value * scaling + 1e-10f) + offset;
+  if (negate) {
+    new_value = -new_value;
+  }
+  return static_cast<int>(rtc::SafeClamp(new_value, min_value, max_value));
+}
+
+}  // namespace aec3
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover_metrics.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover_metrics.h
new file mode 100644
index 0000000..c3d8e20
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover_metrics.h
@@ -0,0 +1,78 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_ECHO_REMOVER_METRICS_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_ECHO_REMOVER_METRICS_H_
+
+#include <array>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/aec_state.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+// Handles the reporting of metrics for the echo remover.
+class EchoRemoverMetrics {
+ public:
+  struct DbMetric {
+    DbMetric();
+    DbMetric(float sum_value, float floor_value, float ceil_value);
+    void Update(float value);
+    void UpdateInstant(float value);
+    float sum_value;
+    float floor_value;
+    float ceil_value;
+  };
+
+  EchoRemoverMetrics();
+
+  // Updates the metric with new data.
+  void Update(
+      const AecState& aec_state,
+      const std::array<float, kFftLengthBy2Plus1>& comfort_noise_spectrum,
+      const std::array<float, kFftLengthBy2Plus1>& suppressor_gain);
+
+  // Returns true if the metrics have just been reported, otherwise false.
+  bool MetricsReported() { return metrics_reported_; }
+
+ private:
+  // Resets the metrics.
+  void ResetMetrics();
+
+  int block_counter_ = 0;
+  DbMetric erl_time_domain_;
+  DbMetric erle_time_domain_;
+  bool saturated_capture_ = false;
+  bool metrics_reported_ = false;
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(EchoRemoverMetrics);
+};
+
+namespace aec3 {
+
+// Updates a banded metric of type DbMetric with the values in the supplied
+// array.
+void UpdateDbMetric(const std::array<float, kFftLengthBy2Plus1>& value,
+                    std::array<EchoRemoverMetrics::DbMetric, 2>* statistic);
+
+// Transforms a DbMetric from the linear domain into the logarithmic domain.
+int TransformDbMetricForReporting(bool negate,
+                                  float min_value,
+                                  float max_value,
+                                  float offset,
+                                  float scaling,
+                                  float value);
+
+}  // namespace aec3
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_ECHO_REMOVER_METRICS_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover_metrics_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover_metrics_unittest.cc
new file mode 100644
index 0000000..45b30a9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover_metrics_unittest.cc
@@ -0,0 +1,156 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/echo_remover_metrics.h"
+
+#include <math.h>
+
+#include <cmath>
+
+#include "modules/audio_processing/aec3/aec3_fft.h"
+#include "modules/audio_processing/aec3/aec_state.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+// Verifies the check for non-null input.
+TEST(UpdateDbMetricDeathTest, NullValue) {
+  std::array<float, kFftLengthBy2Plus1> value;
+  value.fill(0.f);
+  EXPECT_DEATH(aec3::UpdateDbMetric(value, nullptr), "");
+}
+
+#endif
+
+// Verifies the updating functionality of UpdateDbMetric.
+TEST(UpdateDbMetric, Updating) {
+  std::array<float, kFftLengthBy2Plus1> value;
+  std::array<EchoRemoverMetrics::DbMetric, 2> statistic;
+  statistic.fill(EchoRemoverMetrics::DbMetric(0.f, 100.f, -100.f));
+  constexpr float kValue0 = 10.f;
+  constexpr float kValue1 = 20.f;
+  std::fill(value.begin(), value.begin() + 32, kValue0);
+  std::fill(value.begin() + 32, value.begin() + 64, kValue1);
+
+  aec3::UpdateDbMetric(value, &statistic);
+  EXPECT_FLOAT_EQ(kValue0, statistic[0].sum_value);
+  EXPECT_FLOAT_EQ(kValue0, statistic[0].ceil_value);
+  EXPECT_FLOAT_EQ(kValue0, statistic[0].floor_value);
+  EXPECT_FLOAT_EQ(kValue1, statistic[1].sum_value);
+  EXPECT_FLOAT_EQ(kValue1, statistic[1].ceil_value);
+  EXPECT_FLOAT_EQ(kValue1, statistic[1].floor_value);
+
+  aec3::UpdateDbMetric(value, &statistic);
+  EXPECT_FLOAT_EQ(2.f * kValue0, statistic[0].sum_value);
+  EXPECT_FLOAT_EQ(kValue0, statistic[0].ceil_value);
+  EXPECT_FLOAT_EQ(kValue0, statistic[0].floor_value);
+  EXPECT_FLOAT_EQ(2.f * kValue1, statistic[1].sum_value);
+  EXPECT_FLOAT_EQ(kValue1, statistic[1].ceil_value);
+  EXPECT_FLOAT_EQ(kValue1, statistic[1].floor_value);
+}
+
+// Verifies that the TransformDbMetricForReporting method produces the desired
+// output for values for dBFS.
+TEST(TransformDbMetricForReporting, DbFsScaling) {
+  std::array<float, kBlockSize> x;
+  FftData X;
+  std::array<float, kFftLengthBy2Plus1> X2;
+  Aec3Fft fft;
+  x.fill(1000.f);
+  fft.ZeroPaddedFft(x, Aec3Fft::Window::kRectangular, &X);
+  X.Spectrum(Aec3Optimization::kNone, X2);
+
+  float offset = -10.f * std::log10(32768.f * 32768.f);
+  EXPECT_NEAR(offset, -90.3f, 0.1f);
+  EXPECT_EQ(
+      static_cast<int>(30.3f),
+      aec3::TransformDbMetricForReporting(
+          true, 0.f, 90.f, offset, 1.f / (kBlockSize * kBlockSize), X2[0]));
+}
+
+// Verifies that the TransformDbMetricForReporting method is able to properly
+// limit the output.
+TEST(TransformDbMetricForReporting, Limits) {
+  EXPECT_EQ(0, aec3::TransformDbMetricForReporting(false, 0.f, 10.f, 0.f, 1.f,
+                                                   0.001f));
+  EXPECT_EQ(10, aec3::TransformDbMetricForReporting(false, 0.f, 10.f, 0.f, 1.f,
+                                                    100.f));
+}
+
+// Verifies that the TransformDbMetricForReporting method is able to properly
+// negate output.
+TEST(TransformDbMetricForReporting, Negate) {
+  EXPECT_EQ(10, aec3::TransformDbMetricForReporting(true, -20.f, 20.f, 0.f, 1.f,
+                                                    0.1f));
+  EXPECT_EQ(-10, aec3::TransformDbMetricForReporting(true, -20.f, 20.f, 0.f,
+                                                     1.f, 10.f));
+}
+
+// Verify the Update functionality of DbMetric.
+TEST(DbMetric, Update) {
+  EchoRemoverMetrics::DbMetric metric(0.f, 20.f, -20.f);
+  constexpr int kNumValues = 100;
+  constexpr float kValue = 10.f;
+  for (int k = 0; k < kNumValues; ++k) {
+    metric.Update(kValue);
+  }
+  EXPECT_FLOAT_EQ(kValue * kNumValues, metric.sum_value);
+  EXPECT_FLOAT_EQ(kValue, metric.ceil_value);
+  EXPECT_FLOAT_EQ(kValue, metric.floor_value);
+}
+
+// Verify the Update functionality of DbMetric.
+TEST(DbMetric, UpdateInstant) {
+  EchoRemoverMetrics::DbMetric metric(0.f, 20.f, -20.f);
+  constexpr float kMinValue = -77.f;
+  constexpr float kMaxValue = 33.f;
+  constexpr float kLastValue = (kMinValue + kMaxValue) / 2.0f;
+  for (float value = kMinValue; value <= kMaxValue; value++)
+    metric.UpdateInstant(value);
+  metric.UpdateInstant(kLastValue);
+  EXPECT_FLOAT_EQ(kLastValue, metric.sum_value);
+  EXPECT_FLOAT_EQ(kMaxValue, metric.ceil_value);
+  EXPECT_FLOAT_EQ(kMinValue, metric.floor_value);
+}
+
+// Verify the constructor functionality of DbMetric.
+TEST(DbMetric, Constructor) {
+  EchoRemoverMetrics::DbMetric metric;
+  EXPECT_FLOAT_EQ(0.f, metric.sum_value);
+  EXPECT_FLOAT_EQ(0.f, metric.ceil_value);
+  EXPECT_FLOAT_EQ(0.f, metric.floor_value);
+
+  metric = EchoRemoverMetrics::DbMetric(1.f, 2.f, 3.f);
+  EXPECT_FLOAT_EQ(1.f, metric.sum_value);
+  EXPECT_FLOAT_EQ(2.f, metric.floor_value);
+  EXPECT_FLOAT_EQ(3.f, metric.ceil_value);
+}
+
+// Verify the general functionality of EchoRemoverMetrics.
+TEST(EchoRemoverMetrics, NormalUsage) {
+  EchoRemoverMetrics metrics;
+  AecState aec_state(EchoCanceller3Config{}, 1);
+  std::array<float, kFftLengthBy2Plus1> comfort_noise_spectrum;
+  std::array<float, kFftLengthBy2Plus1> suppressor_gain;
+  comfort_noise_spectrum.fill(10.f);
+  suppressor_gain.fill(1.f);
+  for (int j = 0; j < 3; ++j) {
+    for (int k = 0; k < kMetricsReportingIntervalBlocks - 1; ++k) {
+      metrics.Update(aec_state, comfort_noise_spectrum, suppressor_gain);
+      EXPECT_FALSE(metrics.MetricsReported());
+    }
+    metrics.Update(aec_state, comfort_noise_spectrum, suppressor_gain);
+    EXPECT_TRUE(metrics.MetricsReported());
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover_unittest.cc
new file mode 100644
index 0000000..77a2076
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/echo_remover_unittest.cc
@@ -0,0 +1,243 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/echo_remover.h"
+
+#include <algorithm>
+#include <memory>
+#include <numeric>
+#include <string>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/render_buffer.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "modules/audio_processing/test/echo_canceller_test_tools.h"
+#include "rtc_base/random.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace {
+std::string ProduceDebugText(int sample_rate_hz) {
+  rtc::StringBuilder ss;
+  ss << "Sample rate: " << sample_rate_hz;
+  return ss.Release();
+}
+
+std::string ProduceDebugText(int sample_rate_hz, int delay) {
+  rtc::StringBuilder ss(ProduceDebugText(sample_rate_hz));
+  ss << ", Delay: " << delay;
+  return ss.Release();
+}
+
+}  // namespace
+
+class EchoRemoverMultiChannel
+    : public ::testing::Test,
+      public ::testing::WithParamInterface<std::tuple<size_t, size_t>> {};
+
+INSTANTIATE_TEST_SUITE_P(MultiChannel,
+                         EchoRemoverMultiChannel,
+                         ::testing::Combine(::testing::Values(1, 2, 8),
+                                            ::testing::Values(1, 2, 8)));
+
+// Verifies the basic API call sequence
+TEST_P(EchoRemoverMultiChannel, BasicApiCalls) {
+  const size_t num_render_channels = std::get<0>(GetParam());
+  const size_t num_capture_channels = std::get<1>(GetParam());
+  absl::optional<DelayEstimate> delay_estimate;
+  for (auto rate : {16000, 32000, 48000}) {
+    SCOPED_TRACE(ProduceDebugText(rate));
+    std::unique_ptr<EchoRemover> remover(
+        EchoRemover::Create(EchoCanceller3Config(), rate, num_render_channels,
+                            num_capture_channels));
+    std::unique_ptr<RenderDelayBuffer> render_buffer(RenderDelayBuffer::Create(
+        EchoCanceller3Config(), rate, num_render_channels));
+
+    std::vector<std::vector<std::vector<float>>> render(
+        NumBandsForRate(rate),
+        std::vector<std::vector<float>>(num_render_channels,
+                                        std::vector<float>(kBlockSize, 0.f)));
+    std::vector<std::vector<std::vector<float>>> capture(
+        NumBandsForRate(rate),
+        std::vector<std::vector<float>>(num_capture_channels,
+                                        std::vector<float>(kBlockSize, 0.f)));
+    for (size_t k = 0; k < 100; ++k) {
+      EchoPathVariability echo_path_variability(
+          k % 3 == 0 ? true : false,
+          k % 5 == 0 ? EchoPathVariability::DelayAdjustment::kNewDetectedDelay
+                     : EchoPathVariability::DelayAdjustment::kNone,
+          false);
+      render_buffer->Insert(render);
+      render_buffer->PrepareCaptureProcessing();
+
+      remover->ProcessCapture(echo_path_variability, k % 2 == 0 ? true : false,
+                              delay_estimate, render_buffer->GetRenderBuffer(),
+                              nullptr, &capture);
+    }
+  }
+}
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+// Verifies the check for the samplerate.
+// TODO(peah): Re-enable the test once the issue with memory leaks during DEATH
+// tests on test bots has been fixed.
+TEST(EchoRemoverDeathTest, DISABLED_WrongSampleRate) {
+  EXPECT_DEATH(std::unique_ptr<EchoRemover>(
+                   EchoRemover::Create(EchoCanceller3Config(), 8001, 1, 1)),
+               "");
+}
+
+// Verifies the check for the capture block size.
+TEST(EchoRemoverDeathTest, WrongCaptureBlockSize) {
+  absl::optional<DelayEstimate> delay_estimate;
+  for (auto rate : {16000, 32000, 48000}) {
+    SCOPED_TRACE(ProduceDebugText(rate));
+    std::unique_ptr<EchoRemover> remover(
+        EchoRemover::Create(EchoCanceller3Config(), rate, 1, 1));
+    std::unique_ptr<RenderDelayBuffer> render_buffer(
+        RenderDelayBuffer::Create(EchoCanceller3Config(), rate, 1));
+    std::vector<std::vector<std::vector<float>>> capture(
+        NumBandsForRate(rate), std::vector<std::vector<float>>(
+                                   1, std::vector<float>(kBlockSize - 1, 0.f)));
+    EchoPathVariability echo_path_variability(
+        false, EchoPathVariability::DelayAdjustment::kNone, false);
+    EXPECT_DEATH(remover->ProcessCapture(
+                     echo_path_variability, false, delay_estimate,
+                     render_buffer->GetRenderBuffer(), nullptr, &capture),
+                 "");
+  }
+}
+
+// Verifies the check for the number of capture bands.
+// TODO(peah): Re-enable the test once the issue with memory leaks during DEATH
+// tests on test bots has been fixed.c
+TEST(EchoRemoverDeathTest, DISABLED_WrongCaptureNumBands) {
+  absl::optional<DelayEstimate> delay_estimate;
+  for (auto rate : {16000, 32000, 48000}) {
+    SCOPED_TRACE(ProduceDebugText(rate));
+    std::unique_ptr<EchoRemover> remover(
+        EchoRemover::Create(EchoCanceller3Config(), rate, 1, 1));
+    std::unique_ptr<RenderDelayBuffer> render_buffer(
+        RenderDelayBuffer::Create(EchoCanceller3Config(), rate, 1));
+    std::vector<std::vector<std::vector<float>>> capture(
+        NumBandsForRate(rate == 48000 ? 16000 : rate + 16000),
+        std::vector<std::vector<float>>(1,
+                                        std::vector<float>(kBlockSize, 0.f)));
+    EchoPathVariability echo_path_variability(
+        false, EchoPathVariability::DelayAdjustment::kNone, false);
+    EXPECT_DEATH(remover->ProcessCapture(
+                     echo_path_variability, false, delay_estimate,
+                     render_buffer->GetRenderBuffer(), nullptr, &capture),
+                 "");
+  }
+}
+
+// Verifies the check for non-null capture block.
+TEST(EchoRemoverDeathTest, NullCapture) {
+  absl::optional<DelayEstimate> delay_estimate;
+  std::unique_ptr<EchoRemover> remover(
+      EchoRemover::Create(EchoCanceller3Config(), 16000, 1, 1));
+  std::unique_ptr<RenderDelayBuffer> render_buffer(
+      RenderDelayBuffer::Create(EchoCanceller3Config(), 16000, 1));
+  EchoPathVariability echo_path_variability(
+      false, EchoPathVariability::DelayAdjustment::kNone, false);
+  EXPECT_DEATH(remover->ProcessCapture(
+                   echo_path_variability, false, delay_estimate,
+                   render_buffer->GetRenderBuffer(), nullptr, nullptr),
+               "");
+}
+
+#endif
+
+// Performs a sanity check that the echo_remover is able to properly
+// remove echoes.
+TEST(EchoRemover, BasicEchoRemoval) {
+  constexpr int kNumBlocksToProcess = 500;
+  Random random_generator(42U);
+  absl::optional<DelayEstimate> delay_estimate;
+  for (size_t num_channels : {1, 2, 4}) {
+    for (auto rate : {16000, 32000, 48000}) {
+      std::vector<std::vector<std::vector<float>>> x(
+          NumBandsForRate(rate),
+          std::vector<std::vector<float>>(num_channels,
+                                          std::vector<float>(kBlockSize, 0.f)));
+      std::vector<std::vector<std::vector<float>>> y(
+          NumBandsForRate(rate),
+          std::vector<std::vector<float>>(num_channels,
+                                          std::vector<float>(kBlockSize, 0.f)));
+      EchoPathVariability echo_path_variability(
+          false, EchoPathVariability::DelayAdjustment::kNone, false);
+      for (size_t delay_samples : {0, 64, 150, 200, 301}) {
+        SCOPED_TRACE(ProduceDebugText(rate, delay_samples));
+        EchoCanceller3Config config;
+        std::unique_ptr<EchoRemover> remover(
+            EchoRemover::Create(config, rate, num_channels, num_channels));
+        std::unique_ptr<RenderDelayBuffer> render_buffer(
+            RenderDelayBuffer::Create(config, rate, num_channels));
+        render_buffer->AlignFromDelay(delay_samples / kBlockSize);
+
+        std::vector<std::vector<std::unique_ptr<DelayBuffer<float>>>>
+            delay_buffers(x.size());
+        for (size_t band = 0; band < delay_buffers.size(); ++band) {
+          delay_buffers[band].resize(x[0].size());
+        }
+
+        for (size_t band = 0; band < x.size(); ++band) {
+          for (size_t channel = 0; channel < x[0].size(); ++channel) {
+            delay_buffers[band][channel].reset(
+                new DelayBuffer<float>(delay_samples));
+          }
+        }
+
+        float input_energy = 0.f;
+        float output_energy = 0.f;
+        for (int k = 0; k < kNumBlocksToProcess; ++k) {
+          const bool silence = k < 100 || (k % 100 >= 10);
+
+          for (size_t band = 0; band < x.size(); ++band) {
+            for (size_t channel = 0; channel < x[0].size(); ++channel) {
+              if (silence) {
+                std::fill(x[band][channel].begin(), x[band][channel].end(),
+                          0.f);
+              } else {
+                RandomizeSampleVector(&random_generator, x[band][channel]);
+              }
+              delay_buffers[band][channel]->Delay(x[band][channel],
+                                                  y[band][channel]);
+            }
+          }
+
+          if (k > kNumBlocksToProcess / 2) {
+            input_energy = std::inner_product(y[0][0].begin(), y[0][0].end(),
+                                              y[0][0].begin(), input_energy);
+          }
+
+          render_buffer->Insert(x);
+          render_buffer->PrepareCaptureProcessing();
+
+          remover->ProcessCapture(echo_path_variability, false, delay_estimate,
+                                  render_buffer->GetRenderBuffer(), nullptr,
+                                  &y);
+
+          if (k > kNumBlocksToProcess / 2) {
+            output_energy = std::inner_product(y[0][0].begin(), y[0][0].end(),
+                                               y[0][0].begin(), output_energy);
+          }
+        }
+        EXPECT_GT(input_energy, 10.f * output_energy);
+      }
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erl_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erl_estimator.cc
new file mode 100644
index 0000000..01cc33c
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erl_estimator.cc
@@ -0,0 +1,146 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/erl_estimator.h"
+
+#include <algorithm>
+#include <numeric>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+namespace {
+
+constexpr float kMinErl = 0.01f;
+constexpr float kMaxErl = 1000.f;
+
+}  // namespace
+
+ErlEstimator::ErlEstimator(size_t startup_phase_length_blocks_)
+    : startup_phase_length_blocks__(startup_phase_length_blocks_) {
+  erl_.fill(kMaxErl);
+  hold_counters_.fill(0);
+  erl_time_domain_ = kMaxErl;
+  hold_counter_time_domain_ = 0;
+}
+
+ErlEstimator::~ErlEstimator() = default;
+
+void ErlEstimator::Reset() {
+  blocks_since_reset_ = 0;
+}
+
+void ErlEstimator::Update(
+    const std::vector<bool>& converged_filters,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> render_spectra,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+        capture_spectra) {
+  const size_t num_capture_channels = converged_filters.size();
+  RTC_DCHECK_EQ(capture_spectra.size(), num_capture_channels);
+
+  // Corresponds to WGN of power -46 dBFS.
+  constexpr float kX2Min = 44015068.0f;
+
+  const auto first_converged_iter =
+      std::find(converged_filters.begin(), converged_filters.end(), true);
+  const bool any_filter_converged =
+      first_converged_iter != converged_filters.end();
+
+  if (++blocks_since_reset_ < startup_phase_length_blocks__ ||
+      !any_filter_converged) {
+    return;
+  }
+
+  // Use the maximum spectrum across capture and the maximum across render.
+  std::array<float, kFftLengthBy2Plus1> max_capture_spectrum_data;
+  std::array<float, kFftLengthBy2Plus1> max_capture_spectrum =
+      capture_spectra[/*channel=*/0];
+  if (num_capture_channels > 1) {
+    // Initialize using the first channel with a converged filter.
+    const size_t first_converged =
+        std::distance(converged_filters.begin(), first_converged_iter);
+    RTC_DCHECK_GE(first_converged, 0);
+    RTC_DCHECK_LT(first_converged, num_capture_channels);
+    max_capture_spectrum_data = capture_spectra[first_converged];
+
+    for (size_t ch = first_converged + 1; ch < num_capture_channels; ++ch) {
+      if (!converged_filters[ch]) {
+        continue;
+      }
+      for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+        max_capture_spectrum_data[k] =
+            std::max(max_capture_spectrum_data[k], capture_spectra[ch][k]);
+      }
+    }
+    max_capture_spectrum = max_capture_spectrum_data;
+  }
+
+  const size_t num_render_channels = render_spectra.size();
+  std::array<float, kFftLengthBy2Plus1> max_render_spectrum_data;
+  rtc::ArrayView<const float, kFftLengthBy2Plus1> max_render_spectrum =
+      render_spectra[/*channel=*/0];
+  if (num_render_channels > 1) {
+    std::copy(render_spectra[0].begin(), render_spectra[0].end(),
+              max_render_spectrum_data.begin());
+    for (size_t ch = 1; ch < num_render_channels; ++ch) {
+      for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+        max_render_spectrum_data[k] =
+            std::max(max_render_spectrum_data[k], render_spectra[ch][k]);
+      }
+    }
+    max_render_spectrum = max_render_spectrum_data;
+  }
+
+  const auto& X2 = max_render_spectrum;
+  const auto& Y2 = max_capture_spectrum;
+
+  // Update the estimates in a maximum statistics manner.
+  for (size_t k = 1; k < kFftLengthBy2; ++k) {
+    if (X2[k] > kX2Min) {
+      const float new_erl = Y2[k] / X2[k];
+      if (new_erl < erl_[k]) {
+        hold_counters_[k - 1] = 1000;
+        erl_[k] += 0.1f * (new_erl - erl_[k]);
+        erl_[k] = std::max(erl_[k], kMinErl);
+      }
+    }
+  }
+
+  std::for_each(hold_counters_.begin(), hold_counters_.end(),
+                [](int& a) { --a; });
+  std::transform(hold_counters_.begin(), hold_counters_.end(), erl_.begin() + 1,
+                 erl_.begin() + 1, [](int a, float b) {
+                   return a > 0 ? b : std::min(kMaxErl, 2.f * b);
+                 });
+
+  erl_[0] = erl_[1];
+  erl_[kFftLengthBy2] = erl_[kFftLengthBy2 - 1];
+
+  // Compute ERL over all frequency bins.
+  const float X2_sum = std::accumulate(X2.begin(), X2.end(), 0.0f);
+
+  if (X2_sum > kX2Min * X2.size()) {
+    const float Y2_sum = std::accumulate(Y2.begin(), Y2.end(), 0.0f);
+    const float new_erl = Y2_sum / X2_sum;
+    if (new_erl < erl_time_domain_) {
+      hold_counter_time_domain_ = 1000;
+      erl_time_domain_ += 0.1f * (new_erl - erl_time_domain_);
+      erl_time_domain_ = std::max(erl_time_domain_, kMinErl);
+    }
+  }
+
+  --hold_counter_time_domain_;
+  erl_time_domain_ = (hold_counter_time_domain_ > 0)
+                         ? erl_time_domain_
+                         : std::min(kMaxErl, 2.f * erl_time_domain_);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erl_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erl_estimator.h
new file mode 100644
index 0000000..89bf6ac
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erl_estimator.h
@@ -0,0 +1,57 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_ERL_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_ERL_ESTIMATOR_H_
+
+#include <stddef.h>
+
+#include <array>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+// Estimates the echo return loss based on the signal spectra.
+class ErlEstimator {
+ public:
+  explicit ErlEstimator(size_t startup_phase_length_blocks_);
+  ~ErlEstimator();
+
+  // Resets the ERL estimation.
+  void Reset();
+
+  // Updates the ERL estimate.
+  void Update(const std::vector<bool>& converged_filters,
+              rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+                  render_spectra,
+              rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+                  capture_spectra);
+
+  // Returns the most recent ERL estimate.
+  const std::array<float, kFftLengthBy2Plus1>& Erl() const { return erl_; }
+  float ErlTimeDomain() const { return erl_time_domain_; }
+
+ private:
+  const size_t startup_phase_length_blocks__;
+  std::array<float, kFftLengthBy2Plus1> erl_;
+  std::array<int, kFftLengthBy2Minus1> hold_counters_;
+  float erl_time_domain_;
+  int hold_counter_time_domain_;
+  size_t blocks_since_reset_ = 0;
+  RTC_DISALLOW_COPY_AND_ASSIGN(ErlEstimator);
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_ERL_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erl_estimator_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erl_estimator_unittest.cc
new file mode 100644
index 0000000..79e5465
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erl_estimator_unittest.cc
@@ -0,0 +1,104 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/erl_estimator.h"
+
+#include "rtc_base/strings/string_builder.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+namespace {
+std::string ProduceDebugText(size_t num_render_channels,
+                             size_t num_capture_channels) {
+  rtc::StringBuilder ss;
+  ss << "Render channels: " << num_render_channels;
+  ss << ", Capture channels: " << num_capture_channels;
+  return ss.Release();
+}
+
+void VerifyErl(const std::array<float, kFftLengthBy2Plus1>& erl,
+               float erl_time_domain,
+               float reference) {
+  std::for_each(erl.begin(), erl.end(),
+                [reference](float a) { EXPECT_NEAR(reference, a, 0.001); });
+  EXPECT_NEAR(reference, erl_time_domain, 0.001);
+}
+
+}  // namespace
+
+class ErlEstimatorMultiChannel
+    : public ::testing::Test,
+      public ::testing::WithParamInterface<std::tuple<size_t, size_t>> {};
+
+INSTANTIATE_TEST_SUITE_P(MultiChannel,
+                         ErlEstimatorMultiChannel,
+                         ::testing::Combine(::testing::Values(1, 2, 8),
+                                            ::testing::Values(1, 2, 8)));
+
+// Verifies that the correct ERL estimates are achieved.
+TEST_P(ErlEstimatorMultiChannel, Estimates) {
+  const size_t num_render_channels = std::get<0>(GetParam());
+  const size_t num_capture_channels = std::get<1>(GetParam());
+  SCOPED_TRACE(ProduceDebugText(num_render_channels, num_capture_channels));
+  std::vector<std::array<float, kFftLengthBy2Plus1>> X2(num_render_channels);
+  for (auto& X2_ch : X2) {
+    X2_ch.fill(0.f);
+  }
+  std::vector<std::array<float, kFftLengthBy2Plus1>> Y2(num_capture_channels);
+  for (auto& Y2_ch : Y2) {
+    Y2_ch.fill(0.f);
+  }
+  std::vector<bool> converged_filters(num_capture_channels, false);
+  const size_t converged_idx = num_capture_channels - 1;
+  converged_filters[converged_idx] = true;
+
+  ErlEstimator estimator(0);
+
+  // Verifies that the ERL estimate is properly reduced to lower values.
+  for (auto& X2_ch : X2) {
+    X2_ch.fill(500 * 1000.f * 1000.f);
+  }
+  Y2[converged_idx].fill(10 * X2[0][0]);
+  for (size_t k = 0; k < 200; ++k) {
+    estimator.Update(converged_filters, X2, Y2);
+  }
+  VerifyErl(estimator.Erl(), estimator.ErlTimeDomain(), 10.f);
+
+  // Verifies that the ERL is not immediately increased when the ERL in the
+  // data increases.
+  Y2[converged_idx].fill(10000 * X2[0][0]);
+  for (size_t k = 0; k < 998; ++k) {
+    estimator.Update(converged_filters, X2, Y2);
+  }
+  VerifyErl(estimator.Erl(), estimator.ErlTimeDomain(), 10.f);
+
+  // Verifies that the rate of increase is 3 dB.
+  estimator.Update(converged_filters, X2, Y2);
+  VerifyErl(estimator.Erl(), estimator.ErlTimeDomain(), 20.f);
+
+  // Verifies that the maximum ERL is achieved when there are no low RLE
+  // estimates.
+  for (size_t k = 0; k < 1000; ++k) {
+    estimator.Update(converged_filters, X2, Y2);
+  }
+  VerifyErl(estimator.Erl(), estimator.ErlTimeDomain(), 1000.f);
+
+  // Verifies that the ERL estimate is is not updated for low-level signals
+  for (auto& X2_ch : X2) {
+    X2_ch.fill(1000.f * 1000.f);
+  }
+  Y2[converged_idx].fill(10 * X2[0][0]);
+  for (size_t k = 0; k < 200; ++k) {
+    estimator.Update(converged_filters, X2, Y2);
+  }
+  VerifyErl(estimator.Erl(), estimator.ErlTimeDomain(), 1000.f);
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erle_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erle_estimator.cc
new file mode 100644
index 0000000..0e3d715
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erle_estimator.cc
@@ -0,0 +1,89 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/erle_estimator.h"
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+ErleEstimator::ErleEstimator(size_t startup_phase_length_blocks,
+                             const EchoCanceller3Config& config,
+                             size_t num_capture_channels)
+    : startup_phase_length_blocks_(startup_phase_length_blocks),
+      fullband_erle_estimator_(config.erle, num_capture_channels),
+      subband_erle_estimator_(config, num_capture_channels) {
+  if (config.erle.num_sections > 1) {
+    signal_dependent_erle_estimator_ =
+        std::make_unique<SignalDependentErleEstimator>(config,
+                                                       num_capture_channels);
+  }
+  Reset(true);
+}
+
+ErleEstimator::~ErleEstimator() = default;
+
+void ErleEstimator::Reset(bool delay_change) {
+  fullband_erle_estimator_.Reset();
+  subband_erle_estimator_.Reset();
+  if (signal_dependent_erle_estimator_) {
+    signal_dependent_erle_estimator_->Reset();
+  }
+  if (delay_change) {
+    blocks_since_reset_ = 0;
+  }
+}
+
+void ErleEstimator::Update(
+    const RenderBuffer& render_buffer,
+    rtc::ArrayView<const std::vector<std::array<float, kFftLengthBy2Plus1>>>
+        filter_frequency_responses,
+    rtc::ArrayView<const float, kFftLengthBy2Plus1>
+        avg_render_spectrum_with_reverb,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> capture_spectra,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+        subtractor_spectra,
+    const std::vector<bool>& converged_filters) {
+  RTC_DCHECK_EQ(subband_erle_estimator_.Erle(/*onset_compensated=*/true).size(),
+                capture_spectra.size());
+  RTC_DCHECK_EQ(subband_erle_estimator_.Erle(/*onset_compensated=*/true).size(),
+                subtractor_spectra.size());
+  const auto& X2_reverb = avg_render_spectrum_with_reverb;
+  const auto& Y2 = capture_spectra;
+  const auto& E2 = subtractor_spectra;
+
+  if (++blocks_since_reset_ < startup_phase_length_blocks_) {
+    return;
+  }
+
+  subband_erle_estimator_.Update(X2_reverb, Y2, E2, converged_filters);
+
+  if (signal_dependent_erle_estimator_) {
+    signal_dependent_erle_estimator_->Update(
+        render_buffer, filter_frequency_responses, X2_reverb, Y2, E2,
+        subband_erle_estimator_.Erle(/*onset_compensated=*/false),
+        subband_erle_estimator_.Erle(/*onset_compensated=*/true),
+        converged_filters);
+  }
+
+  fullband_erle_estimator_.Update(X2_reverb, Y2, E2, converged_filters);
+}
+
+void ErleEstimator::Dump(
+    const std::unique_ptr<ApmDataDumper>& data_dumper) const {
+  fullband_erle_estimator_.Dump(data_dumper);
+  subband_erle_estimator_.Dump(data_dumper);
+  if (signal_dependent_erle_estimator_) {
+    signal_dependent_erle_estimator_->Dump(data_dumper);
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erle_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erle_estimator.h
new file mode 100644
index 0000000..cae896e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erle_estimator.h
@@ -0,0 +1,100 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_ERLE_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_ERLE_ESTIMATOR_H_
+
+#include <stddef.h>
+
+#include <array>
+#include <memory>
+#include <vector>
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/fullband_erle_estimator.h"
+#include "modules/audio_processing/aec3/render_buffer.h"
+#include "modules/audio_processing/aec3/signal_dependent_erle_estimator.h"
+#include "modules/audio_processing/aec3/subband_erle_estimator.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+
+namespace webrtc {
+
+// Estimates the echo return loss enhancement. One estimate is done per subband
+// and another one is done using the aggreation of energy over all the subbands.
+class ErleEstimator {
+ public:
+  ErleEstimator(size_t startup_phase_length_blocks,
+                const EchoCanceller3Config& config,
+                size_t num_capture_channels);
+  ~ErleEstimator();
+
+  // Resets the fullband ERLE estimator and the subbands ERLE estimators.
+  void Reset(bool delay_change);
+
+  // Updates the ERLE estimates.
+  void Update(
+      const RenderBuffer& render_buffer,
+      rtc::ArrayView<const std::vector<std::array<float, kFftLengthBy2Plus1>>>
+          filter_frequency_responses,
+      rtc::ArrayView<const float, kFftLengthBy2Plus1>
+          avg_render_spectrum_with_reverb,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+          capture_spectra,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+          subtractor_spectra,
+      const std::vector<bool>& converged_filters);
+
+  // Returns the most recent subband ERLE estimates.
+  rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Erle(
+      bool onset_compensated) const {
+    return signal_dependent_erle_estimator_
+               ? signal_dependent_erle_estimator_->Erle(onset_compensated)
+               : subband_erle_estimator_.Erle(onset_compensated);
+  }
+
+  // Returns the subband ERLE that are estimated during onsets (only used for
+  // testing).
+  rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> ErleDuringOnsets()
+      const {
+    return subband_erle_estimator_.ErleDuringOnsets();
+  }
+
+  // Returns the fullband ERLE estimate.
+  float FullbandErleLog2() const {
+    return fullband_erle_estimator_.FullbandErleLog2();
+  }
+
+  // Returns an estimation of the current linear filter quality based on the
+  // current and past fullband ERLE estimates. The returned value is a float
+  // vector with content between 0 and 1 where 1 indicates that, at this current
+  // time instant, the linear filter is reaching its maximum subtraction
+  // performance.
+  rtc::ArrayView<const absl::optional<float>> GetInstLinearQualityEstimates()
+      const {
+    return fullband_erle_estimator_.GetInstLinearQualityEstimates();
+  }
+
+  void Dump(const std::unique_ptr<ApmDataDumper>& data_dumper) const;
+
+ private:
+  const size_t startup_phase_length_blocks_;
+  FullBandErleEstimator fullband_erle_estimator_;
+  SubbandErleEstimator subband_erle_estimator_;
+  std::unique_ptr<SignalDependentErleEstimator>
+      signal_dependent_erle_estimator_;
+  size_t blocks_since_reset_ = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_ERLE_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erle_estimator_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erle_estimator_unittest.cc
new file mode 100644
index 0000000..6df7142
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/erle_estimator_unittest.cc
@@ -0,0 +1,272 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/erle_estimator.h"
+
+#include <cmath>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "modules/audio_processing/aec3/spectrum_buffer.h"
+#include "rtc_base/random.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+namespace {
+constexpr int kLowFrequencyLimit = kFftLengthBy2 / 2;
+constexpr float kTrueErle = 10.f;
+constexpr float kTrueErleOnsets = 1.0f;
+constexpr float kEchoPathGain = 3.f;
+
+void VerifyErleBands(
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> erle,
+    float reference_lf,
+    float reference_hf) {
+  for (size_t ch = 0; ch < erle.size(); ++ch) {
+    std::for_each(
+        erle[ch].begin(), erle[ch].begin() + kLowFrequencyLimit,
+        [reference_lf](float a) { EXPECT_NEAR(reference_lf, a, 0.001); });
+    std::for_each(
+        erle[ch].begin() + kLowFrequencyLimit, erle[ch].end(),
+        [reference_hf](float a) { EXPECT_NEAR(reference_hf, a, 0.001); });
+  }
+}
+
+void VerifyErle(
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> erle,
+    float erle_time_domain,
+    float reference_lf,
+    float reference_hf) {
+  VerifyErleBands(erle, reference_lf, reference_hf);
+  EXPECT_NEAR(kTrueErle, erle_time_domain, 0.5);
+}
+
+void FormFarendTimeFrame(std::vector<std::vector<std::vector<float>>>* x) {
+  const std::array<float, kBlockSize> frame = {
+      7459.88, 17209.6, 17383,   20768.9, 16816.7, 18386.3, 4492.83, 9675.85,
+      6665.52, 14808.6, 9342.3,  7483.28, 19261.7, 4145.98, 1622.18, 13475.2,
+      7166.32, 6856.61, 21937,   7263.14, 9569.07, 14919,   8413.32, 7551.89,
+      7848.65, 6011.27, 13080.6, 15865.2, 12656,   17459.6, 4263.93, 4503.03,
+      9311.79, 21095.8, 12657.9, 13906.6, 19267.2, 11338.1, 16828.9, 11501.6,
+      11405,   15031.4, 14541.6, 19765.5, 18346.3, 19350.2, 3157.47, 18095.8,
+      1743.68, 21328.2, 19727.5, 7295.16, 10332.4, 11055.5, 20107.4, 14708.4,
+      12416.2, 16434,   2454.69, 9840.8,  6867.23, 1615.75, 6059.9,  8394.19};
+  for (size_t band = 0; band < x->size(); ++band) {
+    for (size_t channel = 0; channel < (*x)[band].size(); ++channel) {
+      RTC_DCHECK_GE((*x)[band][channel].size(), frame.size());
+      std::copy(frame.begin(), frame.end(), (*x)[band][channel].begin());
+    }
+  }
+}
+
+void FormFarendFrame(const RenderBuffer& render_buffer,
+                     float erle,
+                     std::array<float, kFftLengthBy2Plus1>* X2,
+                     rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>> E2,
+                     rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>> Y2) {
+  const auto& spectrum_buffer = render_buffer.GetSpectrumBuffer();
+  const int num_render_channels = spectrum_buffer.buffer[0].size();
+  const int num_capture_channels = Y2.size();
+
+  X2->fill(0.f);
+  for (int ch = 0; ch < num_render_channels; ++ch) {
+    for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+      (*X2)[k] += spectrum_buffer.buffer[spectrum_buffer.write][ch][k] /
+                  num_render_channels;
+    }
+  }
+
+  for (int ch = 0; ch < num_capture_channels; ++ch) {
+    std::transform(X2->begin(), X2->end(), Y2[ch].begin(),
+                   [](float a) { return a * kEchoPathGain * kEchoPathGain; });
+    std::transform(Y2[ch].begin(), Y2[ch].end(), E2[ch].begin(),
+                   [erle](float a) { return a / erle; });
+  }
+}
+
+void FormNearendFrame(
+    std::vector<std::vector<std::vector<float>>>* x,
+    std::array<float, kFftLengthBy2Plus1>* X2,
+    rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>> E2,
+    rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>> Y2) {
+  for (size_t band = 0; band < x->size(); ++band) {
+    for (size_t ch = 0; ch < (*x)[band].size(); ++ch) {
+      std::fill((*x)[band][ch].begin(), (*x)[band][ch].end(), 0.f);
+    }
+  }
+
+  X2->fill(0.f);
+  for (size_t ch = 0; ch < Y2.size(); ++ch) {
+    Y2[ch].fill(500.f * 1000.f * 1000.f);
+    E2[ch].fill(Y2[ch][0]);
+  }
+}
+
+void GetFilterFreq(
+    size_t delay_headroom_samples,
+    rtc::ArrayView<std::vector<std::array<float, kFftLengthBy2Plus1>>>
+        filter_frequency_response) {
+  const size_t delay_headroom_blocks = delay_headroom_samples / kBlockSize;
+  for (size_t ch = 0; ch < filter_frequency_response[0].size(); ++ch) {
+    for (auto& block_freq_resp : filter_frequency_response) {
+      block_freq_resp[ch].fill(0.f);
+    }
+
+    for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+      filter_frequency_response[delay_headroom_blocks][ch][k] = kEchoPathGain;
+    }
+  }
+}
+
+}  // namespace
+
+class ErleEstimatorMultiChannel
+    : public ::testing::Test,
+      public ::testing::WithParamInterface<std::tuple<size_t, size_t>> {};
+
+INSTANTIATE_TEST_SUITE_P(MultiChannel,
+                         ErleEstimatorMultiChannel,
+                         ::testing::Combine(::testing::Values(1, 2, 4, 8),
+                                            ::testing::Values(1, 2, 8)));
+
+TEST_P(ErleEstimatorMultiChannel, VerifyErleIncreaseAndHold) {
+  const size_t num_render_channels = std::get<0>(GetParam());
+  const size_t num_capture_channels = std::get<1>(GetParam());
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+
+  std::array<float, kFftLengthBy2Plus1> X2;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> E2(num_capture_channels);
+  std::vector<std::array<float, kFftLengthBy2Plus1>> Y2(num_capture_channels);
+  std::vector<bool> converged_filters(num_capture_channels, true);
+
+  EchoCanceller3Config config;
+  config.erle.onset_detection = true;
+
+  std::vector<std::vector<std::vector<float>>> x(
+      kNumBands, std::vector<std::vector<float>>(
+                     num_render_channels, std::vector<float>(kBlockSize, 0.f)));
+  std::vector<std::vector<std::array<float, kFftLengthBy2Plus1>>>
+  filter_frequency_response(
+      config.filter.refined.length_blocks,
+      std::vector<std::array<float, kFftLengthBy2Plus1>>(num_capture_channels));
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+      RenderDelayBuffer::Create(config, kSampleRateHz, num_render_channels));
+
+  GetFilterFreq(config.delay.delay_headroom_samples, filter_frequency_response);
+
+  ErleEstimator estimator(0, config, num_capture_channels);
+
+  FormFarendTimeFrame(&x);
+  render_delay_buffer->Insert(x);
+  render_delay_buffer->PrepareCaptureProcessing();
+  // Verifies that the ERLE estimate is properly increased to higher values.
+  FormFarendFrame(*render_delay_buffer->GetRenderBuffer(), kTrueErle, &X2, E2,
+                  Y2);
+  for (size_t k = 0; k < 1000; ++k) {
+    render_delay_buffer->Insert(x);
+    render_delay_buffer->PrepareCaptureProcessing();
+    estimator.Update(*render_delay_buffer->GetRenderBuffer(),
+                     filter_frequency_response, X2, Y2, E2, converged_filters);
+  }
+  VerifyErle(estimator.Erle(/*onset_compensated=*/true),
+             std::pow(2.f, estimator.FullbandErleLog2()), config.erle.max_l,
+             config.erle.max_h);
+
+  FormNearendFrame(&x, &X2, E2, Y2);
+  // Verifies that the ERLE is not immediately decreased during nearend
+  // activity.
+  for (size_t k = 0; k < 50; ++k) {
+    render_delay_buffer->Insert(x);
+    render_delay_buffer->PrepareCaptureProcessing();
+    estimator.Update(*render_delay_buffer->GetRenderBuffer(),
+                     filter_frequency_response, X2, Y2, E2, converged_filters);
+  }
+  VerifyErle(estimator.Erle(/*onset_compensated=*/true),
+             std::pow(2.f, estimator.FullbandErleLog2()), config.erle.max_l,
+             config.erle.max_h);
+}
+
+TEST_P(ErleEstimatorMultiChannel, VerifyErleTrackingOnOnsets) {
+  const size_t num_render_channels = std::get<0>(GetParam());
+  const size_t num_capture_channels = std::get<1>(GetParam());
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+
+  std::array<float, kFftLengthBy2Plus1> X2;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> E2(num_capture_channels);
+  std::vector<std::array<float, kFftLengthBy2Plus1>> Y2(num_capture_channels);
+  std::vector<bool> converged_filters(num_capture_channels, true);
+  EchoCanceller3Config config;
+  config.erle.onset_detection = true;
+  std::vector<std::vector<std::vector<float>>> x(
+      kNumBands, std::vector<std::vector<float>>(
+                     num_render_channels, std::vector<float>(kBlockSize, 0.f)));
+  std::vector<std::vector<std::array<float, kFftLengthBy2Plus1>>>
+  filter_frequency_response(
+      config.filter.refined.length_blocks,
+      std::vector<std::array<float, kFftLengthBy2Plus1>>(num_capture_channels));
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+      RenderDelayBuffer::Create(config, kSampleRateHz, num_render_channels));
+
+  GetFilterFreq(config.delay.delay_headroom_samples, filter_frequency_response);
+
+  ErleEstimator estimator(/*startup_phase_length_blocks=*/0, config,
+                          num_capture_channels);
+
+  FormFarendTimeFrame(&x);
+  render_delay_buffer->Insert(x);
+  render_delay_buffer->PrepareCaptureProcessing();
+
+  for (size_t burst = 0; burst < 20; ++burst) {
+    FormFarendFrame(*render_delay_buffer->GetRenderBuffer(), kTrueErleOnsets,
+                    &X2, E2, Y2);
+    for (size_t k = 0; k < 10; ++k) {
+      render_delay_buffer->Insert(x);
+      render_delay_buffer->PrepareCaptureProcessing();
+      estimator.Update(*render_delay_buffer->GetRenderBuffer(),
+                       filter_frequency_response, X2, Y2, E2,
+                       converged_filters);
+    }
+    FormFarendFrame(*render_delay_buffer->GetRenderBuffer(), kTrueErle, &X2, E2,
+                    Y2);
+    for (size_t k = 0; k < 1000; ++k) {
+      render_delay_buffer->Insert(x);
+      render_delay_buffer->PrepareCaptureProcessing();
+      estimator.Update(*render_delay_buffer->GetRenderBuffer(),
+                       filter_frequency_response, X2, Y2, E2,
+                       converged_filters);
+    }
+    FormNearendFrame(&x, &X2, E2, Y2);
+    for (size_t k = 0; k < 300; ++k) {
+      render_delay_buffer->Insert(x);
+      render_delay_buffer->PrepareCaptureProcessing();
+      estimator.Update(*render_delay_buffer->GetRenderBuffer(),
+                       filter_frequency_response, X2, Y2, E2,
+                       converged_filters);
+    }
+  }
+  VerifyErleBands(estimator.ErleDuringOnsets(), config.erle.min,
+                  config.erle.min);
+  FormNearendFrame(&x, &X2, E2, Y2);
+  for (size_t k = 0; k < 1000; k++) {
+    estimator.Update(*render_delay_buffer->GetRenderBuffer(),
+                     filter_frequency_response, X2, Y2, E2, converged_filters);
+  }
+  // Verifies that during ne activity, Erle converges to the Erle for
+  // onsets.
+  VerifyErle(estimator.Erle(/*onset_compensated=*/true),
+             std::pow(2.f, estimator.FullbandErleLog2()), config.erle.min,
+             config.erle.min);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fft_buffer.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fft_buffer.cc
new file mode 100644
index 0000000..1ce2d31
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fft_buffer.cc
@@ -0,0 +1,27 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/fft_buffer.h"
+
+namespace webrtc {
+
+FftBuffer::FftBuffer(size_t size, size_t num_channels)
+    : size(static_cast<int>(size)),
+      buffer(size, std::vector<FftData>(num_channels)) {
+  for (auto& block : buffer) {
+    for (auto& channel_fft_data : block) {
+      channel_fft_data.Clear();
+    }
+  }
+}
+
+FftBuffer::~FftBuffer() = default;
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fft_buffer.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fft_buffer.h
new file mode 100644
index 0000000..4187315
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fft_buffer.h
@@ -0,0 +1,60 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_FFT_BUFFER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_FFT_BUFFER_H_
+
+#include <stddef.h>
+
+#include <vector>
+
+#include "modules/audio_processing/aec3/fft_data.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+// Struct for bundling a circular buffer of FftData objects together with the
+// read and write indices.
+struct FftBuffer {
+  FftBuffer(size_t size, size_t num_channels);
+  ~FftBuffer();
+
+  int IncIndex(int index) const {
+    RTC_DCHECK_EQ(buffer.size(), static_cast<size_t>(size));
+    return index < size - 1 ? index + 1 : 0;
+  }
+
+  int DecIndex(int index) const {
+    RTC_DCHECK_EQ(buffer.size(), static_cast<size_t>(size));
+    return index > 0 ? index - 1 : size - 1;
+  }
+
+  int OffsetIndex(int index, int offset) const {
+    RTC_DCHECK_GE(buffer.size(), offset);
+    RTC_DCHECK_EQ(buffer.size(), static_cast<size_t>(size));
+    return (size + index + offset) % size;
+  }
+
+  void UpdateWriteIndex(int offset) { write = OffsetIndex(write, offset); }
+  void IncWriteIndex() { write = IncIndex(write); }
+  void DecWriteIndex() { write = DecIndex(write); }
+  void UpdateReadIndex(int offset) { read = OffsetIndex(read, offset); }
+  void IncReadIndex() { read = IncIndex(read); }
+  void DecReadIndex() { read = DecIndex(read); }
+
+  const int size;
+  std::vector<std::vector<FftData>> buffer;
+  int write = 0;
+  int read = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_FFT_BUFFER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fft_data.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fft_data.h
new file mode 100644
index 0000000..9c25e78
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fft_data.h
@@ -0,0 +1,104 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_FFT_DATA_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_FFT_DATA_H_
+
+// Defines WEBRTC_ARCH_X86_FAMILY, used below.
+#include "rtc_base/system/arch.h"
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+#include <emmintrin.h>
+#endif
+#include <algorithm>
+#include <array>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+
+namespace webrtc {
+
+// Struct that holds imaginary data produced from 128 point real-valued FFTs.
+struct FftData {
+  // Copies the data in src.
+  void Assign(const FftData& src) {
+    std::copy(src.re.begin(), src.re.end(), re.begin());
+    std::copy(src.im.begin(), src.im.end(), im.begin());
+    im[0] = im[kFftLengthBy2] = 0;
+  }
+
+  // Clears all the imaginary.
+  void Clear() {
+    re.fill(0.f);
+    im.fill(0.f);
+  }
+
+  // Computes the power spectrum of the data.
+  void SpectrumAVX2(rtc::ArrayView<float> power_spectrum) const;
+
+  // Computes the power spectrum of the data.
+  void Spectrum(Aec3Optimization optimization,
+                rtc::ArrayView<float> power_spectrum) const {
+    RTC_DCHECK_EQ(kFftLengthBy2Plus1, power_spectrum.size());
+    switch (optimization) {
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+      case Aec3Optimization::kSse2: {
+        constexpr int kNumFourBinBands = kFftLengthBy2 / 4;
+        constexpr int kLimit = kNumFourBinBands * 4;
+        for (size_t k = 0; k < kLimit; k += 4) {
+          const __m128 r = _mm_loadu_ps(&re[k]);
+          const __m128 i = _mm_loadu_ps(&im[k]);
+          const __m128 ii = _mm_mul_ps(i, i);
+          const __m128 rr = _mm_mul_ps(r, r);
+          const __m128 rrii = _mm_add_ps(rr, ii);
+          _mm_storeu_ps(&power_spectrum[k], rrii);
+        }
+        power_spectrum[kFftLengthBy2] = re[kFftLengthBy2] * re[kFftLengthBy2] +
+                                        im[kFftLengthBy2] * im[kFftLengthBy2];
+      } break;
+      case Aec3Optimization::kAvx2:
+        SpectrumAVX2(power_spectrum);
+        break;
+#endif
+      default:
+        std::transform(re.begin(), re.end(), im.begin(), power_spectrum.begin(),
+                       [](float a, float b) { return a * a + b * b; });
+    }
+  }
+
+  // Copy the data from an interleaved array.
+  void CopyFromPackedArray(const std::array<float, kFftLength>& v) {
+    re[0] = v[0];
+    re[kFftLengthBy2] = v[1];
+    im[0] = im[kFftLengthBy2] = 0;
+    for (size_t k = 1, j = 2; k < kFftLengthBy2; ++k) {
+      re[k] = v[j++];
+      im[k] = v[j++];
+    }
+  }
+
+  // Copies the data into an interleaved array.
+  void CopyToPackedArray(std::array<float, kFftLength>* v) const {
+    RTC_DCHECK(v);
+    (*v)[0] = re[0];
+    (*v)[1] = re[kFftLengthBy2];
+    for (size_t k = 1, j = 2; k < kFftLengthBy2; ++k) {
+      (*v)[j++] = re[k];
+      (*v)[j++] = im[k];
+    }
+  }
+
+  std::array<float, kFftLengthBy2Plus1> re;
+  std::array<float, kFftLengthBy2Plus1> im;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_FFT_DATA_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fft_data_avx2.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fft_data_avx2.cc
new file mode 100644
index 0000000..1fe4bd6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fft_data_avx2.cc
@@ -0,0 +1,33 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/fft_data.h"
+
+#include <immintrin.h>
+
+#include "api/array_view.h"
+
+namespace webrtc {
+
+// Computes the power spectrum of the data.
+void FftData::SpectrumAVX2(rtc::ArrayView<float> power_spectrum) const {
+  RTC_DCHECK_EQ(kFftLengthBy2Plus1, power_spectrum.size());
+  for (size_t k = 0; k < kFftLengthBy2; k += 8) {
+    __m256 r = _mm256_loadu_ps(&re[k]);
+    __m256 i = _mm256_loadu_ps(&im[k]);
+    __m256 ii = _mm256_mul_ps(i, i);
+    ii = _mm256_fmadd_ps(r, r, ii);
+    _mm256_storeu_ps(&power_spectrum[k], ii);
+  }
+  power_spectrum[kFftLengthBy2] = re[kFftLengthBy2] * re[kFftLengthBy2] +
+                                  im[kFftLengthBy2] * im[kFftLengthBy2];
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fft_data_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fft_data_unittest.cc
new file mode 100644
index 0000000..d76fabd
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fft_data_unittest.cc
@@ -0,0 +1,186 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/fft_data.h"
+
+#include "rtc_base/system/arch.h"
+#include "system_wrappers/include/cpu_features_wrapper.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+// Verifies that the optimized methods are bitexact to their reference
+// counterparts.
+TEST(FftData, TestSse2Optimizations) {
+  if (GetCPUInfo(kSSE2) != 0) {
+    FftData x;
+
+    for (size_t k = 0; k < x.re.size(); ++k) {
+      x.re[k] = k + 1;
+    }
+
+    x.im[0] = x.im[x.im.size() - 1] = 0.f;
+    for (size_t k = 1; k < x.im.size() - 1; ++k) {
+      x.im[k] = 2.f * (k + 1);
+    }
+
+    std::array<float, kFftLengthBy2Plus1> spectrum;
+    std::array<float, kFftLengthBy2Plus1> spectrum_sse2;
+    x.Spectrum(Aec3Optimization::kNone, spectrum);
+    x.Spectrum(Aec3Optimization::kSse2, spectrum_sse2);
+    EXPECT_EQ(spectrum, spectrum_sse2);
+  }
+}
+
+// Verifies that the optimized methods are bitexact to their reference
+// counterparts.
+TEST(FftData, TestAvx2Optimizations) {
+  if (GetCPUInfo(kAVX2) != 0) {
+    FftData x;
+
+    for (size_t k = 0; k < x.re.size(); ++k) {
+      x.re[k] = k + 1;
+    }
+
+    x.im[0] = x.im[x.im.size() - 1] = 0.f;
+    for (size_t k = 1; k < x.im.size() - 1; ++k) {
+      x.im[k] = 2.f * (k + 1);
+    }
+
+    std::array<float, kFftLengthBy2Plus1> spectrum;
+    std::array<float, kFftLengthBy2Plus1> spectrum_avx2;
+    x.Spectrum(Aec3Optimization::kNone, spectrum);
+    x.Spectrum(Aec3Optimization::kAvx2, spectrum_avx2);
+    EXPECT_EQ(spectrum, spectrum_avx2);
+  }
+}
+#endif
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+// Verifies the check for null output in CopyToPackedArray.
+TEST(FftDataDeathTest, NonNullCopyToPackedArrayOutput) {
+  EXPECT_DEATH(FftData().CopyToPackedArray(nullptr), "");
+}
+
+// Verifies the check for null output in Spectrum.
+TEST(FftDataDeathTest, NonNullSpectrumOutput) {
+  EXPECT_DEATH(FftData().Spectrum(Aec3Optimization::kNone, nullptr), "");
+}
+
+#endif
+
+// Verifies that the Assign method properly copies the data from the source and
+// ensures that the imaginary components for the DC and Nyquist bins are 0.
+TEST(FftData, Assign) {
+  FftData x;
+  FftData y;
+
+  x.re.fill(1.f);
+  x.im.fill(2.f);
+  y.Assign(x);
+  EXPECT_EQ(x.re, y.re);
+  EXPECT_EQ(0.f, y.im[0]);
+  EXPECT_EQ(0.f, y.im[x.im.size() - 1]);
+  for (size_t k = 1; k < x.im.size() - 1; ++k) {
+    EXPECT_EQ(x.im[k], y.im[k]);
+  }
+}
+
+// Verifies that the Clear method properly clears all the data.
+TEST(FftData, Clear) {
+  FftData x_ref;
+  FftData x;
+
+  x_ref.re.fill(0.f);
+  x_ref.im.fill(0.f);
+
+  x.re.fill(1.f);
+  x.im.fill(2.f);
+  x.Clear();
+
+  EXPECT_EQ(x_ref.re, x.re);
+  EXPECT_EQ(x_ref.im, x.im);
+}
+
+// Verifies that the spectrum is correctly computed.
+TEST(FftData, Spectrum) {
+  FftData x;
+
+  for (size_t k = 0; k < x.re.size(); ++k) {
+    x.re[k] = k + 1;
+  }
+
+  x.im[0] = x.im[x.im.size() - 1] = 0.f;
+  for (size_t k = 1; k < x.im.size() - 1; ++k) {
+    x.im[k] = 2.f * (k + 1);
+  }
+
+  std::array<float, kFftLengthBy2Plus1> spectrum;
+  x.Spectrum(Aec3Optimization::kNone, spectrum);
+
+  EXPECT_EQ(x.re[0] * x.re[0], spectrum[0]);
+  EXPECT_EQ(x.re[spectrum.size() - 1] * x.re[spectrum.size() - 1],
+            spectrum[spectrum.size() - 1]);
+  for (size_t k = 1; k < spectrum.size() - 1; ++k) {
+    EXPECT_EQ(x.re[k] * x.re[k] + x.im[k] * x.im[k], spectrum[k]);
+  }
+}
+
+// Verifies that the functionality in CopyToPackedArray works as intended.
+TEST(FftData, CopyToPackedArray) {
+  FftData x;
+  std::array<float, kFftLength> x_packed;
+
+  for (size_t k = 0; k < x.re.size(); ++k) {
+    x.re[k] = k + 1;
+  }
+
+  x.im[0] = x.im[x.im.size() - 1] = 0.f;
+  for (size_t k = 1; k < x.im.size() - 1; ++k) {
+    x.im[k] = 2.f * (k + 1);
+  }
+
+  x.CopyToPackedArray(&x_packed);
+
+  EXPECT_EQ(x.re[0], x_packed[0]);
+  EXPECT_EQ(x.re[x.re.size() - 1], x_packed[1]);
+  for (size_t k = 1; k < x_packed.size() / 2; ++k) {
+    EXPECT_EQ(x.re[k], x_packed[2 * k]);
+    EXPECT_EQ(x.im[k], x_packed[2 * k + 1]);
+  }
+}
+
+// Verifies that the functionality in CopyFromPackedArray works as intended
+// (relies on that the functionality in CopyToPackedArray has been verified in
+// the test above).
+TEST(FftData, CopyFromPackedArray) {
+  FftData x_ref;
+  FftData x;
+  std::array<float, kFftLength> x_packed;
+
+  for (size_t k = 0; k < x_ref.re.size(); ++k) {
+    x_ref.re[k] = k + 1;
+  }
+
+  x_ref.im[0] = x_ref.im[x_ref.im.size() - 1] = 0.f;
+  for (size_t k = 1; k < x_ref.im.size() - 1; ++k) {
+    x_ref.im[k] = 2.f * (k + 1);
+  }
+
+  x_ref.CopyToPackedArray(&x_packed);
+  x.CopyFromPackedArray(x_packed);
+
+  EXPECT_EQ(x_ref.re, x.re);
+  EXPECT_EQ(x_ref.im, x.im);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/filter_analyzer.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/filter_analyzer.cc
new file mode 100644
index 0000000..be954d3
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/filter_analyzer.cc
@@ -0,0 +1,280 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/filter_analyzer.h"
+
+#include <math.h>
+
+#include <algorithm>
+#include <array>
+#include <numeric>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/render_buffer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/atomic_ops.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+
+size_t FindPeakIndex(rtc::ArrayView<const float> filter_time_domain,
+                     size_t peak_index_in,
+                     size_t start_sample,
+                     size_t end_sample) {
+  size_t peak_index_out = peak_index_in;
+  float max_h2 =
+      filter_time_domain[peak_index_out] * filter_time_domain[peak_index_out];
+  for (size_t k = start_sample; k <= end_sample; ++k) {
+    float tmp = filter_time_domain[k] * filter_time_domain[k];
+    if (tmp > max_h2) {
+      peak_index_out = k;
+      max_h2 = tmp;
+    }
+  }
+
+  return peak_index_out;
+}
+
+}  // namespace
+
+int FilterAnalyzer::instance_count_ = 0;
+
+FilterAnalyzer::FilterAnalyzer(const EchoCanceller3Config& config,
+                               size_t num_capture_channels)
+    : data_dumper_(
+          new ApmDataDumper(rtc::AtomicOps::Increment(&instance_count_))),
+      bounded_erl_(config.ep_strength.bounded_erl),
+      default_gain_(config.ep_strength.default_gain),
+      h_highpass_(num_capture_channels,
+                  std::vector<float>(
+                      GetTimeDomainLength(config.filter.refined.length_blocks),
+                      0.f)),
+      filter_analysis_states_(num_capture_channels,
+                              FilterAnalysisState(config)),
+      filter_delays_blocks_(num_capture_channels, 0) {
+  Reset();
+}
+
+FilterAnalyzer::~FilterAnalyzer() = default;
+
+void FilterAnalyzer::Reset() {
+  blocks_since_reset_ = 0;
+  ResetRegion();
+  for (auto& state : filter_analysis_states_) {
+    state.Reset(default_gain_);
+  }
+  std::fill(filter_delays_blocks_.begin(), filter_delays_blocks_.end(), 0);
+}
+
+void FilterAnalyzer::Update(
+    rtc::ArrayView<const std::vector<float>> filters_time_domain,
+    const RenderBuffer& render_buffer,
+    bool* any_filter_consistent,
+    float* max_echo_path_gain) {
+  RTC_DCHECK(any_filter_consistent);
+  RTC_DCHECK(max_echo_path_gain);
+  RTC_DCHECK_EQ(filters_time_domain.size(), filter_analysis_states_.size());
+  RTC_DCHECK_EQ(filters_time_domain.size(), h_highpass_.size());
+
+  ++blocks_since_reset_;
+  SetRegionToAnalyze(filters_time_domain[0].size());
+  AnalyzeRegion(filters_time_domain, render_buffer);
+
+  // Aggregate the results for all capture channels.
+  auto& st_ch0 = filter_analysis_states_[0];
+  *any_filter_consistent = st_ch0.consistent_estimate;
+  *max_echo_path_gain = st_ch0.gain;
+  min_filter_delay_blocks_ = filter_delays_blocks_[0];
+  for (size_t ch = 1; ch < filters_time_domain.size(); ++ch) {
+    auto& st_ch = filter_analysis_states_[ch];
+    *any_filter_consistent =
+        *any_filter_consistent || st_ch.consistent_estimate;
+    *max_echo_path_gain = std::max(*max_echo_path_gain, st_ch.gain);
+    min_filter_delay_blocks_ =
+        std::min(min_filter_delay_blocks_, filter_delays_blocks_[ch]);
+  }
+}
+
+void FilterAnalyzer::AnalyzeRegion(
+    rtc::ArrayView<const std::vector<float>> filters_time_domain,
+    const RenderBuffer& render_buffer) {
+  // Preprocess the filter to avoid issues with low-frequency components in the
+  // filter.
+  PreProcessFilters(filters_time_domain);
+  data_dumper_->DumpRaw("aec3_linear_filter_processed_td", h_highpass_[0]);
+
+  constexpr float kOneByBlockSize = 1.f / kBlockSize;
+  for (size_t ch = 0; ch < filters_time_domain.size(); ++ch) {
+    RTC_DCHECK_LT(region_.start_sample_, filters_time_domain[ch].size());
+    RTC_DCHECK_LT(region_.end_sample_, filters_time_domain[ch].size());
+
+    auto& st_ch = filter_analysis_states_[ch];
+    RTC_DCHECK_EQ(h_highpass_[ch].size(), filters_time_domain[ch].size());
+    RTC_DCHECK_GT(h_highpass_[ch].size(), 0);
+    st_ch.peak_index = std::min(st_ch.peak_index, h_highpass_[ch].size() - 1);
+
+    st_ch.peak_index =
+        FindPeakIndex(h_highpass_[ch], st_ch.peak_index, region_.start_sample_,
+                      region_.end_sample_);
+    filter_delays_blocks_[ch] = st_ch.peak_index >> kBlockSizeLog2;
+    UpdateFilterGain(h_highpass_[ch], &st_ch);
+    st_ch.filter_length_blocks =
+        filters_time_domain[ch].size() * kOneByBlockSize;
+
+    st_ch.consistent_estimate = st_ch.consistent_filter_detector.Detect(
+        h_highpass_[ch], region_,
+        render_buffer.Block(-filter_delays_blocks_[ch])[0], st_ch.peak_index,
+        filter_delays_blocks_[ch]);
+  }
+}
+
+void FilterAnalyzer::UpdateFilterGain(
+    rtc::ArrayView<const float> filter_time_domain,
+    FilterAnalysisState* st) {
+  bool sufficient_time_to_converge =
+      blocks_since_reset_ > 5 * kNumBlocksPerSecond;
+
+  if (sufficient_time_to_converge && st->consistent_estimate) {
+    st->gain = fabsf(filter_time_domain[st->peak_index]);
+  } else {
+    // TODO(peah): Verify whether this check against a float is ok.
+    if (st->gain) {
+      st->gain = std::max(st->gain, fabsf(filter_time_domain[st->peak_index]));
+    }
+  }
+
+  if (bounded_erl_ && st->gain) {
+    st->gain = std::max(st->gain, 0.01f);
+  }
+}
+
+void FilterAnalyzer::PreProcessFilters(
+    rtc::ArrayView<const std::vector<float>> filters_time_domain) {
+  for (size_t ch = 0; ch < filters_time_domain.size(); ++ch) {
+    RTC_DCHECK_LT(region_.start_sample_, filters_time_domain[ch].size());
+    RTC_DCHECK_LT(region_.end_sample_, filters_time_domain[ch].size());
+
+    RTC_DCHECK_GE(h_highpass_[ch].capacity(), filters_time_domain[ch].size());
+    h_highpass_[ch].resize(filters_time_domain[ch].size());
+    // Minimum phase high-pass filter with cutoff frequency at about 600 Hz.
+    constexpr std::array<float, 3> h = {
+        {0.7929742f, -0.36072128f, -0.47047766f}};
+
+    std::fill(h_highpass_[ch].begin() + region_.start_sample_,
+              h_highpass_[ch].begin() + region_.end_sample_ + 1, 0.f);
+    for (size_t k = std::max(h.size() - 1, region_.start_sample_);
+         k <= region_.end_sample_; ++k) {
+      for (size_t j = 0; j < h.size(); ++j) {
+        h_highpass_[ch][k] += filters_time_domain[ch][k - j] * h[j];
+      }
+    }
+  }
+}
+
+void FilterAnalyzer::ResetRegion() {
+  region_.start_sample_ = 0;
+  region_.end_sample_ = 0;
+}
+
+void FilterAnalyzer::SetRegionToAnalyze(size_t filter_size) {
+  constexpr size_t kNumberBlocksToUpdate = 1;
+  auto& r = region_;
+  r.start_sample_ = r.end_sample_ >= filter_size - 1 ? 0 : r.end_sample_ + 1;
+  r.end_sample_ =
+      std::min(r.start_sample_ + kNumberBlocksToUpdate * kBlockSize - 1,
+               filter_size - 1);
+
+  // Check range.
+  RTC_DCHECK_LT(r.start_sample_, filter_size);
+  RTC_DCHECK_LT(r.end_sample_, filter_size);
+  RTC_DCHECK_LE(r.start_sample_, r.end_sample_);
+}
+
+FilterAnalyzer::ConsistentFilterDetector::ConsistentFilterDetector(
+    const EchoCanceller3Config& config)
+    : active_render_threshold_(config.render_levels.active_render_limit *
+                               config.render_levels.active_render_limit *
+                               kFftLengthBy2) {
+  Reset();
+}
+
+void FilterAnalyzer::ConsistentFilterDetector::Reset() {
+  significant_peak_ = false;
+  filter_floor_accum_ = 0.f;
+  filter_secondary_peak_ = 0.f;
+  filter_floor_low_limit_ = 0;
+  filter_floor_high_limit_ = 0;
+  consistent_estimate_counter_ = 0;
+  consistent_delay_reference_ = -10;
+}
+
+bool FilterAnalyzer::ConsistentFilterDetector::Detect(
+    rtc::ArrayView<const float> filter_to_analyze,
+    const FilterRegion& region,
+    rtc::ArrayView<const std::vector<float>> x_block,
+    size_t peak_index,
+    int delay_blocks) {
+  if (region.start_sample_ == 0) {
+    filter_floor_accum_ = 0.f;
+    filter_secondary_peak_ = 0.f;
+    filter_floor_low_limit_ = peak_index < 64 ? 0 : peak_index - 64;
+    filter_floor_high_limit_ =
+        peak_index > filter_to_analyze.size() - 129 ? 0 : peak_index + 128;
+  }
+
+  for (size_t k = region.start_sample_;
+       k < std::min(region.end_sample_ + 1, filter_floor_low_limit_); ++k) {
+    float abs_h = fabsf(filter_to_analyze[k]);
+    filter_floor_accum_ += abs_h;
+    filter_secondary_peak_ = std::max(filter_secondary_peak_, abs_h);
+  }
+
+  for (size_t k = std::max(filter_floor_high_limit_, region.start_sample_);
+       k <= region.end_sample_; ++k) {
+    float abs_h = fabsf(filter_to_analyze[k]);
+    filter_floor_accum_ += abs_h;
+    filter_secondary_peak_ = std::max(filter_secondary_peak_, abs_h);
+  }
+
+  if (region.end_sample_ == filter_to_analyze.size() - 1) {
+    float filter_floor = filter_floor_accum_ /
+                         (filter_floor_low_limit_ + filter_to_analyze.size() -
+                          filter_floor_high_limit_);
+
+    float abs_peak = fabsf(filter_to_analyze[peak_index]);
+    significant_peak_ = abs_peak > 10.f * filter_floor &&
+                        abs_peak > 2.f * filter_secondary_peak_;
+  }
+
+  if (significant_peak_) {
+    bool active_render_block = false;
+    for (auto& x_channel : x_block) {
+      const float x_energy = std::inner_product(
+          x_channel.begin(), x_channel.end(), x_channel.begin(), 0.f);
+      if (x_energy > active_render_threshold_) {
+        active_render_block = true;
+        break;
+      }
+    }
+
+    if (consistent_delay_reference_ == delay_blocks) {
+      if (active_render_block) {
+        ++consistent_estimate_counter_;
+      }
+    } else {
+      consistent_estimate_counter_ = 0;
+      consistent_delay_reference_ = delay_blocks;
+    }
+  }
+  return consistent_estimate_counter_ > 1.5f * kNumBlocksPerSecond;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/filter_analyzer.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/filter_analyzer.h
new file mode 100644
index 0000000..b0b7070
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/filter_analyzer.h
@@ -0,0 +1,149 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_FILTER_ANALYZER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_FILTER_ANALYZER_H_
+
+#include <stddef.h>
+
+#include <array>
+#include <memory>
+#include <vector>
+
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+class ApmDataDumper;
+class RenderBuffer;
+
+// Class for analyzing the properties of an adaptive filter.
+class FilterAnalyzer {
+ public:
+  FilterAnalyzer(const EchoCanceller3Config& config,
+                 size_t num_capture_channels);
+  ~FilterAnalyzer();
+
+  FilterAnalyzer(const FilterAnalyzer&) = delete;
+  FilterAnalyzer& operator=(const FilterAnalyzer&) = delete;
+
+  // Resets the analysis.
+  void Reset();
+
+  // Updates the estimates with new input data.
+  void Update(rtc::ArrayView<const std::vector<float>> filters_time_domain,
+              const RenderBuffer& render_buffer,
+              bool* any_filter_consistent,
+              float* max_echo_path_gain);
+
+  // Returns the delay in blocks for each filter.
+  rtc::ArrayView<const int> FilterDelaysBlocks() const {
+    return filter_delays_blocks_;
+  }
+
+  // Returns the minimum delay of all filters in terms of blocks.
+  int MinFilterDelayBlocks() const { return min_filter_delay_blocks_; }
+
+  // Returns the number of blocks for the current used filter.
+  int FilterLengthBlocks() const {
+    return filter_analysis_states_[0].filter_length_blocks;
+  }
+
+  // Returns the preprocessed filter.
+  rtc::ArrayView<const std::vector<float>> GetAdjustedFilters() const {
+    return h_highpass_;
+  }
+
+  // Public for testing purposes only.
+  void SetRegionToAnalyze(size_t filter_size);
+
+ private:
+  struct FilterAnalysisState;
+
+  void AnalyzeRegion(
+      rtc::ArrayView<const std::vector<float>> filters_time_domain,
+      const RenderBuffer& render_buffer);
+
+  void UpdateFilterGain(rtc::ArrayView<const float> filters_time_domain,
+                        FilterAnalysisState* st);
+  void PreProcessFilters(
+      rtc::ArrayView<const std::vector<float>> filters_time_domain);
+
+  void ResetRegion();
+
+  struct FilterRegion {
+    size_t start_sample_;
+    size_t end_sample_;
+  };
+
+  // This class checks whether the shape of the impulse response has been
+  // consistent over time.
+  class ConsistentFilterDetector {
+   public:
+    explicit ConsistentFilterDetector(const EchoCanceller3Config& config);
+    void Reset();
+    bool Detect(rtc::ArrayView<const float> filter_to_analyze,
+                const FilterRegion& region,
+                rtc::ArrayView<const std::vector<float>> x_block,
+                size_t peak_index,
+                int delay_blocks);
+
+   private:
+    bool significant_peak_;
+    float filter_floor_accum_;
+    float filter_secondary_peak_;
+    size_t filter_floor_low_limit_;
+    size_t filter_floor_high_limit_;
+    const float active_render_threshold_;
+    size_t consistent_estimate_counter_ = 0;
+    int consistent_delay_reference_ = -10;
+  };
+
+  struct FilterAnalysisState {
+    explicit FilterAnalysisState(const EchoCanceller3Config& config)
+        : filter_length_blocks(config.filter.refined_initial.length_blocks),
+          consistent_filter_detector(config) {
+      Reset(config.ep_strength.default_gain);
+    }
+
+    void Reset(float default_gain) {
+      peak_index = 0;
+      gain = default_gain;
+      consistent_filter_detector.Reset();
+    }
+
+    float gain;
+    size_t peak_index;
+    int filter_length_blocks;
+    bool consistent_estimate = false;
+    ConsistentFilterDetector consistent_filter_detector;
+  };
+
+  static int instance_count_;
+  std::unique_ptr<ApmDataDumper> data_dumper_;
+  const bool bounded_erl_;
+  const float default_gain_;
+  std::vector<std::vector<float>> h_highpass_;
+
+  size_t blocks_since_reset_ = 0;
+  FilterRegion region_;
+
+  std::vector<FilterAnalysisState> filter_analysis_states_;
+  std::vector<int> filter_delays_blocks_;
+
+  int min_filter_delay_blocks_ = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_FILTER_ANALYZER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/filter_analyzer_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/filter_analyzer_unittest.cc
new file mode 100644
index 0000000..f1e2e4c
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/filter_analyzer_unittest.cc
@@ -0,0 +1,33 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/filter_analyzer.h"
+
+#include <algorithm>
+
+#include "test/gmock.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+// Verifies that the filter analyzer handles filter resizes properly.
+TEST(FilterAnalyzer, FilterResize) {
+  EchoCanceller3Config c;
+  std::vector<float> filter(65, 0.f);
+  for (size_t num_capture_channels : {1, 2, 4}) {
+    FilterAnalyzer fa(c, num_capture_channels);
+    fa.SetRegionToAnalyze(filter.size());
+    fa.SetRegionToAnalyze(filter.size());
+    filter.resize(32);
+    fa.SetRegionToAnalyze(filter.size());
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/frame_blocker.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/frame_blocker.cc
new file mode 100644
index 0000000..63aaf09
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/frame_blocker.cc
@@ -0,0 +1,88 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/frame_blocker.h"
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+FrameBlocker::FrameBlocker(size_t num_bands, size_t num_channels)
+    : num_bands_(num_bands),
+      num_channels_(num_channels),
+      buffer_(num_bands_, std::vector<std::vector<float>>(num_channels)) {
+  RTC_DCHECK_LT(0, num_bands);
+  RTC_DCHECK_LT(0, num_channels);
+  for (auto& band : buffer_) {
+    for (auto& channel : band) {
+      channel.reserve(kBlockSize);
+      RTC_DCHECK(channel.empty());
+    }
+  }
+}
+
+FrameBlocker::~FrameBlocker() = default;
+
+void FrameBlocker::InsertSubFrameAndExtractBlock(
+    const std::vector<std::vector<rtc::ArrayView<float>>>& sub_frame,
+    std::vector<std::vector<std::vector<float>>>* block) {
+  RTC_DCHECK(block);
+  RTC_DCHECK_EQ(num_bands_, block->size());
+  RTC_DCHECK_EQ(num_bands_, sub_frame.size());
+  for (size_t band = 0; band < num_bands_; ++band) {
+    RTC_DCHECK_EQ(num_channels_, (*block)[band].size());
+    RTC_DCHECK_EQ(num_channels_, sub_frame[band].size());
+    for (size_t channel = 0; channel < num_channels_; ++channel) {
+      RTC_DCHECK_GE(kBlockSize - 16, buffer_[band][channel].size());
+      RTC_DCHECK_EQ(kBlockSize, (*block)[band][channel].size());
+      RTC_DCHECK_EQ(kSubFrameLength, sub_frame[band][channel].size());
+      const int samples_to_block = kBlockSize - buffer_[band][channel].size();
+      (*block)[band][channel].clear();
+      (*block)[band][channel].insert((*block)[band][channel].begin(),
+                                     buffer_[band][channel].begin(),
+                                     buffer_[band][channel].end());
+      (*block)[band][channel].insert(
+          (*block)[band][channel].begin() + buffer_[band][channel].size(),
+          sub_frame[band][channel].begin(),
+          sub_frame[band][channel].begin() + samples_to_block);
+      buffer_[band][channel].clear();
+      buffer_[band][channel].insert(
+          buffer_[band][channel].begin(),
+          sub_frame[band][channel].begin() + samples_to_block,
+          sub_frame[band][channel].end());
+    }
+  }
+}
+
+bool FrameBlocker::IsBlockAvailable() const {
+  return kBlockSize == buffer_[0][0].size();
+}
+
+void FrameBlocker::ExtractBlock(
+    std::vector<std::vector<std::vector<float>>>* block) {
+  RTC_DCHECK(block);
+  RTC_DCHECK_EQ(num_bands_, block->size());
+  RTC_DCHECK(IsBlockAvailable());
+  for (size_t band = 0; band < num_bands_; ++band) {
+    RTC_DCHECK_EQ(num_channels_, (*block)[band].size());
+    for (size_t channel = 0; channel < num_channels_; ++channel) {
+      RTC_DCHECK_EQ(kBlockSize, buffer_[band][channel].size());
+      RTC_DCHECK_EQ(kBlockSize, (*block)[band][channel].size());
+      (*block)[band][channel].clear();
+      (*block)[band][channel].insert((*block)[band][channel].begin(),
+                                     buffer_[band][channel].begin(),
+                                     buffer_[band][channel].end());
+      buffer_[band][channel].clear();
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/frame_blocker.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/frame_blocker.h
new file mode 100644
index 0000000..ebd6f77
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/frame_blocker.h
@@ -0,0 +1,50 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_FRAME_BLOCKER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_FRAME_BLOCKER_H_
+
+#include <stddef.h>
+
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+
+namespace webrtc {
+
+// Class for producing 64 sample multiband blocks from frames consisting of 2
+// subframes of 80 samples.
+class FrameBlocker {
+ public:
+  FrameBlocker(size_t num_bands, size_t num_channels);
+  ~FrameBlocker();
+  FrameBlocker(const FrameBlocker&) = delete;
+  FrameBlocker& operator=(const FrameBlocker&) = delete;
+
+  // Inserts one 80 sample multiband subframe from the multiband frame and
+  // extracts one 64 sample multiband block.
+  void InsertSubFrameAndExtractBlock(
+      const std::vector<std::vector<rtc::ArrayView<float>>>& sub_frame,
+      std::vector<std::vector<std::vector<float>>>* block);
+  // Reports whether a multiband block of 64 samples is available for
+  // extraction.
+  bool IsBlockAvailable() const;
+  // Extracts a multiband block of 64 samples.
+  void ExtractBlock(std::vector<std::vector<std::vector<float>>>* block);
+
+ private:
+  const size_t num_bands_;
+  const size_t num_channels_;
+  std::vector<std::vector<std::vector<float>>> buffer_;
+};
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_FRAME_BLOCKER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/frame_blocker_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/frame_blocker_unittest.cc
new file mode 100644
index 0000000..216f515
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/frame_blocker_unittest.cc
@@ -0,0 +1,472 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/frame_blocker.h"
+
+#include <string>
+#include <vector>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/block_framer.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace {
+
+float ComputeSampleValue(size_t chunk_counter,
+                         size_t chunk_size,
+                         size_t band,
+                         size_t channel,
+                         size_t sample_index,
+                         int offset) {
+  float value =
+      static_cast<int>(chunk_counter * chunk_size + sample_index + channel) +
+      offset;
+  return value > 0 ? 5000 * band + value : 0;
+}
+
+void FillSubFrame(size_t sub_frame_counter,
+                  int offset,
+                  std::vector<std::vector<std::vector<float>>>* sub_frame) {
+  for (size_t band = 0; band < sub_frame->size(); ++band) {
+    for (size_t channel = 0; channel < (*sub_frame)[band].size(); ++channel) {
+      for (size_t sample = 0; sample < (*sub_frame)[band][channel].size();
+           ++sample) {
+        (*sub_frame)[band][channel][sample] = ComputeSampleValue(
+            sub_frame_counter, kSubFrameLength, band, channel, sample, offset);
+      }
+    }
+  }
+}
+
+void FillSubFrameView(
+    size_t sub_frame_counter,
+    int offset,
+    std::vector<std::vector<std::vector<float>>>* sub_frame,
+    std::vector<std::vector<rtc::ArrayView<float>>>* sub_frame_view) {
+  FillSubFrame(sub_frame_counter, offset, sub_frame);
+  for (size_t band = 0; band < sub_frame_view->size(); ++band) {
+    for (size_t channel = 0; channel < (*sub_frame_view)[band].size();
+         ++channel) {
+      (*sub_frame_view)[band][channel] = rtc::ArrayView<float>(
+          &(*sub_frame)[band][channel][0], (*sub_frame)[band][channel].size());
+    }
+  }
+}
+
+bool VerifySubFrame(
+    size_t sub_frame_counter,
+    int offset,
+    const std::vector<std::vector<rtc::ArrayView<float>>>& sub_frame_view) {
+  std::vector<std::vector<std::vector<float>>> reference_sub_frame(
+      sub_frame_view.size(),
+      std::vector<std::vector<float>>(
+          sub_frame_view[0].size(),
+          std::vector<float>(sub_frame_view[0][0].size(), 0.f)));
+  FillSubFrame(sub_frame_counter, offset, &reference_sub_frame);
+  for (size_t band = 0; band < sub_frame_view.size(); ++band) {
+    for (size_t channel = 0; channel < sub_frame_view[band].size(); ++channel) {
+      for (size_t sample = 0; sample < sub_frame_view[band][channel].size();
+           ++sample) {
+        if (reference_sub_frame[band][channel][sample] !=
+            sub_frame_view[band][channel][sample]) {
+          return false;
+        }
+      }
+    }
+  }
+  return true;
+}
+
+bool VerifyBlock(size_t block_counter,
+                 int offset,
+                 const std::vector<std::vector<std::vector<float>>>& block) {
+  for (size_t band = 0; band < block.size(); ++band) {
+    for (size_t channel = 0; channel < block[band].size(); ++channel) {
+      for (size_t sample = 0; sample < block[band][channel].size(); ++sample) {
+        const float reference_value = ComputeSampleValue(
+            block_counter, kBlockSize, band, channel, sample, offset);
+        if (reference_value != block[band][channel][sample]) {
+          return false;
+        }
+      }
+    }
+  }
+  return true;
+}
+
+// Verifies that the FrameBlocker properly forms blocks out of the frames.
+void RunBlockerTest(int sample_rate_hz, size_t num_channels) {
+  constexpr size_t kNumSubFramesToProcess = 20;
+  const size_t num_bands = NumBandsForRate(sample_rate_hz);
+
+  std::vector<std::vector<std::vector<float>>> block(
+      num_bands, std::vector<std::vector<float>>(
+                     num_channels, std::vector<float>(kBlockSize, 0.f)));
+  std::vector<std::vector<std::vector<float>>> input_sub_frame(
+      num_bands, std::vector<std::vector<float>>(
+                     num_channels, std::vector<float>(kSubFrameLength, 0.f)));
+  std::vector<std::vector<rtc::ArrayView<float>>> input_sub_frame_view(
+      num_bands, std::vector<rtc::ArrayView<float>>(num_channels));
+  FrameBlocker blocker(num_bands, num_channels);
+
+  size_t block_counter = 0;
+  for (size_t sub_frame_index = 0; sub_frame_index < kNumSubFramesToProcess;
+       ++sub_frame_index) {
+    FillSubFrameView(sub_frame_index, 0, &input_sub_frame,
+                     &input_sub_frame_view);
+
+    blocker.InsertSubFrameAndExtractBlock(input_sub_frame_view, &block);
+    VerifyBlock(block_counter++, 0, block);
+
+    if ((sub_frame_index + 1) % 4 == 0) {
+      EXPECT_TRUE(blocker.IsBlockAvailable());
+    } else {
+      EXPECT_FALSE(blocker.IsBlockAvailable());
+    }
+    if (blocker.IsBlockAvailable()) {
+      blocker.ExtractBlock(&block);
+      VerifyBlock(block_counter++, 0, block);
+    }
+  }
+}
+
+// Verifies that the FrameBlocker and BlockFramer work well together and produce
+// the expected output.
+void RunBlockerAndFramerTest(int sample_rate_hz, size_t num_channels) {
+  const size_t kNumSubFramesToProcess = 20;
+  const size_t num_bands = NumBandsForRate(sample_rate_hz);
+
+  std::vector<std::vector<std::vector<float>>> block(
+      num_bands, std::vector<std::vector<float>>(
+                     num_channels, std::vector<float>(kBlockSize, 0.f)));
+  std::vector<std::vector<std::vector<float>>> input_sub_frame(
+      num_bands, std::vector<std::vector<float>>(
+                     num_channels, std::vector<float>(kSubFrameLength, 0.f)));
+  std::vector<std::vector<std::vector<float>>> output_sub_frame(
+      num_bands, std::vector<std::vector<float>>(
+                     num_channels, std::vector<float>(kSubFrameLength, 0.f)));
+  std::vector<std::vector<rtc::ArrayView<float>>> output_sub_frame_view(
+      num_bands, std::vector<rtc::ArrayView<float>>(num_channels));
+  std::vector<std::vector<rtc::ArrayView<float>>> input_sub_frame_view(
+      num_bands, std::vector<rtc::ArrayView<float>>(num_channels));
+  FrameBlocker blocker(num_bands, num_channels);
+  BlockFramer framer(num_bands, num_channels);
+
+  for (size_t sub_frame_index = 0; sub_frame_index < kNumSubFramesToProcess;
+       ++sub_frame_index) {
+    FillSubFrameView(sub_frame_index, 0, &input_sub_frame,
+                     &input_sub_frame_view);
+    FillSubFrameView(sub_frame_index, 0, &output_sub_frame,
+                     &output_sub_frame_view);
+
+    blocker.InsertSubFrameAndExtractBlock(input_sub_frame_view, &block);
+    framer.InsertBlockAndExtractSubFrame(block, &output_sub_frame_view);
+
+    if ((sub_frame_index + 1) % 4 == 0) {
+      EXPECT_TRUE(blocker.IsBlockAvailable());
+    } else {
+      EXPECT_FALSE(blocker.IsBlockAvailable());
+    }
+    if (blocker.IsBlockAvailable()) {
+      blocker.ExtractBlock(&block);
+      framer.InsertBlock(block);
+    }
+    if (sub_frame_index > 1) {
+      EXPECT_TRUE(VerifySubFrame(sub_frame_index, -64, output_sub_frame_view));
+    }
+  }
+}
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+// Verifies that the FrameBlocker crashes if the InsertSubFrameAndExtractBlock
+// method is called for inputs with the wrong number of bands or band lengths.
+void RunWronglySizedInsertAndExtractParametersTest(
+    int sample_rate_hz,
+    size_t correct_num_channels,
+    size_t num_block_bands,
+    size_t num_block_channels,
+    size_t block_length,
+    size_t num_sub_frame_bands,
+    size_t num_sub_frame_channels,
+    size_t sub_frame_length) {
+  const size_t correct_num_bands = NumBandsForRate(sample_rate_hz);
+
+  std::vector<std::vector<std::vector<float>>> block(
+      num_block_bands,
+      std::vector<std::vector<float>>(num_block_channels,
+                                      std::vector<float>(block_length, 0.f)));
+  std::vector<std::vector<std::vector<float>>> input_sub_frame(
+      num_sub_frame_bands,
+      std::vector<std::vector<float>>(
+          num_sub_frame_channels, std::vector<float>(sub_frame_length, 0.f)));
+  std::vector<std::vector<rtc::ArrayView<float>>> input_sub_frame_view(
+      input_sub_frame.size(),
+      std::vector<rtc::ArrayView<float>>(num_sub_frame_channels));
+  FillSubFrameView(0, 0, &input_sub_frame, &input_sub_frame_view);
+  FrameBlocker blocker(correct_num_bands, correct_num_channels);
+  EXPECT_DEATH(
+      blocker.InsertSubFrameAndExtractBlock(input_sub_frame_view, &block), "");
+}
+
+// Verifies that the FrameBlocker crashes if the ExtractBlock method is called
+// for inputs with the wrong number of bands or band lengths.
+void RunWronglySizedExtractParameterTest(int sample_rate_hz,
+                                         size_t correct_num_channels,
+                                         size_t num_block_bands,
+                                         size_t num_block_channels,
+                                         size_t block_length) {
+  const size_t correct_num_bands = NumBandsForRate(sample_rate_hz);
+
+  std::vector<std::vector<std::vector<float>>> correct_block(
+      correct_num_bands,
+      std::vector<std::vector<float>>(correct_num_channels,
+                                      std::vector<float>(kBlockSize, 0.f)));
+  std::vector<std::vector<std::vector<float>>> wrong_block(
+      num_block_bands,
+      std::vector<std::vector<float>>(num_block_channels,
+                                      std::vector<float>(block_length, 0.f)));
+  std::vector<std::vector<std::vector<float>>> input_sub_frame(
+      correct_num_bands,
+      std::vector<std::vector<float>>(
+          correct_num_channels, std::vector<float>(kSubFrameLength, 0.f)));
+  std::vector<std::vector<rtc::ArrayView<float>>> input_sub_frame_view(
+      input_sub_frame.size(),
+      std::vector<rtc::ArrayView<float>>(correct_num_channels));
+  FillSubFrameView(0, 0, &input_sub_frame, &input_sub_frame_view);
+  FrameBlocker blocker(correct_num_bands, correct_num_channels);
+  blocker.InsertSubFrameAndExtractBlock(input_sub_frame_view, &correct_block);
+  blocker.InsertSubFrameAndExtractBlock(input_sub_frame_view, &correct_block);
+  blocker.InsertSubFrameAndExtractBlock(input_sub_frame_view, &correct_block);
+  blocker.InsertSubFrameAndExtractBlock(input_sub_frame_view, &correct_block);
+
+  EXPECT_DEATH(blocker.ExtractBlock(&wrong_block), "");
+}
+
+// Verifies that the FrameBlocker crashes if the ExtractBlock method is called
+// after a wrong number of previous InsertSubFrameAndExtractBlock method calls
+// have been made.
+void RunWrongExtractOrderTest(int sample_rate_hz,
+                              size_t num_channels,
+                              size_t num_preceeding_api_calls) {
+  const size_t num_bands = NumBandsForRate(sample_rate_hz);
+
+  std::vector<std::vector<std::vector<float>>> block(
+      num_bands, std::vector<std::vector<float>>(
+                     num_channels, std::vector<float>(kBlockSize, 0.f)));
+  std::vector<std::vector<std::vector<float>>> input_sub_frame(
+      num_bands, std::vector<std::vector<float>>(
+                     num_channels, std::vector<float>(kSubFrameLength, 0.f)));
+  std::vector<std::vector<rtc::ArrayView<float>>> input_sub_frame_view(
+      input_sub_frame.size(), std::vector<rtc::ArrayView<float>>(num_channels));
+  FillSubFrameView(0, 0, &input_sub_frame, &input_sub_frame_view);
+  FrameBlocker blocker(num_bands, num_channels);
+  for (size_t k = 0; k < num_preceeding_api_calls; ++k) {
+    blocker.InsertSubFrameAndExtractBlock(input_sub_frame_view, &block);
+  }
+
+  EXPECT_DEATH(blocker.ExtractBlock(&block), "");
+}
+#endif
+
+std::string ProduceDebugText(int sample_rate_hz, size_t num_channels) {
+  rtc::StringBuilder ss;
+  ss << "Sample rate: " << sample_rate_hz;
+  ss << ", number of channels: " << num_channels;
+  return ss.Release();
+}
+
+}  // namespace
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+TEST(FrameBlockerDeathTest,
+     WrongNumberOfBandsInBlockForInsertSubFrameAndExtractBlock) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (size_t correct_num_channels : {1, 2, 4, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+      const size_t correct_num_bands = NumBandsForRate(rate);
+      const size_t wrong_num_bands = (correct_num_bands % 3) + 1;
+      RunWronglySizedInsertAndExtractParametersTest(
+          rate, correct_num_channels, wrong_num_bands, correct_num_channels,
+          kBlockSize, correct_num_bands, correct_num_channels, kSubFrameLength);
+    }
+  }
+}
+
+TEST(FrameBlockerDeathTest,
+     WrongNumberOfChannelsInBlockForInsertSubFrameAndExtractBlock) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (size_t correct_num_channels : {1, 2, 4, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+      const size_t correct_num_bands = NumBandsForRate(rate);
+      const size_t wrong_num_channels = correct_num_channels + 1;
+      RunWronglySizedInsertAndExtractParametersTest(
+          rate, correct_num_channels, correct_num_bands, wrong_num_channels,
+          kBlockSize, correct_num_bands, correct_num_channels, kSubFrameLength);
+    }
+  }
+}
+
+TEST(FrameBlockerDeathTest,
+     WrongNumberOfBandsInSubFrameForInsertSubFrameAndExtractBlock) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (size_t correct_num_channels : {1, 2, 4, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+      const size_t correct_num_bands = NumBandsForRate(rate);
+      const size_t wrong_num_bands = (correct_num_bands % 3) + 1;
+      RunWronglySizedInsertAndExtractParametersTest(
+          rate, correct_num_channels, correct_num_bands, correct_num_channels,
+          kBlockSize, wrong_num_bands, correct_num_channels, kSubFrameLength);
+    }
+  }
+}
+
+TEST(FrameBlockerDeathTest,
+     WrongNumberOfChannelsInSubFrameForInsertSubFrameAndExtractBlock) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (size_t correct_num_channels : {1, 2, 4, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+      const size_t correct_num_bands = NumBandsForRate(rate);
+      const size_t wrong_num_channels = correct_num_channels + 1;
+      RunWronglySizedInsertAndExtractParametersTest(
+          rate, correct_num_channels, correct_num_bands, wrong_num_channels,
+          kBlockSize, correct_num_bands, wrong_num_channels, kSubFrameLength);
+    }
+  }
+}
+
+TEST(FrameBlockerDeathTest,
+     WrongNumberOfSamplesInBlockForInsertSubFrameAndExtractBlock) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (size_t correct_num_channels : {1, 2, 4, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+      const size_t correct_num_bands = NumBandsForRate(rate);
+      RunWronglySizedInsertAndExtractParametersTest(
+          rate, correct_num_channels, correct_num_bands, correct_num_channels,
+          kBlockSize - 1, correct_num_bands, correct_num_channels,
+          kSubFrameLength);
+    }
+  }
+}
+
+TEST(FrameBlockerDeathTest,
+     WrongNumberOfSamplesInSubFrameForInsertSubFrameAndExtractBlock) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (size_t correct_num_channels : {1, 2, 4, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+      const size_t correct_num_bands = NumBandsForRate(rate);
+      RunWronglySizedInsertAndExtractParametersTest(
+          rate, correct_num_channels, correct_num_bands, correct_num_channels,
+          kBlockSize, correct_num_bands, correct_num_channels,
+          kSubFrameLength - 1);
+    }
+  }
+}
+
+TEST(FrameBlockerDeathTest, WrongNumberOfBandsInBlockForExtractBlock) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (size_t correct_num_channels : {1, 2, 4, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+      const size_t correct_num_bands = NumBandsForRate(rate);
+      const size_t wrong_num_bands = (correct_num_bands % 3) + 1;
+      RunWronglySizedExtractParameterTest(rate, correct_num_channels,
+                                          wrong_num_bands, correct_num_channels,
+                                          kBlockSize);
+    }
+  }
+}
+
+TEST(FrameBlockerDeathTest, WrongNumberOfChannelsInBlockForExtractBlock) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (size_t correct_num_channels : {1, 2, 4, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+      const size_t correct_num_bands = NumBandsForRate(rate);
+      const size_t wrong_num_channels = correct_num_channels + 1;
+      RunWronglySizedExtractParameterTest(rate, correct_num_channels,
+                                          correct_num_bands, wrong_num_channels,
+                                          kBlockSize);
+    }
+  }
+}
+
+TEST(FrameBlockerDeathTest, WrongNumberOfSamplesInBlockForExtractBlock) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (size_t correct_num_channels : {1, 2, 4, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, correct_num_channels));
+      const size_t correct_num_bands = NumBandsForRate(rate);
+      RunWronglySizedExtractParameterTest(rate, correct_num_channels,
+                                          correct_num_bands,
+                                          correct_num_channels, kBlockSize - 1);
+    }
+  }
+}
+
+TEST(FrameBlockerDeathTest, WrongNumberOfPreceedingApiCallsForExtractBlock) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (size_t num_channels : {1, 2, 4, 8}) {
+      for (size_t num_calls = 0; num_calls < 4; ++num_calls) {
+        rtc::StringBuilder ss;
+        ss << "Sample rate: " << rate;
+        ss << "Num channels: " << num_channels;
+        ss << ", Num preceeding InsertSubFrameAndExtractBlock calls: "
+           << num_calls;
+
+        SCOPED_TRACE(ss.str());
+        RunWrongExtractOrderTest(rate, num_channels, num_calls);
+      }
+    }
+  }
+}
+
+// Verifies that the verification for 0 number of channels works.
+TEST(FrameBlockerDeathTest, ZeroNumberOfChannelsParameter) {
+  EXPECT_DEATH(FrameBlocker(16000, 0), "");
+}
+
+// Verifies that the verification for 0 number of bands works.
+TEST(FrameBlockerDeathTest, ZeroNumberOfBandsParameter) {
+  EXPECT_DEATH(FrameBlocker(0, 1), "");
+}
+
+// Verifiers that the verification for null sub_frame pointer works.
+TEST(FrameBlockerDeathTest, NullBlockParameter) {
+  std::vector<std::vector<std::vector<float>>> sub_frame(
+      1, std::vector<std::vector<float>>(
+             1, std::vector<float>(kSubFrameLength, 0.f)));
+  std::vector<std::vector<rtc::ArrayView<float>>> sub_frame_view(
+      sub_frame.size());
+  FillSubFrameView(0, 0, &sub_frame, &sub_frame_view);
+  EXPECT_DEATH(
+      FrameBlocker(1, 1).InsertSubFrameAndExtractBlock(sub_frame_view, nullptr),
+      "");
+}
+
+#endif
+
+TEST(FrameBlocker, BlockBitexactness) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (size_t num_channels : {1, 2, 4, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, num_channels));
+      RunBlockerTest(rate, num_channels);
+    }
+  }
+}
+
+TEST(FrameBlocker, BlockerAndFramer) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (size_t num_channels : {1, 2, 4, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate, num_channels));
+      RunBlockerAndFramerTest(rate, num_channels);
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fullband_erle_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fullband_erle_estimator.cc
new file mode 100644
index 0000000..e56674e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fullband_erle_estimator.cc
@@ -0,0 +1,191 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/fullband_erle_estimator.h"
+
+#include <algorithm>
+#include <memory>
+#include <numeric>
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_minmax.h"
+
+namespace webrtc {
+
+namespace {
+constexpr float kEpsilon = 1e-3f;
+constexpr float kX2BandEnergyThreshold = 44015068.0f;
+constexpr int kBlocksToHoldErle = 100;
+constexpr int kPointsToAccumulate = 6;
+}  // namespace
+
+FullBandErleEstimator::FullBandErleEstimator(
+    const EchoCanceller3Config::Erle& config,
+    size_t num_capture_channels)
+    : min_erle_log2_(FastApproxLog2f(config.min + kEpsilon)),
+      max_erle_lf_log2_(FastApproxLog2f(config.max_l + kEpsilon)),
+      hold_counters_instantaneous_erle_(num_capture_channels, 0),
+      erle_time_domain_log2_(num_capture_channels, min_erle_log2_),
+      instantaneous_erle_(num_capture_channels, ErleInstantaneous(config)),
+      linear_filters_qualities_(num_capture_channels) {
+  Reset();
+}
+
+FullBandErleEstimator::~FullBandErleEstimator() = default;
+
+void FullBandErleEstimator::Reset() {
+  for (auto& instantaneous_erle_ch : instantaneous_erle_) {
+    instantaneous_erle_ch.Reset();
+  }
+
+  UpdateQualityEstimates();
+  std::fill(erle_time_domain_log2_.begin(), erle_time_domain_log2_.end(),
+            min_erle_log2_);
+  std::fill(hold_counters_instantaneous_erle_.begin(),
+            hold_counters_instantaneous_erle_.end(), 0);
+}
+
+void FullBandErleEstimator::Update(
+    rtc::ArrayView<const float> X2,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Y2,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> E2,
+    const std::vector<bool>& converged_filters) {
+  for (size_t ch = 0; ch < Y2.size(); ++ch) {
+    if (converged_filters[ch]) {
+      // Computes the fullband ERLE.
+      const float X2_sum = std::accumulate(X2.begin(), X2.end(), 0.0f);
+      if (X2_sum > kX2BandEnergyThreshold * X2.size()) {
+        const float Y2_sum =
+            std::accumulate(Y2[ch].begin(), Y2[ch].end(), 0.0f);
+        const float E2_sum =
+            std::accumulate(E2[ch].begin(), E2[ch].end(), 0.0f);
+        if (instantaneous_erle_[ch].Update(Y2_sum, E2_sum)) {
+          hold_counters_instantaneous_erle_[ch] = kBlocksToHoldErle;
+          erle_time_domain_log2_[ch] +=
+              0.05f * ((instantaneous_erle_[ch].GetInstErleLog2().value()) -
+                       erle_time_domain_log2_[ch]);
+          erle_time_domain_log2_[ch] =
+              std::max(erle_time_domain_log2_[ch], min_erle_log2_);
+        }
+      }
+    }
+    --hold_counters_instantaneous_erle_[ch];
+    if (hold_counters_instantaneous_erle_[ch] == 0) {
+      instantaneous_erle_[ch].ResetAccumulators();
+    }
+  }
+
+  UpdateQualityEstimates();
+}
+
+void FullBandErleEstimator::Dump(
+    const std::unique_ptr<ApmDataDumper>& data_dumper) const {
+  data_dumper->DumpRaw("aec3_fullband_erle_log2", FullbandErleLog2());
+  instantaneous_erle_[0].Dump(data_dumper);
+}
+
+void FullBandErleEstimator::UpdateQualityEstimates() {
+  for (size_t ch = 0; ch < instantaneous_erle_.size(); ++ch) {
+    linear_filters_qualities_[ch] =
+        instantaneous_erle_[ch].GetQualityEstimate();
+  }
+}
+
+FullBandErleEstimator::ErleInstantaneous::ErleInstantaneous(
+    const EchoCanceller3Config::Erle& config)
+    : clamp_inst_quality_to_zero_(config.clamp_quality_estimate_to_zero),
+      clamp_inst_quality_to_one_(config.clamp_quality_estimate_to_one) {
+  Reset();
+}
+
+FullBandErleEstimator::ErleInstantaneous::~ErleInstantaneous() = default;
+
+bool FullBandErleEstimator::ErleInstantaneous::Update(const float Y2_sum,
+                                                      const float E2_sum) {
+  bool update_estimates = false;
+  E2_acum_ += E2_sum;
+  Y2_acum_ += Y2_sum;
+  num_points_++;
+  if (num_points_ == kPointsToAccumulate) {
+    if (E2_acum_ > 0.f) {
+      update_estimates = true;
+      erle_log2_ = FastApproxLog2f(Y2_acum_ / E2_acum_ + kEpsilon);
+    }
+    num_points_ = 0;
+    E2_acum_ = 0.f;
+    Y2_acum_ = 0.f;
+  }
+
+  if (update_estimates) {
+    UpdateMaxMin();
+    UpdateQualityEstimate();
+  }
+  return update_estimates;
+}
+
+void FullBandErleEstimator::ErleInstantaneous::Reset() {
+  ResetAccumulators();
+  max_erle_log2_ = -10.f;  // -30 dB.
+  min_erle_log2_ = 33.f;   // 100 dB.
+  inst_quality_estimate_ = 0.f;
+}
+
+void FullBandErleEstimator::ErleInstantaneous::ResetAccumulators() {
+  erle_log2_ = absl::nullopt;
+  inst_quality_estimate_ = 0.f;
+  num_points_ = 0;
+  E2_acum_ = 0.f;
+  Y2_acum_ = 0.f;
+}
+
+void FullBandErleEstimator::ErleInstantaneous::Dump(
+    const std::unique_ptr<ApmDataDumper>& data_dumper) const {
+  data_dumper->DumpRaw("aec3_fullband_erle_inst_log2",
+                       erle_log2_ ? *erle_log2_ : -10.f);
+  data_dumper->DumpRaw(
+      "aec3_erle_instantaneous_quality",
+      GetQualityEstimate() ? GetQualityEstimate().value() : 0.f);
+  data_dumper->DumpRaw("aec3_fullband_erle_max_log2", max_erle_log2_);
+  data_dumper->DumpRaw("aec3_fullband_erle_min_log2", min_erle_log2_);
+}
+
+void FullBandErleEstimator::ErleInstantaneous::UpdateMaxMin() {
+  RTC_DCHECK(erle_log2_);
+  // Adding the forgetting factors for the maximum and minimum and capping the
+  // result to the incoming value.
+  max_erle_log2_ -= 0.0004f;  // Forget factor, approx 1dB every 3 sec.
+  max_erle_log2_ = std::max(max_erle_log2_, erle_log2_.value());
+  min_erle_log2_ += 0.0004f;  // Forget factor, approx 1dB every 3 sec.
+  min_erle_log2_ = std::min(min_erle_log2_, erle_log2_.value());
+}
+
+void FullBandErleEstimator::ErleInstantaneous::UpdateQualityEstimate() {
+  const float alpha = 0.07f;
+  float quality_estimate = 0.f;
+  RTC_DCHECK(erle_log2_);
+  // TODO(peah): Currently, the estimate can become be less than 0; this should
+  // be corrected.
+  if (max_erle_log2_ > min_erle_log2_) {
+    quality_estimate = (erle_log2_.value() - min_erle_log2_) /
+                       (max_erle_log2_ - min_erle_log2_);
+  }
+  if (quality_estimate > inst_quality_estimate_) {
+    inst_quality_estimate_ = quality_estimate;
+  } else {
+    inst_quality_estimate_ +=
+        alpha * (quality_estimate - inst_quality_estimate_);
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fullband_erle_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fullband_erle_estimator.h
new file mode 100644
index 0000000..2b720a4
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/fullband_erle_estimator.h
@@ -0,0 +1,118 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_FULLBAND_ERLE_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_FULLBAND_ERLE_ESTIMATOR_H_
+
+#include <memory>
+#include <vector>
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+
+namespace webrtc {
+
+// Estimates the echo return loss enhancement using the energy of all the
+// freuquency bands.
+class FullBandErleEstimator {
+ public:
+  FullBandErleEstimator(const EchoCanceller3Config::Erle& config,
+                        size_t num_capture_channels);
+  ~FullBandErleEstimator();
+  // Resets the ERLE estimator.
+  void Reset();
+
+  // Updates the ERLE estimator.
+  void Update(rtc::ArrayView<const float> X2,
+              rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Y2,
+              rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> E2,
+              const std::vector<bool>& converged_filters);
+
+  // Returns the fullband ERLE estimates in log2 units.
+  float FullbandErleLog2() const {
+    float min_erle = erle_time_domain_log2_[0];
+    for (size_t ch = 1; ch < erle_time_domain_log2_.size(); ++ch) {
+      min_erle = std::min(min_erle, erle_time_domain_log2_[ch]);
+    }
+    return min_erle;
+  }
+
+  // Returns an estimation of the current linear filter quality. It returns a
+  // float number between 0 and 1 mapping 1 to the highest possible quality.
+  rtc::ArrayView<const absl::optional<float>> GetInstLinearQualityEstimates()
+      const {
+    return linear_filters_qualities_;
+  }
+
+  void Dump(const std::unique_ptr<ApmDataDumper>& data_dumper) const;
+
+ private:
+  void UpdateQualityEstimates();
+
+  class ErleInstantaneous {
+   public:
+    explicit ErleInstantaneous(const EchoCanceller3Config::Erle& config);
+    ~ErleInstantaneous();
+
+    // Updates the estimator with a new point, returns true
+    // if the instantaneous ERLE was updated due to having enough
+    // points for performing the estimate.
+    bool Update(const float Y2_sum, const float E2_sum);
+    // Resets the instantaneous ERLE estimator to its initial state.
+    void Reset();
+    // Resets the members related with an instantaneous estimate.
+    void ResetAccumulators();
+    // Returns the instantaneous ERLE in log2 units.
+    absl::optional<float> GetInstErleLog2() const { return erle_log2_; }
+    // Gets an indication between 0 and 1 of the performance of the linear
+    // filter for the current time instant.
+    absl::optional<float> GetQualityEstimate() const {
+      if (erle_log2_) {
+        float value = inst_quality_estimate_;
+        if (clamp_inst_quality_to_zero_) {
+          value = std::max(0.f, value);
+        }
+        if (clamp_inst_quality_to_one_) {
+          value = std::min(1.f, value);
+        }
+        return absl::optional<float>(value);
+      }
+      return absl::nullopt;
+    }
+    void Dump(const std::unique_ptr<ApmDataDumper>& data_dumper) const;
+
+   private:
+    void UpdateMaxMin();
+    void UpdateQualityEstimate();
+    const bool clamp_inst_quality_to_zero_;
+    const bool clamp_inst_quality_to_one_;
+    absl::optional<float> erle_log2_;
+    float inst_quality_estimate_;
+    float max_erle_log2_;
+    float min_erle_log2_;
+    float Y2_acum_;
+    float E2_acum_;
+    int num_points_;
+  };
+
+  const float min_erle_log2_;
+  const float max_erle_lf_log2_;
+  std::vector<int> hold_counters_instantaneous_erle_;
+  std::vector<float> erle_time_domain_log2_;
+  std::vector<ErleInstantaneous> instantaneous_erle_;
+  std::vector<absl::optional<float>> linear_filters_qualities_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_FULLBAND_ERLE_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter.cc
new file mode 100644
index 0000000..64b2d4e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter.cc
@@ -0,0 +1,464 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "modules/audio_processing/aec3/matched_filter.h"
+
+// Defines WEBRTC_ARCH_X86_FAMILY, used below.
+#include "rtc_base/system/arch.h"
+
+#if defined(WEBRTC_HAS_NEON)
+#include <arm_neon.h>
+#endif
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+#include <emmintrin.h>
+#endif
+#include <algorithm>
+#include <cstddef>
+#include <initializer_list>
+#include <iterator>
+#include <numeric>
+
+#include "modules/audio_processing/aec3/downsampled_render_buffer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+
+namespace webrtc {
+namespace aec3 {
+
+#if defined(WEBRTC_HAS_NEON)
+
+void MatchedFilterCore_NEON(size_t x_start_index,
+                            float x2_sum_threshold,
+                            float smoothing,
+                            rtc::ArrayView<const float> x,
+                            rtc::ArrayView<const float> y,
+                            rtc::ArrayView<float> h,
+                            bool* filters_updated,
+                            float* error_sum) {
+  const int h_size = static_cast<int>(h.size());
+  const int x_size = static_cast<int>(x.size());
+  RTC_DCHECK_EQ(0, h_size % 4);
+
+  // Process for all samples in the sub-block.
+  for (size_t i = 0; i < y.size(); ++i) {
+    // Apply the matched filter as filter * x, and compute x * x.
+
+    RTC_DCHECK_GT(x_size, x_start_index);
+    const float* x_p = &x[x_start_index];
+    const float* h_p = &h[0];
+
+    // Initialize values for the accumulation.
+    float32x4_t s_128 = vdupq_n_f32(0);
+    float32x4_t x2_sum_128 = vdupq_n_f32(0);
+    float x2_sum = 0.f;
+    float s = 0;
+
+    // Compute loop chunk sizes until, and after, the wraparound of the circular
+    // buffer for x.
+    const int chunk1 =
+        std::min(h_size, static_cast<int>(x_size - x_start_index));
+
+    // Perform the loop in two chunks.
+    const int chunk2 = h_size - chunk1;
+    for (int limit : {chunk1, chunk2}) {
+      // Perform 128 bit vector operations.
+      const int limit_by_4 = limit >> 2;
+      for (int k = limit_by_4; k > 0; --k, h_p += 4, x_p += 4) {
+        // Load the data into 128 bit vectors.
+        const float32x4_t x_k = vld1q_f32(x_p);
+        const float32x4_t h_k = vld1q_f32(h_p);
+        // Compute and accumulate x * x and h * x.
+        x2_sum_128 = vmlaq_f32(x2_sum_128, x_k, x_k);
+        s_128 = vmlaq_f32(s_128, h_k, x_k);
+      }
+
+      // Perform non-vector operations for any remaining items.
+      for (int k = limit - limit_by_4 * 4; k > 0; --k, ++h_p, ++x_p) {
+        const float x_k = *x_p;
+        x2_sum += x_k * x_k;
+        s += *h_p * x_k;
+      }
+
+      x_p = &x[0];
+    }
+
+    // Combine the accumulated vector and scalar values.
+    float* v = reinterpret_cast<float*>(&x2_sum_128);
+    x2_sum += v[0] + v[1] + v[2] + v[3];
+    v = reinterpret_cast<float*>(&s_128);
+    s += v[0] + v[1] + v[2] + v[3];
+
+    // Compute the matched filter error.
+    float e = y[i] - s;
+    const bool saturation = y[i] >= 32000.f || y[i] <= -32000.f;
+    (*error_sum) += e * e;
+
+    // Update the matched filter estimate in an NLMS manner.
+    if (x2_sum > x2_sum_threshold && !saturation) {
+      RTC_DCHECK_LT(0.f, x2_sum);
+      const float alpha = smoothing * e / x2_sum;
+      const float32x4_t alpha_128 = vmovq_n_f32(alpha);
+
+      // filter = filter + smoothing * (y - filter * x) * x / x * x.
+      float* h_p = &h[0];
+      x_p = &x[x_start_index];
+
+      // Perform the loop in two chunks.
+      for (int limit : {chunk1, chunk2}) {
+        // Perform 128 bit vector operations.
+        const int limit_by_4 = limit >> 2;
+        for (int k = limit_by_4; k > 0; --k, h_p += 4, x_p += 4) {
+          // Load the data into 128 bit vectors.
+          float32x4_t h_k = vld1q_f32(h_p);
+          const float32x4_t x_k = vld1q_f32(x_p);
+          // Compute h = h + alpha * x.
+          h_k = vmlaq_f32(h_k, alpha_128, x_k);
+
+          // Store the result.
+          vst1q_f32(h_p, h_k);
+        }
+
+        // Perform non-vector operations for any remaining items.
+        for (int k = limit - limit_by_4 * 4; k > 0; --k, ++h_p, ++x_p) {
+          *h_p += alpha * *x_p;
+        }
+
+        x_p = &x[0];
+      }
+
+      *filters_updated = true;
+    }
+
+    x_start_index = x_start_index > 0 ? x_start_index - 1 : x_size - 1;
+  }
+}
+
+#endif
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+
+void MatchedFilterCore_SSE2(size_t x_start_index,
+                            float x2_sum_threshold,
+                            float smoothing,
+                            rtc::ArrayView<const float> x,
+                            rtc::ArrayView<const float> y,
+                            rtc::ArrayView<float> h,
+                            bool* filters_updated,
+                            float* error_sum) {
+  const int h_size = static_cast<int>(h.size());
+  const int x_size = static_cast<int>(x.size());
+  RTC_DCHECK_EQ(0, h_size % 4);
+
+  // Process for all samples in the sub-block.
+  for (size_t i = 0; i < y.size(); ++i) {
+    // Apply the matched filter as filter * x, and compute x * x.
+
+    RTC_DCHECK_GT(x_size, x_start_index);
+    const float* x_p = &x[x_start_index];
+    const float* h_p = &h[0];
+
+    // Initialize values for the accumulation.
+    __m128 s_128 = _mm_set1_ps(0);
+    __m128 x2_sum_128 = _mm_set1_ps(0);
+    float x2_sum = 0.f;
+    float s = 0;
+
+    // Compute loop chunk sizes until, and after, the wraparound of the circular
+    // buffer for x.
+    const int chunk1 =
+        std::min(h_size, static_cast<int>(x_size - x_start_index));
+
+    // Perform the loop in two chunks.
+    const int chunk2 = h_size - chunk1;
+    for (int limit : {chunk1, chunk2}) {
+      // Perform 128 bit vector operations.
+      const int limit_by_4 = limit >> 2;
+      for (int k = limit_by_4; k > 0; --k, h_p += 4, x_p += 4) {
+        // Load the data into 128 bit vectors.
+        const __m128 x_k = _mm_loadu_ps(x_p);
+        const __m128 h_k = _mm_loadu_ps(h_p);
+        const __m128 xx = _mm_mul_ps(x_k, x_k);
+        // Compute and accumulate x * x and h * x.
+        x2_sum_128 = _mm_add_ps(x2_sum_128, xx);
+        const __m128 hx = _mm_mul_ps(h_k, x_k);
+        s_128 = _mm_add_ps(s_128, hx);
+      }
+
+      // Perform non-vector operations for any remaining items.
+      for (int k = limit - limit_by_4 * 4; k > 0; --k, ++h_p, ++x_p) {
+        const float x_k = *x_p;
+        x2_sum += x_k * x_k;
+        s += *h_p * x_k;
+      }
+
+      x_p = &x[0];
+    }
+
+    // Combine the accumulated vector and scalar values.
+    float* v = reinterpret_cast<float*>(&x2_sum_128);
+    x2_sum += v[0] + v[1] + v[2] + v[3];
+    v = reinterpret_cast<float*>(&s_128);
+    s += v[0] + v[1] + v[2] + v[3];
+
+    // Compute the matched filter error.
+    float e = y[i] - s;
+    const bool saturation = y[i] >= 32000.f || y[i] <= -32000.f;
+    (*error_sum) += e * e;
+
+    // Update the matched filter estimate in an NLMS manner.
+    if (x2_sum > x2_sum_threshold && !saturation) {
+      RTC_DCHECK_LT(0.f, x2_sum);
+      const float alpha = smoothing * e / x2_sum;
+      const __m128 alpha_128 = _mm_set1_ps(alpha);
+
+      // filter = filter + smoothing * (y - filter * x) * x / x * x.
+      float* h_p = &h[0];
+      x_p = &x[x_start_index];
+
+      // Perform the loop in two chunks.
+      for (int limit : {chunk1, chunk2}) {
+        // Perform 128 bit vector operations.
+        const int limit_by_4 = limit >> 2;
+        for (int k = limit_by_4; k > 0; --k, h_p += 4, x_p += 4) {
+          // Load the data into 128 bit vectors.
+          __m128 h_k = _mm_loadu_ps(h_p);
+          const __m128 x_k = _mm_loadu_ps(x_p);
+
+          // Compute h = h + alpha * x.
+          const __m128 alpha_x = _mm_mul_ps(alpha_128, x_k);
+          h_k = _mm_add_ps(h_k, alpha_x);
+
+          // Store the result.
+          _mm_storeu_ps(h_p, h_k);
+        }
+
+        // Perform non-vector operations for any remaining items.
+        for (int k = limit - limit_by_4 * 4; k > 0; --k, ++h_p, ++x_p) {
+          *h_p += alpha * *x_p;
+        }
+
+        x_p = &x[0];
+      }
+
+      *filters_updated = true;
+    }
+
+    x_start_index = x_start_index > 0 ? x_start_index - 1 : x_size - 1;
+  }
+}
+#endif
+
+void MatchedFilterCore(size_t x_start_index,
+                       float x2_sum_threshold,
+                       float smoothing,
+                       rtc::ArrayView<const float> x,
+                       rtc::ArrayView<const float> y,
+                       rtc::ArrayView<float> h,
+                       bool* filters_updated,
+                       float* error_sum) {
+  // Process for all samples in the sub-block.
+  for (size_t i = 0; i < y.size(); ++i) {
+    // Apply the matched filter as filter * x, and compute x * x.
+    float x2_sum = 0.f;
+    float s = 0;
+    size_t x_index = x_start_index;
+    for (size_t k = 0; k < h.size(); ++k) {
+      x2_sum += x[x_index] * x[x_index];
+      s += h[k] * x[x_index];
+      x_index = x_index < (x.size() - 1) ? x_index + 1 : 0;
+    }
+
+    // Compute the matched filter error.
+    float e = y[i] - s;
+    const bool saturation = y[i] >= 32000.f || y[i] <= -32000.f;
+    (*error_sum) += e * e;
+
+    // Update the matched filter estimate in an NLMS manner.
+    if (x2_sum > x2_sum_threshold && !saturation) {
+      RTC_DCHECK_LT(0.f, x2_sum);
+      const float alpha = smoothing * e / x2_sum;
+
+      // filter = filter + smoothing * (y - filter * x) * x / x * x.
+      size_t x_index = x_start_index;
+      for (size_t k = 0; k < h.size(); ++k) {
+        h[k] += alpha * x[x_index];
+        x_index = x_index < (x.size() - 1) ? x_index + 1 : 0;
+      }
+      *filters_updated = true;
+    }
+
+    x_start_index = x_start_index > 0 ? x_start_index - 1 : x.size() - 1;
+  }
+}
+
+}  // namespace aec3
+
+MatchedFilter::MatchedFilter(ApmDataDumper* data_dumper,
+                             Aec3Optimization optimization,
+                             size_t sub_block_size,
+                             size_t window_size_sub_blocks,
+                             int num_matched_filters,
+                             size_t alignment_shift_sub_blocks,
+                             float excitation_limit,
+                             float smoothing,
+                             float matching_filter_threshold)
+    : data_dumper_(data_dumper),
+      optimization_(optimization),
+      sub_block_size_(sub_block_size),
+      filter_intra_lag_shift_(alignment_shift_sub_blocks * sub_block_size_),
+      filters_(
+          num_matched_filters,
+          std::vector<float>(window_size_sub_blocks * sub_block_size_, 0.f)),
+      lag_estimates_(num_matched_filters),
+      filters_offsets_(num_matched_filters, 0),
+      excitation_limit_(excitation_limit),
+      smoothing_(smoothing),
+      matching_filter_threshold_(matching_filter_threshold) {
+  RTC_DCHECK(data_dumper);
+  RTC_DCHECK_LT(0, window_size_sub_blocks);
+  RTC_DCHECK((kBlockSize % sub_block_size) == 0);
+  RTC_DCHECK((sub_block_size % 4) == 0);
+}
+
+MatchedFilter::~MatchedFilter() = default;
+
+void MatchedFilter::Reset() {
+  for (auto& f : filters_) {
+    std::fill(f.begin(), f.end(), 0.f);
+  }
+
+  for (auto& l : lag_estimates_) {
+    l = MatchedFilter::LagEstimate();
+  }
+}
+
+void MatchedFilter::Update(const DownsampledRenderBuffer& render_buffer,
+                           rtc::ArrayView<const float> capture) {
+  RTC_DCHECK_EQ(sub_block_size_, capture.size());
+  auto& y = capture;
+
+  const float x2_sum_threshold =
+      filters_[0].size() * excitation_limit_ * excitation_limit_;
+
+  // Apply all matched filters.
+  size_t alignment_shift = 0;
+  for (size_t n = 0; n < filters_.size(); ++n) {
+    float error_sum = 0.f;
+    bool filters_updated = false;
+
+    size_t x_start_index =
+        (render_buffer.read + alignment_shift + sub_block_size_ - 1) %
+        render_buffer.buffer.size();
+
+    switch (optimization_) {
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+      case Aec3Optimization::kSse2:
+        aec3::MatchedFilterCore_SSE2(x_start_index, x2_sum_threshold,
+                                     smoothing_, render_buffer.buffer, y,
+                                     filters_[n], &filters_updated, &error_sum);
+        break;
+      case Aec3Optimization::kAvx2:
+        aec3::MatchedFilterCore_AVX2(x_start_index, x2_sum_threshold,
+                                     smoothing_, render_buffer.buffer, y,
+                                     filters_[n], &filters_updated, &error_sum);
+        break;
+#endif
+#if defined(WEBRTC_HAS_NEON)
+      case Aec3Optimization::kNeon:
+        aec3::MatchedFilterCore_NEON(x_start_index, x2_sum_threshold,
+                                     smoothing_, render_buffer.buffer, y,
+                                     filters_[n], &filters_updated, &error_sum);
+        break;
+#endif
+      default:
+        aec3::MatchedFilterCore(x_start_index, x2_sum_threshold, smoothing_,
+                                render_buffer.buffer, y, filters_[n],
+                                &filters_updated, &error_sum);
+    }
+
+    // Compute anchor for the matched filter error.
+    const float error_sum_anchor =
+        std::inner_product(y.begin(), y.end(), y.begin(), 0.f);
+
+    // Estimate the lag in the matched filter as the distance to the portion in
+    // the filter that contributes the most to the matched filter output. This
+    // is detected as the peak of the matched filter.
+    const size_t lag_estimate = std::distance(
+        filters_[n].begin(),
+        std::max_element(
+            filters_[n].begin(), filters_[n].end(),
+            [](float a, float b) -> bool { return a * a < b * b; }));
+
+    // Update the lag estimates for the matched filter.
+    lag_estimates_[n] = LagEstimate(
+        error_sum_anchor - error_sum,
+        (lag_estimate > 2 && lag_estimate < (filters_[n].size() - 10) &&
+         error_sum < matching_filter_threshold_ * error_sum_anchor),
+        lag_estimate + alignment_shift, filters_updated);
+
+    RTC_DCHECK_GE(10, filters_.size());
+    switch (n) {
+      case 0:
+        data_dumper_->DumpRaw("aec3_correlator_0_h", filters_[0]);
+        break;
+      case 1:
+        data_dumper_->DumpRaw("aec3_correlator_1_h", filters_[1]);
+        break;
+      case 2:
+        data_dumper_->DumpRaw("aec3_correlator_2_h", filters_[2]);
+        break;
+      case 3:
+        data_dumper_->DumpRaw("aec3_correlator_3_h", filters_[3]);
+        break;
+      case 4:
+        data_dumper_->DumpRaw("aec3_correlator_4_h", filters_[4]);
+        break;
+      case 5:
+        data_dumper_->DumpRaw("aec3_correlator_5_h", filters_[5]);
+        break;
+      case 6:
+        data_dumper_->DumpRaw("aec3_correlator_6_h", filters_[6]);
+        break;
+      case 7:
+        data_dumper_->DumpRaw("aec3_correlator_7_h", filters_[7]);
+        break;
+      case 8:
+        data_dumper_->DumpRaw("aec3_correlator_8_h", filters_[8]);
+        break;
+      case 9:
+        data_dumper_->DumpRaw("aec3_correlator_9_h", filters_[9]);
+        break;
+      default:
+        RTC_NOTREACHED();
+    }
+
+    alignment_shift += filter_intra_lag_shift_;
+  }
+}
+
+void MatchedFilter::LogFilterProperties(int sample_rate_hz,
+                                        size_t shift,
+                                        size_t downsampling_factor) const {
+  size_t alignment_shift = 0;
+  constexpr int kFsBy1000 = 16;
+  for (size_t k = 0; k < filters_.size(); ++k) {
+    int start = static_cast<int>(alignment_shift * downsampling_factor);
+    int end = static_cast<int>((alignment_shift + filters_[k].size()) *
+                               downsampling_factor);
+    RTC_LOG(LS_VERBOSE) << "Filter " << k << ": start: "
+                        << (start - static_cast<int>(shift)) / kFsBy1000
+                        << " ms, end: "
+                        << (end - static_cast<int>(shift)) / kFsBy1000
+                        << " ms.";
+    alignment_shift += filter_intra_lag_shift_;
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter.h
new file mode 100644
index 0000000..fa44eb2
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter.h
@@ -0,0 +1,149 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_MATCHED_FILTER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_MATCHED_FILTER_H_
+
+#include <stddef.h>
+
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "rtc_base/system/arch.h"
+
+namespace webrtc {
+
+class ApmDataDumper;
+struct DownsampledRenderBuffer;
+
+namespace aec3 {
+
+#if defined(WEBRTC_HAS_NEON)
+
+// Filter core for the matched filter that is optimized for NEON.
+void MatchedFilterCore_NEON(size_t x_start_index,
+                            float x2_sum_threshold,
+                            float smoothing,
+                            rtc::ArrayView<const float> x,
+                            rtc::ArrayView<const float> y,
+                            rtc::ArrayView<float> h,
+                            bool* filters_updated,
+                            float* error_sum);
+
+#endif
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+
+// Filter core for the matched filter that is optimized for SSE2.
+void MatchedFilterCore_SSE2(size_t x_start_index,
+                            float x2_sum_threshold,
+                            float smoothing,
+                            rtc::ArrayView<const float> x,
+                            rtc::ArrayView<const float> y,
+                            rtc::ArrayView<float> h,
+                            bool* filters_updated,
+                            float* error_sum);
+
+// Filter core for the matched filter that is optimized for AVX2.
+void MatchedFilterCore_AVX2(size_t x_start_index,
+                            float x2_sum_threshold,
+                            float smoothing,
+                            rtc::ArrayView<const float> x,
+                            rtc::ArrayView<const float> y,
+                            rtc::ArrayView<float> h,
+                            bool* filters_updated,
+                            float* error_sum);
+
+#endif
+
+// Filter core for the matched filter.
+void MatchedFilterCore(size_t x_start_index,
+                       float x2_sum_threshold,
+                       float smoothing,
+                       rtc::ArrayView<const float> x,
+                       rtc::ArrayView<const float> y,
+                       rtc::ArrayView<float> h,
+                       bool* filters_updated,
+                       float* error_sum);
+
+}  // namespace aec3
+
+// Produces recursively updated cross-correlation estimates for several signal
+// shifts where the intra-shift spacing is uniform.
+class MatchedFilter {
+ public:
+  // Stores properties for the lag estimate corresponding to a particular signal
+  // shift.
+  struct LagEstimate {
+    LagEstimate() = default;
+    LagEstimate(float accuracy, bool reliable, size_t lag, bool updated)
+        : accuracy(accuracy), reliable(reliable), lag(lag), updated(updated) {}
+
+    float accuracy = 0.f;
+    bool reliable = false;
+    size_t lag = 0;
+    bool updated = false;
+  };
+
+  MatchedFilter(ApmDataDumper* data_dumper,
+                Aec3Optimization optimization,
+                size_t sub_block_size,
+                size_t window_size_sub_blocks,
+                int num_matched_filters,
+                size_t alignment_shift_sub_blocks,
+                float excitation_limit,
+                float smoothing,
+                float matching_filter_threshold);
+
+  MatchedFilter() = delete;
+  MatchedFilter(const MatchedFilter&) = delete;
+  MatchedFilter& operator=(const MatchedFilter&) = delete;
+
+  ~MatchedFilter();
+
+  // Updates the correlation with the values in the capture buffer.
+  void Update(const DownsampledRenderBuffer& render_buffer,
+              rtc::ArrayView<const float> capture);
+
+  // Resets the matched filter.
+  void Reset();
+
+  // Returns the current lag estimates.
+  rtc::ArrayView<const MatchedFilter::LagEstimate> GetLagEstimates() const {
+    return lag_estimates_;
+  }
+
+  // Returns the maximum filter lag.
+  size_t GetMaxFilterLag() const {
+    return filters_.size() * filter_intra_lag_shift_ + filters_[0].size();
+  }
+
+  // Log matched filter properties.
+  void LogFilterProperties(int sample_rate_hz,
+                           size_t shift,
+                           size_t downsampling_factor) const;
+
+ private:
+  ApmDataDumper* const data_dumper_;
+  const Aec3Optimization optimization_;
+  const size_t sub_block_size_;
+  const size_t filter_intra_lag_shift_;
+  std::vector<std::vector<float>> filters_;
+  std::vector<LagEstimate> lag_estimates_;
+  std::vector<size_t> filters_offsets_;
+  const float excitation_limit_;
+  const float smoothing_;
+  const float matching_filter_threshold_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_MATCHED_FILTER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter_avx2.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter_avx2.cc
new file mode 100644
index 0000000..ed32102
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter_avx2.cc
@@ -0,0 +1,132 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/matched_filter.h"
+
+#include <immintrin.h>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace aec3 {
+
+void MatchedFilterCore_AVX2(size_t x_start_index,
+                            float x2_sum_threshold,
+                            float smoothing,
+                            rtc::ArrayView<const float> x,
+                            rtc::ArrayView<const float> y,
+                            rtc::ArrayView<float> h,
+                            bool* filters_updated,
+                            float* error_sum) {
+  const int h_size = static_cast<int>(h.size());
+  const int x_size = static_cast<int>(x.size());
+  RTC_DCHECK_EQ(0, h_size % 8);
+
+  // Process for all samples in the sub-block.
+  for (size_t i = 0; i < y.size(); ++i) {
+    // Apply the matched filter as filter * x, and compute x * x.
+
+    RTC_DCHECK_GT(x_size, x_start_index);
+    const float* x_p = &x[x_start_index];
+    const float* h_p = &h[0];
+
+    // Initialize values for the accumulation.
+    __m256 s_256 = _mm256_set1_ps(0);
+    __m256 x2_sum_256 = _mm256_set1_ps(0);
+    float x2_sum = 0.f;
+    float s = 0;
+
+    // Compute loop chunk sizes until, and after, the wraparound of the circular
+    // buffer for x.
+    const int chunk1 =
+        std::min(h_size, static_cast<int>(x_size - x_start_index));
+
+    // Perform the loop in two chunks.
+    const int chunk2 = h_size - chunk1;
+    for (int limit : {chunk1, chunk2}) {
+      // Perform 256 bit vector operations.
+      const int limit_by_8 = limit >> 3;
+      for (int k = limit_by_8; k > 0; --k, h_p += 8, x_p += 8) {
+        // Load the data into 256 bit vectors.
+        __m256 x_k = _mm256_loadu_ps(x_p);
+        __m256 h_k = _mm256_loadu_ps(h_p);
+        // Compute and accumulate x * x and h * x.
+        x2_sum_256 = _mm256_fmadd_ps(x_k, x_k, x2_sum_256);
+        s_256 = _mm256_fmadd_ps(h_k, x_k, s_256);
+      }
+
+      // Perform non-vector operations for any remaining items.
+      for (int k = limit - limit_by_8 * 8; k > 0; --k, ++h_p, ++x_p) {
+        const float x_k = *x_p;
+        x2_sum += x_k * x_k;
+        s += *h_p * x_k;
+      }
+
+      x_p = &x[0];
+    }
+
+    // Sum components together.
+    __m128 x2_sum_128 = _mm_add_ps(_mm256_extractf128_ps(x2_sum_256, 0),
+                                   _mm256_extractf128_ps(x2_sum_256, 1));
+    __m128 s_128 = _mm_add_ps(_mm256_extractf128_ps(s_256, 0),
+                              _mm256_extractf128_ps(s_256, 1));
+    // Combine the accumulated vector and scalar values.
+    float* v = reinterpret_cast<float*>(&x2_sum_128);
+    x2_sum += v[0] + v[1] + v[2] + v[3];
+    v = reinterpret_cast<float*>(&s_128);
+    s += v[0] + v[1] + v[2] + v[3];
+
+    // Compute the matched filter error.
+    float e = y[i] - s;
+    const bool saturation = y[i] >= 32000.f || y[i] <= -32000.f;
+    (*error_sum) += e * e;
+
+    // Update the matched filter estimate in an NLMS manner.
+    if (x2_sum > x2_sum_threshold && !saturation) {
+      RTC_DCHECK_LT(0.f, x2_sum);
+      const float alpha = smoothing * e / x2_sum;
+      const __m256 alpha_256 = _mm256_set1_ps(alpha);
+
+      // filter = filter + smoothing * (y - filter * x) * x / x * x.
+      float* h_p = &h[0];
+      x_p = &x[x_start_index];
+
+      // Perform the loop in two chunks.
+      for (int limit : {chunk1, chunk2}) {
+        // Perform 256 bit vector operations.
+        const int limit_by_8 = limit >> 3;
+        for (int k = limit_by_8; k > 0; --k, h_p += 8, x_p += 8) {
+          // Load the data into 256 bit vectors.
+          __m256 h_k = _mm256_loadu_ps(h_p);
+          __m256 x_k = _mm256_loadu_ps(x_p);
+          // Compute h = h + alpha * x.
+          h_k = _mm256_fmadd_ps(x_k, alpha_256, h_k);
+
+          // Store the result.
+          _mm256_storeu_ps(h_p, h_k);
+        }
+
+        // Perform non-vector operations for any remaining items.
+        for (int k = limit - limit_by_8 * 8; k > 0; --k, ++h_p, ++x_p) {
+          *h_p += alpha * *x_p;
+        }
+
+        x_p = &x[0];
+      }
+
+      *filters_updated = true;
+    }
+
+    x_start_index = x_start_index > 0 ? x_start_index - 1 : x_size - 1;
+  }
+}
+
+}  // namespace aec3
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter_lag_aggregator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter_lag_aggregator.cc
new file mode 100644
index 0000000..603a864
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter_lag_aggregator.cc
@@ -0,0 +1,97 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "modules/audio_processing/aec3/matched_filter_lag_aggregator.h"
+
+#include <algorithm>
+#include <iterator>
+
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+MatchedFilterLagAggregator::MatchedFilterLagAggregator(
+    ApmDataDumper* data_dumper,
+    size_t max_filter_lag,
+    const EchoCanceller3Config::Delay::DelaySelectionThresholds& thresholds)
+    : data_dumper_(data_dumper),
+      histogram_(max_filter_lag + 1, 0),
+      thresholds_(thresholds) {
+  RTC_DCHECK(data_dumper);
+  RTC_DCHECK_LE(thresholds_.initial, thresholds_.converged);
+  histogram_data_.fill(0);
+}
+
+MatchedFilterLagAggregator::~MatchedFilterLagAggregator() = default;
+
+void MatchedFilterLagAggregator::Reset(bool hard_reset) {
+  std::fill(histogram_.begin(), histogram_.end(), 0);
+  histogram_data_.fill(0);
+  histogram_data_index_ = 0;
+  if (hard_reset) {
+    significant_candidate_found_ = false;
+  }
+}
+
+absl::optional<DelayEstimate> MatchedFilterLagAggregator::Aggregate(
+    rtc::ArrayView<const MatchedFilter::LagEstimate> lag_estimates) {
+  // Choose the strongest lag estimate as the best one.
+  float best_accuracy = 0.f;
+  int best_lag_estimate_index = -1;
+  for (size_t k = 0; k < lag_estimates.size(); ++k) {
+    if (lag_estimates[k].updated && lag_estimates[k].reliable) {
+      if (lag_estimates[k].accuracy > best_accuracy) {
+        best_accuracy = lag_estimates[k].accuracy;
+        best_lag_estimate_index = static_cast<int>(k);
+      }
+    }
+  }
+
+  // TODO(peah): Remove this logging once all development is done.
+  data_dumper_->DumpRaw("aec3_echo_path_delay_estimator_best_index",
+                        best_lag_estimate_index);
+  data_dumper_->DumpRaw("aec3_echo_path_delay_estimator_histogram", histogram_);
+
+  if (best_lag_estimate_index != -1) {
+    RTC_DCHECK_GT(histogram_.size(), histogram_data_[histogram_data_index_]);
+    RTC_DCHECK_LE(0, histogram_data_[histogram_data_index_]);
+    --histogram_[histogram_data_[histogram_data_index_]];
+
+    histogram_data_[histogram_data_index_] =
+        lag_estimates[best_lag_estimate_index].lag;
+
+    RTC_DCHECK_GT(histogram_.size(), histogram_data_[histogram_data_index_]);
+    RTC_DCHECK_LE(0, histogram_data_[histogram_data_index_]);
+    ++histogram_[histogram_data_[histogram_data_index_]];
+
+    histogram_data_index_ =
+        (histogram_data_index_ + 1) % histogram_data_.size();
+
+    const int candidate =
+        std::distance(histogram_.begin(),
+                      std::max_element(histogram_.begin(), histogram_.end()));
+
+    significant_candidate_found_ =
+        significant_candidate_found_ ||
+        histogram_[candidate] > thresholds_.converged;
+    if (histogram_[candidate] > thresholds_.converged ||
+        (histogram_[candidate] > thresholds_.initial &&
+         !significant_candidate_found_)) {
+      DelayEstimate::Quality quality = significant_candidate_found_
+                                           ? DelayEstimate::Quality::kRefined
+                                           : DelayEstimate::Quality::kCoarse;
+      return DelayEstimate(quality, candidate);
+    }
+  }
+
+  return absl::nullopt;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter_lag_aggregator.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter_lag_aggregator.h
new file mode 100644
index 0000000..d48011e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter_lag_aggregator.h
@@ -0,0 +1,58 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_MATCHED_FILTER_LAG_AGGREGATOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_MATCHED_FILTER_LAG_AGGREGATOR_H_
+
+#include <vector>
+
+#include "absl/types/optional.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/delay_estimate.h"
+#include "modules/audio_processing/aec3/matched_filter.h"
+
+namespace webrtc {
+
+class ApmDataDumper;
+
+// Aggregates lag estimates produced by the MatchedFilter class into a single
+// reliable combined lag estimate.
+class MatchedFilterLagAggregator {
+ public:
+  MatchedFilterLagAggregator(
+      ApmDataDumper* data_dumper,
+      size_t max_filter_lag,
+      const EchoCanceller3Config::Delay::DelaySelectionThresholds& thresholds);
+
+  MatchedFilterLagAggregator() = delete;
+  MatchedFilterLagAggregator(const MatchedFilterLagAggregator&) = delete;
+  MatchedFilterLagAggregator& operator=(const MatchedFilterLagAggregator&) =
+      delete;
+
+  ~MatchedFilterLagAggregator();
+
+  // Resets the aggregator.
+  void Reset(bool hard_reset);
+
+  // Aggregates the provided lag estimates.
+  absl::optional<DelayEstimate> Aggregate(
+      rtc::ArrayView<const MatchedFilter::LagEstimate> lag_estimates);
+
+ private:
+  ApmDataDumper* const data_dumper_;
+  std::vector<int> histogram_;
+  std::array<int, 250> histogram_data_;
+  int histogram_data_index_ = 0;
+  bool significant_candidate_found_ = false;
+  const EchoCanceller3Config::Delay::DelaySelectionThresholds thresholds_;
+};
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_MATCHED_FILTER_LAG_AGGREGATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter_lag_aggregator_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter_lag_aggregator_unittest.cc
new file mode 100644
index 0000000..8e2a12e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter_lag_aggregator_unittest.cc
@@ -0,0 +1,156 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/matched_filter_lag_aggregator.h"
+
+#include <sstream>
+#include <string>
+#include <vector>
+
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace {
+
+constexpr size_t kNumLagsBeforeDetection = 26;
+
+}  // namespace
+
+// Verifies that the most accurate lag estimate is chosen.
+TEST(MatchedFilterLagAggregator, MostAccurateLagChosen) {
+  constexpr size_t kLag1 = 5;
+  constexpr size_t kLag2 = 10;
+  ApmDataDumper data_dumper(0);
+  EchoCanceller3Config config;
+  std::vector<MatchedFilter::LagEstimate> lag_estimates(2);
+  MatchedFilterLagAggregator aggregator(
+      &data_dumper, std::max(kLag1, kLag2),
+      config.delay.delay_selection_thresholds);
+  lag_estimates[0] = MatchedFilter::LagEstimate(1.f, true, kLag1, true);
+  lag_estimates[1] = MatchedFilter::LagEstimate(0.5f, true, kLag2, true);
+
+  for (size_t k = 0; k < kNumLagsBeforeDetection; ++k) {
+    aggregator.Aggregate(lag_estimates);
+  }
+
+  absl::optional<DelayEstimate> aggregated_lag =
+      aggregator.Aggregate(lag_estimates);
+  EXPECT_TRUE(aggregated_lag);
+  EXPECT_EQ(kLag1, aggregated_lag->delay);
+
+  lag_estimates[0] = MatchedFilter::LagEstimate(0.5f, true, kLag1, true);
+  lag_estimates[1] = MatchedFilter::LagEstimate(1.f, true, kLag2, true);
+
+  for (size_t k = 0; k < kNumLagsBeforeDetection; ++k) {
+    aggregated_lag = aggregator.Aggregate(lag_estimates);
+    EXPECT_TRUE(aggregated_lag);
+    EXPECT_EQ(kLag1, aggregated_lag->delay);
+  }
+
+  aggregated_lag = aggregator.Aggregate(lag_estimates);
+  aggregated_lag = aggregator.Aggregate(lag_estimates);
+  EXPECT_TRUE(aggregated_lag);
+  EXPECT_EQ(kLag2, aggregated_lag->delay);
+}
+
+// Verifies that varying lag estimates causes lag estimates to not be deemed
+// reliable.
+TEST(MatchedFilterLagAggregator,
+     LagEstimateInvarianceRequiredForAggregatedLag) {
+  ApmDataDumper data_dumper(0);
+  EchoCanceller3Config config;
+  std::vector<MatchedFilter::LagEstimate> lag_estimates(1);
+  MatchedFilterLagAggregator aggregator(
+      &data_dumper, 100, config.delay.delay_selection_thresholds);
+
+  absl::optional<DelayEstimate> aggregated_lag;
+  for (size_t k = 0; k < kNumLagsBeforeDetection; ++k) {
+    lag_estimates[0] = MatchedFilter::LagEstimate(1.f, true, 10, true);
+    aggregated_lag = aggregator.Aggregate(lag_estimates);
+  }
+  EXPECT_TRUE(aggregated_lag);
+
+  for (size_t k = 0; k < kNumLagsBeforeDetection * 100; ++k) {
+    lag_estimates[0] = MatchedFilter::LagEstimate(1.f, true, k % 100, true);
+    aggregated_lag = aggregator.Aggregate(lag_estimates);
+  }
+  EXPECT_FALSE(aggregated_lag);
+
+  for (size_t k = 0; k < kNumLagsBeforeDetection * 100; ++k) {
+    lag_estimates[0] = MatchedFilter::LagEstimate(1.f, true, k % 100, true);
+    aggregated_lag = aggregator.Aggregate(lag_estimates);
+    EXPECT_FALSE(aggregated_lag);
+  }
+}
+
+// Verifies that lag estimate updates are required to produce an updated lag
+// aggregate.
+TEST(MatchedFilterLagAggregator,
+     DISABLED_LagEstimateUpdatesRequiredForAggregatedLag) {
+  constexpr size_t kLag = 5;
+  ApmDataDumper data_dumper(0);
+  EchoCanceller3Config config;
+  std::vector<MatchedFilter::LagEstimate> lag_estimates(1);
+  MatchedFilterLagAggregator aggregator(
+      &data_dumper, kLag, config.delay.delay_selection_thresholds);
+  for (size_t k = 0; k < kNumLagsBeforeDetection * 10; ++k) {
+    lag_estimates[0] = MatchedFilter::LagEstimate(1.f, true, kLag, false);
+    absl::optional<DelayEstimate> aggregated_lag =
+        aggregator.Aggregate(lag_estimates);
+    EXPECT_FALSE(aggregated_lag);
+    EXPECT_EQ(kLag, aggregated_lag->delay);
+  }
+}
+
+// Verifies that an aggregated lag is persistent if the lag estimates do not
+// change and that an aggregated lag is not produced without gaining lag
+// estimate confidence.
+TEST(MatchedFilterLagAggregator, DISABLED_PersistentAggregatedLag) {
+  constexpr size_t kLag1 = 5;
+  constexpr size_t kLag2 = 10;
+  ApmDataDumper data_dumper(0);
+  EchoCanceller3Config config;
+  std::vector<MatchedFilter::LagEstimate> lag_estimates(1);
+  MatchedFilterLagAggregator aggregator(
+      &data_dumper, std::max(kLag1, kLag2),
+      config.delay.delay_selection_thresholds);
+  absl::optional<DelayEstimate> aggregated_lag;
+  for (size_t k = 0; k < kNumLagsBeforeDetection; ++k) {
+    lag_estimates[0] = MatchedFilter::LagEstimate(1.f, true, kLag1, true);
+    aggregated_lag = aggregator.Aggregate(lag_estimates);
+  }
+  EXPECT_TRUE(aggregated_lag);
+  EXPECT_EQ(kLag1, aggregated_lag->delay);
+
+  for (size_t k = 0; k < kNumLagsBeforeDetection * 40; ++k) {
+    lag_estimates[0] = MatchedFilter::LagEstimate(1.f, false, kLag2, true);
+    aggregated_lag = aggregator.Aggregate(lag_estimates);
+    EXPECT_TRUE(aggregated_lag);
+    EXPECT_EQ(kLag1, aggregated_lag->delay);
+  }
+}
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+// Verifies the check for non-null data dumper.
+TEST(MatchedFilterLagAggregatorDeathTest, NullDataDumper) {
+  EchoCanceller3Config config;
+  EXPECT_DEATH(MatchedFilterLagAggregator(
+                   nullptr, 10, config.delay.delay_selection_thresholds),
+               "");
+}
+
+#endif
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter_unittest.cc
new file mode 100644
index 0000000..137275f
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/matched_filter_unittest.cc
@@ -0,0 +1,463 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/matched_filter.h"
+
+// Defines WEBRTC_ARCH_X86_FAMILY, used below.
+#include "rtc_base/system/arch.h"
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+#include <emmintrin.h>
+#endif
+#include <algorithm>
+#include <string>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/decimator.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "modules/audio_processing/test/echo_canceller_test_tools.h"
+#include "rtc_base/random.h"
+#include "rtc_base/strings/string_builder.h"
+#include "system_wrappers/include/cpu_features_wrapper.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace aec3 {
+namespace {
+
+std::string ProduceDebugText(size_t delay, size_t down_sampling_factor) {
+  rtc::StringBuilder ss;
+  ss << "Delay: " << delay;
+  ss << ", Down sampling factor: " << down_sampling_factor;
+  return ss.Release();
+}
+
+constexpr size_t kNumMatchedFilters = 10;
+constexpr size_t kDownSamplingFactors[] = {2, 4, 8};
+constexpr size_t kWindowSizeSubBlocks = 32;
+constexpr size_t kAlignmentShiftSubBlocks = kWindowSizeSubBlocks * 3 / 4;
+
+}  // namespace
+
+#if defined(WEBRTC_HAS_NEON)
+// Verifies that the optimized methods for NEON are similar to their reference
+// counterparts.
+TEST(MatchedFilter, TestNeonOptimizations) {
+  Random random_generator(42U);
+  constexpr float kSmoothing = 0.7f;
+  for (auto down_sampling_factor : kDownSamplingFactors) {
+    const size_t sub_block_size = kBlockSize / down_sampling_factor;
+
+    std::vector<float> x(2000);
+    RandomizeSampleVector(&random_generator, x);
+    std::vector<float> y(sub_block_size);
+    std::vector<float> h_NEON(512);
+    std::vector<float> h(512);
+    int x_index = 0;
+    for (int k = 0; k < 1000; ++k) {
+      RandomizeSampleVector(&random_generator, y);
+
+      bool filters_updated = false;
+      float error_sum = 0.f;
+      bool filters_updated_NEON = false;
+      float error_sum_NEON = 0.f;
+
+      MatchedFilterCore_NEON(x_index, h.size() * 150.f * 150.f, kSmoothing, x,
+                             y, h_NEON, &filters_updated_NEON, &error_sum_NEON);
+
+      MatchedFilterCore(x_index, h.size() * 150.f * 150.f, kSmoothing, x, y, h,
+                        &filters_updated, &error_sum);
+
+      EXPECT_EQ(filters_updated, filters_updated_NEON);
+      EXPECT_NEAR(error_sum, error_sum_NEON, error_sum / 100000.f);
+
+      for (size_t j = 0; j < h.size(); ++j) {
+        EXPECT_NEAR(h[j], h_NEON[j], 0.00001f);
+      }
+
+      x_index = (x_index + sub_block_size) % x.size();
+    }
+  }
+}
+#endif
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+// Verifies that the optimized methods for SSE2 are bitexact to their reference
+// counterparts.
+TEST(MatchedFilter, TestSse2Optimizations) {
+  bool use_sse2 = (GetCPUInfo(kSSE2) != 0);
+  if (use_sse2) {
+    Random random_generator(42U);
+    constexpr float kSmoothing = 0.7f;
+    for (auto down_sampling_factor : kDownSamplingFactors) {
+      const size_t sub_block_size = kBlockSize / down_sampling_factor;
+      std::vector<float> x(2000);
+      RandomizeSampleVector(&random_generator, x);
+      std::vector<float> y(sub_block_size);
+      std::vector<float> h_SSE2(512);
+      std::vector<float> h(512);
+      int x_index = 0;
+      for (int k = 0; k < 1000; ++k) {
+        RandomizeSampleVector(&random_generator, y);
+
+        bool filters_updated = false;
+        float error_sum = 0.f;
+        bool filters_updated_SSE2 = false;
+        float error_sum_SSE2 = 0.f;
+
+        MatchedFilterCore_SSE2(x_index, h.size() * 150.f * 150.f, kSmoothing, x,
+                               y, h_SSE2, &filters_updated_SSE2,
+                               &error_sum_SSE2);
+
+        MatchedFilterCore(x_index, h.size() * 150.f * 150.f, kSmoothing, x, y,
+                          h, &filters_updated, &error_sum);
+
+        EXPECT_EQ(filters_updated, filters_updated_SSE2);
+        EXPECT_NEAR(error_sum, error_sum_SSE2, error_sum / 100000.f);
+
+        for (size_t j = 0; j < h.size(); ++j) {
+          EXPECT_NEAR(h[j], h_SSE2[j], 0.00001f);
+        }
+
+        x_index = (x_index + sub_block_size) % x.size();
+      }
+    }
+  }
+}
+
+TEST(MatchedFilter, TestAvx2Optimizations) {
+  bool use_avx2 = (GetCPUInfo(kAVX2) != 0);
+  if (use_avx2) {
+    Random random_generator(42U);
+    constexpr float kSmoothing = 0.7f;
+    for (auto down_sampling_factor : kDownSamplingFactors) {
+      const size_t sub_block_size = kBlockSize / down_sampling_factor;
+      std::vector<float> x(2000);
+      RandomizeSampleVector(&random_generator, x);
+      std::vector<float> y(sub_block_size);
+      std::vector<float> h_AVX2(512);
+      std::vector<float> h(512);
+      int x_index = 0;
+      for (int k = 0; k < 1000; ++k) {
+        RandomizeSampleVector(&random_generator, y);
+
+        bool filters_updated = false;
+        float error_sum = 0.f;
+        bool filters_updated_AVX2 = false;
+        float error_sum_AVX2 = 0.f;
+
+        MatchedFilterCore_AVX2(x_index, h.size() * 150.f * 150.f, kSmoothing, x,
+                               y, h_AVX2, &filters_updated_AVX2,
+                               &error_sum_AVX2);
+
+        MatchedFilterCore(x_index, h.size() * 150.f * 150.f, kSmoothing, x, y,
+                          h, &filters_updated, &error_sum);
+
+        EXPECT_EQ(filters_updated, filters_updated_AVX2);
+        EXPECT_NEAR(error_sum, error_sum_AVX2, error_sum / 100000.f);
+
+        for (size_t j = 0; j < h.size(); ++j) {
+          EXPECT_NEAR(h[j], h_AVX2[j], 0.00001f);
+        }
+
+        x_index = (x_index + sub_block_size) % x.size();
+      }
+    }
+  }
+}
+
+#endif
+
+// Verifies that the matched filter produces proper lag estimates for
+// artificially
+// delayed signals.
+TEST(MatchedFilter, LagEstimation) {
+  Random random_generator(42U);
+  constexpr size_t kNumChannels = 1;
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+
+  for (auto down_sampling_factor : kDownSamplingFactors) {
+    const size_t sub_block_size = kBlockSize / down_sampling_factor;
+
+    std::vector<std::vector<std::vector<float>>> render(
+        kNumBands, std::vector<std::vector<float>>(
+                       kNumChannels, std::vector<float>(kBlockSize, 0.f)));
+    std::vector<std::vector<float>> capture(
+        1, std::vector<float>(kBlockSize, 0.f));
+    ApmDataDumper data_dumper(0);
+    for (size_t delay_samples : {5, 64, 150, 200, 800, 1000}) {
+      SCOPED_TRACE(ProduceDebugText(delay_samples, down_sampling_factor));
+      EchoCanceller3Config config;
+      config.delay.down_sampling_factor = down_sampling_factor;
+      config.delay.num_filters = kNumMatchedFilters;
+      Decimator capture_decimator(down_sampling_factor);
+      DelayBuffer<float> signal_delay_buffer(down_sampling_factor *
+                                             delay_samples);
+      MatchedFilter filter(&data_dumper, DetectOptimization(), sub_block_size,
+                           kWindowSizeSubBlocks, kNumMatchedFilters,
+                           kAlignmentShiftSubBlocks, 150,
+                           config.delay.delay_estimate_smoothing,
+                           config.delay.delay_candidate_detection_threshold);
+
+      std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+          RenderDelayBuffer::Create(config, kSampleRateHz, kNumChannels));
+
+      // Analyze the correlation between render and capture.
+      for (size_t k = 0; k < (600 + delay_samples / sub_block_size); ++k) {
+        for (size_t band = 0; band < kNumBands; ++band) {
+          for (size_t channel = 0; channel < kNumChannels; ++channel) {
+            RandomizeSampleVector(&random_generator, render[band][channel]);
+          }
+        }
+        signal_delay_buffer.Delay(render[0][0], capture[0]);
+        render_delay_buffer->Insert(render);
+
+        if (k == 0) {
+          render_delay_buffer->Reset();
+        }
+
+        render_delay_buffer->PrepareCaptureProcessing();
+        std::array<float, kBlockSize> downsampled_capture_data;
+        rtc::ArrayView<float> downsampled_capture(
+            downsampled_capture_data.data(), sub_block_size);
+        capture_decimator.Decimate(capture[0], downsampled_capture);
+        filter.Update(render_delay_buffer->GetDownsampledRenderBuffer(),
+                      downsampled_capture);
+      }
+
+      // Obtain the lag estimates.
+      auto lag_estimates = filter.GetLagEstimates();
+
+      // Find which lag estimate should be the most accurate.
+      absl::optional<size_t> expected_most_accurate_lag_estimate;
+      size_t alignment_shift_sub_blocks = 0;
+      for (size_t k = 0; k < config.delay.num_filters; ++k) {
+        if ((alignment_shift_sub_blocks + 3 * kWindowSizeSubBlocks / 4) *
+                sub_block_size >
+            delay_samples) {
+          expected_most_accurate_lag_estimate = k > 0 ? k - 1 : 0;
+          break;
+        }
+        alignment_shift_sub_blocks += kAlignmentShiftSubBlocks;
+      }
+      ASSERT_TRUE(expected_most_accurate_lag_estimate);
+
+      // Verify that the expected most accurate lag estimate is the most
+      // accurate estimate.
+      for (size_t k = 0; k < kNumMatchedFilters; ++k) {
+        if (k != *expected_most_accurate_lag_estimate &&
+            k != (*expected_most_accurate_lag_estimate + 1)) {
+          EXPECT_TRUE(
+              lag_estimates[*expected_most_accurate_lag_estimate].accuracy >
+                  lag_estimates[k].accuracy ||
+              !lag_estimates[k].reliable ||
+              !lag_estimates[*expected_most_accurate_lag_estimate].reliable);
+        }
+      }
+
+      // Verify that all lag estimates are updated as expected for signals
+      // containing strong noise.
+      for (auto& le : lag_estimates) {
+        EXPECT_TRUE(le.updated);
+      }
+
+      // Verify that the expected most accurate lag estimate is reliable.
+      EXPECT_TRUE(
+          lag_estimates[*expected_most_accurate_lag_estimate].reliable ||
+          lag_estimates[std::min(*expected_most_accurate_lag_estimate + 1,
+                                 lag_estimates.size() - 1)]
+              .reliable);
+
+      // Verify that the expected most accurate lag estimate is correct.
+      if (lag_estimates[*expected_most_accurate_lag_estimate].reliable) {
+        EXPECT_TRUE(delay_samples ==
+                    lag_estimates[*expected_most_accurate_lag_estimate].lag);
+      } else {
+        EXPECT_TRUE(
+            delay_samples ==
+            lag_estimates[std::min(*expected_most_accurate_lag_estimate + 1,
+                                   lag_estimates.size() - 1)]
+                .lag);
+      }
+    }
+  }
+}
+
+// Verifies that the matched filter does not produce reliable and accurate
+// estimates for uncorrelated render and capture signals.
+TEST(MatchedFilter, LagNotReliableForUncorrelatedRenderAndCapture) {
+  constexpr size_t kNumChannels = 1;
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+  Random random_generator(42U);
+  for (auto down_sampling_factor : kDownSamplingFactors) {
+    EchoCanceller3Config config;
+    config.delay.down_sampling_factor = down_sampling_factor;
+    config.delay.num_filters = kNumMatchedFilters;
+    const size_t sub_block_size = kBlockSize / down_sampling_factor;
+
+    std::vector<std::vector<std::vector<float>>> render(
+        kNumBands, std::vector<std::vector<float>>(
+                       kNumChannels, std::vector<float>(kBlockSize, 0.f)));
+    std::array<float, kBlockSize> capture_data;
+    rtc::ArrayView<float> capture(capture_data.data(), sub_block_size);
+    std::fill(capture.begin(), capture.end(), 0.f);
+    ApmDataDumper data_dumper(0);
+    std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+        RenderDelayBuffer::Create(config, kSampleRateHz, kNumChannels));
+    MatchedFilter filter(&data_dumper, DetectOptimization(), sub_block_size,
+                         kWindowSizeSubBlocks, kNumMatchedFilters,
+                         kAlignmentShiftSubBlocks, 150,
+                         config.delay.delay_estimate_smoothing,
+                         config.delay.delay_candidate_detection_threshold);
+
+    // Analyze the correlation between render and capture.
+    for (size_t k = 0; k < 100; ++k) {
+      RandomizeSampleVector(&random_generator, render[0][0]);
+      RandomizeSampleVector(&random_generator, capture);
+      render_delay_buffer->Insert(render);
+      filter.Update(render_delay_buffer->GetDownsampledRenderBuffer(), capture);
+    }
+
+    // Obtain the lag estimates.
+    auto lag_estimates = filter.GetLagEstimates();
+    EXPECT_EQ(kNumMatchedFilters, lag_estimates.size());
+
+    // Verify that no lag estimates are reliable.
+    for (auto& le : lag_estimates) {
+      EXPECT_FALSE(le.reliable);
+    }
+  }
+}
+
+// Verifies that the matched filter does not produce updated lag estimates for
+// render signals of low level.
+TEST(MatchedFilter, LagNotUpdatedForLowLevelRender) {
+  Random random_generator(42U);
+  constexpr size_t kNumChannels = 1;
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+
+  for (auto down_sampling_factor : kDownSamplingFactors) {
+    const size_t sub_block_size = kBlockSize / down_sampling_factor;
+
+    std::vector<std::vector<std::vector<float>>> render(
+        kNumBands, std::vector<std::vector<float>>(
+                       kNumChannels, std::vector<float>(kBlockSize, 0.f)));
+    std::vector<std::vector<float>> capture(
+        1, std::vector<float>(kBlockSize, 0.f));
+    ApmDataDumper data_dumper(0);
+    EchoCanceller3Config config;
+    MatchedFilter filter(&data_dumper, DetectOptimization(), sub_block_size,
+                         kWindowSizeSubBlocks, kNumMatchedFilters,
+                         kAlignmentShiftSubBlocks, 150,
+                         config.delay.delay_estimate_smoothing,
+                         config.delay.delay_candidate_detection_threshold);
+    std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+        RenderDelayBuffer::Create(EchoCanceller3Config(), kSampleRateHz,
+                                  kNumChannels));
+    Decimator capture_decimator(down_sampling_factor);
+
+    // Analyze the correlation between render and capture.
+    for (size_t k = 0; k < 100; ++k) {
+      RandomizeSampleVector(&random_generator, render[0][0]);
+      for (auto& render_k : render[0][0]) {
+        render_k *= 149.f / 32767.f;
+      }
+      std::copy(render[0][0].begin(), render[0][0].end(), capture[0].begin());
+      std::array<float, kBlockSize> downsampled_capture_data;
+      rtc::ArrayView<float> downsampled_capture(downsampled_capture_data.data(),
+                                                sub_block_size);
+      capture_decimator.Decimate(capture[0], downsampled_capture);
+      filter.Update(render_delay_buffer->GetDownsampledRenderBuffer(),
+                    downsampled_capture);
+    }
+
+    // Obtain the lag estimates.
+    auto lag_estimates = filter.GetLagEstimates();
+    EXPECT_EQ(kNumMatchedFilters, lag_estimates.size());
+
+    // Verify that no lag estimates are updated and that no lag estimates are
+    // reliable.
+    for (auto& le : lag_estimates) {
+      EXPECT_FALSE(le.updated);
+      EXPECT_FALSE(le.reliable);
+    }
+  }
+}
+
+// Verifies that the correct number of lag estimates are produced for a certain
+// number of alignment shifts.
+TEST(MatchedFilter, NumberOfLagEstimates) {
+  ApmDataDumper data_dumper(0);
+  EchoCanceller3Config config;
+  for (auto down_sampling_factor : kDownSamplingFactors) {
+    const size_t sub_block_size = kBlockSize / down_sampling_factor;
+    for (size_t num_matched_filters = 0; num_matched_filters < 10;
+         ++num_matched_filters) {
+      MatchedFilter filter(&data_dumper, DetectOptimization(), sub_block_size,
+                           32, num_matched_filters, 1, 150,
+                           config.delay.delay_estimate_smoothing,
+                           config.delay.delay_candidate_detection_threshold);
+      EXPECT_EQ(num_matched_filters, filter.GetLagEstimates().size());
+    }
+  }
+}
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+// Verifies the check for non-zero windows size.
+TEST(MatchedFilterDeathTest, ZeroWindowSize) {
+  ApmDataDumper data_dumper(0);
+  EchoCanceller3Config config;
+  EXPECT_DEATH(MatchedFilter(&data_dumper, DetectOptimization(), 16, 0, 1, 1,
+                             150, config.delay.delay_estimate_smoothing,
+                             config.delay.delay_candidate_detection_threshold),
+               "");
+}
+
+// Verifies the check for non-null data dumper.
+TEST(MatchedFilterDeathTest, NullDataDumper) {
+  EchoCanceller3Config config;
+  EXPECT_DEATH(MatchedFilter(nullptr, DetectOptimization(), 16, 1, 1, 1, 150,
+                             config.delay.delay_estimate_smoothing,
+                             config.delay.delay_candidate_detection_threshold),
+               "");
+}
+
+// Verifies the check for that the sub block size is a multiple of 4.
+// TODO(peah): Activate the unittest once the required code has been landed.
+TEST(MatchedFilterDeathTest, DISABLED_BlockSizeMultipleOf4) {
+  ApmDataDumper data_dumper(0);
+  EchoCanceller3Config config;
+  EXPECT_DEATH(MatchedFilter(&data_dumper, DetectOptimization(), 15, 1, 1, 1,
+                             150, config.delay.delay_estimate_smoothing,
+                             config.delay.delay_candidate_detection_threshold),
+               "");
+}
+
+// Verifies the check for that there is an integer number of sub blocks that add
+// up to a block size.
+// TODO(peah): Activate the unittest once the required code has been landed.
+TEST(MatchedFilterDeathTest, DISABLED_SubBlockSizeAddsUpToBlockSize) {
+  ApmDataDumper data_dumper(0);
+  EchoCanceller3Config config;
+  EXPECT_DEATH(MatchedFilter(&data_dumper, DetectOptimization(), 12, 1, 1, 1,
+                             150, config.delay.delay_estimate_smoothing,
+                             config.delay.delay_candidate_detection_threshold),
+               "");
+}
+
+#endif
+
+}  // namespace aec3
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_block_processor.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_block_processor.cc
new file mode 100644
index 0000000..c5c33db
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_block_processor.cc
@@ -0,0 +1,20 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/mock/mock_block_processor.h"
+
+namespace webrtc {
+namespace test {
+
+MockBlockProcessor::MockBlockProcessor() = default;
+MockBlockProcessor::~MockBlockProcessor() = default;
+
+}  // namespace test
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_block_processor.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_block_processor.h
new file mode 100644
index 0000000..aa61225
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_block_processor.h
@@ -0,0 +1,56 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_MOCK_MOCK_BLOCK_PROCESSOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_MOCK_MOCK_BLOCK_PROCESSOR_H_
+
+#include <vector>
+
+#include "modules/audio_processing/aec3/block_processor.h"
+#include "test/gmock.h"
+
+namespace webrtc {
+namespace test {
+
+class MockBlockProcessor : public BlockProcessor {
+ public:
+  MockBlockProcessor();
+  virtual ~MockBlockProcessor();
+
+  MOCK_METHOD(void,
+              ProcessCapture,
+              (bool level_change,
+               bool saturated_microphone_signal,
+               std::vector<std::vector<std::vector<float>>>* linear_output,
+               std::vector<std::vector<std::vector<float>>>* capture_block),
+              (override));
+  MOCK_METHOD(void,
+              BufferRender,
+              (const std::vector<std::vector<std::vector<float>>>& block),
+              (override));
+  MOCK_METHOD(void,
+              UpdateEchoLeakageStatus,
+              (bool leakage_detected),
+              (override));
+  MOCK_METHOD(void,
+              GetMetrics,
+              (EchoControl::Metrics * metrics),
+              (const, override));
+  MOCK_METHOD(void, SetAudioBufferDelay, (int delay_ms), (override));
+  MOCK_METHOD(void,
+              SetCaptureOutputUsage,
+              (bool capture_output_used),
+              (override));
+};
+
+}  // namespace test
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_MOCK_MOCK_BLOCK_PROCESSOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_echo_remover.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_echo_remover.cc
new file mode 100644
index 0000000..b903bf0
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_echo_remover.cc
@@ -0,0 +1,20 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/mock/mock_echo_remover.h"
+
+namespace webrtc {
+namespace test {
+
+MockEchoRemover::MockEchoRemover() = default;
+MockEchoRemover::~MockEchoRemover() = default;
+
+}  // namespace test
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_echo_remover.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_echo_remover.h
new file mode 100644
index 0000000..60c5bf4
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_echo_remover.h
@@ -0,0 +1,56 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_MOCK_MOCK_ECHO_REMOVER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_MOCK_MOCK_ECHO_REMOVER_H_
+
+#include <vector>
+
+#include "absl/types/optional.h"
+#include "modules/audio_processing/aec3/echo_path_variability.h"
+#include "modules/audio_processing/aec3/echo_remover.h"
+#include "modules/audio_processing/aec3/render_buffer.h"
+#include "test/gmock.h"
+
+namespace webrtc {
+namespace test {
+
+class MockEchoRemover : public EchoRemover {
+ public:
+  MockEchoRemover();
+  virtual ~MockEchoRemover();
+
+  MOCK_METHOD(void,
+              ProcessCapture,
+              (EchoPathVariability echo_path_variability,
+               bool capture_signal_saturation,
+               const absl::optional<DelayEstimate>& delay_estimate,
+               RenderBuffer* render_buffer,
+               std::vector<std::vector<std::vector<float>>>* linear_output,
+               std::vector<std::vector<std::vector<float>>>* capture),
+              (override));
+  MOCK_METHOD(void,
+              UpdateEchoLeakageStatus,
+              (bool leakage_detected),
+              (override));
+  MOCK_METHOD(void,
+              GetMetrics,
+              (EchoControl::Metrics * metrics),
+              (const, override));
+  MOCK_METHOD(void,
+              SetCaptureOutputUsage,
+              (bool capture_output_used),
+              (override));
+};
+
+}  // namespace test
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_MOCK_MOCK_ECHO_REMOVER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_render_delay_buffer.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_render_delay_buffer.cc
new file mode 100644
index 0000000..d7099b0
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_render_delay_buffer.cc
@@ -0,0 +1,37 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/mock/mock_render_delay_buffer.h"
+
+namespace webrtc {
+namespace test {
+
+MockRenderDelayBuffer::MockRenderDelayBuffer(int sample_rate_hz,
+                                             size_t num_channels)
+    : block_buffer_(GetRenderDelayBufferSize(4, 4, 12),
+                    NumBandsForRate(sample_rate_hz),
+                    num_channels,
+                    kBlockSize),
+      spectrum_buffer_(block_buffer_.buffer.size(), num_channels),
+      fft_buffer_(block_buffer_.buffer.size(), num_channels),
+      render_buffer_(&block_buffer_, &spectrum_buffer_, &fft_buffer_),
+      downsampled_render_buffer_(GetDownSampledBufferSize(4, 4)) {
+  ON_CALL(*this, GetRenderBuffer())
+      .WillByDefault(
+          ::testing::Invoke(this, &MockRenderDelayBuffer::FakeGetRenderBuffer));
+  ON_CALL(*this, GetDownsampledRenderBuffer())
+      .WillByDefault(::testing::Invoke(
+          this, &MockRenderDelayBuffer::FakeGetDownsampledRenderBuffer));
+}
+
+MockRenderDelayBuffer::~MockRenderDelayBuffer() = default;
+
+}  // namespace test
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_render_delay_buffer.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_render_delay_buffer.h
new file mode 100644
index 0000000..9d7b8f4
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_render_delay_buffer.h
@@ -0,0 +1,67 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_MOCK_MOCK_RENDER_DELAY_BUFFER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_MOCK_MOCK_RENDER_DELAY_BUFFER_H_
+
+#include <vector>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/downsampled_render_buffer.h"
+#include "modules/audio_processing/aec3/render_buffer.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "test/gmock.h"
+
+namespace webrtc {
+namespace test {
+
+class MockRenderDelayBuffer : public RenderDelayBuffer {
+ public:
+  MockRenderDelayBuffer(int sample_rate_hz, size_t num_channels);
+  virtual ~MockRenderDelayBuffer();
+
+  MOCK_METHOD(void, Reset, (), (override));
+  MOCK_METHOD(RenderDelayBuffer::BufferingEvent,
+              Insert,
+              (const std::vector<std::vector<std::vector<float>>>& block),
+              (override));
+  MOCK_METHOD(void, HandleSkippedCaptureProcessing, (), (override));
+  MOCK_METHOD(RenderDelayBuffer::BufferingEvent,
+              PrepareCaptureProcessing,
+              (),
+              (override));
+  MOCK_METHOD(bool, AlignFromDelay, (size_t delay), (override));
+  MOCK_METHOD(void, AlignFromExternalDelay, (), (override));
+  MOCK_METHOD(size_t, Delay, (), (const, override));
+  MOCK_METHOD(size_t, MaxDelay, (), (const, override));
+  MOCK_METHOD(RenderBuffer*, GetRenderBuffer, (), (override));
+  MOCK_METHOD(const DownsampledRenderBuffer&,
+              GetDownsampledRenderBuffer,
+              (),
+              (const, override));
+  MOCK_METHOD(void, SetAudioBufferDelay, (int delay_ms), (override));
+  MOCK_METHOD(bool, HasReceivedBufferDelay, (), (override));
+
+ private:
+  RenderBuffer* FakeGetRenderBuffer() { return &render_buffer_; }
+  const DownsampledRenderBuffer& FakeGetDownsampledRenderBuffer() const {
+    return downsampled_render_buffer_;
+  }
+  BlockBuffer block_buffer_;
+  SpectrumBuffer spectrum_buffer_;
+  FftBuffer fft_buffer_;
+  RenderBuffer render_buffer_;
+  DownsampledRenderBuffer downsampled_render_buffer_;
+};
+
+}  // namespace test
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_MOCK_MOCK_RENDER_DELAY_BUFFER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_render_delay_controller.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_render_delay_controller.cc
new file mode 100644
index 0000000..4ae2af9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_render_delay_controller.cc
@@ -0,0 +1,20 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/mock/mock_render_delay_controller.h"
+
+namespace webrtc {
+namespace test {
+
+MockRenderDelayController::MockRenderDelayController() = default;
+MockRenderDelayController::~MockRenderDelayController() = default;
+
+}  // namespace test
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_render_delay_controller.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_render_delay_controller.h
new file mode 100644
index 0000000..67d8bae
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/mock/mock_render_delay_controller.h
@@ -0,0 +1,42 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_MOCK_MOCK_RENDER_DELAY_CONTROLLER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_MOCK_MOCK_RENDER_DELAY_CONTROLLER_H_
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/downsampled_render_buffer.h"
+#include "modules/audio_processing/aec3/render_delay_controller.h"
+#include "test/gmock.h"
+
+namespace webrtc {
+namespace test {
+
+class MockRenderDelayController : public RenderDelayController {
+ public:
+  MockRenderDelayController();
+  virtual ~MockRenderDelayController();
+
+  MOCK_METHOD(void, Reset, (bool reset_delay_statistics), (override));
+  MOCK_METHOD(void, LogRenderCall, (), (override));
+  MOCK_METHOD(absl::optional<DelayEstimate>,
+              GetDelay,
+              (const DownsampledRenderBuffer& render_buffer,
+               size_t render_delay_buffer_delay,
+               const std::vector<std::vector<float>>& capture),
+              (override));
+  MOCK_METHOD(bool, HasClockdrift, (), (const, override));
+};
+
+}  // namespace test
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_MOCK_MOCK_RENDER_DELAY_CONTROLLER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/moving_average.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/moving_average.cc
new file mode 100644
index 0000000..7a81ee8
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/moving_average.cc
@@ -0,0 +1,60 @@
+
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/moving_average.h"
+
+#include <algorithm>
+#include <functional>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace aec3 {
+
+MovingAverage::MovingAverage(size_t num_elem, size_t mem_len)
+    : num_elem_(num_elem),
+      mem_len_(mem_len - 1),
+      scaling_(1.0f / static_cast<float>(mem_len)),
+      memory_(num_elem * mem_len_, 0.f),
+      mem_index_(0) {
+  RTC_DCHECK(num_elem_ > 0);
+  RTC_DCHECK(mem_len > 0);
+}
+
+MovingAverage::~MovingAverage() = default;
+
+void MovingAverage::Average(rtc::ArrayView<const float> input,
+                            rtc::ArrayView<float> output) {
+  RTC_DCHECK(input.size() == num_elem_);
+  RTC_DCHECK(output.size() == num_elem_);
+
+  // Sum all contributions.
+  std::copy(input.begin(), input.end(), output.begin());
+  for (auto i = memory_.begin(); i < memory_.end(); i += num_elem_) {
+    std::transform(i, i + num_elem_, output.begin(), output.begin(),
+                   std::plus<float>());
+  }
+
+  // Divide by mem_len_.
+  for (float& o : output) {
+    o *= scaling_;
+  }
+
+  // Update memory.
+  if (mem_len_ > 0) {
+    std::copy(input.begin(), input.end(),
+              memory_.begin() + mem_index_ * num_elem_);
+    mem_index_ = (mem_index_ + 1) % mem_len_;
+  }
+}
+
+}  // namespace aec3
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/moving_average.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/moving_average.h
new file mode 100644
index 0000000..913d785
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/moving_average.h
@@ -0,0 +1,45 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_MOVING_AVERAGE_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_MOVING_AVERAGE_H_
+
+#include <stddef.h>
+
+#include <vector>
+
+#include "api/array_view.h"
+
+namespace webrtc {
+namespace aec3 {
+
+class MovingAverage {
+ public:
+  // Creates an instance of MovingAverage that accepts inputs of length num_elem
+  // and averages over mem_len inputs.
+  MovingAverage(size_t num_elem, size_t mem_len);
+  ~MovingAverage();
+
+  // Computes the average of input and mem_len-1 previous inputs and stores the
+  // result in output.
+  void Average(rtc::ArrayView<const float> input, rtc::ArrayView<float> output);
+
+ private:
+  const size_t num_elem_;
+  const size_t mem_len_;
+  const float scaling_;
+  std::vector<float> memory_;
+  size_t mem_index_;
+};
+
+}  // namespace aec3
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_MOVING_AVERAGE_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/moving_average_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/moving_average_unittest.cc
new file mode 100644
index 0000000..84ba9cb
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/moving_average_unittest.cc
@@ -0,0 +1,89 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/moving_average.h"
+
+#include "test/gtest.h"
+
+namespace webrtc {
+
+TEST(MovingAverage, Average) {
+  constexpr size_t num_elem = 4;
+  constexpr size_t mem_len = 3;
+  constexpr float e = 1e-6f;
+  aec3::MovingAverage ma(num_elem, mem_len);
+  std::array<float, num_elem> data1 = {1, 2, 3, 4};
+  std::array<float, num_elem> data2 = {5, 1, 9, 7};
+  std::array<float, num_elem> data3 = {3, 3, 5, 6};
+  std::array<float, num_elem> data4 = {8, 4, 2, 1};
+  std::array<float, num_elem> output;
+
+  ma.Average(data1, output);
+  EXPECT_NEAR(output[0], data1[0] / 3.0f, e);
+  EXPECT_NEAR(output[1], data1[1] / 3.0f, e);
+  EXPECT_NEAR(output[2], data1[2] / 3.0f, e);
+  EXPECT_NEAR(output[3], data1[3] / 3.0f, e);
+
+  ma.Average(data2, output);
+  EXPECT_NEAR(output[0], (data1[0] + data2[0]) / 3.0f, e);
+  EXPECT_NEAR(output[1], (data1[1] + data2[1]) / 3.0f, e);
+  EXPECT_NEAR(output[2], (data1[2] + data2[2]) / 3.0f, e);
+  EXPECT_NEAR(output[3], (data1[3] + data2[3]) / 3.0f, e);
+
+  ma.Average(data3, output);
+  EXPECT_NEAR(output[0], (data1[0] + data2[0] + data3[0]) / 3.0f, e);
+  EXPECT_NEAR(output[1], (data1[1] + data2[1] + data3[1]) / 3.0f, e);
+  EXPECT_NEAR(output[2], (data1[2] + data2[2] + data3[2]) / 3.0f, e);
+  EXPECT_NEAR(output[3], (data1[3] + data2[3] + data3[3]) / 3.0f, e);
+
+  ma.Average(data4, output);
+  EXPECT_NEAR(output[0], (data2[0] + data3[0] + data4[0]) / 3.0f, e);
+  EXPECT_NEAR(output[1], (data2[1] + data3[1] + data4[1]) / 3.0f, e);
+  EXPECT_NEAR(output[2], (data2[2] + data3[2] + data4[2]) / 3.0f, e);
+  EXPECT_NEAR(output[3], (data2[3] + data3[3] + data4[3]) / 3.0f, e);
+}
+
+TEST(MovingAverage, PassThrough) {
+  constexpr size_t num_elem = 4;
+  constexpr size_t mem_len = 1;
+  constexpr float e = 1e-6f;
+  aec3::MovingAverage ma(num_elem, mem_len);
+  std::array<float, num_elem> data1 = {1, 2, 3, 4};
+  std::array<float, num_elem> data2 = {5, 1, 9, 7};
+  std::array<float, num_elem> data3 = {3, 3, 5, 6};
+  std::array<float, num_elem> data4 = {8, 4, 2, 1};
+  std::array<float, num_elem> output;
+
+  ma.Average(data1, output);
+  EXPECT_NEAR(output[0], data1[0], e);
+  EXPECT_NEAR(output[1], data1[1], e);
+  EXPECT_NEAR(output[2], data1[2], e);
+  EXPECT_NEAR(output[3], data1[3], e);
+
+  ma.Average(data2, output);
+  EXPECT_NEAR(output[0], data2[0], e);
+  EXPECT_NEAR(output[1], data2[1], e);
+  EXPECT_NEAR(output[2], data2[2], e);
+  EXPECT_NEAR(output[3], data2[3], e);
+
+  ma.Average(data3, output);
+  EXPECT_NEAR(output[0], data3[0], e);
+  EXPECT_NEAR(output[1], data3[1], e);
+  EXPECT_NEAR(output[2], data3[2], e);
+  EXPECT_NEAR(output[3], data3[3], e);
+
+  ma.Average(data4, output);
+  EXPECT_NEAR(output[0], data4[0], e);
+  EXPECT_NEAR(output[1], data4[1], e);
+  EXPECT_NEAR(output[2], data4[2], e);
+  EXPECT_NEAR(output[3], data4[3], e);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/nearend_detector.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/nearend_detector.h
new file mode 100644
index 0000000..0d8a06b
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/nearend_detector.h
@@ -0,0 +1,42 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_NEAREND_DETECTOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_NEAREND_DETECTOR_H_
+
+#include <vector>
+
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+
+namespace webrtc {
+// Class for selecting whether the suppressor is in the nearend or echo state.
+class NearendDetector {
+ public:
+  virtual ~NearendDetector() {}
+
+  // Returns whether the current state is the nearend state.
+  virtual bool IsNearendState() const = 0;
+
+  // Updates the state selection based on latest spectral estimates.
+  virtual void Update(
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+          nearend_spectrum,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+          residual_echo_spectrum,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+          comfort_noise_spectrum,
+      bool initial_state) = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_NEAREND_DETECTOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/refined_filter_update_gain.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/refined_filter_update_gain.cc
new file mode 100644
index 0000000..db5203d
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/refined_filter_update_gain.cc
@@ -0,0 +1,175 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/refined_filter_update_gain.h"
+
+#include <algorithm>
+#include <functional>
+
+#include "modules/audio_processing/aec3/adaptive_fir_filter.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/echo_path_variability.h"
+#include "modules/audio_processing/aec3/fft_data.h"
+#include "modules/audio_processing/aec3/render_signal_analyzer.h"
+#include "modules/audio_processing/aec3/subtractor_output.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/atomic_ops.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+
+constexpr float kHErrorInitial = 10000.f;
+constexpr int kPoorExcitationCounterInitial = 1000;
+
+}  // namespace
+
+int RefinedFilterUpdateGain::instance_count_ = 0;
+
+RefinedFilterUpdateGain::RefinedFilterUpdateGain(
+    const EchoCanceller3Config::Filter::RefinedConfiguration& config,
+    size_t config_change_duration_blocks)
+    : data_dumper_(
+          new ApmDataDumper(rtc::AtomicOps::Increment(&instance_count_))),
+      config_change_duration_blocks_(
+          static_cast<int>(config_change_duration_blocks)),
+      poor_excitation_counter_(kPoorExcitationCounterInitial) {
+  SetConfig(config, true);
+  H_error_.fill(kHErrorInitial);
+  RTC_DCHECK_LT(0, config_change_duration_blocks_);
+  one_by_config_change_duration_blocks_ = 1.f / config_change_duration_blocks_;
+}
+
+RefinedFilterUpdateGain::~RefinedFilterUpdateGain() {}
+
+void RefinedFilterUpdateGain::HandleEchoPathChange(
+    const EchoPathVariability& echo_path_variability) {
+  if (echo_path_variability.gain_change) {
+    // TODO(bugs.webrtc.org/9526) Handle gain changes.
+  }
+
+  if (echo_path_variability.delay_change !=
+      EchoPathVariability::DelayAdjustment::kNone) {
+    H_error_.fill(kHErrorInitial);
+  }
+
+  if (!echo_path_variability.gain_change) {
+    poor_excitation_counter_ = kPoorExcitationCounterInitial;
+    call_counter_ = 0;
+  }
+}
+
+void RefinedFilterUpdateGain::Compute(
+    const std::array<float, kFftLengthBy2Plus1>& render_power,
+    const RenderSignalAnalyzer& render_signal_analyzer,
+    const SubtractorOutput& subtractor_output,
+    rtc::ArrayView<const float> erl,
+    size_t size_partitions,
+    bool saturated_capture_signal,
+    bool disallow_leakage_diverged,
+    FftData* gain_fft) {
+  RTC_DCHECK(gain_fft);
+  // Introducing shorter notation to improve readability.
+  const FftData& E_refined = subtractor_output.E_refined;
+  const auto& E2_refined = subtractor_output.E2_refined;
+  const auto& E2_coarse = subtractor_output.E2_coarse;
+  FftData* G = gain_fft;
+  const auto& X2 = render_power;
+
+  ++call_counter_;
+
+  UpdateCurrentConfig();
+
+  if (render_signal_analyzer.PoorSignalExcitation()) {
+    poor_excitation_counter_ = 0;
+  }
+
+  // Do not update the filter if the render is not sufficiently excited.
+  if (++poor_excitation_counter_ < size_partitions ||
+      saturated_capture_signal || call_counter_ <= size_partitions) {
+    G->re.fill(0.f);
+    G->im.fill(0.f);
+  } else {
+    // Corresponds to WGN of power -39 dBFS.
+    std::array<float, kFftLengthBy2Plus1> mu;
+    // mu = H_error / (0.5* H_error* X2 + n * E2).
+    for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+      if (X2[k] >= current_config_.noise_gate) {
+        mu[k] = H_error_[k] /
+                (0.5f * H_error_[k] * X2[k] + size_partitions * E2_refined[k]);
+      } else {
+        mu[k] = 0.f;
+      }
+    }
+
+    // Avoid updating the filter close to narrow bands in the render signals.
+    render_signal_analyzer.MaskRegionsAroundNarrowBands(&mu);
+
+    // H_error = H_error - 0.5 * mu * X2 * H_error.
+    for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+      H_error_[k] -= 0.5f * mu[k] * X2[k] * H_error_[k];
+    }
+
+    // G = mu * E.
+    for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+      G->re[k] = mu[k] * E_refined.re[k];
+      G->im[k] = mu[k] * E_refined.im[k];
+    }
+  }
+
+  // H_error = H_error + factor * erl.
+  for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+    if (E2_refined[k] <= E2_coarse[k] || disallow_leakage_diverged) {
+      H_error_[k] += current_config_.leakage_converged * erl[k];
+    } else {
+      H_error_[k] += current_config_.leakage_diverged * erl[k];
+    }
+
+    H_error_[k] = std::max(H_error_[k], current_config_.error_floor);
+    H_error_[k] = std::min(H_error_[k], current_config_.error_ceil);
+  }
+
+  data_dumper_->DumpRaw("aec3_refined_gain_H_error", H_error_);
+}
+
+void RefinedFilterUpdateGain::UpdateCurrentConfig() {
+  RTC_DCHECK_GE(config_change_duration_blocks_, config_change_counter_);
+  if (config_change_counter_ > 0) {
+    if (--config_change_counter_ > 0) {
+      auto average = [](float from, float to, float from_weight) {
+        return from * from_weight + to * (1.f - from_weight);
+      };
+
+      float change_factor =
+          config_change_counter_ * one_by_config_change_duration_blocks_;
+
+      current_config_.leakage_converged =
+          average(old_target_config_.leakage_converged,
+                  target_config_.leakage_converged, change_factor);
+      current_config_.leakage_diverged =
+          average(old_target_config_.leakage_diverged,
+                  target_config_.leakage_diverged, change_factor);
+      current_config_.error_floor =
+          average(old_target_config_.error_floor, target_config_.error_floor,
+                  change_factor);
+      current_config_.error_ceil =
+          average(old_target_config_.error_ceil, target_config_.error_ceil,
+                  change_factor);
+      current_config_.noise_gate =
+          average(old_target_config_.noise_gate, target_config_.noise_gate,
+                  change_factor);
+    } else {
+      current_config_ = old_target_config_ = target_config_;
+    }
+  }
+  RTC_DCHECK_LE(0, config_change_counter_);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/refined_filter_update_gain.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/refined_filter_update_gain.h
new file mode 100644
index 0000000..ae4fe84
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/refined_filter_update_gain.h
@@ -0,0 +1,90 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_REFINED_FILTER_UPDATE_GAIN_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_REFINED_FILTER_UPDATE_GAIN_H_
+
+#include <stddef.h>
+
+#include <array>
+#include <memory>
+
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+
+namespace webrtc {
+
+class AdaptiveFirFilter;
+class ApmDataDumper;
+struct EchoPathVariability;
+struct FftData;
+class RenderSignalAnalyzer;
+struct SubtractorOutput;
+
+// Provides functionality for  computing the adaptive gain for the refined
+// filter.
+class RefinedFilterUpdateGain {
+ public:
+  RefinedFilterUpdateGain(
+      const EchoCanceller3Config::Filter::RefinedConfiguration& config,
+      size_t config_change_duration_blocks);
+  ~RefinedFilterUpdateGain();
+
+  RefinedFilterUpdateGain(const RefinedFilterUpdateGain&) = delete;
+  RefinedFilterUpdateGain& operator=(const RefinedFilterUpdateGain&) = delete;
+
+  // Takes action in the case of a known echo path change.
+  void HandleEchoPathChange(const EchoPathVariability& echo_path_variability);
+
+  // Computes the gain.
+  void Compute(const std::array<float, kFftLengthBy2Plus1>& render_power,
+               const RenderSignalAnalyzer& render_signal_analyzer,
+               const SubtractorOutput& subtractor_output,
+               rtc::ArrayView<const float> erl,
+               size_t size_partitions,
+               bool saturated_capture_signal,
+               bool disallow_leakage_diverged,
+               FftData* gain_fft);
+
+  // Sets a new config.
+  void SetConfig(
+      const EchoCanceller3Config::Filter::RefinedConfiguration& config,
+      bool immediate_effect) {
+    if (immediate_effect) {
+      old_target_config_ = current_config_ = target_config_ = config;
+      config_change_counter_ = 0;
+    } else {
+      old_target_config_ = current_config_;
+      target_config_ = config;
+      config_change_counter_ = config_change_duration_blocks_;
+    }
+  }
+
+ private:
+  static int instance_count_;
+  std::unique_ptr<ApmDataDumper> data_dumper_;
+  const int config_change_duration_blocks_;
+  float one_by_config_change_duration_blocks_;
+  EchoCanceller3Config::Filter::RefinedConfiguration current_config_;
+  EchoCanceller3Config::Filter::RefinedConfiguration target_config_;
+  EchoCanceller3Config::Filter::RefinedConfiguration old_target_config_;
+  std::array<float, kFftLengthBy2Plus1> H_error_;
+  size_t poor_excitation_counter_;
+  size_t call_counter_ = 0;
+  int config_change_counter_ = 0;
+
+  // Updates the current config towards the target config.
+  void UpdateCurrentConfig();
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_REFINED_FILTER_UPDATE_GAIN_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/refined_filter_update_gain_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/refined_filter_update_gain_unittest.cc
new file mode 100644
index 0000000..6fce858
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/refined_filter_update_gain_unittest.cc
@@ -0,0 +1,394 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/refined_filter_update_gain.h"
+
+#include <algorithm>
+#include <numeric>
+#include <string>
+#include <vector>
+
+#include "modules/audio_processing/aec3/adaptive_fir_filter.h"
+#include "modules/audio_processing/aec3/adaptive_fir_filter_erl.h"
+#include "modules/audio_processing/aec3/aec_state.h"
+#include "modules/audio_processing/aec3/coarse_filter_update_gain.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "modules/audio_processing/aec3/render_signal_analyzer.h"
+#include "modules/audio_processing/aec3/subtractor_output.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "modules/audio_processing/test/echo_canceller_test_tools.h"
+#include "rtc_base/numerics/safe_minmax.h"
+#include "rtc_base/random.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace {
+
+// Method for performing the simulations needed to test the refined filter
+// update gain functionality.
+void RunFilterUpdateTest(int num_blocks_to_process,
+                         size_t delay_samples,
+                         int filter_length_blocks,
+                         const std::vector<int>& blocks_with_echo_path_changes,
+                         const std::vector<int>& blocks_with_saturation,
+                         bool use_silent_render_in_second_half,
+                         std::array<float, kBlockSize>* e_last_block,
+                         std::array<float, kBlockSize>* y_last_block,
+                         FftData* G_last_block) {
+  ApmDataDumper data_dumper(42);
+  Aec3Optimization optimization = DetectOptimization();
+  constexpr size_t kNumRenderChannels = 1;
+  constexpr size_t kNumCaptureChannels = 1;
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+
+  EchoCanceller3Config config;
+  config.filter.refined.length_blocks = filter_length_blocks;
+  config.filter.coarse.length_blocks = filter_length_blocks;
+  AdaptiveFirFilter refined_filter(
+      config.filter.refined.length_blocks, config.filter.refined.length_blocks,
+      config.filter.config_change_duration_blocks, kNumRenderChannels,
+      optimization, &data_dumper);
+  AdaptiveFirFilter coarse_filter(
+      config.filter.coarse.length_blocks, config.filter.coarse.length_blocks,
+      config.filter.config_change_duration_blocks, kNumRenderChannels,
+      optimization, &data_dumper);
+  std::vector<std::vector<std::array<float, kFftLengthBy2Plus1>>> H2(
+      kNumCaptureChannels, std::vector<std::array<float, kFftLengthBy2Plus1>>(
+                               refined_filter.max_filter_size_partitions(),
+                               std::array<float, kFftLengthBy2Plus1>()));
+  for (auto& H2_ch : H2) {
+    for (auto& H2_k : H2_ch) {
+      H2_k.fill(0.f);
+    }
+  }
+  std::vector<std::vector<float>> h(
+      kNumCaptureChannels,
+      std::vector<float>(
+          GetTimeDomainLength(refined_filter.max_filter_size_partitions()),
+          0.f));
+
+  Aec3Fft fft;
+  std::array<float, kBlockSize> x_old;
+  x_old.fill(0.f);
+  CoarseFilterUpdateGain coarse_gain(
+      config.filter.coarse, config.filter.config_change_duration_blocks);
+  RefinedFilterUpdateGain refined_gain(
+      config.filter.refined, config.filter.config_change_duration_blocks);
+  Random random_generator(42U);
+  std::vector<std::vector<std::vector<float>>> x(
+      kNumBands, std::vector<std::vector<float>>(
+                     kNumRenderChannels, std::vector<float>(kBlockSize, 0.f)));
+  std::vector<float> y(kBlockSize, 0.f);
+  config.delay.default_delay = 1;
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+      RenderDelayBuffer::Create(config, kSampleRateHz, kNumRenderChannels));
+  AecState aec_state(config, kNumCaptureChannels);
+  RenderSignalAnalyzer render_signal_analyzer(config);
+  absl::optional<DelayEstimate> delay_estimate;
+  std::array<float, kFftLength> s_scratch;
+  std::array<float, kBlockSize> s;
+  FftData S;
+  FftData G;
+  std::vector<SubtractorOutput> output(kNumCaptureChannels);
+  for (auto& subtractor_output : output) {
+    subtractor_output.Reset();
+  }
+  FftData& E_refined = output[0].E_refined;
+  FftData E_coarse;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> Y2(kNumCaptureChannels);
+  std::vector<std::array<float, kFftLengthBy2Plus1>> E2_refined(
+      kNumCaptureChannels);
+  std::array<float, kBlockSize>& e_refined = output[0].e_refined;
+  std::array<float, kBlockSize>& e_coarse = output[0].e_coarse;
+  for (auto& Y2_ch : Y2) {
+    Y2_ch.fill(0.f);
+  }
+
+  constexpr float kScale = 1.0f / kFftLengthBy2;
+
+  DelayBuffer<float> delay_buffer(delay_samples);
+  for (int k = 0; k < num_blocks_to_process; ++k) {
+    // Handle echo path changes.
+    if (std::find(blocks_with_echo_path_changes.begin(),
+                  blocks_with_echo_path_changes.end(),
+                  k) != blocks_with_echo_path_changes.end()) {
+      refined_filter.HandleEchoPathChange();
+    }
+
+    // Handle saturation.
+    const bool saturation =
+        std::find(blocks_with_saturation.begin(), blocks_with_saturation.end(),
+                  k) != blocks_with_saturation.end();
+
+    // Create the render signal.
+    if (use_silent_render_in_second_half && k > num_blocks_to_process / 2) {
+      for (size_t band = 0; band < x.size(); ++band) {
+        for (size_t channel = 0; channel < x[band].size(); ++channel) {
+          std::fill(x[band][channel].begin(), x[band][channel].end(), 0.f);
+        }
+      }
+    } else {
+      for (size_t band = 0; band < x.size(); ++band) {
+        for (size_t channel = 0; channel < x[band].size(); ++channel) {
+          RandomizeSampleVector(&random_generator, x[band][channel]);
+        }
+      }
+    }
+    delay_buffer.Delay(x[0][0], y);
+
+    render_delay_buffer->Insert(x);
+    if (k == 0) {
+      render_delay_buffer->Reset();
+    }
+    render_delay_buffer->PrepareCaptureProcessing();
+
+    render_signal_analyzer.Update(*render_delay_buffer->GetRenderBuffer(),
+                                  aec_state.MinDirectPathFilterDelay());
+
+    // Apply the refined filter.
+    refined_filter.Filter(*render_delay_buffer->GetRenderBuffer(), &S);
+    fft.Ifft(S, &s_scratch);
+    std::transform(y.begin(), y.end(), s_scratch.begin() + kFftLengthBy2,
+                   e_refined.begin(),
+                   [&](float a, float b) { return a - b * kScale; });
+    std::for_each(e_refined.begin(), e_refined.end(),
+                  [](float& a) { a = rtc::SafeClamp(a, -32768.f, 32767.f); });
+    fft.ZeroPaddedFft(e_refined, Aec3Fft::Window::kRectangular, &E_refined);
+    for (size_t k = 0; k < kBlockSize; ++k) {
+      s[k] = kScale * s_scratch[k + kFftLengthBy2];
+    }
+
+    // Apply the coarse filter.
+    coarse_filter.Filter(*render_delay_buffer->GetRenderBuffer(), &S);
+    fft.Ifft(S, &s_scratch);
+    std::transform(y.begin(), y.end(), s_scratch.begin() + kFftLengthBy2,
+                   e_coarse.begin(),
+                   [&](float a, float b) { return a - b * kScale; });
+    std::for_each(e_coarse.begin(), e_coarse.end(),
+                  [](float& a) { a = rtc::SafeClamp(a, -32768.f, 32767.f); });
+    fft.ZeroPaddedFft(e_coarse, Aec3Fft::Window::kRectangular, &E_coarse);
+
+    // Compute spectra for future use.
+    E_refined.Spectrum(Aec3Optimization::kNone, output[0].E2_refined);
+    E_coarse.Spectrum(Aec3Optimization::kNone, output[0].E2_coarse);
+
+    // Adapt the coarse filter.
+    std::array<float, kFftLengthBy2Plus1> render_power;
+    render_delay_buffer->GetRenderBuffer()->SpectralSum(
+        coarse_filter.SizePartitions(), &render_power);
+    coarse_gain.Compute(render_power, render_signal_analyzer, E_coarse,
+                        coarse_filter.SizePartitions(), saturation, &G);
+    coarse_filter.Adapt(*render_delay_buffer->GetRenderBuffer(), G);
+
+    // Adapt the refined filter
+    render_delay_buffer->GetRenderBuffer()->SpectralSum(
+        refined_filter.SizePartitions(), &render_power);
+
+    std::array<float, kFftLengthBy2Plus1> erl;
+    ComputeErl(optimization, H2[0], erl);
+    refined_gain.Compute(render_power, render_signal_analyzer, output[0], erl,
+                         refined_filter.SizePartitions(), saturation, false,
+                         &G);
+    refined_filter.Adapt(*render_delay_buffer->GetRenderBuffer(), G, &h[0]);
+
+    // Update the delay.
+    aec_state.HandleEchoPathChange(EchoPathVariability(
+        false, EchoPathVariability::DelayAdjustment::kNone, false));
+    refined_filter.ComputeFrequencyResponse(&H2[0]);
+    std::copy(output[0].E2_refined.begin(), output[0].E2_refined.end(),
+              E2_refined[0].begin());
+    aec_state.Update(delay_estimate, H2, h,
+                     *render_delay_buffer->GetRenderBuffer(), E2_refined, Y2,
+                     output);
+  }
+
+  std::copy(e_refined.begin(), e_refined.end(), e_last_block->begin());
+  std::copy(y.begin(), y.end(), y_last_block->begin());
+  std::copy(G.re.begin(), G.re.end(), G_last_block->re.begin());
+  std::copy(G.im.begin(), G.im.end(), G_last_block->im.begin());
+}
+
+std::string ProduceDebugText(int filter_length_blocks) {
+  rtc::StringBuilder ss;
+  ss << "Length: " << filter_length_blocks;
+  return ss.Release();
+}
+
+std::string ProduceDebugText(size_t delay, int filter_length_blocks) {
+  rtc::StringBuilder ss;
+  ss << "Delay: " << delay << ", ";
+  ss << ProduceDebugText(filter_length_blocks);
+  return ss.Release();
+}
+
+}  // namespace
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+// Verifies that the check for non-null output gain parameter works.
+TEST(RefinedFilterUpdateGainDeathTest, NullDataOutputGain) {
+  ApmDataDumper data_dumper(42);
+  EchoCanceller3Config config;
+  RenderSignalAnalyzer analyzer(config);
+  SubtractorOutput output;
+  RefinedFilterUpdateGain gain(config.filter.refined,
+                               config.filter.config_change_duration_blocks);
+  std::array<float, kFftLengthBy2Plus1> render_power;
+  render_power.fill(0.f);
+  std::array<float, kFftLengthBy2Plus1> erl;
+  erl.fill(0.f);
+  EXPECT_DEATH(
+      gain.Compute(render_power, analyzer, output, erl,
+                   config.filter.refined.length_blocks, false, false, nullptr),
+      "");
+}
+
+#endif
+
+// Verifies that the gain formed causes the filter using it to converge.
+TEST(RefinedFilterUpdateGain, GainCausesFilterToConverge) {
+  std::vector<int> blocks_with_echo_path_changes;
+  std::vector<int> blocks_with_saturation;
+  for (size_t filter_length_blocks : {12, 20, 30}) {
+    for (size_t delay_samples : {0, 64, 150, 200, 301}) {
+      SCOPED_TRACE(ProduceDebugText(delay_samples, filter_length_blocks));
+
+      std::array<float, kBlockSize> e;
+      std::array<float, kBlockSize> y;
+      FftData G;
+
+      RunFilterUpdateTest(600, delay_samples, filter_length_blocks,
+                          blocks_with_echo_path_changes, blocks_with_saturation,
+                          false, &e, &y, &G);
+
+      // Verify that the refined filter is able to perform well.
+      // Use different criteria to take overmodelling into account.
+      if (filter_length_blocks == 12) {
+        EXPECT_LT(1000 * std::inner_product(e.begin(), e.end(), e.begin(), 0.f),
+                  std::inner_product(y.begin(), y.end(), y.begin(), 0.f));
+      } else {
+        EXPECT_LT(std::inner_product(e.begin(), e.end(), e.begin(), 0.f),
+                  std::inner_product(y.begin(), y.end(), y.begin(), 0.f));
+      }
+    }
+  }
+}
+
+// Verifies that the magnitude of the gain on average decreases for a
+// persistently exciting signal.
+TEST(RefinedFilterUpdateGain, DecreasingGain) {
+  std::vector<int> blocks_with_echo_path_changes;
+  std::vector<int> blocks_with_saturation;
+
+  std::array<float, kBlockSize> e;
+  std::array<float, kBlockSize> y;
+  FftData G_a;
+  FftData G_b;
+  FftData G_c;
+  std::array<float, kFftLengthBy2Plus1> G_a_power;
+  std::array<float, kFftLengthBy2Plus1> G_b_power;
+  std::array<float, kFftLengthBy2Plus1> G_c_power;
+
+  RunFilterUpdateTest(250, 65, 12, blocks_with_echo_path_changes,
+                      blocks_with_saturation, false, &e, &y, &G_a);
+  RunFilterUpdateTest(500, 65, 12, blocks_with_echo_path_changes,
+                      blocks_with_saturation, false, &e, &y, &G_b);
+  RunFilterUpdateTest(750, 65, 12, blocks_with_echo_path_changes,
+                      blocks_with_saturation, false, &e, &y, &G_c);
+
+  G_a.Spectrum(Aec3Optimization::kNone, G_a_power);
+  G_b.Spectrum(Aec3Optimization::kNone, G_b_power);
+  G_c.Spectrum(Aec3Optimization::kNone, G_c_power);
+
+  EXPECT_GT(std::accumulate(G_a_power.begin(), G_a_power.end(), 0.),
+            std::accumulate(G_b_power.begin(), G_b_power.end(), 0.));
+
+  EXPECT_GT(std::accumulate(G_b_power.begin(), G_b_power.end(), 0.),
+            std::accumulate(G_c_power.begin(), G_c_power.end(), 0.));
+}
+
+// Verifies that the gain is zero when there is saturation and that the internal
+// error estimates cause the gain to increase after a period of saturation.
+TEST(RefinedFilterUpdateGain, SaturationBehavior) {
+  std::vector<int> blocks_with_echo_path_changes;
+  std::vector<int> blocks_with_saturation;
+  for (int k = 99; k < 200; ++k) {
+    blocks_with_saturation.push_back(k);
+  }
+
+  for (size_t filter_length_blocks : {12, 20, 30}) {
+    SCOPED_TRACE(ProduceDebugText(filter_length_blocks));
+    std::array<float, kBlockSize> e;
+    std::array<float, kBlockSize> y;
+    FftData G_a;
+    FftData G_b;
+    FftData G_a_ref;
+    G_a_ref.re.fill(0.f);
+    G_a_ref.im.fill(0.f);
+
+    std::array<float, kFftLengthBy2Plus1> G_a_power;
+    std::array<float, kFftLengthBy2Plus1> G_b_power;
+
+    RunFilterUpdateTest(100, 65, filter_length_blocks,
+                        blocks_with_echo_path_changes, blocks_with_saturation,
+                        false, &e, &y, &G_a);
+
+    EXPECT_EQ(G_a_ref.re, G_a.re);
+    EXPECT_EQ(G_a_ref.im, G_a.im);
+
+    RunFilterUpdateTest(99, 65, filter_length_blocks,
+                        blocks_with_echo_path_changes, blocks_with_saturation,
+                        false, &e, &y, &G_a);
+    RunFilterUpdateTest(201, 65, filter_length_blocks,
+                        blocks_with_echo_path_changes, blocks_with_saturation,
+                        false, &e, &y, &G_b);
+
+    G_a.Spectrum(Aec3Optimization::kNone, G_a_power);
+    G_b.Spectrum(Aec3Optimization::kNone, G_b_power);
+
+    EXPECT_LT(std::accumulate(G_a_power.begin(), G_a_power.end(), 0.),
+              std::accumulate(G_b_power.begin(), G_b_power.end(), 0.));
+  }
+}
+
+// Verifies that the gain increases after an echo path change.
+// TODO(peah): Correct and reactivate this test.
+TEST(RefinedFilterUpdateGain, DISABLED_EchoPathChangeBehavior) {
+  for (size_t filter_length_blocks : {12, 20, 30}) {
+    SCOPED_TRACE(ProduceDebugText(filter_length_blocks));
+    std::vector<int> blocks_with_echo_path_changes;
+    std::vector<int> blocks_with_saturation;
+    blocks_with_echo_path_changes.push_back(99);
+
+    std::array<float, kBlockSize> e;
+    std::array<float, kBlockSize> y;
+    FftData G_a;
+    FftData G_b;
+    std::array<float, kFftLengthBy2Plus1> G_a_power;
+    std::array<float, kFftLengthBy2Plus1> G_b_power;
+
+    RunFilterUpdateTest(100, 65, filter_length_blocks,
+                        blocks_with_echo_path_changes, blocks_with_saturation,
+                        false, &e, &y, &G_a);
+    RunFilterUpdateTest(101, 65, filter_length_blocks,
+                        blocks_with_echo_path_changes, blocks_with_saturation,
+                        false, &e, &y, &G_b);
+
+    G_a.Spectrum(Aec3Optimization::kNone, G_a_power);
+    G_b.Spectrum(Aec3Optimization::kNone, G_b_power);
+
+    EXPECT_LT(std::accumulate(G_a_power.begin(), G_a_power.end(), 0.),
+              std::accumulate(G_b_power.begin(), G_b_power.end(), 0.));
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_buffer.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_buffer.cc
new file mode 100644
index 0000000..60ea69c
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_buffer.cc
@@ -0,0 +1,80 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/render_buffer.h"
+
+#include <algorithm>
+#include <functional>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+RenderBuffer::RenderBuffer(BlockBuffer* block_buffer,
+                           SpectrumBuffer* spectrum_buffer,
+                           FftBuffer* fft_buffer)
+    : block_buffer_(block_buffer),
+      spectrum_buffer_(spectrum_buffer),
+      fft_buffer_(fft_buffer) {
+  RTC_DCHECK(block_buffer_);
+  RTC_DCHECK(spectrum_buffer_);
+  RTC_DCHECK(fft_buffer_);
+  RTC_DCHECK_EQ(block_buffer_->buffer.size(), fft_buffer_->buffer.size());
+  RTC_DCHECK_EQ(spectrum_buffer_->buffer.size(), fft_buffer_->buffer.size());
+  RTC_DCHECK_EQ(spectrum_buffer_->read, fft_buffer_->read);
+  RTC_DCHECK_EQ(spectrum_buffer_->write, fft_buffer_->write);
+}
+
+RenderBuffer::~RenderBuffer() = default;
+
+void RenderBuffer::SpectralSum(
+    size_t num_spectra,
+    std::array<float, kFftLengthBy2Plus1>* X2) const {
+  X2->fill(0.f);
+  int position = spectrum_buffer_->read;
+  for (size_t j = 0; j < num_spectra; ++j) {
+    for (const auto& channel_spectrum : spectrum_buffer_->buffer[position]) {
+      std::transform(X2->begin(), X2->end(), channel_spectrum.begin(),
+                     X2->begin(), std::plus<float>());
+    }
+    position = spectrum_buffer_->IncIndex(position);
+  }
+}
+
+void RenderBuffer::SpectralSums(
+    size_t num_spectra_shorter,
+    size_t num_spectra_longer,
+    std::array<float, kFftLengthBy2Plus1>* X2_shorter,
+    std::array<float, kFftLengthBy2Plus1>* X2_longer) const {
+  RTC_DCHECK_LE(num_spectra_shorter, num_spectra_longer);
+  X2_shorter->fill(0.f);
+  int position = spectrum_buffer_->read;
+  size_t j = 0;
+  for (; j < num_spectra_shorter; ++j) {
+    for (const auto& channel_spectrum : spectrum_buffer_->buffer[position]) {
+      std::transform(X2_shorter->begin(), X2_shorter->end(),
+                     channel_spectrum.begin(), X2_shorter->begin(),
+                     std::plus<float>());
+    }
+    position = spectrum_buffer_->IncIndex(position);
+  }
+  std::copy(X2_shorter->begin(), X2_shorter->end(), X2_longer->begin());
+  for (; j < num_spectra_longer; ++j) {
+    for (const auto& channel_spectrum : spectrum_buffer_->buffer[position]) {
+      std::transform(X2_longer->begin(), X2_longer->end(),
+                     channel_spectrum.begin(), X2_longer->begin(),
+                     std::plus<float>());
+    }
+    position = spectrum_buffer_->IncIndex(position);
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_buffer.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_buffer.h
new file mode 100644
index 0000000..b8be6f5
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_buffer.h
@@ -0,0 +1,116 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_RENDER_BUFFER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_RENDER_BUFFER_H_
+
+#include <stddef.h>
+
+#include <array>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/block_buffer.h"
+#include "modules/audio_processing/aec3/fft_buffer.h"
+#include "modules/audio_processing/aec3/fft_data.h"
+#include "modules/audio_processing/aec3/spectrum_buffer.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+// Provides a buffer of the render data for the echo remover.
+class RenderBuffer {
+ public:
+  RenderBuffer(BlockBuffer* block_buffer,
+               SpectrumBuffer* spectrum_buffer,
+               FftBuffer* fft_buffer);
+
+  RenderBuffer() = delete;
+  RenderBuffer(const RenderBuffer&) = delete;
+  RenderBuffer& operator=(const RenderBuffer&) = delete;
+
+  ~RenderBuffer();
+
+  // Get a block.
+  const std::vector<std::vector<std::vector<float>>>& Block(
+      int buffer_offset_blocks) const {
+    int position =
+        block_buffer_->OffsetIndex(block_buffer_->read, buffer_offset_blocks);
+    return block_buffer_->buffer[position];
+  }
+
+  // Get the spectrum from one of the FFTs in the buffer.
+  rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Spectrum(
+      int buffer_offset_ffts) const {
+    int position = spectrum_buffer_->OffsetIndex(spectrum_buffer_->read,
+                                                 buffer_offset_ffts);
+    return spectrum_buffer_->buffer[position];
+  }
+
+  // Returns the circular fft buffer.
+  rtc::ArrayView<const std::vector<FftData>> GetFftBuffer() const {
+    return fft_buffer_->buffer;
+  }
+
+  // Returns the current position in the circular buffer.
+  size_t Position() const {
+    RTC_DCHECK_EQ(spectrum_buffer_->read, fft_buffer_->read);
+    RTC_DCHECK_EQ(spectrum_buffer_->write, fft_buffer_->write);
+    return fft_buffer_->read;
+  }
+
+  // Returns the sum of the spectrums for a certain number of FFTs.
+  void SpectralSum(size_t num_spectra,
+                   std::array<float, kFftLengthBy2Plus1>* X2) const;
+
+  // Returns the sums of the spectrums for two numbers of FFTs.
+  void SpectralSums(size_t num_spectra_shorter,
+                    size_t num_spectra_longer,
+                    std::array<float, kFftLengthBy2Plus1>* X2_shorter,
+                    std::array<float, kFftLengthBy2Plus1>* X2_longer) const;
+
+  // Gets the recent activity seen in the render signal.
+  bool GetRenderActivity() const { return render_activity_; }
+
+  // Specifies the recent activity seen in the render signal.
+  void SetRenderActivity(bool activity) { render_activity_ = activity; }
+
+  // Returns the headroom between the write and the read positions in the
+  // buffer.
+  int Headroom() const {
+    // The write and read indices are decreased over time.
+    int headroom =
+        fft_buffer_->write < fft_buffer_->read
+            ? fft_buffer_->read - fft_buffer_->write
+            : fft_buffer_->size - fft_buffer_->write + fft_buffer_->read;
+
+    RTC_DCHECK_LE(0, headroom);
+    RTC_DCHECK_GE(fft_buffer_->size, headroom);
+
+    return headroom;
+  }
+
+  // Returns a reference to the spectrum buffer.
+  const SpectrumBuffer& GetSpectrumBuffer() const { return *spectrum_buffer_; }
+
+  // Returns a reference to the block buffer.
+  const BlockBuffer& GetBlockBuffer() const { return *block_buffer_; }
+
+ private:
+  const BlockBuffer* const block_buffer_;
+  const SpectrumBuffer* const spectrum_buffer_;
+  const FftBuffer* const fft_buffer_;
+  bool render_activity_ = false;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_RENDER_BUFFER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_buffer_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_buffer_unittest.cc
new file mode 100644
index 0000000..4559528
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_buffer_unittest.cc
@@ -0,0 +1,46 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/render_buffer.h"
+
+#include <algorithm>
+#include <functional>
+#include <vector>
+
+#include "test/gtest.h"
+
+namespace webrtc {
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+// Verifies the check for non-null fft buffer.
+TEST(RenderBufferDeathTest, NullExternalFftBuffer) {
+  BlockBuffer block_buffer(10, 3, 1, kBlockSize);
+  SpectrumBuffer spectrum_buffer(10, 1);
+  EXPECT_DEATH(RenderBuffer(&block_buffer, &spectrum_buffer, nullptr), "");
+}
+
+// Verifies the check for non-null spectrum buffer.
+TEST(RenderBufferDeathTest, NullExternalSpectrumBuffer) {
+  FftBuffer fft_buffer(10, 1);
+  BlockBuffer block_buffer(10, 3, 1, kBlockSize);
+  EXPECT_DEATH(RenderBuffer(&block_buffer, nullptr, &fft_buffer), "");
+}
+
+// Verifies the check for non-null block buffer.
+TEST(RenderBufferDeathTest, NullExternalBlockBuffer) {
+  FftBuffer fft_buffer(10, 1);
+  SpectrumBuffer spectrum_buffer(10, 1);
+  EXPECT_DEATH(RenderBuffer(nullptr, &spectrum_buffer, &fft_buffer), "");
+}
+
+#endif
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_buffer.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_buffer.cc
new file mode 100644
index 0000000..7bebc6f
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_buffer.cc
@@ -0,0 +1,523 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+
+#include <string.h>
+
+#include <algorithm>
+#include <cmath>
+#include <memory>
+#include <numeric>
+#include <vector>
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/aec3_fft.h"
+#include "modules/audio_processing/aec3/alignment_mixer.h"
+#include "modules/audio_processing/aec3/block_buffer.h"
+#include "modules/audio_processing/aec3/decimator.h"
+#include "modules/audio_processing/aec3/downsampled_render_buffer.h"
+#include "modules/audio_processing/aec3/fft_buffer.h"
+#include "modules/audio_processing/aec3/fft_data.h"
+#include "modules/audio_processing/aec3/render_buffer.h"
+#include "modules/audio_processing/aec3/spectrum_buffer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/atomic_ops.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+#include "system_wrappers/include/field_trial.h"
+
+namespace webrtc {
+namespace {
+
+bool UpdateCaptureCallCounterOnSkippedBlocks() {
+  return !field_trial::IsEnabled(
+      "WebRTC-Aec3RenderBufferCallCounterUpdateKillSwitch");
+}
+
+class RenderDelayBufferImpl final : public RenderDelayBuffer {
+ public:
+  RenderDelayBufferImpl(const EchoCanceller3Config& config,
+                        int sample_rate_hz,
+                        size_t num_render_channels);
+  RenderDelayBufferImpl() = delete;
+  ~RenderDelayBufferImpl() override;
+
+  void Reset() override;
+  BufferingEvent Insert(
+      const std::vector<std::vector<std::vector<float>>>& block) override;
+  BufferingEvent PrepareCaptureProcessing() override;
+  void HandleSkippedCaptureProcessing() override;
+  bool AlignFromDelay(size_t delay) override;
+  void AlignFromExternalDelay() override;
+  size_t Delay() const override { return ComputeDelay(); }
+  size_t MaxDelay() const override {
+    return blocks_.buffer.size() - 1 - buffer_headroom_;
+  }
+  RenderBuffer* GetRenderBuffer() override { return &echo_remover_buffer_; }
+
+  const DownsampledRenderBuffer& GetDownsampledRenderBuffer() const override {
+    return low_rate_;
+  }
+
+  int BufferLatency() const;
+  void SetAudioBufferDelay(int delay_ms) override;
+  bool HasReceivedBufferDelay() override;
+
+ private:
+  static int instance_count_;
+  std::unique_ptr<ApmDataDumper> data_dumper_;
+  const Aec3Optimization optimization_;
+  const EchoCanceller3Config config_;
+  const bool update_capture_call_counter_on_skipped_blocks_;
+  const float render_linear_amplitude_gain_;
+  const rtc::LoggingSeverity delay_log_level_;
+  size_t down_sampling_factor_;
+  const int sub_block_size_;
+  BlockBuffer blocks_;
+  SpectrumBuffer spectra_;
+  FftBuffer ffts_;
+  absl::optional<size_t> delay_;
+  RenderBuffer echo_remover_buffer_;
+  DownsampledRenderBuffer low_rate_;
+  AlignmentMixer render_mixer_;
+  Decimator render_decimator_;
+  const Aec3Fft fft_;
+  std::vector<float> render_ds_;
+  const int buffer_headroom_;
+  bool last_call_was_render_ = false;
+  int num_api_calls_in_a_row_ = 0;
+  int max_observed_jitter_ = 1;
+  int64_t capture_call_counter_ = 0;
+  int64_t render_call_counter_ = 0;
+  bool render_activity_ = false;
+  size_t render_activity_counter_ = 0;
+  absl::optional<int> external_audio_buffer_delay_;
+  bool external_audio_buffer_delay_verified_after_reset_ = false;
+  size_t min_latency_blocks_ = 0;
+  size_t excess_render_detection_counter_ = 0;
+
+  int MapDelayToTotalDelay(size_t delay) const;
+  int ComputeDelay() const;
+  void ApplyTotalDelay(int delay);
+  void InsertBlock(const std::vector<std::vector<std::vector<float>>>& block,
+                   int previous_write);
+  bool DetectActiveRender(rtc::ArrayView<const float> x) const;
+  bool DetectExcessRenderBlocks();
+  void IncrementWriteIndices();
+  void IncrementLowRateReadIndices();
+  void IncrementReadIndices();
+  bool RenderOverrun();
+  bool RenderUnderrun();
+};
+
+int RenderDelayBufferImpl::instance_count_ = 0;
+
+RenderDelayBufferImpl::RenderDelayBufferImpl(const EchoCanceller3Config& config,
+                                             int sample_rate_hz,
+                                             size_t num_render_channels)
+    : data_dumper_(
+          new ApmDataDumper(rtc::AtomicOps::Increment(&instance_count_))),
+      optimization_(DetectOptimization()),
+      config_(config),
+      update_capture_call_counter_on_skipped_blocks_(
+          UpdateCaptureCallCounterOnSkippedBlocks()),
+      render_linear_amplitude_gain_(
+          std::pow(10.0f, config_.render_levels.render_power_gain_db / 20.f)),
+      delay_log_level_(config_.delay.log_warning_on_delay_changes
+                           ? rtc::LS_WARNING
+                           : rtc::LS_VERBOSE),
+      down_sampling_factor_(config.delay.down_sampling_factor),
+      sub_block_size_(static_cast<int>(down_sampling_factor_ > 0
+                                           ? kBlockSize / down_sampling_factor_
+                                           : kBlockSize)),
+      blocks_(GetRenderDelayBufferSize(down_sampling_factor_,
+                                       config.delay.num_filters,
+                                       config.filter.refined.length_blocks),
+              NumBandsForRate(sample_rate_hz),
+              num_render_channels,
+              kBlockSize),
+      spectra_(blocks_.buffer.size(), num_render_channels),
+      ffts_(blocks_.buffer.size(), num_render_channels),
+      delay_(config_.delay.default_delay),
+      echo_remover_buffer_(&blocks_, &spectra_, &ffts_),
+      low_rate_(GetDownSampledBufferSize(down_sampling_factor_,
+                                         config.delay.num_filters)),
+      render_mixer_(num_render_channels, config.delay.render_alignment_mixing),
+      render_decimator_(down_sampling_factor_),
+      fft_(),
+      render_ds_(sub_block_size_, 0.f),
+      buffer_headroom_(config.filter.refined.length_blocks) {
+  RTC_DCHECK_EQ(blocks_.buffer.size(), ffts_.buffer.size());
+  RTC_DCHECK_EQ(spectra_.buffer.size(), ffts_.buffer.size());
+  for (size_t i = 0; i < blocks_.buffer.size(); ++i) {
+    RTC_DCHECK_EQ(blocks_.buffer[i][0].size(), ffts_.buffer[i].size());
+    RTC_DCHECK_EQ(spectra_.buffer[i].size(), ffts_.buffer[i].size());
+  }
+
+  Reset();
+}
+
+RenderDelayBufferImpl::~RenderDelayBufferImpl() = default;
+
+// Resets the buffer delays and clears the reported delays.
+void RenderDelayBufferImpl::Reset() {
+  last_call_was_render_ = false;
+  num_api_calls_in_a_row_ = 1;
+  min_latency_blocks_ = 0;
+  excess_render_detection_counter_ = 0;
+
+  // Initialize the read index to one sub-block before the write index.
+  low_rate_.read = low_rate_.OffsetIndex(low_rate_.write, sub_block_size_);
+
+  // Check for any external audio buffer delay and whether it is feasible.
+  if (external_audio_buffer_delay_) {
+    const int headroom = 2;
+    size_t audio_buffer_delay_to_set;
+    // Minimum delay is 1 (like the low-rate render buffer).
+    if (*external_audio_buffer_delay_ <= headroom) {
+      audio_buffer_delay_to_set = 1;
+    } else {
+      audio_buffer_delay_to_set = *external_audio_buffer_delay_ - headroom;
+    }
+
+    audio_buffer_delay_to_set = std::min(audio_buffer_delay_to_set, MaxDelay());
+
+    // When an external delay estimate is available, use that delay as the
+    // initial render buffer delay.
+    ApplyTotalDelay(audio_buffer_delay_to_set);
+    delay_ = ComputeDelay();
+
+    external_audio_buffer_delay_verified_after_reset_ = false;
+  } else {
+    // If an external delay estimate is not available, use that delay as the
+    // initial delay. Set the render buffer delays to the default delay.
+    ApplyTotalDelay(config_.delay.default_delay);
+
+    // Unset the delays which are set by AlignFromDelay.
+    delay_ = absl::nullopt;
+  }
+}
+
+// Inserts a new block into the render buffers.
+RenderDelayBuffer::BufferingEvent RenderDelayBufferImpl::Insert(
+    const std::vector<std::vector<std::vector<float>>>& block) {
+  ++render_call_counter_;
+  if (delay_) {
+    if (!last_call_was_render_) {
+      last_call_was_render_ = true;
+      num_api_calls_in_a_row_ = 1;
+    } else {
+      if (++num_api_calls_in_a_row_ > max_observed_jitter_) {
+        max_observed_jitter_ = num_api_calls_in_a_row_;
+        RTC_LOG_V(delay_log_level_)
+            << "New max number api jitter observed at render block "
+            << render_call_counter_ << ":  " << num_api_calls_in_a_row_
+            << " blocks";
+      }
+    }
+  }
+
+  // Increase the write indices to where the new blocks should be written.
+  const int previous_write = blocks_.write;
+  IncrementWriteIndices();
+
+  // Allow overrun and do a reset when render overrun occurrs due to more render
+  // data being inserted than capture data is received.
+  BufferingEvent event =
+      RenderOverrun() ? BufferingEvent::kRenderOverrun : BufferingEvent::kNone;
+
+  // Detect and update render activity.
+  if (!render_activity_) {
+    render_activity_counter_ += DetectActiveRender(block[0][0]) ? 1 : 0;
+    render_activity_ = render_activity_counter_ >= 20;
+  }
+
+  // Insert the new render block into the specified position.
+  InsertBlock(block, previous_write);
+
+  if (event != BufferingEvent::kNone) {
+    Reset();
+  }
+
+  return event;
+}
+
+void RenderDelayBufferImpl::HandleSkippedCaptureProcessing() {
+  if (update_capture_call_counter_on_skipped_blocks_) {
+    ++capture_call_counter_;
+  }
+}
+
+// Prepares the render buffers for processing another capture block.
+RenderDelayBuffer::BufferingEvent
+RenderDelayBufferImpl::PrepareCaptureProcessing() {
+  RenderDelayBuffer::BufferingEvent event = BufferingEvent::kNone;
+  ++capture_call_counter_;
+
+  if (delay_) {
+    if (last_call_was_render_) {
+      last_call_was_render_ = false;
+      num_api_calls_in_a_row_ = 1;
+    } else {
+      if (++num_api_calls_in_a_row_ > max_observed_jitter_) {
+        max_observed_jitter_ = num_api_calls_in_a_row_;
+        RTC_LOG_V(delay_log_level_)
+            << "New max number api jitter observed at capture block "
+            << capture_call_counter_ << ":  " << num_api_calls_in_a_row_
+            << " blocks";
+      }
+    }
+  }
+
+  if (DetectExcessRenderBlocks()) {
+    // Too many render blocks compared to capture blocks. Risk of delay ending
+    // up before the filter used by the delay estimator.
+    RTC_LOG_V(delay_log_level_)
+        << "Excess render blocks detected at block " << capture_call_counter_;
+    Reset();
+    event = BufferingEvent::kRenderOverrun;
+  } else if (RenderUnderrun()) {
+    // Don't increment the read indices of the low rate buffer if there is a
+    // render underrun.
+    RTC_LOG_V(delay_log_level_)
+        << "Render buffer underrun detected at block " << capture_call_counter_;
+    IncrementReadIndices();
+    // Incrementing the buffer index without increasing the low rate buffer
+    // index means that the delay is reduced by one.
+    if (delay_ && *delay_ > 0)
+      delay_ = *delay_ - 1;
+    event = BufferingEvent::kRenderUnderrun;
+  } else {
+    // Increment the read indices in the render buffers to point to the most
+    // recent block to use in the capture processing.
+    IncrementLowRateReadIndices();
+    IncrementReadIndices();
+  }
+
+  echo_remover_buffer_.SetRenderActivity(render_activity_);
+  if (render_activity_) {
+    render_activity_counter_ = 0;
+    render_activity_ = false;
+  }
+
+  return event;
+}
+
+// Sets the delay and returns a bool indicating whether the delay was changed.
+bool RenderDelayBufferImpl::AlignFromDelay(size_t delay) {
+  RTC_DCHECK(!config_.delay.use_external_delay_estimator);
+  if (!external_audio_buffer_delay_verified_after_reset_ &&
+      external_audio_buffer_delay_ && delay_) {
+    int difference = static_cast<int>(delay) - static_cast<int>(*delay_);
+    RTC_LOG_V(delay_log_level_)
+        << "Mismatch between first estimated delay after reset "
+           "and externally reported audio buffer delay: "
+        << difference << " blocks";
+    external_audio_buffer_delay_verified_after_reset_ = true;
+  }
+  if (delay_ && *delay_ == delay) {
+    return false;
+  }
+  delay_ = delay;
+
+  // Compute the total delay and limit the delay to the allowed range.
+  int total_delay = MapDelayToTotalDelay(*delay_);
+  total_delay =
+      std::min(MaxDelay(), static_cast<size_t>(std::max(total_delay, 0)));
+
+  // Apply the delay to the buffers.
+  ApplyTotalDelay(total_delay);
+  return true;
+}
+
+void RenderDelayBufferImpl::SetAudioBufferDelay(int delay_ms) {
+  if (!external_audio_buffer_delay_) {
+    RTC_LOG_V(delay_log_level_)
+        << "Receiving a first externally reported audio buffer delay of "
+        << delay_ms << " ms.";
+  }
+
+  // Convert delay from milliseconds to blocks (rounded down).
+  external_audio_buffer_delay_ = delay_ms / 4;
+}
+
+bool RenderDelayBufferImpl::HasReceivedBufferDelay() {
+  return external_audio_buffer_delay_.has_value();
+}
+
+// Maps the externally computed delay to the delay used internally.
+int RenderDelayBufferImpl::MapDelayToTotalDelay(
+    size_t external_delay_blocks) const {
+  const int latency_blocks = BufferLatency();
+  return latency_blocks + static_cast<int>(external_delay_blocks);
+}
+
+// Returns the delay (not including call jitter).
+int RenderDelayBufferImpl::ComputeDelay() const {
+  const int latency_blocks = BufferLatency();
+  int internal_delay = spectra_.read >= spectra_.write
+                           ? spectra_.read - spectra_.write
+                           : spectra_.size + spectra_.read - spectra_.write;
+
+  return internal_delay - latency_blocks;
+}
+
+// Set the read indices according to the delay.
+void RenderDelayBufferImpl::ApplyTotalDelay(int delay) {
+  RTC_LOG_V(delay_log_level_)
+      << "Applying total delay of " << delay << " blocks.";
+  blocks_.read = blocks_.OffsetIndex(blocks_.write, -delay);
+  spectra_.read = spectra_.OffsetIndex(spectra_.write, delay);
+  ffts_.read = ffts_.OffsetIndex(ffts_.write, delay);
+}
+
+void RenderDelayBufferImpl::AlignFromExternalDelay() {
+  RTC_DCHECK(config_.delay.use_external_delay_estimator);
+  if (external_audio_buffer_delay_) {
+    const int64_t delay = render_call_counter_ - capture_call_counter_ +
+                          *external_audio_buffer_delay_;
+    const int64_t delay_with_headroom =
+        delay - config_.delay.delay_headroom_samples / kBlockSize;
+    ApplyTotalDelay(delay_with_headroom);
+  }
+}
+
+// Inserts a block into the render buffers.
+void RenderDelayBufferImpl::InsertBlock(
+    const std::vector<std::vector<std::vector<float>>>& block,
+    int previous_write) {
+  auto& b = blocks_;
+  auto& lr = low_rate_;
+  auto& ds = render_ds_;
+  auto& f = ffts_;
+  auto& s = spectra_;
+  const size_t num_bands = b.buffer[b.write].size();
+  const size_t num_render_channels = b.buffer[b.write][0].size();
+  RTC_DCHECK_EQ(block.size(), b.buffer[b.write].size());
+  for (size_t band = 0; band < num_bands; ++band) {
+    RTC_DCHECK_EQ(block[band].size(), num_render_channels);
+    RTC_DCHECK_EQ(b.buffer[b.write][band].size(), num_render_channels);
+    for (size_t ch = 0; ch < num_render_channels; ++ch) {
+      RTC_DCHECK_EQ(block[band][ch].size(), b.buffer[b.write][band][ch].size());
+      std::copy(block[band][ch].begin(), block[band][ch].end(),
+                b.buffer[b.write][band][ch].begin());
+    }
+  }
+
+  if (render_linear_amplitude_gain_ != 1.f) {
+    for (size_t band = 0; band < num_bands; ++band) {
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        for (size_t k = 0; k < 64; ++k) {
+          b.buffer[b.write][band][ch][k] *= render_linear_amplitude_gain_;
+        }
+      }
+    }
+  }
+
+  std::array<float, kBlockSize> downmixed_render;
+  render_mixer_.ProduceOutput(b.buffer[b.write][0], downmixed_render);
+  render_decimator_.Decimate(downmixed_render, ds);
+  data_dumper_->DumpWav("aec3_render_decimator_output", ds.size(), ds.data(),
+                        16000 / down_sampling_factor_, 1);
+  std::copy(ds.rbegin(), ds.rend(), lr.buffer.begin() + lr.write);
+  for (size_t channel = 0; channel < b.buffer[b.write][0].size(); ++channel) {
+    fft_.PaddedFft(b.buffer[b.write][0][channel],
+                   b.buffer[previous_write][0][channel],
+                   &f.buffer[f.write][channel]);
+    f.buffer[f.write][channel].Spectrum(optimization_,
+                                        s.buffer[s.write][channel]);
+  }
+}
+
+bool RenderDelayBufferImpl::DetectActiveRender(
+    rtc::ArrayView<const float> x) const {
+  const float x_energy = std::inner_product(x.begin(), x.end(), x.begin(), 0.f);
+  return x_energy > (config_.render_levels.active_render_limit *
+                     config_.render_levels.active_render_limit) *
+                        kFftLengthBy2;
+}
+
+bool RenderDelayBufferImpl::DetectExcessRenderBlocks() {
+  bool excess_render_detected = false;
+  const size_t latency_blocks = static_cast<size_t>(BufferLatency());
+  // The recently seen minimum latency in blocks. Should be close to 0.
+  min_latency_blocks_ = std::min(min_latency_blocks_, latency_blocks);
+  // After processing a configurable number of blocks the minimum latency is
+  // checked.
+  if (++excess_render_detection_counter_ >=
+      config_.buffering.excess_render_detection_interval_blocks) {
+    // If the minimum latency is not lower than the threshold there have been
+    // more render than capture frames.
+    excess_render_detected = min_latency_blocks_ >
+                             config_.buffering.max_allowed_excess_render_blocks;
+    // Reset the counter and let the minimum latency be the current latency.
+    min_latency_blocks_ = latency_blocks;
+    excess_render_detection_counter_ = 0;
+  }
+
+  data_dumper_->DumpRaw("aec3_latency_blocks", latency_blocks);
+  data_dumper_->DumpRaw("aec3_min_latency_blocks", min_latency_blocks_);
+  data_dumper_->DumpRaw("aec3_excess_render_detected", excess_render_detected);
+  return excess_render_detected;
+}
+
+// Computes the latency in the buffer (the number of unread sub-blocks).
+int RenderDelayBufferImpl::BufferLatency() const {
+  const DownsampledRenderBuffer& l = low_rate_;
+  int latency_samples = (l.buffer.size() + l.read - l.write) % l.buffer.size();
+  int latency_blocks = latency_samples / sub_block_size_;
+  return latency_blocks;
+}
+
+// Increments the write indices for the render buffers.
+void RenderDelayBufferImpl::IncrementWriteIndices() {
+  low_rate_.UpdateWriteIndex(-sub_block_size_);
+  blocks_.IncWriteIndex();
+  spectra_.DecWriteIndex();
+  ffts_.DecWriteIndex();
+}
+
+// Increments the read indices of the low rate render buffers.
+void RenderDelayBufferImpl::IncrementLowRateReadIndices() {
+  low_rate_.UpdateReadIndex(-sub_block_size_);
+}
+
+// Increments the read indices for the render buffers.
+void RenderDelayBufferImpl::IncrementReadIndices() {
+  if (blocks_.read != blocks_.write) {
+    blocks_.IncReadIndex();
+    spectra_.DecReadIndex();
+    ffts_.DecReadIndex();
+  }
+}
+
+// Checks for a render buffer overrun.
+bool RenderDelayBufferImpl::RenderOverrun() {
+  return low_rate_.read == low_rate_.write || blocks_.read == blocks_.write;
+}
+
+// Checks for a render buffer underrun.
+bool RenderDelayBufferImpl::RenderUnderrun() {
+  return low_rate_.read == low_rate_.write;
+}
+
+}  // namespace
+
+RenderDelayBuffer* RenderDelayBuffer::Create(const EchoCanceller3Config& config,
+                                             int sample_rate_hz,
+                                             size_t num_render_channels) {
+  return new RenderDelayBufferImpl(config, sample_rate_hz, num_render_channels);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_buffer.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_buffer.h
new file mode 100644
index 0000000..79ffc4d
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_buffer.h
@@ -0,0 +1,86 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_RENDER_DELAY_BUFFER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_RENDER_DELAY_BUFFER_H_
+
+#include <stddef.h>
+
+#include <vector>
+
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/downsampled_render_buffer.h"
+#include "modules/audio_processing/aec3/render_buffer.h"
+
+namespace webrtc {
+
+// Class for buffering the incoming render blocks such that these may be
+// extracted with a specified delay.
+class RenderDelayBuffer {
+ public:
+  enum class BufferingEvent {
+    kNone,
+    kRenderUnderrun,
+    kRenderOverrun,
+    kApiCallSkew
+  };
+
+  static RenderDelayBuffer* Create(const EchoCanceller3Config& config,
+                                   int sample_rate_hz,
+                                   size_t num_render_channels);
+  virtual ~RenderDelayBuffer() = default;
+
+  // Resets the buffer alignment.
+  virtual void Reset() = 0;
+
+  // Inserts a block into the buffer.
+  virtual BufferingEvent Insert(
+      const std::vector<std::vector<std::vector<float>>>& block) = 0;
+
+  // Updates the buffers one step based on the specified buffer delay. Returns
+  // an enum indicating whether there was a special event that occurred.
+  virtual BufferingEvent PrepareCaptureProcessing() = 0;
+
+  // Called on capture blocks where PrepareCaptureProcessing is not called.
+  virtual void HandleSkippedCaptureProcessing() = 0;
+
+  // Sets the buffer delay and returns a bool indicating whether the delay
+  // changed.
+  virtual bool AlignFromDelay(size_t delay) = 0;
+
+  // Sets the buffer delay from the most recently reported external delay.
+  virtual void AlignFromExternalDelay() = 0;
+
+  // Gets the buffer delay.
+  virtual size_t Delay() const = 0;
+
+  // Gets the buffer delay.
+  virtual size_t MaxDelay() const = 0;
+
+  // Returns the render buffer for the echo remover.
+  virtual RenderBuffer* GetRenderBuffer() = 0;
+
+  // Returns the downsampled render buffer.
+  virtual const DownsampledRenderBuffer& GetDownsampledRenderBuffer() const = 0;
+
+  // Returns the maximum non calusal offset that can occur in the delay buffer.
+  static int DelayEstimatorOffset(const EchoCanceller3Config& config);
+
+  // Provides an optional external estimate of the audio buffer delay.
+  virtual void SetAudioBufferDelay(int delay_ms) = 0;
+
+  // Returns whether an external delay estimate has been reported via
+  // SetAudioBufferDelay.
+  virtual bool HasReceivedBufferDelay() = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_RENDER_DELAY_BUFFER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_buffer_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_buffer_unittest.cc
new file mode 100644
index 0000000..efd4a29
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_buffer_unittest.cc
@@ -0,0 +1,156 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+
+#include <memory>
+#include <string>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/random.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace {
+
+std::string ProduceDebugText(int sample_rate_hz) {
+  rtc::StringBuilder ss;
+  ss << "Sample rate: " << sample_rate_hz;
+  return ss.Release();
+}
+
+}  // namespace
+
+// Verifies that the buffer overflow is correctly reported.
+TEST(RenderDelayBuffer, BufferOverflow) {
+  const EchoCanceller3Config config;
+  for (auto num_channels : {1, 2, 8}) {
+    for (auto rate : {16000, 32000, 48000}) {
+      SCOPED_TRACE(ProduceDebugText(rate));
+      std::unique_ptr<RenderDelayBuffer> delay_buffer(
+          RenderDelayBuffer::Create(config, rate, num_channels));
+      std::vector<std::vector<std::vector<float>>> block_to_insert(
+          NumBandsForRate(rate),
+          std::vector<std::vector<float>>(num_channels,
+                                          std::vector<float>(kBlockSize, 0.f)));
+      for (size_t k = 0; k < 10; ++k) {
+        EXPECT_EQ(RenderDelayBuffer::BufferingEvent::kNone,
+                  delay_buffer->Insert(block_to_insert));
+      }
+      bool overrun_occurred = false;
+      for (size_t k = 0; k < 1000; ++k) {
+        RenderDelayBuffer::BufferingEvent event =
+            delay_buffer->Insert(block_to_insert);
+        overrun_occurred =
+            overrun_occurred ||
+            RenderDelayBuffer::BufferingEvent::kRenderOverrun == event;
+      }
+
+      EXPECT_TRUE(overrun_occurred);
+    }
+  }
+}
+
+// Verifies that the check for available block works.
+TEST(RenderDelayBuffer, AvailableBlock) {
+  constexpr size_t kNumChannels = 1;
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+  std::unique_ptr<RenderDelayBuffer> delay_buffer(RenderDelayBuffer::Create(
+      EchoCanceller3Config(), kSampleRateHz, kNumChannels));
+  std::vector<std::vector<std::vector<float>>> input_block(
+      kNumBands, std::vector<std::vector<float>>(
+                     kNumChannels, std::vector<float>(kBlockSize, 1.f)));
+  EXPECT_EQ(RenderDelayBuffer::BufferingEvent::kNone,
+            delay_buffer->Insert(input_block));
+  delay_buffer->PrepareCaptureProcessing();
+}
+
+// Verifies the AlignFromDelay method.
+TEST(RenderDelayBuffer, AlignFromDelay) {
+  EchoCanceller3Config config;
+  std::unique_ptr<RenderDelayBuffer> delay_buffer(
+      RenderDelayBuffer::Create(config, 16000, 1));
+  ASSERT_TRUE(delay_buffer->Delay());
+  delay_buffer->Reset();
+  size_t initial_internal_delay = 0;
+  for (size_t delay = initial_internal_delay;
+       delay < initial_internal_delay + 20; ++delay) {
+    ASSERT_TRUE(delay_buffer->AlignFromDelay(delay));
+    EXPECT_EQ(delay, delay_buffer->Delay());
+  }
+}
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+// Verifies the check for feasible delay.
+// TODO(peah): Re-enable the test once the issue with memory leaks during DEATH
+// tests on test bots has been fixed.
+TEST(RenderDelayBufferDeathTest, DISABLED_WrongDelay) {
+  std::unique_ptr<RenderDelayBuffer> delay_buffer(
+      RenderDelayBuffer::Create(EchoCanceller3Config(), 48000, 1));
+  EXPECT_DEATH(delay_buffer->AlignFromDelay(21), "");
+}
+
+// Verifies the check for the number of bands in the inserted blocks.
+TEST(RenderDelayBufferDeathTest, WrongNumberOfBands) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (size_t num_channels : {1, 2, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate));
+      std::unique_ptr<RenderDelayBuffer> delay_buffer(RenderDelayBuffer::Create(
+          EchoCanceller3Config(), rate, num_channels));
+      std::vector<std::vector<std::vector<float>>> block_to_insert(
+          NumBandsForRate(rate < 48000 ? rate + 16000 : 16000),
+          std::vector<std::vector<float>>(num_channels,
+                                          std::vector<float>(kBlockSize, 0.f)));
+      EXPECT_DEATH(delay_buffer->Insert(block_to_insert), "");
+    }
+  }
+}
+
+// Verifies the check for the number of channels in the inserted blocks.
+TEST(RenderDelayBufferDeathTest, WrongNumberOfChannels) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (size_t num_channels : {1, 2, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate));
+      std::unique_ptr<RenderDelayBuffer> delay_buffer(RenderDelayBuffer::Create(
+          EchoCanceller3Config(), rate, num_channels));
+      std::vector<std::vector<std::vector<float>>> block_to_insert(
+          NumBandsForRate(rate),
+          std::vector<std::vector<float>>(num_channels + 1,
+                                          std::vector<float>(kBlockSize, 0.f)));
+      EXPECT_DEATH(delay_buffer->Insert(block_to_insert), "");
+    }
+  }
+}
+
+// Verifies the check of the length of the inserted blocks.
+TEST(RenderDelayBufferDeathTest, WrongBlockLength) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (size_t num_channels : {1, 2, 8}) {
+      SCOPED_TRACE(ProduceDebugText(rate));
+      std::unique_ptr<RenderDelayBuffer> delay_buffer(RenderDelayBuffer::Create(
+          EchoCanceller3Config(), rate, num_channels));
+      std::vector<std::vector<std::vector<float>>> block_to_insert(
+          NumBandsForRate(rate),
+          std::vector<std::vector<float>>(
+              num_channels, std::vector<float>(kBlockSize - 1, 0.f)));
+      EXPECT_DEATH(delay_buffer->Insert(block_to_insert), "");
+    }
+  }
+}
+
+#endif
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller.cc
new file mode 100644
index 0000000..3677085
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller.cc
@@ -0,0 +1,196 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "modules/audio_processing/aec3/render_delay_controller.h"
+
+#include <stddef.h>
+
+#include <algorithm>
+#include <memory>
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/delay_estimate.h"
+#include "modules/audio_processing/aec3/downsampled_render_buffer.h"
+#include "modules/audio_processing/aec3/echo_path_delay_estimator.h"
+#include "modules/audio_processing/aec3/render_delay_controller_metrics.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/atomic_ops.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+namespace {
+
+class RenderDelayControllerImpl final : public RenderDelayController {
+ public:
+  RenderDelayControllerImpl(const EchoCanceller3Config& config,
+                            int sample_rate_hz,
+                            size_t num_capture_channels);
+
+  RenderDelayControllerImpl() = delete;
+  RenderDelayControllerImpl(const RenderDelayControllerImpl&) = delete;
+  RenderDelayControllerImpl& operator=(const RenderDelayControllerImpl&) =
+      delete;
+
+  ~RenderDelayControllerImpl() override;
+  void Reset(bool reset_delay_confidence) override;
+  void LogRenderCall() override;
+  absl::optional<DelayEstimate> GetDelay(
+      const DownsampledRenderBuffer& render_buffer,
+      size_t render_delay_buffer_delay,
+      const std::vector<std::vector<float>>& capture) override;
+  bool HasClockdrift() const override;
+
+ private:
+  static int instance_count_;
+  std::unique_ptr<ApmDataDumper> data_dumper_;
+  const int hysteresis_limit_blocks_;
+  const int delay_headroom_samples_;
+  absl::optional<DelayEstimate> delay_;
+  EchoPathDelayEstimator delay_estimator_;
+  RenderDelayControllerMetrics metrics_;
+  absl::optional<DelayEstimate> delay_samples_;
+  size_t capture_call_counter_ = 0;
+  int delay_change_counter_ = 0;
+  DelayEstimate::Quality last_delay_estimate_quality_;
+};
+
+DelayEstimate ComputeBufferDelay(
+    const absl::optional<DelayEstimate>& current_delay,
+    int hysteresis_limit_blocks,
+    int delay_headroom_samples,
+    DelayEstimate estimated_delay) {
+  // Subtract delay headroom.
+  const int delay_with_headroom_samples = std::max(
+      static_cast<int>(estimated_delay.delay) - delay_headroom_samples, 0);
+
+  // Compute the buffer delay increase required to achieve the desired latency.
+  size_t new_delay_blocks = delay_with_headroom_samples >> kBlockSizeLog2;
+
+  // Add hysteresis.
+  if (current_delay) {
+    size_t current_delay_blocks = current_delay->delay;
+    if (new_delay_blocks > current_delay_blocks &&
+        new_delay_blocks <= current_delay_blocks + hysteresis_limit_blocks) {
+      new_delay_blocks = current_delay_blocks;
+    }
+  }
+
+  DelayEstimate new_delay = estimated_delay;
+  new_delay.delay = new_delay_blocks;
+  return new_delay;
+}
+
+int RenderDelayControllerImpl::instance_count_ = 0;
+
+RenderDelayControllerImpl::RenderDelayControllerImpl(
+    const EchoCanceller3Config& config,
+    int sample_rate_hz,
+    size_t num_capture_channels)
+    : data_dumper_(
+          new ApmDataDumper(rtc::AtomicOps::Increment(&instance_count_))),
+      hysteresis_limit_blocks_(
+          static_cast<int>(config.delay.hysteresis_limit_blocks)),
+      delay_headroom_samples_(config.delay.delay_headroom_samples),
+      delay_estimator_(data_dumper_.get(), config, num_capture_channels),
+      last_delay_estimate_quality_(DelayEstimate::Quality::kCoarse) {
+  RTC_DCHECK(ValidFullBandRate(sample_rate_hz));
+  delay_estimator_.LogDelayEstimationProperties(sample_rate_hz, 0);
+}
+
+RenderDelayControllerImpl::~RenderDelayControllerImpl() = default;
+
+void RenderDelayControllerImpl::Reset(bool reset_delay_confidence) {
+  delay_ = absl::nullopt;
+  delay_samples_ = absl::nullopt;
+  delay_estimator_.Reset(reset_delay_confidence);
+  delay_change_counter_ = 0;
+  if (reset_delay_confidence) {
+    last_delay_estimate_quality_ = DelayEstimate::Quality::kCoarse;
+  }
+}
+
+void RenderDelayControllerImpl::LogRenderCall() {}
+
+absl::optional<DelayEstimate> RenderDelayControllerImpl::GetDelay(
+    const DownsampledRenderBuffer& render_buffer,
+    size_t render_delay_buffer_delay,
+    const std::vector<std::vector<float>>& capture) {
+  RTC_DCHECK_EQ(kBlockSize, capture[0].size());
+  ++capture_call_counter_;
+
+  auto delay_samples = delay_estimator_.EstimateDelay(render_buffer, capture);
+
+  if (delay_samples) {
+    if (!delay_samples_ || delay_samples->delay != delay_samples_->delay) {
+      delay_change_counter_ = 0;
+    }
+    if (delay_samples_) {
+      delay_samples_->blocks_since_last_change =
+          delay_samples_->delay == delay_samples->delay
+              ? delay_samples_->blocks_since_last_change + 1
+              : 0;
+      delay_samples_->blocks_since_last_update = 0;
+      delay_samples_->delay = delay_samples->delay;
+      delay_samples_->quality = delay_samples->quality;
+    } else {
+      delay_samples_ = delay_samples;
+    }
+  } else {
+    if (delay_samples_) {
+      ++delay_samples_->blocks_since_last_change;
+      ++delay_samples_->blocks_since_last_update;
+    }
+  }
+
+  if (delay_change_counter_ < 2 * kNumBlocksPerSecond) {
+    ++delay_change_counter_;
+  }
+
+  if (delay_samples_) {
+    // Compute the render delay buffer delay.
+    const bool use_hysteresis =
+        last_delay_estimate_quality_ == DelayEstimate::Quality::kRefined &&
+        delay_samples_->quality == DelayEstimate::Quality::kRefined;
+    delay_ = ComputeBufferDelay(delay_,
+                                use_hysteresis ? hysteresis_limit_blocks_ : 0,
+                                delay_headroom_samples_, *delay_samples_);
+    last_delay_estimate_quality_ = delay_samples_->quality;
+  }
+
+  metrics_.Update(delay_samples_ ? absl::optional<size_t>(delay_samples_->delay)
+                                 : absl::nullopt,
+                  delay_ ? delay_->delay : 0, 0, delay_estimator_.Clockdrift());
+
+  data_dumper_->DumpRaw("aec3_render_delay_controller_delay",
+                        delay_samples ? delay_samples->delay : 0);
+  data_dumper_->DumpRaw("aec3_render_delay_controller_buffer_delay",
+                        delay_ ? delay_->delay : 0);
+
+  return delay_;
+}
+
+bool RenderDelayControllerImpl::HasClockdrift() const {
+  return delay_estimator_.Clockdrift() != ClockdriftDetector::Level::kNone;
+}
+
+}  // namespace
+
+RenderDelayController* RenderDelayController::Create(
+    const EchoCanceller3Config& config,
+    int sample_rate_hz,
+    size_t num_capture_channels) {
+  return new RenderDelayControllerImpl(config, sample_rate_hz,
+                                       num_capture_channels);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller.h
new file mode 100644
index 0000000..c45ab1f
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller.h
@@ -0,0 +1,50 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_RENDER_DELAY_CONTROLLER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_RENDER_DELAY_CONTROLLER_H_
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/delay_estimate.h"
+#include "modules/audio_processing/aec3/downsampled_render_buffer.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+
+namespace webrtc {
+
+// Class for aligning the render and capture signal using a RenderDelayBuffer.
+class RenderDelayController {
+ public:
+  static RenderDelayController* Create(const EchoCanceller3Config& config,
+                                       int sample_rate_hz,
+                                       size_t num_capture_channels);
+  virtual ~RenderDelayController() = default;
+
+  // Resets the delay controller. If the delay confidence is reset, the reset
+  // behavior is as if the call is restarted.
+  virtual void Reset(bool reset_delay_confidence) = 0;
+
+  // Logs a render call.
+  virtual void LogRenderCall() = 0;
+
+  // Aligns the render buffer content with the capture signal.
+  virtual absl::optional<DelayEstimate> GetDelay(
+      const DownsampledRenderBuffer& render_buffer,
+      size_t render_delay_buffer_delay,
+      const std::vector<std::vector<float>>& capture) = 0;
+
+  // Returns true if clockdrift has been detected.
+  virtual bool HasClockdrift() const = 0;
+};
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_RENDER_DELAY_CONTROLLER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller_metrics.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller_metrics.cc
new file mode 100644
index 0000000..582e033
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller_metrics.cc
@@ -0,0 +1,145 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/render_delay_controller_metrics.h"
+
+#include <algorithm>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "rtc_base/checks.h"
+#include "system_wrappers/include/metrics.h"
+
+namespace webrtc {
+
+namespace {
+
+enum class DelayReliabilityCategory {
+  kNone,
+  kPoor,
+  kMedium,
+  kGood,
+  kExcellent,
+  kNumCategories
+};
+enum class DelayChangesCategory {
+  kNone,
+  kFew,
+  kSeveral,
+  kMany,
+  kConstant,
+  kNumCategories
+};
+
+constexpr int kMaxSkewShiftCount = 20;
+
+}  // namespace
+
+RenderDelayControllerMetrics::RenderDelayControllerMetrics() = default;
+
+void RenderDelayControllerMetrics::Update(
+    absl::optional<size_t> delay_samples,
+    size_t buffer_delay_blocks,
+    absl::optional<int> skew_shift_blocks,
+    ClockdriftDetector::Level clockdrift) {
+  ++call_counter_;
+
+  if (!initial_update) {
+    size_t delay_blocks;
+    if (delay_samples) {
+      ++reliable_delay_estimate_counter_;
+      delay_blocks = (*delay_samples) / kBlockSize + 2;
+    } else {
+      delay_blocks = 0;
+    }
+
+    if (delay_blocks != delay_blocks_) {
+      ++delay_change_counter_;
+      delay_blocks_ = delay_blocks;
+    }
+
+    if (skew_shift_blocks) {
+      skew_shift_count_ = std::min(kMaxSkewShiftCount, skew_shift_count_);
+    }
+  } else if (++initial_call_counter_ == 5 * kNumBlocksPerSecond) {
+    initial_update = false;
+  }
+
+  if (call_counter_ == kMetricsReportingIntervalBlocks) {
+    int value_to_report = static_cast<int>(delay_blocks_);
+    value_to_report = std::min(124, value_to_report >> 1);
+    RTC_HISTOGRAM_COUNTS_LINEAR("WebRTC.Audio.EchoCanceller.EchoPathDelay",
+                                value_to_report, 0, 124, 125);
+
+    value_to_report = static_cast<int>(buffer_delay_blocks + 2);
+    value_to_report = std::min(124, value_to_report >> 1);
+    RTC_HISTOGRAM_COUNTS_LINEAR("WebRTC.Audio.EchoCanceller.BufferDelay",
+                                value_to_report, 0, 124, 125);
+
+    DelayReliabilityCategory delay_reliability;
+    if (reliable_delay_estimate_counter_ == 0) {
+      delay_reliability = DelayReliabilityCategory::kNone;
+    } else if (reliable_delay_estimate_counter_ > (call_counter_ >> 1)) {
+      delay_reliability = DelayReliabilityCategory::kExcellent;
+    } else if (reliable_delay_estimate_counter_ > 100) {
+      delay_reliability = DelayReliabilityCategory::kGood;
+    } else if (reliable_delay_estimate_counter_ > 10) {
+      delay_reliability = DelayReliabilityCategory::kMedium;
+    } else {
+      delay_reliability = DelayReliabilityCategory::kPoor;
+    }
+    RTC_HISTOGRAM_ENUMERATION(
+        "WebRTC.Audio.EchoCanceller.ReliableDelayEstimates",
+        static_cast<int>(delay_reliability),
+        static_cast<int>(DelayReliabilityCategory::kNumCategories));
+
+    DelayChangesCategory delay_changes;
+    if (delay_change_counter_ == 0) {
+      delay_changes = DelayChangesCategory::kNone;
+    } else if (delay_change_counter_ > 10) {
+      delay_changes = DelayChangesCategory::kConstant;
+    } else if (delay_change_counter_ > 5) {
+      delay_changes = DelayChangesCategory::kMany;
+    } else if (delay_change_counter_ > 2) {
+      delay_changes = DelayChangesCategory::kSeveral;
+    } else {
+      delay_changes = DelayChangesCategory::kFew;
+    }
+    RTC_HISTOGRAM_ENUMERATION(
+        "WebRTC.Audio.EchoCanceller.DelayChanges",
+        static_cast<int>(delay_changes),
+        static_cast<int>(DelayChangesCategory::kNumCategories));
+
+    RTC_HISTOGRAM_ENUMERATION(
+        "WebRTC.Audio.EchoCanceller.Clockdrift", static_cast<int>(clockdrift),
+        static_cast<int>(ClockdriftDetector::Level::kNumCategories));
+
+    metrics_reported_ = true;
+    call_counter_ = 0;
+    ResetMetrics();
+  } else {
+    metrics_reported_ = false;
+  }
+
+  if (!initial_update && ++skew_report_timer_ == 60 * kNumBlocksPerSecond) {
+    RTC_HISTOGRAM_COUNTS_LINEAR("WebRTC.Audio.EchoCanceller.MaxSkewShiftCount",
+                                skew_shift_count_, 0, kMaxSkewShiftCount,
+                                kMaxSkewShiftCount + 1);
+
+    skew_shift_count_ = 0;
+    skew_report_timer_ = 0;
+  }
+}
+
+void RenderDelayControllerMetrics::ResetMetrics() {
+  delay_change_counter_ = 0;
+  reliable_delay_estimate_counter_ = 0;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller_metrics.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller_metrics.h
new file mode 100644
index 0000000..8c527a1
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller_metrics.h
@@ -0,0 +1,55 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_RENDER_DELAY_CONTROLLER_METRICS_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_RENDER_DELAY_CONTROLLER_METRICS_H_
+
+#include <stddef.h>
+
+#include "absl/types/optional.h"
+#include "modules/audio_processing/aec3/clockdrift_detector.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+// Handles the reporting of metrics for the render delay controller.
+class RenderDelayControllerMetrics {
+ public:
+  RenderDelayControllerMetrics();
+
+  // Updates the metric with new data.
+  void Update(absl::optional<size_t> delay_samples,
+              size_t buffer_delay_blocks,
+              absl::optional<int> skew_shift_blocks,
+              ClockdriftDetector::Level clockdrift);
+
+  // Returns true if the metrics have just been reported, otherwise false.
+  bool MetricsReported() { return metrics_reported_; }
+
+ private:
+  // Resets the metrics.
+  void ResetMetrics();
+
+  size_t delay_blocks_ = 0;
+  int reliable_delay_estimate_counter_ = 0;
+  int delay_change_counter_ = 0;
+  int call_counter_ = 0;
+  int skew_report_timer_ = 0;
+  int initial_call_counter_ = 0;
+  bool metrics_reported_ = false;
+  bool initial_update = true;
+  int skew_shift_count_ = 0;
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(RenderDelayControllerMetrics);
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_RENDER_DELAY_CONTROLLER_METRICS_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller_metrics_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller_metrics_unittest.cc
new file mode 100644
index 0000000..e7d7703
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller_metrics_unittest.cc
@@ -0,0 +1,35 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/render_delay_controller_metrics.h"
+
+#include "absl/types/optional.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+// Verify the general functionality of RenderDelayControllerMetrics.
+TEST(RenderDelayControllerMetrics, NormalUsage) {
+  RenderDelayControllerMetrics metrics;
+
+  for (int j = 0; j < 3; ++j) {
+    for (int k = 0; k < kMetricsReportingIntervalBlocks - 1; ++k) {
+      metrics.Update(absl::nullopt, 0, absl::nullopt,
+                     ClockdriftDetector::Level::kNone);
+      EXPECT_FALSE(metrics.MetricsReported());
+    }
+    metrics.Update(absl::nullopt, 0, absl::nullopt,
+                   ClockdriftDetector::Level::kNone);
+    EXPECT_TRUE(metrics.MetricsReported());
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller_unittest.cc
new file mode 100644
index 0000000..0d3c856
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_delay_controller_unittest.cc
@@ -0,0 +1,363 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/render_delay_controller.h"
+
+#include <algorithm>
+#include <memory>
+#include <string>
+#include <vector>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/block_processor.h"
+#include "modules/audio_processing/aec3/decimator.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "modules/audio_processing/test/echo_canceller_test_tools.h"
+#include "rtc_base/random.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace {
+
+std::string ProduceDebugText(int sample_rate_hz) {
+  rtc::StringBuilder ss;
+  ss << "Sample rate: " << sample_rate_hz;
+  return ss.Release();
+}
+
+std::string ProduceDebugText(int sample_rate_hz,
+                             size_t delay,
+                             size_t num_render_channels,
+                             size_t num_capture_channels) {
+  rtc::StringBuilder ss;
+  ss << ProduceDebugText(sample_rate_hz) << ", Delay: " << delay
+     << ", Num render channels: " << num_render_channels
+     << ", Num capture channels: " << num_capture_channels;
+  return ss.Release();
+}
+
+constexpr size_t kDownSamplingFactors[] = {2, 4, 8};
+
+}  // namespace
+
+// Verifies the output of GetDelay when there are no AnalyzeRender calls.
+// TODO(bugs.webrtc.org/11161): Re-enable tests.
+TEST(RenderDelayController, DISABLED_NoRenderSignal) {
+  for (size_t num_render_channels : {1, 2, 8}) {
+    std::vector<std::vector<float>> block(1,
+                                          std::vector<float>(kBlockSize, 0.f));
+    EchoCanceller3Config config;
+    for (size_t num_matched_filters = 4; num_matched_filters <= 10;
+         num_matched_filters++) {
+      for (auto down_sampling_factor : kDownSamplingFactors) {
+        config.delay.down_sampling_factor = down_sampling_factor;
+        config.delay.num_filters = num_matched_filters;
+        for (auto rate : {16000, 32000, 48000}) {
+          SCOPED_TRACE(ProduceDebugText(rate));
+          std::unique_ptr<RenderDelayBuffer> delay_buffer(
+              RenderDelayBuffer::Create(config, rate, num_render_channels));
+          std::unique_ptr<RenderDelayController> delay_controller(
+              RenderDelayController::Create(config, rate,
+                                            /*num_capture_channels*/ 1));
+          for (size_t k = 0; k < 100; ++k) {
+            auto delay = delay_controller->GetDelay(
+                delay_buffer->GetDownsampledRenderBuffer(),
+                delay_buffer->Delay(), block);
+            EXPECT_FALSE(delay->delay);
+          }
+        }
+      }
+    }
+  }
+}
+
+// Verifies the basic API call sequence.
+// TODO(bugs.webrtc.org/11161): Re-enable tests.
+TEST(RenderDelayController, DISABLED_BasicApiCalls) {
+  for (size_t num_capture_channels : {1, 2, 4}) {
+    for (size_t num_render_channels : {1, 2, 8}) {
+      std::vector<std::vector<float>> capture_block(
+          num_capture_channels, std::vector<float>(kBlockSize, 0.f));
+      absl::optional<DelayEstimate> delay_blocks;
+      for (size_t num_matched_filters = 4; num_matched_filters <= 10;
+           num_matched_filters++) {
+        for (auto down_sampling_factor : kDownSamplingFactors) {
+          EchoCanceller3Config config;
+          config.delay.down_sampling_factor = down_sampling_factor;
+          config.delay.num_filters = num_matched_filters;
+          config.delay.capture_alignment_mixing.downmix = false;
+          config.delay.capture_alignment_mixing.adaptive_selection = false;
+
+          for (auto rate : {16000, 32000, 48000}) {
+            std::vector<std::vector<std::vector<float>>> render_block(
+                NumBandsForRate(rate),
+                std::vector<std::vector<float>>(
+                    num_render_channels, std::vector<float>(kBlockSize, 0.f)));
+            std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+                RenderDelayBuffer::Create(config, rate, num_render_channels));
+            std::unique_ptr<RenderDelayController> delay_controller(
+                RenderDelayController::Create(EchoCanceller3Config(), rate,
+                                              num_capture_channels));
+            for (size_t k = 0; k < 10; ++k) {
+              render_delay_buffer->Insert(render_block);
+              render_delay_buffer->PrepareCaptureProcessing();
+
+              delay_blocks = delay_controller->GetDelay(
+                  render_delay_buffer->GetDownsampledRenderBuffer(),
+                  render_delay_buffer->Delay(), capture_block);
+            }
+            EXPECT_TRUE(delay_blocks);
+            EXPECT_FALSE(delay_blocks->delay);
+          }
+        }
+      }
+    }
+  }
+}
+
+// Verifies that the RenderDelayController is able to align the signals for
+// simple timeshifts between the signals.
+// TODO(bugs.webrtc.org/11161): Re-enable tests.
+TEST(RenderDelayController, DISABLED_Alignment) {
+  Random random_generator(42U);
+  for (size_t num_capture_channels : {1, 2, 4}) {
+    std::vector<std::vector<float>> capture_block(
+        num_capture_channels, std::vector<float>(kBlockSize, 0.f));
+    for (size_t num_matched_filters = 4; num_matched_filters <= 10;
+         num_matched_filters++) {
+      for (auto down_sampling_factor : kDownSamplingFactors) {
+        EchoCanceller3Config config;
+        config.delay.down_sampling_factor = down_sampling_factor;
+        config.delay.num_filters = num_matched_filters;
+        config.delay.capture_alignment_mixing.downmix = false;
+        config.delay.capture_alignment_mixing.adaptive_selection = false;
+
+        for (size_t num_render_channels : {1, 2, 8}) {
+          for (auto rate : {16000, 32000, 48000}) {
+            std::vector<std::vector<std::vector<float>>> render_block(
+                NumBandsForRate(rate),
+                std::vector<std::vector<float>>(
+                    num_render_channels, std::vector<float>(kBlockSize, 0.f)));
+
+            for (size_t delay_samples : {15, 50, 150, 200, 800, 4000}) {
+              absl::optional<DelayEstimate> delay_blocks;
+              SCOPED_TRACE(ProduceDebugText(rate, delay_samples,
+                                            num_render_channels,
+                                            num_capture_channels));
+              std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+                  RenderDelayBuffer::Create(config, rate, num_render_channels));
+              std::unique_ptr<RenderDelayController> delay_controller(
+                  RenderDelayController::Create(config, rate,
+                                                num_capture_channels));
+              DelayBuffer<float> signal_delay_buffer(delay_samples);
+              for (size_t k = 0; k < (400 + delay_samples / kBlockSize); ++k) {
+                for (size_t band = 0; band < render_block.size(); ++band) {
+                  for (size_t channel = 0; channel < render_block[band].size();
+                       ++channel) {
+                    RandomizeSampleVector(&random_generator,
+                                          render_block[band][channel]);
+                  }
+                }
+                signal_delay_buffer.Delay(render_block[0][0], capture_block[0]);
+                render_delay_buffer->Insert(render_block);
+                render_delay_buffer->PrepareCaptureProcessing();
+                delay_blocks = delay_controller->GetDelay(
+                    render_delay_buffer->GetDownsampledRenderBuffer(),
+                    render_delay_buffer->Delay(), capture_block);
+              }
+              ASSERT_TRUE(!!delay_blocks);
+
+              constexpr int kDelayHeadroomBlocks = 1;
+              size_t expected_delay_blocks =
+                  std::max(0, static_cast<int>(delay_samples / kBlockSize) -
+                                  kDelayHeadroomBlocks);
+
+              EXPECT_EQ(expected_delay_blocks, delay_blocks->delay);
+            }
+          }
+        }
+      }
+    }
+  }
+}
+
+// Verifies that the RenderDelayController is able to properly handle noncausal
+// delays.
+// TODO(bugs.webrtc.org/11161): Re-enable tests.
+TEST(RenderDelayController, DISABLED_NonCausalAlignment) {
+  Random random_generator(42U);
+  for (size_t num_capture_channels : {1, 2, 4}) {
+    for (size_t num_render_channels : {1, 2, 8}) {
+      for (size_t num_matched_filters = 4; num_matched_filters <= 10;
+           num_matched_filters++) {
+        for (auto down_sampling_factor : kDownSamplingFactors) {
+          EchoCanceller3Config config;
+          config.delay.down_sampling_factor = down_sampling_factor;
+          config.delay.num_filters = num_matched_filters;
+          config.delay.capture_alignment_mixing.downmix = false;
+          config.delay.capture_alignment_mixing.adaptive_selection = false;
+          for (auto rate : {16000, 32000, 48000}) {
+            std::vector<std::vector<std::vector<float>>> render_block(
+                NumBandsForRate(rate),
+                std::vector<std::vector<float>>(
+                    num_render_channels, std::vector<float>(kBlockSize, 0.f)));
+            std::vector<std::vector<std::vector<float>>> capture_block(
+                NumBandsForRate(rate),
+                std::vector<std::vector<float>>(
+                    num_capture_channels, std::vector<float>(kBlockSize, 0.f)));
+
+            for (int delay_samples : {-15, -50, -150, -200}) {
+              absl::optional<DelayEstimate> delay_blocks;
+              SCOPED_TRACE(ProduceDebugText(rate, -delay_samples,
+                                            num_render_channels,
+                                            num_capture_channels));
+              std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+                  RenderDelayBuffer::Create(config, rate, num_render_channels));
+              std::unique_ptr<RenderDelayController> delay_controller(
+                  RenderDelayController::Create(EchoCanceller3Config(), rate,
+                                                num_capture_channels));
+              DelayBuffer<float> signal_delay_buffer(-delay_samples);
+              for (int k = 0;
+                   k < (400 - delay_samples / static_cast<int>(kBlockSize));
+                   ++k) {
+                RandomizeSampleVector(&random_generator, capture_block[0][0]);
+                signal_delay_buffer.Delay(capture_block[0][0],
+                                          render_block[0][0]);
+                render_delay_buffer->Insert(render_block);
+                render_delay_buffer->PrepareCaptureProcessing();
+                delay_blocks = delay_controller->GetDelay(
+                    render_delay_buffer->GetDownsampledRenderBuffer(),
+                    render_delay_buffer->Delay(), capture_block[0]);
+              }
+
+              ASSERT_FALSE(delay_blocks);
+            }
+          }
+        }
+      }
+    }
+  }
+}
+
+// Verifies that the RenderDelayController is able to align the signals for
+// simple timeshifts between the signals when there is jitter in the API calls.
+// TODO(bugs.webrtc.org/11161): Re-enable tests.
+TEST(RenderDelayController, DISABLED_AlignmentWithJitter) {
+  Random random_generator(42U);
+  for (size_t num_capture_channels : {1, 2, 4}) {
+    for (size_t num_render_channels : {1, 2, 8}) {
+      std::vector<std::vector<float>> capture_block(
+          num_capture_channels, std::vector<float>(kBlockSize, 0.f));
+      for (size_t num_matched_filters = 4; num_matched_filters <= 10;
+           num_matched_filters++) {
+        for (auto down_sampling_factor : kDownSamplingFactors) {
+          EchoCanceller3Config config;
+          config.delay.down_sampling_factor = down_sampling_factor;
+          config.delay.num_filters = num_matched_filters;
+          config.delay.capture_alignment_mixing.downmix = false;
+          config.delay.capture_alignment_mixing.adaptive_selection = false;
+
+          for (auto rate : {16000, 32000, 48000}) {
+            std::vector<std::vector<std::vector<float>>> render_block(
+                NumBandsForRate(rate),
+                std::vector<std::vector<float>>(
+                    num_render_channels, std::vector<float>(kBlockSize, 0.f)));
+            for (size_t delay_samples : {15, 50, 300, 800}) {
+              absl::optional<DelayEstimate> delay_blocks;
+              SCOPED_TRACE(ProduceDebugText(rate, delay_samples,
+                                            num_render_channels,
+                                            num_capture_channels));
+              std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+                  RenderDelayBuffer::Create(config, rate, num_render_channels));
+              std::unique_ptr<RenderDelayController> delay_controller(
+                  RenderDelayController::Create(config, rate,
+                                                num_capture_channels));
+              DelayBuffer<float> signal_delay_buffer(delay_samples);
+              constexpr size_t kMaxTestJitterBlocks = 26;
+              for (size_t j = 0; j < (1000 + delay_samples / kBlockSize) /
+                                             kMaxTestJitterBlocks +
+                                         1;
+                   ++j) {
+                std::vector<std::vector<std::vector<float>>>
+                    capture_block_buffer;
+                for (size_t k = 0; k < (kMaxTestJitterBlocks - 1); ++k) {
+                  RandomizeSampleVector(&random_generator, render_block[0][0]);
+                  signal_delay_buffer.Delay(render_block[0][0],
+                                            capture_block[0]);
+                  capture_block_buffer.push_back(capture_block);
+                  render_delay_buffer->Insert(render_block);
+                }
+                for (size_t k = 0; k < (kMaxTestJitterBlocks - 1); ++k) {
+                  render_delay_buffer->PrepareCaptureProcessing();
+                  delay_blocks = delay_controller->GetDelay(
+                      render_delay_buffer->GetDownsampledRenderBuffer(),
+                      render_delay_buffer->Delay(), capture_block_buffer[k]);
+                }
+              }
+
+              constexpr int kDelayHeadroomBlocks = 1;
+              size_t expected_delay_blocks =
+                  std::max(0, static_cast<int>(delay_samples / kBlockSize) -
+                                  kDelayHeadroomBlocks);
+              if (expected_delay_blocks < 2) {
+                expected_delay_blocks = 0;
+              }
+
+              ASSERT_TRUE(delay_blocks);
+              EXPECT_EQ(expected_delay_blocks, delay_blocks->delay);
+            }
+          }
+        }
+      }
+    }
+  }
+}
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+// Verifies the check for the capture signal block size.
+TEST(RenderDelayControllerDeathTest, WrongCaptureSize) {
+  std::vector<std::vector<float>> block(
+      1, std::vector<float>(kBlockSize - 1, 0.f));
+  EchoCanceller3Config config;
+  for (auto rate : {16000, 32000, 48000}) {
+    SCOPED_TRACE(ProduceDebugText(rate));
+    std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+        RenderDelayBuffer::Create(config, rate, 1));
+    EXPECT_DEATH(
+        std::unique_ptr<RenderDelayController>(
+            RenderDelayController::Create(EchoCanceller3Config(), rate, 1))
+            ->GetDelay(render_delay_buffer->GetDownsampledRenderBuffer(),
+                       render_delay_buffer->Delay(), block),
+        "");
+  }
+}
+
+// Verifies the check for correct sample rate.
+// TODO(peah): Re-enable the test once the issue with memory leaks during DEATH
+// tests on test bots has been fixed.
+TEST(RenderDelayControllerDeathTest, DISABLED_WrongSampleRate) {
+  for (auto rate : {-1, 0, 8001, 16001}) {
+    SCOPED_TRACE(ProduceDebugText(rate));
+    EchoCanceller3Config config;
+    std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+        RenderDelayBuffer::Create(config, rate, 1));
+    EXPECT_DEATH(
+        std::unique_ptr<RenderDelayController>(
+            RenderDelayController::Create(EchoCanceller3Config(), rate, 1)),
+        "");
+  }
+}
+
+#endif
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_signal_analyzer.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_signal_analyzer.cc
new file mode 100644
index 0000000..f570aac
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_signal_analyzer.cc
@@ -0,0 +1,156 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/render_signal_analyzer.h"
+
+#include <math.h>
+
+#include <algorithm>
+#include <utility>
+#include <vector>
+
+#include "api/array_view.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+namespace {
+constexpr size_t kCounterThreshold = 5;
+
+// Identifies local bands with narrow characteristics.
+void IdentifySmallNarrowBandRegions(
+    const RenderBuffer& render_buffer,
+    const absl::optional<size_t>& delay_partitions,
+    std::array<size_t, kFftLengthBy2 - 1>* narrow_band_counters) {
+  RTC_DCHECK(narrow_band_counters);
+
+  if (!delay_partitions) {
+    narrow_band_counters->fill(0);
+    return;
+  }
+
+  std::array<size_t, kFftLengthBy2 - 1> channel_counters;
+  channel_counters.fill(0);
+  rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> X2 =
+      render_buffer.Spectrum(*delay_partitions);
+  for (size_t ch = 0; ch < X2.size(); ++ch) {
+    for (size_t k = 1; k < kFftLengthBy2; ++k) {
+      if (X2[ch][k] > 3 * std::max(X2[ch][k - 1], X2[ch][k + 1])) {
+        ++channel_counters[k - 1];
+      }
+    }
+  }
+  for (size_t k = 1; k < kFftLengthBy2; ++k) {
+    (*narrow_band_counters)[k - 1] =
+        channel_counters[k - 1] > 0 ? (*narrow_band_counters)[k - 1] + 1 : 0;
+  }
+}
+
+// Identifies whether the signal has a single strong narrow-band component.
+void IdentifyStrongNarrowBandComponent(const RenderBuffer& render_buffer,
+                                       int strong_peak_freeze_duration,
+                                       absl::optional<int>* narrow_peak_band,
+                                       size_t* narrow_peak_counter) {
+  RTC_DCHECK(narrow_peak_band);
+  RTC_DCHECK(narrow_peak_counter);
+  if (*narrow_peak_band &&
+      ++(*narrow_peak_counter) >
+          static_cast<size_t>(strong_peak_freeze_duration)) {
+    *narrow_peak_band = absl::nullopt;
+  }
+
+  const std::vector<std::vector<std::vector<float>>>& x_latest =
+      render_buffer.Block(0);
+  float max_peak_level = 0.f;
+  for (size_t channel = 0; channel < x_latest[0].size(); ++channel) {
+    rtc::ArrayView<const float, kFftLengthBy2Plus1> X2_latest =
+        render_buffer.Spectrum(0)[channel];
+
+    // Identify the spectral peak.
+    const int peak_bin =
+        static_cast<int>(std::max_element(X2_latest.begin(), X2_latest.end()) -
+                         X2_latest.begin());
+
+    // Compute the level around the peak.
+    float non_peak_power = 0.f;
+    for (int k = std::max(0, peak_bin - 14); k < peak_bin - 4; ++k) {
+      non_peak_power = std::max(X2_latest[k], non_peak_power);
+    }
+    for (int k = peak_bin + 5;
+         k < std::min(peak_bin + 15, static_cast<int>(kFftLengthBy2Plus1));
+         ++k) {
+      non_peak_power = std::max(X2_latest[k], non_peak_power);
+    }
+
+    // Assess the render signal strength.
+    auto result0 = std::minmax_element(x_latest[0][channel].begin(),
+                                       x_latest[0][channel].end());
+    float max_abs = std::max(fabs(*result0.first), fabs(*result0.second));
+
+    if (x_latest.size() > 1) {
+      const auto result1 = std::minmax_element(x_latest[1][channel].begin(),
+                                               x_latest[1][channel].end());
+      max_abs =
+          std::max(max_abs, static_cast<float>(std::max(
+                                fabs(*result1.first), fabs(*result1.second))));
+    }
+
+    // Detect whether the spectral peak has as strong narrowband nature.
+    const float peak_level = X2_latest[peak_bin];
+    if (peak_bin > 0 && max_abs > 100 && peak_level > 100 * non_peak_power) {
+      // Store the strongest peak across channels.
+      if (peak_level > max_peak_level) {
+        max_peak_level = peak_level;
+        *narrow_peak_band = peak_bin;
+        *narrow_peak_counter = 0;
+      }
+    }
+  }
+}
+
+}  // namespace
+
+RenderSignalAnalyzer::RenderSignalAnalyzer(const EchoCanceller3Config& config)
+    : strong_peak_freeze_duration_(config.filter.refined.length_blocks) {
+  narrow_band_counters_.fill(0);
+}
+RenderSignalAnalyzer::~RenderSignalAnalyzer() = default;
+
+void RenderSignalAnalyzer::Update(
+    const RenderBuffer& render_buffer,
+    const absl::optional<size_t>& delay_partitions) {
+  // Identify bands of narrow nature.
+  IdentifySmallNarrowBandRegions(render_buffer, delay_partitions,
+                                 &narrow_band_counters_);
+
+  // Identify the presence of a strong narrow band.
+  IdentifyStrongNarrowBandComponent(render_buffer, strong_peak_freeze_duration_,
+                                    &narrow_peak_band_, &narrow_peak_counter_);
+}
+
+void RenderSignalAnalyzer::MaskRegionsAroundNarrowBands(
+    std::array<float, kFftLengthBy2Plus1>* v) const {
+  RTC_DCHECK(v);
+
+  // Set v to zero around narrow band signal regions.
+  if (narrow_band_counters_[0] > kCounterThreshold) {
+    (*v)[1] = (*v)[0] = 0.f;
+  }
+  for (size_t k = 2; k < kFftLengthBy2 - 1; ++k) {
+    if (narrow_band_counters_[k - 1] > kCounterThreshold) {
+      (*v)[k - 2] = (*v)[k - 1] = (*v)[k] = (*v)[k + 1] = (*v)[k + 2] = 0.f;
+    }
+  }
+  if (narrow_band_counters_[kFftLengthBy2 - 2] > kCounterThreshold) {
+    (*v)[kFftLengthBy2] = (*v)[kFftLengthBy2 - 1] = 0.f;
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_signal_analyzer.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_signal_analyzer.h
new file mode 100644
index 0000000..c7a3d8b
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_signal_analyzer.h
@@ -0,0 +1,62 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_RENDER_SIGNAL_ANALYZER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_RENDER_SIGNAL_ANALYZER_H_
+
+#include <algorithm>
+#include <array>
+#include <cstddef>
+
+#include "absl/types/optional.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/render_buffer.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+// Provides functionality for analyzing the properties of the render signal.
+class RenderSignalAnalyzer {
+ public:
+  explicit RenderSignalAnalyzer(const EchoCanceller3Config& config);
+  ~RenderSignalAnalyzer();
+
+  // Updates the render signal analysis with the most recent render signal.
+  void Update(const RenderBuffer& render_buffer,
+              const absl::optional<size_t>& delay_partitions);
+
+  // Returns true if the render signal is poorly exciting.
+  bool PoorSignalExcitation() const {
+    RTC_DCHECK_LT(2, narrow_band_counters_.size());
+    return std::any_of(narrow_band_counters_.begin(),
+                       narrow_band_counters_.end(),
+                       [](size_t a) { return a > 10; });
+  }
+
+  // Zeros the array around regions with narrow bands signal characteristics.
+  void MaskRegionsAroundNarrowBands(
+      std::array<float, kFftLengthBy2Plus1>* v) const;
+
+  absl::optional<int> NarrowPeakBand() const { return narrow_peak_band_; }
+
+ private:
+  const int strong_peak_freeze_duration_;
+  std::array<size_t, kFftLengthBy2 - 1> narrow_band_counters_;
+  absl::optional<int> narrow_peak_band_;
+  size_t narrow_peak_counter_;
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(RenderSignalAnalyzer);
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_RENDER_SIGNAL_ANALYZER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_signal_analyzer_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_signal_analyzer_unittest.cc
new file mode 100644
index 0000000..7a48cc4
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/render_signal_analyzer_unittest.cc
@@ -0,0 +1,175 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/render_signal_analyzer.h"
+
+#include <math.h>
+
+#include <array>
+#include <cmath>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/aec3_fft.h"
+#include "modules/audio_processing/aec3/fft_data.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "modules/audio_processing/test/echo_canceller_test_tools.h"
+#include "rtc_base/random.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace {
+
+constexpr float kPi = 3.141592f;
+
+void ProduceSinusoidInNoise(int sample_rate_hz,
+                            size_t sinusoid_channel,
+                            float sinusoidal_frequency_hz,
+                            Random* random_generator,
+                            size_t* sample_counter,
+                            std::vector<std::vector<std::vector<float>>>* x) {
+  // Fill x with low-amplitude noise.
+  for (auto& band : *x) {
+    for (auto& channel : band) {
+      RandomizeSampleVector(random_generator, channel,
+                            /*amplitude=*/500.f);
+    }
+  }
+  // Produce a sinusoid of the specified frequency in the specified channel.
+  for (size_t k = *sample_counter, j = 0; k < (*sample_counter + kBlockSize);
+       ++k, ++j) {
+    (*x)[0][sinusoid_channel][j] +=
+        32000.f *
+        std::sin(2.f * kPi * sinusoidal_frequency_hz * k / sample_rate_hz);
+  }
+  *sample_counter = *sample_counter + kBlockSize;
+}
+
+void RunNarrowBandDetectionTest(size_t num_channels) {
+  RenderSignalAnalyzer analyzer(EchoCanceller3Config{});
+  Random random_generator(42U);
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+  std::vector<std::vector<std::vector<float>>> x(
+      kNumBands, std::vector<std::vector<float>>(
+                     num_channels, std::vector<float>(kBlockSize, 0.f)));
+  std::array<float, kBlockSize> x_old;
+  Aec3Fft fft;
+  EchoCanceller3Config config;
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+      RenderDelayBuffer::Create(config, kSampleRateHz, num_channels));
+
+  std::array<float, kFftLengthBy2Plus1> mask;
+  x_old.fill(0.f);
+  constexpr int kSinusFrequencyBin = 32;
+
+  auto generate_sinusoid_test = [&](bool known_delay) {
+    size_t sample_counter = 0;
+    for (size_t k = 0; k < 100; ++k) {
+      ProduceSinusoidInNoise(16000, num_channels - 1,
+                             16000 / 2 * kSinusFrequencyBin / kFftLengthBy2,
+                             &random_generator, &sample_counter, &x);
+
+      render_delay_buffer->Insert(x);
+      if (k == 0) {
+        render_delay_buffer->Reset();
+      }
+      render_delay_buffer->PrepareCaptureProcessing();
+
+      analyzer.Update(*render_delay_buffer->GetRenderBuffer(),
+                      known_delay ? absl::optional<size_t>(0) : absl::nullopt);
+    }
+  };
+
+  generate_sinusoid_test(true);
+  mask.fill(1.f);
+  analyzer.MaskRegionsAroundNarrowBands(&mask);
+  for (int k = 0; k < static_cast<int>(mask.size()); ++k) {
+    EXPECT_EQ(abs(k - kSinusFrequencyBin) <= 2 ? 0.f : 1.f, mask[k]);
+  }
+  EXPECT_TRUE(analyzer.PoorSignalExcitation());
+  EXPECT_TRUE(static_cast<bool>(analyzer.NarrowPeakBand()));
+  EXPECT_EQ(*analyzer.NarrowPeakBand(), 32);
+
+  // Verify that no bands are detected as narrow when the delay is unknown.
+  generate_sinusoid_test(false);
+  mask.fill(1.f);
+  analyzer.MaskRegionsAroundNarrowBands(&mask);
+  std::for_each(mask.begin(), mask.end(), [](float a) { EXPECT_EQ(1.f, a); });
+  EXPECT_FALSE(analyzer.PoorSignalExcitation());
+}
+
+std::string ProduceDebugText(size_t num_channels) {
+  rtc::StringBuilder ss;
+  ss << "number of channels: " << num_channels;
+  return ss.Release();
+}
+}  // namespace
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+// Verifies that the check for non-null output parameter works.
+TEST(RenderSignalAnalyzerDeathTest, NullMaskOutput) {
+  RenderSignalAnalyzer analyzer(EchoCanceller3Config{});
+  EXPECT_DEATH(analyzer.MaskRegionsAroundNarrowBands(nullptr), "");
+}
+
+#endif
+
+// Verify that no narrow bands are detected in a Gaussian noise signal.
+TEST(RenderSignalAnalyzer, NoFalseDetectionOfNarrowBands) {
+  for (auto num_channels : {1, 2, 8}) {
+    SCOPED_TRACE(ProduceDebugText(num_channels));
+    RenderSignalAnalyzer analyzer(EchoCanceller3Config{});
+    Random random_generator(42U);
+    std::vector<std::vector<std::vector<float>>> x(
+        3, std::vector<std::vector<float>>(
+               num_channels, std::vector<float>(kBlockSize, 0.f)));
+    std::array<float, kBlockSize> x_old;
+    std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+        RenderDelayBuffer::Create(EchoCanceller3Config(), 48000, num_channels));
+    std::array<float, kFftLengthBy2Plus1> mask;
+    x_old.fill(0.f);
+
+    for (size_t k = 0; k < 100; ++k) {
+      for (auto& band : x) {
+        for (auto& channel : band) {
+          RandomizeSampleVector(&random_generator, channel);
+        }
+      }
+
+      render_delay_buffer->Insert(x);
+      if (k == 0) {
+        render_delay_buffer->Reset();
+      }
+      render_delay_buffer->PrepareCaptureProcessing();
+
+      analyzer.Update(*render_delay_buffer->GetRenderBuffer(),
+                      absl::optional<size_t>(0));
+    }
+
+    mask.fill(1.f);
+    analyzer.MaskRegionsAroundNarrowBands(&mask);
+    EXPECT_TRUE(std::all_of(mask.begin(), mask.end(),
+                            [](float a) { return a == 1.f; }));
+    EXPECT_FALSE(analyzer.PoorSignalExcitation());
+    EXPECT_FALSE(static_cast<bool>(analyzer.NarrowPeakBand()));
+  }
+}
+
+// Verify that a sinusoid signal is detected as narrow bands.
+TEST(RenderSignalAnalyzer, NarrowBandDetection) {
+  for (auto num_channels : {1, 2, 8}) {
+    SCOPED_TRACE(ProduceDebugText(num_channels));
+    RunNarrowBandDetectionTest(num_channels);
+  }
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/residual_echo_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/residual_echo_estimator.cc
new file mode 100644
index 0000000..0688429
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/residual_echo_estimator.cc
@@ -0,0 +1,365 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/residual_echo_estimator.h"
+
+#include <stddef.h>
+
+#include <algorithm>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/reverb_model.h"
+#include "rtc_base/checks.h"
+#include "system_wrappers/include/field_trial.h"
+
+namespace webrtc {
+namespace {
+
+constexpr float kDefaultTransparentModeGain = 0.01f;
+
+float GetTransparentModeGain() {
+  return kDefaultTransparentModeGain;
+}
+
+float GetEarlyReflectionsDefaultModeGain(
+    const EchoCanceller3Config::EpStrength& config) {
+  if (field_trial::IsEnabled("WebRTC-Aec3UseLowEarlyReflectionsDefaultGain")) {
+    return 0.1f;
+  }
+  return config.default_gain;
+}
+
+float GetLateReflectionsDefaultModeGain(
+    const EchoCanceller3Config::EpStrength& config) {
+  if (field_trial::IsEnabled("WebRTC-Aec3UseLowLateReflectionsDefaultGain")) {
+    return 0.1f;
+  }
+  return config.default_gain;
+}
+
+bool UseErleOnsetCompensationInDominantNearend(
+    const EchoCanceller3Config::EpStrength& config) {
+  return config.erle_onset_compensation_in_dominant_nearend ||
+         field_trial::IsEnabled(
+             "WebRTC-Aec3UseErleOnsetCompensationInDominantNearend");
+}
+
+// Computes the indexes that will be used for computing spectral power over
+// the blocks surrounding the delay.
+void GetRenderIndexesToAnalyze(
+    const SpectrumBuffer& spectrum_buffer,
+    const EchoCanceller3Config::EchoModel& echo_model,
+    int filter_delay_blocks,
+    int* idx_start,
+    int* idx_stop) {
+  RTC_DCHECK(idx_start);
+  RTC_DCHECK(idx_stop);
+  size_t window_start;
+  size_t window_end;
+  window_start =
+      std::max(0, filter_delay_blocks -
+                      static_cast<int>(echo_model.render_pre_window_size));
+  window_end = filter_delay_blocks +
+               static_cast<int>(echo_model.render_post_window_size);
+  *idx_start = spectrum_buffer.OffsetIndex(spectrum_buffer.read, window_start);
+  *idx_stop = spectrum_buffer.OffsetIndex(spectrum_buffer.read, window_end + 1);
+}
+
+// Estimates the residual echo power based on the echo return loss enhancement
+// (ERLE) and the linear power estimate.
+void LinearEstimate(
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> S2_linear,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> erle,
+    rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>> R2) {
+  RTC_DCHECK_EQ(S2_linear.size(), erle.size());
+  RTC_DCHECK_EQ(S2_linear.size(), R2.size());
+
+  const size_t num_capture_channels = R2.size();
+  for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+    for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+      RTC_DCHECK_LT(0.f, erle[ch][k]);
+      R2[ch][k] = S2_linear[ch][k] / erle[ch][k];
+    }
+  }
+}
+
+// Estimates the residual echo power based on the estimate of the echo path
+// gain.
+void NonLinearEstimate(
+    float echo_path_gain,
+    const std::array<float, kFftLengthBy2Plus1>& X2,
+    rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>> R2) {
+  const size_t num_capture_channels = R2.size();
+  for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+    for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+      R2[ch][k] = X2[k] * echo_path_gain;
+    }
+  }
+}
+
+// Applies a soft noise gate to the echo generating power.
+void ApplyNoiseGate(const EchoCanceller3Config::EchoModel& config,
+                    rtc::ArrayView<float, kFftLengthBy2Plus1> X2) {
+  for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+    if (config.noise_gate_power > X2[k]) {
+      X2[k] = std::max(0.f, X2[k] - config.noise_gate_slope *
+                                        (config.noise_gate_power - X2[k]));
+    }
+  }
+}
+
+// Estimates the echo generating signal power as gated maximal power over a
+// time window.
+void EchoGeneratingPower(size_t num_render_channels,
+                         const SpectrumBuffer& spectrum_buffer,
+                         const EchoCanceller3Config::EchoModel& echo_model,
+                         int filter_delay_blocks,
+                         rtc::ArrayView<float, kFftLengthBy2Plus1> X2) {
+  int idx_stop;
+  int idx_start;
+  GetRenderIndexesToAnalyze(spectrum_buffer, echo_model, filter_delay_blocks,
+                            &idx_start, &idx_stop);
+
+  std::fill(X2.begin(), X2.end(), 0.f);
+  if (num_render_channels == 1) {
+    for (int k = idx_start; k != idx_stop; k = spectrum_buffer.IncIndex(k)) {
+      for (size_t j = 0; j < kFftLengthBy2Plus1; ++j) {
+        X2[j] = std::max(X2[j], spectrum_buffer.buffer[k][/*channel=*/0][j]);
+      }
+    }
+  } else {
+    for (int k = idx_start; k != idx_stop; k = spectrum_buffer.IncIndex(k)) {
+      std::array<float, kFftLengthBy2Plus1> render_power;
+      render_power.fill(0.f);
+      for (size_t ch = 0; ch < num_render_channels; ++ch) {
+        const auto& channel_power = spectrum_buffer.buffer[k][ch];
+        for (size_t j = 0; j < kFftLengthBy2Plus1; ++j) {
+          render_power[j] += channel_power[j];
+        }
+      }
+      for (size_t j = 0; j < kFftLengthBy2Plus1; ++j) {
+        X2[j] = std::max(X2[j], render_power[j]);
+      }
+    }
+  }
+}
+
+}  // namespace
+
+ResidualEchoEstimator::ResidualEchoEstimator(const EchoCanceller3Config& config,
+                                             size_t num_render_channels)
+    : config_(config),
+      num_render_channels_(num_render_channels),
+      early_reflections_transparent_mode_gain_(GetTransparentModeGain()),
+      late_reflections_transparent_mode_gain_(GetTransparentModeGain()),
+      early_reflections_general_gain_(
+          GetEarlyReflectionsDefaultModeGain(config_.ep_strength)),
+      late_reflections_general_gain_(
+          GetLateReflectionsDefaultModeGain(config_.ep_strength)),
+      erle_onset_compensation_in_dominant_nearend_(
+          UseErleOnsetCompensationInDominantNearend(config_.ep_strength)) {
+  Reset();
+}
+
+ResidualEchoEstimator::~ResidualEchoEstimator() = default;
+
+void ResidualEchoEstimator::Estimate(
+    const AecState& aec_state,
+    const RenderBuffer& render_buffer,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> S2_linear,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Y2,
+    bool dominant_nearend,
+    rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>> R2) {
+  RTC_DCHECK_EQ(R2.size(), Y2.size());
+  RTC_DCHECK_EQ(R2.size(), S2_linear.size());
+
+  const size_t num_capture_channels = R2.size();
+
+  // Estimate the power of the stationary noise in the render signal.
+  UpdateRenderNoisePower(render_buffer);
+
+  // Estimate the residual echo power.
+  if (aec_state.UsableLinearEstimate()) {
+    // When there is saturated echo, assume the same spectral content as is
+    // present in the microphone signal.
+    if (aec_state.SaturatedEcho()) {
+      for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+        std::copy(Y2[ch].begin(), Y2[ch].end(), R2[ch].begin());
+      }
+    } else {
+      const bool onset_compensated =
+          erle_onset_compensation_in_dominant_nearend_ || !dominant_nearend;
+      LinearEstimate(S2_linear, aec_state.Erle(onset_compensated), R2);
+    }
+
+    AddReverb(ReverbType::kLinear, aec_state, render_buffer, R2);
+  } else {
+    const float echo_path_gain =
+        GetEchoPathGain(aec_state, /*gain_for_early_reflections=*/true);
+
+    // When there is saturated echo, assume the same spectral content as is
+    // present in the microphone signal.
+    if (aec_state.SaturatedEcho()) {
+      for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+        std::copy(Y2[ch].begin(), Y2[ch].end(), R2[ch].begin());
+      }
+    } else {
+      // Estimate the echo generating signal power.
+      std::array<float, kFftLengthBy2Plus1> X2;
+      EchoGeneratingPower(num_render_channels_,
+                          render_buffer.GetSpectrumBuffer(), config_.echo_model,
+                          aec_state.MinDirectPathFilterDelay(), X2);
+      if (!aec_state.UseStationarityProperties()) {
+        ApplyNoiseGate(config_.echo_model, X2);
+      }
+
+      // Subtract the stationary noise power to avoid stationary noise causing
+      // excessive echo suppression.
+      for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+        X2[k] -= config_.echo_model.stationary_gate_slope * X2_noise_floor_[k];
+        X2[k] = std::max(0.f, X2[k]);
+      }
+
+      NonLinearEstimate(echo_path_gain, X2, R2);
+    }
+
+    if (config_.echo_model.model_reverb_in_nonlinear_mode &&
+        !aec_state.TransparentModeActive()) {
+      AddReverb(ReverbType::kNonLinear, aec_state, render_buffer, R2);
+    }
+  }
+
+  if (aec_state.UseStationarityProperties()) {
+    // Scale the echo according to echo audibility.
+    std::array<float, kFftLengthBy2Plus1> residual_scaling;
+    aec_state.GetResidualEchoScaling(residual_scaling);
+    for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+      for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+        R2[ch][k] *= residual_scaling[k];
+      }
+    }
+  }
+}
+
+void ResidualEchoEstimator::Reset() {
+  echo_reverb_.Reset();
+  X2_noise_floor_counter_.fill(config_.echo_model.noise_floor_hold);
+  X2_noise_floor_.fill(config_.echo_model.min_noise_floor_power);
+}
+
+void ResidualEchoEstimator::UpdateRenderNoisePower(
+    const RenderBuffer& render_buffer) {
+  std::array<float, kFftLengthBy2Plus1> render_power_data;
+  rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> X2 =
+      render_buffer.Spectrum(0);
+  rtc::ArrayView<const float, kFftLengthBy2Plus1> render_power =
+      X2[/*channel=*/0];
+  if (num_render_channels_ > 1) {
+    render_power_data.fill(0.f);
+    for (size_t ch = 0; ch < num_render_channels_; ++ch) {
+      const auto& channel_power = X2[ch];
+      for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+        render_power_data[k] += channel_power[k];
+      }
+    }
+    render_power = render_power_data;
+  }
+
+  // Estimate the stationary noise power in a minimum statistics manner.
+  for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+    // Decrease rapidly.
+    if (render_power[k] < X2_noise_floor_[k]) {
+      X2_noise_floor_[k] = render_power[k];
+      X2_noise_floor_counter_[k] = 0;
+    } else {
+      // Increase in a delayed, leaky manner.
+      if (X2_noise_floor_counter_[k] >=
+          static_cast<int>(config_.echo_model.noise_floor_hold)) {
+        X2_noise_floor_[k] = std::max(X2_noise_floor_[k] * 1.1f,
+                                      config_.echo_model.min_noise_floor_power);
+      } else {
+        ++X2_noise_floor_counter_[k];
+      }
+    }
+  }
+}
+
+// Adds the estimated power of the reverb to the residual echo power.
+void ResidualEchoEstimator::AddReverb(
+    ReverbType reverb_type,
+    const AecState& aec_state,
+    const RenderBuffer& render_buffer,
+    rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>> R2) {
+  const size_t num_capture_channels = R2.size();
+
+  // Choose reverb partition based on what type of echo power model is used.
+  const size_t first_reverb_partition =
+      reverb_type == ReverbType::kLinear
+          ? aec_state.FilterLengthBlocks() + 1
+          : aec_state.MinDirectPathFilterDelay() + 1;
+
+  // Compute render power for the reverb.
+  std::array<float, kFftLengthBy2Plus1> render_power_data;
+  rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> X2 =
+      render_buffer.Spectrum(first_reverb_partition);
+  rtc::ArrayView<const float, kFftLengthBy2Plus1> render_power =
+      X2[/*channel=*/0];
+  if (num_render_channels_ > 1) {
+    render_power_data.fill(0.f);
+    for (size_t ch = 0; ch < num_render_channels_; ++ch) {
+      const auto& channel_power = X2[ch];
+      for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+        render_power_data[k] += channel_power[k];
+      }
+    }
+    render_power = render_power_data;
+  }
+
+  // Update the reverb estimate.
+  if (reverb_type == ReverbType::kLinear) {
+    echo_reverb_.UpdateReverb(render_power,
+                              aec_state.GetReverbFrequencyResponse(),
+                              aec_state.ReverbDecay());
+  } else {
+    const float echo_path_gain =
+        GetEchoPathGain(aec_state, /*gain_for_early_reflections=*/false);
+    echo_reverb_.UpdateReverbNoFreqShaping(render_power, echo_path_gain,
+                                           aec_state.ReverbDecay());
+  }
+
+  // Add the reverb power.
+  rtc::ArrayView<const float, kFftLengthBy2Plus1> reverb_power =
+      echo_reverb_.reverb();
+  for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+    for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+      R2[ch][k] += reverb_power[k];
+    }
+  }
+}
+
+// Chooses the echo path gain to use.
+float ResidualEchoEstimator::GetEchoPathGain(
+    const AecState& aec_state,
+    bool gain_for_early_reflections) const {
+  float gain_amplitude;
+  if (aec_state.TransparentModeActive()) {
+    gain_amplitude = gain_for_early_reflections
+                         ? early_reflections_transparent_mode_gain_
+                         : late_reflections_transparent_mode_gain_;
+  } else {
+    gain_amplitude = gain_for_early_reflections
+                         ? early_reflections_general_gain_
+                         : late_reflections_general_gain_;
+  }
+  return gain_amplitude * gain_amplitude;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/residual_echo_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/residual_echo_estimator.h
new file mode 100644
index 0000000..9e97776
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/residual_echo_estimator.h
@@ -0,0 +1,80 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_RESIDUAL_ECHO_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_RESIDUAL_ECHO_ESTIMATOR_H_
+
+#include <array>
+#include <memory>
+
+#include "absl/types/optional.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/aec_state.h"
+#include "modules/audio_processing/aec3/render_buffer.h"
+#include "modules/audio_processing/aec3/reverb_model.h"
+#include "modules/audio_processing/aec3/spectrum_buffer.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+class ResidualEchoEstimator {
+ public:
+  ResidualEchoEstimator(const EchoCanceller3Config& config,
+                        size_t num_render_channels);
+  ~ResidualEchoEstimator();
+
+  ResidualEchoEstimator(const ResidualEchoEstimator&) = delete;
+  ResidualEchoEstimator& operator=(const ResidualEchoEstimator&) = delete;
+
+  void Estimate(
+      const AecState& aec_state,
+      const RenderBuffer& render_buffer,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> S2_linear,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Y2,
+      bool dominant_nearend,
+      rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>> R2);
+
+ private:
+  enum class ReverbType { kLinear, kNonLinear };
+
+  // Resets the state.
+  void Reset();
+
+  // Updates estimate for the power of the stationary noise component in the
+  // render signal.
+  void UpdateRenderNoisePower(const RenderBuffer& render_buffer);
+
+  // Adds the estimated unmodelled echo power to the residual echo power
+  // estimate.
+  void AddReverb(ReverbType reverb_type,
+                 const AecState& aec_state,
+                 const RenderBuffer& render_buffer,
+                 rtc::ArrayView<std::array<float, kFftLengthBy2Plus1>> R2);
+
+  // Gets the echo path gain to apply.
+  float GetEchoPathGain(const AecState& aec_state,
+                        bool gain_for_early_reflections) const;
+
+  const EchoCanceller3Config config_;
+  const size_t num_render_channels_;
+  const float early_reflections_transparent_mode_gain_;
+  const float late_reflections_transparent_mode_gain_;
+  const float early_reflections_general_gain_;
+  const float late_reflections_general_gain_;
+  const bool erle_onset_compensation_in_dominant_nearend_;
+  std::array<float, kFftLengthBy2Plus1> X2_noise_floor_;
+  std::array<int, kFftLengthBy2Plus1> X2_noise_floor_counter_;
+  ReverbModel echo_reverb_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_RESIDUAL_ECHO_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/residual_echo_estimator_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/residual_echo_estimator_unittest.cc
new file mode 100644
index 0000000..e80838b
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/residual_echo_estimator_unittest.cc
@@ -0,0 +1,107 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/residual_echo_estimator.h"
+
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_fft.h"
+#include "modules/audio_processing/aec3/aec_state.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "modules/audio_processing/test/echo_canceller_test_tools.h"
+#include "rtc_base/random.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+class ResidualEchoEstimatorMultiChannel
+    : public ::testing::Test,
+      public ::testing::WithParamInterface<std::tuple<size_t, size_t>> {};
+
+INSTANTIATE_TEST_SUITE_P(MultiChannel,
+                         ResidualEchoEstimatorMultiChannel,
+                         ::testing::Combine(::testing::Values(1, 2, 4),
+                                            ::testing::Values(1, 2, 4)));
+
+TEST_P(ResidualEchoEstimatorMultiChannel, BasicTest) {
+  const size_t num_render_channels = std::get<0>(GetParam());
+  const size_t num_capture_channels = std::get<1>(GetParam());
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+
+  EchoCanceller3Config config;
+  ResidualEchoEstimator estimator(config, num_render_channels);
+  AecState aec_state(config, num_capture_channels);
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+      RenderDelayBuffer::Create(config, kSampleRateHz, num_render_channels));
+
+  std::vector<std::array<float, kFftLengthBy2Plus1>> E2_refined(
+      num_capture_channels);
+  std::vector<std::array<float, kFftLengthBy2Plus1>> S2_linear(
+      num_capture_channels);
+  std::vector<std::array<float, kFftLengthBy2Plus1>> Y2(num_capture_channels);
+  std::vector<std::array<float, kFftLengthBy2Plus1>> R2(num_capture_channels);
+  std::vector<std::vector<std::vector<float>>> x(
+      kNumBands, std::vector<std::vector<float>>(
+                     num_render_channels, std::vector<float>(kBlockSize, 0.f)));
+  std::vector<std::vector<std::array<float, kFftLengthBy2Plus1>>> H2(
+      num_capture_channels,
+      std::vector<std::array<float, kFftLengthBy2Plus1>>(10));
+  Random random_generator(42U);
+  std::vector<SubtractorOutput> output(num_capture_channels);
+  std::array<float, kBlockSize> y;
+  absl::optional<DelayEstimate> delay_estimate;
+
+  for (auto& H2_ch : H2) {
+    for (auto& H2_k : H2_ch) {
+      H2_k.fill(0.01f);
+    }
+    H2_ch[2].fill(10.f);
+    H2_ch[2][0] = 0.1f;
+  }
+
+  std::vector<std::vector<float>> h(
+      num_capture_channels,
+      std::vector<float>(
+          GetTimeDomainLength(config.filter.refined.length_blocks), 0.f));
+
+  for (auto& subtractor_output : output) {
+    subtractor_output.Reset();
+    subtractor_output.s_refined.fill(100.f);
+  }
+  y.fill(0.f);
+
+  constexpr float kLevel = 10.f;
+  for (auto& E2_refined_ch : E2_refined) {
+    E2_refined_ch.fill(kLevel);
+  }
+  S2_linear[0].fill(kLevel);
+  for (auto& Y2_ch : Y2) {
+    Y2_ch.fill(kLevel);
+  }
+
+  for (int k = 0; k < 1993; ++k) {
+    RandomizeSampleVector(&random_generator, x[0][0]);
+    render_delay_buffer->Insert(x);
+    if (k == 0) {
+      render_delay_buffer->Reset();
+    }
+    render_delay_buffer->PrepareCaptureProcessing();
+
+    aec_state.Update(delay_estimate, H2, h,
+                     *render_delay_buffer->GetRenderBuffer(), E2_refined, Y2,
+                     output);
+
+    estimator.Estimate(aec_state, *render_delay_buffer->GetRenderBuffer(),
+                       S2_linear, Y2, /*dominant_nearend=*/false, R2);
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_decay_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_decay_estimator.cc
new file mode 100644
index 0000000..f160b83
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_decay_estimator.cc
@@ -0,0 +1,409 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/reverb_decay_estimator.h"
+
+#include <stddef.h>
+
+#include <algorithm>
+#include <cmath>
+#include <numeric>
+
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+namespace {
+
+constexpr int kEarlyReverbMinSizeBlocks = 3;
+constexpr int kBlocksPerSection = 6;
+// Linear regression approach assumes symmetric index around 0.
+constexpr float kEarlyReverbFirstPointAtLinearRegressors =
+    -0.5f * kBlocksPerSection * kFftLengthBy2 + 0.5f;
+
+// Averages the values in a block of size kFftLengthBy2;
+float BlockAverage(rtc::ArrayView<const float> v, size_t block_index) {
+  constexpr float kOneByFftLengthBy2 = 1.f / kFftLengthBy2;
+  const int i = block_index * kFftLengthBy2;
+  RTC_DCHECK_GE(v.size(), i + kFftLengthBy2);
+  const float sum =
+      std::accumulate(v.begin() + i, v.begin() + i + kFftLengthBy2, 0.f);
+  return sum * kOneByFftLengthBy2;
+}
+
+// Analyzes the gain in a block.
+void AnalyzeBlockGain(const std::array<float, kFftLengthBy2>& h2,
+                      float floor_gain,
+                      float* previous_gain,
+                      bool* block_adapting,
+                      bool* decaying_gain) {
+  float gain = std::max(BlockAverage(h2, 0), 1e-32f);
+  *block_adapting =
+      *previous_gain > 1.1f * gain || *previous_gain < 0.9f * gain;
+  *decaying_gain = gain > floor_gain;
+  *previous_gain = gain;
+}
+
+// Arithmetic sum of $2 \sum_{i=0.5}^{(N-1)/2}i^2$ calculated directly.
+constexpr float SymmetricArithmetricSum(int N) {
+  return N * (N * N - 1.0f) * (1.f / 12.f);
+}
+
+// Returns the peak energy of an impulse response.
+float BlockEnergyPeak(rtc::ArrayView<const float> h, int peak_block) {
+  RTC_DCHECK_LE((peak_block + 1) * kFftLengthBy2, h.size());
+  RTC_DCHECK_GE(peak_block, 0);
+  float peak_value =
+      *std::max_element(h.begin() + peak_block * kFftLengthBy2,
+                        h.begin() + (peak_block + 1) * kFftLengthBy2,
+                        [](float a, float b) { return a * a < b * b; });
+  return peak_value * peak_value;
+}
+
+// Returns the average energy of an impulse response block.
+float BlockEnergyAverage(rtc::ArrayView<const float> h, int block_index) {
+  RTC_DCHECK_LE((block_index + 1) * kFftLengthBy2, h.size());
+  RTC_DCHECK_GE(block_index, 0);
+  constexpr float kOneByFftLengthBy2 = 1.f / kFftLengthBy2;
+  const auto sum_of_squares = [](float a, float b) { return a + b * b; };
+  return std::accumulate(h.begin() + block_index * kFftLengthBy2,
+                         h.begin() + (block_index + 1) * kFftLengthBy2, 0.f,
+                         sum_of_squares) *
+         kOneByFftLengthBy2;
+}
+
+}  // namespace
+
+ReverbDecayEstimator::ReverbDecayEstimator(const EchoCanceller3Config& config)
+    : filter_length_blocks_(config.filter.refined.length_blocks),
+      filter_length_coefficients_(GetTimeDomainLength(filter_length_blocks_)),
+      use_adaptive_echo_decay_(config.ep_strength.default_len < 0.f),
+      early_reverb_estimator_(config.filter.refined.length_blocks -
+                              kEarlyReverbMinSizeBlocks),
+      late_reverb_start_(kEarlyReverbMinSizeBlocks),
+      late_reverb_end_(kEarlyReverbMinSizeBlocks),
+      previous_gains_(config.filter.refined.length_blocks, 0.f),
+      decay_(std::fabs(config.ep_strength.default_len)) {
+  RTC_DCHECK_GT(config.filter.refined.length_blocks,
+                static_cast<size_t>(kEarlyReverbMinSizeBlocks));
+}
+
+ReverbDecayEstimator::~ReverbDecayEstimator() = default;
+
+void ReverbDecayEstimator::Update(rtc::ArrayView<const float> filter,
+                                  const absl::optional<float>& filter_quality,
+                                  int filter_delay_blocks,
+                                  bool usable_linear_filter,
+                                  bool stationary_signal) {
+  const int filter_size = static_cast<int>(filter.size());
+
+  if (stationary_signal) {
+    return;
+  }
+
+  bool estimation_feasible =
+      filter_delay_blocks <=
+      filter_length_blocks_ - kEarlyReverbMinSizeBlocks - 1;
+  estimation_feasible =
+      estimation_feasible && filter_size == filter_length_coefficients_;
+  estimation_feasible = estimation_feasible && filter_delay_blocks > 0;
+  estimation_feasible = estimation_feasible && usable_linear_filter;
+
+  if (!estimation_feasible) {
+    ResetDecayEstimation();
+    return;
+  }
+
+  if (!use_adaptive_echo_decay_) {
+    return;
+  }
+
+  const float new_smoothing = filter_quality ? *filter_quality * 0.2f : 0.f;
+  smoothing_constant_ = std::max(new_smoothing, smoothing_constant_);
+  if (smoothing_constant_ == 0.f) {
+    return;
+  }
+
+  if (block_to_analyze_ < filter_length_blocks_) {
+    // Analyze the filter and accumulate data for reverb estimation.
+    AnalyzeFilter(filter);
+    ++block_to_analyze_;
+  } else {
+    // When the filter is fully analyzed, estimate the reverb decay and reset
+    // the block_to_analyze_ counter.
+    EstimateDecay(filter, filter_delay_blocks);
+  }
+}
+
+void ReverbDecayEstimator::ResetDecayEstimation() {
+  early_reverb_estimator_.Reset();
+  late_reverb_decay_estimator_.Reset(0);
+  block_to_analyze_ = 0;
+  estimation_region_candidate_size_ = 0;
+  estimation_region_identified_ = false;
+  smoothing_constant_ = 0.f;
+  late_reverb_start_ = 0;
+  late_reverb_end_ = 0;
+}
+
+void ReverbDecayEstimator::EstimateDecay(rtc::ArrayView<const float> filter,
+                                         int peak_block) {
+  auto& h = filter;
+  RTC_DCHECK_EQ(0, h.size() % kFftLengthBy2);
+
+  // Reset the block analysis counter.
+  block_to_analyze_ =
+      std::min(peak_block + kEarlyReverbMinSizeBlocks, filter_length_blocks_);
+
+  // To estimate the reverb decay, the energy of the first filter section must
+  // be substantially larger than the last. Also, the first filter section
+  // energy must not deviate too much from the max peak.
+  const float first_reverb_gain = BlockEnergyAverage(h, block_to_analyze_);
+  const size_t h_size_blocks = h.size() >> kFftLengthBy2Log2;
+  tail_gain_ = BlockEnergyAverage(h, h_size_blocks - 1);
+  float peak_energy = BlockEnergyPeak(h, peak_block);
+  const bool sufficient_reverb_decay = first_reverb_gain > 4.f * tail_gain_;
+  const bool valid_filter =
+      first_reverb_gain > 2.f * tail_gain_ && peak_energy < 100.f;
+
+  // Estimate the size of the regions with early and late reflections.
+  const int size_early_reverb = early_reverb_estimator_.Estimate();
+  const int size_late_reverb =
+      std::max(estimation_region_candidate_size_ - size_early_reverb, 0);
+
+  // Only update the reverb decay estimate if the size of the identified late
+  // reverb is sufficiently large.
+  if (size_late_reverb >= 5) {
+    if (valid_filter && late_reverb_decay_estimator_.EstimateAvailable()) {
+      float decay = std::pow(
+          2.0f, late_reverb_decay_estimator_.Estimate() * kFftLengthBy2);
+      constexpr float kMaxDecay = 0.95f;  // ~1 sec min RT60.
+      constexpr float kMinDecay = 0.02f;  // ~15 ms max RT60.
+      decay = std::max(.97f * decay_, decay);
+      decay = std::min(decay, kMaxDecay);
+      decay = std::max(decay, kMinDecay);
+      decay_ += smoothing_constant_ * (decay - decay_);
+    }
+
+    // Update length of decay. Must have enough data (number of sections) in
+    // order to estimate decay rate.
+    late_reverb_decay_estimator_.Reset(size_late_reverb * kFftLengthBy2);
+    late_reverb_start_ =
+        peak_block + kEarlyReverbMinSizeBlocks + size_early_reverb;
+    late_reverb_end_ =
+        block_to_analyze_ + estimation_region_candidate_size_ - 1;
+  } else {
+    late_reverb_decay_estimator_.Reset(0);
+    late_reverb_start_ = 0;
+    late_reverb_end_ = 0;
+  }
+
+  // Reset variables for the identification of the region for reverb decay
+  // estimation.
+  estimation_region_identified_ = !(valid_filter && sufficient_reverb_decay);
+  estimation_region_candidate_size_ = 0;
+
+  // Stop estimation of the decay until another good filter is received.
+  smoothing_constant_ = 0.f;
+
+  // Reset early reflections detector.
+  early_reverb_estimator_.Reset();
+}
+
+void ReverbDecayEstimator::AnalyzeFilter(rtc::ArrayView<const float> filter) {
+  auto h = rtc::ArrayView<const float>(
+      filter.begin() + block_to_analyze_ * kFftLengthBy2, kFftLengthBy2);
+
+  // Compute squared filter coeffiecients for the block to analyze_;
+  std::array<float, kFftLengthBy2> h2;
+  std::transform(h.begin(), h.end(), h2.begin(), [](float a) { return a * a; });
+
+  // Map out the region for estimating the reverb decay.
+  bool adapting;
+  bool above_noise_floor;
+  AnalyzeBlockGain(h2, tail_gain_, &previous_gains_[block_to_analyze_],
+                   &adapting, &above_noise_floor);
+
+  // Count consecutive number of "good" filter sections, where "good" means:
+  // 1) energy is above noise floor.
+  // 2) energy of current section has not changed too much from last check.
+  estimation_region_identified_ =
+      estimation_region_identified_ || adapting || !above_noise_floor;
+  if (!estimation_region_identified_) {
+    ++estimation_region_candidate_size_;
+  }
+
+  // Accumulate data for reverb decay estimation and for the estimation of early
+  // reflections.
+  if (block_to_analyze_ <= late_reverb_end_) {
+    if (block_to_analyze_ >= late_reverb_start_) {
+      for (float h2_k : h2) {
+        float h2_log2 = FastApproxLog2f(h2_k + 1e-10);
+        late_reverb_decay_estimator_.Accumulate(h2_log2);
+        early_reverb_estimator_.Accumulate(h2_log2, smoothing_constant_);
+      }
+    } else {
+      for (float h2_k : h2) {
+        float h2_log2 = FastApproxLog2f(h2_k + 1e-10);
+        early_reverb_estimator_.Accumulate(h2_log2, smoothing_constant_);
+      }
+    }
+  }
+}
+
+void ReverbDecayEstimator::Dump(ApmDataDumper* data_dumper) const {
+  data_dumper->DumpRaw("aec3_reverb_decay", decay_);
+  data_dumper->DumpRaw("aec3_reverb_tail_energy", tail_gain_);
+  data_dumper->DumpRaw("aec3_reverb_alpha", smoothing_constant_);
+  data_dumper->DumpRaw("aec3_num_reverb_decay_blocks",
+                       late_reverb_end_ - late_reverb_start_);
+  data_dumper->DumpRaw("aec3_late_reverb_start", late_reverb_start_);
+  data_dumper->DumpRaw("aec3_late_reverb_end", late_reverb_end_);
+  early_reverb_estimator_.Dump(data_dumper);
+}
+
+void ReverbDecayEstimator::LateReverbLinearRegressor::Reset(
+    int num_data_points) {
+  RTC_DCHECK_LE(0, num_data_points);
+  RTC_DCHECK_EQ(0, num_data_points % 2);
+  const int N = num_data_points;
+  nz_ = 0.f;
+  // Arithmetic sum of $2 \sum_{i=0.5}^{(N-1)/2}i^2$ calculated directly.
+  nn_ = SymmetricArithmetricSum(N);
+  // The linear regression approach assumes symmetric index around 0.
+  count_ = N > 0 ? -N * 0.5f + 0.5f : 0.f;
+  N_ = N;
+  n_ = 0;
+}
+
+void ReverbDecayEstimator::LateReverbLinearRegressor::Accumulate(float z) {
+  nz_ += count_ * z;
+  ++count_;
+  ++n_;
+}
+
+float ReverbDecayEstimator::LateReverbLinearRegressor::Estimate() {
+  RTC_DCHECK(EstimateAvailable());
+  if (nn_ == 0.f) {
+    RTC_NOTREACHED();
+    return 0.f;
+  }
+  return nz_ / nn_;
+}
+
+ReverbDecayEstimator::EarlyReverbLengthEstimator::EarlyReverbLengthEstimator(
+    int max_blocks)
+    : numerators_smooth_(max_blocks - kBlocksPerSection, 0.f),
+      numerators_(numerators_smooth_.size(), 0.f),
+      coefficients_counter_(0) {
+  RTC_DCHECK_LE(0, max_blocks);
+}
+
+ReverbDecayEstimator::EarlyReverbLengthEstimator::
+    ~EarlyReverbLengthEstimator() = default;
+
+void ReverbDecayEstimator::EarlyReverbLengthEstimator::Reset() {
+  coefficients_counter_ = 0;
+  std::fill(numerators_.begin(), numerators_.end(), 0.f);
+  block_counter_ = 0;
+}
+
+void ReverbDecayEstimator::EarlyReverbLengthEstimator::Accumulate(
+    float value,
+    float smoothing) {
+  // Each section is composed by kBlocksPerSection blocks and each section
+  // overlaps with the next one in (kBlocksPerSection - 1) blocks. For example,
+  // the first section covers the blocks [0:5], the second covers the blocks
+  // [1:6] and so on. As a result, for each value, kBlocksPerSection sections
+  // need to be updated.
+  int first_section_index = std::max(block_counter_ - kBlocksPerSection + 1, 0);
+  int last_section_index =
+      std::min(block_counter_, static_cast<int>(numerators_.size() - 1));
+  float x_value = static_cast<float>(coefficients_counter_) +
+                  kEarlyReverbFirstPointAtLinearRegressors;
+  const float value_to_inc = kFftLengthBy2 * value;
+  float value_to_add =
+      x_value * value + (block_counter_ - last_section_index) * value_to_inc;
+  for (int section = last_section_index; section >= first_section_index;
+       --section, value_to_add += value_to_inc) {
+    numerators_[section] += value_to_add;
+  }
+
+  // Check if this update was the last coefficient of the current block. In that
+  // case, check if we are at the end of one of the sections and update the
+  // numerator of the linear regressor that is computed in such section.
+  if (++coefficients_counter_ == kFftLengthBy2) {
+    if (block_counter_ >= (kBlocksPerSection - 1)) {
+      size_t section = block_counter_ - (kBlocksPerSection - 1);
+      RTC_DCHECK_GT(numerators_.size(), section);
+      RTC_DCHECK_GT(numerators_smooth_.size(), section);
+      numerators_smooth_[section] +=
+          smoothing * (numerators_[section] - numerators_smooth_[section]);
+      n_sections_ = section + 1;
+    }
+    ++block_counter_;
+    coefficients_counter_ = 0;
+  }
+}
+
+// Estimates the size in blocks of the early reverb. The estimation is done by
+// comparing the tilt that is estimated in each section. As an optimization
+// detail and due to the fact that all the linear regressors that are computed
+// shared the same denominator, the comparison of the tilts is done by a
+// comparison of the numerator of the linear regressors.
+int ReverbDecayEstimator::EarlyReverbLengthEstimator::Estimate() {
+  constexpr float N = kBlocksPerSection * kFftLengthBy2;
+  constexpr float nn = SymmetricArithmetricSum(N);
+  // numerator_11 refers to the quantity that the linear regressor needs in the
+  // numerator for getting a decay equal to 1.1 (which is not a decay).
+  // log2(1.1) * nn / kFftLengthBy2.
+  constexpr float numerator_11 = 0.13750352374993502f * nn / kFftLengthBy2;
+  // log2(0.8) *  nn / kFftLengthBy2.
+  constexpr float numerator_08 = -0.32192809488736229f * nn / kFftLengthBy2;
+  constexpr int kNumSectionsToAnalyze = 9;
+
+  if (n_sections_ < kNumSectionsToAnalyze) {
+    return 0;
+  }
+
+  // Estimation of the blocks that correspond to early reverberations. The
+  // estimation is done by analyzing the impulse response. The portions of the
+  // impulse response whose energy is not decreasing over its coefficients are
+  // considered to be part of the early reverberations. Furthermore, the blocks
+  // where the energy is decreasing faster than what it does at the end of the
+  // impulse response are also considered to be part of the early
+  // reverberations. The estimation is limited to the first
+  // kNumSectionsToAnalyze sections.
+
+  RTC_DCHECK_LE(n_sections_, numerators_smooth_.size());
+  const float min_numerator_tail =
+      *std::min_element(numerators_smooth_.begin() + kNumSectionsToAnalyze,
+                        numerators_smooth_.begin() + n_sections_);
+  int early_reverb_size_minus_1 = 0;
+  for (int k = 0; k < kNumSectionsToAnalyze; ++k) {
+    if ((numerators_smooth_[k] > numerator_11) ||
+        (numerators_smooth_[k] < numerator_08 &&
+         numerators_smooth_[k] < 0.9f * min_numerator_tail)) {
+      early_reverb_size_minus_1 = k;
+    }
+  }
+
+  return early_reverb_size_minus_1 == 0 ? 0 : early_reverb_size_minus_1 + 1;
+}
+
+void ReverbDecayEstimator::EarlyReverbLengthEstimator::Dump(
+    ApmDataDumper* data_dumper) const {
+  data_dumper->DumpRaw("aec3_er_acum_numerator", numerators_smooth_);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_decay_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_decay_estimator.h
new file mode 100644
index 0000000..3bb9b2b
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_decay_estimator.h
@@ -0,0 +1,112 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_REVERB_DECAY_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_REVERB_DECAY_ESTIMATOR_H_
+
+#include <array>
+#include <vector>
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"  // kMaxAdaptiveFilter...
+
+namespace webrtc {
+
+class ApmDataDumper;
+struct EchoCanceller3Config;
+
+// Class for estimating the decay of the late reverb.
+class ReverbDecayEstimator {
+ public:
+  explicit ReverbDecayEstimator(const EchoCanceller3Config& config);
+  ~ReverbDecayEstimator();
+  // Updates the decay estimate.
+  void Update(rtc::ArrayView<const float> filter,
+              const absl::optional<float>& filter_quality,
+              int filter_delay_blocks,
+              bool usable_linear_filter,
+              bool stationary_signal);
+  // Returns the decay for the exponential model.
+  float Decay() const { return decay_; }
+  // Dumps debug data.
+  void Dump(ApmDataDumper* data_dumper) const;
+
+ private:
+  void EstimateDecay(rtc::ArrayView<const float> filter, int peak_block);
+  void AnalyzeFilter(rtc::ArrayView<const float> filter);
+
+  void ResetDecayEstimation();
+
+  // Class for estimating the decay of the late reverb from the linear filter.
+  class LateReverbLinearRegressor {
+   public:
+    // Resets the estimator to receive a specified number of data points.
+    void Reset(int num_data_points);
+    // Accumulates estimation data.
+    void Accumulate(float z);
+    // Estimates the decay.
+    float Estimate();
+    // Returns whether an estimate is available.
+    bool EstimateAvailable() const { return n_ == N_ && N_ != 0; }
+
+   public:
+    float nz_ = 0.f;
+    float nn_ = 0.f;
+    float count_ = 0.f;
+    int N_ = 0;
+    int n_ = 0;
+  };
+
+  // Class for identifying the length of the early reverb from the linear
+  // filter. For identifying the early reverberations, the impulse response is
+  // divided in sections and the tilt of each section is computed by a linear
+  // regressor.
+  class EarlyReverbLengthEstimator {
+   public:
+    explicit EarlyReverbLengthEstimator(int max_blocks);
+    ~EarlyReverbLengthEstimator();
+
+    // Resets the estimator.
+    void Reset();
+    // Accumulates estimation data.
+    void Accumulate(float value, float smoothing);
+    // Estimates the size in blocks of the early reverb.
+    int Estimate();
+    // Dumps debug data.
+    void Dump(ApmDataDumper* data_dumper) const;
+
+   private:
+    std::vector<float> numerators_smooth_;
+    std::vector<float> numerators_;
+    int coefficients_counter_;
+    int block_counter_ = 0;
+    int n_sections_ = 0;
+  };
+
+  const int filter_length_blocks_;
+  const int filter_length_coefficients_;
+  const bool use_adaptive_echo_decay_;
+  LateReverbLinearRegressor late_reverb_decay_estimator_;
+  EarlyReverbLengthEstimator early_reverb_estimator_;
+  int late_reverb_start_;
+  int late_reverb_end_;
+  int block_to_analyze_ = 0;
+  int estimation_region_candidate_size_ = 0;
+  bool estimation_region_identified_ = false;
+  std::vector<float> previous_gains_;
+  float decay_;
+  float tail_gain_ = 0.f;
+  float smoothing_constant_ = 0.f;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_REVERB_DECAY_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_frequency_response.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_frequency_response.cc
new file mode 100644
index 0000000..f4bd91f
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_frequency_response.cc
@@ -0,0 +1,98 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/reverb_frequency_response.h"
+
+#include <stddef.h>
+
+#include <algorithm>
+#include <array>
+#include <numeric>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+namespace {
+
+// Computes the ratio of the energies between the direct path and the tail. The
+// energy is computed in the power spectrum domain discarding the DC
+// contributions.
+float AverageDecayWithinFilter(
+    rtc::ArrayView<const float> freq_resp_direct_path,
+    rtc::ArrayView<const float> freq_resp_tail) {
+  // Skipping the DC for the ratio computation
+  constexpr size_t kSkipBins = 1;
+  RTC_CHECK_EQ(freq_resp_direct_path.size(), freq_resp_tail.size());
+
+  float direct_path_energy =
+      std::accumulate(freq_resp_direct_path.begin() + kSkipBins,
+                      freq_resp_direct_path.end(), 0.f);
+
+  if (direct_path_energy == 0.f) {
+    return 0.f;
+  }
+
+  float tail_energy = std::accumulate(freq_resp_tail.begin() + kSkipBins,
+                                      freq_resp_tail.end(), 0.f);
+  return tail_energy / direct_path_energy;
+}
+
+}  // namespace
+
+ReverbFrequencyResponse::ReverbFrequencyResponse() {
+  tail_response_.fill(0.f);
+}
+ReverbFrequencyResponse::~ReverbFrequencyResponse() = default;
+
+void ReverbFrequencyResponse::Update(
+    const std::vector<std::array<float, kFftLengthBy2Plus1>>&
+        frequency_response,
+    int filter_delay_blocks,
+    const absl::optional<float>& linear_filter_quality,
+    bool stationary_block) {
+  if (stationary_block || !linear_filter_quality) {
+    return;
+  }
+
+  Update(frequency_response, filter_delay_blocks, *linear_filter_quality);
+}
+
+void ReverbFrequencyResponse::Update(
+    const std::vector<std::array<float, kFftLengthBy2Plus1>>&
+        frequency_response,
+    int filter_delay_blocks,
+    float linear_filter_quality) {
+  rtc::ArrayView<const float> freq_resp_tail(
+      frequency_response[frequency_response.size() - 1]);
+
+  rtc::ArrayView<const float> freq_resp_direct_path(
+      frequency_response[filter_delay_blocks]);
+
+  float average_decay =
+      AverageDecayWithinFilter(freq_resp_direct_path, freq_resp_tail);
+
+  const float smoothing = 0.2f * linear_filter_quality;
+  average_decay_ += smoothing * (average_decay - average_decay_);
+
+  for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+    tail_response_[k] = freq_resp_direct_path[k] * average_decay_;
+  }
+
+  for (size_t k = 1; k < kFftLengthBy2; ++k) {
+    const float avg_neighbour =
+        0.5f * (tail_response_[k - 1] + tail_response_[k + 1]);
+    tail_response_[k] = std::max(tail_response_[k], avg_neighbour);
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_frequency_response.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_frequency_response.h
new file mode 100644
index 0000000..b164186
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_frequency_response.h
@@ -0,0 +1,53 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_REVERB_FREQUENCY_RESPONSE_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_REVERB_FREQUENCY_RESPONSE_H_
+
+#include <array>
+#include <vector>
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+
+namespace webrtc {
+
+// Class for updating the frequency response for the reverb.
+class ReverbFrequencyResponse {
+ public:
+  ReverbFrequencyResponse();
+  ~ReverbFrequencyResponse();
+
+  // Updates the frequency response estimate of the reverb.
+  void Update(const std::vector<std::array<float, kFftLengthBy2Plus1>>&
+                  frequency_response,
+              int filter_delay_blocks,
+              const absl::optional<float>& linear_filter_quality,
+              bool stationary_block);
+
+  // Returns the estimated frequency response for the reverb.
+  rtc::ArrayView<const float> FrequencyResponse() const {
+    return tail_response_;
+  }
+
+ private:
+  void Update(const std::vector<std::array<float, kFftLengthBy2Plus1>>&
+                  frequency_response,
+              int filter_delay_blocks,
+              float linear_filter_quality);
+
+  float average_decay_ = 0.f;
+  std::array<float, kFftLengthBy2Plus1> tail_response_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_REVERB_FREQUENCY_RESPONSE_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model.cc
new file mode 100644
index 0000000..e4f3507
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model.cc
@@ -0,0 +1,59 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/reverb_model.h"
+
+#include <stddef.h>
+
+#include <algorithm>
+#include <functional>
+
+#include "api/array_view.h"
+
+namespace webrtc {
+
+ReverbModel::ReverbModel() {
+  Reset();
+}
+
+ReverbModel::~ReverbModel() = default;
+
+void ReverbModel::Reset() {
+  reverb_.fill(0.);
+}
+
+void ReverbModel::UpdateReverbNoFreqShaping(
+    rtc::ArrayView<const float> power_spectrum,
+    float power_spectrum_scaling,
+    float reverb_decay) {
+  if (reverb_decay > 0) {
+    // Update the estimate of the reverberant power.
+    for (size_t k = 0; k < power_spectrum.size(); ++k) {
+      reverb_[k] = (reverb_[k] + power_spectrum[k] * power_spectrum_scaling) *
+                   reverb_decay;
+    }
+  }
+}
+
+void ReverbModel::UpdateReverb(
+    rtc::ArrayView<const float> power_spectrum,
+    rtc::ArrayView<const float> power_spectrum_scaling,
+    float reverb_decay) {
+  if (reverb_decay > 0) {
+    // Update the estimate of the reverberant power.
+    for (size_t k = 0; k < power_spectrum.size(); ++k) {
+      reverb_[k] =
+          (reverb_[k] + power_spectrum[k] * power_spectrum_scaling[k]) *
+          reverb_decay;
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model.h
new file mode 100644
index 0000000..5ba5485
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model.h
@@ -0,0 +1,58 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_REVERB_MODEL_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_REVERB_MODEL_H_
+
+#include <array>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+
+namespace webrtc {
+
+// The ReverbModel class describes an exponential reverberant model
+// that can be applied over power spectrums.
+class ReverbModel {
+ public:
+  ReverbModel();
+  ~ReverbModel();
+
+  // Resets the state.
+  void Reset();
+
+  // Returns the reverb.
+  rtc::ArrayView<const float, kFftLengthBy2Plus1> reverb() const {
+    return reverb_;
+  }
+
+  // The methods UpdateReverbNoFreqShaping and UpdateReverb update the
+  // estimate of the reverberation contribution to an input/output power
+  // spectrum. Before applying the exponential reverberant model, the input
+  // power spectrum is pre-scaled. Use the method UpdateReverb when a different
+  // scaling should be applied per frequency and UpdateReverb_no_freq_shape if
+  // the same scaling should be used for all the frequencies.
+  void UpdateReverbNoFreqShaping(rtc::ArrayView<const float> power_spectrum,
+                                 float power_spectrum_scaling,
+                                 float reverb_decay);
+
+  // Update the reverb based on new data.
+  void UpdateReverb(rtc::ArrayView<const float> power_spectrum,
+                    rtc::ArrayView<const float> power_spectrum_scaling,
+                    float reverb_decay);
+
+ private:
+
+  std::array<float, kFftLengthBy2Plus1> reverb_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_REVERB_MODEL_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model_estimator.cc
new file mode 100644
index 0000000..7174311
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model_estimator.cc
@@ -0,0 +1,54 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/reverb_model_estimator.h"
+
+namespace webrtc {
+
+ReverbModelEstimator::ReverbModelEstimator(const EchoCanceller3Config& config,
+                                           size_t num_capture_channels)
+    : reverb_decay_estimators_(num_capture_channels),
+      reverb_frequency_responses_(num_capture_channels) {
+  for (size_t ch = 0; ch < reverb_decay_estimators_.size(); ++ch) {
+    reverb_decay_estimators_[ch] =
+        std::make_unique<ReverbDecayEstimator>(config);
+  }
+}
+
+ReverbModelEstimator::~ReverbModelEstimator() = default;
+
+void ReverbModelEstimator::Update(
+    rtc::ArrayView<const std::vector<float>> impulse_responses,
+    rtc::ArrayView<const std::vector<std::array<float, kFftLengthBy2Plus1>>>
+        frequency_responses,
+    rtc::ArrayView<const absl::optional<float>> linear_filter_qualities,
+    rtc::ArrayView<const int> filter_delays_blocks,
+    const std::vector<bool>& usable_linear_estimates,
+    bool stationary_block) {
+  const size_t num_capture_channels = reverb_decay_estimators_.size();
+  RTC_DCHECK_EQ(num_capture_channels, impulse_responses.size());
+  RTC_DCHECK_EQ(num_capture_channels, frequency_responses.size());
+  RTC_DCHECK_EQ(num_capture_channels, usable_linear_estimates.size());
+
+  for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+    // Estimate the frequency response for the reverb.
+    reverb_frequency_responses_[ch].Update(
+        frequency_responses[ch], filter_delays_blocks[ch],
+        linear_filter_qualities[ch], stationary_block);
+
+    // Estimate the reverb decay,
+    reverb_decay_estimators_[ch]->Update(
+        impulse_responses[ch], linear_filter_qualities[ch],
+        filter_delays_blocks[ch], usable_linear_estimates[ch],
+        stationary_block);
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model_estimator.h
new file mode 100644
index 0000000..e4e9540
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model_estimator.h
@@ -0,0 +1,68 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_REVERB_MODEL_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_REVERB_MODEL_ESTIMATOR_H_
+
+#include <array>
+#include <memory>
+#include <vector>
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"  // kFftLengthBy2Plus1
+#include "modules/audio_processing/aec3/reverb_decay_estimator.h"
+#include "modules/audio_processing/aec3/reverb_frequency_response.h"
+
+namespace webrtc {
+
+class ApmDataDumper;
+
+// Class for estimating the model parameters for the reverberant echo.
+class ReverbModelEstimator {
+ public:
+  ReverbModelEstimator(const EchoCanceller3Config& config,
+                       size_t num_capture_channels);
+  ~ReverbModelEstimator();
+
+  // Updates the estimates based on new data.
+  void Update(
+      rtc::ArrayView<const std::vector<float>> impulse_responses,
+      rtc::ArrayView<const std::vector<std::array<float, kFftLengthBy2Plus1>>>
+          frequency_responses,
+      rtc::ArrayView<const absl::optional<float>> linear_filter_qualities,
+      rtc::ArrayView<const int> filter_delays_blocks,
+      const std::vector<bool>& usable_linear_estimates,
+      bool stationary_block);
+
+  // Returns the exponential decay of the reverberant echo.
+  // TODO(peah): Correct to properly support multiple channels.
+  float ReverbDecay() const { return reverb_decay_estimators_[0]->Decay(); }
+
+  // Return the frequency response of the reverberant echo.
+  // TODO(peah): Correct to properly support multiple channels.
+  rtc::ArrayView<const float> GetReverbFrequencyResponse() const {
+    return reverb_frequency_responses_[0].FrequencyResponse();
+  }
+
+  // Dumps debug data.
+  void Dump(ApmDataDumper* data_dumper) const {
+    reverb_decay_estimators_[0]->Dump(data_dumper);
+  }
+
+ private:
+  std::vector<std::unique_ptr<ReverbDecayEstimator>> reverb_decay_estimators_;
+  std::vector<ReverbFrequencyResponse> reverb_frequency_responses_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_REVERB_MODEL_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model_estimator_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model_estimator_unittest.cc
new file mode 100644
index 0000000..f360a6f
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/reverb_model_estimator_unittest.cc
@@ -0,0 +1,150 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/reverb_model_estimator.h"
+
+#include <algorithm>
+#include <array>
+#include <cmath>
+#include <numeric>
+#include <vector>
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/aec3_fft.h"
+#include "modules/audio_processing/aec3/fft_data.h"
+#include "rtc_base/checks.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+namespace {
+
+EchoCanceller3Config CreateConfigForTest(float default_decay) {
+  EchoCanceller3Config cfg;
+  cfg.ep_strength.default_len = default_decay;
+  cfg.filter.refined.length_blocks = 40;
+  return cfg;
+}
+
+constexpr int kFilterDelayBlocks = 2;
+
+}  // namespace
+
+class ReverbModelEstimatorTest {
+ public:
+  ReverbModelEstimatorTest(float default_decay, size_t num_capture_channels)
+      : aec3_config_(CreateConfigForTest(default_decay)),
+        estimated_decay_(default_decay),
+        h_(num_capture_channels,
+           std::vector<float>(
+               aec3_config_.filter.refined.length_blocks * kBlockSize,
+               0.f)),
+        H2_(num_capture_channels,
+            std::vector<std::array<float, kFftLengthBy2Plus1>>(
+                aec3_config_.filter.refined.length_blocks)),
+        quality_linear_(num_capture_channels, 1.0f) {
+    CreateImpulseResponseWithDecay();
+  }
+  void RunEstimator();
+  float GetDecay() { return estimated_decay_; }
+  float GetTrueDecay() { return kTruePowerDecay; }
+  float GetPowerTailDb() { return 10.f * std::log10(estimated_power_tail_); }
+  float GetTruePowerTailDb() { return 10.f * std::log10(true_power_tail_); }
+
+ private:
+  void CreateImpulseResponseWithDecay();
+  static constexpr bool kStationaryBlock = false;
+  static constexpr float kTruePowerDecay = 0.5f;
+  const EchoCanceller3Config aec3_config_;
+  float estimated_decay_;
+  float estimated_power_tail_ = 0.f;
+  float true_power_tail_ = 0.f;
+  std::vector<std::vector<float>> h_;
+  std::vector<std::vector<std::array<float, kFftLengthBy2Plus1>>> H2_;
+  std::vector<absl::optional<float>> quality_linear_;
+};
+
+void ReverbModelEstimatorTest::CreateImpulseResponseWithDecay() {
+  const Aec3Fft fft;
+  for (const auto& h_k : h_) {
+    RTC_DCHECK_EQ(h_k.size(),
+                  aec3_config_.filter.refined.length_blocks * kBlockSize);
+  }
+  for (const auto& H2_k : H2_) {
+    RTC_DCHECK_EQ(H2_k.size(), aec3_config_.filter.refined.length_blocks);
+  }
+  RTC_DCHECK_EQ(kFilterDelayBlocks, 2);
+
+  float decay_sample = std::sqrt(powf(kTruePowerDecay, 1.f / kBlockSize));
+  const size_t filter_delay_coefficients = kFilterDelayBlocks * kBlockSize;
+  for (auto& h_i : h_) {
+    std::fill(h_i.begin(), h_i.end(), 0.f);
+    h_i[filter_delay_coefficients] = 1.f;
+    for (size_t k = filter_delay_coefficients + 1; k < h_i.size(); ++k) {
+      h_i[k] = h_i[k - 1] * decay_sample;
+    }
+  }
+
+  for (size_t ch = 0; ch < H2_.size(); ++ch) {
+    for (size_t j = 0, k = 0; j < H2_[ch].size(); ++j, k += kBlockSize) {
+      std::array<float, kFftLength> fft_data;
+      fft_data.fill(0.f);
+      std::copy(h_[ch].begin() + k, h_[ch].begin() + k + kBlockSize,
+                fft_data.begin());
+      FftData H_j;
+      fft.Fft(&fft_data, &H_j);
+      H_j.Spectrum(Aec3Optimization::kNone, H2_[ch][j]);
+    }
+  }
+  rtc::ArrayView<float> H2_tail(H2_[0][H2_[0].size() - 1]);
+  true_power_tail_ = std::accumulate(H2_tail.begin(), H2_tail.end(), 0.f);
+}
+void ReverbModelEstimatorTest::RunEstimator() {
+  const size_t num_capture_channels = H2_.size();
+  constexpr bool kUsableLinearEstimate = true;
+  ReverbModelEstimator estimator(aec3_config_, num_capture_channels);
+  std::vector<bool> usable_linear_estimates(num_capture_channels,
+                                            kUsableLinearEstimate);
+  std::vector<int> filter_delay_blocks(num_capture_channels,
+                                       kFilterDelayBlocks);
+  for (size_t k = 0; k < 3000; ++k) {
+    estimator.Update(h_, H2_, quality_linear_, filter_delay_blocks,
+                     usable_linear_estimates, kStationaryBlock);
+  }
+  estimated_decay_ = estimator.ReverbDecay();
+  auto freq_resp_tail = estimator.GetReverbFrequencyResponse();
+  estimated_power_tail_ =
+      std::accumulate(freq_resp_tail.begin(), freq_resp_tail.end(), 0.f);
+}
+
+TEST(ReverbModelEstimatorTests, NotChangingDecay) {
+  constexpr float kDefaultDecay = 0.9f;
+  for (size_t num_capture_channels : {1, 2, 4, 8}) {
+    ReverbModelEstimatorTest test(kDefaultDecay, num_capture_channels);
+    test.RunEstimator();
+    EXPECT_EQ(test.GetDecay(), kDefaultDecay);
+    EXPECT_NEAR(test.GetPowerTailDb(), test.GetTruePowerTailDb(), 5.f);
+  }
+}
+
+TEST(ReverbModelEstimatorTests, ChangingDecay) {
+  constexpr float kDefaultDecay = -0.9f;
+  for (size_t num_capture_channels : {1, 2, 4, 8}) {
+    ReverbModelEstimatorTest test(kDefaultDecay, num_capture_channels);
+    test.RunEstimator();
+    EXPECT_NEAR(test.GetDecay(), test.GetTrueDecay(), 0.1);
+    EXPECT_NEAR(test.GetPowerTailDb(), test.GetTruePowerTailDb(), 5.f);
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/signal_dependent_erle_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/signal_dependent_erle_estimator.cc
new file mode 100644
index 0000000..a5e7709
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/signal_dependent_erle_estimator.cc
@@ -0,0 +1,416 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/signal_dependent_erle_estimator.h"
+
+#include <algorithm>
+#include <functional>
+#include <numeric>
+
+#include "modules/audio_processing/aec3/spectrum_buffer.h"
+#include "rtc_base/numerics/safe_minmax.h"
+
+namespace webrtc {
+
+namespace {
+
+constexpr std::array<size_t, SignalDependentErleEstimator::kSubbands + 1>
+    kBandBoundaries = {1, 8, 16, 24, 32, 48, kFftLengthBy2Plus1};
+
+std::array<size_t, kFftLengthBy2Plus1> FormSubbandMap() {
+  std::array<size_t, kFftLengthBy2Plus1> map_band_to_subband;
+  size_t subband = 1;
+  for (size_t k = 0; k < map_band_to_subband.size(); ++k) {
+    RTC_DCHECK_LT(subband, kBandBoundaries.size());
+    if (k >= kBandBoundaries[subband]) {
+      subband++;
+      RTC_DCHECK_LT(k, kBandBoundaries[subband]);
+    }
+    map_band_to_subband[k] = subband - 1;
+  }
+  return map_band_to_subband;
+}
+
+// Defines the size in blocks of the sections that are used for dividing the
+// linear filter. The sections are split in a non-linear manner so that lower
+// sections that typically represent the direct path have a larger resolution
+// than the higher sections which typically represent more reverberant acoustic
+// paths.
+std::vector<size_t> DefineFilterSectionSizes(size_t delay_headroom_blocks,
+                                             size_t num_blocks,
+                                             size_t num_sections) {
+  size_t filter_length_blocks = num_blocks - delay_headroom_blocks;
+  std::vector<size_t> section_sizes(num_sections);
+  size_t remaining_blocks = filter_length_blocks;
+  size_t remaining_sections = num_sections;
+  size_t estimator_size = 2;
+  size_t idx = 0;
+  while (remaining_sections > 1 &&
+         remaining_blocks > estimator_size * remaining_sections) {
+    RTC_DCHECK_LT(idx, section_sizes.size());
+    section_sizes[idx] = estimator_size;
+    remaining_blocks -= estimator_size;
+    remaining_sections--;
+    estimator_size *= 2;
+    idx++;
+  }
+
+  size_t last_groups_size = remaining_blocks / remaining_sections;
+  for (; idx < num_sections; idx++) {
+    section_sizes[idx] = last_groups_size;
+  }
+  section_sizes[num_sections - 1] +=
+      remaining_blocks - last_groups_size * remaining_sections;
+  return section_sizes;
+}
+
+// Forms the limits in blocks for each filter section. Those sections
+// are used for analyzing the echo estimates and investigating which
+// linear filter sections contribute most to the echo estimate energy.
+std::vector<size_t> SetSectionsBoundaries(size_t delay_headroom_blocks,
+                                          size_t num_blocks,
+                                          size_t num_sections) {
+  std::vector<size_t> estimator_boundaries_blocks(num_sections + 1);
+  if (estimator_boundaries_blocks.size() == 2) {
+    estimator_boundaries_blocks[0] = 0;
+    estimator_boundaries_blocks[1] = num_blocks;
+    return estimator_boundaries_blocks;
+  }
+  RTC_DCHECK_GT(estimator_boundaries_blocks.size(), 2);
+  const std::vector<size_t> section_sizes =
+      DefineFilterSectionSizes(delay_headroom_blocks, num_blocks,
+                               estimator_boundaries_blocks.size() - 1);
+
+  size_t idx = 0;
+  size_t current_size_block = 0;
+  RTC_DCHECK_EQ(section_sizes.size() + 1, estimator_boundaries_blocks.size());
+  estimator_boundaries_blocks[0] = delay_headroom_blocks;
+  for (size_t k = delay_headroom_blocks; k < num_blocks; ++k) {
+    current_size_block++;
+    if (current_size_block >= section_sizes[idx]) {
+      idx = idx + 1;
+      if (idx == section_sizes.size()) {
+        break;
+      }
+      estimator_boundaries_blocks[idx] = k + 1;
+      current_size_block = 0;
+    }
+  }
+  estimator_boundaries_blocks[section_sizes.size()] = num_blocks;
+  return estimator_boundaries_blocks;
+}
+
+std::array<float, SignalDependentErleEstimator::kSubbands>
+SetMaxErleSubbands(float max_erle_l, float max_erle_h, size_t limit_subband_l) {
+  std::array<float, SignalDependentErleEstimator::kSubbands> max_erle;
+  std::fill(max_erle.begin(), max_erle.begin() + limit_subband_l, max_erle_l);
+  std::fill(max_erle.begin() + limit_subband_l, max_erle.end(), max_erle_h);
+  return max_erle;
+}
+
+}  // namespace
+
+SignalDependentErleEstimator::SignalDependentErleEstimator(
+    const EchoCanceller3Config& config,
+    size_t num_capture_channels)
+    : min_erle_(config.erle.min),
+      num_sections_(config.erle.num_sections),
+      num_blocks_(config.filter.refined.length_blocks),
+      delay_headroom_blocks_(config.delay.delay_headroom_samples / kBlockSize),
+      band_to_subband_(FormSubbandMap()),
+      max_erle_(SetMaxErleSubbands(config.erle.max_l,
+                                   config.erle.max_h,
+                                   band_to_subband_[kFftLengthBy2 / 2])),
+      section_boundaries_blocks_(SetSectionsBoundaries(delay_headroom_blocks_,
+                                                       num_blocks_,
+                                                       num_sections_)),
+      use_onset_detection_(config.erle.onset_detection),
+      erle_(num_capture_channels),
+      erle_onset_compensated_(num_capture_channels),
+      S2_section_accum_(
+          num_capture_channels,
+          std::vector<std::array<float, kFftLengthBy2Plus1>>(num_sections_)),
+      erle_estimators_(
+          num_capture_channels,
+          std::vector<std::array<float, kSubbands>>(num_sections_)),
+      erle_ref_(num_capture_channels),
+      correction_factors_(
+          num_capture_channels,
+          std::vector<std::array<float, kSubbands>>(num_sections_)),
+      num_updates_(num_capture_channels),
+      n_active_sections_(num_capture_channels) {
+  RTC_DCHECK_LE(num_sections_, num_blocks_);
+  RTC_DCHECK_GE(num_sections_, 1);
+  Reset();
+}
+
+SignalDependentErleEstimator::~SignalDependentErleEstimator() = default;
+
+void SignalDependentErleEstimator::Reset() {
+  for (size_t ch = 0; ch < erle_.size(); ++ch) {
+    erle_[ch].fill(min_erle_);
+    erle_onset_compensated_[ch].fill(min_erle_);
+    for (auto& erle_estimator : erle_estimators_[ch]) {
+      erle_estimator.fill(min_erle_);
+    }
+    erle_ref_[ch].fill(min_erle_);
+    for (auto& factor : correction_factors_[ch]) {
+      factor.fill(1.0f);
+    }
+    num_updates_[ch].fill(0);
+    n_active_sections_[ch].fill(0);
+  }
+}
+
+// Updates the Erle estimate by analyzing the current input signals. It takes
+// the render buffer and the filter frequency response in order to do an
+// estimation of the number of sections of the linear filter that are needed
+// for getting the majority of the energy in the echo estimate. Based on that
+// number of sections, it updates the erle estimation by introducing a
+// correction factor to the erle that is given as an input to this method.
+void SignalDependentErleEstimator::Update(
+    const RenderBuffer& render_buffer,
+    rtc::ArrayView<const std::vector<std::array<float, kFftLengthBy2Plus1>>>
+        filter_frequency_responses,
+    rtc::ArrayView<const float, kFftLengthBy2Plus1> X2,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Y2,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> E2,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> average_erle,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+        average_erle_onset_compensated,
+    const std::vector<bool>& converged_filters) {
+  RTC_DCHECK_GT(num_sections_, 1);
+
+  // Gets the number of filter sections that are needed for achieving 90 %
+  // of the power spectrum energy of the echo estimate.
+  ComputeNumberOfActiveFilterSections(render_buffer,
+                                      filter_frequency_responses);
+
+  // Updates the correction factors that is used for correcting the erle and
+  // adapt it to the particular characteristics of the input signal.
+  UpdateCorrectionFactors(X2, Y2, E2, converged_filters);
+
+  // Applies the correction factor to the input erle for getting a more refined
+  // erle estimation for the current input signal.
+  for (size_t ch = 0; ch < erle_.size(); ++ch) {
+    for (size_t k = 0; k < kFftLengthBy2; ++k) {
+      RTC_DCHECK_GT(correction_factors_[ch].size(), n_active_sections_[ch][k]);
+      float correction_factor =
+          correction_factors_[ch][n_active_sections_[ch][k]]
+                             [band_to_subband_[k]];
+      erle_[ch][k] = rtc::SafeClamp(average_erle[ch][k] * correction_factor,
+                                    min_erle_, max_erle_[band_to_subband_[k]]);
+      if (use_onset_detection_) {
+        erle_onset_compensated_[ch][k] = rtc::SafeClamp(
+            average_erle_onset_compensated[ch][k] * correction_factor,
+            min_erle_, max_erle_[band_to_subband_[k]]);
+      }
+    }
+  }
+}
+
+void SignalDependentErleEstimator::Dump(
+    const std::unique_ptr<ApmDataDumper>& data_dumper) const {
+  for (auto& erle : erle_estimators_[0]) {
+    data_dumper->DumpRaw("aec3_all_erle", erle);
+  }
+  data_dumper->DumpRaw("aec3_ref_erle", erle_ref_[0]);
+  for (auto& factor : correction_factors_[0]) {
+    data_dumper->DumpRaw("aec3_erle_correction_factor", factor);
+  }
+}
+
+// Estimates for each band the smallest number of sections in the filter that
+// together constitute 90% of the estimated echo energy.
+void SignalDependentErleEstimator::ComputeNumberOfActiveFilterSections(
+    const RenderBuffer& render_buffer,
+    rtc::ArrayView<const std::vector<std::array<float, kFftLengthBy2Plus1>>>
+        filter_frequency_responses) {
+  RTC_DCHECK_GT(num_sections_, 1);
+  // Computes an approximation of the power spectrum if the filter would have
+  // been limited to a certain number of filter sections.
+  ComputeEchoEstimatePerFilterSection(render_buffer,
+                                      filter_frequency_responses);
+  // For each band, computes the number of filter sections that are needed for
+  // achieving the 90 % energy in the echo estimate.
+  ComputeActiveFilterSections();
+}
+
+void SignalDependentErleEstimator::UpdateCorrectionFactors(
+    rtc::ArrayView<const float, kFftLengthBy2Plus1> X2,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Y2,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> E2,
+    const std::vector<bool>& converged_filters) {
+  for (size_t ch = 0; ch < converged_filters.size(); ++ch) {
+    if (converged_filters[ch]) {
+      constexpr float kX2BandEnergyThreshold = 44015068.0f;
+      constexpr float kSmthConstantDecreases = 0.1f;
+      constexpr float kSmthConstantIncreases = kSmthConstantDecreases / 2.f;
+      auto subband_powers = [](rtc::ArrayView<const float> power_spectrum,
+                               rtc::ArrayView<float> power_spectrum_subbands) {
+        for (size_t subband = 0; subband < kSubbands; ++subband) {
+          RTC_DCHECK_LE(kBandBoundaries[subband + 1], power_spectrum.size());
+          power_spectrum_subbands[subband] = std::accumulate(
+              power_spectrum.begin() + kBandBoundaries[subband],
+              power_spectrum.begin() + kBandBoundaries[subband + 1], 0.f);
+        }
+      };
+
+      std::array<float, kSubbands> X2_subbands, E2_subbands, Y2_subbands;
+      subband_powers(X2, X2_subbands);
+      subband_powers(E2[ch], E2_subbands);
+      subband_powers(Y2[ch], Y2_subbands);
+      std::array<size_t, kSubbands> idx_subbands;
+      for (size_t subband = 0; subband < kSubbands; ++subband) {
+        // When aggregating the number of active sections in the filter for
+        // different bands we choose to take the minimum of all of them. As an
+        // example, if for one of the bands it is the direct path its refined
+        // contributor to the final echo estimate, we consider the direct path
+        // is as well the refined contributor for the subband that contains that
+        // particular band. That aggregate number of sections will be later used
+        // as the identifier of the erle estimator that needs to be updated.
+        RTC_DCHECK_LE(kBandBoundaries[subband + 1],
+                      n_active_sections_[ch].size());
+        idx_subbands[subband] = *std::min_element(
+            n_active_sections_[ch].begin() + kBandBoundaries[subband],
+            n_active_sections_[ch].begin() + kBandBoundaries[subband + 1]);
+      }
+
+      std::array<float, kSubbands> new_erle;
+      std::array<bool, kSubbands> is_erle_updated;
+      is_erle_updated.fill(false);
+      new_erle.fill(0.f);
+      for (size_t subband = 0; subband < kSubbands; ++subband) {
+        if (X2_subbands[subband] > kX2BandEnergyThreshold &&
+            E2_subbands[subband] > 0) {
+          new_erle[subband] = Y2_subbands[subband] / E2_subbands[subband];
+          RTC_DCHECK_GT(new_erle[subband], 0);
+          is_erle_updated[subband] = true;
+          ++num_updates_[ch][subband];
+        }
+      }
+
+      for (size_t subband = 0; subband < kSubbands; ++subband) {
+        const size_t idx = idx_subbands[subband];
+        RTC_DCHECK_LT(idx, erle_estimators_[ch].size());
+        float alpha = new_erle[subband] > erle_estimators_[ch][idx][subband]
+                          ? kSmthConstantIncreases
+                          : kSmthConstantDecreases;
+        alpha = static_cast<float>(is_erle_updated[subband]) * alpha;
+        erle_estimators_[ch][idx][subband] +=
+            alpha * (new_erle[subband] - erle_estimators_[ch][idx][subband]);
+        erle_estimators_[ch][idx][subband] = rtc::SafeClamp(
+            erle_estimators_[ch][idx][subband], min_erle_, max_erle_[subband]);
+      }
+
+      for (size_t subband = 0; subband < kSubbands; ++subband) {
+        float alpha = new_erle[subband] > erle_ref_[ch][subband]
+                          ? kSmthConstantIncreases
+                          : kSmthConstantDecreases;
+        alpha = static_cast<float>(is_erle_updated[subband]) * alpha;
+        erle_ref_[ch][subband] +=
+            alpha * (new_erle[subband] - erle_ref_[ch][subband]);
+        erle_ref_[ch][subband] = rtc::SafeClamp(erle_ref_[ch][subband],
+                                                min_erle_, max_erle_[subband]);
+      }
+
+      for (size_t subband = 0; subband < kSubbands; ++subband) {
+        constexpr int kNumUpdateThr = 50;
+        if (is_erle_updated[subband] &&
+            num_updates_[ch][subband] > kNumUpdateThr) {
+          const size_t idx = idx_subbands[subband];
+          RTC_DCHECK_GT(erle_ref_[ch][subband], 0.f);
+          // Computes the ratio between the erle that is updated using all the
+          // points and the erle that is updated only on signals that share the
+          // same number of active filter sections.
+          float new_correction_factor =
+              erle_estimators_[ch][idx][subband] / erle_ref_[ch][subband];
+
+          correction_factors_[ch][idx][subband] +=
+              0.1f *
+              (new_correction_factor - correction_factors_[ch][idx][subband]);
+        }
+      }
+    }
+  }
+}
+
+void SignalDependentErleEstimator::ComputeEchoEstimatePerFilterSection(
+    const RenderBuffer& render_buffer,
+    rtc::ArrayView<const std::vector<std::array<float, kFftLengthBy2Plus1>>>
+        filter_frequency_responses) {
+  const SpectrumBuffer& spectrum_render_buffer =
+      render_buffer.GetSpectrumBuffer();
+  const size_t num_render_channels = spectrum_render_buffer.buffer[0].size();
+  const size_t num_capture_channels = S2_section_accum_.size();
+  const float one_by_num_render_channels = 1.f / num_render_channels;
+
+  RTC_DCHECK_EQ(S2_section_accum_.size(), filter_frequency_responses.size());
+
+  for (size_t capture_ch = 0; capture_ch < num_capture_channels; ++capture_ch) {
+    RTC_DCHECK_EQ(S2_section_accum_[capture_ch].size() + 1,
+                  section_boundaries_blocks_.size());
+    size_t idx_render = render_buffer.Position();
+    idx_render = spectrum_render_buffer.OffsetIndex(
+        idx_render, section_boundaries_blocks_[0]);
+
+    for (size_t section = 0; section < num_sections_; ++section) {
+      std::array<float, kFftLengthBy2Plus1> X2_section;
+      std::array<float, kFftLengthBy2Plus1> H2_section;
+      X2_section.fill(0.f);
+      H2_section.fill(0.f);
+      const size_t block_limit =
+          std::min(section_boundaries_blocks_[section + 1],
+                   filter_frequency_responses[capture_ch].size());
+      for (size_t block = section_boundaries_blocks_[section];
+           block < block_limit; ++block) {
+        for (size_t render_ch = 0;
+             render_ch < spectrum_render_buffer.buffer[idx_render].size();
+             ++render_ch) {
+          for (size_t k = 0; k < X2_section.size(); ++k) {
+            X2_section[k] +=
+                spectrum_render_buffer.buffer[idx_render][render_ch][k] *
+                one_by_num_render_channels;
+          }
+        }
+        std::transform(H2_section.begin(), H2_section.end(),
+                       filter_frequency_responses[capture_ch][block].begin(),
+                       H2_section.begin(), std::plus<float>());
+        idx_render = spectrum_render_buffer.IncIndex(idx_render);
+      }
+
+      std::transform(X2_section.begin(), X2_section.end(), H2_section.begin(),
+                     S2_section_accum_[capture_ch][section].begin(),
+                     std::multiplies<float>());
+    }
+
+    for (size_t section = 1; section < num_sections_; ++section) {
+      std::transform(S2_section_accum_[capture_ch][section - 1].begin(),
+                     S2_section_accum_[capture_ch][section - 1].end(),
+                     S2_section_accum_[capture_ch][section].begin(),
+                     S2_section_accum_[capture_ch][section].begin(),
+                     std::plus<float>());
+    }
+  }
+}
+
+void SignalDependentErleEstimator::ComputeActiveFilterSections() {
+  for (size_t ch = 0; ch < n_active_sections_.size(); ++ch) {
+    std::fill(n_active_sections_[ch].begin(), n_active_sections_[ch].end(), 0);
+    for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+      size_t section = num_sections_;
+      float target = 0.9f * S2_section_accum_[ch][num_sections_ - 1][k];
+      while (section > 0 && S2_section_accum_[ch][section - 1][k] >= target) {
+        n_active_sections_[ch][k] = --section;
+      }
+    }
+  }
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/signal_dependent_erle_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/signal_dependent_erle_estimator.h
new file mode 100644
index 0000000..6847c1a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/signal_dependent_erle_estimator.h
@@ -0,0 +1,104 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_SIGNAL_DEPENDENT_ERLE_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_SIGNAL_DEPENDENT_ERLE_ESTIMATOR_H_
+
+#include <memory>
+#include <vector>
+
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/render_buffer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+
+namespace webrtc {
+
+// This class estimates the dependency of the Erle to the input signal. By
+// looking at the input signal, an estimation on whether the current echo
+// estimate is due to the direct path or to a more reverberant one is performed.
+// Once that estimation is done, it is possible to refine the average Erle that
+// this class receive as an input.
+class SignalDependentErleEstimator {
+ public:
+  SignalDependentErleEstimator(const EchoCanceller3Config& config,
+                               size_t num_capture_channels);
+
+  ~SignalDependentErleEstimator();
+
+  void Reset();
+
+  // Returns the Erle per frequency subband.
+  rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Erle(
+      bool onset_compensated) const {
+    return onset_compensated && use_onset_detection_ ? erle_onset_compensated_
+                                                     : erle_;
+  }
+
+  // Updates the Erle estimate. The Erle that is passed as an input is required
+  // to be an estimation of the average Erle achieved by the linear filter.
+  void Update(
+      const RenderBuffer& render_buffer,
+      rtc::ArrayView<const std::vector<std::array<float, kFftLengthBy2Plus1>>>
+          filter_frequency_response,
+      rtc::ArrayView<const float, kFftLengthBy2Plus1> X2,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Y2,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> E2,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> average_erle,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+          average_erle_onset_compensated,
+      const std::vector<bool>& converged_filters);
+
+  void Dump(const std::unique_ptr<ApmDataDumper>& data_dumper) const;
+
+  static constexpr size_t kSubbands = 6;
+
+ private:
+  void ComputeNumberOfActiveFilterSections(
+      const RenderBuffer& render_buffer,
+      rtc::ArrayView<const std::vector<std::array<float, kFftLengthBy2Plus1>>>
+          filter_frequency_responses);
+
+  void UpdateCorrectionFactors(
+      rtc::ArrayView<const float, kFftLengthBy2Plus1> X2,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Y2,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> E2,
+      const std::vector<bool>& converged_filters);
+
+  void ComputeEchoEstimatePerFilterSection(
+      const RenderBuffer& render_buffer,
+      rtc::ArrayView<const std::vector<std::array<float, kFftLengthBy2Plus1>>>
+          filter_frequency_responses);
+
+  void ComputeActiveFilterSections();
+
+  const float min_erle_;
+  const size_t num_sections_;
+  const size_t num_blocks_;
+  const size_t delay_headroom_blocks_;
+  const std::array<size_t, kFftLengthBy2Plus1> band_to_subband_;
+  const std::array<float, kSubbands> max_erle_;
+  const std::vector<size_t> section_boundaries_blocks_;
+  const bool use_onset_detection_;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> erle_;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> erle_onset_compensated_;
+  std::vector<std::vector<std::array<float, kFftLengthBy2Plus1>>>
+      S2_section_accum_;
+  std::vector<std::vector<std::array<float, kSubbands>>> erle_estimators_;
+  std::vector<std::array<float, kSubbands>> erle_ref_;
+  std::vector<std::vector<std::array<float, kSubbands>>> correction_factors_;
+  std::vector<std::array<int, kSubbands>> num_updates_;
+  std::vector<std::array<size_t, kFftLengthBy2Plus1>> n_active_sections_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_SIGNAL_DEPENDENT_ERLE_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/signal_dependent_erle_estimator_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/signal_dependent_erle_estimator_unittest.cc
new file mode 100644
index 0000000..58f56d8
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/signal_dependent_erle_estimator_unittest.cc
@@ -0,0 +1,209 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/signal_dependent_erle_estimator.h"
+
+#include <algorithm>
+#include <iostream>
+#include <string>
+
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/render_buffer.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+namespace {
+
+void GetActiveFrame(std::vector<std::vector<std::vector<float>>>* x) {
+  const std::array<float, kBlockSize> frame = {
+      7459.88, 17209.6, 17383,   20768.9, 16816.7, 18386.3, 4492.83, 9675.85,
+      6665.52, 14808.6, 9342.3,  7483.28, 19261.7, 4145.98, 1622.18, 13475.2,
+      7166.32, 6856.61, 21937,   7263.14, 9569.07, 14919,   8413.32, 7551.89,
+      7848.65, 6011.27, 13080.6, 15865.2, 12656,   17459.6, 4263.93, 4503.03,
+      9311.79, 21095.8, 12657.9, 13906.6, 19267.2, 11338.1, 16828.9, 11501.6,
+      11405,   15031.4, 14541.6, 19765.5, 18346.3, 19350.2, 3157.47, 18095.8,
+      1743.68, 21328.2, 19727.5, 7295.16, 10332.4, 11055.5, 20107.4, 14708.4,
+      12416.2, 16434,   2454.69, 9840.8,  6867.23, 1615.75, 6059.9,  8394.19};
+  for (size_t band = 0; band < x->size(); ++band) {
+    for (size_t channel = 0; channel < (*x)[band].size(); ++channel) {
+      RTC_DCHECK_GE((*x)[band][channel].size(), frame.size());
+      std::copy(frame.begin(), frame.end(), (*x)[band][channel].begin());
+    }
+  }
+}
+
+class TestInputs {
+ public:
+  TestInputs(const EchoCanceller3Config& cfg,
+             size_t num_render_channels,
+             size_t num_capture_channels);
+  ~TestInputs();
+  const RenderBuffer& GetRenderBuffer() { return *render_buffer_; }
+  rtc::ArrayView<const float, kFftLengthBy2Plus1> GetX2() { return X2_; }
+  rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> GetY2() const {
+    return Y2_;
+  }
+  rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> GetE2() const {
+    return E2_;
+  }
+  rtc::ArrayView<const std::vector<std::array<float, kFftLengthBy2Plus1>>>
+  GetH2() const {
+    return H2_;
+  }
+  const std::vector<bool>& GetConvergedFilters() const {
+    return converged_filters_;
+  }
+  void Update();
+
+ private:
+  void UpdateCurrentPowerSpectra();
+  int n_ = 0;
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer_;
+  RenderBuffer* render_buffer_;
+  std::array<float, kFftLengthBy2Plus1> X2_;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> Y2_;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> E2_;
+  std::vector<std::vector<std::array<float, kFftLengthBy2Plus1>>> H2_;
+  std::vector<std::vector<std::vector<float>>> x_;
+  std::vector<bool> converged_filters_;
+};
+
+TestInputs::TestInputs(const EchoCanceller3Config& cfg,
+                       size_t num_render_channels,
+                       size_t num_capture_channels)
+    : render_delay_buffer_(
+          RenderDelayBuffer::Create(cfg, 16000, num_render_channels)),
+      Y2_(num_capture_channels),
+      E2_(num_capture_channels),
+      H2_(num_capture_channels,
+          std::vector<std::array<float, kFftLengthBy2Plus1>>(
+              cfg.filter.refined.length_blocks)),
+      x_(1,
+         std::vector<std::vector<float>>(num_render_channels,
+                                         std::vector<float>(kBlockSize, 0.f))),
+      converged_filters_(num_capture_channels, true) {
+  render_delay_buffer_->AlignFromDelay(4);
+  render_buffer_ = render_delay_buffer_->GetRenderBuffer();
+  for (auto& H2_ch : H2_) {
+    for (auto& H2_p : H2_ch) {
+      H2_p.fill(0.f);
+    }
+  }
+  for (auto& H2_p : H2_[0]) {
+    H2_p.fill(1.f);
+  }
+}
+
+TestInputs::~TestInputs() = default;
+
+void TestInputs::Update() {
+  if (n_ % 2 == 0) {
+    std::fill(x_[0][0].begin(), x_[0][0].end(), 0.f);
+  } else {
+    GetActiveFrame(&x_);
+  }
+
+  render_delay_buffer_->Insert(x_);
+  render_delay_buffer_->PrepareCaptureProcessing();
+  UpdateCurrentPowerSpectra();
+  ++n_;
+}
+
+void TestInputs::UpdateCurrentPowerSpectra() {
+  const SpectrumBuffer& spectrum_render_buffer =
+      render_buffer_->GetSpectrumBuffer();
+  size_t idx = render_buffer_->Position();
+  size_t prev_idx = spectrum_render_buffer.OffsetIndex(idx, 1);
+  auto& X2 = spectrum_render_buffer.buffer[idx][/*channel=*/0];
+  auto& X2_prev = spectrum_render_buffer.buffer[prev_idx][/*channel=*/0];
+  std::copy(X2.begin(), X2.end(), X2_.begin());
+  for (size_t ch = 0; ch < Y2_.size(); ++ch) {
+    RTC_DCHECK_EQ(X2.size(), Y2_[ch].size());
+    for (size_t k = 0; k < X2.size(); ++k) {
+      E2_[ch][k] = 0.01f * X2_prev[k];
+      Y2_[ch][k] = X2[k] + E2_[ch][k];
+    }
+  }
+}
+
+}  // namespace
+
+class SignalDependentErleEstimatorMultiChannel
+    : public ::testing::Test,
+      public ::testing::WithParamInterface<std::tuple<size_t, size_t>> {};
+
+INSTANTIATE_TEST_SUITE_P(MultiChannel,
+                         SignalDependentErleEstimatorMultiChannel,
+                         ::testing::Combine(::testing::Values(1, 2, 4),
+                                            ::testing::Values(1, 2, 4)));
+
+TEST_P(SignalDependentErleEstimatorMultiChannel, SweepSettings) {
+  const size_t num_render_channels = std::get<0>(GetParam());
+  const size_t num_capture_channels = std::get<1>(GetParam());
+  EchoCanceller3Config cfg;
+  size_t max_length_blocks = 50;
+  for (size_t blocks = 1; blocks < max_length_blocks; blocks = blocks + 10) {
+    for (size_t delay_headroom = 0; delay_headroom < 5; ++delay_headroom) {
+      for (size_t num_sections = 2; num_sections < max_length_blocks;
+           ++num_sections) {
+        cfg.filter.refined.length_blocks = blocks;
+        cfg.filter.refined_initial.length_blocks =
+            std::min(cfg.filter.refined_initial.length_blocks, blocks);
+        cfg.delay.delay_headroom_samples = delay_headroom * kBlockSize;
+        cfg.erle.num_sections = num_sections;
+        if (EchoCanceller3Config::Validate(&cfg)) {
+          SignalDependentErleEstimator s(cfg, num_capture_channels);
+          std::vector<std::array<float, kFftLengthBy2Plus1>> average_erle(
+              num_capture_channels);
+          for (auto& e : average_erle) {
+            e.fill(cfg.erle.max_l);
+          }
+          TestInputs inputs(cfg, num_render_channels, num_capture_channels);
+          for (size_t n = 0; n < 10; ++n) {
+            inputs.Update();
+            s.Update(inputs.GetRenderBuffer(), inputs.GetH2(), inputs.GetX2(),
+                     inputs.GetY2(), inputs.GetE2(), average_erle, average_erle,
+                     inputs.GetConvergedFilters());
+          }
+        }
+      }
+    }
+  }
+}
+
+TEST_P(SignalDependentErleEstimatorMultiChannel, LongerRun) {
+  const size_t num_render_channels = std::get<0>(GetParam());
+  const size_t num_capture_channels = std::get<1>(GetParam());
+  EchoCanceller3Config cfg;
+  cfg.filter.refined.length_blocks = 2;
+  cfg.filter.refined_initial.length_blocks = 1;
+  cfg.delay.delay_headroom_samples = 0;
+  cfg.delay.hysteresis_limit_blocks = 0;
+  cfg.erle.num_sections = 2;
+  EXPECT_EQ(EchoCanceller3Config::Validate(&cfg), true);
+  std::vector<std::array<float, kFftLengthBy2Plus1>> average_erle(
+      num_capture_channels);
+  for (auto& e : average_erle) {
+    e.fill(cfg.erle.max_l);
+  }
+  SignalDependentErleEstimator s(cfg, num_capture_channels);
+  TestInputs inputs(cfg, num_render_channels, num_capture_channels);
+  for (size_t n = 0; n < 200; ++n) {
+    inputs.Update();
+    s.Update(inputs.GetRenderBuffer(), inputs.GetH2(), inputs.GetX2(),
+             inputs.GetY2(), inputs.GetE2(), average_erle, average_erle,
+             inputs.GetConvergedFilters());
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/spectrum_buffer.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/spectrum_buffer.cc
new file mode 100644
index 0000000..fe32ece
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/spectrum_buffer.cc
@@ -0,0 +1,30 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/spectrum_buffer.h"
+
+#include <algorithm>
+
+namespace webrtc {
+
+SpectrumBuffer::SpectrumBuffer(size_t size, size_t num_channels)
+    : size(static_cast<int>(size)),
+      buffer(size,
+             std::vector<std::array<float, kFftLengthBy2Plus1>>(num_channels)) {
+  for (auto& channel : buffer) {
+    for (auto& c : channel) {
+      std::fill(c.begin(), c.end(), 0.f);
+    }
+  }
+}
+
+SpectrumBuffer::~SpectrumBuffer() = default;
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/spectrum_buffer.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/spectrum_buffer.h
new file mode 100644
index 0000000..51e1317
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/spectrum_buffer.h
@@ -0,0 +1,62 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_SPECTRUM_BUFFER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_SPECTRUM_BUFFER_H_
+
+#include <stddef.h>
+
+#include <array>
+#include <vector>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+// Struct for bundling a circular buffer of one dimensional vector objects
+// together with the read and write indices.
+struct SpectrumBuffer {
+  SpectrumBuffer(size_t size, size_t num_channels);
+  ~SpectrumBuffer();
+
+  int IncIndex(int index) const {
+    RTC_DCHECK_EQ(buffer.size(), static_cast<size_t>(size));
+    return index < size - 1 ? index + 1 : 0;
+  }
+
+  int DecIndex(int index) const {
+    RTC_DCHECK_EQ(buffer.size(), static_cast<size_t>(size));
+    return index > 0 ? index - 1 : size - 1;
+  }
+
+  int OffsetIndex(int index, int offset) const {
+    RTC_DCHECK_GE(size, offset);
+    RTC_DCHECK_EQ(buffer.size(), static_cast<size_t>(size));
+    RTC_DCHECK_GE(size + index + offset, 0);
+    return (size + index + offset) % size;
+  }
+
+  void UpdateWriteIndex(int offset) { write = OffsetIndex(write, offset); }
+  void IncWriteIndex() { write = IncIndex(write); }
+  void DecWriteIndex() { write = DecIndex(write); }
+  void UpdateReadIndex(int offset) { read = OffsetIndex(read, offset); }
+  void IncReadIndex() { read = IncIndex(read); }
+  void DecReadIndex() { read = DecIndex(read); }
+
+  const int size;
+  std::vector<std::vector<std::array<float, kFftLengthBy2Plus1>>> buffer;
+  int write = 0;
+  int read = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_SPECTRUM_BUFFER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/stationarity_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/stationarity_estimator.cc
new file mode 100644
index 0000000..01628f3
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/stationarity_estimator.cc
@@ -0,0 +1,243 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/stationarity_estimator.h"
+
+#include <algorithm>
+#include <array>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/spectrum_buffer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/atomic_ops.h"
+
+namespace webrtc {
+
+namespace {
+constexpr float kMinNoisePower = 10.f;
+constexpr int kHangoverBlocks = kNumBlocksPerSecond / 20;
+constexpr int kNBlocksAverageInitPhase = 20;
+constexpr int kNBlocksInitialPhase = kNumBlocksPerSecond * 2.;
+}  // namespace
+
+StationarityEstimator::StationarityEstimator()
+    : data_dumper_(
+          new ApmDataDumper(rtc::AtomicOps::Increment(&instance_count_))) {
+  Reset();
+}
+
+StationarityEstimator::~StationarityEstimator() = default;
+
+void StationarityEstimator::Reset() {
+  noise_.Reset();
+  hangovers_.fill(0);
+  stationarity_flags_.fill(false);
+}
+
+// Update just the noise estimator. Usefull until the delay is known
+void StationarityEstimator::UpdateNoiseEstimator(
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> spectrum) {
+  noise_.Update(spectrum);
+  data_dumper_->DumpRaw("aec3_stationarity_noise_spectrum", noise_.Spectrum());
+  data_dumper_->DumpRaw("aec3_stationarity_is_block_stationary",
+                        IsBlockStationary());
+}
+
+void StationarityEstimator::UpdateStationarityFlags(
+    const SpectrumBuffer& spectrum_buffer,
+    rtc::ArrayView<const float> render_reverb_contribution_spectrum,
+    int idx_current,
+    int num_lookahead) {
+  std::array<int, kWindowLength> indexes;
+  int num_lookahead_bounded = std::min(num_lookahead, kWindowLength - 1);
+  int idx = idx_current;
+
+  if (num_lookahead_bounded < kWindowLength - 1) {
+    int num_lookback = (kWindowLength - 1) - num_lookahead_bounded;
+    idx = spectrum_buffer.OffsetIndex(idx_current, num_lookback);
+  }
+  // For estimating the stationarity properties of the current frame, the
+  // power for each band is accumulated for several consecutive spectra in the
+  // method EstimateBandStationarity.
+  // In order to avoid getting the indexes of the spectra for every band with
+  // its associated overhead, those indexes are stored in an array and then use
+  // when the estimation is done.
+  indexes[0] = idx;
+  for (size_t k = 1; k < indexes.size(); ++k) {
+    indexes[k] = spectrum_buffer.DecIndex(indexes[k - 1]);
+  }
+  RTC_DCHECK_EQ(
+      spectrum_buffer.DecIndex(indexes[kWindowLength - 1]),
+      spectrum_buffer.OffsetIndex(idx_current, -(num_lookahead_bounded + 1)));
+
+  for (size_t k = 0; k < stationarity_flags_.size(); ++k) {
+    stationarity_flags_[k] = EstimateBandStationarity(
+        spectrum_buffer, render_reverb_contribution_spectrum, indexes, k);
+  }
+  UpdateHangover();
+  SmoothStationaryPerFreq();
+}
+
+bool StationarityEstimator::IsBlockStationary() const {
+  float acum_stationarity = 0.f;
+  RTC_DCHECK_EQ(stationarity_flags_.size(), kFftLengthBy2Plus1);
+  for (size_t band = 0; band < stationarity_flags_.size(); ++band) {
+    bool st = IsBandStationary(band);
+    acum_stationarity += static_cast<float>(st);
+  }
+  return ((acum_stationarity * (1.f / kFftLengthBy2Plus1)) > 0.75f);
+}
+
+bool StationarityEstimator::EstimateBandStationarity(
+    const SpectrumBuffer& spectrum_buffer,
+    rtc::ArrayView<const float> average_reverb,
+    const std::array<int, kWindowLength>& indexes,
+    size_t band) const {
+  constexpr float kThrStationarity = 10.f;
+  float acum_power = 0.f;
+  const int num_render_channels =
+      static_cast<int>(spectrum_buffer.buffer[0].size());
+  const float one_by_num_channels = 1.f / num_render_channels;
+  for (auto idx : indexes) {
+    for (int ch = 0; ch < num_render_channels; ++ch) {
+      acum_power += spectrum_buffer.buffer[idx][ch][band] * one_by_num_channels;
+    }
+  }
+  acum_power += average_reverb[band];
+  float noise = kWindowLength * GetStationarityPowerBand(band);
+  RTC_CHECK_LT(0.f, noise);
+  bool stationary = acum_power < kThrStationarity * noise;
+  data_dumper_->DumpRaw("aec3_stationarity_long_ratio", acum_power / noise);
+  return stationary;
+}
+
+bool StationarityEstimator::AreAllBandsStationary() {
+  for (auto b : stationarity_flags_) {
+    if (!b)
+      return false;
+  }
+  return true;
+}
+
+void StationarityEstimator::UpdateHangover() {
+  bool reduce_hangover = AreAllBandsStationary();
+  for (size_t k = 0; k < stationarity_flags_.size(); ++k) {
+    if (!stationarity_flags_[k]) {
+      hangovers_[k] = kHangoverBlocks;
+    } else if (reduce_hangover) {
+      hangovers_[k] = std::max(hangovers_[k] - 1, 0);
+    }
+  }
+}
+
+void StationarityEstimator::SmoothStationaryPerFreq() {
+  std::array<bool, kFftLengthBy2Plus1> all_ahead_stationary_smooth;
+  for (size_t k = 1; k < kFftLengthBy2Plus1 - 1; ++k) {
+    all_ahead_stationary_smooth[k] = stationarity_flags_[k - 1] &&
+                                     stationarity_flags_[k] &&
+                                     stationarity_flags_[k + 1];
+  }
+
+  all_ahead_stationary_smooth[0] = all_ahead_stationary_smooth[1];
+  all_ahead_stationary_smooth[kFftLengthBy2Plus1 - 1] =
+      all_ahead_stationary_smooth[kFftLengthBy2Plus1 - 2];
+
+  stationarity_flags_ = all_ahead_stationary_smooth;
+}
+
+int StationarityEstimator::instance_count_ = 0;
+
+StationarityEstimator::NoiseSpectrum::NoiseSpectrum() {
+  Reset();
+}
+
+StationarityEstimator::NoiseSpectrum::~NoiseSpectrum() = default;
+
+void StationarityEstimator::NoiseSpectrum::Reset() {
+  block_counter_ = 0;
+  noise_spectrum_.fill(kMinNoisePower);
+}
+
+void StationarityEstimator::NoiseSpectrum::Update(
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> spectrum) {
+  RTC_DCHECK_LE(1, spectrum[0].size());
+  const int num_render_channels = static_cast<int>(spectrum.size());
+
+  std::array<float, kFftLengthBy2Plus1> avg_spectrum_data;
+  rtc::ArrayView<const float> avg_spectrum;
+  if (num_render_channels == 1) {
+    avg_spectrum = spectrum[0];
+  } else {
+    // For multiple channels, average the channel spectra before passing to the
+    // noise spectrum estimator.
+    avg_spectrum = avg_spectrum_data;
+    std::copy(spectrum[0].begin(), spectrum[0].end(),
+              avg_spectrum_data.begin());
+    for (int ch = 1; ch < num_render_channels; ++ch) {
+      for (size_t k = 1; k < kFftLengthBy2Plus1; ++k) {
+        avg_spectrum_data[k] += spectrum[ch][k];
+      }
+    }
+
+    const float one_by_num_channels = 1.f / num_render_channels;
+    for (size_t k = 1; k < kFftLengthBy2Plus1; ++k) {
+      avg_spectrum_data[k] *= one_by_num_channels;
+    }
+  }
+
+  ++block_counter_;
+  float alpha = GetAlpha();
+  for (size_t k = 0; k < kFftLengthBy2Plus1; ++k) {
+    if (block_counter_ <= kNBlocksAverageInitPhase) {
+      noise_spectrum_[k] += (1.f / kNBlocksAverageInitPhase) * avg_spectrum[k];
+    } else {
+      noise_spectrum_[k] =
+          UpdateBandBySmoothing(avg_spectrum[k], noise_spectrum_[k], alpha);
+    }
+  }
+}
+
+float StationarityEstimator::NoiseSpectrum::GetAlpha() const {
+  constexpr float kAlpha = 0.004f;
+  constexpr float kAlphaInit = 0.04f;
+  constexpr float kTiltAlpha = (kAlphaInit - kAlpha) / kNBlocksInitialPhase;
+
+  if (block_counter_ > (kNBlocksInitialPhase + kNBlocksAverageInitPhase)) {
+    return kAlpha;
+  } else {
+    return kAlphaInit -
+           kTiltAlpha * (block_counter_ - kNBlocksAverageInitPhase);
+  }
+}
+
+float StationarityEstimator::NoiseSpectrum::UpdateBandBySmoothing(
+    float power_band,
+    float power_band_noise,
+    float alpha) const {
+  float power_band_noise_updated = power_band_noise;
+  if (power_band_noise < power_band) {
+    RTC_DCHECK_GT(power_band, 0.f);
+    float alpha_inc = alpha * (power_band_noise / power_band);
+    if (block_counter_ > kNBlocksInitialPhase) {
+      if (10.f * power_band_noise < power_band) {
+        alpha_inc *= 0.1f;
+      }
+    }
+    power_band_noise_updated += alpha_inc * (power_band - power_band_noise);
+  } else {
+    power_band_noise_updated += alpha * (power_band - power_band_noise);
+    power_band_noise_updated =
+        std::max(power_band_noise_updated, kMinNoisePower);
+  }
+  return power_band_noise_updated;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/stationarity_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/stationarity_estimator.h
new file mode 100644
index 0000000..6f7ad40
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/stationarity_estimator.h
@@ -0,0 +1,122 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_STATIONARITY_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_STATIONARITY_ESTIMATOR_H_
+
+#include <stddef.h>
+
+#include <array>
+#include <memory>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"  // kFftLengthBy2Plus1...
+#include "modules/audio_processing/aec3/reverb_model.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+class ApmDataDumper;
+struct SpectrumBuffer;
+
+class StationarityEstimator {
+ public:
+  StationarityEstimator();
+  ~StationarityEstimator();
+
+  // Reset the stationarity estimator.
+  void Reset();
+
+  // Update just the noise estimator. Usefull until the delay is known
+  void UpdateNoiseEstimator(
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> spectrum);
+
+  // Update the flag indicating whether this current frame is stationary. For
+  // getting a more robust estimation, it looks at future and/or past frames.
+  void UpdateStationarityFlags(
+      const SpectrumBuffer& spectrum_buffer,
+      rtc::ArrayView<const float> render_reverb_contribution_spectrum,
+      int idx_current,
+      int num_lookahead);
+
+  // Returns true if the current band is stationary.
+  bool IsBandStationary(size_t band) const {
+    return stationarity_flags_[band] && (hangovers_[band] == 0);
+  }
+
+  // Returns true if the current block is estimated as stationary.
+  bool IsBlockStationary() const;
+
+ private:
+  static constexpr int kWindowLength = 13;
+  // Returns the power of the stationary noise spectrum at a band.
+  float GetStationarityPowerBand(size_t k) const { return noise_.Power(k); }
+
+  // Get an estimation of the stationarity for the current band by looking
+  // at the past/present/future available data.
+  bool EstimateBandStationarity(const SpectrumBuffer& spectrum_buffer,
+                                rtc::ArrayView<const float> average_reverb,
+                                const std::array<int, kWindowLength>& indexes,
+                                size_t band) const;
+
+  // True if all bands at the current point are stationary.
+  bool AreAllBandsStationary();
+
+  // Update the hangover depending on the stationary status of the current
+  // frame.
+  void UpdateHangover();
+
+  // Smooth the stationarity detection by looking at neighbouring frequency
+  // bands.
+  void SmoothStationaryPerFreq();
+
+  class NoiseSpectrum {
+   public:
+    NoiseSpectrum();
+    ~NoiseSpectrum();
+
+    // Reset the noise power spectrum estimate state.
+    void Reset();
+
+    // Update the noise power spectrum with a new frame.
+    void Update(
+        rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> spectrum);
+
+    // Get the noise estimation power spectrum.
+    rtc::ArrayView<const float> Spectrum() const { return noise_spectrum_; }
+
+    // Get the noise power spectrum at a certain band.
+    float Power(size_t band) const {
+      RTC_DCHECK_LT(band, noise_spectrum_.size());
+      return noise_spectrum_[band];
+    }
+
+   private:
+    // Get the update coefficient to be used for the current frame.
+    float GetAlpha() const;
+
+    // Update the noise power spectrum at a certain band with a new frame.
+    float UpdateBandBySmoothing(float power_band,
+                                float power_band_noise,
+                                float alpha) const;
+    std::array<float, kFftLengthBy2Plus1> noise_spectrum_;
+    size_t block_counter_;
+  };
+
+  static int instance_count_;
+  std::unique_ptr<ApmDataDumper> data_dumper_;
+  NoiseSpectrum noise_;
+  std::array<int, kFftLengthBy2Plus1> hangovers_;
+  std::array<bool, kFftLengthBy2Plus1> stationarity_flags_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_STATIONARITY_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subband_erle_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subband_erle_estimator.cc
new file mode 100644
index 0000000..1e957f2
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subband_erle_estimator.cc
@@ -0,0 +1,240 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/subband_erle_estimator.h"
+
+#include <algorithm>
+#include <functional>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_minmax.h"
+#include "system_wrappers/include/field_trial.h"
+
+namespace webrtc {
+
+namespace {
+
+constexpr float kX2BandEnergyThreshold = 44015068.0f;
+constexpr int kBlocksToHoldErle = 100;
+constexpr int kBlocksForOnsetDetection = kBlocksToHoldErle + 150;
+constexpr int kPointsToAccumulate = 6;
+
+std::array<float, kFftLengthBy2Plus1> SetMaxErleBands(float max_erle_l,
+                                                      float max_erle_h) {
+  std::array<float, kFftLengthBy2Plus1> max_erle;
+  std::fill(max_erle.begin(), max_erle.begin() + kFftLengthBy2 / 2, max_erle_l);
+  std::fill(max_erle.begin() + kFftLengthBy2 / 2, max_erle.end(), max_erle_h);
+  return max_erle;
+}
+
+bool EnableMinErleDuringOnsets() {
+  return !field_trial::IsEnabled("WebRTC-Aec3MinErleDuringOnsetsKillSwitch");
+}
+
+}  // namespace
+
+SubbandErleEstimator::SubbandErleEstimator(const EchoCanceller3Config& config,
+                                           size_t num_capture_channels)
+    : use_onset_detection_(config.erle.onset_detection),
+      min_erle_(config.erle.min),
+      max_erle_(SetMaxErleBands(config.erle.max_l, config.erle.max_h)),
+      use_min_erle_during_onsets_(EnableMinErleDuringOnsets()),
+      accum_spectra_(num_capture_channels),
+      erle_(num_capture_channels),
+      erle_onset_compensated_(num_capture_channels),
+      erle_during_onsets_(num_capture_channels),
+      coming_onset_(num_capture_channels),
+      hold_counters_(num_capture_channels) {
+  Reset();
+}
+
+SubbandErleEstimator::~SubbandErleEstimator() = default;
+
+void SubbandErleEstimator::Reset() {
+  const size_t num_capture_channels = erle_.size();
+  for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+    erle_[ch].fill(min_erle_);
+    erle_onset_compensated_[ch].fill(min_erle_);
+    erle_during_onsets_[ch].fill(min_erle_);
+    coming_onset_[ch].fill(true);
+    hold_counters_[ch].fill(0);
+  }
+  ResetAccumulatedSpectra();
+}
+
+void SubbandErleEstimator::Update(
+    rtc::ArrayView<const float, kFftLengthBy2Plus1> X2,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Y2,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> E2,
+    const std::vector<bool>& converged_filters) {
+  UpdateAccumulatedSpectra(X2, Y2, E2, converged_filters);
+  UpdateBands(converged_filters);
+
+  if (use_onset_detection_) {
+    DecreaseErlePerBandForLowRenderSignals();
+  }
+
+  const size_t num_capture_channels = erle_.size();
+  for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+    auto& erle = erle_[ch];
+    erle[0] = erle[1];
+    erle[kFftLengthBy2] = erle[kFftLengthBy2 - 1];
+
+    auto& erle_oc = erle_onset_compensated_[ch];
+    erle_oc[0] = erle_oc[1];
+    erle_oc[kFftLengthBy2] = erle_oc[kFftLengthBy2 - 1];
+  }
+}
+
+void SubbandErleEstimator::Dump(
+    const std::unique_ptr<ApmDataDumper>& data_dumper) const {
+  data_dumper->DumpRaw("aec3_erle_onset", ErleDuringOnsets()[0]);
+}
+
+void SubbandErleEstimator::UpdateBands(
+    const std::vector<bool>& converged_filters) {
+  const int num_capture_channels = static_cast<int>(accum_spectra_.Y2.size());
+  for (int ch = 0; ch < num_capture_channels; ++ch) {
+    // Note that the use of the converged_filter flag already imposed
+    // a minimum of the erle that can be estimated as that flag would
+    // be false if the filter is performing poorly.
+    if (!converged_filters[ch]) {
+      continue;
+    }
+
+    if (accum_spectra_.num_points[ch] != kPointsToAccumulate) {
+      continue;
+    }
+
+    std::array<float, kFftLengthBy2> new_erle;
+    std::array<bool, kFftLengthBy2> is_erle_updated;
+    is_erle_updated.fill(false);
+
+    for (size_t k = 1; k < kFftLengthBy2; ++k) {
+      if (accum_spectra_.E2[ch][k] > 0.f) {
+        new_erle[k] = accum_spectra_.Y2[ch][k] / accum_spectra_.E2[ch][k];
+        is_erle_updated[k] = true;
+      }
+    }
+
+    if (use_onset_detection_) {
+      for (size_t k = 1; k < kFftLengthBy2; ++k) {
+        if (is_erle_updated[k] && !accum_spectra_.low_render_energy[ch][k]) {
+          if (coming_onset_[ch][k]) {
+            coming_onset_[ch][k] = false;
+            if (!use_min_erle_during_onsets_) {
+              float alpha =
+                  new_erle[k] < erle_during_onsets_[ch][k] ? 0.3f : 0.15f;
+              erle_during_onsets_[ch][k] = rtc::SafeClamp(
+                  erle_during_onsets_[ch][k] +
+                      alpha * (new_erle[k] - erle_during_onsets_[ch][k]),
+                  min_erle_, max_erle_[k]);
+            }
+          }
+          hold_counters_[ch][k] = kBlocksForOnsetDetection;
+        }
+      }
+    }
+
+    auto update_erle_band = [](float& erle, float new_erle,
+                               bool low_render_energy, float min_erle,
+                               float max_erle) {
+      float alpha = 0.05f;
+      if (new_erle < erle) {
+        alpha = low_render_energy ? 0.f : 0.1f;
+      }
+      erle =
+          rtc::SafeClamp(erle + alpha * (new_erle - erle), min_erle, max_erle);
+    };
+
+    for (size_t k = 1; k < kFftLengthBy2; ++k) {
+      if (is_erle_updated[k]) {
+        const bool low_render_energy = accum_spectra_.low_render_energy[ch][k];
+        update_erle_band(erle_[ch][k], new_erle[k], low_render_energy,
+                         min_erle_, max_erle_[k]);
+        if (use_onset_detection_) {
+          update_erle_band(erle_onset_compensated_[ch][k], new_erle[k],
+                           low_render_energy, min_erle_, max_erle_[k]);
+        }
+      }
+    }
+  }
+}
+
+void SubbandErleEstimator::DecreaseErlePerBandForLowRenderSignals() {
+  const int num_capture_channels = static_cast<int>(accum_spectra_.Y2.size());
+  for (int ch = 0; ch < num_capture_channels; ++ch) {
+    for (size_t k = 1; k < kFftLengthBy2; ++k) {
+      --hold_counters_[ch][k];
+      if (hold_counters_[ch][k] <=
+          (kBlocksForOnsetDetection - kBlocksToHoldErle)) {
+        if (erle_onset_compensated_[ch][k] > erle_during_onsets_[ch][k]) {
+          erle_onset_compensated_[ch][k] =
+              std::max(erle_during_onsets_[ch][k],
+                       0.97f * erle_onset_compensated_[ch][k]);
+          RTC_DCHECK_LE(min_erle_, erle_onset_compensated_[ch][k]);
+        }
+        if (hold_counters_[ch][k] <= 0) {
+          coming_onset_[ch][k] = true;
+          hold_counters_[ch][k] = 0;
+        }
+      }
+    }
+  }
+}
+
+void SubbandErleEstimator::ResetAccumulatedSpectra() {
+  for (size_t ch = 0; ch < erle_during_onsets_.size(); ++ch) {
+    accum_spectra_.Y2[ch].fill(0.f);
+    accum_spectra_.E2[ch].fill(0.f);
+    accum_spectra_.num_points[ch] = 0;
+    accum_spectra_.low_render_energy[ch].fill(false);
+  }
+}
+
+void SubbandErleEstimator::UpdateAccumulatedSpectra(
+    rtc::ArrayView<const float, kFftLengthBy2Plus1> X2,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Y2,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> E2,
+    const std::vector<bool>& converged_filters) {
+  auto& st = accum_spectra_;
+  RTC_DCHECK_EQ(st.E2.size(), E2.size());
+  RTC_DCHECK_EQ(st.E2.size(), E2.size());
+  const int num_capture_channels = static_cast<int>(Y2.size());
+  for (int ch = 0; ch < num_capture_channels; ++ch) {
+    // Note that the use of the converged_filter flag already imposed
+    // a minimum of the erle that can be estimated as that flag would
+    // be false if the filter is performing poorly.
+    if (!converged_filters[ch]) {
+      continue;
+    }
+
+    if (st.num_points[ch] == kPointsToAccumulate) {
+      st.num_points[ch] = 0;
+      st.Y2[ch].fill(0.f);
+      st.E2[ch].fill(0.f);
+      st.low_render_energy[ch].fill(false);
+    }
+
+    std::transform(Y2[ch].begin(), Y2[ch].end(), st.Y2[ch].begin(),
+                   st.Y2[ch].begin(), std::plus<float>());
+    std::transform(E2[ch].begin(), E2[ch].end(), st.E2[ch].begin(),
+                   st.E2[ch].begin(), std::plus<float>());
+
+    for (size_t k = 0; k < X2.size(); ++k) {
+      st.low_render_energy[ch][k] =
+          st.low_render_energy[ch][k] || X2[k] < kX2BandEnergyThreshold;
+    }
+
+    ++st.num_points[ch];
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subband_erle_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subband_erle_estimator.h
new file mode 100644
index 0000000..ffed6a5
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subband_erle_estimator.h
@@ -0,0 +1,99 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_SUBBAND_ERLE_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_SUBBAND_ERLE_ESTIMATOR_H_
+
+#include <stddef.h>
+
+#include <array>
+#include <memory>
+#include <vector>
+
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+
+namespace webrtc {
+
+// Estimates the echo return loss enhancement for each frequency subband.
+class SubbandErleEstimator {
+ public:
+  SubbandErleEstimator(const EchoCanceller3Config& config,
+                       size_t num_capture_channels);
+  ~SubbandErleEstimator();
+
+  // Resets the ERLE estimator.
+  void Reset();
+
+  // Updates the ERLE estimate.
+  void Update(rtc::ArrayView<const float, kFftLengthBy2Plus1> X2,
+              rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Y2,
+              rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> E2,
+              const std::vector<bool>& converged_filters);
+
+  // Returns the ERLE estimate.
+  rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Erle(
+      bool onset_compensated) const {
+    return onset_compensated && use_onset_detection_ ? erle_onset_compensated_
+                                                     : erle_;
+  }
+
+  // Returns the ERLE estimate at onsets (only used for testing).
+  rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> ErleDuringOnsets()
+      const {
+    return erle_during_onsets_;
+  }
+
+  void Dump(const std::unique_ptr<ApmDataDumper>& data_dumper) const;
+
+ private:
+  struct AccumulatedSpectra {
+    explicit AccumulatedSpectra(size_t num_capture_channels)
+        : Y2(num_capture_channels),
+          E2(num_capture_channels),
+          low_render_energy(num_capture_channels),
+          num_points(num_capture_channels) {}
+    std::vector<std::array<float, kFftLengthBy2Plus1>> Y2;
+    std::vector<std::array<float, kFftLengthBy2Plus1>> E2;
+    std::vector<std::array<bool, kFftLengthBy2Plus1>> low_render_energy;
+    std::vector<int> num_points;
+  };
+
+  void UpdateAccumulatedSpectra(
+      rtc::ArrayView<const float, kFftLengthBy2Plus1> X2,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> Y2,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> E2,
+      const std::vector<bool>& converged_filters);
+
+  void ResetAccumulatedSpectra();
+
+  void UpdateBands(const std::vector<bool>& converged_filters);
+  void DecreaseErlePerBandForLowRenderSignals();
+
+  const bool use_onset_detection_;
+  const float min_erle_;
+  const std::array<float, kFftLengthBy2Plus1> max_erle_;
+  const bool use_min_erle_during_onsets_;
+  AccumulatedSpectra accum_spectra_;
+  // ERLE without special handling of render onsets.
+  std::vector<std::array<float, kFftLengthBy2Plus1>> erle_;
+  // ERLE lowered during render onsets.
+  std::vector<std::array<float, kFftLengthBy2Plus1>> erle_onset_compensated_;
+  // Estimation of ERLE during render onsets.
+  std::vector<std::array<float, kFftLengthBy2Plus1>> erle_during_onsets_;
+  std::vector<std::array<bool, kFftLengthBy2Plus1>> coming_onset_;
+  std::vector<std::array<int, kFftLengthBy2Plus1>> hold_counters_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_SUBBAND_ERLE_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subband_nearend_detector.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subband_nearend_detector.cc
new file mode 100644
index 0000000..2aa400c
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subband_nearend_detector.cc
@@ -0,0 +1,70 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/subband_nearend_detector.h"
+
+#include <numeric>
+
+namespace webrtc {
+SubbandNearendDetector::SubbandNearendDetector(
+    const EchoCanceller3Config::Suppressor::SubbandNearendDetection& config,
+    size_t num_capture_channels)
+    : config_(config),
+      num_capture_channels_(num_capture_channels),
+      nearend_smoothers_(num_capture_channels_,
+                         aec3::MovingAverage(kFftLengthBy2Plus1,
+                                             config_.nearend_average_blocks)),
+      one_over_subband_length1_(
+          1.f / (config_.subband1.high - config_.subband1.low + 1)),
+      one_over_subband_length2_(
+          1.f / (config_.subband2.high - config_.subband2.low + 1)) {}
+
+void SubbandNearendDetector::Update(
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+        nearend_spectrum,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+        residual_echo_spectrum,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+        comfort_noise_spectrum,
+    bool initial_state) {
+  nearend_state_ = false;
+  for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+    const std::array<float, kFftLengthBy2Plus1>& noise =
+        comfort_noise_spectrum[ch];
+    std::array<float, kFftLengthBy2Plus1> nearend;
+    nearend_smoothers_[ch].Average(nearend_spectrum[ch], nearend);
+
+    // Noise power of the first region.
+    float noise_power =
+        std::accumulate(noise.begin() + config_.subband1.low,
+                        noise.begin() + config_.subband1.high + 1, 0.f) *
+        one_over_subband_length1_;
+
+    // Nearend power of the first region.
+    float nearend_power_subband1 =
+        std::accumulate(nearend.begin() + config_.subband1.low,
+                        nearend.begin() + config_.subband1.high + 1, 0.f) *
+        one_over_subband_length1_;
+
+    // Nearend power of the second region.
+    float nearend_power_subband2 =
+        std::accumulate(nearend.begin() + config_.subband2.low,
+                        nearend.begin() + config_.subband2.high + 1, 0.f) *
+        one_over_subband_length2_;
+
+    // One channel is sufficient to trigger nearend state.
+    nearend_state_ =
+        nearend_state_ ||
+        (nearend_power_subband1 <
+             config_.nearend_threshold * nearend_power_subband2 &&
+         (nearend_power_subband1 > config_.snr_threshold * noise_power));
+  }
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subband_nearend_detector.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subband_nearend_detector.h
new file mode 100644
index 0000000..8357edb
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subband_nearend_detector.h
@@ -0,0 +1,52 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_SUBBAND_NEAREND_DETECTOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_SUBBAND_NEAREND_DETECTOR_H_
+
+#include <vector>
+
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/moving_average.h"
+#include "modules/audio_processing/aec3/nearend_detector.h"
+
+namespace webrtc {
+// Class for selecting whether the suppressor is in the nearend or echo state.
+class SubbandNearendDetector : public NearendDetector {
+ public:
+  SubbandNearendDetector(
+      const EchoCanceller3Config::Suppressor::SubbandNearendDetection& config,
+      size_t num_capture_channels);
+
+  // Returns whether the current state is the nearend state.
+  bool IsNearendState() const override { return nearend_state_; }
+
+  // Updates the state selection based on latest spectral estimates.
+  void Update(rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+                  nearend_spectrum,
+              rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+                  residual_echo_spectrum,
+              rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+                  comfort_noise_spectrum,
+              bool initial_state) override;
+
+ private:
+  const EchoCanceller3Config::Suppressor::SubbandNearendDetection config_;
+  const size_t num_capture_channels_;
+  std::vector<aec3::MovingAverage> nearend_smoothers_;
+  const float one_over_subband_length1_;
+  const float one_over_subband_length2_;
+  bool nearend_state_ = false;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_SUBBAND_NEAREND_DETECTOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor.cc
new file mode 100644
index 0000000..d10e4ff
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor.cc
@@ -0,0 +1,345 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/subtractor.h"
+
+#include <algorithm>
+#include <utility>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/adaptive_fir_filter_erl.h"
+#include "modules/audio_processing/aec3/fft_data.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_minmax.h"
+#include "system_wrappers/include/field_trial.h"
+
+namespace webrtc {
+
+namespace {
+
+bool UseCoarseFilterResetHangover() {
+  return !field_trial::IsEnabled(
+      "WebRTC-Aec3CoarseFilterResetHangoverKillSwitch");
+}
+
+void PredictionError(const Aec3Fft& fft,
+                     const FftData& S,
+                     rtc::ArrayView<const float> y,
+                     std::array<float, kBlockSize>* e,
+                     std::array<float, kBlockSize>* s) {
+  std::array<float, kFftLength> tmp;
+  fft.Ifft(S, &tmp);
+  constexpr float kScale = 1.0f / kFftLengthBy2;
+  std::transform(y.begin(), y.end(), tmp.begin() + kFftLengthBy2, e->begin(),
+                 [&](float a, float b) { return a - b * kScale; });
+
+  if (s) {
+    for (size_t k = 0; k < s->size(); ++k) {
+      (*s)[k] = kScale * tmp[k + kFftLengthBy2];
+    }
+  }
+}
+
+void ScaleFilterOutput(rtc::ArrayView<const float> y,
+                       float factor,
+                       rtc::ArrayView<float> e,
+                       rtc::ArrayView<float> s) {
+  RTC_DCHECK_EQ(y.size(), e.size());
+  RTC_DCHECK_EQ(y.size(), s.size());
+  for (size_t k = 0; k < y.size(); ++k) {
+    s[k] *= factor;
+    e[k] = y[k] - s[k];
+  }
+}
+
+}  // namespace
+
+Subtractor::Subtractor(const EchoCanceller3Config& config,
+                       size_t num_render_channels,
+                       size_t num_capture_channels,
+                       ApmDataDumper* data_dumper,
+                       Aec3Optimization optimization)
+    : fft_(),
+      data_dumper_(data_dumper),
+      optimization_(optimization),
+      config_(config),
+      num_capture_channels_(num_capture_channels),
+      use_coarse_filter_reset_hangover_(UseCoarseFilterResetHangover()),
+      refined_filters_(num_capture_channels_),
+      coarse_filter_(num_capture_channels_),
+      refined_gains_(num_capture_channels_),
+      coarse_gains_(num_capture_channels_),
+      filter_misadjustment_estimators_(num_capture_channels_),
+      poor_coarse_filter_counters_(num_capture_channels_, 0),
+      coarse_filter_reset_hangover_(num_capture_channels_, 0),
+      refined_frequency_responses_(
+          num_capture_channels_,
+          std::vector<std::array<float, kFftLengthBy2Plus1>>(
+              std::max(config_.filter.refined_initial.length_blocks,
+                       config_.filter.refined.length_blocks),
+              std::array<float, kFftLengthBy2Plus1>())),
+      refined_impulse_responses_(
+          num_capture_channels_,
+          std::vector<float>(GetTimeDomainLength(std::max(
+                                 config_.filter.refined_initial.length_blocks,
+                                 config_.filter.refined.length_blocks)),
+                             0.f)) {
+  for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+    refined_filters_[ch] = std::make_unique<AdaptiveFirFilter>(
+        config_.filter.refined.length_blocks,
+        config_.filter.refined_initial.length_blocks,
+        config.filter.config_change_duration_blocks, num_render_channels,
+        optimization, data_dumper_);
+
+    coarse_filter_[ch] = std::make_unique<AdaptiveFirFilter>(
+        config_.filter.coarse.length_blocks,
+        config_.filter.coarse_initial.length_blocks,
+        config.filter.config_change_duration_blocks, num_render_channels,
+        optimization, data_dumper_);
+    refined_gains_[ch] = std::make_unique<RefinedFilterUpdateGain>(
+        config_.filter.refined_initial,
+        config_.filter.config_change_duration_blocks);
+    coarse_gains_[ch] = std::make_unique<CoarseFilterUpdateGain>(
+        config_.filter.coarse_initial,
+        config.filter.config_change_duration_blocks);
+  }
+
+  RTC_DCHECK(data_dumper_);
+  for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+    for (auto& H2_k : refined_frequency_responses_[ch]) {
+      H2_k.fill(0.f);
+    }
+  }
+}
+
+Subtractor::~Subtractor() = default;
+
+void Subtractor::HandleEchoPathChange(
+    const EchoPathVariability& echo_path_variability) {
+  const auto full_reset = [&]() {
+    for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+      refined_filters_[ch]->HandleEchoPathChange();
+      coarse_filter_[ch]->HandleEchoPathChange();
+      refined_gains_[ch]->HandleEchoPathChange(echo_path_variability);
+      coarse_gains_[ch]->HandleEchoPathChange();
+      refined_gains_[ch]->SetConfig(config_.filter.refined_initial, true);
+      coarse_gains_[ch]->SetConfig(config_.filter.coarse_initial, true);
+      refined_filters_[ch]->SetSizePartitions(
+          config_.filter.refined_initial.length_blocks, true);
+      coarse_filter_[ch]->SetSizePartitions(
+          config_.filter.coarse_initial.length_blocks, true);
+    }
+  };
+
+  if (echo_path_variability.delay_change !=
+      EchoPathVariability::DelayAdjustment::kNone) {
+    full_reset();
+  }
+
+  if (echo_path_variability.gain_change) {
+    for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+      refined_gains_[ch]->HandleEchoPathChange(echo_path_variability);
+    }
+  }
+}
+
+void Subtractor::ExitInitialState() {
+  for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+    refined_gains_[ch]->SetConfig(config_.filter.refined, false);
+    coarse_gains_[ch]->SetConfig(config_.filter.coarse, false);
+    refined_filters_[ch]->SetSizePartitions(
+        config_.filter.refined.length_blocks, false);
+    coarse_filter_[ch]->SetSizePartitions(config_.filter.coarse.length_blocks,
+                                          false);
+  }
+}
+
+void Subtractor::Process(const RenderBuffer& render_buffer,
+                         const std::vector<std::vector<float>>& capture,
+                         const RenderSignalAnalyzer& render_signal_analyzer,
+                         const AecState& aec_state,
+                         rtc::ArrayView<SubtractorOutput> outputs) {
+  RTC_DCHECK_EQ(num_capture_channels_, capture.size());
+
+  // Compute the render powers.
+  const bool same_filter_sizes = refined_filters_[0]->SizePartitions() ==
+                                 coarse_filter_[0]->SizePartitions();
+  std::array<float, kFftLengthBy2Plus1> X2_refined;
+  std::array<float, kFftLengthBy2Plus1> X2_coarse_data;
+  auto& X2_coarse = same_filter_sizes ? X2_refined : X2_coarse_data;
+  if (same_filter_sizes) {
+    render_buffer.SpectralSum(refined_filters_[0]->SizePartitions(),
+                              &X2_refined);
+  } else if (refined_filters_[0]->SizePartitions() >
+             coarse_filter_[0]->SizePartitions()) {
+    render_buffer.SpectralSums(coarse_filter_[0]->SizePartitions(),
+                               refined_filters_[0]->SizePartitions(),
+                               &X2_coarse, &X2_refined);
+  } else {
+    render_buffer.SpectralSums(refined_filters_[0]->SizePartitions(),
+                               coarse_filter_[0]->SizePartitions(), &X2_refined,
+                               &X2_coarse);
+  }
+
+  // Process all capture channels
+  for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+    RTC_DCHECK_EQ(kBlockSize, capture[ch].size());
+    SubtractorOutput& output = outputs[ch];
+    rtc::ArrayView<const float> y = capture[ch];
+    FftData& E_refined = output.E_refined;
+    FftData E_coarse;
+    std::array<float, kBlockSize>& e_refined = output.e_refined;
+    std::array<float, kBlockSize>& e_coarse = output.e_coarse;
+
+    FftData S;
+    FftData& G = S;
+
+    // Form the outputs of the refined and coarse filters.
+    refined_filters_[ch]->Filter(render_buffer, &S);
+    PredictionError(fft_, S, y, &e_refined, &output.s_refined);
+
+    coarse_filter_[ch]->Filter(render_buffer, &S);
+    PredictionError(fft_, S, y, &e_coarse, &output.s_coarse);
+
+    // Compute the signal powers in the subtractor output.
+    output.ComputeMetrics(y);
+
+    // Adjust the filter if needed.
+    bool refined_filters_adjusted = false;
+    filter_misadjustment_estimators_[ch].Update(output);
+    if (filter_misadjustment_estimators_[ch].IsAdjustmentNeeded()) {
+      float scale = filter_misadjustment_estimators_[ch].GetMisadjustment();
+      refined_filters_[ch]->ScaleFilter(scale);
+      for (auto& h_k : refined_impulse_responses_[ch]) {
+        h_k *= scale;
+      }
+      ScaleFilterOutput(y, scale, e_refined, output.s_refined);
+      filter_misadjustment_estimators_[ch].Reset();
+      refined_filters_adjusted = true;
+    }
+
+    // Compute the FFts of the refined and coarse filter outputs.
+    fft_.ZeroPaddedFft(e_refined, Aec3Fft::Window::kHanning, &E_refined);
+    fft_.ZeroPaddedFft(e_coarse, Aec3Fft::Window::kHanning, &E_coarse);
+
+    // Compute spectra for future use.
+    E_coarse.Spectrum(optimization_, output.E2_coarse);
+    E_refined.Spectrum(optimization_, output.E2_refined);
+
+    // Update the refined filter.
+    if (!refined_filters_adjusted) {
+      // Do not allow the performance of the coarse filter to affect the
+      // adaptation speed of the refined filter just after the coarse filter has
+      // been reset.
+      const bool disallow_leakage_diverged =
+          coarse_filter_reset_hangover_[ch] > 0 &&
+          use_coarse_filter_reset_hangover_;
+
+      std::array<float, kFftLengthBy2Plus1> erl;
+      ComputeErl(optimization_, refined_frequency_responses_[ch], erl);
+      refined_gains_[ch]->Compute(X2_refined, render_signal_analyzer, output,
+                                  erl, refined_filters_[ch]->SizePartitions(),
+                                  aec_state.SaturatedCapture(),
+                                  disallow_leakage_diverged, &G);
+    } else {
+      G.re.fill(0.f);
+      G.im.fill(0.f);
+    }
+    refined_filters_[ch]->Adapt(render_buffer, G,
+                                &refined_impulse_responses_[ch]);
+    refined_filters_[ch]->ComputeFrequencyResponse(
+        &refined_frequency_responses_[ch]);
+
+    if (ch == 0) {
+      data_dumper_->DumpRaw("aec3_subtractor_G_refined", G.re);
+      data_dumper_->DumpRaw("aec3_subtractor_G_refined", G.im);
+    }
+
+    // Update the coarse filter.
+    poor_coarse_filter_counters_[ch] =
+        output.e2_refined < output.e2_coarse
+            ? poor_coarse_filter_counters_[ch] + 1
+            : 0;
+    if (poor_coarse_filter_counters_[ch] < 5) {
+      coarse_gains_[ch]->Compute(X2_coarse, render_signal_analyzer, E_coarse,
+                                 coarse_filter_[ch]->SizePartitions(),
+                                 aec_state.SaturatedCapture(), &G);
+      coarse_filter_reset_hangover_[ch] =
+          std::max(coarse_filter_reset_hangover_[ch] - 1, 0);
+    } else {
+      poor_coarse_filter_counters_[ch] = 0;
+      coarse_filter_[ch]->SetFilter(refined_filters_[ch]->SizePartitions(),
+                                    refined_filters_[ch]->GetFilter());
+      coarse_gains_[ch]->Compute(X2_coarse, render_signal_analyzer, E_refined,
+                                 coarse_filter_[ch]->SizePartitions(),
+                                 aec_state.SaturatedCapture(), &G);
+      coarse_filter_reset_hangover_[ch] =
+          config_.filter.coarse_reset_hangover_blocks;
+    }
+
+    coarse_filter_[ch]->Adapt(render_buffer, G);
+    if (ch == 0) {
+      data_dumper_->DumpRaw("aec3_subtractor_G_coarse", G.re);
+      data_dumper_->DumpRaw("aec3_subtractor_G_coarse", G.im);
+      filter_misadjustment_estimators_[ch].Dump(data_dumper_);
+      DumpFilters();
+    }
+
+    std::for_each(e_refined.begin(), e_refined.end(),
+                  [](float& a) { a = rtc::SafeClamp(a, -32768.f, 32767.f); });
+
+    if (ch == 0) {
+      data_dumper_->DumpWav("aec3_refined_filters_output", kBlockSize,
+                            &e_refined[0], 16000, 1);
+      data_dumper_->DumpWav("aec3_coarse_filter_output", kBlockSize,
+                            &e_coarse[0], 16000, 1);
+    }
+  }
+}
+
+void Subtractor::FilterMisadjustmentEstimator::Update(
+    const SubtractorOutput& output) {
+  e2_acum_ += output.e2_refined;
+  y2_acum_ += output.y2;
+  if (++n_blocks_acum_ == n_blocks_) {
+    if (y2_acum_ > n_blocks_ * 200.f * 200.f * kBlockSize) {
+      float update = (e2_acum_ / y2_acum_);
+      if (e2_acum_ > n_blocks_ * 7500.f * 7500.f * kBlockSize) {
+        // Duration equal to blockSizeMs * n_blocks_ * 4.
+        overhang_ = 4;
+      } else {
+        overhang_ = std::max(overhang_ - 1, 0);
+      }
+
+      if ((update < inv_misadjustment_) || (overhang_ > 0)) {
+        inv_misadjustment_ += 0.1f * (update - inv_misadjustment_);
+      }
+    }
+    e2_acum_ = 0.f;
+    y2_acum_ = 0.f;
+    n_blocks_acum_ = 0;
+  }
+}
+
+void Subtractor::FilterMisadjustmentEstimator::Reset() {
+  e2_acum_ = 0.f;
+  y2_acum_ = 0.f;
+  n_blocks_acum_ = 0;
+  inv_misadjustment_ = 0.f;
+  overhang_ = 0.f;
+}
+
+void Subtractor::FilterMisadjustmentEstimator::Dump(
+    ApmDataDumper* data_dumper) const {
+  data_dumper->DumpRaw("aec3_inv_misadjustment_factor", inv_misadjustment_);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor.h
new file mode 100644
index 0000000..560f656
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor.h
@@ -0,0 +1,139 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_SUBTRACTOR_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_SUBTRACTOR_H_
+
+#include <math.h>
+#include <stddef.h>
+
+#include <array>
+#include <vector>
+
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/adaptive_fir_filter.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/aec3_fft.h"
+#include "modules/audio_processing/aec3/aec_state.h"
+#include "modules/audio_processing/aec3/coarse_filter_update_gain.h"
+#include "modules/audio_processing/aec3/echo_path_variability.h"
+#include "modules/audio_processing/aec3/refined_filter_update_gain.h"
+#include "modules/audio_processing/aec3/render_buffer.h"
+#include "modules/audio_processing/aec3/render_signal_analyzer.h"
+#include "modules/audio_processing/aec3/subtractor_output.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+// Proves linear echo cancellation functionality
+class Subtractor {
+ public:
+  Subtractor(const EchoCanceller3Config& config,
+             size_t num_render_channels,
+             size_t num_capture_channels,
+             ApmDataDumper* data_dumper,
+             Aec3Optimization optimization);
+  ~Subtractor();
+  Subtractor(const Subtractor&) = delete;
+  Subtractor& operator=(const Subtractor&) = delete;
+
+  // Performs the echo subtraction.
+  void Process(const RenderBuffer& render_buffer,
+               const std::vector<std::vector<float>>& capture,
+               const RenderSignalAnalyzer& render_signal_analyzer,
+               const AecState& aec_state,
+               rtc::ArrayView<SubtractorOutput> outputs);
+
+  void HandleEchoPathChange(const EchoPathVariability& echo_path_variability);
+
+  // Exits the initial state.
+  void ExitInitialState();
+
+  // Returns the block-wise frequency responses for the refined adaptive
+  // filters.
+  const std::vector<std::vector<std::array<float, kFftLengthBy2Plus1>>>&
+  FilterFrequencyResponses() const {
+    return refined_frequency_responses_;
+  }
+
+  // Returns the estimates of the impulse responses for the refined adaptive
+  // filters.
+  const std::vector<std::vector<float>>& FilterImpulseResponses() const {
+    return refined_impulse_responses_;
+  }
+
+  void DumpFilters() {
+    data_dumper_->DumpRaw(
+        "aec3_subtractor_h_refined",
+        rtc::ArrayView<const float>(
+            refined_impulse_responses_[0].data(),
+            GetTimeDomainLength(
+                refined_filters_[0]->max_filter_size_partitions())));
+
+    refined_filters_[0]->DumpFilter("aec3_subtractor_H_refined");
+    coarse_filter_[0]->DumpFilter("aec3_subtractor_H_coarse");
+  }
+
+ private:
+  class FilterMisadjustmentEstimator {
+   public:
+    FilterMisadjustmentEstimator() = default;
+    ~FilterMisadjustmentEstimator() = default;
+    // Update the misadjustment estimator.
+    void Update(const SubtractorOutput& output);
+    // GetMisadjustment() Returns a recommended scale for the filter so the
+    // prediction error energy gets closer to the energy that is seen at the
+    // microphone input.
+    float GetMisadjustment() const {
+      RTC_DCHECK_GT(inv_misadjustment_, 0.0f);
+      // It is not aiming to adjust all the estimated mismatch. Instead,
+      // it adjusts half of that estimated mismatch.
+      return 2.f / sqrtf(inv_misadjustment_);
+    }
+    // Returns true if the prediciton error energy is significantly larger
+    // than the microphone signal energy and, therefore, an adjustment is
+    // recommended.
+    bool IsAdjustmentNeeded() const { return inv_misadjustment_ > 10.f; }
+    void Reset();
+    void Dump(ApmDataDumper* data_dumper) const;
+
+   private:
+    const int n_blocks_ = 4;
+    int n_blocks_acum_ = 0;
+    float e2_acum_ = 0.f;
+    float y2_acum_ = 0.f;
+    float inv_misadjustment_ = 0.f;
+    int overhang_ = 0.f;
+  };
+
+  const Aec3Fft fft_;
+  ApmDataDumper* data_dumper_;
+  const Aec3Optimization optimization_;
+  const EchoCanceller3Config config_;
+  const size_t num_capture_channels_;
+  const bool use_coarse_filter_reset_hangover_;
+
+  std::vector<std::unique_ptr<AdaptiveFirFilter>> refined_filters_;
+  std::vector<std::unique_ptr<AdaptiveFirFilter>> coarse_filter_;
+  std::vector<std::unique_ptr<RefinedFilterUpdateGain>> refined_gains_;
+  std::vector<std::unique_ptr<CoarseFilterUpdateGain>> coarse_gains_;
+  std::vector<FilterMisadjustmentEstimator> filter_misadjustment_estimators_;
+  std::vector<size_t> poor_coarse_filter_counters_;
+  std::vector<int> coarse_filter_reset_hangover_;
+  std::vector<std::vector<std::array<float, kFftLengthBy2Plus1>>>
+      refined_frequency_responses_;
+  std::vector<std::vector<float>> refined_impulse_responses_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_SUBTRACTOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor_output.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor_output.cc
new file mode 100644
index 0000000..ed80101
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor_output.cc
@@ -0,0 +1,58 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/subtractor_output.h"
+
+#include <numeric>
+
+namespace webrtc {
+
+SubtractorOutput::SubtractorOutput() = default;
+SubtractorOutput::~SubtractorOutput() = default;
+
+void SubtractorOutput::Reset() {
+  s_refined.fill(0.f);
+  s_coarse.fill(0.f);
+  e_refined.fill(0.f);
+  e_coarse.fill(0.f);
+  E_refined.re.fill(0.f);
+  E_refined.im.fill(0.f);
+  E2_refined.fill(0.f);
+  E2_coarse.fill(0.f);
+  e2_refined = 0.f;
+  e2_coarse = 0.f;
+  s2_refined = 0.f;
+  s2_coarse = 0.f;
+  y2 = 0.f;
+}
+
+void SubtractorOutput::ComputeMetrics(rtc::ArrayView<const float> y) {
+  const auto sum_of_squares = [](float a, float b) { return a + b * b; };
+  y2 = std::accumulate(y.begin(), y.end(), 0.f, sum_of_squares);
+  e2_refined =
+      std::accumulate(e_refined.begin(), e_refined.end(), 0.f, sum_of_squares);
+  e2_coarse =
+      std::accumulate(e_coarse.begin(), e_coarse.end(), 0.f, sum_of_squares);
+  s2_refined =
+      std::accumulate(s_refined.begin(), s_refined.end(), 0.f, sum_of_squares);
+  s2_coarse =
+      std::accumulate(s_coarse.begin(), s_coarse.end(), 0.f, sum_of_squares);
+
+  s_refined_max_abs = *std::max_element(s_refined.begin(), s_refined.end());
+  s_refined_max_abs =
+      std::max(s_refined_max_abs,
+               -(*std::min_element(s_refined.begin(), s_refined.end())));
+
+  s_coarse_max_abs = *std::max_element(s_coarse.begin(), s_coarse.end());
+  s_coarse_max_abs = std::max(
+      s_coarse_max_abs, -(*std::min_element(s_coarse.begin(), s_coarse.end())));
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor_output.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor_output.h
new file mode 100644
index 0000000..d2d1208
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor_output.h
@@ -0,0 +1,52 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_SUBTRACTOR_OUTPUT_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_SUBTRACTOR_OUTPUT_H_
+
+#include <array>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/fft_data.h"
+
+namespace webrtc {
+
+// Stores the values being returned from the echo subtractor for a single
+// capture channel.
+struct SubtractorOutput {
+  SubtractorOutput();
+  ~SubtractorOutput();
+
+  std::array<float, kBlockSize> s_refined;
+  std::array<float, kBlockSize> s_coarse;
+  std::array<float, kBlockSize> e_refined;
+  std::array<float, kBlockSize> e_coarse;
+  FftData E_refined;
+  std::array<float, kFftLengthBy2Plus1> E2_refined;
+  std::array<float, kFftLengthBy2Plus1> E2_coarse;
+  float s2_refined = 0.f;
+  float s2_coarse = 0.f;
+  float e2_refined = 0.f;
+  float e2_coarse = 0.f;
+  float y2 = 0.f;
+  float s_refined_max_abs = 0.f;
+  float s_coarse_max_abs = 0.f;
+
+  // Reset the struct content.
+  void Reset();
+
+  // Updates the powers of the signals.
+  void ComputeMetrics(rtc::ArrayView<const float> y);
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_SUBTRACTOR_OUTPUT_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor_output_analyzer.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor_output_analyzer.cc
new file mode 100644
index 0000000..baf0600
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor_output_analyzer.cc
@@ -0,0 +1,64 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/subtractor_output_analyzer.h"
+
+#include <algorithm>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+
+namespace webrtc {
+
+SubtractorOutputAnalyzer::SubtractorOutputAnalyzer(size_t num_capture_channels)
+    : filters_converged_(num_capture_channels, false) {}
+
+void SubtractorOutputAnalyzer::Update(
+    rtc::ArrayView<const SubtractorOutput> subtractor_output,
+    bool* any_filter_converged,
+    bool* any_coarse_filter_converged,
+    bool* all_filters_diverged) {
+  RTC_DCHECK(any_filter_converged);
+  RTC_DCHECK(all_filters_diverged);
+  RTC_DCHECK_EQ(subtractor_output.size(), filters_converged_.size());
+
+  *any_filter_converged = false;
+  *any_coarse_filter_converged = false;
+  *all_filters_diverged = true;
+
+  for (size_t ch = 0; ch < subtractor_output.size(); ++ch) {
+    const float y2 = subtractor_output[ch].y2;
+    const float e2_refined = subtractor_output[ch].e2_refined;
+    const float e2_coarse = subtractor_output[ch].e2_coarse;
+
+    constexpr float kConvergenceThreshold = 50 * 50 * kBlockSize;
+    constexpr float kConvergenceThresholdLowLevel = 20 * 20 * kBlockSize;
+    bool refined_filter_converged =
+        e2_refined < 0.5f * y2 && y2 > kConvergenceThreshold;
+    bool coarse_filter_converged_strict =
+        e2_coarse < 0.05f * y2 && y2 > kConvergenceThreshold;
+    bool coarse_filter_converged_relaxed =
+        e2_coarse < 0.2f * y2 && y2 > kConvergenceThresholdLowLevel;
+    float min_e2 = std::min(e2_refined, e2_coarse);
+    bool filter_diverged = min_e2 > 1.5f * y2 && y2 > 30.f * 30.f * kBlockSize;
+    filters_converged_[ch] =
+        refined_filter_converged || coarse_filter_converged_strict;
+
+    *any_filter_converged = *any_filter_converged || filters_converged_[ch];
+    *any_coarse_filter_converged =
+        *any_coarse_filter_converged || coarse_filter_converged_relaxed;
+    *all_filters_diverged = *all_filters_diverged && filter_diverged;
+  }
+}
+
+void SubtractorOutputAnalyzer::HandleEchoPathChange() {
+  std::fill(filters_converged_.begin(), filters_converged_.end(), false);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor_output_analyzer.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor_output_analyzer.h
new file mode 100644
index 0000000..32707db
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor_output_analyzer.h
@@ -0,0 +1,45 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_SUBTRACTOR_OUTPUT_ANALYZER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_SUBTRACTOR_OUTPUT_ANALYZER_H_
+
+#include <vector>
+
+#include "modules/audio_processing/aec3/subtractor_output.h"
+
+namespace webrtc {
+
+// Class for analyzing the properties subtractor output.
+class SubtractorOutputAnalyzer {
+ public:
+  explicit SubtractorOutputAnalyzer(size_t num_capture_channels);
+  ~SubtractorOutputAnalyzer() = default;
+
+  // Analyses the subtractor output.
+  void Update(rtc::ArrayView<const SubtractorOutput> subtractor_output,
+              bool* any_filter_converged,
+              bool* any_coarse_filter_converged,
+              bool* all_filters_diverged);
+
+  const std::vector<bool>& ConvergedFilters() const {
+    return filters_converged_;
+  }
+
+  // Handle echo path change.
+  void HandleEchoPathChange();
+
+ private:
+  std::vector<bool> filters_converged_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_SUBTRACTOR_OUTPUT_ANALYZER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor_unittest.cc
new file mode 100644
index 0000000..bbc1e4f
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/subtractor_unittest.cc
@@ -0,0 +1,337 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/subtractor.h"
+
+#include <algorithm>
+#include <memory>
+#include <numeric>
+#include <string>
+
+#include "modules/audio_processing/aec3/aec_state.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "modules/audio_processing/test/echo_canceller_test_tools.h"
+#include "modules/audio_processing/utility/cascaded_biquad_filter.h"
+#include "rtc_base/random.h"
+#include "rtc_base/strings/string_builder.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace {
+
+std::vector<float> RunSubtractorTest(
+    size_t num_render_channels,
+    size_t num_capture_channels,
+    int num_blocks_to_process,
+    int delay_samples,
+    int refined_filter_length_blocks,
+    int coarse_filter_length_blocks,
+    bool uncorrelated_inputs,
+    const std::vector<int>& blocks_with_echo_path_changes) {
+  ApmDataDumper data_dumper(42);
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+  EchoCanceller3Config config;
+  config.filter.refined.length_blocks = refined_filter_length_blocks;
+  config.filter.coarse.length_blocks = coarse_filter_length_blocks;
+
+  Subtractor subtractor(config, num_render_channels, num_capture_channels,
+                        &data_dumper, DetectOptimization());
+  absl::optional<DelayEstimate> delay_estimate;
+  std::vector<std::vector<std::vector<float>>> x(
+      kNumBands, std::vector<std::vector<float>>(
+                     num_render_channels, std::vector<float>(kBlockSize, 0.f)));
+  std::vector<std::vector<float>> y(num_capture_channels,
+                                    std::vector<float>(kBlockSize, 0.f));
+  std::array<float, kBlockSize> x_old;
+  std::vector<SubtractorOutput> output(num_capture_channels);
+  config.delay.default_delay = 1;
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+      RenderDelayBuffer::Create(config, kSampleRateHz, num_render_channels));
+  RenderSignalAnalyzer render_signal_analyzer(config);
+  Random random_generator(42U);
+  Aec3Fft fft;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> Y2(num_capture_channels);
+  std::vector<std::array<float, kFftLengthBy2Plus1>> E2_refined(
+      num_capture_channels);
+  std::array<float, kFftLengthBy2Plus1> E2_coarse;
+  AecState aec_state(config, num_capture_channels);
+  x_old.fill(0.f);
+  for (auto& Y2_ch : Y2) {
+    Y2_ch.fill(0.f);
+  }
+  for (auto& E2_refined_ch : E2_refined) {
+    E2_refined_ch.fill(0.f);
+  }
+  E2_coarse.fill(0.f);
+
+  std::vector<std::vector<std::unique_ptr<DelayBuffer<float>>>> delay_buffer(
+      num_capture_channels);
+  for (size_t capture_ch = 0; capture_ch < num_capture_channels; ++capture_ch) {
+    delay_buffer[capture_ch].resize(num_render_channels);
+    for (size_t render_ch = 0; render_ch < num_render_channels; ++render_ch) {
+      delay_buffer[capture_ch][render_ch] =
+          std::make_unique<DelayBuffer<float>>(delay_samples);
+    }
+  }
+
+  // [B,A] = butter(2,100/8000,'high')
+  constexpr CascadedBiQuadFilter::BiQuadCoefficients
+      kHighPassFilterCoefficients = {{0.97261f, -1.94523f, 0.97261f},
+                                     {-1.94448f, 0.94598f}};
+  std::vector<std::unique_ptr<CascadedBiQuadFilter>> x_hp_filter(
+      num_render_channels);
+  for (size_t ch = 0; ch < num_render_channels; ++ch) {
+    x_hp_filter[ch] =
+        std::make_unique<CascadedBiQuadFilter>(kHighPassFilterCoefficients, 1);
+  }
+  std::vector<std::unique_ptr<CascadedBiQuadFilter>> y_hp_filter(
+      num_capture_channels);
+  for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+    y_hp_filter[ch] =
+        std::make_unique<CascadedBiQuadFilter>(kHighPassFilterCoefficients, 1);
+  }
+
+  for (int k = 0; k < num_blocks_to_process; ++k) {
+    for (size_t render_ch = 0; render_ch < num_render_channels; ++render_ch) {
+      RandomizeSampleVector(&random_generator, x[0][render_ch]);
+    }
+    if (uncorrelated_inputs) {
+      for (size_t capture_ch = 0; capture_ch < num_capture_channels;
+           ++capture_ch) {
+        RandomizeSampleVector(&random_generator, y[capture_ch]);
+      }
+    } else {
+      for (size_t capture_ch = 0; capture_ch < num_capture_channels;
+           ++capture_ch) {
+        for (size_t render_ch = 0; render_ch < num_render_channels;
+             ++render_ch) {
+          std::array<float, kBlockSize> y_channel;
+          delay_buffer[capture_ch][render_ch]->Delay(x[0][render_ch],
+                                                     y_channel);
+          for (size_t k = 0; k < y.size(); ++k) {
+            y[capture_ch][k] += y_channel[k] / num_render_channels;
+          }
+        }
+      }
+    }
+    for (size_t ch = 0; ch < num_render_channels; ++ch) {
+      x_hp_filter[ch]->Process(x[0][ch]);
+    }
+    for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+      y_hp_filter[ch]->Process(y[ch]);
+    }
+
+    render_delay_buffer->Insert(x);
+    if (k == 0) {
+      render_delay_buffer->Reset();
+    }
+    render_delay_buffer->PrepareCaptureProcessing();
+    render_signal_analyzer.Update(*render_delay_buffer->GetRenderBuffer(),
+                                  aec_state.MinDirectPathFilterDelay());
+
+    // Handle echo path changes.
+    if (std::find(blocks_with_echo_path_changes.begin(),
+                  blocks_with_echo_path_changes.end(),
+                  k) != blocks_with_echo_path_changes.end()) {
+      subtractor.HandleEchoPathChange(EchoPathVariability(
+          true, EchoPathVariability::DelayAdjustment::kNewDetectedDelay,
+          false));
+    }
+    subtractor.Process(*render_delay_buffer->GetRenderBuffer(), y,
+                       render_signal_analyzer, aec_state, output);
+
+    aec_state.HandleEchoPathChange(EchoPathVariability(
+        false, EchoPathVariability::DelayAdjustment::kNone, false));
+    aec_state.Update(delay_estimate, subtractor.FilterFrequencyResponses(),
+                     subtractor.FilterImpulseResponses(),
+                     *render_delay_buffer->GetRenderBuffer(), E2_refined, Y2,
+                     output);
+  }
+
+  std::vector<float> results(num_capture_channels);
+  for (size_t ch = 0; ch < num_capture_channels; ++ch) {
+    const float output_power = std::inner_product(
+        output[ch].e_refined.begin(), output[ch].e_refined.end(),
+        output[ch].e_refined.begin(), 0.f);
+    const float y_power =
+        std::inner_product(y[ch].begin(), y[ch].end(), y[ch].begin(), 0.f);
+    if (y_power == 0.f) {
+      ADD_FAILURE();
+      results[ch] = -1.f;
+    }
+    results[ch] = output_power / y_power;
+  }
+  return results;
+}
+
+std::string ProduceDebugText(size_t num_render_channels,
+                             size_t num_capture_channels,
+                             size_t delay,
+                             int filter_length_blocks) {
+  rtc::StringBuilder ss;
+  ss << "delay: " << delay << ", ";
+  ss << "filter_length_blocks:" << filter_length_blocks << ", ";
+  ss << "num_render_channels:" << num_render_channels << ", ";
+  ss << "num_capture_channels:" << num_capture_channels;
+  return ss.Release();
+}
+
+}  // namespace
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+// Verifies that the check for non data dumper works.
+TEST(SubtractorDeathTest, NullDataDumper) {
+  EXPECT_DEATH(
+      Subtractor(EchoCanceller3Config(), 1, 1, nullptr, DetectOptimization()),
+      "");
+}
+
+// Verifies the check for the capture signal size.
+TEST(Subtractor, WrongCaptureSize) {
+  ApmDataDumper data_dumper(42);
+  EchoCanceller3Config config;
+  Subtractor subtractor(config, 1, 1, &data_dumper, DetectOptimization());
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+      RenderDelayBuffer::Create(config, 48000, 1));
+  RenderSignalAnalyzer render_signal_analyzer(config);
+  std::vector<std::vector<float>> y(1, std::vector<float>(kBlockSize - 1, 0.f));
+  std::array<SubtractorOutput, 1> output;
+
+  EXPECT_DEATH(
+      subtractor.Process(*render_delay_buffer->GetRenderBuffer(), y,
+                         render_signal_analyzer, AecState(config, 1), output),
+      "");
+}
+
+#endif
+
+// Verifies that the subtractor is able to converge on correlated data.
+TEST(Subtractor, Convergence) {
+  std::vector<int> blocks_with_echo_path_changes;
+  for (size_t filter_length_blocks : {12, 20, 30}) {
+    for (size_t delay_samples : {0, 64, 150, 200, 301}) {
+      SCOPED_TRACE(ProduceDebugText(1, 1, delay_samples, filter_length_blocks));
+      std::vector<float> echo_to_nearend_powers = RunSubtractorTest(
+          1, 1, 2500, delay_samples, filter_length_blocks, filter_length_blocks,
+          false, blocks_with_echo_path_changes);
+
+      for (float echo_to_nearend_power : echo_to_nearend_powers) {
+        EXPECT_GT(0.1f, echo_to_nearend_power);
+      }
+    }
+  }
+}
+
+// Verifies that the subtractor is able to handle the case when the refined
+// filter is longer than the coarse filter.
+TEST(Subtractor, RefinedFilterLongerThanCoarseFilter) {
+  std::vector<int> blocks_with_echo_path_changes;
+  std::vector<float> echo_to_nearend_powers = RunSubtractorTest(
+      1, 1, 400, 64, 20, 15, false, blocks_with_echo_path_changes);
+  for (float echo_to_nearend_power : echo_to_nearend_powers) {
+    EXPECT_GT(0.5f, echo_to_nearend_power);
+  }
+}
+
+// Verifies that the subtractor is able to handle the case when the coarse
+// filter is longer than the refined filter.
+TEST(Subtractor, CoarseFilterLongerThanRefinedFilter) {
+  std::vector<int> blocks_with_echo_path_changes;
+  std::vector<float> echo_to_nearend_powers = RunSubtractorTest(
+      1, 1, 400, 64, 15, 20, false, blocks_with_echo_path_changes);
+  for (float echo_to_nearend_power : echo_to_nearend_powers) {
+    EXPECT_GT(0.5f, echo_to_nearend_power);
+  }
+}
+
+// Verifies that the subtractor does not converge on uncorrelated signals.
+TEST(Subtractor, NonConvergenceOnUncorrelatedSignals) {
+  std::vector<int> blocks_with_echo_path_changes;
+  for (size_t filter_length_blocks : {12, 20, 30}) {
+    for (size_t delay_samples : {0, 64, 150, 200, 301}) {
+      SCOPED_TRACE(ProduceDebugText(1, 1, delay_samples, filter_length_blocks));
+
+      std::vector<float> echo_to_nearend_powers = RunSubtractorTest(
+          1, 1, 3000, delay_samples, filter_length_blocks, filter_length_blocks,
+          true, blocks_with_echo_path_changes);
+      for (float echo_to_nearend_power : echo_to_nearend_powers) {
+        EXPECT_NEAR(1.f, echo_to_nearend_power, 0.1);
+      }
+    }
+  }
+}
+
+class SubtractorMultiChannelUpToEightRender
+    : public ::testing::Test,
+      public ::testing::WithParamInterface<std::tuple<size_t, size_t>> {};
+
+#if defined(NDEBUG)
+INSTANTIATE_TEST_SUITE_P(NonDebugMultiChannel,
+                         SubtractorMultiChannelUpToEightRender,
+                         ::testing::Combine(::testing::Values(1, 2, 8),
+                                            ::testing::Values(1, 2, 4)));
+#else
+INSTANTIATE_TEST_SUITE_P(DebugMultiChannel,
+                         SubtractorMultiChannelUpToEightRender,
+                         ::testing::Combine(::testing::Values(1, 2),
+                                            ::testing::Values(1, 2)));
+#endif
+
+// Verifies that the subtractor is able to converge on correlated data.
+TEST_P(SubtractorMultiChannelUpToEightRender, Convergence) {
+  const size_t num_render_channels = std::get<0>(GetParam());
+  const size_t num_capture_channels = std::get<1>(GetParam());
+
+  std::vector<int> blocks_with_echo_path_changes;
+  size_t num_blocks_to_process = 2500 * num_render_channels;
+  std::vector<float> echo_to_nearend_powers = RunSubtractorTest(
+      num_render_channels, num_capture_channels, num_blocks_to_process, 64, 20,
+      20, false, blocks_with_echo_path_changes);
+
+  for (float echo_to_nearend_power : echo_to_nearend_powers) {
+    EXPECT_GT(0.1f, echo_to_nearend_power);
+  }
+}
+
+class SubtractorMultiChannelUpToFourRender
+    : public ::testing::Test,
+      public ::testing::WithParamInterface<std::tuple<size_t, size_t>> {};
+
+#if defined(NDEBUG)
+INSTANTIATE_TEST_SUITE_P(NonDebugMultiChannel,
+                         SubtractorMultiChannelUpToFourRender,
+                         ::testing::Combine(::testing::Values(1, 2, 4),
+                                            ::testing::Values(1, 2, 4)));
+#else
+INSTANTIATE_TEST_SUITE_P(DebugMultiChannel,
+                         SubtractorMultiChannelUpToFourRender,
+                         ::testing::Combine(::testing::Values(1, 2),
+                                            ::testing::Values(1, 2)));
+#endif
+
+// Verifies that the subtractor does not converge on uncorrelated signals.
+TEST_P(SubtractorMultiChannelUpToFourRender,
+       NonConvergenceOnUncorrelatedSignals) {
+  const size_t num_render_channels = std::get<0>(GetParam());
+  const size_t num_capture_channels = std::get<1>(GetParam());
+
+  std::vector<int> blocks_with_echo_path_changes;
+  size_t num_blocks_to_process = 5000 * num_render_channels;
+  std::vector<float> echo_to_nearend_powers = RunSubtractorTest(
+      num_render_channels, num_capture_channels, num_blocks_to_process, 64, 20,
+      20, true, blocks_with_echo_path_changes);
+  for (float echo_to_nearend_power : echo_to_nearend_powers) {
+    EXPECT_LT(.8f, echo_to_nearend_power);
+    EXPECT_NEAR(1.f, echo_to_nearend_power, 0.25f);
+  }
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_filter.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_filter.cc
new file mode 100644
index 0000000..8a813d9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_filter.cc
@@ -0,0 +1,179 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/suppression_filter.h"
+
+#include <algorithm>
+#include <cmath>
+#include <cstring>
+#include <functional>
+#include <iterator>
+
+#include "modules/audio_processing/aec3/vector_math.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_minmax.h"
+
+namespace webrtc {
+namespace {
+
+// Hanning window from Matlab command win = sqrt(hanning(128)).
+const float kSqrtHanning[kFftLength] = {
+    0.00000000000000f, 0.02454122852291f, 0.04906767432742f, 0.07356456359967f,
+    0.09801714032956f, 0.12241067519922f, 0.14673047445536f, 0.17096188876030f,
+    0.19509032201613f, 0.21910124015687f, 0.24298017990326f, 0.26671275747490f,
+    0.29028467725446f, 0.31368174039889f, 0.33688985339222f, 0.35989503653499f,
+    0.38268343236509f, 0.40524131400499f, 0.42755509343028f, 0.44961132965461f,
+    0.47139673682600f, 0.49289819222978f, 0.51410274419322f, 0.53499761988710f,
+    0.55557023301960f, 0.57580819141785f, 0.59569930449243f, 0.61523159058063f,
+    0.63439328416365f, 0.65317284295378f, 0.67155895484702f, 0.68954054473707f,
+    0.70710678118655f, 0.72424708295147f, 0.74095112535496f, 0.75720884650648f,
+    0.77301045336274f, 0.78834642762661f, 0.80320753148064f, 0.81758481315158f,
+    0.83146961230255f, 0.84485356524971f, 0.85772861000027f, 0.87008699110871f,
+    0.88192126434835f, 0.89322430119552f, 0.90398929312344f, 0.91420975570353f,
+    0.92387953251129f, 0.93299279883474f, 0.94154406518302f, 0.94952818059304f,
+    0.95694033573221f, 0.96377606579544f, 0.97003125319454f, 0.97570213003853f,
+    0.98078528040323f, 0.98527764238894f, 0.98917650996478f, 0.99247953459871f,
+    0.99518472667220f, 0.99729045667869f, 0.99879545620517f, 0.99969881869620f,
+    1.00000000000000f, 0.99969881869620f, 0.99879545620517f, 0.99729045667869f,
+    0.99518472667220f, 0.99247953459871f, 0.98917650996478f, 0.98527764238894f,
+    0.98078528040323f, 0.97570213003853f, 0.97003125319454f, 0.96377606579544f,
+    0.95694033573221f, 0.94952818059304f, 0.94154406518302f, 0.93299279883474f,
+    0.92387953251129f, 0.91420975570353f, 0.90398929312344f, 0.89322430119552f,
+    0.88192126434835f, 0.87008699110871f, 0.85772861000027f, 0.84485356524971f,
+    0.83146961230255f, 0.81758481315158f, 0.80320753148064f, 0.78834642762661f,
+    0.77301045336274f, 0.75720884650648f, 0.74095112535496f, 0.72424708295147f,
+    0.70710678118655f, 0.68954054473707f, 0.67155895484702f, 0.65317284295378f,
+    0.63439328416365f, 0.61523159058063f, 0.59569930449243f, 0.57580819141785f,
+    0.55557023301960f, 0.53499761988710f, 0.51410274419322f, 0.49289819222978f,
+    0.47139673682600f, 0.44961132965461f, 0.42755509343028f, 0.40524131400499f,
+    0.38268343236509f, 0.35989503653499f, 0.33688985339222f, 0.31368174039889f,
+    0.29028467725446f, 0.26671275747490f, 0.24298017990326f, 0.21910124015687f,
+    0.19509032201613f, 0.17096188876030f, 0.14673047445536f, 0.12241067519922f,
+    0.09801714032956f, 0.07356456359967f, 0.04906767432742f, 0.02454122852291f};
+
+}  // namespace
+
+SuppressionFilter::SuppressionFilter(Aec3Optimization optimization,
+                                     int sample_rate_hz,
+                                     size_t num_capture_channels)
+    : optimization_(optimization),
+      sample_rate_hz_(sample_rate_hz),
+      num_capture_channels_(num_capture_channels),
+      fft_(),
+      e_output_old_(NumBandsForRate(sample_rate_hz_),
+                    std::vector<std::array<float, kFftLengthBy2>>(
+                        num_capture_channels_)) {
+  RTC_DCHECK(ValidFullBandRate(sample_rate_hz_));
+  for (size_t b = 0; b < e_output_old_.size(); ++b) {
+    for (size_t ch = 0; ch < e_output_old_[b].size(); ++ch) {
+      e_output_old_[b][ch].fill(0.f);
+    }
+  }
+}
+
+SuppressionFilter::~SuppressionFilter() = default;
+
+void SuppressionFilter::ApplyGain(
+    rtc::ArrayView<const FftData> comfort_noise,
+    rtc::ArrayView<const FftData> comfort_noise_high_band,
+    const std::array<float, kFftLengthBy2Plus1>& suppression_gain,
+    float high_bands_gain,
+    rtc::ArrayView<const FftData> E_lowest_band,
+    std::vector<std::vector<std::vector<float>>>* e) {
+  RTC_DCHECK(e);
+  RTC_DCHECK_EQ(e->size(), NumBandsForRate(sample_rate_hz_));
+
+  // Comfort noise gain is sqrt(1-g^2), where g is the suppression gain.
+  std::array<float, kFftLengthBy2Plus1> noise_gain;
+  for (size_t i = 0; i < kFftLengthBy2Plus1; ++i) {
+    noise_gain[i] = 1.f - suppression_gain[i] * suppression_gain[i];
+  }
+  aec3::VectorMath(optimization_).Sqrt(noise_gain);
+
+  const float high_bands_noise_scaling =
+      0.4f * std::sqrt(1.f - high_bands_gain * high_bands_gain);
+
+  for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+    FftData E;
+
+    // Analysis filterbank.
+    E.Assign(E_lowest_band[ch]);
+
+    for (size_t i = 0; i < kFftLengthBy2Plus1; ++i) {
+      // Apply suppression gains.
+      E.re[i] *= suppression_gain[i];
+      E.im[i] *= suppression_gain[i];
+
+      // Scale and add the comfort noise.
+      E.re[i] += noise_gain[i] * comfort_noise[ch].re[i];
+      E.im[i] += noise_gain[i] * comfort_noise[ch].im[i];
+    }
+
+    // Synthesis filterbank.
+    std::array<float, kFftLength> e_extended;
+    constexpr float kIfftNormalization = 2.f / kFftLength;
+    fft_.Ifft(E, &e_extended);
+
+    auto& e0 = (*e)[0][ch];
+    auto& e0_old = e_output_old_[0][ch];
+
+    // Window and add the first half of e_extended with the second half of
+    // e_extended from the previous block.
+    for (size_t i = 0; i < kFftLengthBy2; ++i) {
+      e0[i] = e0_old[i] * kSqrtHanning[kFftLengthBy2 + i];
+      e0[i] += e_extended[i] * kSqrtHanning[i];
+      e0[i] *= kIfftNormalization;
+    }
+
+    // The second half of e_extended is stored for the succeeding frame.
+    std::copy(e_extended.begin() + kFftLengthBy2,
+              e_extended.begin() + kFftLength, std::begin(e0_old));
+
+    // Apply suppression gain to upper bands.
+    for (size_t b = 1; b < e->size(); ++b) {
+      auto& e_band = (*e)[b][ch];
+      for (size_t i = 0; i < kFftLengthBy2; ++i) {
+        e_band[i] *= high_bands_gain;
+      }
+    }
+
+    // Add comfort noise to band 1.
+    if (e->size() > 1) {
+      E.Assign(comfort_noise_high_band[ch]);
+      std::array<float, kFftLength> time_domain_high_band_noise;
+      fft_.Ifft(E, &time_domain_high_band_noise);
+
+      auto& e1 = (*e)[1][ch];
+      const float gain = high_bands_noise_scaling * kIfftNormalization;
+      for (size_t i = 0; i < kFftLengthBy2; ++i) {
+        e1[i] += time_domain_high_band_noise[i] * gain;
+      }
+    }
+
+    // Delay upper bands to match the delay of the filter bank.
+    for (size_t b = 1; b < e->size(); ++b) {
+      auto& e_band = (*e)[b][ch];
+      auto& e_band_old = e_output_old_[b][ch];
+      for (size_t i = 0; i < kFftLengthBy2; ++i) {
+        std::swap(e_band[i], e_band_old[i]);
+      }
+    }
+
+    // Clamp output of all bands.
+    for (size_t b = 0; b < e->size(); ++b) {
+      auto& e_band = (*e)[b][ch];
+      for (size_t i = 0; i < kFftLengthBy2; ++i) {
+        e_band[i] = rtc::SafeClamp(e_band[i], -32768.f, 32767.f);
+      }
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_filter.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_filter.h
new file mode 100644
index 0000000..dcf2292
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_filter.h
@@ -0,0 +1,48 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_SUPPRESSION_FILTER_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_SUPPRESSION_FILTER_H_
+
+#include <array>
+#include <vector>
+
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/aec3_fft.h"
+#include "modules/audio_processing/aec3/fft_data.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+class SuppressionFilter {
+ public:
+  SuppressionFilter(Aec3Optimization optimization,
+                    int sample_rate_hz,
+                    size_t num_capture_channels_);
+  ~SuppressionFilter();
+  void ApplyGain(rtc::ArrayView<const FftData> comfort_noise,
+                 rtc::ArrayView<const FftData> comfort_noise_high_bands,
+                 const std::array<float, kFftLengthBy2Plus1>& suppression_gain,
+                 float high_bands_gain,
+                 rtc::ArrayView<const FftData> E_lowest_band,
+                 std::vector<std::vector<std::vector<float>>>* e);
+
+ private:
+  const Aec3Optimization optimization_;
+  const int sample_rate_hz_;
+  const size_t num_capture_channels_;
+  const Aec3Fft fft_;
+  std::vector<std::vector<std::array<float, kFftLengthBy2>>> e_output_old_;
+  RTC_DISALLOW_COPY_AND_ASSIGN(SuppressionFilter);
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_SUPPRESSION_FILTER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_filter_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_filter_unittest.cc
new file mode 100644
index 0000000..a160bec
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_filter_unittest.cc
@@ -0,0 +1,249 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/suppression_filter.h"
+
+#include <math.h>
+
+#include <algorithm>
+#include <cmath>
+#include <numeric>
+
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace {
+
+constexpr float kPi = 3.141592f;
+
+void ProduceSinusoid(int sample_rate_hz,
+                     float sinusoidal_frequency_hz,
+                     size_t* sample_counter,
+                     std::vector<std::vector<std::vector<float>>>* x) {
+  // Produce a sinusoid of the specified frequency.
+  for (size_t k = *sample_counter, j = 0; k < (*sample_counter + kBlockSize);
+       ++k, ++j) {
+    for (size_t channel = 0; channel < (*x)[0].size(); ++channel) {
+      (*x)[0][channel][j] =
+          32767.f *
+          std::sin(2.f * kPi * sinusoidal_frequency_hz * k / sample_rate_hz);
+    }
+  }
+  *sample_counter = *sample_counter + kBlockSize;
+
+  for (size_t band = 1; band < x->size(); ++band) {
+    for (size_t channel = 0; channel < (*x)[band].size(); ++channel) {
+      std::fill((*x)[band][channel].begin(), (*x)[band][channel].end(), 0.f);
+    }
+  }
+}
+
+}  // namespace
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+// Verifies the check for null suppressor output.
+TEST(SuppressionFilterDeathTest, NullOutput) {
+  std::vector<FftData> cn(1);
+  std::vector<FftData> cn_high_bands(1);
+  std::vector<FftData> E(1);
+  std::array<float, kFftLengthBy2Plus1> gain;
+
+  EXPECT_DEATH(SuppressionFilter(Aec3Optimization::kNone, 16000, 1)
+                   .ApplyGain(cn, cn_high_bands, gain, 1.0f, E, nullptr),
+               "");
+}
+
+// Verifies the check for allowed sample rate.
+TEST(SuppressionFilterDeathTest, ProperSampleRate) {
+  EXPECT_DEATH(SuppressionFilter(Aec3Optimization::kNone, 16001, 1), "");
+}
+
+#endif
+
+// Verifies that no comfort noise is added when the gain is 1.
+TEST(SuppressionFilter, ComfortNoiseInUnityGain) {
+  SuppressionFilter filter(Aec3Optimization::kNone, 48000, 1);
+  std::vector<FftData> cn(1);
+  std::vector<FftData> cn_high_bands(1);
+  std::array<float, kFftLengthBy2Plus1> gain;
+  std::array<float, kFftLengthBy2> e_old_;
+  Aec3Fft fft;
+
+  e_old_.fill(0.f);
+  gain.fill(1.f);
+  cn[0].re.fill(1.f);
+  cn[0].im.fill(1.f);
+  cn_high_bands[0].re.fill(1.f);
+  cn_high_bands[0].im.fill(1.f);
+
+  std::vector<std::vector<std::vector<float>>> e(
+      3,
+      std::vector<std::vector<float>>(1, std::vector<float>(kBlockSize, 0.f)));
+  std::vector<std::vector<std::vector<float>>> e_ref = e;
+
+  std::vector<FftData> E(1);
+  fft.PaddedFft(e[0][0], e_old_, Aec3Fft::Window::kSqrtHanning, &E[0]);
+  std::copy(e[0][0].begin(), e[0][0].end(), e_old_.begin());
+
+  filter.ApplyGain(cn, cn_high_bands, gain, 1.f, E, &e);
+
+  for (size_t band = 0; band < e.size(); ++band) {
+    for (size_t channel = 0; channel < e[band].size(); ++channel) {
+      for (size_t sample = 0; sample < e[band][channel].size(); ++sample) {
+        EXPECT_EQ(e_ref[band][channel][sample], e[band][channel][sample]);
+      }
+    }
+  }
+}
+
+// Verifies that the suppressor is able to suppress a signal.
+TEST(SuppressionFilter, SignalSuppression) {
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+  constexpr size_t kNumChannels = 1;
+
+  SuppressionFilter filter(Aec3Optimization::kNone, kSampleRateHz, 1);
+  std::vector<FftData> cn(1);
+  std::vector<FftData> cn_high_bands(1);
+  std::array<float, kFftLengthBy2> e_old_;
+  Aec3Fft fft;
+  std::array<float, kFftLengthBy2Plus1> gain;
+  std::vector<std::vector<std::vector<float>>> e(
+      kNumBands, std::vector<std::vector<float>>(
+                     kNumChannels, std::vector<float>(kBlockSize, 0.f)));
+  e_old_.fill(0.f);
+
+  gain.fill(1.f);
+  std::for_each(gain.begin() + 10, gain.end(), [](float& a) { a = 0.f; });
+
+  cn[0].re.fill(0.f);
+  cn[0].im.fill(0.f);
+  cn_high_bands[0].re.fill(0.f);
+  cn_high_bands[0].im.fill(0.f);
+
+  size_t sample_counter = 0;
+
+  float e0_input = 0.f;
+  float e0_output = 0.f;
+  for (size_t k = 0; k < 100; ++k) {
+    ProduceSinusoid(16000, 16000 * 40 / kFftLengthBy2 / 2, &sample_counter, &e);
+    e0_input = std::inner_product(e[0][0].begin(), e[0][0].end(),
+                                  e[0][0].begin(), e0_input);
+
+    std::vector<FftData> E(1);
+    fft.PaddedFft(e[0][0], e_old_, Aec3Fft::Window::kSqrtHanning, &E[0]);
+    std::copy(e[0][0].begin(), e[0][0].end(), e_old_.begin());
+
+    filter.ApplyGain(cn, cn_high_bands, gain, 1.f, E, &e);
+    e0_output = std::inner_product(e[0][0].begin(), e[0][0].end(),
+                                   e[0][0].begin(), e0_output);
+  }
+
+  EXPECT_LT(e0_output, e0_input / 1000.f);
+}
+
+// Verifies that the suppressor is able to pass through a desired signal while
+// applying suppressing for some frequencies.
+TEST(SuppressionFilter, SignalTransparency) {
+  constexpr size_t kNumChannels = 1;
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+
+  SuppressionFilter filter(Aec3Optimization::kNone, kSampleRateHz, 1);
+  std::vector<FftData> cn(1);
+  std::array<float, kFftLengthBy2> e_old_;
+  Aec3Fft fft;
+  std::vector<FftData> cn_high_bands(1);
+  std::array<float, kFftLengthBy2Plus1> gain;
+  std::vector<std::vector<std::vector<float>>> e(
+      kNumBands, std::vector<std::vector<float>>(
+                     kNumChannels, std::vector<float>(kBlockSize, 0.f)));
+  e_old_.fill(0.f);
+  gain.fill(1.f);
+  std::for_each(gain.begin() + 30, gain.end(), [](float& a) { a = 0.f; });
+
+  cn[0].re.fill(0.f);
+  cn[0].im.fill(0.f);
+  cn_high_bands[0].re.fill(0.f);
+  cn_high_bands[0].im.fill(0.f);
+
+  size_t sample_counter = 0;
+
+  float e0_input = 0.f;
+  float e0_output = 0.f;
+  for (size_t k = 0; k < 100; ++k) {
+    ProduceSinusoid(16000, 16000 * 10 / kFftLengthBy2 / 2, &sample_counter, &e);
+    e0_input = std::inner_product(e[0][0].begin(), e[0][0].end(),
+                                  e[0][0].begin(), e0_input);
+
+    std::vector<FftData> E(1);
+    fft.PaddedFft(e[0][0], e_old_, Aec3Fft::Window::kSqrtHanning, &E[0]);
+    std::copy(e[0][0].begin(), e[0][0].end(), e_old_.begin());
+
+    filter.ApplyGain(cn, cn_high_bands, gain, 1.f, E, &e);
+    e0_output = std::inner_product(e[0][0].begin(), e[0][0].end(),
+                                   e[0][0].begin(), e0_output);
+  }
+
+  EXPECT_LT(0.9f * e0_input, e0_output);
+}
+
+// Verifies that the suppressor delay.
+TEST(SuppressionFilter, Delay) {
+  constexpr size_t kNumChannels = 1;
+  constexpr int kSampleRateHz = 48000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+
+  SuppressionFilter filter(Aec3Optimization::kNone, kSampleRateHz, 1);
+  std::vector<FftData> cn(1);
+  std::vector<FftData> cn_high_bands(1);
+  std::array<float, kFftLengthBy2> e_old_;
+  Aec3Fft fft;
+  std::array<float, kFftLengthBy2Plus1> gain;
+  std::vector<std::vector<std::vector<float>>> e(
+      kNumBands, std::vector<std::vector<float>>(
+                     kNumChannels, std::vector<float>(kBlockSize, 0.f)));
+
+  gain.fill(1.f);
+
+  cn[0].re.fill(0.f);
+  cn[0].im.fill(0.f);
+  cn_high_bands[0].re.fill(0.f);
+  cn_high_bands[0].im.fill(0.f);
+
+  for (size_t k = 0; k < 100; ++k) {
+    for (size_t band = 0; band < kNumBands; ++band) {
+      for (size_t channel = 0; channel < kNumChannels; ++channel) {
+        for (size_t sample = 0; sample < kBlockSize; ++sample) {
+          e[band][channel][sample] = k * kBlockSize + sample + channel;
+        }
+      }
+    }
+
+    std::vector<FftData> E(1);
+    fft.PaddedFft(e[0][0], e_old_, Aec3Fft::Window::kSqrtHanning, &E[0]);
+    std::copy(e[0][0].begin(), e[0][0].end(), e_old_.begin());
+
+    filter.ApplyGain(cn, cn_high_bands, gain, 1.f, E, &e);
+    if (k > 2) {
+      for (size_t band = 0; band < kNumBands; ++band) {
+        for (size_t channel = 0; channel < kNumChannels; ++channel) {
+          for (size_t sample = 0; sample < kBlockSize; ++sample) {
+            EXPECT_NEAR(k * kBlockSize + sample - kBlockSize + channel,
+                        e[band][channel][sample], 0.01);
+          }
+        }
+      }
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_gain.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_gain.cc
new file mode 100644
index 0000000..5b01c52
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_gain.cc
@@ -0,0 +1,448 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/suppression_gain.h"
+
+#include <math.h>
+#include <stddef.h>
+
+#include <algorithm>
+#include <numeric>
+
+#include "modules/audio_processing/aec3/dominant_nearend_detector.h"
+#include "modules/audio_processing/aec3/moving_average.h"
+#include "modules/audio_processing/aec3/subband_nearend_detector.h"
+#include "modules/audio_processing/aec3/vector_math.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/atomic_ops.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+
+void LimitLowFrequencyGains(std::array<float, kFftLengthBy2Plus1>* gain) {
+  // Limit the low frequency gains to avoid the impact of the high-pass filter
+  // on the lower-frequency gain influencing the overall achieved gain.
+  (*gain)[0] = (*gain)[1] = std::min((*gain)[1], (*gain)[2]);
+}
+
+void LimitHighFrequencyGains(bool conservative_hf_suppression,
+                             std::array<float, kFftLengthBy2Plus1>* gain) {
+  // Limit the high frequency gains to avoid echo leakage due to an imperfect
+  // filter.
+  constexpr size_t kFirstBandToLimit = (64 * 2000) / 8000;
+  const float min_upper_gain = (*gain)[kFirstBandToLimit];
+  std::for_each(
+      gain->begin() + kFirstBandToLimit + 1, gain->end(),
+      [min_upper_gain](float& a) { a = std::min(a, min_upper_gain); });
+  (*gain)[kFftLengthBy2] = (*gain)[kFftLengthBy2Minus1];
+
+  if (conservative_hf_suppression) {
+    // Limits the gain in the frequencies for which the adaptive filter has not
+    // converged.
+    // TODO(peah): Make adaptive to take the actual filter error into account.
+    constexpr size_t kUpperAccurateBandPlus1 = 29;
+
+    constexpr float oneByBandsInSum =
+        1 / static_cast<float>(kUpperAccurateBandPlus1 - 20);
+    const float hf_gain_bound =
+        std::accumulate(gain->begin() + 20,
+                        gain->begin() + kUpperAccurateBandPlus1, 0.f) *
+        oneByBandsInSum;
+
+    std::for_each(
+        gain->begin() + kUpperAccurateBandPlus1, gain->end(),
+        [hf_gain_bound](float& a) { a = std::min(a, hf_gain_bound); });
+  }
+}
+
+// Scales the echo according to assessed audibility at the other end.
+void WeightEchoForAudibility(const EchoCanceller3Config& config,
+                             rtc::ArrayView<const float> echo,
+                             rtc::ArrayView<float> weighted_echo) {
+  RTC_DCHECK_EQ(kFftLengthBy2Plus1, echo.size());
+  RTC_DCHECK_EQ(kFftLengthBy2Plus1, weighted_echo.size());
+
+  auto weigh = [](float threshold, float normalizer, size_t begin, size_t end,
+                  rtc::ArrayView<const float> echo,
+                  rtc::ArrayView<float> weighted_echo) {
+    for (size_t k = begin; k < end; ++k) {
+      if (echo[k] < threshold) {
+        float tmp = (threshold - echo[k]) * normalizer;
+        weighted_echo[k] = echo[k] * std::max(0.f, 1.f - tmp * tmp);
+      } else {
+        weighted_echo[k] = echo[k];
+      }
+    }
+  };
+
+  float threshold = config.echo_audibility.floor_power *
+                    config.echo_audibility.audibility_threshold_lf;
+  float normalizer = 1.f / (threshold - config.echo_audibility.floor_power);
+  weigh(threshold, normalizer, 0, 3, echo, weighted_echo);
+
+  threshold = config.echo_audibility.floor_power *
+              config.echo_audibility.audibility_threshold_mf;
+  normalizer = 1.f / (threshold - config.echo_audibility.floor_power);
+  weigh(threshold, normalizer, 3, 7, echo, weighted_echo);
+
+  threshold = config.echo_audibility.floor_power *
+              config.echo_audibility.audibility_threshold_hf;
+  normalizer = 1.f / (threshold - config.echo_audibility.floor_power);
+  weigh(threshold, normalizer, 7, kFftLengthBy2Plus1, echo, weighted_echo);
+}
+
+}  // namespace
+
+int SuppressionGain::instance_count_ = 0;
+
+float SuppressionGain::UpperBandsGain(
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> echo_spectrum,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+        comfort_noise_spectrum,
+    const absl::optional<int>& narrow_peak_band,
+    bool saturated_echo,
+    const std::vector<std::vector<std::vector<float>>>& render,
+    const std::array<float, kFftLengthBy2Plus1>& low_band_gain) const {
+  RTC_DCHECK_LT(0, render.size());
+  if (render.size() == 1) {
+    return 1.f;
+  }
+  const size_t num_render_channels = render[0].size();
+
+  if (narrow_peak_band &&
+      (*narrow_peak_band > static_cast<int>(kFftLengthBy2Plus1 - 10))) {
+    return 0.001f;
+  }
+
+  constexpr size_t kLowBandGainLimit = kFftLengthBy2 / 2;
+  const float gain_below_8_khz = *std::min_element(
+      low_band_gain.begin() + kLowBandGainLimit, low_band_gain.end());
+
+  // Always attenuate the upper bands when there is saturated echo.
+  if (saturated_echo) {
+    return std::min(0.001f, gain_below_8_khz);
+  }
+
+  // Compute the upper and lower band energies.
+  const auto sum_of_squares = [](float a, float b) { return a + b * b; };
+  float low_band_energy = 0.f;
+  for (size_t ch = 0; ch < num_render_channels; ++ch) {
+    const float channel_energy = std::accumulate(
+        render[0][0].begin(), render[0][0].end(), 0.f, sum_of_squares);
+    low_band_energy = std::max(low_band_energy, channel_energy);
+  }
+  float high_band_energy = 0.f;
+  for (size_t k = 1; k < render.size(); ++k) {
+    for (size_t ch = 0; ch < num_render_channels; ++ch) {
+      const float energy = std::accumulate(
+          render[k][ch].begin(), render[k][ch].end(), 0.f, sum_of_squares);
+      high_band_energy = std::max(high_band_energy, energy);
+    }
+  }
+
+  // If there is more power in the lower frequencies than the upper frequencies,
+  // or if the power in upper frequencies is low, do not bound the gain in the
+  // upper bands.
+  float anti_howling_gain;
+  const float activation_threshold =
+      kBlockSize * config_.suppressor.high_bands_suppression
+                       .anti_howling_activation_threshold;
+  if (high_band_energy < std::max(low_band_energy, activation_threshold)) {
+    anti_howling_gain = 1.f;
+  } else {
+    // In all other cases, bound the gain for upper frequencies.
+    RTC_DCHECK_LE(low_band_energy, high_band_energy);
+    RTC_DCHECK_NE(0.f, high_band_energy);
+    anti_howling_gain =
+        config_.suppressor.high_bands_suppression.anti_howling_gain *
+        sqrtf(low_band_energy / high_band_energy);
+  }
+
+  float gain_bound = 1.f;
+  if (!dominant_nearend_detector_->IsNearendState()) {
+    // Bound the upper gain during significant echo activity.
+    const auto& cfg = config_.suppressor.high_bands_suppression;
+    auto low_frequency_energy = [](rtc::ArrayView<const float> spectrum) {
+      RTC_DCHECK_LE(16, spectrum.size());
+      return std::accumulate(spectrum.begin() + 1, spectrum.begin() + 16, 0.f);
+    };
+    for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+      const float echo_sum = low_frequency_energy(echo_spectrum[ch]);
+      const float noise_sum = low_frequency_energy(comfort_noise_spectrum[ch]);
+      if (echo_sum > cfg.enr_threshold * noise_sum) {
+        gain_bound = cfg.max_gain_during_echo;
+        break;
+      }
+    }
+  }
+
+  // Choose the gain as the minimum of the lower and upper gains.
+  return std::min(std::min(gain_below_8_khz, anti_howling_gain), gain_bound);
+}
+
+// Computes the gain to reduce the echo to a non audible level.
+void SuppressionGain::GainToNoAudibleEcho(
+    const std::array<float, kFftLengthBy2Plus1>& nearend,
+    const std::array<float, kFftLengthBy2Plus1>& echo,
+    const std::array<float, kFftLengthBy2Plus1>& masker,
+    std::array<float, kFftLengthBy2Plus1>* gain) const {
+  const auto& p = dominant_nearend_detector_->IsNearendState() ? nearend_params_
+                                                               : normal_params_;
+  for (size_t k = 0; k < gain->size(); ++k) {
+    float enr = echo[k] / (nearend[k] + 1.f);  // Echo-to-nearend ratio.
+    float emr = echo[k] / (masker[k] + 1.f);   // Echo-to-masker (noise) ratio.
+    float g = 1.0f;
+    if (enr > p.enr_transparent_[k] && emr > p.emr_transparent_[k]) {
+      g = (p.enr_suppress_[k] - enr) /
+          (p.enr_suppress_[k] - p.enr_transparent_[k]);
+      g = std::max(g, p.emr_transparent_[k] / emr);
+    }
+    (*gain)[k] = g;
+  }
+}
+
+// Compute the minimum gain as the attenuating gain to put the signal just
+// above the zero sample values.
+void SuppressionGain::GetMinGain(
+    rtc::ArrayView<const float> weighted_residual_echo,
+    rtc::ArrayView<const float> last_nearend,
+    rtc::ArrayView<const float> last_echo,
+    bool low_noise_render,
+    bool saturated_echo,
+    rtc::ArrayView<float> min_gain) const {
+  if (!saturated_echo) {
+    const float min_echo_power =
+        low_noise_render ? config_.echo_audibility.low_render_limit
+                         : config_.echo_audibility.normal_render_limit;
+
+    for (size_t k = 0; k < min_gain.size(); ++k) {
+      min_gain[k] = weighted_residual_echo[k] > 0.f
+                        ? min_echo_power / weighted_residual_echo[k]
+                        : 1.f;
+      min_gain[k] = std::min(min_gain[k], 1.f);
+    }
+
+    const bool is_nearend_state = dominant_nearend_detector_->IsNearendState();
+    for (size_t k = 0; k < 6; ++k) {
+      const auto& dec = is_nearend_state ? nearend_params_.max_dec_factor_lf
+                                         : normal_params_.max_dec_factor_lf;
+
+      // Make sure the gains of the low frequencies do not decrease too
+      // quickly after strong nearend.
+      if (last_nearend[k] > last_echo[k]) {
+        min_gain[k] = std::max(min_gain[k], last_gain_[k] * dec);
+        min_gain[k] = std::min(min_gain[k], 1.f);
+      }
+    }
+  } else {
+    std::fill(min_gain.begin(), min_gain.end(), 0.f);
+  }
+}
+
+// Compute the maximum gain by limiting the gain increase from the previous
+// gain.
+void SuppressionGain::GetMaxGain(rtc::ArrayView<float> max_gain) const {
+  const auto& inc = dominant_nearend_detector_->IsNearendState()
+                        ? nearend_params_.max_inc_factor
+                        : normal_params_.max_inc_factor;
+  const auto& floor = config_.suppressor.floor_first_increase;
+  for (size_t k = 0; k < max_gain.size(); ++k) {
+    max_gain[k] = std::min(std::max(last_gain_[k] * inc, floor), 1.f);
+  }
+}
+
+void SuppressionGain::LowerBandGain(
+    bool low_noise_render,
+    const AecState& aec_state,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+        suppressor_input,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> residual_echo,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> comfort_noise,
+    bool clock_drift,
+    std::array<float, kFftLengthBy2Plus1>* gain) {
+  gain->fill(1.f);
+  const bool saturated_echo = aec_state.SaturatedEcho();
+  std::array<float, kFftLengthBy2Plus1> max_gain;
+  GetMaxGain(max_gain);
+
+  for (size_t ch = 0; ch < num_capture_channels_; ++ch) {
+    std::array<float, kFftLengthBy2Plus1> G;
+    std::array<float, kFftLengthBy2Plus1> nearend;
+    nearend_smoothers_[ch].Average(suppressor_input[ch], nearend);
+
+    // Weight echo power in terms of audibility.
+    std::array<float, kFftLengthBy2Plus1> weighted_residual_echo;
+    WeightEchoForAudibility(config_, residual_echo[ch], weighted_residual_echo);
+
+    std::array<float, kFftLengthBy2Plus1> min_gain;
+    GetMinGain(weighted_residual_echo, last_nearend_[ch], last_echo_[ch],
+               low_noise_render, saturated_echo, min_gain);
+
+    GainToNoAudibleEcho(nearend, weighted_residual_echo, comfort_noise[0], &G);
+
+    // Clamp gains.
+    for (size_t k = 0; k < gain->size(); ++k) {
+      G[k] = std::max(std::min(G[k], max_gain[k]), min_gain[k]);
+      (*gain)[k] = std::min((*gain)[k], G[k]);
+    }
+
+    // Store data required for the gain computation of the next block.
+    std::copy(nearend.begin(), nearend.end(), last_nearend_[ch].begin());
+    std::copy(weighted_residual_echo.begin(), weighted_residual_echo.end(),
+              last_echo_[ch].begin());
+  }
+
+  LimitLowFrequencyGains(gain);
+  // Use conservative high-frequency gains during clock-drift or when not in
+  // dominant nearend.
+  if (!dominant_nearend_detector_->IsNearendState() || clock_drift ||
+      config_.suppressor.conservative_hf_suppression) {
+    LimitHighFrequencyGains(config_.suppressor.conservative_hf_suppression,
+                            gain);
+  }
+
+  // Store computed gains.
+  std::copy(gain->begin(), gain->end(), last_gain_.begin());
+
+  // Transform gains to amplitude domain.
+  aec3::VectorMath(optimization_).Sqrt(*gain);
+}
+
+SuppressionGain::SuppressionGain(const EchoCanceller3Config& config,
+                                 Aec3Optimization optimization,
+                                 int sample_rate_hz,
+                                 size_t num_capture_channels)
+    : data_dumper_(
+          new ApmDataDumper(rtc::AtomicOps::Increment(&instance_count_))),
+      optimization_(optimization),
+      config_(config),
+      num_capture_channels_(num_capture_channels),
+      state_change_duration_blocks_(
+          static_cast<int>(config_.filter.config_change_duration_blocks)),
+      last_nearend_(num_capture_channels_, {0}),
+      last_echo_(num_capture_channels_, {0}),
+      nearend_smoothers_(
+          num_capture_channels_,
+          aec3::MovingAverage(kFftLengthBy2Plus1,
+                              config.suppressor.nearend_average_blocks)),
+      nearend_params_(config_.suppressor.nearend_tuning),
+      normal_params_(config_.suppressor.normal_tuning) {
+  RTC_DCHECK_LT(0, state_change_duration_blocks_);
+  last_gain_.fill(1.f);
+  if (config_.suppressor.use_subband_nearend_detection) {
+    dominant_nearend_detector_ = std::make_unique<SubbandNearendDetector>(
+        config_.suppressor.subband_nearend_detection, num_capture_channels_);
+  } else {
+    dominant_nearend_detector_ = std::make_unique<DominantNearendDetector>(
+        config_.suppressor.dominant_nearend_detection, num_capture_channels_);
+  }
+  RTC_DCHECK(dominant_nearend_detector_);
+}
+
+SuppressionGain::~SuppressionGain() = default;
+
+void SuppressionGain::GetGain(
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+        nearend_spectrum,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> echo_spectrum,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+        residual_echo_spectrum,
+    rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+        comfort_noise_spectrum,
+    const RenderSignalAnalyzer& render_signal_analyzer,
+    const AecState& aec_state,
+    const std::vector<std::vector<std::vector<float>>>& render,
+    bool clock_drift,
+    float* high_bands_gain,
+    std::array<float, kFftLengthBy2Plus1>* low_band_gain) {
+  RTC_DCHECK(high_bands_gain);
+  RTC_DCHECK(low_band_gain);
+
+  // Update the nearend state selection.
+  dominant_nearend_detector_->Update(nearend_spectrum, residual_echo_spectrum,
+                                     comfort_noise_spectrum, initial_state_);
+
+  // Compute gain for the lower band.
+  bool low_noise_render = low_render_detector_.Detect(render);
+  LowerBandGain(low_noise_render, aec_state, nearend_spectrum,
+                residual_echo_spectrum, comfort_noise_spectrum, clock_drift,
+                low_band_gain);
+
+  // Compute the gain for the upper bands.
+  const absl::optional<int> narrow_peak_band =
+      render_signal_analyzer.NarrowPeakBand();
+
+  *high_bands_gain =
+      UpperBandsGain(echo_spectrum, comfort_noise_spectrum, narrow_peak_band,
+                     aec_state.SaturatedEcho(), render, *low_band_gain);
+}
+
+void SuppressionGain::SetInitialState(bool state) {
+  initial_state_ = state;
+  if (state) {
+    initial_state_change_counter_ = state_change_duration_blocks_;
+  } else {
+    initial_state_change_counter_ = 0;
+  }
+}
+
+// Detects when the render signal can be considered to have low power and
+// consist of stationary noise.
+bool SuppressionGain::LowNoiseRenderDetector::Detect(
+    const std::vector<std::vector<std::vector<float>>>& render) {
+  float x2_sum = 0.f;
+  float x2_max = 0.f;
+  for (const auto& x_ch : render[0]) {
+    for (const auto& x_k : x_ch) {
+      const float x2 = x_k * x_k;
+      x2_sum += x2;
+      x2_max = std::max(x2_max, x2);
+    }
+  }
+  const size_t num_render_channels = render[0].size();
+  x2_sum = x2_sum / num_render_channels;
+  ;
+
+  constexpr float kThreshold = 50.f * 50.f * 64.f;
+  const bool low_noise_render =
+      average_power_ < kThreshold && x2_max < 3 * average_power_;
+  average_power_ = average_power_ * 0.9f + x2_sum * 0.1f;
+  return low_noise_render;
+}
+
+SuppressionGain::GainParameters::GainParameters(
+    const EchoCanceller3Config::Suppressor::Tuning& tuning)
+    : max_inc_factor(tuning.max_inc_factor),
+      max_dec_factor_lf(tuning.max_dec_factor_lf) {
+  // Compute per-band masking thresholds.
+  constexpr size_t kLastLfBand = 5;
+  constexpr size_t kFirstHfBand = 8;
+  RTC_DCHECK_LT(kLastLfBand, kFirstHfBand);
+  auto& lf = tuning.mask_lf;
+  auto& hf = tuning.mask_hf;
+  RTC_DCHECK_LT(lf.enr_transparent, lf.enr_suppress);
+  RTC_DCHECK_LT(hf.enr_transparent, hf.enr_suppress);
+  for (size_t k = 0; k < kFftLengthBy2Plus1; k++) {
+    float a;
+    if (k <= kLastLfBand) {
+      a = 0.f;
+    } else if (k < kFirstHfBand) {
+      a = (k - kLastLfBand) / static_cast<float>(kFirstHfBand - kLastLfBand);
+    } else {
+      a = 1.f;
+    }
+    enr_transparent_[k] = (1 - a) * lf.enr_transparent + a * hf.enr_transparent;
+    enr_suppress_[k] = (1 - a) * lf.enr_suppress + a * hf.enr_suppress;
+    emr_transparent_[k] = (1 - a) * lf.emr_transparent + a * hf.emr_transparent;
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_gain.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_gain.h
new file mode 100644
index 0000000..d049bae
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_gain.h
@@ -0,0 +1,136 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_SUPPRESSION_GAIN_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_SUPPRESSION_GAIN_H_
+
+#include <array>
+#include <memory>
+#include <vector>
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "modules/audio_processing/aec3/aec_state.h"
+#include "modules/audio_processing/aec3/fft_data.h"
+#include "modules/audio_processing/aec3/moving_average.h"
+#include "modules/audio_processing/aec3/nearend_detector.h"
+#include "modules/audio_processing/aec3/render_signal_analyzer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+class SuppressionGain {
+ public:
+  SuppressionGain(const EchoCanceller3Config& config,
+                  Aec3Optimization optimization,
+                  int sample_rate_hz,
+                  size_t num_capture_channels);
+  ~SuppressionGain();
+  void GetGain(
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+          nearend_spectrum,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> echo_spectrum,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+          residual_echo_spectrum,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+          comfort_noise_spectrum,
+      const RenderSignalAnalyzer& render_signal_analyzer,
+      const AecState& aec_state,
+      const std::vector<std::vector<std::vector<float>>>& render,
+      bool clock_drift,
+      float* high_bands_gain,
+      std::array<float, kFftLengthBy2Plus1>* low_band_gain);
+
+  bool IsDominantNearend() {
+    return dominant_nearend_detector_->IsNearendState();
+  }
+
+  // Toggles the usage of the initial state.
+  void SetInitialState(bool state);
+
+ private:
+  // Computes the gain to apply for the bands beyond the first band.
+  float UpperBandsGain(
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> echo_spectrum,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+          comfort_noise_spectrum,
+      const absl::optional<int>& narrow_peak_band,
+      bool saturated_echo,
+      const std::vector<std::vector<std::vector<float>>>& render,
+      const std::array<float, kFftLengthBy2Plus1>& low_band_gain) const;
+
+  void GainToNoAudibleEcho(const std::array<float, kFftLengthBy2Plus1>& nearend,
+                           const std::array<float, kFftLengthBy2Plus1>& echo,
+                           const std::array<float, kFftLengthBy2Plus1>& masker,
+                           std::array<float, kFftLengthBy2Plus1>* gain) const;
+
+  void LowerBandGain(
+      bool stationary_with_low_power,
+      const AecState& aec_state,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>>
+          suppressor_input,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> residual_echo,
+      rtc::ArrayView<const std::array<float, kFftLengthBy2Plus1>> comfort_noise,
+      bool clock_drift,
+      std::array<float, kFftLengthBy2Plus1>* gain);
+
+  void GetMinGain(rtc::ArrayView<const float> weighted_residual_echo,
+                  rtc::ArrayView<const float> last_nearend,
+                  rtc::ArrayView<const float> last_echo,
+                  bool low_noise_render,
+                  bool saturated_echo,
+                  rtc::ArrayView<float> min_gain) const;
+
+  void GetMaxGain(rtc::ArrayView<float> max_gain) const;
+
+  class LowNoiseRenderDetector {
+   public:
+    bool Detect(const std::vector<std::vector<std::vector<float>>>& render);
+
+   private:
+    float average_power_ = 32768.f * 32768.f;
+  };
+
+  struct GainParameters {
+    explicit GainParameters(
+        const EchoCanceller3Config::Suppressor::Tuning& tuning);
+    const float max_inc_factor;
+    const float max_dec_factor_lf;
+    std::array<float, kFftLengthBy2Plus1> enr_transparent_;
+    std::array<float, kFftLengthBy2Plus1> enr_suppress_;
+    std::array<float, kFftLengthBy2Plus1> emr_transparent_;
+  };
+
+  static int instance_count_;
+  std::unique_ptr<ApmDataDumper> data_dumper_;
+  const Aec3Optimization optimization_;
+  const EchoCanceller3Config config_;
+  const size_t num_capture_channels_;
+  const int state_change_duration_blocks_;
+  std::array<float, kFftLengthBy2Plus1> last_gain_;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> last_nearend_;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> last_echo_;
+  LowNoiseRenderDetector low_render_detector_;
+  bool initial_state_ = true;
+  int initial_state_change_counter_ = 0;
+  std::vector<aec3::MovingAverage> nearend_smoothers_;
+  const GainParameters nearend_params_;
+  const GainParameters normal_params_;
+  std::unique_ptr<NearendDetector> dominant_nearend_detector_;
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(SuppressionGain);
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_SUPPRESSION_GAIN_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_gain_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_gain_unittest.cc
new file mode 100644
index 0000000..26bfc24
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/suppression_gain_unittest.cc
@@ -0,0 +1,148 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/suppression_gain.h"
+
+#include "modules/audio_processing/aec3/aec_state.h"
+#include "modules/audio_processing/aec3/render_delay_buffer.h"
+#include "modules/audio_processing/aec3/subtractor.h"
+#include "modules/audio_processing/aec3/subtractor_output.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+#include "system_wrappers/include/cpu_features_wrapper.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace aec3 {
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+// Verifies that the check for non-null output gains works.
+TEST(SuppressionGainDeathTest, NullOutputGains) {
+  std::vector<std::array<float, kFftLengthBy2Plus1>> E2(1, {0.f});
+  std::vector<std::array<float, kFftLengthBy2Plus1>> R2(1, {0.f});
+  std::vector<std::array<float, kFftLengthBy2Plus1>> S2(1);
+  std::vector<std::array<float, kFftLengthBy2Plus1>> N2(1, {0.f});
+  for (auto& S2_k : S2) {
+    S2_k.fill(.1f);
+  }
+  FftData E;
+  FftData Y;
+  E.re.fill(0.f);
+  E.im.fill(0.f);
+  Y.re.fill(0.f);
+  Y.im.fill(0.f);
+
+  float high_bands_gain;
+  AecState aec_state(EchoCanceller3Config{}, 1);
+  EXPECT_DEATH(
+      SuppressionGain(EchoCanceller3Config{}, DetectOptimization(), 16000, 1)
+          .GetGain(E2, S2, R2, N2,
+                   RenderSignalAnalyzer((EchoCanceller3Config{})), aec_state,
+                   std::vector<std::vector<std::vector<float>>>(
+                       3, std::vector<std::vector<float>>(
+                              1, std::vector<float>(kBlockSize, 0.f))),
+                   false, &high_bands_gain, nullptr),
+      "");
+}
+
+#endif
+
+// Does a sanity check that the gains are correctly computed.
+TEST(SuppressionGain, BasicGainComputation) {
+  constexpr size_t kNumRenderChannels = 1;
+  constexpr size_t kNumCaptureChannels = 2;
+  constexpr int kSampleRateHz = 16000;
+  constexpr size_t kNumBands = NumBandsForRate(kSampleRateHz);
+  SuppressionGain suppression_gain(EchoCanceller3Config(), DetectOptimization(),
+                                   kSampleRateHz, kNumCaptureChannels);
+  RenderSignalAnalyzer analyzer(EchoCanceller3Config{});
+  float high_bands_gain;
+  std::vector<std::array<float, kFftLengthBy2Plus1>> E2(kNumCaptureChannels);
+  std::vector<std::array<float, kFftLengthBy2Plus1>> S2(kNumCaptureChannels,
+                                                        {0.f});
+  std::vector<std::array<float, kFftLengthBy2Plus1>> Y2(kNumCaptureChannels);
+  std::vector<std::array<float, kFftLengthBy2Plus1>> R2(kNumCaptureChannels);
+  std::vector<std::array<float, kFftLengthBy2Plus1>> N2(kNumCaptureChannels);
+  std::array<float, kFftLengthBy2Plus1> g;
+  std::vector<SubtractorOutput> output(kNumCaptureChannels);
+  std::vector<std::vector<std::vector<float>>> x(
+      kNumBands, std::vector<std::vector<float>>(
+                     kNumRenderChannels, std::vector<float>(kBlockSize, 0.f)));
+  EchoCanceller3Config config;
+  AecState aec_state(config, kNumCaptureChannels);
+  ApmDataDumper data_dumper(42);
+  Subtractor subtractor(config, kNumRenderChannels, kNumCaptureChannels,
+                        &data_dumper, DetectOptimization());
+  std::unique_ptr<RenderDelayBuffer> render_delay_buffer(
+      RenderDelayBuffer::Create(config, kSampleRateHz, kNumRenderChannels));
+  absl::optional<DelayEstimate> delay_estimate;
+
+  // Ensure that a strong noise is detected to mask any echoes.
+  for (size_t ch = 0; ch < kNumCaptureChannels; ++ch) {
+    E2[ch].fill(10.f);
+    Y2[ch].fill(10.f);
+    R2[ch].fill(.1f);
+    N2[ch].fill(100.f);
+  }
+  for (auto& subtractor_output : output) {
+    subtractor_output.Reset();
+  }
+
+  // Ensure that the gain is no longer forced to zero.
+  for (int k = 0; k <= kNumBlocksPerSecond / 5 + 1; ++k) {
+    aec_state.Update(delay_estimate, subtractor.FilterFrequencyResponses(),
+                     subtractor.FilterImpulseResponses(),
+                     *render_delay_buffer->GetRenderBuffer(), E2, Y2, output);
+  }
+
+  for (int k = 0; k < 100; ++k) {
+    aec_state.Update(delay_estimate, subtractor.FilterFrequencyResponses(),
+                     subtractor.FilterImpulseResponses(),
+                     *render_delay_buffer->GetRenderBuffer(), E2, Y2, output);
+    suppression_gain.GetGain(E2, S2, R2, N2, analyzer, aec_state, x, false,
+                             &high_bands_gain, &g);
+  }
+  std::for_each(g.begin(), g.end(),
+                [](float a) { EXPECT_NEAR(1.f, a, 0.001); });
+
+  // Ensure that a strong nearend is detected to mask any echoes.
+  for (size_t ch = 0; ch < kNumCaptureChannels; ++ch) {
+    E2[ch].fill(100.f);
+    Y2[ch].fill(100.f);
+    R2[ch].fill(0.1f);
+    S2[ch].fill(0.1f);
+    N2[ch].fill(0.f);
+  }
+
+  for (int k = 0; k < 100; ++k) {
+    aec_state.Update(delay_estimate, subtractor.FilterFrequencyResponses(),
+                     subtractor.FilterImpulseResponses(),
+                     *render_delay_buffer->GetRenderBuffer(), E2, Y2, output);
+    suppression_gain.GetGain(E2, S2, R2, N2, analyzer, aec_state, x, false,
+                             &high_bands_gain, &g);
+  }
+  std::for_each(g.begin(), g.end(),
+                [](float a) { EXPECT_NEAR(1.f, a, 0.001); });
+
+  // Add a strong echo to one of the channels and ensure that it is suppressed.
+  E2[1].fill(1000000000.f);
+  R2[1].fill(10000000000000.f);
+
+  for (int k = 0; k < 10; ++k) {
+    suppression_gain.GetGain(E2, S2, R2, N2, analyzer, aec_state, x, false,
+                             &high_bands_gain, &g);
+  }
+  std::for_each(g.begin(), g.end(),
+                [](float a) { EXPECT_NEAR(0.f, a, 0.001); });
+}
+
+}  // namespace aec3
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/transparent_mode.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/transparent_mode.cc
new file mode 100644
index 0000000..7cfa3e8
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/transparent_mode.cc
@@ -0,0 +1,239 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/transparent_mode.h"
+
+#include "rtc_base/checks.h"
+#include "system_wrappers/include/field_trial.h"
+
+namespace webrtc {
+namespace {
+
+constexpr size_t kBlocksSinceConvergencedFilterInit = 10000;
+constexpr size_t kBlocksSinceConsistentEstimateInit = 10000;
+
+bool DeactivateTransparentMode() {
+  return field_trial::IsEnabled("WebRTC-Aec3TransparentModeKillSwitch");
+}
+
+bool ActivateTransparentModeHmm() {
+  return field_trial::IsEnabled("WebRTC-Aec3TransparentModeHmm");
+}
+
+}  // namespace
+
+// Classifier that toggles transparent mode which reduces echo suppression when
+// headsets are used.
+class TransparentModeImpl : public TransparentMode {
+ public:
+  bool Active() const override { return transparency_activated_; }
+
+  void Reset() override {
+    // Determines if transparent mode is used.
+    transparency_activated_ = false;
+
+    // The estimated probability of being transparent mode.
+    prob_transparent_state_ = 0.f;
+  }
+
+  void Update(int filter_delay_blocks,
+              bool any_filter_consistent,
+              bool any_filter_converged,
+              bool any_coarse_filter_converged,
+              bool all_filters_diverged,
+              bool active_render,
+              bool saturated_capture) override {
+    // The classifier is implemented as a Hidden Markov Model (HMM) with two
+    // hidden states: "normal" and "transparent". The estimated probabilities of
+    // the two states are updated by observing filter convergence during active
+    // render. The filters are less likely to be reported as converged when
+    // there is no echo present in the microphone signal.
+
+    // The constants have been obtained by observing active_render and
+    // any_coarse_filter_converged under varying call scenarios. They
+    // have further been hand tuned to prefer normal state during uncertain
+    // regions (to avoid echo leaks).
+
+    // The model is only updated during active render.
+    if (!active_render)
+      return;
+
+    // Probability of switching from one state to the other.
+    constexpr float kSwitch = 0.000001f;
+
+    // Probability of observing converged filters in states "normal" and
+    // "transparent" during active render.
+    constexpr float kConvergedNormal = 0.01f;
+    constexpr float kConvergedTransparent = 0.001f;
+
+    // Probability of transitioning to transparent state from normal state and
+    // transparent state respectively.
+    constexpr float kA[2] = {kSwitch, 1.f - kSwitch};
+
+    // Probability of the two observations (converged filter or not converged
+    // filter) in normal state and transparent state respectively.
+    constexpr float kB[2][2] = {
+        {1.f - kConvergedNormal, kConvergedNormal},
+        {1.f - kConvergedTransparent, kConvergedTransparent}};
+
+    // Probability of the two states before the update.
+    const float prob_transparent = prob_transparent_state_;
+    const float prob_normal = 1.f - prob_transparent;
+
+    // Probability of transitioning to transparent state.
+    const float prob_transition_transparent =
+        prob_normal * kA[0] + prob_transparent * kA[1];
+    const float prob_transition_normal = 1.f - prob_transition_transparent;
+
+    // Observed output.
+    const int out = static_cast<int>(any_coarse_filter_converged);
+
+    // Joint probabilites of the observed output and respective states.
+    const float prob_joint_normal = prob_transition_normal * kB[0][out];
+    const float prob_joint_transparent =
+        prob_transition_transparent * kB[1][out];
+
+    // Conditional probability of transparent state and the observed output.
+    RTC_DCHECK_GT(prob_joint_normal + prob_joint_transparent, 0.f);
+    prob_transparent_state_ =
+        prob_joint_transparent / (prob_joint_normal + prob_joint_transparent);
+
+    // Transparent mode is only activated when its state probability is high.
+    // Dead zone between activation/deactivation thresholds to avoid switching
+    // back and forth.
+    if (prob_transparent_state_ > 0.95f) {
+      transparency_activated_ = true;
+    } else if (prob_transparent_state_ < 0.5f) {
+      transparency_activated_ = false;
+    }
+  }
+
+ private:
+  bool transparency_activated_ = false;
+  float prob_transparent_state_ = 0.f;
+};
+
+// Legacy classifier for toggling transparent mode.
+class LegacyTransparentModeImpl : public TransparentMode {
+ public:
+  explicit LegacyTransparentModeImpl(const EchoCanceller3Config& config)
+      : linear_and_stable_echo_path_(
+            config.echo_removal_control.linear_and_stable_echo_path),
+        active_blocks_since_sane_filter_(kBlocksSinceConsistentEstimateInit),
+        non_converged_sequence_size_(kBlocksSinceConvergencedFilterInit) {}
+
+  bool Active() const override { return transparency_activated_; }
+
+  void Reset() override {
+    non_converged_sequence_size_ = kBlocksSinceConvergencedFilterInit;
+    diverged_sequence_size_ = 0;
+    strong_not_saturated_render_blocks_ = 0;
+    if (linear_and_stable_echo_path_) {
+      recent_convergence_during_activity_ = false;
+    }
+  }
+
+  void Update(int filter_delay_blocks,
+              bool any_filter_consistent,
+              bool any_filter_converged,
+              bool any_coarse_filter_converged,
+              bool all_filters_diverged,
+              bool active_render,
+              bool saturated_capture) override {
+    ++capture_block_counter_;
+    strong_not_saturated_render_blocks_ +=
+        active_render && !saturated_capture ? 1 : 0;
+
+    if (any_filter_consistent && filter_delay_blocks < 5) {
+      sane_filter_observed_ = true;
+      active_blocks_since_sane_filter_ = 0;
+    } else if (active_render) {
+      ++active_blocks_since_sane_filter_;
+    }
+
+    bool sane_filter_recently_seen;
+    if (!sane_filter_observed_) {
+      sane_filter_recently_seen =
+          capture_block_counter_ <= 5 * kNumBlocksPerSecond;
+    } else {
+      sane_filter_recently_seen =
+          active_blocks_since_sane_filter_ <= 30 * kNumBlocksPerSecond;
+    }
+
+    if (any_filter_converged) {
+      recent_convergence_during_activity_ = true;
+      active_non_converged_sequence_size_ = 0;
+      non_converged_sequence_size_ = 0;
+      ++num_converged_blocks_;
+    } else {
+      if (++non_converged_sequence_size_ > 20 * kNumBlocksPerSecond) {
+        num_converged_blocks_ = 0;
+      }
+
+      if (active_render &&
+          ++active_non_converged_sequence_size_ > 60 * kNumBlocksPerSecond) {
+        recent_convergence_during_activity_ = false;
+      }
+    }
+
+    if (!all_filters_diverged) {
+      diverged_sequence_size_ = 0;
+    } else if (++diverged_sequence_size_ >= 60) {
+      // TODO(peah): Change these lines to ensure proper triggering of usable
+      // filter.
+      non_converged_sequence_size_ = kBlocksSinceConvergencedFilterInit;
+    }
+
+    if (active_non_converged_sequence_size_ > 60 * kNumBlocksPerSecond) {
+      finite_erl_recently_detected_ = false;
+    }
+    if (num_converged_blocks_ > 50) {
+      finite_erl_recently_detected_ = true;
+    }
+
+    if (finite_erl_recently_detected_) {
+      transparency_activated_ = false;
+    } else if (sane_filter_recently_seen &&
+               recent_convergence_during_activity_) {
+      transparency_activated_ = false;
+    } else {
+      const bool filter_should_have_converged =
+          strong_not_saturated_render_blocks_ > 6 * kNumBlocksPerSecond;
+      transparency_activated_ = filter_should_have_converged;
+    }
+  }
+
+ private:
+  const bool linear_and_stable_echo_path_;
+  size_t capture_block_counter_ = 0;
+  bool transparency_activated_ = false;
+  size_t active_blocks_since_sane_filter_;
+  bool sane_filter_observed_ = false;
+  bool finite_erl_recently_detected_ = false;
+  size_t non_converged_sequence_size_;
+  size_t diverged_sequence_size_ = 0;
+  size_t active_non_converged_sequence_size_ = 0;
+  size_t num_converged_blocks_ = 0;
+  bool recent_convergence_during_activity_ = false;
+  size_t strong_not_saturated_render_blocks_ = 0;
+};
+
+std::unique_ptr<TransparentMode> TransparentMode::Create(
+    const EchoCanceller3Config& config) {
+  if (config.ep_strength.bounded_erl || DeactivateTransparentMode()) {
+    return nullptr;
+  }
+  if (ActivateTransparentModeHmm()) {
+    return std::make_unique<TransparentModeImpl>();
+  }
+  return std::make_unique<LegacyTransparentModeImpl>(config);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/transparent_mode.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/transparent_mode.h
new file mode 100644
index 0000000..bc5dd03
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/transparent_mode.h
@@ -0,0 +1,47 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_TRANSPARENT_MODE_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_TRANSPARENT_MODE_H_
+
+#include <memory>
+
+#include "api/audio/echo_canceller3_config.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+
+namespace webrtc {
+
+// Class for detecting and toggling the transparent mode which causes the
+// suppressor to apply less suppression.
+class TransparentMode {
+ public:
+  static std::unique_ptr<TransparentMode> Create(
+      const EchoCanceller3Config& config);
+
+  virtual ~TransparentMode() {}
+
+  // Returns whether the transparent mode should be active.
+  virtual bool Active() const = 0;
+
+  // Resets the state of the detector.
+  virtual void Reset() = 0;
+
+  // Updates the detection decision based on new data.
+  virtual void Update(int filter_delay_blocks,
+                      bool any_filter_consistent,
+                      bool any_filter_converged,
+                      bool any_coarse_filter_converged,
+                      bool all_filters_diverged,
+                      bool active_render,
+                      bool saturated_capture) = 0;
+};
+
+}  // namespace webrtc
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_TRANSPARENT_MODE_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/vector_math.h b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/vector_math.h
new file mode 100644
index 0000000..e4d1381
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/vector_math.h
@@ -0,0 +1,229 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AEC3_VECTOR_MATH_H_
+#define MODULES_AUDIO_PROCESSING_AEC3_VECTOR_MATH_H_
+
+// Defines WEBRTC_ARCH_X86_FAMILY, used below.
+#include "rtc_base/system/arch.h"
+
+#if defined(WEBRTC_HAS_NEON)
+#include <arm_neon.h>
+#endif
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+#include <emmintrin.h>
+#endif
+#include <math.h>
+
+#include <algorithm>
+#include <array>
+#include <functional>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/aec3/aec3_common.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace aec3 {
+
+// Provides optimizations for mathematical operations based on vectors.
+class VectorMath {
+ public:
+  explicit VectorMath(Aec3Optimization optimization)
+      : optimization_(optimization) {}
+
+  // Elementwise square root.
+  void SqrtAVX2(rtc::ArrayView<float> x);
+  void Sqrt(rtc::ArrayView<float> x) {
+    switch (optimization_) {
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+      case Aec3Optimization::kSse2: {
+        const int x_size = static_cast<int>(x.size());
+        const int vector_limit = x_size >> 2;
+
+        int j = 0;
+        for (; j < vector_limit * 4; j += 4) {
+          __m128 g = _mm_loadu_ps(&x[j]);
+          g = _mm_sqrt_ps(g);
+          _mm_storeu_ps(&x[j], g);
+        }
+
+        for (; j < x_size; ++j) {
+          x[j] = sqrtf(x[j]);
+        }
+      } break;
+      case Aec3Optimization::kAvx2:
+        SqrtAVX2(x);
+        break;
+#endif
+#if defined(WEBRTC_HAS_NEON)
+      case Aec3Optimization::kNeon: {
+        const int x_size = static_cast<int>(x.size());
+        const int vector_limit = x_size >> 2;
+
+        int j = 0;
+        for (; j < vector_limit * 4; j += 4) {
+          float32x4_t g = vld1q_f32(&x[j]);
+#if !defined(WEBRTC_ARCH_ARM64)
+          float32x4_t y = vrsqrteq_f32(g);
+
+          // Code to handle sqrt(0).
+          // If the input to sqrtf() is zero, a zero will be returned.
+          // If the input to vrsqrteq_f32() is zero, positive infinity is
+          // returned.
+          const uint32x4_t vec_p_inf = vdupq_n_u32(0x7F800000);
+          // check for divide by zero
+          const uint32x4_t div_by_zero =
+              vceqq_u32(vec_p_inf, vreinterpretq_u32_f32(y));
+          // zero out the positive infinity results
+          y = vreinterpretq_f32_u32(
+              vandq_u32(vmvnq_u32(div_by_zero), vreinterpretq_u32_f32(y)));
+          // from arm documentation
+          // The Newton-Raphson iteration:
+          //     y[n+1] = y[n] * (3 - d * (y[n] * y[n])) / 2)
+          // converges to (1/d) if y0 is the result of VRSQRTE applied to d.
+          //
+          // Note: The precision did not improve after 2 iterations.
+          for (int i = 0; i < 2; i++) {
+            y = vmulq_f32(vrsqrtsq_f32(vmulq_f32(y, y), g), y);
+          }
+          // sqrt(g) = g * 1/sqrt(g)
+          g = vmulq_f32(g, y);
+#else
+          g = vsqrtq_f32(g);
+#endif
+          vst1q_f32(&x[j], g);
+        }
+
+        for (; j < x_size; ++j) {
+          x[j] = sqrtf(x[j]);
+        }
+      }
+#endif
+      break;
+      default:
+        std::for_each(x.begin(), x.end(), [](float& a) { a = sqrtf(a); });
+    }
+  }
+
+  // Elementwise vector multiplication z = x * y.
+  void MultiplyAVX2(rtc::ArrayView<const float> x,
+                    rtc::ArrayView<const float> y,
+                    rtc::ArrayView<float> z);
+  void Multiply(rtc::ArrayView<const float> x,
+                rtc::ArrayView<const float> y,
+                rtc::ArrayView<float> z) {
+    RTC_DCHECK_EQ(z.size(), x.size());
+    RTC_DCHECK_EQ(z.size(), y.size());
+    switch (optimization_) {
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+      case Aec3Optimization::kSse2: {
+        const int x_size = static_cast<int>(x.size());
+        const int vector_limit = x_size >> 2;
+
+        int j = 0;
+        for (; j < vector_limit * 4; j += 4) {
+          const __m128 x_j = _mm_loadu_ps(&x[j]);
+          const __m128 y_j = _mm_loadu_ps(&y[j]);
+          const __m128 z_j = _mm_mul_ps(x_j, y_j);
+          _mm_storeu_ps(&z[j], z_j);
+        }
+
+        for (; j < x_size; ++j) {
+          z[j] = x[j] * y[j];
+        }
+      } break;
+      case Aec3Optimization::kAvx2:
+        MultiplyAVX2(x, y, z);
+        break;
+#endif
+#if defined(WEBRTC_HAS_NEON)
+      case Aec3Optimization::kNeon: {
+        const int x_size = static_cast<int>(x.size());
+        const int vector_limit = x_size >> 2;
+
+        int j = 0;
+        for (; j < vector_limit * 4; j += 4) {
+          const float32x4_t x_j = vld1q_f32(&x[j]);
+          const float32x4_t y_j = vld1q_f32(&y[j]);
+          const float32x4_t z_j = vmulq_f32(x_j, y_j);
+          vst1q_f32(&z[j], z_j);
+        }
+
+        for (; j < x_size; ++j) {
+          z[j] = x[j] * y[j];
+        }
+      } break;
+#endif
+      default:
+        std::transform(x.begin(), x.end(), y.begin(), z.begin(),
+                       std::multiplies<float>());
+    }
+  }
+
+  // Elementwise vector accumulation z += x.
+  void AccumulateAVX2(rtc::ArrayView<const float> x, rtc::ArrayView<float> z);
+  void Accumulate(rtc::ArrayView<const float> x, rtc::ArrayView<float> z) {
+    RTC_DCHECK_EQ(z.size(), x.size());
+    switch (optimization_) {
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+      case Aec3Optimization::kSse2: {
+        const int x_size = static_cast<int>(x.size());
+        const int vector_limit = x_size >> 2;
+
+        int j = 0;
+        for (; j < vector_limit * 4; j += 4) {
+          const __m128 x_j = _mm_loadu_ps(&x[j]);
+          __m128 z_j = _mm_loadu_ps(&z[j]);
+          z_j = _mm_add_ps(x_j, z_j);
+          _mm_storeu_ps(&z[j], z_j);
+        }
+
+        for (; j < x_size; ++j) {
+          z[j] += x[j];
+        }
+      } break;
+      case Aec3Optimization::kAvx2:
+        AccumulateAVX2(x, z);
+        break;
+#endif
+#if defined(WEBRTC_HAS_NEON)
+      case Aec3Optimization::kNeon: {
+        const int x_size = static_cast<int>(x.size());
+        const int vector_limit = x_size >> 2;
+
+        int j = 0;
+        for (; j < vector_limit * 4; j += 4) {
+          const float32x4_t x_j = vld1q_f32(&x[j]);
+          float32x4_t z_j = vld1q_f32(&z[j]);
+          z_j = vaddq_f32(z_j, x_j);
+          vst1q_f32(&z[j], z_j);
+        }
+
+        for (; j < x_size; ++j) {
+          z[j] += x[j];
+        }
+      } break;
+#endif
+      default:
+        std::transform(x.begin(), x.end(), z.begin(), z.begin(),
+                       std::plus<float>());
+    }
+  }
+
+ private:
+  Aec3Optimization optimization_;
+};
+
+}  // namespace aec3
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AEC3_VECTOR_MATH_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/vector_math_avx2.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/vector_math_avx2.cc
new file mode 100644
index 0000000..0b5f3c1
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/vector_math_avx2.cc
@@ -0,0 +1,82 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/vector_math.h"
+
+#include <immintrin.h>
+#include <math.h>
+
+#include "api/array_view.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace aec3 {
+
+// Elementwise square root.
+void VectorMath::SqrtAVX2(rtc::ArrayView<float> x) {
+  const int x_size = static_cast<int>(x.size());
+  const int vector_limit = x_size >> 3;
+
+  int j = 0;
+  for (; j < vector_limit * 8; j += 8) {
+    __m256 g = _mm256_loadu_ps(&x[j]);
+    g = _mm256_sqrt_ps(g);
+    _mm256_storeu_ps(&x[j], g);
+  }
+
+  for (; j < x_size; ++j) {
+    x[j] = sqrtf(x[j]);
+  }
+}
+
+// Elementwise vector multiplication z = x * y.
+void VectorMath::MultiplyAVX2(rtc::ArrayView<const float> x,
+                              rtc::ArrayView<const float> y,
+                              rtc::ArrayView<float> z) {
+  RTC_DCHECK_EQ(z.size(), x.size());
+  RTC_DCHECK_EQ(z.size(), y.size());
+  const int x_size = static_cast<int>(x.size());
+  const int vector_limit = x_size >> 3;
+
+  int j = 0;
+  for (; j < vector_limit * 8; j += 8) {
+    const __m256 x_j = _mm256_loadu_ps(&x[j]);
+    const __m256 y_j = _mm256_loadu_ps(&y[j]);
+    const __m256 z_j = _mm256_mul_ps(x_j, y_j);
+    _mm256_storeu_ps(&z[j], z_j);
+  }
+
+  for (; j < x_size; ++j) {
+    z[j] = x[j] * y[j];
+  }
+}
+
+// Elementwise vector accumulation z += x.
+void VectorMath::AccumulateAVX2(rtc::ArrayView<const float> x,
+                                rtc::ArrayView<float> z) {
+  RTC_DCHECK_EQ(z.size(), x.size());
+  const int x_size = static_cast<int>(x.size());
+  const int vector_limit = x_size >> 3;
+
+  int j = 0;
+  for (; j < vector_limit * 8; j += 8) {
+    const __m256 x_j = _mm256_loadu_ps(&x[j]);
+    __m256 z_j = _mm256_loadu_ps(&z[j]);
+    z_j = _mm256_add_ps(x_j, z_j);
+    _mm256_storeu_ps(&z[j], z_j);
+  }
+
+  for (; j < x_size; ++j) {
+    z[j] += x[j];
+  }
+}
+
+}  // namespace aec3
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/aec3/vector_math_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/vector_math_unittest.cc
new file mode 100644
index 0000000..a9c37e3
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/aec3/vector_math_unittest.cc
@@ -0,0 +1,209 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/vector_math.h"
+
+#include <math.h>
+
+#include "rtc_base/system/arch.h"
+#include "system_wrappers/include/cpu_features_wrapper.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+#if defined(WEBRTC_HAS_NEON)
+
+TEST(VectorMath, Sqrt) {
+  std::array<float, kFftLengthBy2Plus1> x;
+  std::array<float, kFftLengthBy2Plus1> z;
+  std::array<float, kFftLengthBy2Plus1> z_neon;
+
+  for (size_t k = 0; k < x.size(); ++k) {
+    x[k] = (2.f / 3.f) * k;
+  }
+
+  std::copy(x.begin(), x.end(), z.begin());
+  aec3::VectorMath(Aec3Optimization::kNone).Sqrt(z);
+  std::copy(x.begin(), x.end(), z_neon.begin());
+  aec3::VectorMath(Aec3Optimization::kNeon).Sqrt(z_neon);
+  for (size_t k = 0; k < z.size(); ++k) {
+    EXPECT_NEAR(z[k], z_neon[k], 0.0001f);
+    EXPECT_NEAR(sqrtf(x[k]), z_neon[k], 0.0001f);
+  }
+}
+
+TEST(VectorMath, Multiply) {
+  std::array<float, kFftLengthBy2Plus1> x;
+  std::array<float, kFftLengthBy2Plus1> y;
+  std::array<float, kFftLengthBy2Plus1> z;
+  std::array<float, kFftLengthBy2Plus1> z_neon;
+
+  for (size_t k = 0; k < x.size(); ++k) {
+    x[k] = k;
+    y[k] = (2.f / 3.f) * k;
+  }
+
+  aec3::VectorMath(Aec3Optimization::kNone).Multiply(x, y, z);
+  aec3::VectorMath(Aec3Optimization::kNeon).Multiply(x, y, z_neon);
+  for (size_t k = 0; k < z.size(); ++k) {
+    EXPECT_FLOAT_EQ(z[k], z_neon[k]);
+    EXPECT_FLOAT_EQ(x[k] * y[k], z_neon[k]);
+  }
+}
+
+TEST(VectorMath, Accumulate) {
+  std::array<float, kFftLengthBy2Plus1> x;
+  std::array<float, kFftLengthBy2Plus1> z;
+  std::array<float, kFftLengthBy2Plus1> z_neon;
+
+  for (size_t k = 0; k < x.size(); ++k) {
+    x[k] = k;
+    z[k] = z_neon[k] = 2.f * k;
+  }
+
+  aec3::VectorMath(Aec3Optimization::kNone).Accumulate(x, z);
+  aec3::VectorMath(Aec3Optimization::kNeon).Accumulate(x, z_neon);
+  for (size_t k = 0; k < z.size(); ++k) {
+    EXPECT_FLOAT_EQ(z[k], z_neon[k]);
+    EXPECT_FLOAT_EQ(x[k] + 2.f * x[k], z_neon[k]);
+  }
+}
+#endif
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+
+TEST(VectorMath, Sse2Sqrt) {
+  if (GetCPUInfo(kSSE2) != 0) {
+    std::array<float, kFftLengthBy2Plus1> x;
+    std::array<float, kFftLengthBy2Plus1> z;
+    std::array<float, kFftLengthBy2Plus1> z_sse2;
+
+    for (size_t k = 0; k < x.size(); ++k) {
+      x[k] = (2.f / 3.f) * k;
+    }
+
+    std::copy(x.begin(), x.end(), z.begin());
+    aec3::VectorMath(Aec3Optimization::kNone).Sqrt(z);
+    std::copy(x.begin(), x.end(), z_sse2.begin());
+    aec3::VectorMath(Aec3Optimization::kSse2).Sqrt(z_sse2);
+    EXPECT_EQ(z, z_sse2);
+    for (size_t k = 0; k < z.size(); ++k) {
+      EXPECT_FLOAT_EQ(z[k], z_sse2[k]);
+      EXPECT_FLOAT_EQ(sqrtf(x[k]), z_sse2[k]);
+    }
+  }
+}
+
+TEST(VectorMath, Avx2Sqrt) {
+  if (GetCPUInfo(kAVX2) != 0) {
+    std::array<float, kFftLengthBy2Plus1> x;
+    std::array<float, kFftLengthBy2Plus1> z;
+    std::array<float, kFftLengthBy2Plus1> z_avx2;
+
+    for (size_t k = 0; k < x.size(); ++k) {
+      x[k] = (2.f / 3.f) * k;
+    }
+
+    std::copy(x.begin(), x.end(), z.begin());
+    aec3::VectorMath(Aec3Optimization::kNone).Sqrt(z);
+    std::copy(x.begin(), x.end(), z_avx2.begin());
+    aec3::VectorMath(Aec3Optimization::kAvx2).Sqrt(z_avx2);
+    EXPECT_EQ(z, z_avx2);
+    for (size_t k = 0; k < z.size(); ++k) {
+      EXPECT_FLOAT_EQ(z[k], z_avx2[k]);
+      EXPECT_FLOAT_EQ(sqrtf(x[k]), z_avx2[k]);
+    }
+  }
+}
+
+TEST(VectorMath, Sse2Multiply) {
+  if (GetCPUInfo(kSSE2) != 0) {
+    std::array<float, kFftLengthBy2Plus1> x;
+    std::array<float, kFftLengthBy2Plus1> y;
+    std::array<float, kFftLengthBy2Plus1> z;
+    std::array<float, kFftLengthBy2Plus1> z_sse2;
+
+    for (size_t k = 0; k < x.size(); ++k) {
+      x[k] = k;
+      y[k] = (2.f / 3.f) * k;
+    }
+
+    aec3::VectorMath(Aec3Optimization::kNone).Multiply(x, y, z);
+    aec3::VectorMath(Aec3Optimization::kSse2).Multiply(x, y, z_sse2);
+    for (size_t k = 0; k < z.size(); ++k) {
+      EXPECT_FLOAT_EQ(z[k], z_sse2[k]);
+      EXPECT_FLOAT_EQ(x[k] * y[k], z_sse2[k]);
+    }
+  }
+}
+
+TEST(VectorMath, Avx2Multiply) {
+  if (GetCPUInfo(kAVX2) != 0) {
+    std::array<float, kFftLengthBy2Plus1> x;
+    std::array<float, kFftLengthBy2Plus1> y;
+    std::array<float, kFftLengthBy2Plus1> z;
+    std::array<float, kFftLengthBy2Plus1> z_avx2;
+
+    for (size_t k = 0; k < x.size(); ++k) {
+      x[k] = k;
+      y[k] = (2.f / 3.f) * k;
+    }
+
+    aec3::VectorMath(Aec3Optimization::kNone).Multiply(x, y, z);
+    aec3::VectorMath(Aec3Optimization::kAvx2).Multiply(x, y, z_avx2);
+    for (size_t k = 0; k < z.size(); ++k) {
+      EXPECT_FLOAT_EQ(z[k], z_avx2[k]);
+      EXPECT_FLOAT_EQ(x[k] * y[k], z_avx2[k]);
+    }
+  }
+}
+
+TEST(VectorMath, Sse2Accumulate) {
+  if (GetCPUInfo(kSSE2) != 0) {
+    std::array<float, kFftLengthBy2Plus1> x;
+    std::array<float, kFftLengthBy2Plus1> z;
+    std::array<float, kFftLengthBy2Plus1> z_sse2;
+
+    for (size_t k = 0; k < x.size(); ++k) {
+      x[k] = k;
+      z[k] = z_sse2[k] = 2.f * k;
+    }
+
+    aec3::VectorMath(Aec3Optimization::kNone).Accumulate(x, z);
+    aec3::VectorMath(Aec3Optimization::kSse2).Accumulate(x, z_sse2);
+    for (size_t k = 0; k < z.size(); ++k) {
+      EXPECT_FLOAT_EQ(z[k], z_sse2[k]);
+      EXPECT_FLOAT_EQ(x[k] + 2.f * x[k], z_sse2[k]);
+    }
+  }
+}
+
+TEST(VectorMath, Avx2Accumulate) {
+  if (GetCPUInfo(kAVX2) != 0) {
+    std::array<float, kFftLengthBy2Plus1> x;
+    std::array<float, kFftLengthBy2Plus1> z;
+    std::array<float, kFftLengthBy2Plus1> z_avx2;
+
+    for (size_t k = 0; k < x.size(); ++k) {
+      x[k] = k;
+      z[k] = z_avx2[k] = 2.f * k;
+    }
+
+    aec3::VectorMath(Aec3Optimization::kNone).Accumulate(x, z);
+    aec3::VectorMath(Aec3Optimization::kAvx2).Accumulate(x, z_avx2);
+    for (size_t k = 0; k < z.size(); ++k) {
+      EXPECT_FLOAT_EQ(z[k], z_avx2[k]);
+      EXPECT_FLOAT_EQ(x[k] + 2.f * x[k], z_avx2[k]);
+    }
+  }
+}
+#endif
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/BUILD.gn b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/BUILD.gn
new file mode 100644
index 0000000..4c6cfab
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/BUILD.gn
@@ -0,0 +1,291 @@
+# Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+#
+# Use of this source code is governed by a BSD-style license
+# that can be found in the LICENSE file in the root of the source
+# tree. An additional intellectual property rights grant can be found
+# in the file PATENTS.  All contributing project authors may
+# be found in the AUTHORS file in the root of the source tree.
+
+import("../../../webrtc.gni")
+
+group("agc2") {
+  deps = [
+    ":adaptive_digital",
+    ":fixed_digital",
+  ]
+}
+
+rtc_library("adaptive_digital") {
+  sources = [
+    "adaptive_agc.cc",
+    "adaptive_agc.h",
+    "adaptive_digital_gain_applier.cc",
+    "adaptive_digital_gain_applier.h",
+    "adaptive_mode_level_estimator.cc",
+    "adaptive_mode_level_estimator.h",
+    "saturation_protector.cc",
+    "saturation_protector.h",
+    "saturation_protector_buffer.cc",
+    "saturation_protector_buffer.h",
+  ]
+
+  configs += [ "..:apm_debug_dump" ]
+
+  deps = [
+    ":common",
+    ":cpu_features",
+    ":gain_applier",
+    ":noise_level_estimator",
+    ":rnn_vad_with_level",
+    "..:api",
+    "..:apm_logging",
+    "..:audio_frame_view",
+    "../../../api:array_view",
+    "../../../common_audio",
+    "../../../rtc_base:checks",
+    "../../../rtc_base:logging",
+    "../../../rtc_base:rtc_base_approved",
+    "../../../rtc_base:safe_compare",
+    "../../../rtc_base:safe_minmax",
+    "../../../system_wrappers:metrics",
+  ]
+
+  absl_deps = [ "//third_party/abseil-cpp/absl/types:optional" ]
+}
+
+rtc_library("biquad_filter") {
+  visibility = [ "./*" ]
+  sources = [
+    "biquad_filter.cc",
+    "biquad_filter.h",
+  ]
+  deps = [
+    "../../../api:array_view",
+    "../../../rtc_base:rtc_base_approved",
+  ]
+}
+
+rtc_source_set("common") {
+  sources = [ "agc2_common.h" ]
+}
+
+rtc_library("fixed_digital") {
+  sources = [
+    "fixed_digital_level_estimator.cc",
+    "fixed_digital_level_estimator.h",
+    "interpolated_gain_curve.cc",
+    "interpolated_gain_curve.h",
+    "limiter.cc",
+    "limiter.h",
+  ]
+
+  configs += [ "..:apm_debug_dump" ]
+
+  deps = [
+    ":common",
+    "..:apm_logging",
+    "..:audio_frame_view",
+    "../../../api:array_view",
+    "../../../common_audio",
+    "../../../rtc_base:checks",
+    "../../../rtc_base:gtest_prod",
+    "../../../rtc_base:rtc_base_approved",
+    "../../../rtc_base:safe_minmax",
+    "../../../system_wrappers:metrics",
+  ]
+}
+
+rtc_library("gain_applier") {
+  sources = [
+    "gain_applier.cc",
+    "gain_applier.h",
+  ]
+  deps = [
+    ":common",
+    "..:audio_frame_view",
+    "../../../api:array_view",
+    "../../../rtc_base:safe_minmax",
+  ]
+}
+
+rtc_library("noise_level_estimator") {
+  sources = [
+    "down_sampler.cc",
+    "down_sampler.h",
+    "noise_level_estimator.cc",
+    "noise_level_estimator.h",
+    "noise_spectrum_estimator.cc",
+    "noise_spectrum_estimator.h",
+    "signal_classifier.cc",
+    "signal_classifier.h",
+  ]
+  deps = [
+    ":biquad_filter",
+    "..:apm_logging",
+    "..:audio_frame_view",
+    "../../../api:array_view",
+    "../../../common_audio",
+    "../../../common_audio/third_party/ooura:fft_size_128",
+    "../../../rtc_base:checks",
+    "../../../rtc_base:macromagic",
+    "../../../system_wrappers",
+  ]
+
+  configs += [ "..:apm_debug_dump" ]
+}
+
+rtc_library("rnn_vad_with_level") {
+  sources = [
+    "vad_with_level.cc",
+    "vad_with_level.h",
+  ]
+
+  defines = []
+  if (rtc_build_with_neon && current_cpu != "arm64") {
+    suppressed_configs += [ "//build/config/compiler:compiler_arm_fpu" ]
+    cflags = [ "-mfpu=neon" ]
+  }
+
+  deps = [
+    ":common",
+    ":cpu_features",
+    "..:audio_frame_view",
+    "../../../api:array_view",
+    "../../../common_audio",
+    "../../../rtc_base:checks",
+    "rnn_vad",
+    "rnn_vad:rnn_vad_common",
+  ]
+}
+
+rtc_library("cpu_features") {
+  sources = [
+    "cpu_features.cc",
+    "cpu_features.h",
+  ]
+  visibility = [ "./*" ]
+  deps = [
+    "../../../rtc_base:stringutils",
+    "../../../rtc_base/system:arch",
+    "../../../system_wrappers",
+  ]
+}
+
+rtc_library("adaptive_digital_unittests") {
+  testonly = true
+  configs += [ "..:apm_debug_dump" ]
+
+  sources = [
+    "adaptive_digital_gain_applier_unittest.cc",
+    "adaptive_mode_level_estimator_unittest.cc",
+    "gain_applier_unittest.cc",
+    "saturation_protector_buffer_unittest.cc",
+    "saturation_protector_unittest.cc",
+  ]
+  deps = [
+    ":adaptive_digital",
+    ":common",
+    ":gain_applier",
+    ":test_utils",
+    "..:apm_logging",
+    "..:audio_frame_view",
+    "../../../api:array_view",
+    "../../../common_audio",
+    "../../../rtc_base:checks",
+    "../../../rtc_base:gunit_helpers",
+    "../../../rtc_base:rtc_base_approved",
+    "../../../test:test_support",
+  ]
+}
+
+rtc_library("biquad_filter_unittests") {
+  testonly = true
+  sources = [ "biquad_filter_unittest.cc" ]
+  deps = [
+    ":biquad_filter",
+    "../../../rtc_base:gunit_helpers",
+  ]
+}
+
+rtc_library("fixed_digital_unittests") {
+  testonly = true
+  configs += [ "..:apm_debug_dump" ]
+
+  sources = [
+    "agc2_testing_common_unittest.cc",
+    "compute_interpolated_gain_curve.cc",
+    "compute_interpolated_gain_curve.h",
+    "fixed_digital_level_estimator_unittest.cc",
+    "interpolated_gain_curve_unittest.cc",
+    "limiter_db_gain_curve.cc",
+    "limiter_db_gain_curve.h",
+    "limiter_db_gain_curve_unittest.cc",
+    "limiter_unittest.cc",
+  ]
+  deps = [
+    ":common",
+    ":fixed_digital",
+    ":test_utils",
+    "..:apm_logging",
+    "..:audio_frame_view",
+    "../../../api:array_view",
+    "../../../common_audio",
+    "../../../rtc_base:checks",
+    "../../../rtc_base:gunit_helpers",
+    "../../../rtc_base:rtc_base_approved",
+    "../../../system_wrappers:metrics",
+  ]
+}
+
+rtc_library("noise_estimator_unittests") {
+  testonly = true
+  configs += [ "..:apm_debug_dump" ]
+
+  sources = [
+    "noise_level_estimator_unittest.cc",
+    "signal_classifier_unittest.cc",
+  ]
+  deps = [
+    ":noise_level_estimator",
+    ":test_utils",
+    "..:apm_logging",
+    "..:audio_frame_view",
+    "../../../api:array_view",
+    "../../../api:function_view",
+    "../../../rtc_base:checks",
+    "../../../rtc_base:gunit_helpers",
+    "../../../rtc_base:rtc_base_approved",
+  ]
+}
+
+rtc_library("rnn_vad_with_level_unittests") {
+  testonly = true
+  sources = [ "vad_with_level_unittest.cc" ]
+  deps = [
+    ":common",
+    ":rnn_vad_with_level",
+    "..:audio_frame_view",
+    "../../../rtc_base:gunit_helpers",
+    "../../../rtc_base:safe_compare",
+    "../../../test:test_support",
+  ]
+}
+
+rtc_library("test_utils") {
+  testonly = true
+  visibility = [
+    ":*",
+    "..:audio_processing_unittests",
+  ]
+  sources = [
+    "agc2_testing_common.cc",
+    "agc2_testing_common.h",
+    "vector_float_frame.cc",
+    "vector_float_frame.h",
+  ]
+  deps = [
+    "..:audio_frame_view",
+    "../../../rtc_base:checks",
+    "../../../rtc_base:rtc_base_approved",
+  ]
+}
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_agc.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_agc.cc
new file mode 100644
index 0000000..8bf192e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_agc.cc
@@ -0,0 +1,146 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/adaptive_agc.h"
+
+#include "common_audio/include/audio_util.h"
+#include "modules/audio_processing/agc2/cpu_features.h"
+#include "modules/audio_processing/agc2/vad_with_level.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+
+namespace webrtc {
+namespace {
+
+using AdaptiveDigitalConfig =
+    AudioProcessing::Config::GainController2::AdaptiveDigital;
+using NoiseEstimatorType =
+    AudioProcessing::Config::GainController2::NoiseEstimator;
+
+constexpr int kGainApplierAdjacentSpeechFramesThreshold = 1;
+constexpr float kMaxGainChangePerSecondDb = 3.0f;
+constexpr float kMaxOutputNoiseLevelDbfs = -50.0f;
+
+// Detects the available CPU features and applies any kill-switches.
+AvailableCpuFeatures GetAllowedCpuFeatures(
+    const AdaptiveDigitalConfig& config) {
+  AvailableCpuFeatures features = GetAvailableCpuFeatures();
+  if (!config.sse2_allowed) {
+    features.sse2 = false;
+  }
+  if (!config.avx2_allowed) {
+    features.avx2 = false;
+  }
+  if (!config.neon_allowed) {
+    features.neon = false;
+  }
+  return features;
+}
+
+std::unique_ptr<NoiseLevelEstimator> CreateNoiseLevelEstimator(
+    NoiseEstimatorType estimator_type,
+    ApmDataDumper* apm_data_dumper) {
+  switch (estimator_type) {
+    case NoiseEstimatorType::kStationaryNoise:
+      return CreateStationaryNoiseEstimator(apm_data_dumper);
+    case NoiseEstimatorType::kNoiseFloor:
+      return CreateNoiseFloorEstimator(apm_data_dumper);
+  }
+}
+
+constexpr NoiseEstimatorType kDefaultNoiseLevelEstimatorType =
+    NoiseEstimatorType::kNoiseFloor;
+
+}  // namespace
+
+AdaptiveAgc::AdaptiveAgc(ApmDataDumper* apm_data_dumper)
+    : speech_level_estimator_(apm_data_dumper),
+      gain_controller_(apm_data_dumper,
+                       kGainApplierAdjacentSpeechFramesThreshold,
+                       kMaxGainChangePerSecondDb,
+                       kMaxOutputNoiseLevelDbfs),
+      apm_data_dumper_(apm_data_dumper),
+      noise_level_estimator_(
+          CreateNoiseLevelEstimator(kDefaultNoiseLevelEstimatorType,
+                                    apm_data_dumper)),
+      saturation_protector_(
+          CreateSaturationProtector(kSaturationProtectorInitialHeadroomDb,
+                                    kSaturationProtectorExtraHeadroomDb,
+                                    kGainApplierAdjacentSpeechFramesThreshold,
+                                    apm_data_dumper)) {
+  RTC_DCHECK(apm_data_dumper);
+}
+
+AdaptiveAgc::AdaptiveAgc(ApmDataDumper* apm_data_dumper,
+                         const AdaptiveDigitalConfig& config)
+    : speech_level_estimator_(apm_data_dumper,
+                              config.adjacent_speech_frames_threshold),
+      vad_(config.vad_reset_period_ms, GetAllowedCpuFeatures(config)),
+      gain_controller_(apm_data_dumper,
+                       config.adjacent_speech_frames_threshold,
+                       config.max_gain_change_db_per_second,
+                       config.max_output_noise_level_dbfs),
+      apm_data_dumper_(apm_data_dumper),
+      noise_level_estimator_(
+          CreateNoiseLevelEstimator(config.noise_estimator, apm_data_dumper)),
+      saturation_protector_(
+          CreateSaturationProtector(kSaturationProtectorInitialHeadroomDb,
+                                    kSaturationProtectorExtraHeadroomDb,
+                                    config.adjacent_speech_frames_threshold,
+                                    apm_data_dumper)) {
+  RTC_DCHECK(apm_data_dumper);
+  RTC_DCHECK(noise_level_estimator_);
+  RTC_DCHECK(saturation_protector_);
+  if (!config.use_saturation_protector) {
+    RTC_LOG(LS_WARNING) << "The saturation protector cannot be disabled.";
+  }
+}
+
+AdaptiveAgc::~AdaptiveAgc() = default;
+
+void AdaptiveAgc::Process(AudioFrameView<float> frame, float limiter_envelope) {
+  AdaptiveDigitalGainApplier::FrameInfo info;
+
+  VadLevelAnalyzer::Result vad_result = vad_.AnalyzeFrame(frame);
+  info.speech_probability = vad_result.speech_probability;
+  apm_data_dumper_->DumpRaw("agc2_speech_probability",
+                            vad_result.speech_probability);
+  apm_data_dumper_->DumpRaw("agc2_input_rms_dbfs", vad_result.rms_dbfs);
+  apm_data_dumper_->DumpRaw("agc2_input_peak_dbfs", vad_result.peak_dbfs);
+
+  speech_level_estimator_.Update(vad_result);
+  info.speech_level_dbfs = speech_level_estimator_.level_dbfs();
+  info.speech_level_reliable = speech_level_estimator_.IsConfident();
+  apm_data_dumper_->DumpRaw("agc2_speech_level_dbfs", info.speech_level_dbfs);
+  apm_data_dumper_->DumpRaw("agc2_speech_level_reliable",
+                            info.speech_level_reliable);
+
+  info.noise_rms_dbfs = noise_level_estimator_->Analyze(frame);
+  apm_data_dumper_->DumpRaw("agc2_noise_rms_dbfs", info.noise_rms_dbfs);
+
+  saturation_protector_->Analyze(info.speech_probability, vad_result.peak_dbfs,
+                                 info.speech_level_dbfs);
+  info.headroom_db = saturation_protector_->HeadroomDb();
+  apm_data_dumper_->DumpRaw("agc2_headroom_db", info.headroom_db);
+
+  info.limiter_envelope_dbfs = FloatS16ToDbfs(limiter_envelope);
+  apm_data_dumper_->DumpRaw("agc2_limiter_envelope_dbfs",
+                            info.limiter_envelope_dbfs);
+
+  gain_controller_.Process(info, frame);
+}
+
+void AdaptiveAgc::HandleInputGainChange() {
+  speech_level_estimator_.Reset();
+  saturation_protector_->Reset();
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_agc.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_agc.h
new file mode 100644
index 0000000..fe81444
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_agc.h
@@ -0,0 +1,57 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_ADAPTIVE_AGC_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_ADAPTIVE_AGC_H_
+
+#include <memory>
+
+#include "modules/audio_processing/agc2/adaptive_digital_gain_applier.h"
+#include "modules/audio_processing/agc2/adaptive_mode_level_estimator.h"
+#include "modules/audio_processing/agc2/noise_level_estimator.h"
+#include "modules/audio_processing/agc2/saturation_protector.h"
+#include "modules/audio_processing/agc2/vad_with_level.h"
+#include "modules/audio_processing/include/audio_frame_view.h"
+#include "modules/audio_processing/include/audio_processing.h"
+
+namespace webrtc {
+class ApmDataDumper;
+
+// Adaptive digital gain controller.
+// TODO(crbug.com/webrtc/7494): Unify with `AdaptiveDigitalGainApplier`.
+class AdaptiveAgc {
+ public:
+  explicit AdaptiveAgc(ApmDataDumper* apm_data_dumper);
+  // TODO(crbug.com/webrtc/7494): Remove ctor above.
+  AdaptiveAgc(
+      ApmDataDumper* apm_data_dumper,
+      const AudioProcessing::Config::GainController2::AdaptiveDigital& config);
+  ~AdaptiveAgc();
+
+  // Analyzes `frame` and applies a digital adaptive gain to it. Takes into
+  // account the envelope measured by the limiter.
+  // TODO(crbug.com/webrtc/7494): Make the class depend on the limiter.
+  void Process(AudioFrameView<float> frame, float limiter_envelope);
+
+  // Handles a gain change applied to the input signal (e.g., analog gain).
+  void HandleInputGainChange();
+
+ private:
+  AdaptiveModeLevelEstimator speech_level_estimator_;
+  VadLevelAnalyzer vad_;
+  AdaptiveDigitalGainApplier gain_controller_;
+  ApmDataDumper* const apm_data_dumper_;
+  std::unique_ptr<NoiseLevelEstimator> noise_level_estimator_;
+  std::unique_ptr<SaturationProtector> saturation_protector_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_ADAPTIVE_AGC_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_digital_gain_applier.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_digital_gain_applier.cc
new file mode 100644
index 0000000..8a8a7fd
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_digital_gain_applier.cc
@@ -0,0 +1,206 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/adaptive_digital_gain_applier.h"
+
+#include <algorithm>
+
+#include "common_audio/include/audio_util.h"
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+#include "rtc_base/numerics/safe_minmax.h"
+#include "system_wrappers/include/metrics.h"
+
+namespace webrtc {
+namespace {
+
+constexpr int kHeadroomHistogramMin = 0;
+constexpr int kHeadroomHistogramMax = 50;
+
+// This function maps input level to desired applied gain. We want to
+// boost the signal so that peaks are at -kHeadroomDbfs. We can't
+// apply more than kMaxGainDb gain.
+float ComputeGainDb(float input_level_dbfs) {
+  // If the level is very low, boost it as much as we can.
+  if (input_level_dbfs < -(kHeadroomDbfs + kMaxGainDb)) {
+    return kMaxGainDb;
+  }
+  // We expect to end up here most of the time: the level is below
+  // -headroom, but we can boost it to -headroom.
+  if (input_level_dbfs < -kHeadroomDbfs) {
+    return -kHeadroomDbfs - input_level_dbfs;
+  }
+  // Otherwise, the level is too high and we can't boost.
+  RTC_DCHECK_GE(input_level_dbfs, -kHeadroomDbfs);
+  return 0.f;
+}
+
+// Returns `target_gain` if the output noise level is below
+// `max_output_noise_level_dbfs`; otherwise returns a capped gain so that the
+// output noise level equals `max_output_noise_level_dbfs`.
+float LimitGainByNoise(float target_gain,
+                       float input_noise_level_dbfs,
+                       float max_output_noise_level_dbfs,
+                       ApmDataDumper& apm_data_dumper) {
+  const float max_allowed_gain_db =
+      max_output_noise_level_dbfs - input_noise_level_dbfs;
+  apm_data_dumper.DumpRaw("agc2_adaptive_gain_applier_max_allowed_gain_db",
+                          max_allowed_gain_db);
+  return std::min(target_gain, std::max(max_allowed_gain_db, 0.f));
+}
+
+float LimitGainByLowConfidence(float target_gain,
+                               float last_gain,
+                               float limiter_audio_level_dbfs,
+                               bool estimate_is_confident) {
+  if (estimate_is_confident ||
+      limiter_audio_level_dbfs <= kLimiterThresholdForAgcGainDbfs) {
+    return target_gain;
+  }
+  const float limiter_level_before_gain = limiter_audio_level_dbfs - last_gain;
+
+  // Compute a new gain so that `limiter_level_before_gain` + `new_target_gain`
+  // is not great than `kLimiterThresholdForAgcGainDbfs`.
+  const float new_target_gain = std::max(
+      kLimiterThresholdForAgcGainDbfs - limiter_level_before_gain, 0.f);
+  return std::min(new_target_gain, target_gain);
+}
+
+// Computes how the gain should change during this frame.
+// Return the gain difference in db to 'last_gain_db'.
+float ComputeGainChangeThisFrameDb(float target_gain_db,
+                                   float last_gain_db,
+                                   bool gain_increase_allowed,
+                                   float max_gain_decrease_db,
+                                   float max_gain_increase_db) {
+  RTC_DCHECK_GT(max_gain_decrease_db, 0);
+  RTC_DCHECK_GT(max_gain_increase_db, 0);
+  float target_gain_difference_db = target_gain_db - last_gain_db;
+  if (!gain_increase_allowed) {
+    target_gain_difference_db = std::min(target_gain_difference_db, 0.f);
+  }
+  return rtc::SafeClamp(target_gain_difference_db, -max_gain_decrease_db,
+                        max_gain_increase_db);
+}
+
+}  // namespace
+
+AdaptiveDigitalGainApplier::AdaptiveDigitalGainApplier(
+    ApmDataDumper* apm_data_dumper,
+    int adjacent_speech_frames_threshold,
+    float max_gain_change_db_per_second,
+    float max_output_noise_level_dbfs)
+    : apm_data_dumper_(apm_data_dumper),
+      gain_applier_(
+          /*hard_clip_samples=*/false,
+          /*initial_gain_factor=*/DbToRatio(kInitialAdaptiveDigitalGainDb)),
+      adjacent_speech_frames_threshold_(adjacent_speech_frames_threshold),
+      max_gain_change_db_per_10ms_(max_gain_change_db_per_second *
+                                   kFrameDurationMs / 1000.f),
+      max_output_noise_level_dbfs_(max_output_noise_level_dbfs),
+      calls_since_last_gain_log_(0),
+      frames_to_gain_increase_allowed_(adjacent_speech_frames_threshold_),
+      last_gain_db_(kInitialAdaptiveDigitalGainDb) {
+  RTC_DCHECK_GT(max_gain_change_db_per_second, 0.f);
+  RTC_DCHECK_GE(frames_to_gain_increase_allowed_, 1);
+  RTC_DCHECK_GE(max_output_noise_level_dbfs_, -90.f);
+  RTC_DCHECK_LE(max_output_noise_level_dbfs_, 0.f);
+}
+
+void AdaptiveDigitalGainApplier::Process(const FrameInfo& info,
+                                         AudioFrameView<float> frame) {
+  RTC_DCHECK_GE(info.speech_level_dbfs, -150.f);
+  RTC_DCHECK_GE(frame.num_channels(), 1);
+  RTC_DCHECK(
+      frame.samples_per_channel() == 80 || frame.samples_per_channel() == 160 ||
+      frame.samples_per_channel() == 320 || frame.samples_per_channel() == 480)
+      << "`frame` does not look like a 10 ms frame for an APM supported sample "
+         "rate";
+
+  // Compute the input level used to select the desired gain.
+  RTC_DCHECK_GT(info.headroom_db, 0.0f);
+  const float input_level_dbfs = info.speech_level_dbfs + info.headroom_db;
+
+  const float target_gain_db = LimitGainByLowConfidence(
+      LimitGainByNoise(ComputeGainDb(input_level_dbfs), info.noise_rms_dbfs,
+                       max_output_noise_level_dbfs_, *apm_data_dumper_),
+      last_gain_db_, info.limiter_envelope_dbfs, info.speech_level_reliable);
+
+  // Forbid increasing the gain until enough adjacent speech frames are
+  // observed.
+  bool first_confident_speech_frame = false;
+  if (info.speech_probability < kVadConfidenceThreshold) {
+    frames_to_gain_increase_allowed_ = adjacent_speech_frames_threshold_;
+  } else if (frames_to_gain_increase_allowed_ > 0) {
+    frames_to_gain_increase_allowed_--;
+    first_confident_speech_frame = frames_to_gain_increase_allowed_ == 0;
+  }
+  apm_data_dumper_->DumpRaw(
+      "agc2_adaptive_gain_applier_frames_to_gain_increase_allowed",
+      frames_to_gain_increase_allowed_);
+
+  const bool gain_increase_allowed = frames_to_gain_increase_allowed_ == 0;
+
+  float max_gain_increase_db = max_gain_change_db_per_10ms_;
+  if (first_confident_speech_frame) {
+    // No gain increase happened while waiting for a long enough speech
+    // sequence. Therefore, temporarily allow a faster gain increase.
+    RTC_DCHECK(gain_increase_allowed);
+    max_gain_increase_db *= adjacent_speech_frames_threshold_;
+  }
+
+  const float gain_change_this_frame_db = ComputeGainChangeThisFrameDb(
+      target_gain_db, last_gain_db_, gain_increase_allowed,
+      /*max_gain_decrease_db=*/max_gain_change_db_per_10ms_,
+      max_gain_increase_db);
+
+  apm_data_dumper_->DumpRaw("agc2_adaptive_gain_applier_want_to_change_by_db",
+                            target_gain_db - last_gain_db_);
+  apm_data_dumper_->DumpRaw("agc2_adaptive_gain_applier_will_change_by_db",
+                            gain_change_this_frame_db);
+
+  // Optimization: avoid calling math functions if gain does not
+  // change.
+  if (gain_change_this_frame_db != 0.f) {
+    gain_applier_.SetGainFactor(
+        DbToRatio(last_gain_db_ + gain_change_this_frame_db));
+  }
+  gain_applier_.ApplyGain(frame);
+
+  // Remember that the gain has changed for the next iteration.
+  last_gain_db_ = last_gain_db_ + gain_change_this_frame_db;
+  apm_data_dumper_->DumpRaw("agc2_adaptive_gain_applier_applied_gain_db",
+                            last_gain_db_);
+
+  // Log every 10 seconds.
+  calls_since_last_gain_log_++;
+  if (calls_since_last_gain_log_ == 1000) {
+    calls_since_last_gain_log_ = 0;
+    RTC_HISTOGRAM_COUNTS_LINEAR("WebRTC.Audio.Agc2.EstimatedSpeechLevel",
+                                -info.speech_level_dbfs, 0, 100, 101);
+    RTC_HISTOGRAM_COUNTS_LINEAR("WebRTC.Audio.Agc2.EstimatedNoiseLevel",
+                                -info.noise_rms_dbfs, 0, 100, 101);
+    RTC_HISTOGRAM_COUNTS_LINEAR(
+        "WebRTC.Audio.Agc2.Headroom", info.headroom_db, kHeadroomHistogramMin,
+        kHeadroomHistogramMax,
+        kHeadroomHistogramMax - kHeadroomHistogramMin + 1);
+    RTC_HISTOGRAM_COUNTS_LINEAR("WebRTC.Audio.Agc2.DigitalGainApplied",
+                                last_gain_db_, 0, kMaxGainDb, kMaxGainDb + 1);
+    RTC_LOG(LS_INFO) << "AGC2 adaptive digital"
+                     << " | speech_dbfs: " << info.speech_level_dbfs
+                     << " | noise_dbfs: " << info.noise_rms_dbfs
+                     << " | headroom_db: " << info.headroom_db
+                     << " | gain_db: " << last_gain_db_;
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_digital_gain_applier.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_digital_gain_applier.h
new file mode 100644
index 0000000..74220fa
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_digital_gain_applier.h
@@ -0,0 +1,68 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_ADAPTIVE_DIGITAL_GAIN_APPLIER_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_ADAPTIVE_DIGITAL_GAIN_APPLIER_H_
+
+#include "modules/audio_processing/agc2/gain_applier.h"
+#include "modules/audio_processing/include/audio_frame_view.h"
+
+namespace webrtc {
+
+class ApmDataDumper;
+
+// TODO(bugs.webrtc.org): Split into `GainAdaptor` and `GainApplier`.
+// Selects the target digital gain, decides when and how quickly to adapt to the
+// target and applies the current gain to 10 ms frames.
+class AdaptiveDigitalGainApplier {
+ public:
+  // Information about a frame to process.
+  struct FrameInfo {
+    float speech_probability;     // Probability of speech in the [0, 1] range.
+    float speech_level_dbfs;      // Estimated speech level (dBFS).
+    bool speech_level_reliable;   // True with reliable speech level estimation.
+    float noise_rms_dbfs;         // Estimated noise RMS level (dBFS).
+    float headroom_db;            // Headroom (dB).
+    float limiter_envelope_dbfs;  // Envelope level from the limiter (dBFS).
+  };
+
+  // Ctor. `adjacent_speech_frames_threshold` indicates how many adjacent speech
+  // frames must be observed in order to consider the sequence as speech.
+  // `max_gain_change_db_per_second` limits the adaptation speed (uniformly
+  // operated across frames). `max_output_noise_level_dbfs` limits the output
+  // noise level.
+  AdaptiveDigitalGainApplier(ApmDataDumper* apm_data_dumper,
+                             int adjacent_speech_frames_threshold,
+                             float max_gain_change_db_per_second,
+                             float max_output_noise_level_dbfs);
+  AdaptiveDigitalGainApplier(const AdaptiveDigitalGainApplier&) = delete;
+  AdaptiveDigitalGainApplier& operator=(const AdaptiveDigitalGainApplier&) =
+      delete;
+
+  // Analyzes `info`, updates the digital gain and applies it to a 10 ms
+  // `frame`. Supports any sample rate supported by APM.
+  void Process(const FrameInfo& info, AudioFrameView<float> frame);
+
+ private:
+  ApmDataDumper* const apm_data_dumper_;
+  GainApplier gain_applier_;
+
+  const int adjacent_speech_frames_threshold_;
+  const float max_gain_change_db_per_10ms_;
+  const float max_output_noise_level_dbfs_;
+
+  int calls_since_last_gain_log_;
+  int frames_to_gain_increase_allowed_;
+  float last_gain_db_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_ADAPTIVE_DIGITAL_GAIN_APPLIER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_digital_gain_applier_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_digital_gain_applier_unittest.cc
new file mode 100644
index 0000000..ee9cb02
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_digital_gain_applier_unittest.cc
@@ -0,0 +1,273 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/adaptive_digital_gain_applier.h"
+
+#include <algorithm>
+#include <memory>
+
+#include "common_audio/include/audio_util.h"
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "modules/audio_processing/agc2/vector_float_frame.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/gunit.h"
+
+namespace webrtc {
+namespace {
+
+constexpr int kMono = 1;
+constexpr int kStereo = 2;
+constexpr int kFrameLen10ms8kHz = 80;
+constexpr int kFrameLen10ms48kHz = 480;
+
+constexpr float kMaxSpeechProbability = 1.0f;
+
+// Constants used in place of estimated noise levels.
+constexpr float kNoNoiseDbfs = kMinLevelDbfs;
+constexpr float kWithNoiseDbfs = -20.f;
+
+constexpr float kMaxGainChangePerSecondDb = 3.0f;
+constexpr float kMaxGainChangePerFrameDb =
+    kMaxGainChangePerSecondDb * kFrameDurationMs / 1000.0f;
+constexpr float kMaxOutputNoiseLevelDbfs = -50.0f;
+
+// Helper to create initialized `AdaptiveDigitalGainApplier` objects.
+struct GainApplierHelper {
+  GainApplierHelper()
+      : GainApplierHelper(/*adjacent_speech_frames_threshold=*/1) {}
+  explicit GainApplierHelper(int adjacent_speech_frames_threshold)
+      : apm_data_dumper(0),
+        gain_applier(std::make_unique<AdaptiveDigitalGainApplier>(
+            &apm_data_dumper,
+            adjacent_speech_frames_threshold,
+            kMaxGainChangePerSecondDb,
+            kMaxOutputNoiseLevelDbfs)) {}
+  ApmDataDumper apm_data_dumper;
+  std::unique_ptr<AdaptiveDigitalGainApplier> gain_applier;
+};
+
+// Voice on, no noise, low limiter, confident level.
+static_assert(std::is_trivially_destructible<
+                  AdaptiveDigitalGainApplier::FrameInfo>::value,
+              "");
+constexpr AdaptiveDigitalGainApplier::FrameInfo kFrameInfo{
+    /*speech_probability=*/kMaxSpeechProbability,
+    /*speech_level_dbfs=*/kInitialSpeechLevelEstimateDbfs,
+    /*speech_level_reliable=*/true,
+    /*noise_rms_dbfs=*/kNoNoiseDbfs,
+    /*headroom_db=*/kSaturationProtectorInitialHeadroomDb,
+    /*limiter_envelope_dbfs=*/-2.0f};
+
+TEST(GainController2AdaptiveGainApplier, GainApplierShouldNotCrash) {
+  GainApplierHelper helper;
+  // Make one call with reasonable audio level values and settings.
+  VectorFloatFrame fake_audio(kStereo, kFrameLen10ms48kHz, 10000.0f);
+  AdaptiveDigitalGainApplier::FrameInfo info = kFrameInfo;
+  info.speech_level_dbfs = -5.0f;
+  helper.gain_applier->Process(kFrameInfo, fake_audio.float_frame_view());
+}
+
+// Checks that the maximum allowed gain is applied.
+TEST(GainController2AdaptiveGainApplier, MaxGainApplied) {
+  constexpr int kNumFramesToAdapt =
+      static_cast<int>(kMaxGainDb / kMaxGainChangePerFrameDb) + 10;
+
+  GainApplierHelper helper;
+  AdaptiveDigitalGainApplier::FrameInfo info = kFrameInfo;
+  info.speech_level_dbfs = -60.0f;
+  float applied_gain;
+  for (int i = 0; i < kNumFramesToAdapt; ++i) {
+    VectorFloatFrame fake_audio(kMono, kFrameLen10ms8kHz, 1.0f);
+    helper.gain_applier->Process(info, fake_audio.float_frame_view());
+    applied_gain = fake_audio.float_frame_view().channel(0)[0];
+  }
+  const float applied_gain_db = 20.0f * std::log10f(applied_gain);
+  EXPECT_NEAR(applied_gain_db, kMaxGainDb, 0.1f);
+}
+
+TEST(GainController2AdaptiveGainApplier, GainDoesNotChangeFast) {
+  GainApplierHelper helper;
+
+  constexpr float initial_level_dbfs = -25.0f;
+  // A few extra frames for safety.
+  constexpr int kNumFramesToAdapt =
+      static_cast<int>(initial_level_dbfs / kMaxGainChangePerFrameDb) + 10;
+
+  const float kMaxChangePerFrameLinear = DbToRatio(kMaxGainChangePerFrameDb);
+
+  float last_gain_linear = 1.f;
+  for (int i = 0; i < kNumFramesToAdapt; ++i) {
+    SCOPED_TRACE(i);
+    VectorFloatFrame fake_audio(kMono, kFrameLen10ms8kHz, 1.0f);
+    AdaptiveDigitalGainApplier::FrameInfo info = kFrameInfo;
+    info.speech_level_dbfs = initial_level_dbfs;
+    helper.gain_applier->Process(info, fake_audio.float_frame_view());
+    float current_gain_linear = fake_audio.float_frame_view().channel(0)[0];
+    EXPECT_LE(std::abs(current_gain_linear - last_gain_linear),
+              kMaxChangePerFrameLinear);
+    last_gain_linear = current_gain_linear;
+  }
+
+  // Check that the same is true when gain decreases as well.
+  for (int i = 0; i < kNumFramesToAdapt; ++i) {
+    SCOPED_TRACE(i);
+    VectorFloatFrame fake_audio(kMono, kFrameLen10ms8kHz, 1.0f);
+    AdaptiveDigitalGainApplier::FrameInfo info = kFrameInfo;
+    info.speech_level_dbfs = 0.f;
+    helper.gain_applier->Process(info, fake_audio.float_frame_view());
+    float current_gain_linear = fake_audio.float_frame_view().channel(0)[0];
+    EXPECT_LE(std::abs(current_gain_linear - last_gain_linear),
+              kMaxChangePerFrameLinear);
+    last_gain_linear = current_gain_linear;
+  }
+}
+
+TEST(GainController2AdaptiveGainApplier, GainIsRampedInAFrame) {
+  GainApplierHelper helper;
+
+  constexpr float initial_level_dbfs = -25.0f;
+
+  VectorFloatFrame fake_audio(kMono, kFrameLen10ms48kHz, 1.0f);
+  AdaptiveDigitalGainApplier::FrameInfo info = kFrameInfo;
+  info.speech_level_dbfs = initial_level_dbfs;
+  helper.gain_applier->Process(info, fake_audio.float_frame_view());
+  float maximal_difference = 0.0f;
+  float current_value = 1.0f * DbToRatio(kInitialAdaptiveDigitalGainDb);
+  for (const auto& x : fake_audio.float_frame_view().channel(0)) {
+    const float difference = std::abs(x - current_value);
+    maximal_difference = std::max(maximal_difference, difference);
+    current_value = x;
+  }
+
+  const float kMaxChangePerFrameLinear = DbToRatio(kMaxGainChangePerFrameDb);
+  const float kMaxChangePerSample =
+      kMaxChangePerFrameLinear / kFrameLen10ms48kHz;
+
+  EXPECT_LE(maximal_difference, kMaxChangePerSample);
+}
+
+TEST(GainController2AdaptiveGainApplier, NoiseLimitsGain) {
+  GainApplierHelper helper;
+
+  constexpr float initial_level_dbfs = -25.0f;
+  constexpr int num_initial_frames =
+      kInitialAdaptiveDigitalGainDb / kMaxGainChangePerFrameDb;
+  constexpr int num_frames = 50;
+
+  ASSERT_GT(kWithNoiseDbfs, kMaxOutputNoiseLevelDbfs)
+      << "kWithNoiseDbfs is too low";
+
+  for (int i = 0; i < num_initial_frames + num_frames; ++i) {
+    VectorFloatFrame fake_audio(kMono, kFrameLen10ms48kHz, 1.0f);
+    AdaptiveDigitalGainApplier::FrameInfo info = kFrameInfo;
+    info.speech_level_dbfs = initial_level_dbfs;
+    info.noise_rms_dbfs = kWithNoiseDbfs;
+    helper.gain_applier->Process(info, fake_audio.float_frame_view());
+
+    // Wait so that the adaptive gain applier has time to lower the gain.
+    if (i > num_initial_frames) {
+      const float maximal_ratio =
+          *std::max_element(fake_audio.float_frame_view().channel(0).begin(),
+                            fake_audio.float_frame_view().channel(0).end());
+
+      EXPECT_NEAR(maximal_ratio, 1.0f, 0.001f);
+    }
+  }
+}
+
+TEST(GainController2GainApplier, CanHandlePositiveSpeechLevels) {
+  GainApplierHelper helper;
+
+  // Make one call with positive audio level values and settings.
+  VectorFloatFrame fake_audio(kStereo, kFrameLen10ms48kHz, 10000.0f);
+  AdaptiveDigitalGainApplier::FrameInfo info = kFrameInfo;
+  info.speech_level_dbfs = 5.0f;
+  helper.gain_applier->Process(info, fake_audio.float_frame_view());
+}
+
+TEST(GainController2GainApplier, AudioLevelLimitsGain) {
+  GainApplierHelper helper;
+
+  constexpr float initial_level_dbfs = -25.0f;
+  constexpr int num_initial_frames =
+      kInitialAdaptiveDigitalGainDb / kMaxGainChangePerFrameDb;
+  constexpr int num_frames = 50;
+
+  ASSERT_GT(kWithNoiseDbfs, kMaxOutputNoiseLevelDbfs)
+      << "kWithNoiseDbfs is too low";
+
+  for (int i = 0; i < num_initial_frames + num_frames; ++i) {
+    VectorFloatFrame fake_audio(kMono, kFrameLen10ms48kHz, 1.0f);
+    AdaptiveDigitalGainApplier::FrameInfo info = kFrameInfo;
+    info.speech_level_dbfs = initial_level_dbfs;
+    info.limiter_envelope_dbfs = 1.0f;
+    info.speech_level_reliable = false;
+    helper.gain_applier->Process(info, fake_audio.float_frame_view());
+
+    // Wait so that the adaptive gain applier has time to lower the gain.
+    if (i > num_initial_frames) {
+      const float maximal_ratio =
+          *std::max_element(fake_audio.float_frame_view().channel(0).begin(),
+                            fake_audio.float_frame_view().channel(0).end());
+
+      EXPECT_NEAR(maximal_ratio, 1.0f, 0.001f);
+    }
+  }
+}
+
+class AdaptiveDigitalGainApplierTest : public ::testing::TestWithParam<int> {
+ protected:
+  int AdjacentSpeechFramesThreshold() const { return GetParam(); }
+};
+
+TEST_P(AdaptiveDigitalGainApplierTest,
+       DoNotIncreaseGainWithTooFewSpeechFrames) {
+  const int adjacent_speech_frames_threshold = AdjacentSpeechFramesThreshold();
+  GainApplierHelper helper(adjacent_speech_frames_threshold);
+
+  float prev_gain = 0.0f;
+  for (int i = 0; i < adjacent_speech_frames_threshold; ++i) {
+    SCOPED_TRACE(i);
+    VectorFloatFrame audio(kMono, kFrameLen10ms48kHz, 1.0f);
+    helper.gain_applier->Process(kFrameInfo, audio.float_frame_view());
+    const float gain = audio.float_frame_view().channel(0)[0];
+    if (i > 0) {
+      EXPECT_EQ(prev_gain, gain);  // No gain increase.
+    }
+    prev_gain = gain;
+  }
+}
+
+TEST_P(AdaptiveDigitalGainApplierTest, IncreaseGainWithEnoughSpeechFrames) {
+  const int adjacent_speech_frames_threshold = AdjacentSpeechFramesThreshold();
+  GainApplierHelper helper(adjacent_speech_frames_threshold);
+
+  float prev_gain = 0.0f;
+  for (int i = 0; i < adjacent_speech_frames_threshold; ++i) {
+    SCOPED_TRACE(i);
+    VectorFloatFrame audio(kMono, kFrameLen10ms48kHz, 1.0f);
+    helper.gain_applier->Process(kFrameInfo, audio.float_frame_view());
+    prev_gain = audio.float_frame_view().channel(0)[0];
+  }
+
+  // Process one more speech frame.
+  VectorFloatFrame audio(kMono, kFrameLen10ms48kHz, 1.0f);
+  helper.gain_applier->Process(kFrameInfo, audio.float_frame_view());
+
+  // The gain has increased.
+  EXPECT_GT(audio.float_frame_view().channel(0)[0], prev_gain);
+}
+
+INSTANTIATE_TEST_SUITE_P(GainController2,
+                         AdaptiveDigitalGainApplierTest,
+                         ::testing::Values(1, 7, 31));
+
+}  // namespace
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_mode_level_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_mode_level_estimator.cc
new file mode 100644
index 0000000..507aa12
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_mode_level_estimator.cc
@@ -0,0 +1,163 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/adaptive_mode_level_estimator.h"
+
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+#include "rtc_base/numerics/safe_minmax.h"
+
+namespace webrtc {
+namespace {
+
+using LevelEstimatorType =
+    AudioProcessing::Config::GainController2::LevelEstimator;
+
+float ClampLevelEstimateDbfs(float level_estimate_dbfs) {
+  return rtc::SafeClamp<float>(level_estimate_dbfs, -90.f, 30.f);
+}
+
+}  // namespace
+
+bool AdaptiveModeLevelEstimator::LevelEstimatorState::operator==(
+    const AdaptiveModeLevelEstimator::LevelEstimatorState& b) const {
+  return time_to_confidence_ms == b.time_to_confidence_ms &&
+         level_dbfs.numerator == b.level_dbfs.numerator &&
+         level_dbfs.denominator == b.level_dbfs.denominator;
+}
+
+float AdaptiveModeLevelEstimator::LevelEstimatorState::Ratio::GetRatio() const {
+  RTC_DCHECK_NE(denominator, 0.f);
+  return numerator / denominator;
+}
+
+AdaptiveModeLevelEstimator::AdaptiveModeLevelEstimator(
+    ApmDataDumper* apm_data_dumper)
+    : AdaptiveModeLevelEstimator(
+          apm_data_dumper,
+          kDefaultLevelEstimatorAdjacentSpeechFramesThreshold) {}
+
+AdaptiveModeLevelEstimator::AdaptiveModeLevelEstimator(
+    ApmDataDumper* apm_data_dumper,
+    int adjacent_speech_frames_threshold)
+    : apm_data_dumper_(apm_data_dumper),
+      adjacent_speech_frames_threshold_(adjacent_speech_frames_threshold),
+      level_dbfs_(ClampLevelEstimateDbfs(kInitialSpeechLevelEstimateDbfs)) {
+  RTC_DCHECK(apm_data_dumper_);
+  RTC_DCHECK_GE(adjacent_speech_frames_threshold_, 1);
+  Reset();
+}
+
+void AdaptiveModeLevelEstimator::Update(
+    const VadLevelAnalyzer::Result& vad_level) {
+  RTC_DCHECK_GT(vad_level.rms_dbfs, -150.f);
+  RTC_DCHECK_LT(vad_level.rms_dbfs, 50.f);
+  RTC_DCHECK_GT(vad_level.peak_dbfs, -150.f);
+  RTC_DCHECK_LT(vad_level.peak_dbfs, 50.f);
+  RTC_DCHECK_GE(vad_level.speech_probability, 0.f);
+  RTC_DCHECK_LE(vad_level.speech_probability, 1.f);
+  if (vad_level.speech_probability < kVadConfidenceThreshold) {
+    // Not a speech frame.
+    if (adjacent_speech_frames_threshold_ > 1) {
+      // When two or more adjacent speech frames are required in order to update
+      // the state, we need to decide whether to discard or confirm the updates
+      // based on the speech sequence length.
+      if (num_adjacent_speech_frames_ >= adjacent_speech_frames_threshold_) {
+        // First non-speech frame after a long enough sequence of speech frames.
+        // Update the reliable state.
+        reliable_state_ = preliminary_state_;
+      } else if (num_adjacent_speech_frames_ > 0) {
+        // First non-speech frame after a too short sequence of speech frames.
+        // Reset to the last reliable state.
+        preliminary_state_ = reliable_state_;
+      }
+    }
+    num_adjacent_speech_frames_ = 0;
+  } else {
+    // Speech frame observed.
+    num_adjacent_speech_frames_++;
+
+    // Update preliminary level estimate.
+    RTC_DCHECK_GE(preliminary_state_.time_to_confidence_ms, 0);
+    const bool buffer_is_full = preliminary_state_.time_to_confidence_ms == 0;
+    if (!buffer_is_full) {
+      preliminary_state_.time_to_confidence_ms -= kFrameDurationMs;
+    }
+    // Weighted average of levels with speech probability as weight.
+    RTC_DCHECK_GT(vad_level.speech_probability, 0.f);
+    const float leak_factor = buffer_is_full ? kLevelEstimatorLeakFactor : 1.f;
+    preliminary_state_.level_dbfs.numerator =
+        preliminary_state_.level_dbfs.numerator * leak_factor +
+        vad_level.rms_dbfs * vad_level.speech_probability;
+    preliminary_state_.level_dbfs.denominator =
+        preliminary_state_.level_dbfs.denominator * leak_factor +
+        vad_level.speech_probability;
+
+    const float level_dbfs = preliminary_state_.level_dbfs.GetRatio();
+
+    if (num_adjacent_speech_frames_ >= adjacent_speech_frames_threshold_) {
+      // `preliminary_state_` is now reliable. Update the last level estimation.
+      level_dbfs_ = ClampLevelEstimateDbfs(level_dbfs);
+    }
+  }
+  DumpDebugData();
+}
+
+bool AdaptiveModeLevelEstimator::IsConfident() const {
+  if (adjacent_speech_frames_threshold_ == 1) {
+    // Ignore `reliable_state_` when a single frame is enough to update the
+    // level estimate (because it is not used).
+    return preliminary_state_.time_to_confidence_ms == 0;
+  }
+  // Once confident, it remains confident.
+  RTC_DCHECK(reliable_state_.time_to_confidence_ms != 0 ||
+             preliminary_state_.time_to_confidence_ms == 0);
+  // During the first long enough speech sequence, `reliable_state_` must be
+  // ignored since `preliminary_state_` is used.
+  return reliable_state_.time_to_confidence_ms == 0 ||
+         (num_adjacent_speech_frames_ >= adjacent_speech_frames_threshold_ &&
+          preliminary_state_.time_to_confidence_ms == 0);
+}
+
+void AdaptiveModeLevelEstimator::Reset() {
+  ResetLevelEstimatorState(preliminary_state_);
+  ResetLevelEstimatorState(reliable_state_);
+  level_dbfs_ = ClampLevelEstimateDbfs(kInitialSpeechLevelEstimateDbfs);
+  num_adjacent_speech_frames_ = 0;
+}
+
+void AdaptiveModeLevelEstimator::ResetLevelEstimatorState(
+    LevelEstimatorState& state) const {
+  state.time_to_confidence_ms = kLevelEstimatorTimeToConfidenceMs;
+  state.level_dbfs.numerator = kInitialSpeechLevelEstimateDbfs;
+  state.level_dbfs.denominator = 1.0f;
+}
+
+void AdaptiveModeLevelEstimator::DumpDebugData() const {
+  apm_data_dumper_->DumpRaw(
+      "agc2_adaptive_level_estimator_num_adjacent_speech_frames",
+      num_adjacent_speech_frames_);
+  apm_data_dumper_->DumpRaw(
+      "agc2_adaptive_level_estimator_preliminary_level_estimate_num",
+      preliminary_state_.level_dbfs.numerator);
+  apm_data_dumper_->DumpRaw(
+      "agc2_adaptive_level_estimator_preliminary_level_estimate_den",
+      preliminary_state_.level_dbfs.denominator);
+  apm_data_dumper_->DumpRaw(
+      "agc2_adaptive_level_estimator_preliminary_time_to_confidence_ms",
+      preliminary_state_.time_to_confidence_ms);
+  apm_data_dumper_->DumpRaw(
+      "agc2_adaptive_level_estimator_reliable_time_to_confidence_ms",
+      reliable_state_.time_to_confidence_ms);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_mode_level_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_mode_level_estimator.h
new file mode 100644
index 0000000..6d44938
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_mode_level_estimator.h
@@ -0,0 +1,76 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_ADAPTIVE_MODE_LEVEL_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_ADAPTIVE_MODE_LEVEL_ESTIMATOR_H_
+
+#include <stddef.h>
+#include <type_traits>
+
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "modules/audio_processing/agc2/vad_with_level.h"
+#include "modules/audio_processing/include/audio_processing.h"
+
+namespace webrtc {
+class ApmDataDumper;
+
+// Level estimator for the digital adaptive gain controller.
+class AdaptiveModeLevelEstimator {
+ public:
+  explicit AdaptiveModeLevelEstimator(ApmDataDumper* apm_data_dumper);
+  AdaptiveModeLevelEstimator(const AdaptiveModeLevelEstimator&) = delete;
+  AdaptiveModeLevelEstimator& operator=(const AdaptiveModeLevelEstimator&) =
+      delete;
+  AdaptiveModeLevelEstimator(ApmDataDumper* apm_data_dumper,
+                             int adjacent_speech_frames_threshold);
+
+  // Updates the level estimation.
+  void Update(const VadLevelAnalyzer::Result& vad_data);
+  // Returns the estimated speech plus noise level.
+  float level_dbfs() const { return level_dbfs_; }
+  // Returns true if the estimator is confident on its current estimate.
+  bool IsConfident() const;
+
+  void Reset();
+
+ private:
+  // Part of the level estimator state used for check-pointing and restore ops.
+  struct LevelEstimatorState {
+    bool operator==(const LevelEstimatorState& s) const;
+    inline bool operator!=(const LevelEstimatorState& s) const {
+      return !(*this == s);
+    }
+    struct Ratio {
+      float numerator;
+      float denominator;
+      float GetRatio() const;
+    };
+    // TODO(crbug.com/webrtc/7494): Remove time_to_confidence_ms if redundant.
+    int time_to_confidence_ms;
+    Ratio level_dbfs;
+  };
+  static_assert(std::is_trivially_copyable<LevelEstimatorState>::value, "");
+
+  void ResetLevelEstimatorState(LevelEstimatorState& state) const;
+
+  void DumpDebugData() const;
+
+  ApmDataDumper* const apm_data_dumper_;
+
+  const int adjacent_speech_frames_threshold_;
+  LevelEstimatorState preliminary_state_;
+  LevelEstimatorState reliable_state_;
+  float level_dbfs_;
+  int num_adjacent_speech_frames_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_ADAPTIVE_MODE_LEVEL_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_mode_level_estimator_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_mode_level_estimator_unittest.cc
new file mode 100644
index 0000000..c55950a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/adaptive_mode_level_estimator_unittest.cc
@@ -0,0 +1,202 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/adaptive_mode_level_estimator.h"
+
+#include <memory>
+
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/gunit.h"
+
+namespace webrtc {
+namespace {
+
+// Number of speech frames that the level estimator must observe in order to
+// become confident about the estimated level.
+constexpr int kNumFramesToConfidence =
+    kLevelEstimatorTimeToConfidenceMs / kFrameDurationMs;
+static_assert(kNumFramesToConfidence > 0, "");
+
+// Fake levels and speech probabilities used in the tests.
+static_assert(kInitialSpeechLevelEstimateDbfs < 0.0f, "");
+constexpr float kVadLevelRms = kInitialSpeechLevelEstimateDbfs / 2.0f;
+constexpr float kVadLevelPeak = kInitialSpeechLevelEstimateDbfs / 3.0f;
+static_assert(kVadLevelRms < kVadLevelPeak, "");
+static_assert(kVadLevelRms > kInitialSpeechLevelEstimateDbfs, "");
+static_assert(kVadLevelRms - kInitialSpeechLevelEstimateDbfs > 5.0f,
+              "Adjust `kVadLevelRms` so that the difference from the initial "
+              "level is wide enough for the tests.");
+
+constexpr VadLevelAnalyzer::Result kVadDataSpeech{/*speech_probability=*/1.0f,
+                                                  kVadLevelRms, kVadLevelPeak};
+constexpr VadLevelAnalyzer::Result kVadDataNonSpeech{
+    /*speech_probability=*/kVadConfidenceThreshold / 2.0f, kVadLevelRms,
+    kVadLevelPeak};
+
+constexpr float kMinSpeechProbability = 0.0f;
+constexpr float kMaxSpeechProbability = 1.0f;
+
+constexpr float kConvergenceSpeedTestsLevelTolerance = 0.5f;
+
+// Provides the `vad_level` value `num_iterations` times to `level_estimator`.
+void RunOnConstantLevel(int num_iterations,
+                        const VadLevelAnalyzer::Result& vad_level,
+                        AdaptiveModeLevelEstimator& level_estimator) {
+  for (int i = 0; i < num_iterations; ++i) {
+    level_estimator.Update(vad_level);
+  }
+}
+
+// Level estimator with data dumper.
+struct TestLevelEstimator {
+  TestLevelEstimator()
+      : data_dumper(0),
+        estimator(std::make_unique<AdaptiveModeLevelEstimator>(
+            &data_dumper,
+            /*adjacent_speech_frames_threshold=*/1)) {}
+  ApmDataDumper data_dumper;
+  std::unique_ptr<AdaptiveModeLevelEstimator> estimator;
+};
+
+// Checks the initially estimated level.
+TEST(GainController2AdaptiveModeLevelEstimator, CheckInitialEstimate) {
+  TestLevelEstimator level_estimator;
+  EXPECT_FLOAT_EQ(level_estimator.estimator->level_dbfs(),
+                  kInitialSpeechLevelEstimateDbfs);
+}
+
+// Checks that the level estimator converges to a constant input speech level.
+TEST(GainController2AdaptiveModeLevelEstimator, LevelStabilizes) {
+  TestLevelEstimator level_estimator;
+  RunOnConstantLevel(/*num_iterations=*/kNumFramesToConfidence, kVadDataSpeech,
+                     *level_estimator.estimator);
+  const float estimated_level_dbfs = level_estimator.estimator->level_dbfs();
+  RunOnConstantLevel(/*num_iterations=*/1, kVadDataSpeech,
+                     *level_estimator.estimator);
+  EXPECT_NEAR(level_estimator.estimator->level_dbfs(), estimated_level_dbfs,
+              0.1f);
+}
+
+// Checks that the level controller does not become confident when too few
+// speech frames are observed.
+TEST(GainController2AdaptiveModeLevelEstimator, IsNotConfident) {
+  TestLevelEstimator level_estimator;
+  RunOnConstantLevel(/*num_iterations=*/kNumFramesToConfidence / 2,
+                     kVadDataSpeech, *level_estimator.estimator);
+  EXPECT_FALSE(level_estimator.estimator->IsConfident());
+}
+
+// Checks that the level controller becomes confident when enough speech frames
+// are observed.
+TEST(GainController2AdaptiveModeLevelEstimator, IsConfident) {
+  TestLevelEstimator level_estimator;
+  RunOnConstantLevel(/*num_iterations=*/kNumFramesToConfidence, kVadDataSpeech,
+                     *level_estimator.estimator);
+  EXPECT_TRUE(level_estimator.estimator->IsConfident());
+}
+
+// Checks that the estimated level is not affected by the level of non-speech
+// frames.
+TEST(GainController2AdaptiveModeLevelEstimator,
+     EstimatorIgnoresNonSpeechFrames) {
+  TestLevelEstimator level_estimator;
+  // Simulate speech.
+  RunOnConstantLevel(/*num_iterations=*/kNumFramesToConfidence, kVadDataSpeech,
+                     *level_estimator.estimator);
+  const float estimated_level_dbfs = level_estimator.estimator->level_dbfs();
+  // Simulate full-scale non-speech.
+  RunOnConstantLevel(/*num_iterations=*/kNumFramesToConfidence,
+                     VadLevelAnalyzer::Result{kMinSpeechProbability,
+                                              /*rms_dbfs=*/0.0f,
+                                              /*peak_dbfs=*/0.0f},
+                     *level_estimator.estimator);
+  // No estimated level change is expected.
+  EXPECT_FLOAT_EQ(level_estimator.estimator->level_dbfs(),
+                  estimated_level_dbfs);
+}
+
+// Checks the convergence speed of the estimator before it becomes confident.
+TEST(GainController2AdaptiveModeLevelEstimator,
+     ConvergenceSpeedBeforeConfidence) {
+  TestLevelEstimator level_estimator;
+  RunOnConstantLevel(/*num_iterations=*/kNumFramesToConfidence, kVadDataSpeech,
+                     *level_estimator.estimator);
+  EXPECT_NEAR(level_estimator.estimator->level_dbfs(), kVadDataSpeech.rms_dbfs,
+              kConvergenceSpeedTestsLevelTolerance);
+}
+
+// Checks the convergence speed of the estimator after it becomes confident.
+TEST(GainController2AdaptiveModeLevelEstimator,
+     ConvergenceSpeedAfterConfidence) {
+  TestLevelEstimator level_estimator;
+  // Reach confidence using the initial level estimate.
+  RunOnConstantLevel(
+      /*num_iterations=*/kNumFramesToConfidence,
+      VadLevelAnalyzer::Result{
+          kMaxSpeechProbability,
+          /*rms_dbfs=*/kInitialSpeechLevelEstimateDbfs,
+          /*peak_dbfs=*/kInitialSpeechLevelEstimateDbfs + 6.0f},
+      *level_estimator.estimator);
+  // No estimate change should occur, but confidence is achieved.
+  ASSERT_FLOAT_EQ(level_estimator.estimator->level_dbfs(),
+                  kInitialSpeechLevelEstimateDbfs);
+  ASSERT_TRUE(level_estimator.estimator->IsConfident());
+  // After confidence.
+  constexpr float kConvergenceTimeAfterConfidenceNumFrames = 600;  // 6 seconds.
+  static_assert(
+      kConvergenceTimeAfterConfidenceNumFrames > kNumFramesToConfidence, "");
+  RunOnConstantLevel(
+      /*num_iterations=*/kConvergenceTimeAfterConfidenceNumFrames,
+      kVadDataSpeech, *level_estimator.estimator);
+  EXPECT_NEAR(level_estimator.estimator->level_dbfs(), kVadDataSpeech.rms_dbfs,
+              kConvergenceSpeedTestsLevelTolerance);
+}
+
+class AdaptiveModeLevelEstimatorParametrization
+    : public ::testing::TestWithParam<int> {
+ protected:
+  int adjacent_speech_frames_threshold() const { return GetParam(); }
+};
+
+TEST_P(AdaptiveModeLevelEstimatorParametrization,
+       DoNotAdaptToShortSpeechSegments) {
+  ApmDataDumper apm_data_dumper(0);
+  AdaptiveModeLevelEstimator level_estimator(
+      &apm_data_dumper, adjacent_speech_frames_threshold());
+  const float initial_level = level_estimator.level_dbfs();
+  ASSERT_LT(initial_level, kVadDataSpeech.peak_dbfs);
+  for (int i = 0; i < adjacent_speech_frames_threshold() - 1; ++i) {
+    SCOPED_TRACE(i);
+    level_estimator.Update(kVadDataSpeech);
+    EXPECT_EQ(initial_level, level_estimator.level_dbfs());
+  }
+  level_estimator.Update(kVadDataNonSpeech);
+  EXPECT_EQ(initial_level, level_estimator.level_dbfs());
+}
+
+TEST_P(AdaptiveModeLevelEstimatorParametrization, AdaptToEnoughSpeechSegments) {
+  ApmDataDumper apm_data_dumper(0);
+  AdaptiveModeLevelEstimator level_estimator(
+      &apm_data_dumper, adjacent_speech_frames_threshold());
+  const float initial_level = level_estimator.level_dbfs();
+  ASSERT_LT(initial_level, kVadDataSpeech.peak_dbfs);
+  for (int i = 0; i < adjacent_speech_frames_threshold(); ++i) {
+    level_estimator.Update(kVadDataSpeech);
+  }
+  EXPECT_LT(initial_level, level_estimator.level_dbfs());
+}
+
+INSTANTIATE_TEST_SUITE_P(GainController2,
+                         AdaptiveModeLevelEstimatorParametrization,
+                         ::testing::Values(1, 9, 17));
+
+}  // namespace
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/agc2_common.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/agc2_common.h
new file mode 100644
index 0000000..0f806d3
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/agc2_common.h
@@ -0,0 +1,73 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_AGC2_COMMON_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_AGC2_COMMON_H_
+
+namespace webrtc {
+
+constexpr float kMinFloatS16Value = -32768.0f;
+constexpr float kMaxFloatS16Value = 32767.0f;
+constexpr float kMaxAbsFloatS16Value = 32768.0f;
+
+// Minimum audio level in dBFS scale for S16 samples.
+constexpr float kMinLevelDbfs = -90.31f;
+
+constexpr int kFrameDurationMs = 10;
+constexpr int kSubFramesInFrame = 20;
+constexpr int kMaximalNumberOfSamplesPerChannel = 480;
+
+// Adaptive digital gain applier settings below.
+constexpr float kHeadroomDbfs = 1.0f;
+constexpr float kMaxGainDb = 30.0f;
+constexpr float kInitialAdaptiveDigitalGainDb = 8.0f;
+// At what limiter levels should we start decreasing the adaptive digital gain.
+constexpr float kLimiterThresholdForAgcGainDbfs = -kHeadroomDbfs;
+
+// This is the threshold for speech. Speech frames are used for updating the
+// speech level, measuring the amount of speech, and decide when to allow target
+// gain reduction.
+constexpr float kVadConfidenceThreshold = 0.95f;
+
+// Adaptive digital level estimator parameters.
+// Number of milliseconds of speech frames to observe to make the estimator
+// confident.
+constexpr float kLevelEstimatorTimeToConfidenceMs = 400;
+constexpr float kLevelEstimatorLeakFactor =
+    1.0f - 1.0f / kLevelEstimatorTimeToConfidenceMs;
+
+// Robust VAD probability and speech decisions.
+constexpr int kDefaultVadRnnResetPeriodMs = 1500;
+static_assert(kDefaultVadRnnResetPeriodMs % kFrameDurationMs == 0, "");
+constexpr int kDefaultLevelEstimatorAdjacentSpeechFramesThreshold = 12;
+
+// Saturation Protector settings.
+constexpr float kSaturationProtectorInitialHeadroomDb = 20.0f;
+constexpr float kSaturationProtectorExtraHeadroomDb = 5.0f;
+constexpr int kSaturationProtectorBufferSize = 4;
+
+// Set the initial speech level estimate so that `kInitialAdaptiveDigitalGainDb`
+// is applied at the beginning of the call.
+constexpr float kInitialSpeechLevelEstimateDbfs =
+    -kSaturationProtectorExtraHeadroomDb -
+    kSaturationProtectorInitialHeadroomDb - kInitialAdaptiveDigitalGainDb -
+    kHeadroomDbfs;
+
+// Number of interpolation points for each region of the limiter.
+// These values have been tuned to limit the interpolated gain curve error given
+// the limiter parameters and allowing a maximum error of +/- 32768^-1.
+constexpr int kInterpolatedGainCurveKneePoints = 22;
+constexpr int kInterpolatedGainCurveBeyondKneePoints = 10;
+constexpr int kInterpolatedGainCurveTotalPoints =
+    kInterpolatedGainCurveKneePoints + kInterpolatedGainCurveBeyondKneePoints;
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_AGC2_COMMON_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/agc2_testing_common.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/agc2_testing_common.cc
new file mode 100644
index 0000000..125e551
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/agc2_testing_common.cc
@@ -0,0 +1,93 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/agc2_testing_common.h"
+
+#include <cmath>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace test {
+
+std::vector<double> LinSpace(double l, double r, int num_points) {
+  RTC_CHECK_GE(num_points, 2);
+  std::vector<double> points(num_points);
+  const double step = (r - l) / (num_points - 1.0);
+  points[0] = l;
+  for (int i = 1; i < num_points - 1; i++) {
+    points[i] = static_cast<double>(l) + i * step;
+  }
+  points[num_points - 1] = r;
+  return points;
+}
+
+WhiteNoiseGenerator::WhiteNoiseGenerator(int min_amplitude, int max_amplitude)
+    : rand_gen_(42),
+      min_amplitude_(min_amplitude),
+      max_amplitude_(max_amplitude) {
+  RTC_DCHECK_LT(min_amplitude_, max_amplitude_);
+  RTC_DCHECK_LE(kMinS16, min_amplitude_);
+  RTC_DCHECK_LE(min_amplitude_, kMaxS16);
+  RTC_DCHECK_LE(kMinS16, max_amplitude_);
+  RTC_DCHECK_LE(max_amplitude_, kMaxS16);
+}
+
+float WhiteNoiseGenerator::operator()() {
+  return static_cast<float>(rand_gen_.Rand(min_amplitude_, max_amplitude_));
+}
+
+SineGenerator::SineGenerator(float amplitude,
+                             float frequency_hz,
+                             int sample_rate_hz)
+    : amplitude_(amplitude),
+      frequency_hz_(frequency_hz),
+      sample_rate_hz_(sample_rate_hz),
+      x_radians_(0.0f) {
+  RTC_DCHECK_GT(amplitude_, 0);
+  RTC_DCHECK_LE(amplitude_, kMaxS16);
+}
+
+float SineGenerator::operator()() {
+  constexpr float kPi = 3.1415926536f;
+  x_radians_ += frequency_hz_ / sample_rate_hz_ * 2 * kPi;
+  if (x_radians_ >= 2 * kPi) {
+    x_radians_ -= 2 * kPi;
+  }
+  return amplitude_ * std::sinf(x_radians_);
+}
+
+PulseGenerator::PulseGenerator(float pulse_amplitude,
+                               float no_pulse_amplitude,
+                               float frequency_hz,
+                               int sample_rate_hz)
+    : pulse_amplitude_(pulse_amplitude),
+      no_pulse_amplitude_(no_pulse_amplitude),
+      samples_period_(
+          static_cast<int>(static_cast<float>(sample_rate_hz) / frequency_hz)),
+      sample_counter_(0) {
+  RTC_DCHECK_GE(pulse_amplitude_, kMinS16);
+  RTC_DCHECK_LE(pulse_amplitude_, kMaxS16);
+  RTC_DCHECK_GT(no_pulse_amplitude_, kMinS16);
+  RTC_DCHECK_LE(no_pulse_amplitude_, kMaxS16);
+  RTC_DCHECK_GT(sample_rate_hz, frequency_hz);
+}
+
+float PulseGenerator::operator()() {
+  sample_counter_++;
+  if (sample_counter_ >= samples_period_) {
+    sample_counter_ -= samples_period_;
+  }
+  return static_cast<float>(sample_counter_ == 0 ? pulse_amplitude_
+                                                 : no_pulse_amplitude_);
+}
+
+}  // namespace test
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/agc2_testing_common.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/agc2_testing_common.h
new file mode 100644
index 0000000..4572d9c
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/agc2_testing_common.h
@@ -0,0 +1,82 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_AGC2_TESTING_COMMON_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_AGC2_TESTING_COMMON_H_
+
+#include <limits>
+#include <vector>
+
+#include "rtc_base/random.h"
+
+namespace webrtc {
+namespace test {
+
+constexpr float kMinS16 =
+    static_cast<float>(std::numeric_limits<int16_t>::min());
+constexpr float kMaxS16 =
+    static_cast<float>(std::numeric_limits<int16_t>::max());
+
+// Level Estimator test parameters.
+constexpr float kDecayMs = 500.f;
+
+// Limiter parameters.
+constexpr float kLimiterMaxInputLevelDbFs = 1.f;
+constexpr float kLimiterKneeSmoothnessDb = 1.f;
+constexpr float kLimiterCompressionRatio = 5.f;
+
+// Returns evenly spaced `num_points` numbers over a specified interval [l, r].
+std::vector<double> LinSpace(double l, double r, int num_points);
+
+// Generates white noise.
+class WhiteNoiseGenerator {
+ public:
+  WhiteNoiseGenerator(int min_amplitude, int max_amplitude);
+  float operator()();
+
+ private:
+  Random rand_gen_;
+  const int min_amplitude_;
+  const int max_amplitude_;
+};
+
+// Generates a sine function.
+class SineGenerator {
+ public:
+  SineGenerator(float amplitude, float frequency_hz, int sample_rate_hz);
+  float operator()();
+
+ private:
+  const float amplitude_;
+  const float frequency_hz_;
+  const int sample_rate_hz_;
+  float x_radians_;
+};
+
+// Generates periodic pulses.
+class PulseGenerator {
+ public:
+  PulseGenerator(float pulse_amplitude,
+                 float no_pulse_amplitude,
+                 float frequency_hz,
+                 int sample_rate_hz);
+  float operator()();
+
+ private:
+  const float pulse_amplitude_;
+  const float no_pulse_amplitude_;
+  const int samples_period_;
+  int sample_counter_;
+};
+
+}  // namespace test
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_AGC2_TESTING_COMMON_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/agc2_testing_common_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/agc2_testing_common_unittest.cc
new file mode 100644
index 0000000..79c3cc9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/agc2_testing_common_unittest.cc
@@ -0,0 +1,27 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/agc2_testing_common.h"
+
+#include "rtc_base/gunit.h"
+
+namespace webrtc {
+
+TEST(GainController2TestingCommon, LinSpace) {
+  std::vector<double> points1 = test::LinSpace(-1.0, 2.0, 4);
+  const std::vector<double> expected_points1{{-1.0, 0.0, 1.0, 2.0}};
+  EXPECT_EQ(expected_points1, points1);
+
+  std::vector<double> points2 = test::LinSpace(0.0, 1.0, 4);
+  const std::vector<double> expected_points2{{0.0, 1.0 / 3.0, 2.0 / 3.0, 1.0}};
+  EXPECT_EQ(points2, expected_points2);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/biquad_filter.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/biquad_filter.cc
new file mode 100644
index 0000000..da8557c
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/biquad_filter.cc
@@ -0,0 +1,36 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/biquad_filter.h"
+
+#include <stddef.h>
+
+namespace webrtc {
+
+// Transposed direct form I implementation of a bi-quad filter applied to an
+// input signal |x| to produce an output signal |y|.
+void BiQuadFilter::Process(rtc::ArrayView<const float> x,
+                           rtc::ArrayView<float> y) {
+  for (size_t k = 0; k < x.size(); ++k) {
+    // Use temporary variable for x[k] to allow in-place function call
+    // (that x and y refer to the same array).
+    const float tmp = x[k];
+    y[k] = coefficients_.b[0] * tmp + coefficients_.b[1] * biquad_state_.b[0] +
+           coefficients_.b[2] * biquad_state_.b[1] -
+           coefficients_.a[0] * biquad_state_.a[0] -
+           coefficients_.a[1] * biquad_state_.a[1];
+    biquad_state_.b[1] = biquad_state_.b[0];
+    biquad_state_.b[0] = tmp;
+    biquad_state_.a[1] = biquad_state_.a[0];
+    biquad_state_.a[0] = y[k];
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/biquad_filter.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/biquad_filter.h
new file mode 100644
index 0000000..7bf3301
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/biquad_filter.h
@@ -0,0 +1,66 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_BIQUAD_FILTER_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_BIQUAD_FILTER_H_
+
+#include <algorithm>
+
+#include "api/array_view.h"
+#include "rtc_base/arraysize.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+class BiQuadFilter {
+ public:
+  // Normalized filter coefficients.
+  //        b_0 + b_1  z^(-1) + b_2  z^(-2)
+  // H(z) = ---------------------------------
+  //         1 + a_1  z^(-1) + a_2  z^(-2)
+  struct BiQuadCoefficients {
+    float b[3];
+    float a[2];
+  };
+
+  BiQuadFilter() = default;
+
+  void Initialize(const BiQuadCoefficients& coefficients) {
+    coefficients_ = coefficients;
+  }
+
+  void Reset() { biquad_state_.Reset(); }
+
+  // Produces a filtered output y of the input x. Both x and y need to
+  // have the same length. In-place modification is allowed.
+  void Process(rtc::ArrayView<const float> x, rtc::ArrayView<float> y);
+
+ private:
+  struct BiQuadState {
+    BiQuadState() { Reset(); }
+
+    void Reset() {
+      std::fill(b, b + arraysize(b), 0.f);
+      std::fill(a, a + arraysize(a), 0.f);
+    }
+
+    float b[2];
+    float a[2];
+  };
+
+  BiQuadState biquad_state_;
+  BiQuadCoefficients coefficients_;
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(BiQuadFilter);
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_BIQUAD_FILTER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/biquad_filter_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/biquad_filter_unittest.cc
new file mode 100644
index 0000000..cd9a272
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/biquad_filter_unittest.cc
@@ -0,0 +1,136 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/biquad_filter.h"
+
+#include <algorithm>
+#include <array>
+#include <cmath>
+
+// TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+// #include "test/fpe_observer.h"
+#include "rtc_base/gunit.h"
+
+namespace webrtc {
+namespace test {
+namespace {
+
+constexpr size_t kFrameSize = 8;
+constexpr size_t kNumFrames = 4;
+using FloatArraySequence =
+    std::array<std::array<float, kFrameSize>, kNumFrames>;
+
+constexpr FloatArraySequence kBiQuadInputSeq = {
+    {{{-87.166290f, -8.029022f, 101.619583f, -0.294296f, -5.825764f, -8.890625f,
+       10.310432f, 54.845333f}},
+     {{-64.647644f, -6.883945f, 11.059189f, -95.242538f, -108.870834f,
+       11.024944f, 63.044102f, -52.709583f}},
+     {{-32.350529f, -18.108028f, -74.022339f, -8.986874f, -1.525581f,
+       103.705513f, 6.346226f, -14.319557f}},
+     {{22.645832f, -64.597153f, 55.462521f, -109.393188f, 10.117825f,
+       -40.019642f, -98.612228f, -8.330326f}}}};
+
+// Generated via "B, A = scipy.signal.butter(2, 30/12000, btype='highpass')"
+const BiQuadFilter::BiQuadCoefficients kBiQuadConfig = {
+    {0.99446179f, -1.98892358f, 0.99446179f},
+    {-1.98889291f, 0.98895425f}};
+
+// Comparing to scipy. The expected output is generated as follows:
+// zi = np.float32([0, 0])
+// for i in range(4):
+//   yn, zi = scipy.signal.lfilter(B, A, x[i], zi=zi)
+//   print(yn)
+constexpr FloatArraySequence kBiQuadOutputSeq = {
+    {{{-86.68354497f, -7.02175351f, 102.10290352f, -0.37487333f, -5.87205847f,
+       -8.85521608f, 10.33772563f, 54.51157181f}},
+     {{-64.92531604f, -6.76395978f, 11.15534507f, -94.68073341f, -107.18177856f,
+       13.24642474f, 64.84288941f, -50.97822629f}},
+     {{-30.1579652f, -15.64850899f, -71.06662821f, -5.5883229f, 1.91175353f,
+       106.5572003f, 8.57183046f, -12.06298473f}},
+     {{24.84286614f, -62.18094158f, 57.91488056f, -106.65685933f, 13.38760103f,
+       -36.60367134f, -94.44880104f, -3.59920354f}}}};
+
+// Fail for every pair from two equally sized rtc::ArrayView<float> views such
+// that their relative error is above a given threshold. If the expected value
+// of a pair is 0, the tolerance is used to check the absolute error.
+void ExpectNearRelative(rtc::ArrayView<const float> expected,
+                        rtc::ArrayView<const float> computed,
+                        const float tolerance) {
+  // The relative error is undefined when the expected value is 0.
+  // When that happens, check the absolute error instead. |safe_den| is used
+  // below to implement such logic.
+  auto safe_den = [](float x) { return (x == 0.f) ? 1.f : std::fabs(x); };
+  ASSERT_EQ(expected.size(), computed.size());
+  for (size_t i = 0; i < expected.size(); ++i) {
+    const float abs_diff = std::fabs(expected[i] - computed[i]);
+    // No failure when the values are equal.
+    if (abs_diff == 0.f)
+      continue;
+    SCOPED_TRACE(i);
+    SCOPED_TRACE(expected[i]);
+    SCOPED_TRACE(computed[i]);
+    EXPECT_LE(abs_diff / safe_den(expected[i]), tolerance);
+  }
+}
+
+}  // namespace
+
+TEST(BiQuadFilterTest, FilterNotInPlace) {
+  BiQuadFilter filter;
+  filter.Initialize(kBiQuadConfig);
+  std::array<float, kFrameSize> samples;
+
+  // TODO(https://bugs.webrtc.org/8948): Add when the issue is fixed.
+  // FloatingPointExceptionObserver fpe_observer;
+
+  for (size_t i = 0; i < kNumFrames; ++i) {
+    SCOPED_TRACE(i);
+    filter.Process(kBiQuadInputSeq[i], samples);
+    ExpectNearRelative(kBiQuadOutputSeq[i], samples, 2e-4f);
+  }
+}
+
+TEST(BiQuadFilterTest, FilterInPlace) {
+  BiQuadFilter filter;
+  filter.Initialize(kBiQuadConfig);
+  std::array<float, kFrameSize> samples;
+
+  // TODO(https://bugs.webrtc.org/8948): Add when the issue is fixed.
+  // FloatingPointExceptionObserver fpe_observer;
+
+  for (size_t i = 0; i < kNumFrames; ++i) {
+    SCOPED_TRACE(i);
+    std::copy(kBiQuadInputSeq[i].begin(), kBiQuadInputSeq[i].end(),
+              samples.begin());
+    filter.Process({samples}, {samples});
+    ExpectNearRelative(kBiQuadOutputSeq[i], samples, 2e-4f);
+  }
+}
+
+TEST(BiQuadFilterTest, Reset) {
+  BiQuadFilter filter;
+  filter.Initialize(kBiQuadConfig);
+
+  std::array<float, kFrameSize> samples1;
+  for (size_t i = 0; i < kNumFrames; ++i) {
+    filter.Process(kBiQuadInputSeq[i], samples1);
+  }
+
+  filter.Reset();
+  std::array<float, kFrameSize> samples2;
+  for (size_t i = 0; i < kNumFrames; ++i) {
+    filter.Process(kBiQuadInputSeq[i], samples2);
+  }
+
+  EXPECT_EQ(samples1, samples2);
+}
+
+}  // namespace test
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/compute_interpolated_gain_curve.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/compute_interpolated_gain_curve.cc
new file mode 100644
index 0000000..bc92613
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/compute_interpolated_gain_curve.cc
@@ -0,0 +1,229 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/compute_interpolated_gain_curve.h"
+
+#include <algorithm>
+#include <cmath>
+#include <queue>
+#include <tuple>
+#include <utility>
+#include <vector>
+
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "modules/audio_processing/agc2/agc2_testing_common.h"
+#include "modules/audio_processing/agc2/limiter_db_gain_curve.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+
+std::pair<double, double> ComputeLinearApproximationParams(
+    const LimiterDbGainCurve* limiter,
+    const double x) {
+  const double m = limiter->GetGainFirstDerivativeLinear(x);
+  const double q = limiter->GetGainLinear(x) - m * x;
+  return {m, q};
+}
+
+double ComputeAreaUnderPiecewiseLinearApproximation(
+    const LimiterDbGainCurve* limiter,
+    const double x0,
+    const double x1) {
+  RTC_CHECK_LT(x0, x1);
+
+  // Linear approximation in x0 and x1.
+  double m0, q0, m1, q1;
+  std::tie(m0, q0) = ComputeLinearApproximationParams(limiter, x0);
+  std::tie(m1, q1) = ComputeLinearApproximationParams(limiter, x1);
+
+  // Intersection point between two adjacent linear pieces.
+  RTC_CHECK_NE(m1, m0);
+  const double x_split = (q0 - q1) / (m1 - m0);
+  RTC_CHECK_LT(x0, x_split);
+  RTC_CHECK_LT(x_split, x1);
+
+  auto area_under_linear_piece = [](double x_l, double x_r, double m,
+                                    double q) {
+    return x_r * (m * x_r / 2.0 + q) - x_l * (m * x_l / 2.0 + q);
+  };
+  return area_under_linear_piece(x0, x_split, m0, q0) +
+         area_under_linear_piece(x_split, x1, m1, q1);
+}
+
+// Computes the approximation error in the limiter region for a given interval.
+// The error is computed as the difference between the areas beneath the limiter
+// curve to approximate and its linear under-approximation.
+double LimiterUnderApproximationNegativeError(const LimiterDbGainCurve* limiter,
+                                              const double x0,
+                                              const double x1) {
+  const double area_limiter = limiter->GetGainIntegralLinear(x0, x1);
+  const double area_interpolated_curve =
+      ComputeAreaUnderPiecewiseLinearApproximation(limiter, x0, x1);
+  RTC_CHECK_GE(area_limiter, area_interpolated_curve);
+  return area_limiter - area_interpolated_curve;
+}
+
+// Automatically finds where to sample the beyond-knee region of a limiter using
+// a greedy optimization algorithm that iteratively decreases the approximation
+// error.
+// The solution is sub-optimal because the algorithm is greedy and the points
+// are assigned by halving intervals (starting with the whole beyond-knee region
+// as a single interval). However, even if sub-optimal, this algorithm works
+// well in practice and it is efficiently implemented using priority queues.
+std::vector<double> SampleLimiterRegion(const LimiterDbGainCurve* limiter) {
+  static_assert(kInterpolatedGainCurveBeyondKneePoints > 2, "");
+
+  struct Interval {
+    Interval() = default;  // Ctor required by std::priority_queue.
+    Interval(double l, double r, double e) : x0(l), x1(r), error(e) {
+      RTC_CHECK(x0 < x1);
+    }
+    bool operator<(const Interval& other) const { return error < other.error; }
+
+    double x0;
+    double x1;
+    double error;
+  };
+
+  std::priority_queue<Interval, std::vector<Interval>> q;
+  q.emplace(limiter->limiter_start_linear(), limiter->max_input_level_linear(),
+            LimiterUnderApproximationNegativeError(
+                limiter, limiter->limiter_start_linear(),
+                limiter->max_input_level_linear()));
+
+  // Iteratively find points by halving the interval with greatest error.
+  while (q.size() < kInterpolatedGainCurveBeyondKneePoints) {
+    // Get the interval with highest error.
+    const auto interval = q.top();
+    q.pop();
+
+    // Split |interval| and enqueue.
+    double x_split = (interval.x0 + interval.x1) / 2.0;
+    q.emplace(interval.x0, x_split,
+              LimiterUnderApproximationNegativeError(limiter, interval.x0,
+                                                     x_split));  // Left.
+    q.emplace(x_split, interval.x1,
+              LimiterUnderApproximationNegativeError(limiter, x_split,
+                                                     interval.x1));  // Right.
+  }
+
+  // Copy x1 values and sort them.
+  RTC_CHECK_EQ(q.size(), kInterpolatedGainCurveBeyondKneePoints);
+  std::vector<double> samples(kInterpolatedGainCurveBeyondKneePoints);
+  for (size_t i = 0; i < kInterpolatedGainCurveBeyondKneePoints; ++i) {
+    const auto interval = q.top();
+    q.pop();
+    samples[i] = interval.x1;
+  }
+  RTC_CHECK(q.empty());
+  std::sort(samples.begin(), samples.end());
+
+  return samples;
+}
+
+// Compute the parameters to over-approximate the knee region via linear
+// interpolation. Over-approximating is saturation-safe since the knee region is
+// convex.
+void PrecomputeKneeApproxParams(const LimiterDbGainCurve* limiter,
+                                test::InterpolatedParameters* parameters) {
+  static_assert(kInterpolatedGainCurveKneePoints > 2, "");
+  // Get |kInterpolatedGainCurveKneePoints| - 1 equally spaced points.
+  const std::vector<double> points = test::LinSpace(
+      limiter->knee_start_linear(), limiter->limiter_start_linear(),
+      kInterpolatedGainCurveKneePoints - 1);
+
+  // Set the first two points. The second is computed to help with the beginning
+  // of the knee region, which has high curvature.
+  parameters->computed_approximation_params_x[0] = points[0];
+  parameters->computed_approximation_params_x[1] =
+      (points[0] + points[1]) / 2.0;
+  // Copy the remaining points.
+  std::copy(std::begin(points) + 1, std::end(points),
+            std::begin(parameters->computed_approximation_params_x) + 2);
+
+  // Compute (m, q) pairs for each linear piece y = mx + q.
+  for (size_t i = 0; i < kInterpolatedGainCurveKneePoints - 1; ++i) {
+    const double x0 = parameters->computed_approximation_params_x[i];
+    const double x1 = parameters->computed_approximation_params_x[i + 1];
+    const double y0 = limiter->GetGainLinear(x0);
+    const double y1 = limiter->GetGainLinear(x1);
+    RTC_CHECK_NE(x1, x0);
+    parameters->computed_approximation_params_m[i] = (y1 - y0) / (x1 - x0);
+    parameters->computed_approximation_params_q[i] =
+        y0 - parameters->computed_approximation_params_m[i] * x0;
+  }
+}
+
+// Compute the parameters to under-approximate the beyond-knee region via linear
+// interpolation and greedy sampling. Under-approximating is saturation-safe
+// since the beyond-knee region is concave.
+void PrecomputeBeyondKneeApproxParams(
+    const LimiterDbGainCurve* limiter,
+    test::InterpolatedParameters* parameters) {
+  // Find points on which the linear pieces are tangent to the gain curve.
+  const auto samples = SampleLimiterRegion(limiter);
+
+  // Parametrize each linear piece.
+  double m, q;
+  std::tie(m, q) = ComputeLinearApproximationParams(
+      limiter,
+      parameters
+          ->computed_approximation_params_x[kInterpolatedGainCurveKneePoints -
+                                            1]);
+  parameters
+      ->computed_approximation_params_m[kInterpolatedGainCurveKneePoints - 1] =
+      m;
+  parameters
+      ->computed_approximation_params_q[kInterpolatedGainCurveKneePoints - 1] =
+      q;
+  for (size_t i = 0; i < samples.size(); ++i) {
+    std::tie(m, q) = ComputeLinearApproximationParams(limiter, samples[i]);
+    parameters
+        ->computed_approximation_params_m[i +
+                                          kInterpolatedGainCurveKneePoints] = m;
+    parameters
+        ->computed_approximation_params_q[i +
+                                          kInterpolatedGainCurveKneePoints] = q;
+  }
+
+  // Find the point of intersection between adjacent linear pieces. They will be
+  // used as boundaries between adjacent linear pieces.
+  for (size_t i = kInterpolatedGainCurveKneePoints;
+       i < kInterpolatedGainCurveKneePoints +
+               kInterpolatedGainCurveBeyondKneePoints;
+       ++i) {
+    RTC_CHECK_NE(parameters->computed_approximation_params_m[i],
+                 parameters->computed_approximation_params_m[i - 1]);
+    parameters->computed_approximation_params_x[i] =
+        (  // Formula: (q0 - q1) / (m1 - m0).
+            parameters->computed_approximation_params_q[i - 1] -
+            parameters->computed_approximation_params_q[i]) /
+        (parameters->computed_approximation_params_m[i] -
+         parameters->computed_approximation_params_m[i - 1]);
+  }
+}
+
+}  // namespace
+
+namespace test {
+
+InterpolatedParameters ComputeInterpolatedGainCurveApproximationParams() {
+  InterpolatedParameters parameters;
+  LimiterDbGainCurve limiter;
+  parameters.computed_approximation_params_x.fill(0.0f);
+  parameters.computed_approximation_params_m.fill(0.0f);
+  parameters.computed_approximation_params_q.fill(0.0f);
+  PrecomputeKneeApproxParams(&limiter, &parameters);
+  PrecomputeBeyondKneeApproxParams(&limiter, &parameters);
+  return parameters;
+}
+}  // namespace test
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/compute_interpolated_gain_curve.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/compute_interpolated_gain_curve.h
new file mode 100644
index 0000000..5f52441
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/compute_interpolated_gain_curve.h
@@ -0,0 +1,48 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_COMPUTE_INTERPOLATED_GAIN_CURVE_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_COMPUTE_INTERPOLATED_GAIN_CURVE_H_
+
+#include <array>
+
+#include "modules/audio_processing/agc2/agc2_common.h"
+
+namespace webrtc {
+
+namespace test {
+
+// Parameters for interpolated gain curve using under-approximation to
+// avoid saturation.
+//
+// The saturation gain is defined in order to let hard-clipping occur for
+// those samples having a level that falls in the saturation region. It is an
+// upper bound of the actual gain to apply - i.e., that returned by the
+// limiter.
+
+// Knee and beyond-knee regions approximation parameters.
+// The gain curve is approximated as a piece-wise linear function.
+// |approx_params_x_| are the boundaries between adjacent linear pieces,
+// |approx_params_m_| and |approx_params_q_| are the slope and the y-intercept
+// values of each piece.
+struct InterpolatedParameters {
+  std::array<float, kInterpolatedGainCurveTotalPoints>
+      computed_approximation_params_x;
+  std::array<float, kInterpolatedGainCurveTotalPoints>
+      computed_approximation_params_m;
+  std::array<float, kInterpolatedGainCurveTotalPoints>
+      computed_approximation_params_q;
+};
+
+InterpolatedParameters ComputeInterpolatedGainCurveApproximationParams();
+}  // namespace test
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_COMPUTE_INTERPOLATED_GAIN_CURVE_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/cpu_features.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/cpu_features.cc
new file mode 100644
index 0000000..cced761
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/cpu_features.cc
@@ -0,0 +1,62 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/cpu_features.h"
+
+#include "rtc_base/strings/string_builder.h"
+#include "rtc_base/system/arch.h"
+#include "system_wrappers/include/cpu_features_wrapper.h"
+
+namespace webrtc {
+
+std::string AvailableCpuFeatures::ToString() const {
+  char buf[64];
+  rtc::SimpleStringBuilder builder(buf);
+  bool first = true;
+  if (sse2) {
+    builder << (first ? "SSE2" : "_SSE2");
+    first = false;
+  }
+  if (avx2) {
+    builder << (first ? "AVX2" : "_AVX2");
+    first = false;
+  }
+  if (neon) {
+    builder << (first ? "NEON" : "_NEON");
+    first = false;
+  }
+  if (first) {
+    return "none";
+  }
+  return builder.str();
+}
+
+// Detects available CPU features.
+AvailableCpuFeatures GetAvailableCpuFeatures() {
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+  return {/*sse2=*/GetCPUInfo(kSSE2) != 0,
+          /*avx2=*/GetCPUInfo(kAVX2) != 0,
+          /*neon=*/false};
+#elif defined(WEBRTC_HAS_NEON)
+  return {/*sse2=*/false,
+          /*avx2=*/false,
+          /*neon=*/true};
+#else
+  return {/*sse2=*/false,
+          /*avx2=*/false,
+          /*neon=*/false};
+#endif
+}
+
+AvailableCpuFeatures NoAvailableCpuFeatures() {
+  return {/*sse2=*/false, /*avx2=*/false, /*neon=*/false};
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/cpu_features.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/cpu_features.h
new file mode 100644
index 0000000..54ddfb3
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/cpu_features.h
@@ -0,0 +1,39 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_CPU_FEATURES_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_CPU_FEATURES_H_
+
+#include <string>
+
+namespace webrtc {
+
+// Collection of flags indicating which CPU features are available on the
+// current platform. True means available.
+struct AvailableCpuFeatures {
+  AvailableCpuFeatures(bool sse2, bool avx2, bool neon)
+      : sse2(sse2), avx2(avx2), neon(neon) {}
+  // Intel.
+  bool sse2;
+  bool avx2;
+  // ARM.
+  bool neon;
+  std::string ToString() const;
+};
+
+// Detects what CPU features are available.
+AvailableCpuFeatures GetAvailableCpuFeatures();
+
+// Returns the CPU feature flags all set to false.
+AvailableCpuFeatures NoAvailableCpuFeatures();
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_CPU_FEATURES_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/down_sampler.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/down_sampler.cc
new file mode 100644
index 0000000..fd1a2c3
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/down_sampler.cc
@@ -0,0 +1,99 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/down_sampler.h"
+
+#include <string.h>
+
+#include <algorithm>
+
+#include "modules/audio_processing/agc2/biquad_filter.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+
+constexpr int kChunkSizeMs = 10;
+constexpr int kSampleRate8kHz = 8000;
+constexpr int kSampleRate16kHz = 16000;
+constexpr int kSampleRate32kHz = 32000;
+constexpr int kSampleRate48kHz = 48000;
+
+// Bandlimiter coefficients computed based on that only
+// the first 40 bins of the spectrum for the downsampled
+// signal are used.
+// [B,A] = butter(2,(41/64*4000)/8000)
+const BiQuadFilter::BiQuadCoefficients kLowPassFilterCoefficients_16kHz = {
+    {0.1455f, 0.2911f, 0.1455f},
+    {-0.6698f, 0.2520f}};
+
+// [B,A] = butter(2,(41/64*4000)/16000)
+const BiQuadFilter::BiQuadCoefficients kLowPassFilterCoefficients_32kHz = {
+    {0.0462f, 0.0924f, 0.0462f},
+    {-1.3066f, 0.4915f}};
+
+// [B,A] = butter(2,(41/64*4000)/24000)
+const BiQuadFilter::BiQuadCoefficients kLowPassFilterCoefficients_48kHz = {
+    {0.0226f, 0.0452f, 0.0226f},
+    {-1.5320f, 0.6224f}};
+
+}  // namespace
+
+DownSampler::DownSampler(ApmDataDumper* data_dumper)
+    : data_dumper_(data_dumper) {
+  Initialize(48000);
+}
+void DownSampler::Initialize(int sample_rate_hz) {
+  RTC_DCHECK(
+      sample_rate_hz == kSampleRate8kHz || sample_rate_hz == kSampleRate16kHz ||
+      sample_rate_hz == kSampleRate32kHz || sample_rate_hz == kSampleRate48kHz);
+
+  sample_rate_hz_ = sample_rate_hz;
+  down_sampling_factor_ = rtc::CheckedDivExact(sample_rate_hz_, 8000);
+
+  /// Note that the down sampling filter is not used if the sample rate is 8
+  /// kHz.
+  if (sample_rate_hz_ == kSampleRate16kHz) {
+    low_pass_filter_.Initialize(kLowPassFilterCoefficients_16kHz);
+  } else if (sample_rate_hz_ == kSampleRate32kHz) {
+    low_pass_filter_.Initialize(kLowPassFilterCoefficients_32kHz);
+  } else if (sample_rate_hz_ == kSampleRate48kHz) {
+    low_pass_filter_.Initialize(kLowPassFilterCoefficients_48kHz);
+  }
+}
+
+void DownSampler::DownSample(rtc::ArrayView<const float> in,
+                             rtc::ArrayView<float> out) {
+  data_dumper_->DumpWav("agc2_down_sampler_input", in, sample_rate_hz_, 1);
+  RTC_DCHECK_EQ(sample_rate_hz_ * kChunkSizeMs / 1000, in.size());
+  RTC_DCHECK_EQ(kSampleRate8kHz * kChunkSizeMs / 1000, out.size());
+  const size_t kMaxNumFrames = kSampleRate48kHz * kChunkSizeMs / 1000;
+  float x[kMaxNumFrames];
+
+  // Band-limit the signal to 4 kHz.
+  if (sample_rate_hz_ != kSampleRate8kHz) {
+    low_pass_filter_.Process(in, rtc::ArrayView<float>(x, in.size()));
+
+    // Downsample the signal.
+    size_t k = 0;
+    for (size_t j = 0; j < out.size(); ++j) {
+      RTC_DCHECK_GT(kMaxNumFrames, k);
+      out[j] = x[k];
+      k += down_sampling_factor_;
+    }
+  } else {
+    std::copy(in.data(), in.data() + in.size(), out.data());
+  }
+
+  data_dumper_->DumpWav("agc2_down_sampler_output", out, kSampleRate8kHz, 1);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/down_sampler.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/down_sampler.h
new file mode 100644
index 0000000..a44f96f
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/down_sampler.h
@@ -0,0 +1,42 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_DOWN_SAMPLER_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_DOWN_SAMPLER_H_
+
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/biquad_filter.h"
+
+namespace webrtc {
+
+class ApmDataDumper;
+
+class DownSampler {
+ public:
+  explicit DownSampler(ApmDataDumper* data_dumper);
+
+  DownSampler() = delete;
+  DownSampler(const DownSampler&) = delete;
+  DownSampler& operator=(const DownSampler&) = delete;
+
+  void Initialize(int sample_rate_hz);
+
+  void DownSample(rtc::ArrayView<const float> in, rtc::ArrayView<float> out);
+
+ private:
+  ApmDataDumper* const data_dumper_;
+  int sample_rate_hz_;
+  int down_sampling_factor_;
+  BiQuadFilter low_pass_filter_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_DOWN_SAMPLER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/fixed_digital_level_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/fixed_digital_level_estimator.cc
new file mode 100644
index 0000000..3e9bb2e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/fixed_digital_level_estimator.cc
@@ -0,0 +1,120 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/fixed_digital_level_estimator.h"
+
+#include <algorithm>
+#include <cmath>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+
+constexpr float kInitialFilterStateLevel = 0.f;
+
+// Instant attack.
+constexpr float kAttackFilterConstant = 0.f;
+// This is computed from kDecayMs by
+// 10 ** (-1/20 * subframe_duration / kDecayMs).
+// |subframe_duration| is |kFrameDurationMs / kSubFramesInFrame|.
+// kDecayMs is defined in agc2_testing_common.h
+constexpr float kDecayFilterConstant = 0.9998848773724686f;
+
+}  // namespace
+
+FixedDigitalLevelEstimator::FixedDigitalLevelEstimator(
+    int sample_rate_hz,
+    ApmDataDumper* apm_data_dumper)
+    : apm_data_dumper_(apm_data_dumper),
+      filter_state_level_(kInitialFilterStateLevel) {
+  SetSampleRate(sample_rate_hz);
+  CheckParameterCombination();
+  RTC_DCHECK(apm_data_dumper_);
+  apm_data_dumper_->DumpRaw("agc2_level_estimator_samplerate", sample_rate_hz);
+}
+
+void FixedDigitalLevelEstimator::CheckParameterCombination() {
+  RTC_DCHECK_GT(samples_in_frame_, 0);
+  RTC_DCHECK_LE(kSubFramesInFrame, samples_in_frame_);
+  RTC_DCHECK_EQ(samples_in_frame_ % kSubFramesInFrame, 0);
+  RTC_DCHECK_GT(samples_in_sub_frame_, 1);
+}
+
+std::array<float, kSubFramesInFrame> FixedDigitalLevelEstimator::ComputeLevel(
+    const AudioFrameView<const float>& float_frame) {
+  RTC_DCHECK_GT(float_frame.num_channels(), 0);
+  RTC_DCHECK_EQ(float_frame.samples_per_channel(), samples_in_frame_);
+
+  // Compute max envelope without smoothing.
+  std::array<float, kSubFramesInFrame> envelope{};
+  for (size_t channel_idx = 0; channel_idx < float_frame.num_channels();
+       ++channel_idx) {
+    const auto channel = float_frame.channel(channel_idx);
+    for (int sub_frame = 0; sub_frame < kSubFramesInFrame; ++sub_frame) {
+      for (int sample_in_sub_frame = 0;
+           sample_in_sub_frame < samples_in_sub_frame_; ++sample_in_sub_frame) {
+        envelope[sub_frame] =
+            std::max(envelope[sub_frame],
+                     std::abs(channel[sub_frame * samples_in_sub_frame_ +
+                                      sample_in_sub_frame]));
+      }
+    }
+  }
+
+  // Make sure envelope increases happen one step earlier so that the
+  // corresponding *gain decrease* doesn't miss a sudden signal
+  // increase due to interpolation.
+  for (int sub_frame = 0; sub_frame < kSubFramesInFrame - 1; ++sub_frame) {
+    if (envelope[sub_frame] < envelope[sub_frame + 1]) {
+      envelope[sub_frame] = envelope[sub_frame + 1];
+    }
+  }
+
+  // Add attack / decay smoothing.
+  for (int sub_frame = 0; sub_frame < kSubFramesInFrame; ++sub_frame) {
+    const float envelope_value = envelope[sub_frame];
+    if (envelope_value > filter_state_level_) {
+      envelope[sub_frame] = envelope_value * (1 - kAttackFilterConstant) +
+                            filter_state_level_ * kAttackFilterConstant;
+    } else {
+      envelope[sub_frame] = envelope_value * (1 - kDecayFilterConstant) +
+                            filter_state_level_ * kDecayFilterConstant;
+    }
+    filter_state_level_ = envelope[sub_frame];
+
+    // Dump data for debug.
+    RTC_DCHECK(apm_data_dumper_);
+    const auto channel = float_frame.channel(0);
+    apm_data_dumper_->DumpRaw("agc2_level_estimator_samples",
+                              samples_in_sub_frame_,
+                              &channel[sub_frame * samples_in_sub_frame_]);
+    apm_data_dumper_->DumpRaw("agc2_level_estimator_level",
+                              envelope[sub_frame]);
+  }
+
+  return envelope;
+}
+
+void FixedDigitalLevelEstimator::SetSampleRate(int sample_rate_hz) {
+  samples_in_frame_ =
+      rtc::CheckedDivExact(sample_rate_hz * kFrameDurationMs, 1000);
+  samples_in_sub_frame_ =
+      rtc::CheckedDivExact(samples_in_frame_, kSubFramesInFrame);
+  CheckParameterCombination();
+}
+
+void FixedDigitalLevelEstimator::Reset() {
+  filter_state_level_ = kInitialFilterStateLevel;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/fixed_digital_level_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/fixed_digital_level_estimator.h
new file mode 100644
index 0000000..d96aeda
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/fixed_digital_level_estimator.h
@@ -0,0 +1,65 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_FIXED_DIGITAL_LEVEL_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_FIXED_DIGITAL_LEVEL_ESTIMATOR_H_
+
+#include <array>
+#include <vector>
+
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "modules/audio_processing/include/audio_frame_view.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+class ApmDataDumper;
+// Produces a smooth signal level estimate from an input audio
+// stream. The estimate smoothing is done through exponential
+// filtering.
+class FixedDigitalLevelEstimator {
+ public:
+  // Sample rates are allowed if the number of samples in a frame
+  // (sample_rate_hz * kFrameDurationMs / 1000) is divisible by
+  // kSubFramesInSample. For kFrameDurationMs=10 and
+  // kSubFramesInSample=20, this means that sample_rate_hz has to be
+  // divisible by 2000.
+  FixedDigitalLevelEstimator(int sample_rate_hz,
+                             ApmDataDumper* apm_data_dumper);
+
+  // The input is assumed to be in FloatS16 format. Scaled input will
+  // produce similarly scaled output. A frame of with kFrameDurationMs
+  // ms of audio produces a level estimates in the same scale. The
+  // level estimate contains kSubFramesInFrame values.
+  std::array<float, kSubFramesInFrame> ComputeLevel(
+      const AudioFrameView<const float>& float_frame);
+
+  // Rate may be changed at any time (but not concurrently) from the
+  // value passed to the constructor. The class is not thread safe.
+  void SetSampleRate(int sample_rate_hz);
+
+  // Resets the level estimator internal state.
+  void Reset();
+
+  float LastAudioLevel() const { return filter_state_level_; }
+
+ private:
+  void CheckParameterCombination();
+
+  ApmDataDumper* const apm_data_dumper_ = nullptr;
+  float filter_state_level_;
+  int samples_in_frame_;
+  int samples_in_sub_frame_;
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(FixedDigitalLevelEstimator);
+};
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_FIXED_DIGITAL_LEVEL_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/fixed_digital_level_estimator_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/fixed_digital_level_estimator_unittest.cc
new file mode 100644
index 0000000..97b421d
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/fixed_digital_level_estimator_unittest.cc
@@ -0,0 +1,159 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/fixed_digital_level_estimator.h"
+
+#include <limits>
+
+#include "common_audio/include/audio_util.h"
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "modules/audio_processing/agc2/agc2_testing_common.h"
+#include "modules/audio_processing/agc2/vector_float_frame.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/gunit.h"
+
+namespace webrtc {
+namespace {
+
+constexpr float kInputLevel = 10000.f;
+
+// Run audio at specified settings through the level estimator, and
+// verify that the output level falls within the bounds.
+void TestLevelEstimator(int sample_rate_hz,
+                        int num_channels,
+                        float input_level_linear_scale,
+                        float expected_min,
+                        float expected_max) {
+  ApmDataDumper apm_data_dumper(0);
+  FixedDigitalLevelEstimator level_estimator(sample_rate_hz, &apm_data_dumper);
+
+  const VectorFloatFrame vectors_with_float_frame(
+      num_channels, rtc::CheckedDivExact(sample_rate_hz, 100),
+      input_level_linear_scale);
+
+  for (int i = 0; i < 500; ++i) {
+    const auto level = level_estimator.ComputeLevel(
+        vectors_with_float_frame.float_frame_view());
+
+    // Give the estimator some time to ramp up.
+    if (i < 50) {
+      continue;
+    }
+
+    for (const auto& x : level) {
+      EXPECT_LE(expected_min, x);
+      EXPECT_LE(x, expected_max);
+    }
+  }
+}
+
+// Returns time it takes for the level estimator to decrease its level
+// estimate by 'level_reduction_db'.
+float TimeMsToDecreaseLevel(int sample_rate_hz,
+                            int num_channels,
+                            float input_level_db,
+                            float level_reduction_db) {
+  const float input_level = DbfsToFloatS16(input_level_db);
+  RTC_DCHECK_GT(level_reduction_db, 0);
+
+  const VectorFloatFrame vectors_with_float_frame(
+      num_channels, rtc::CheckedDivExact(sample_rate_hz, 100), input_level);
+
+  ApmDataDumper apm_data_dumper(0);
+  FixedDigitalLevelEstimator level_estimator(sample_rate_hz, &apm_data_dumper);
+
+  // Give the LevelEstimator plenty of time to ramp up and stabilize
+  float last_level = 0.f;
+  for (int i = 0; i < 500; ++i) {
+    const auto level_envelope = level_estimator.ComputeLevel(
+        vectors_with_float_frame.float_frame_view());
+    last_level = *level_envelope.rbegin();
+  }
+
+  // Set input to 0.
+  VectorFloatFrame vectors_with_zero_float_frame(
+      num_channels, rtc::CheckedDivExact(sample_rate_hz, 100), 0);
+
+  const float reduced_level_linear =
+      DbfsToFloatS16(input_level_db - level_reduction_db);
+  int sub_frames_until_level_reduction = 0;
+  while (last_level > reduced_level_linear) {
+    const auto level_envelope = level_estimator.ComputeLevel(
+        vectors_with_zero_float_frame.float_frame_view());
+    for (const auto& v : level_envelope) {
+      EXPECT_LT(v, last_level);
+      sub_frames_until_level_reduction++;
+      last_level = v;
+      if (last_level <= reduced_level_linear) {
+        break;
+      }
+    }
+  }
+  return static_cast<float>(sub_frames_until_level_reduction) *
+         kFrameDurationMs / kSubFramesInFrame;
+}
+}  // namespace
+
+TEST(GainController2FixedDigitalLevelEstimator, EstimatorShouldNotCrash) {
+  TestLevelEstimator(8000, 1, 0, std::numeric_limits<float>::lowest(),
+                     std::numeric_limits<float>::max());
+}
+
+TEST(GainController2FixedDigitalLevelEstimator,
+     EstimatorShouldEstimateConstantLevel) {
+  TestLevelEstimator(10000, 1, kInputLevel, kInputLevel * 0.99,
+                     kInputLevel * 1.01);
+}
+
+TEST(GainController2FixedDigitalLevelEstimator,
+     EstimatorShouldEstimateConstantLevelForManyChannels) {
+  constexpr size_t num_channels = 10;
+  TestLevelEstimator(20000, num_channels, kInputLevel, kInputLevel * 0.99,
+                     kInputLevel * 1.01);
+}
+
+TEST(GainController2FixedDigitalLevelEstimator, TimeToDecreaseForLowLevel) {
+  constexpr float kLevelReductionDb = 25;
+  constexpr float kInitialLowLevel = -40;
+  constexpr float kExpectedTime = kLevelReductionDb * test::kDecayMs;
+
+  const float time_to_decrease =
+      TimeMsToDecreaseLevel(22000, 1, kInitialLowLevel, kLevelReductionDb);
+
+  EXPECT_LE(kExpectedTime * 0.9, time_to_decrease);
+  EXPECT_LE(time_to_decrease, kExpectedTime * 1.1);
+}
+
+TEST(GainController2FixedDigitalLevelEstimator,
+     TimeToDecreaseForFullScaleLevel) {
+  constexpr float kLevelReductionDb = 25;
+  constexpr float kExpectedTime = kLevelReductionDb * test::kDecayMs;
+
+  const float time_to_decrease =
+      TimeMsToDecreaseLevel(26000, 1, 0, kLevelReductionDb);
+
+  EXPECT_LE(kExpectedTime * 0.9, time_to_decrease);
+  EXPECT_LE(time_to_decrease, kExpectedTime * 1.1);
+}
+
+TEST(GainController2FixedDigitalLevelEstimator,
+     TimeToDecreaseForMultipleChannels) {
+  constexpr float kLevelReductionDb = 25;
+  constexpr float kExpectedTime = kLevelReductionDb * test::kDecayMs;
+  constexpr size_t kNumChannels = 10;
+
+  const float time_to_decrease =
+      TimeMsToDecreaseLevel(28000, kNumChannels, 0, kLevelReductionDb);
+
+  EXPECT_LE(kExpectedTime * 0.9, time_to_decrease);
+  EXPECT_LE(time_to_decrease, kExpectedTime * 1.1);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/gain_applier.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/gain_applier.cc
new file mode 100644
index 0000000..8c43717
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/gain_applier.cc
@@ -0,0 +1,102 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/gain_applier.h"
+
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "rtc_base/numerics/safe_minmax.h"
+
+namespace webrtc {
+namespace {
+
+// Returns true when the gain factor is so close to 1 that it would
+// not affect int16 samples.
+bool GainCloseToOne(float gain_factor) {
+  return 1.f - 1.f / kMaxFloatS16Value <= gain_factor &&
+         gain_factor <= 1.f + 1.f / kMaxFloatS16Value;
+}
+
+void ClipSignal(AudioFrameView<float> signal) {
+  for (size_t k = 0; k < signal.num_channels(); ++k) {
+    rtc::ArrayView<float> channel_view = signal.channel(k);
+    for (auto& sample : channel_view) {
+      sample = rtc::SafeClamp(sample, kMinFloatS16Value, kMaxFloatS16Value);
+    }
+  }
+}
+
+void ApplyGainWithRamping(float last_gain_linear,
+                          float gain_at_end_of_frame_linear,
+                          float inverse_samples_per_channel,
+                          AudioFrameView<float> float_frame) {
+  // Do not modify the signal.
+  if (last_gain_linear == gain_at_end_of_frame_linear &&
+      GainCloseToOne(gain_at_end_of_frame_linear)) {
+    return;
+  }
+
+  // Gain is constant and different from 1.
+  if (last_gain_linear == gain_at_end_of_frame_linear) {
+    for (size_t k = 0; k < float_frame.num_channels(); ++k) {
+      rtc::ArrayView<float> channel_view = float_frame.channel(k);
+      for (auto& sample : channel_view) {
+        sample *= gain_at_end_of_frame_linear;
+      }
+    }
+    return;
+  }
+
+  // The gain changes. We have to change slowly to avoid discontinuities.
+  const float increment = (gain_at_end_of_frame_linear - last_gain_linear) *
+                          inverse_samples_per_channel;
+  float gain = last_gain_linear;
+  for (size_t i = 0; i < float_frame.samples_per_channel(); ++i) {
+    for (size_t ch = 0; ch < float_frame.num_channels(); ++ch) {
+      float_frame.channel(ch)[i] *= gain;
+    }
+    gain += increment;
+  }
+}
+
+}  // namespace
+
+GainApplier::GainApplier(bool hard_clip_samples, float initial_gain_factor)
+    : hard_clip_samples_(hard_clip_samples),
+      last_gain_factor_(initial_gain_factor),
+      current_gain_factor_(initial_gain_factor) {}
+
+void GainApplier::ApplyGain(AudioFrameView<float> signal) {
+  if (static_cast<int>(signal.samples_per_channel()) != samples_per_channel_) {
+    Initialize(signal.samples_per_channel());
+  }
+
+  ApplyGainWithRamping(last_gain_factor_, current_gain_factor_,
+                       inverse_samples_per_channel_, signal);
+
+  last_gain_factor_ = current_gain_factor_;
+
+  if (hard_clip_samples_) {
+    ClipSignal(signal);
+  }
+}
+
+void GainApplier::SetGainFactor(float gain_factor) {
+  RTC_DCHECK_GT(gain_factor, 0.f);
+  current_gain_factor_ = gain_factor;
+}
+
+void GainApplier::Initialize(size_t samples_per_channel) {
+  RTC_DCHECK_GT(samples_per_channel, 0);
+  samples_per_channel_ = static_cast<int>(samples_per_channel);
+  inverse_samples_per_channel_ = 1.f / samples_per_channel_;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/gain_applier.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/gain_applier.h
new file mode 100644
index 0000000..d9aa19d
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/gain_applier.h
@@ -0,0 +1,44 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_GAIN_APPLIER_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_GAIN_APPLIER_H_
+
+#include <stddef.h>
+
+#include "modules/audio_processing/include/audio_frame_view.h"
+
+namespace webrtc {
+class GainApplier {
+ public:
+  GainApplier(bool hard_clip_samples, float initial_gain_factor);
+
+  void ApplyGain(AudioFrameView<float> signal);
+  void SetGainFactor(float gain_factor);
+  float GetGainFactor() const { return current_gain_factor_; }
+
+ private:
+  void Initialize(size_t samples_per_channel);
+
+  // Whether to clip samples after gain is applied. If 'true', result
+  // will fit in FloatS16 range.
+  const bool hard_clip_samples_;
+  float last_gain_factor_;
+
+  // If this value is not equal to 'last_gain_factor', gain will be
+  // ramped from 'last_gain_factor_' to this value during the next
+  // 'ApplyGain'.
+  float current_gain_factor_;
+  int samples_per_channel_ = -1;
+  float inverse_samples_per_channel_ = -1.f;
+};
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_GAIN_APPLIER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/gain_applier_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/gain_applier_unittest.cc
new file mode 100644
index 0000000..3296345
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/gain_applier_unittest.cc
@@ -0,0 +1,93 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/gain_applier.h"
+
+#include <math.h>
+
+#include <algorithm>
+#include <limits>
+
+#include "modules/audio_processing/agc2/vector_float_frame.h"
+#include "rtc_base/gunit.h"
+
+namespace webrtc {
+TEST(AutomaticGainController2GainApplier, InitialGainIsRespected) {
+  constexpr float initial_signal_level = 123.f;
+  constexpr float gain_factor = 10.f;
+  VectorFloatFrame fake_audio(1, 1, initial_signal_level);
+  GainApplier gain_applier(true, gain_factor);
+
+  gain_applier.ApplyGain(fake_audio.float_frame_view());
+  EXPECT_NEAR(fake_audio.float_frame_view().channel(0)[0],
+              initial_signal_level * gain_factor, 0.1f);
+}
+
+TEST(AutomaticGainController2GainApplier, ClippingIsDone) {
+  constexpr float initial_signal_level = 30000.f;
+  constexpr float gain_factor = 10.f;
+  VectorFloatFrame fake_audio(1, 1, initial_signal_level);
+  GainApplier gain_applier(true, gain_factor);
+
+  gain_applier.ApplyGain(fake_audio.float_frame_view());
+  EXPECT_NEAR(fake_audio.float_frame_view().channel(0)[0],
+              std::numeric_limits<int16_t>::max(), 0.1f);
+}
+
+TEST(AutomaticGainController2GainApplier, ClippingIsNotDone) {
+  constexpr float initial_signal_level = 30000.f;
+  constexpr float gain_factor = 10.f;
+  VectorFloatFrame fake_audio(1, 1, initial_signal_level);
+  GainApplier gain_applier(false, gain_factor);
+
+  gain_applier.ApplyGain(fake_audio.float_frame_view());
+
+  EXPECT_NEAR(fake_audio.float_frame_view().channel(0)[0],
+              initial_signal_level * gain_factor, 0.1f);
+}
+
+TEST(AutomaticGainController2GainApplier, RampingIsDone) {
+  constexpr float initial_signal_level = 30000.f;
+  constexpr float initial_gain_factor = 1.f;
+  constexpr float target_gain_factor = 0.5f;
+  constexpr int num_channels = 3;
+  constexpr int samples_per_channel = 4;
+  VectorFloatFrame fake_audio(num_channels, samples_per_channel,
+                              initial_signal_level);
+  GainApplier gain_applier(false, initial_gain_factor);
+
+  gain_applier.SetGainFactor(target_gain_factor);
+  gain_applier.ApplyGain(fake_audio.float_frame_view());
+
+  // The maximal gain change should be close to that in linear interpolation.
+  for (size_t channel = 0; channel < num_channels; ++channel) {
+    float max_signal_change = 0.f;
+    float last_signal_level = initial_signal_level;
+    for (const auto sample : fake_audio.float_frame_view().channel(channel)) {
+      const float current_change = fabs(last_signal_level - sample);
+      max_signal_change = std::max(max_signal_change, current_change);
+      last_signal_level = sample;
+    }
+    const float total_gain_change =
+        fabs((initial_gain_factor - target_gain_factor) * initial_signal_level);
+    EXPECT_NEAR(max_signal_change, total_gain_change / samples_per_channel,
+                0.1f);
+  }
+
+  // Next frame should have the desired level.
+  VectorFloatFrame next_fake_audio_frame(num_channels, samples_per_channel,
+                                         initial_signal_level);
+  gain_applier.ApplyGain(next_fake_audio_frame.float_frame_view());
+
+  // The last sample should have the new gain.
+  EXPECT_NEAR(next_fake_audio_frame.float_frame_view().channel(0)[0],
+              initial_signal_level * target_gain_factor, 0.1f);
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/interpolated_gain_curve.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/interpolated_gain_curve.cc
new file mode 100644
index 0000000..3dd5010
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/interpolated_gain_curve.cc
@@ -0,0 +1,196 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/interpolated_gain_curve.h"
+
+#include <algorithm>
+#include <iterator>
+
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+constexpr std::array<float, kInterpolatedGainCurveTotalPoints>
+    InterpolatedGainCurve::approximation_params_x_;
+
+constexpr std::array<float, kInterpolatedGainCurveTotalPoints>
+    InterpolatedGainCurve::approximation_params_m_;
+
+constexpr std::array<float, kInterpolatedGainCurveTotalPoints>
+    InterpolatedGainCurve::approximation_params_q_;
+
+InterpolatedGainCurve::InterpolatedGainCurve(
+    ApmDataDumper* apm_data_dumper,
+    const std::string& histogram_name_prefix)
+    : region_logger_("WebRTC.Audio." + histogram_name_prefix +
+                         ".FixedDigitalGainCurveRegion.Identity",
+                     "WebRTC.Audio." + histogram_name_prefix +
+                         ".FixedDigitalGainCurveRegion.Knee",
+                     "WebRTC.Audio." + histogram_name_prefix +
+                         ".FixedDigitalGainCurveRegion.Limiter",
+                     "WebRTC.Audio." + histogram_name_prefix +
+                         ".FixedDigitalGainCurveRegion.Saturation"),
+      apm_data_dumper_(apm_data_dumper) {}
+
+InterpolatedGainCurve::~InterpolatedGainCurve() {
+  if (stats_.available) {
+    RTC_DCHECK(apm_data_dumper_);
+    apm_data_dumper_->DumpRaw("agc2_interp_gain_curve_lookups_identity",
+                              stats_.look_ups_identity_region);
+    apm_data_dumper_->DumpRaw("agc2_interp_gain_curve_lookups_knee",
+                              stats_.look_ups_knee_region);
+    apm_data_dumper_->DumpRaw("agc2_interp_gain_curve_lookups_limiter",
+                              stats_.look_ups_limiter_region);
+    apm_data_dumper_->DumpRaw("agc2_interp_gain_curve_lookups_saturation",
+                              stats_.look_ups_saturation_region);
+    region_logger_.LogRegionStats(stats_);
+  }
+}
+
+InterpolatedGainCurve::RegionLogger::RegionLogger(
+    const std::string& identity_histogram_name,
+    const std::string& knee_histogram_name,
+    const std::string& limiter_histogram_name,
+    const std::string& saturation_histogram_name)
+    : identity_histogram(
+          metrics::HistogramFactoryGetCounts(identity_histogram_name,
+                                             1,
+                                             10000,
+                                             50)),
+      knee_histogram(metrics::HistogramFactoryGetCounts(knee_histogram_name,
+                                                        1,
+                                                        10000,
+                                                        50)),
+      limiter_histogram(
+          metrics::HistogramFactoryGetCounts(limiter_histogram_name,
+                                             1,
+                                             10000,
+                                             50)),
+      saturation_histogram(
+          metrics::HistogramFactoryGetCounts(saturation_histogram_name,
+                                             1,
+                                             10000,
+                                             50)) {}
+
+InterpolatedGainCurve::RegionLogger::~RegionLogger() = default;
+
+void InterpolatedGainCurve::RegionLogger::LogRegionStats(
+    const InterpolatedGainCurve::Stats& stats) const {
+  using Region = InterpolatedGainCurve::GainCurveRegion;
+  const int duration_s =
+      stats.region_duration_frames / (1000 / kFrameDurationMs);
+
+  switch (stats.region) {
+    case Region::kIdentity: {
+      if (identity_histogram) {
+        metrics::HistogramAdd(identity_histogram, duration_s);
+      }
+      break;
+    }
+    case Region::kKnee: {
+      if (knee_histogram) {
+        metrics::HistogramAdd(knee_histogram, duration_s);
+      }
+      break;
+    }
+    case Region::kLimiter: {
+      if (limiter_histogram) {
+        metrics::HistogramAdd(limiter_histogram, duration_s);
+      }
+      break;
+    }
+    case Region::kSaturation: {
+      if (saturation_histogram) {
+        metrics::HistogramAdd(saturation_histogram, duration_s);
+      }
+      break;
+    }
+    default: {
+      RTC_NOTREACHED();
+    }
+  }
+}
+
+void InterpolatedGainCurve::UpdateStats(float input_level) const {
+  stats_.available = true;
+
+  GainCurveRegion region;
+
+  if (input_level < approximation_params_x_[0]) {
+    stats_.look_ups_identity_region++;
+    region = GainCurveRegion::kIdentity;
+  } else if (input_level <
+             approximation_params_x_[kInterpolatedGainCurveKneePoints - 1]) {
+    stats_.look_ups_knee_region++;
+    region = GainCurveRegion::kKnee;
+  } else if (input_level < kMaxInputLevelLinear) {
+    stats_.look_ups_limiter_region++;
+    region = GainCurveRegion::kLimiter;
+  } else {
+    stats_.look_ups_saturation_region++;
+    region = GainCurveRegion::kSaturation;
+  }
+
+  if (region == stats_.region) {
+    ++stats_.region_duration_frames;
+  } else {
+    region_logger_.LogRegionStats(stats_);
+
+    stats_.region_duration_frames = 0;
+    stats_.region = region;
+  }
+}
+
+// Looks up a gain to apply given a non-negative input level.
+// The cost of this operation depends on the region in which |input_level|
+// falls.
+// For the identity and the saturation regions the cost is O(1).
+// For the other regions, namely knee and limiter, the cost is
+// O(2 + log2(|LightkInterpolatedGainCurveTotalPoints|), plus O(1) for the
+// linear interpolation (one product and one sum).
+float InterpolatedGainCurve::LookUpGainToApply(float input_level) const {
+  UpdateStats(input_level);
+
+  if (input_level <= approximation_params_x_[0]) {
+    // Identity region.
+    return 1.0f;
+  }
+
+  if (input_level >= kMaxInputLevelLinear) {
+    // Saturating lower bound. The saturing samples exactly hit the clipping
+    // level. This method achieves has the lowest harmonic distorsion, but it
+    // may reduce the amplitude of the non-saturating samples too much.
+    return 32768.f / input_level;
+  }
+
+  // Knee and limiter regions; find the linear piece index. Spelling
+  // out the complete type was the only way to silence both the clang
+  // plugin and the windows compilers.
+  std::array<float, kInterpolatedGainCurveTotalPoints>::const_iterator it =
+      std::lower_bound(approximation_params_x_.begin(),
+                       approximation_params_x_.end(), input_level);
+  const size_t index = std::distance(approximation_params_x_.begin(), it) - 1;
+  RTC_DCHECK_LE(0, index);
+  RTC_DCHECK_LT(index, approximation_params_m_.size());
+  RTC_DCHECK_LE(approximation_params_x_[index], input_level);
+  if (index < approximation_params_m_.size() - 1) {
+    RTC_DCHECK_LE(input_level, approximation_params_x_[index + 1]);
+  }
+
+  // Piece-wise linear interploation.
+  const float gain = approximation_params_m_[index] * input_level +
+                     approximation_params_q_[index];
+  RTC_DCHECK_LE(0.f, gain);
+  return gain;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/interpolated_gain_curve.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/interpolated_gain_curve.h
new file mode 100644
index 0000000..af99320
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/interpolated_gain_curve.h
@@ -0,0 +1,152 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_INTERPOLATED_GAIN_CURVE_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_INTERPOLATED_GAIN_CURVE_H_
+
+#include <array>
+#include <string>
+
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "rtc_base/constructor_magic.h"
+#include "rtc_base/gtest_prod_util.h"
+#include "system_wrappers/include/metrics.h"
+
+namespace webrtc {
+
+class ApmDataDumper;
+
+constexpr float kInputLevelScalingFactor = 32768.0f;
+
+// Defined as DbfsToLinear(kLimiterMaxInputLevelDbFs)
+constexpr float kMaxInputLevelLinear = static_cast<float>(36766.300710566735);
+
+// Interpolated gain curve using under-approximation to avoid saturation.
+//
+// The goal of this class is allowing fast look ups to get an accurate
+// estimates of the gain to apply given an estimated input level.
+class InterpolatedGainCurve {
+ public:
+  enum class GainCurveRegion {
+    kIdentity = 0,
+    kKnee = 1,
+    kLimiter = 2,
+    kSaturation = 3
+  };
+
+  struct Stats {
+    // Region in which the output level equals the input one.
+    size_t look_ups_identity_region = 0;
+    // Smoothing between the identity and the limiter regions.
+    size_t look_ups_knee_region = 0;
+    // Limiter region in which the output and input levels are linearly related.
+    size_t look_ups_limiter_region = 0;
+    // Region in which saturation may occur since the input level is beyond the
+    // maximum expected by the limiter.
+    size_t look_ups_saturation_region = 0;
+    // True if stats have been populated.
+    bool available = false;
+
+    // The current region, and for how many frames the level has been
+    // in that region.
+    GainCurveRegion region = GainCurveRegion::kIdentity;
+    int64_t region_duration_frames = 0;
+  };
+
+  InterpolatedGainCurve(ApmDataDumper* apm_data_dumper,
+                        const std::string& histogram_name_prefix);
+  ~InterpolatedGainCurve();
+
+  Stats get_stats() const { return stats_; }
+
+  // Given a non-negative input level (linear scale), a scalar factor to apply
+  // to a sub-frame is returned.
+  // Levels above kLimiterMaxInputLevelDbFs will be reduced to 0 dBFS
+  // after applying this gain
+  float LookUpGainToApply(float input_level) const;
+
+ private:
+  // For comparing 'approximation_params_*_' with ones computed by
+  // ComputeInterpolatedGainCurve.
+  FRIEND_TEST_ALL_PREFIXES(GainController2InterpolatedGainCurve,
+                           CheckApproximationParams);
+
+  struct RegionLogger {
+    metrics::Histogram* identity_histogram;
+    metrics::Histogram* knee_histogram;
+    metrics::Histogram* limiter_histogram;
+    metrics::Histogram* saturation_histogram;
+
+    RegionLogger(const std::string& identity_histogram_name,
+                 const std::string& knee_histogram_name,
+                 const std::string& limiter_histogram_name,
+                 const std::string& saturation_histogram_name);
+
+    ~RegionLogger();
+
+    void LogRegionStats(const InterpolatedGainCurve::Stats& stats) const;
+  } region_logger_;
+
+  void UpdateStats(float input_level) const;
+
+  ApmDataDumper* const apm_data_dumper_;
+
+  static constexpr std::array<float, kInterpolatedGainCurveTotalPoints>
+      approximation_params_x_ = {
+          {30057.296875,    30148.986328125, 30240.67578125,  30424.052734375,
+           30607.4296875,   30790.806640625, 30974.18359375,  31157.560546875,
+           31340.939453125, 31524.31640625,  31707.693359375, 31891.0703125,
+           32074.447265625, 32257.82421875,  32441.201171875, 32624.580078125,
+           32807.95703125,  32991.33203125,  33174.7109375,   33358.08984375,
+           33541.46484375,  33724.84375,     33819.53515625,  34009.5390625,
+           34200.05859375,  34389.81640625,  34674.48828125,  35054.375,
+           35434.86328125,  35814.81640625,  36195.16796875,  36575.03125}};
+  static constexpr std::array<float, kInterpolatedGainCurveTotalPoints>
+      approximation_params_m_ = {
+          {-3.515235675877192989e-07, -1.050251626111275982e-06,
+           -2.085213736791047268e-06, -3.443004743530764244e-06,
+           -4.773849468620028347e-06, -6.077375928725814447e-06,
+           -7.353257842623861507e-06, -8.601219633419532329e-06,
+           -9.821013009059242904e-06, -1.101243378798244521e-05,
+           -1.217532644659513608e-05, -1.330956911260727793e-05,
+           -1.441507538402220234e-05, -1.549179251014720649e-05,
+           -1.653970684856176376e-05, -1.755882840370759368e-05,
+           -1.854918446042574942e-05, -1.951086778717581183e-05,
+           -2.044398024736437947e-05, -2.1348627342376858e-05,
+           -2.222496914328075945e-05, -2.265374678245279938e-05,
+           -2.242570917587727308e-05, -2.220122041762806475e-05,
+           -2.19802095671184361e-05,  -2.176260204578284174e-05,
+           -2.133731686626560986e-05, -2.092481918225530535e-05,
+           -2.052459603874012828e-05, -2.013615448959171772e-05,
+           -1.975903069251216948e-05, -1.939277899509761482e-05}};
+
+  static constexpr std::array<float, kInterpolatedGainCurveTotalPoints>
+      approximation_params_q_ = {
+          {1.010565876960754395, 1.031631827354431152, 1.062929749488830566,
+           1.104239225387573242, 1.144973039627075195, 1.185109615325927734,
+           1.224629044532775879, 1.263512492179870605, 1.301741957664489746,
+           1.339300632476806641, 1.376173257827758789, 1.412345528602600098,
+           1.447803974151611328, 1.482536554336547852, 1.516532182693481445,
+           1.549780607223510742, 1.582272171974182129, 1.613999366760253906,
+           1.644955039024353027, 1.675132393836975098, 1.704526185989379883,
+           1.718986630439758301, 1.711274504661560059, 1.703639745712280273,
+           1.696081161499023438, 1.688597679138183594, 1.673851132392883301,
+           1.659391283988952637, 1.645209431648254395, 1.631297469139099121,
+           1.617647409439086914, 1.604251742362976074}};
+
+  // Stats.
+  mutable Stats stats_;
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(InterpolatedGainCurve);
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_INTERPOLATED_GAIN_CURVE_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/interpolated_gain_curve_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/interpolated_gain_curve_unittest.cc
new file mode 100644
index 0000000..7861ae9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/interpolated_gain_curve_unittest.cc
@@ -0,0 +1,203 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/interpolated_gain_curve.h"
+
+#include <array>
+#include <type_traits>
+#include <vector>
+
+#include "api/array_view.h"
+#include "common_audio/include/audio_util.h"
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "modules/audio_processing/agc2/compute_interpolated_gain_curve.h"
+#include "modules/audio_processing/agc2/limiter_db_gain_curve.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/gunit.h"
+
+namespace webrtc {
+namespace {
+
+constexpr double kLevelEpsilon = 1e-2 * kMaxAbsFloatS16Value;
+constexpr float kInterpolatedGainCurveTolerance = 1.f / 32768.f;
+ApmDataDumper apm_data_dumper(0);
+static_assert(std::is_trivially_destructible<LimiterDbGainCurve>::value, "");
+const LimiterDbGainCurve limiter;
+
+}  // namespace
+
+TEST(GainController2InterpolatedGainCurve, CreateUse) {
+  InterpolatedGainCurve igc(&apm_data_dumper, "");
+
+  const auto levels = test::LinSpace(
+      kLevelEpsilon, DbfsToFloatS16(limiter.max_input_level_db() + 1), 500);
+  for (const auto level : levels) {
+    EXPECT_GE(igc.LookUpGainToApply(level), 0.0f);
+  }
+}
+
+TEST(GainController2InterpolatedGainCurve, CheckValidOutput) {
+  InterpolatedGainCurve igc(&apm_data_dumper, "");
+
+  const auto levels = test::LinSpace(
+      kLevelEpsilon, limiter.max_input_level_linear() * 2.0, 500);
+  for (const auto level : levels) {
+    SCOPED_TRACE(std::to_string(level));
+    const float gain = igc.LookUpGainToApply(level);
+    EXPECT_LE(0.0f, gain);
+    EXPECT_LE(gain, 1.0f);
+  }
+}
+
+TEST(GainController2InterpolatedGainCurve, CheckMonotonicity) {
+  InterpolatedGainCurve igc(&apm_data_dumper, "");
+
+  const auto levels = test::LinSpace(
+      kLevelEpsilon, limiter.max_input_level_linear() + kLevelEpsilon + 0.5,
+      500);
+  float prev_gain = igc.LookUpGainToApply(0.0f);
+  for (const auto level : levels) {
+    const float gain = igc.LookUpGainToApply(level);
+    EXPECT_GE(prev_gain, gain);
+    prev_gain = gain;
+  }
+}
+
+TEST(GainController2InterpolatedGainCurve, CheckApproximation) {
+  InterpolatedGainCurve igc(&apm_data_dumper, "");
+
+  const auto levels = test::LinSpace(
+      kLevelEpsilon, limiter.max_input_level_linear() - kLevelEpsilon, 500);
+  for (const auto level : levels) {
+    SCOPED_TRACE(std::to_string(level));
+    EXPECT_LT(
+        std::fabs(limiter.GetGainLinear(level) - igc.LookUpGainToApply(level)),
+        kInterpolatedGainCurveTolerance);
+  }
+}
+
+TEST(GainController2InterpolatedGainCurve, CheckRegionBoundaries) {
+  InterpolatedGainCurve igc(&apm_data_dumper, "");
+
+  const std::vector<double> levels{
+      {kLevelEpsilon, limiter.knee_start_linear() + kLevelEpsilon,
+       limiter.limiter_start_linear() + kLevelEpsilon,
+       limiter.max_input_level_linear() + kLevelEpsilon}};
+  for (const auto level : levels) {
+    igc.LookUpGainToApply(level);
+  }
+
+  const auto stats = igc.get_stats();
+  EXPECT_EQ(1ul, stats.look_ups_identity_region);
+  EXPECT_EQ(1ul, stats.look_ups_knee_region);
+  EXPECT_EQ(1ul, stats.look_ups_limiter_region);
+  EXPECT_EQ(1ul, stats.look_ups_saturation_region);
+}
+
+TEST(GainController2InterpolatedGainCurve, CheckIdentityRegion) {
+  constexpr size_t kNumSteps = 10;
+  InterpolatedGainCurve igc(&apm_data_dumper, "");
+
+  const auto levels =
+      test::LinSpace(kLevelEpsilon, limiter.knee_start_linear(), kNumSteps);
+  for (const auto level : levels) {
+    SCOPED_TRACE(std::to_string(level));
+    EXPECT_EQ(1.0f, igc.LookUpGainToApply(level));
+  }
+
+  const auto stats = igc.get_stats();
+  EXPECT_EQ(kNumSteps - 1, stats.look_ups_identity_region);
+  EXPECT_EQ(1ul, stats.look_ups_knee_region);
+  EXPECT_EQ(0ul, stats.look_ups_limiter_region);
+  EXPECT_EQ(0ul, stats.look_ups_saturation_region);
+}
+
+TEST(GainController2InterpolatedGainCurve, CheckNoOverApproximationKnee) {
+  constexpr size_t kNumSteps = 10;
+  InterpolatedGainCurve igc(&apm_data_dumper, "");
+
+  const auto levels =
+      test::LinSpace(limiter.knee_start_linear() + kLevelEpsilon,
+                     limiter.limiter_start_linear(), kNumSteps);
+  for (const auto level : levels) {
+    SCOPED_TRACE(std::to_string(level));
+    // Small tolerance added (needed because comparing a float with a double).
+    EXPECT_LE(igc.LookUpGainToApply(level),
+              limiter.GetGainLinear(level) + 1e-7);
+  }
+
+  const auto stats = igc.get_stats();
+  EXPECT_EQ(0ul, stats.look_ups_identity_region);
+  EXPECT_EQ(kNumSteps - 1, stats.look_ups_knee_region);
+  EXPECT_EQ(1ul, stats.look_ups_limiter_region);
+  EXPECT_EQ(0ul, stats.look_ups_saturation_region);
+}
+
+TEST(GainController2InterpolatedGainCurve, CheckNoOverApproximationBeyondKnee) {
+  constexpr size_t kNumSteps = 10;
+  InterpolatedGainCurve igc(&apm_data_dumper, "");
+
+  const auto levels = test::LinSpace(
+      limiter.limiter_start_linear() + kLevelEpsilon,
+      limiter.max_input_level_linear() - kLevelEpsilon, kNumSteps);
+  for (const auto level : levels) {
+    SCOPED_TRACE(std::to_string(level));
+    // Small tolerance added (needed because comparing a float with a double).
+    EXPECT_LE(igc.LookUpGainToApply(level),
+              limiter.GetGainLinear(level) + 1e-7);
+  }
+
+  const auto stats = igc.get_stats();
+  EXPECT_EQ(0ul, stats.look_ups_identity_region);
+  EXPECT_EQ(0ul, stats.look_ups_knee_region);
+  EXPECT_EQ(kNumSteps, stats.look_ups_limiter_region);
+  EXPECT_EQ(0ul, stats.look_ups_saturation_region);
+}
+
+TEST(GainController2InterpolatedGainCurve,
+     CheckNoOverApproximationWithSaturation) {
+  constexpr size_t kNumSteps = 3;
+  InterpolatedGainCurve igc(&apm_data_dumper, "");
+
+  const auto levels = test::LinSpace(
+      limiter.max_input_level_linear() + kLevelEpsilon,
+      limiter.max_input_level_linear() + kLevelEpsilon + 0.5, kNumSteps);
+  for (const auto level : levels) {
+    SCOPED_TRACE(std::to_string(level));
+    EXPECT_LE(igc.LookUpGainToApply(level), limiter.GetGainLinear(level));
+  }
+
+  const auto stats = igc.get_stats();
+  EXPECT_EQ(0ul, stats.look_ups_identity_region);
+  EXPECT_EQ(0ul, stats.look_ups_knee_region);
+  EXPECT_EQ(0ul, stats.look_ups_limiter_region);
+  EXPECT_EQ(kNumSteps, stats.look_ups_saturation_region);
+}
+
+TEST(GainController2InterpolatedGainCurve, CheckApproximationParams) {
+  test::InterpolatedParameters parameters =
+      test::ComputeInterpolatedGainCurveApproximationParams();
+
+  InterpolatedGainCurve igc(&apm_data_dumper, "");
+
+  for (size_t i = 0; i < kInterpolatedGainCurveTotalPoints; ++i) {
+    // The tolerance levels are chosen to account for deviations due
+    // to computing with single precision floating point numbers.
+    EXPECT_NEAR(igc.approximation_params_x_[i],
+                parameters.computed_approximation_params_x[i], 0.9f);
+    EXPECT_NEAR(igc.approximation_params_m_[i],
+                parameters.computed_approximation_params_m[i], 0.00001f);
+    EXPECT_NEAR(igc.approximation_params_q_[i],
+                parameters.computed_approximation_params_q[i], 0.001f);
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter.cc
new file mode 100644
index 0000000..ed7d3ee
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter.cc
@@ -0,0 +1,152 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/limiter.h"
+
+#include <algorithm>
+#include <array>
+#include <cmath>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_minmax.h"
+
+namespace webrtc {
+namespace {
+
+// This constant affects the way scaling factors are interpolated for the first
+// sub-frame of a frame. Only in the case in which the first sub-frame has an
+// estimated level which is greater than the that of the previous analyzed
+// sub-frame, linear interpolation is replaced with a power function which
+// reduces the chances of over-shooting (and hence saturation), however reducing
+// the fixed gain effectiveness.
+constexpr float kAttackFirstSubframeInterpolationPower = 8.f;
+
+void InterpolateFirstSubframe(float last_factor,
+                              float current_factor,
+                              rtc::ArrayView<float> subframe) {
+  const auto n = subframe.size();
+  constexpr auto p = kAttackFirstSubframeInterpolationPower;
+  for (size_t i = 0; i < n; ++i) {
+    subframe[i] = std::pow(1.f - i / n, p) * (last_factor - current_factor) +
+                  current_factor;
+  }
+}
+
+void ComputePerSampleSubframeFactors(
+    const std::array<float, kSubFramesInFrame + 1>& scaling_factors,
+    size_t samples_per_channel,
+    rtc::ArrayView<float> per_sample_scaling_factors) {
+  const size_t num_subframes = scaling_factors.size() - 1;
+  const size_t subframe_size =
+      rtc::CheckedDivExact(samples_per_channel, num_subframes);
+
+  // Handle first sub-frame differently in case of attack.
+  const bool is_attack = scaling_factors[0] > scaling_factors[1];
+  if (is_attack) {
+    InterpolateFirstSubframe(
+        scaling_factors[0], scaling_factors[1],
+        rtc::ArrayView<float>(
+            per_sample_scaling_factors.subview(0, subframe_size)));
+  }
+
+  for (size_t i = is_attack ? 1 : 0; i < num_subframes; ++i) {
+    const size_t subframe_start = i * subframe_size;
+    const float scaling_start = scaling_factors[i];
+    const float scaling_end = scaling_factors[i + 1];
+    const float scaling_diff = (scaling_end - scaling_start) / subframe_size;
+    for (size_t j = 0; j < subframe_size; ++j) {
+      per_sample_scaling_factors[subframe_start + j] =
+          scaling_start + scaling_diff * j;
+    }
+  }
+}
+
+void ScaleSamples(rtc::ArrayView<const float> per_sample_scaling_factors,
+                  AudioFrameView<float> signal) {
+  const size_t samples_per_channel = signal.samples_per_channel();
+  RTC_DCHECK_EQ(samples_per_channel, per_sample_scaling_factors.size());
+  for (size_t i = 0; i < signal.num_channels(); ++i) {
+    auto channel = signal.channel(i);
+    for (size_t j = 0; j < samples_per_channel; ++j) {
+      channel[j] = rtc::SafeClamp(channel[j] * per_sample_scaling_factors[j],
+                                  kMinFloatS16Value, kMaxFloatS16Value);
+    }
+  }
+}
+
+void CheckLimiterSampleRate(size_t sample_rate_hz) {
+  // Check that per_sample_scaling_factors_ is large enough.
+  RTC_DCHECK_LE(sample_rate_hz,
+                kMaximalNumberOfSamplesPerChannel * 1000 / kFrameDurationMs);
+}
+
+}  // namespace
+
+Limiter::Limiter(size_t sample_rate_hz,
+                 ApmDataDumper* apm_data_dumper,
+                 const std::string& histogram_name)
+    : interp_gain_curve_(apm_data_dumper, histogram_name),
+      level_estimator_(sample_rate_hz, apm_data_dumper),
+      apm_data_dumper_(apm_data_dumper) {
+  CheckLimiterSampleRate(sample_rate_hz);
+}
+
+Limiter::~Limiter() = default;
+
+void Limiter::Process(AudioFrameView<float> signal) {
+  const auto level_estimate = level_estimator_.ComputeLevel(signal);
+
+  RTC_DCHECK_EQ(level_estimate.size() + 1, scaling_factors_.size());
+  scaling_factors_[0] = last_scaling_factor_;
+  std::transform(level_estimate.begin(), level_estimate.end(),
+                 scaling_factors_.begin() + 1, [this](float x) {
+                   return interp_gain_curve_.LookUpGainToApply(x);
+                 });
+
+  const size_t samples_per_channel = signal.samples_per_channel();
+  RTC_DCHECK_LE(samples_per_channel, kMaximalNumberOfSamplesPerChannel);
+
+  auto per_sample_scaling_factors = rtc::ArrayView<float>(
+      &per_sample_scaling_factors_[0], samples_per_channel);
+  ComputePerSampleSubframeFactors(scaling_factors_, samples_per_channel,
+                                  per_sample_scaling_factors);
+  ScaleSamples(per_sample_scaling_factors, signal);
+
+  last_scaling_factor_ = scaling_factors_.back();
+
+  // Dump data for debug.
+  apm_data_dumper_->DumpRaw("agc2_limiter_last_scaling_factor",
+                            last_scaling_factor_);
+  apm_data_dumper_->DumpRaw(
+      "agc2_limiter_region",
+      static_cast<int>(interp_gain_curve_.get_stats().region));
+}
+
+InterpolatedGainCurve::Stats Limiter::GetGainCurveStats() const {
+  return interp_gain_curve_.get_stats();
+}
+
+void Limiter::SetSampleRate(size_t sample_rate_hz) {
+  CheckLimiterSampleRate(sample_rate_hz);
+  level_estimator_.SetSampleRate(sample_rate_hz);
+}
+
+void Limiter::Reset() {
+  level_estimator_.Reset();
+}
+
+float Limiter::LastAudioLevel() const {
+  return level_estimator_.LastAudioLevel();
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter.h
new file mode 100644
index 0000000..df7b540
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter.h
@@ -0,0 +1,64 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_LIMITER_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_LIMITER_H_
+
+#include <string>
+#include <vector>
+
+#include "modules/audio_processing/agc2/fixed_digital_level_estimator.h"
+#include "modules/audio_processing/agc2/interpolated_gain_curve.h"
+#include "modules/audio_processing/include/audio_frame_view.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+class ApmDataDumper;
+
+class Limiter {
+ public:
+  Limiter(size_t sample_rate_hz,
+          ApmDataDumper* apm_data_dumper,
+          const std::string& histogram_name_prefix);
+  Limiter(const Limiter& limiter) = delete;
+  Limiter& operator=(const Limiter& limiter) = delete;
+  ~Limiter();
+
+  // Applies limiter and hard-clipping to |signal|.
+  void Process(AudioFrameView<float> signal);
+  InterpolatedGainCurve::Stats GetGainCurveStats() const;
+
+  // Supported rates must be
+  // * supported by FixedDigitalLevelEstimator
+  // * below kMaximalNumberOfSamplesPerChannel*1000/kFrameDurationMs
+  //   so that samples_per_channel fit in the
+  //   per_sample_scaling_factors_ array.
+  void SetSampleRate(size_t sample_rate_hz);
+
+  // Resets the internal state.
+  void Reset();
+
+  float LastAudioLevel() const;
+
+ private:
+  const InterpolatedGainCurve interp_gain_curve_;
+  FixedDigitalLevelEstimator level_estimator_;
+  ApmDataDumper* const apm_data_dumper_ = nullptr;
+
+  // Work array containing the sub-frame scaling factors to be interpolated.
+  std::array<float, kSubFramesInFrame + 1> scaling_factors_ = {};
+  std::array<float, kMaximalNumberOfSamplesPerChannel>
+      per_sample_scaling_factors_ = {};
+  float last_scaling_factor_ = 1.f;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_LIMITER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter_db_gain_curve.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter_db_gain_curve.cc
new file mode 100644
index 0000000..d55ed5d
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter_db_gain_curve.cc
@@ -0,0 +1,138 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/limiter_db_gain_curve.h"
+
+#include <cmath>
+
+#include "common_audio/include/audio_util.h"
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+
+double ComputeKneeStart(double max_input_level_db,
+                        double knee_smoothness_db,
+                        double compression_ratio) {
+  RTC_CHECK_LT((compression_ratio - 1.0) * knee_smoothness_db /
+                   (2.0 * compression_ratio),
+               max_input_level_db);
+  return -knee_smoothness_db / 2.0 -
+         max_input_level_db / (compression_ratio - 1.0);
+}
+
+std::array<double, 3> ComputeKneeRegionPolynomial(double knee_start_dbfs,
+                                                  double knee_smoothness_db,
+                                                  double compression_ratio) {
+  const double a = (1.0 - compression_ratio) /
+                   (2.0 * knee_smoothness_db * compression_ratio);
+  const double b = 1.0 - 2.0 * a * knee_start_dbfs;
+  const double c = a * knee_start_dbfs * knee_start_dbfs;
+  return {{a, b, c}};
+}
+
+double ComputeLimiterD1(double max_input_level_db, double compression_ratio) {
+  return (std::pow(10.0, -max_input_level_db / (20.0 * compression_ratio)) *
+          (1.0 - compression_ratio) / compression_ratio) /
+         kMaxAbsFloatS16Value;
+}
+
+constexpr double ComputeLimiterD2(double compression_ratio) {
+  return (1.0 - 2.0 * compression_ratio) / compression_ratio;
+}
+
+double ComputeLimiterI2(double max_input_level_db,
+                        double compression_ratio,
+                        double gain_curve_limiter_i1) {
+  RTC_CHECK_NE(gain_curve_limiter_i1, 0.f);
+  return std::pow(10.0, -max_input_level_db / (20.0 * compression_ratio)) /
+         gain_curve_limiter_i1 /
+         std::pow(kMaxAbsFloatS16Value, gain_curve_limiter_i1 - 1);
+}
+
+}  // namespace
+
+LimiterDbGainCurve::LimiterDbGainCurve()
+    : max_input_level_linear_(DbfsToFloatS16(max_input_level_db_)),
+      knee_start_dbfs_(ComputeKneeStart(max_input_level_db_,
+                                        knee_smoothness_db_,
+                                        compression_ratio_)),
+      knee_start_linear_(DbfsToFloatS16(knee_start_dbfs_)),
+      limiter_start_dbfs_(knee_start_dbfs_ + knee_smoothness_db_),
+      limiter_start_linear_(DbfsToFloatS16(limiter_start_dbfs_)),
+      knee_region_polynomial_(ComputeKneeRegionPolynomial(knee_start_dbfs_,
+                                                          knee_smoothness_db_,
+                                                          compression_ratio_)),
+      gain_curve_limiter_d1_(
+          ComputeLimiterD1(max_input_level_db_, compression_ratio_)),
+      gain_curve_limiter_d2_(ComputeLimiterD2(compression_ratio_)),
+      gain_curve_limiter_i1_(1.0 / compression_ratio_),
+      gain_curve_limiter_i2_(ComputeLimiterI2(max_input_level_db_,
+                                              compression_ratio_,
+                                              gain_curve_limiter_i1_)) {
+  static_assert(knee_smoothness_db_ > 0.0f, "");
+  static_assert(compression_ratio_ > 1.0f, "");
+  RTC_CHECK_GE(max_input_level_db_, knee_start_dbfs_ + knee_smoothness_db_);
+}
+
+constexpr double LimiterDbGainCurve::max_input_level_db_;
+constexpr double LimiterDbGainCurve::knee_smoothness_db_;
+constexpr double LimiterDbGainCurve::compression_ratio_;
+
+double LimiterDbGainCurve::GetOutputLevelDbfs(double input_level_dbfs) const {
+  if (input_level_dbfs < knee_start_dbfs_) {
+    return input_level_dbfs;
+  } else if (input_level_dbfs < limiter_start_dbfs_) {
+    return GetKneeRegionOutputLevelDbfs(input_level_dbfs);
+  }
+  return GetCompressorRegionOutputLevelDbfs(input_level_dbfs);
+}
+
+double LimiterDbGainCurve::GetGainLinear(double input_level_linear) const {
+  if (input_level_linear < knee_start_linear_) {
+    return 1.0;
+  }
+  return DbfsToFloatS16(
+             GetOutputLevelDbfs(FloatS16ToDbfs(input_level_linear))) /
+         input_level_linear;
+}
+
+// Computes the first derivative of GetGainLinear() in |x|.
+double LimiterDbGainCurve::GetGainFirstDerivativeLinear(double x) const {
+  // Beyond-knee region only.
+  RTC_CHECK_GE(x, limiter_start_linear_ - 1e-7 * kMaxAbsFloatS16Value);
+  return gain_curve_limiter_d1_ *
+         std::pow(x / kMaxAbsFloatS16Value, gain_curve_limiter_d2_);
+}
+
+// Computes the integral of GetGainLinear() in the range [x0, x1].
+double LimiterDbGainCurve::GetGainIntegralLinear(double x0, double x1) const {
+  RTC_CHECK_LE(x0, x1);                     // Valid interval.
+  RTC_CHECK_GE(x0, limiter_start_linear_);  // Beyond-knee region only.
+  auto limiter_integral = [this](const double& x) {
+    return gain_curve_limiter_i2_ * std::pow(x, gain_curve_limiter_i1_);
+  };
+  return limiter_integral(x1) - limiter_integral(x0);
+}
+
+double LimiterDbGainCurve::GetKneeRegionOutputLevelDbfs(
+    double input_level_dbfs) const {
+  return knee_region_polynomial_[0] * input_level_dbfs * input_level_dbfs +
+         knee_region_polynomial_[1] * input_level_dbfs +
+         knee_region_polynomial_[2];
+}
+
+double LimiterDbGainCurve::GetCompressorRegionOutputLevelDbfs(
+    double input_level_dbfs) const {
+  return (input_level_dbfs - max_input_level_db_) / compression_ratio_;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter_db_gain_curve.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter_db_gain_curve.h
new file mode 100644
index 0000000..9086e26
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter_db_gain_curve.h
@@ -0,0 +1,76 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_LIMITER_DB_GAIN_CURVE_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_LIMITER_DB_GAIN_CURVE_H_
+
+#include <array>
+
+#include "modules/audio_processing/agc2/agc2_testing_common.h"
+
+namespace webrtc {
+
+// A class for computing a limiter gain curve (in dB scale) given a set of
+// hard-coded parameters (namely, kLimiterDbGainCurveMaxInputLevelDbFs,
+// kLimiterDbGainCurveKneeSmoothnessDb, and
+// kLimiterDbGainCurveCompressionRatio). The generated curve consists of four
+// regions: identity (linear), knee (quadratic polynomial), compression
+// (linear), saturation (linear). The aforementioned constants are used to shape
+// the different regions.
+class LimiterDbGainCurve {
+ public:
+  LimiterDbGainCurve();
+
+  double max_input_level_db() const { return max_input_level_db_; }
+  double max_input_level_linear() const { return max_input_level_linear_; }
+  double knee_start_linear() const { return knee_start_linear_; }
+  double limiter_start_linear() const { return limiter_start_linear_; }
+
+  // These methods can be marked 'constexpr' in C++ 14.
+  double GetOutputLevelDbfs(double input_level_dbfs) const;
+  double GetGainLinear(double input_level_linear) const;
+  double GetGainFirstDerivativeLinear(double x) const;
+  double GetGainIntegralLinear(double x0, double x1) const;
+
+ private:
+  double GetKneeRegionOutputLevelDbfs(double input_level_dbfs) const;
+  double GetCompressorRegionOutputLevelDbfs(double input_level_dbfs) const;
+
+  static constexpr double max_input_level_db_ = test::kLimiterMaxInputLevelDbFs;
+  static constexpr double knee_smoothness_db_ = test::kLimiterKneeSmoothnessDb;
+  static constexpr double compression_ratio_ = test::kLimiterCompressionRatio;
+
+  const double max_input_level_linear_;
+
+  // Do not modify signal with level <= knee_start_dbfs_.
+  const double knee_start_dbfs_;
+  const double knee_start_linear_;
+
+  // The upper end of the knee region, which is between knee_start_dbfs_ and
+  // limiter_start_dbfs_.
+  const double limiter_start_dbfs_;
+  const double limiter_start_linear_;
+
+  // Coefficients {a, b, c} of the knee region polynomial
+  // ax^2 + bx + c in the DB scale.
+  const std::array<double, 3> knee_region_polynomial_;
+
+  // Parameters for the computation of the first derivative of GetGainLinear().
+  const double gain_curve_limiter_d1_;
+  const double gain_curve_limiter_d2_;
+
+  // Parameters for the computation of the integral of GetGainLinear().
+  const double gain_curve_limiter_i1_;
+  const double gain_curve_limiter_i2_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_LIMITER_DB_GAIN_CURVE_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter_db_gain_curve_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter_db_gain_curve_unittest.cc
new file mode 100644
index 0000000..049c8d5
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter_db_gain_curve_unittest.cc
@@ -0,0 +1,60 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/limiter_db_gain_curve.h"
+
+#include "rtc_base/gunit.h"
+
+namespace webrtc {
+
+TEST(FixedDigitalGainController2Limiter, ConstructDestruct) {
+  LimiterDbGainCurve l;
+}
+
+TEST(FixedDigitalGainController2Limiter, GainCurveShouldBeMonotone) {
+  LimiterDbGainCurve l;
+  float last_output_level = 0.f;
+  bool has_last_output_level = false;
+  for (float level = -90.f; level <= l.max_input_level_db(); level += 0.5f) {
+    const float current_output_level = l.GetOutputLevelDbfs(level);
+    if (!has_last_output_level) {
+      last_output_level = current_output_level;
+      has_last_output_level = true;
+    }
+    EXPECT_LE(last_output_level, current_output_level);
+    last_output_level = current_output_level;
+  }
+}
+
+TEST(FixedDigitalGainController2Limiter, GainCurveShouldBeContinuous) {
+  LimiterDbGainCurve l;
+  float last_output_level = 0.f;
+  bool has_last_output_level = false;
+  constexpr float kMaxDelta = 0.5f;
+  for (float level = -90.f; level <= l.max_input_level_db(); level += 0.5f) {
+    const float current_output_level = l.GetOutputLevelDbfs(level);
+    if (!has_last_output_level) {
+      last_output_level = current_output_level;
+      has_last_output_level = true;
+    }
+    EXPECT_LE(current_output_level, last_output_level + kMaxDelta);
+    last_output_level = current_output_level;
+  }
+}
+
+TEST(FixedDigitalGainController2Limiter, OutputGainShouldBeLessThanFullScale) {
+  LimiterDbGainCurve l;
+  for (float level = -90.f; level <= l.max_input_level_db(); level += 0.5f) {
+    const float current_output_level = l.GetOutputLevelDbfs(level);
+    EXPECT_LE(current_output_level, 0.f);
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter_unittest.cc
new file mode 100644
index 0000000..e662a7f
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/limiter_unittest.cc
@@ -0,0 +1,60 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/limiter.h"
+
+#include "common_audio/include/audio_util.h"
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "modules/audio_processing/agc2/agc2_testing_common.h"
+#include "modules/audio_processing/agc2/vector_float_frame.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/gunit.h"
+
+namespace webrtc {
+
+TEST(Limiter, LimiterShouldConstructAndRun) {
+  const int sample_rate_hz = 48000;
+  ApmDataDumper apm_data_dumper(0);
+
+  Limiter limiter(sample_rate_hz, &apm_data_dumper, "");
+
+  VectorFloatFrame vectors_with_float_frame(1, sample_rate_hz / 100,
+                                            kMaxAbsFloatS16Value);
+  limiter.Process(vectors_with_float_frame.float_frame_view());
+}
+
+TEST(Limiter, OutputVolumeAboveThreshold) {
+  const int sample_rate_hz = 48000;
+  const float input_level =
+      (kMaxAbsFloatS16Value + DbfsToFloatS16(test::kLimiterMaxInputLevelDbFs)) /
+      2.f;
+  ApmDataDumper apm_data_dumper(0);
+
+  Limiter limiter(sample_rate_hz, &apm_data_dumper, "");
+
+  // Give the level estimator time to adapt.
+  for (int i = 0; i < 5; ++i) {
+    VectorFloatFrame vectors_with_float_frame(1, sample_rate_hz / 100,
+                                              input_level);
+    limiter.Process(vectors_with_float_frame.float_frame_view());
+  }
+
+  VectorFloatFrame vectors_with_float_frame(1, sample_rate_hz / 100,
+                                            input_level);
+  limiter.Process(vectors_with_float_frame.float_frame_view());
+  rtc::ArrayView<const float> channel =
+      vectors_with_float_frame.float_frame_view().channel(0);
+
+  for (const auto& sample : channel) {
+    EXPECT_LT(0.9f * kMaxAbsFloatS16Value, sample);
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/noise_level_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/noise_level_estimator.cc
new file mode 100644
index 0000000..10e8437
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/noise_level_estimator.cc
@@ -0,0 +1,260 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/noise_level_estimator.h"
+
+#include <stddef.h>
+
+#include <algorithm>
+#include <cmath>
+#include <numeric>
+
+#include "api/array_view.h"
+#include "common_audio/include/audio_util.h"
+#include "modules/audio_processing/agc2/signal_classifier.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+constexpr int kFramesPerSecond = 100;
+
+float FrameEnergy(const AudioFrameView<const float>& audio) {
+  float energy = 0.0f;
+  for (size_t k = 0; k < audio.num_channels(); ++k) {
+    float channel_energy =
+        std::accumulate(audio.channel(k).begin(), audio.channel(k).end(), 0.0f,
+                        [](float a, float b) -> float { return a + b * b; });
+    energy = std::max(channel_energy, energy);
+  }
+  return energy;
+}
+
+float EnergyToDbfs(float signal_energy, size_t num_samples) {
+  const float rms = std::sqrt(signal_energy / num_samples);
+  return FloatS16ToDbfs(rms);
+}
+
+class NoiseLevelEstimatorImpl : public NoiseLevelEstimator {
+ public:
+  NoiseLevelEstimatorImpl(ApmDataDumper* data_dumper)
+      : data_dumper_(data_dumper), signal_classifier_(data_dumper) {
+    // Initially assume that 48 kHz will be used. `Analyze()` will detect the
+    // used sample rate and call `Initialize()` again if needed.
+    Initialize(/*sample_rate_hz=*/48000);
+  }
+  NoiseLevelEstimatorImpl(const NoiseLevelEstimatorImpl&) = delete;
+  NoiseLevelEstimatorImpl& operator=(const NoiseLevelEstimatorImpl&) = delete;
+  ~NoiseLevelEstimatorImpl() = default;
+
+  float Analyze(const AudioFrameView<const float>& frame) override {
+    data_dumper_->DumpRaw("agc2_noise_level_estimator_hold_counter",
+                          noise_energy_hold_counter_);
+    const int sample_rate_hz =
+        static_cast<int>(frame.samples_per_channel() * kFramesPerSecond);
+    if (sample_rate_hz != sample_rate_hz_) {
+      Initialize(sample_rate_hz);
+    }
+    const float frame_energy = FrameEnergy(frame);
+    if (frame_energy <= 0.f) {
+      RTC_DCHECK_GE(frame_energy, 0.f);
+      data_dumper_->DumpRaw("agc2_noise_level_estimator_signal_type", -1);
+      return EnergyToDbfs(noise_energy_, frame.samples_per_channel());
+    }
+
+    if (first_update_) {
+      // Initialize the noise energy to the frame energy.
+      first_update_ = false;
+      data_dumper_->DumpRaw("agc2_noise_level_estimator_signal_type", -1);
+      noise_energy_ = std::max(frame_energy, min_noise_energy_);
+      return EnergyToDbfs(noise_energy_, frame.samples_per_channel());
+    }
+
+    const SignalClassifier::SignalType signal_type =
+        signal_classifier_.Analyze(frame.channel(0));
+    data_dumper_->DumpRaw("agc2_noise_level_estimator_signal_type",
+                          static_cast<int>(signal_type));
+
+    // Update the noise estimate in a minimum statistics-type manner.
+    if (signal_type == SignalClassifier::SignalType::kStationary) {
+      if (frame_energy > noise_energy_) {
+        // Leak the estimate upwards towards the frame energy if no recent
+        // downward update.
+        noise_energy_hold_counter_ =
+            std::max(noise_energy_hold_counter_ - 1, 0);
+
+        if (noise_energy_hold_counter_ == 0) {
+          constexpr float kMaxNoiseEnergyFactor = 1.01f;
+          noise_energy_ =
+              std::min(noise_energy_ * kMaxNoiseEnergyFactor, frame_energy);
+        }
+      } else {
+        // Update smoothly downwards with a limited maximum update magnitude.
+        constexpr float kMinNoiseEnergyFactor = 0.9f;
+        constexpr float kNoiseEnergyDeltaFactor = 0.05f;
+        noise_energy_ =
+            std::max(noise_energy_ * kMinNoiseEnergyFactor,
+                     noise_energy_ - kNoiseEnergyDeltaFactor *
+                                         (noise_energy_ - frame_energy));
+        // Prevent an energy increase for the next 10 seconds.
+        constexpr int kNumFramesToEnergyIncreaseAllowed = 1000;
+        noise_energy_hold_counter_ = kNumFramesToEnergyIncreaseAllowed;
+      }
+    } else {
+      // TODO(bugs.webrtc.org/7494): Remove to not forget the estimated level.
+      // For a non-stationary signal, leak the estimate downwards in order to
+      // avoid estimate locking due to incorrect signal classification.
+      noise_energy_ = noise_energy_ * 0.99f;
+    }
+
+    // Ensure a minimum of the estimate.
+    noise_energy_ = std::max(noise_energy_, min_noise_energy_);
+    return EnergyToDbfs(noise_energy_, frame.samples_per_channel());
+  }
+
+ private:
+  void Initialize(int sample_rate_hz) {
+    sample_rate_hz_ = sample_rate_hz;
+    noise_energy_ = 1.0f;
+    first_update_ = true;
+    // Initialize the minimum noise energy to -84 dBFS.
+    min_noise_energy_ = sample_rate_hz * 2.0f * 2.0f / kFramesPerSecond;
+    noise_energy_hold_counter_ = 0;
+    signal_classifier_.Initialize(sample_rate_hz);
+  }
+
+  ApmDataDumper* const data_dumper_;
+  int sample_rate_hz_;
+  float min_noise_energy_;
+  bool first_update_;
+  float noise_energy_;
+  int noise_energy_hold_counter_;
+  SignalClassifier signal_classifier_;
+};
+
+// Updates the noise floor with instant decay and slow attack. This tuning is
+// specific for AGC2, so that (i) it can promptly increase the gain if the noise
+// floor drops (instant decay) and (ii) in case of music or fast speech, due to
+// which the noise floor can be overestimated, the gain reduction is slowed
+// down.
+float SmoothNoiseFloorEstimate(float current_estimate, float new_estimate) {
+  constexpr float kAttack = 0.5f;
+  if (current_estimate < new_estimate) {
+    // Attack phase.
+    return kAttack * new_estimate + (1.0f - kAttack) * current_estimate;
+  }
+  // Instant attack.
+  return new_estimate;
+}
+
+class NoiseFloorEstimator : public NoiseLevelEstimator {
+ public:
+  // Update the noise floor every 5 seconds.
+  static constexpr int kUpdatePeriodNumFrames = 500;
+  static_assert(kUpdatePeriodNumFrames >= 200,
+                "A too small value may cause noise level overestimation.");
+  static_assert(kUpdatePeriodNumFrames <= 1500,
+                "A too large value may make AGC2 slow at reacting to increased "
+                "noise levels.");
+
+  NoiseFloorEstimator(ApmDataDumper* data_dumper) : data_dumper_(data_dumper) {
+    // Initially assume that 48 kHz will be used. `Analyze()` will detect the
+    // used sample rate and call `Initialize()` again if needed.
+    Initialize(/*sample_rate_hz=*/48000);
+  }
+  NoiseFloorEstimator(const NoiseFloorEstimator&) = delete;
+  NoiseFloorEstimator& operator=(const NoiseFloorEstimator&) = delete;
+  ~NoiseFloorEstimator() = default;
+
+  float Analyze(const AudioFrameView<const float>& frame) override {
+    // Detect sample rate changes.
+    const int sample_rate_hz =
+        static_cast<int>(frame.samples_per_channel() * kFramesPerSecond);
+    if (sample_rate_hz != sample_rate_hz_) {
+      Initialize(sample_rate_hz);
+    }
+
+    const float frame_energy = FrameEnergy(frame);
+    if (frame_energy <= min_noise_energy_) {
+      // Ignore frames when muted or below the minimum measurable energy.
+      data_dumper_->DumpRaw("agc2_noise_floor_estimator_preliminary_level",
+                            noise_energy_);
+      return EnergyToDbfs(noise_energy_, frame.samples_per_channel());
+    }
+
+    if (preliminary_noise_energy_set_) {
+      preliminary_noise_energy_ =
+          std::min(preliminary_noise_energy_, frame_energy);
+    } else {
+      preliminary_noise_energy_ = frame_energy;
+      preliminary_noise_energy_set_ = true;
+    }
+    data_dumper_->DumpRaw("agc2_noise_floor_estimator_preliminary_level",
+                          preliminary_noise_energy_);
+
+    if (counter_ == 0) {
+      // Full period observed.
+      first_period_ = false;
+      // Update the estimated noise floor energy with the preliminary
+      // estimation.
+      noise_energy_ = SmoothNoiseFloorEstimate(
+          /*current_estimate=*/noise_energy_,
+          /*new_estimate=*/preliminary_noise_energy_);
+      // Reset for a new observation period.
+      counter_ = kUpdatePeriodNumFrames;
+      preliminary_noise_energy_set_ = false;
+    } else if (first_period_) {
+      // While analyzing the signal during the initial period, continuously
+      // update the estimated noise energy, which is monotonic.
+      noise_energy_ = preliminary_noise_energy_;
+      counter_--;
+    } else {
+      // During the observation period it's only allowed to lower the energy.
+      noise_energy_ = std::min(noise_energy_, preliminary_noise_energy_);
+      counter_--;
+    }
+    return EnergyToDbfs(noise_energy_, frame.samples_per_channel());
+  }
+
+ private:
+  void Initialize(int sample_rate_hz) {
+    sample_rate_hz_ = sample_rate_hz;
+    first_period_ = true;
+    preliminary_noise_energy_set_ = false;
+    // Initialize the minimum noise energy to -84 dBFS.
+    min_noise_energy_ = sample_rate_hz * 2.0f * 2.0f / kFramesPerSecond;
+    preliminary_noise_energy_ = min_noise_energy_;
+    noise_energy_ = min_noise_energy_;
+    counter_ = kUpdatePeriodNumFrames;
+  }
+
+  ApmDataDumper* const data_dumper_;
+  int sample_rate_hz_;
+  float min_noise_energy_;
+  bool first_period_;
+  bool preliminary_noise_energy_set_;
+  float preliminary_noise_energy_;
+  float noise_energy_;
+  int counter_;
+};
+
+}  // namespace
+
+std::unique_ptr<NoiseLevelEstimator> CreateStationaryNoiseEstimator(
+    ApmDataDumper* data_dumper) {
+  return std::make_unique<NoiseLevelEstimatorImpl>(data_dumper);
+}
+
+std::unique_ptr<NoiseLevelEstimator> CreateNoiseFloorEstimator(
+    ApmDataDumper* data_dumper) {
+  return std::make_unique<NoiseFloorEstimator>(data_dumper);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/noise_level_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/noise_level_estimator.h
new file mode 100644
index 0000000..94aecda
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/noise_level_estimator.h
@@ -0,0 +1,40 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_NOISE_LEVEL_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_NOISE_LEVEL_ESTIMATOR_H_
+
+#include <memory>
+
+#include "modules/audio_processing/include/audio_frame_view.h"
+
+namespace webrtc {
+class ApmDataDumper;
+
+// Noise level estimator interface.
+class NoiseLevelEstimator {
+ public:
+  virtual ~NoiseLevelEstimator() = default;
+  // Analyzes a 10 ms `frame`, updates the noise level estimation and returns
+  // the value for the latter in dBFS.
+  virtual float Analyze(const AudioFrameView<const float>& frame) = 0;
+};
+
+// Creates a noise level estimator based on stationarity detection.
+std::unique_ptr<NoiseLevelEstimator> CreateStationaryNoiseEstimator(
+    ApmDataDumper* data_dumper);
+
+// Creates a noise level estimator based on noise floor detection.
+std::unique_ptr<NoiseLevelEstimator> CreateNoiseFloorEstimator(
+    ApmDataDumper* data_dumper);
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_NOISE_LEVEL_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/noise_level_estimator_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/noise_level_estimator_unittest.cc
new file mode 100644
index 0000000..51ad1ba
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/noise_level_estimator_unittest.cc
@@ -0,0 +1,136 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/noise_level_estimator.h"
+
+#include <array>
+#include <cmath>
+#include <functional>
+#include <limits>
+
+#include "api/function_view.h"
+#include "modules/audio_processing/agc2/agc2_testing_common.h"
+#include "modules/audio_processing/agc2/vector_float_frame.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/gunit.h"
+
+namespace webrtc {
+namespace {
+
+constexpr int kNumIterations = 200;
+constexpr int kFramesPerSecond = 100;
+
+// Runs the noise estimator on audio generated by 'sample_generator'
+// for kNumIterations. Returns the last noise level estimate.
+float RunEstimator(rtc::FunctionView<float()> sample_generator,
+                   NoiseLevelEstimator& estimator,
+                   int sample_rate_hz) {
+  const int samples_per_channel =
+      rtc::CheckedDivExact(sample_rate_hz, kFramesPerSecond);
+  VectorFloatFrame signal(1, samples_per_channel, 0.0f);
+  for (int i = 0; i < kNumIterations; ++i) {
+    AudioFrameView<float> frame_view = signal.float_frame_view();
+    for (int j = 0; j < samples_per_channel; ++j) {
+      frame_view.channel(0)[j] = sample_generator();
+    }
+    estimator.Analyze(frame_view);
+  }
+  return estimator.Analyze(signal.float_frame_view());
+}
+
+class NoiseEstimatorParametrization : public ::testing::TestWithParam<int> {
+ protected:
+  int sample_rate_hz() const { return GetParam(); }
+};
+
+// White random noise is stationary, but does not trigger the detector
+// every frame due to the randomness.
+TEST_P(NoiseEstimatorParametrization, StationaryNoiseEstimatorWithRandomNoise) {
+  ApmDataDumper data_dumper(0);
+  auto estimator = CreateStationaryNoiseEstimator(&data_dumper);
+
+  test::WhiteNoiseGenerator gen(/*min_amplitude=*/test::kMinS16,
+                                /*max_amplitude=*/test::kMaxS16);
+  const float noise_level_dbfs =
+      RunEstimator(gen, *estimator, sample_rate_hz());
+  EXPECT_NEAR(noise_level_dbfs, -5.5f, 1.0f);
+}
+
+// Sine curves are (very) stationary. They trigger the detector all
+// the time. Except for a few initial frames.
+TEST_P(NoiseEstimatorParametrization, StationaryNoiseEstimatorWithSineTone) {
+  ApmDataDumper data_dumper(0);
+  auto estimator = CreateStationaryNoiseEstimator(&data_dumper);
+
+  test::SineGenerator gen(/*amplitude=*/test::kMaxS16, /*frequency_hz=*/600.0f,
+                          sample_rate_hz());
+  const float noise_level_dbfs =
+      RunEstimator(gen, *estimator, sample_rate_hz());
+  EXPECT_NEAR(noise_level_dbfs, -3.0f, 1.0f);
+}
+
+// Pulses are transient if they are far enough apart. They shouldn't
+// trigger the noise detector.
+TEST_P(NoiseEstimatorParametrization, StationaryNoiseEstimatorWithPulseTone) {
+  ApmDataDumper data_dumper(0);
+  auto estimator = CreateStationaryNoiseEstimator(&data_dumper);
+
+  test::PulseGenerator gen(/*pulse_amplitude=*/test::kMaxS16,
+                           /*no_pulse_amplitude=*/10.0f, /*frequency_hz=*/20.0f,
+                           sample_rate_hz());
+  const int noise_level_dbfs = RunEstimator(gen, *estimator, sample_rate_hz());
+  EXPECT_NEAR(noise_level_dbfs, -79.0f, 1.0f);
+}
+
+// Checks that full scale white noise maps to about -5.5 dBFS.
+TEST_P(NoiseEstimatorParametrization, NoiseFloorEstimatorWithRandomNoise) {
+  ApmDataDumper data_dumper(0);
+  auto estimator = CreateNoiseFloorEstimator(&data_dumper);
+
+  test::WhiteNoiseGenerator gen(/*min_amplitude=*/test::kMinS16,
+                                /*max_amplitude=*/test::kMaxS16);
+  const float noise_level_dbfs =
+      RunEstimator(gen, *estimator, sample_rate_hz());
+  EXPECT_NEAR(noise_level_dbfs, -5.5f, 0.5f);
+}
+
+// Checks that a full scale sine wave maps to about -3 dBFS.
+TEST_P(NoiseEstimatorParametrization, NoiseFloorEstimatorWithSineTone) {
+  ApmDataDumper data_dumper(0);
+  auto estimator = CreateNoiseFloorEstimator(&data_dumper);
+
+  test::SineGenerator gen(/*amplitude=*/test::kMaxS16, /*frequency_hz=*/600.0f,
+                          sample_rate_hz());
+  const float noise_level_dbfs =
+      RunEstimator(gen, *estimator, sample_rate_hz());
+  EXPECT_NEAR(noise_level_dbfs, -3.0f, 0.1f);
+}
+
+// Check that sufficiently spaced periodic pulses do not raise the estimated
+// noise floor, which is determined by the amplitude of the non-pulse samples.
+TEST_P(NoiseEstimatorParametrization, NoiseFloorEstimatorWithPulseTone) {
+  ApmDataDumper data_dumper(0);
+  auto estimator = CreateNoiseFloorEstimator(&data_dumper);
+
+  constexpr float kNoPulseAmplitude = 10.0f;
+  test::PulseGenerator gen(/*pulse_amplitude=*/test::kMaxS16, kNoPulseAmplitude,
+                           /*frequency_hz=*/20.0f, sample_rate_hz());
+  const int noise_level_dbfs = RunEstimator(gen, *estimator, sample_rate_hz());
+  const float expected_noise_floor_dbfs =
+      20.0f * std::log10f(kNoPulseAmplitude / test::kMaxS16);
+  EXPECT_NEAR(noise_level_dbfs, expected_noise_floor_dbfs, 0.5f);
+}
+
+INSTANTIATE_TEST_SUITE_P(GainController2NoiseEstimator,
+                         NoiseEstimatorParametrization,
+                         ::testing::Values(8000, 16000, 32000, 48000));
+
+}  // namespace
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/noise_spectrum_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/noise_spectrum_estimator.cc
new file mode 100644
index 0000000..f283f4e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/noise_spectrum_estimator.cc
@@ -0,0 +1,70 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/noise_spectrum_estimator.h"
+
+#include <string.h>
+
+#include <algorithm>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/arraysize.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+constexpr float kMinNoisePower = 100.f;
+}  // namespace
+
+NoiseSpectrumEstimator::NoiseSpectrumEstimator(ApmDataDumper* data_dumper)
+    : data_dumper_(data_dumper) {
+  Initialize();
+}
+
+void NoiseSpectrumEstimator::Initialize() {
+  std::fill(noise_spectrum_, noise_spectrum_ + arraysize(noise_spectrum_),
+            kMinNoisePower);
+}
+
+void NoiseSpectrumEstimator::Update(rtc::ArrayView<const float> spectrum,
+                                    bool first_update) {
+  RTC_DCHECK_EQ(65, spectrum.size());
+
+  if (first_update) {
+    // Initialize the noise spectral estimate with the signal spectrum.
+    std::copy(spectrum.data(), spectrum.data() + spectrum.size(),
+              noise_spectrum_);
+  } else {
+    // Smoothly update the noise spectral estimate towards the signal spectrum
+    // such that the magnitude of the updates are limited.
+    for (size_t k = 0; k < spectrum.size(); ++k) {
+      if (noise_spectrum_[k] < spectrum[k]) {
+        noise_spectrum_[k] = std::min(
+            1.01f * noise_spectrum_[k],
+            noise_spectrum_[k] + 0.05f * (spectrum[k] - noise_spectrum_[k]));
+      } else {
+        noise_spectrum_[k] = std::max(
+            0.99f * noise_spectrum_[k],
+            noise_spectrum_[k] + 0.05f * (spectrum[k] - noise_spectrum_[k]));
+      }
+    }
+  }
+
+  // Ensure that the noise spectal estimate does not become too low.
+  for (auto& v : noise_spectrum_) {
+    v = std::max(v, kMinNoisePower);
+  }
+
+  data_dumper_->DumpRaw("agc2_noise_spectrum", 65, noise_spectrum_);
+  data_dumper_->DumpRaw("agc2_signal_spectrum", spectrum);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/noise_spectrum_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/noise_spectrum_estimator.h
new file mode 100644
index 0000000..e9895f0
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/noise_spectrum_estimator.h
@@ -0,0 +1,42 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_NOISE_SPECTRUM_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_NOISE_SPECTRUM_ESTIMATOR_H_
+
+#include "api/array_view.h"
+
+namespace webrtc {
+
+class ApmDataDumper;
+
+class NoiseSpectrumEstimator {
+ public:
+  explicit NoiseSpectrumEstimator(ApmDataDumper* data_dumper);
+
+  NoiseSpectrumEstimator() = delete;
+  NoiseSpectrumEstimator(const NoiseSpectrumEstimator&) = delete;
+  NoiseSpectrumEstimator& operator=(const NoiseSpectrumEstimator&) = delete;
+
+  void Initialize();
+  void Update(rtc::ArrayView<const float> spectrum, bool first_update);
+
+  rtc::ArrayView<const float> GetNoiseSpectrum() const {
+    return rtc::ArrayView<const float>(noise_spectrum_);
+  }
+
+ private:
+  ApmDataDumper* data_dumper_;
+  float noise_spectrum_[65];
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_NOISE_SPECTRUM_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/BUILD.gn b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/BUILD.gn
new file mode 100644
index 0000000..bc848b3
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/BUILD.gn
@@ -0,0 +1,333 @@
+# Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+#
+# Use of this source code is governed by a BSD-style license
+# that can be found in the LICENSE file in the root of the source
+# tree. An additional intellectual property rights grant can be found
+# in the file PATENTS.  All contributing project authors may
+# be found in the AUTHORS file in the root of the source tree.
+
+import("../../../../webrtc.gni")
+
+rtc_library("rnn_vad") {
+  visibility = [ "../*" ]
+  sources = [
+    "features_extraction.cc",
+    "features_extraction.h",
+    "rnn.cc",
+    "rnn.h",
+  ]
+
+  defines = []
+  if (rtc_build_with_neon && current_cpu != "arm64") {
+    suppressed_configs += [ "//build/config/compiler:compiler_arm_fpu" ]
+    cflags = [ "-mfpu=neon" ]
+  }
+
+  deps = [
+    ":rnn_vad_common",
+    ":rnn_vad_layers",
+    ":rnn_vad_lp_residual",
+    ":rnn_vad_pitch",
+    ":rnn_vad_sequence_buffer",
+    ":rnn_vad_spectral_features",
+    "..:biquad_filter",
+    "..:cpu_features",
+    "../../../../api:array_view",
+    "../../../../rtc_base:checks",
+    "../../../../rtc_base:safe_compare",
+    "../../../../rtc_base:safe_conversions",
+    "//third_party/rnnoise:rnn_vad",
+  ]
+}
+
+rtc_library("rnn_vad_auto_correlation") {
+  sources = [
+    "auto_correlation.cc",
+    "auto_correlation.h",
+  ]
+  deps = [
+    ":rnn_vad_common",
+    "../../../../api:array_view",
+    "../../../../rtc_base:checks",
+    "../../utility:pffft_wrapper",
+  ]
+}
+
+rtc_source_set("rnn_vad_common") {
+  # TODO(alessiob): Make this target visibility private.
+  visibility = [
+    ":*",
+    "..:rnn_vad_with_level",
+  ]
+  sources = [ "common.h" ]
+  deps = [
+    "../../../../rtc_base/system:arch",
+    "../../../../system_wrappers",
+  ]
+}
+
+rtc_library("rnn_vad_lp_residual") {
+  sources = [
+    "lp_residual.cc",
+    "lp_residual.h",
+  ]
+  deps = [
+    "../../../../api:array_view",
+    "../../../../rtc_base:checks",
+    "../../../../rtc_base:safe_compare",
+  ]
+}
+
+rtc_source_set("rnn_vad_layers") {
+  sources = [
+    "rnn_fc.cc",
+    "rnn_fc.h",
+    "rnn_gru.cc",
+    "rnn_gru.h",
+  ]
+
+  defines = []
+  if (rtc_build_with_neon && current_cpu != "arm64") {
+    suppressed_configs += [ "//build/config/compiler:compiler_arm_fpu" ]
+    cflags = [ "-mfpu=neon" ]
+  }
+
+  deps = [
+    ":rnn_vad_common",
+    ":vector_math",
+    "..:cpu_features",
+    "../../../../api:array_view",
+    "../../../../api:function_view",
+    "../../../../rtc_base:checks",
+    "../../../../rtc_base:safe_conversions",
+    "//third_party/rnnoise:rnn_vad",
+  ]
+  if (current_cpu == "x86" || current_cpu == "x64") {
+    deps += [ ":vector_math_avx2" ]
+  }
+  absl_deps = [ "//third_party/abseil-cpp/absl/strings" ]
+}
+
+rtc_source_set("vector_math") {
+  sources = [ "vector_math.h" ]
+  deps = [
+    "..:cpu_features",
+    "../../../../api:array_view",
+    "../../../../rtc_base:checks",
+    "../../../../rtc_base:safe_conversions",
+    "../../../../rtc_base/system:arch",
+  ]
+}
+
+if (current_cpu == "x86" || current_cpu == "x64") {
+  rtc_library("vector_math_avx2") {
+    sources = [ "vector_math_avx2.cc" ]
+    if (is_win) {
+      cflags = [ "/arch:AVX2" ]
+    } else {
+      cflags = [
+        "-mavx2",
+        "-mfma",
+      ]
+    }
+    deps = [
+      ":vector_math",
+      "../../../../api:array_view",
+      "../../../../rtc_base:checks",
+      "../../../../rtc_base:safe_conversions",
+    ]
+  }
+}
+
+rtc_library("rnn_vad_pitch") {
+  sources = [
+    "pitch_search.cc",
+    "pitch_search.h",
+    "pitch_search_internal.cc",
+    "pitch_search_internal.h",
+  ]
+
+  defines = []
+  if (rtc_build_with_neon && current_cpu != "arm64") {
+    suppressed_configs += [ "//build/config/compiler:compiler_arm_fpu" ]
+    cflags = [ "-mfpu=neon" ]
+  }
+
+  deps = [
+    ":rnn_vad_auto_correlation",
+    ":rnn_vad_common",
+    ":vector_math",
+    "..:cpu_features",
+    "../../../../api:array_view",
+    "../../../../rtc_base:checks",
+    "../../../../rtc_base:gtest_prod",
+    "../../../../rtc_base:safe_compare",
+    "../../../../rtc_base:safe_conversions",
+    "../../../../rtc_base/system:arch",
+  ]
+  if (current_cpu == "x86" || current_cpu == "x64") {
+    deps += [ ":vector_math_avx2" ]
+  }
+}
+
+rtc_source_set("rnn_vad_ring_buffer") {
+  sources = [ "ring_buffer.h" ]
+  deps = [
+    "../../../../api:array_view",
+    "../../../../rtc_base:checks",
+  ]
+}
+
+rtc_source_set("rnn_vad_sequence_buffer") {
+  sources = [ "sequence_buffer.h" ]
+  deps = [
+    "../../../../api:array_view",
+    "../../../../rtc_base:checks",
+  ]
+}
+
+rtc_library("rnn_vad_spectral_features") {
+  sources = [
+    "spectral_features.cc",
+    "spectral_features.h",
+    "spectral_features_internal.cc",
+    "spectral_features_internal.h",
+  ]
+  deps = [
+    ":rnn_vad_common",
+    ":rnn_vad_ring_buffer",
+    ":rnn_vad_symmetric_matrix_buffer",
+    "../../../../api:array_view",
+    "../../../../rtc_base:checks",
+    "../../../../rtc_base:safe_compare",
+    "../../utility:pffft_wrapper",
+  ]
+}
+
+rtc_source_set("rnn_vad_symmetric_matrix_buffer") {
+  sources = [ "symmetric_matrix_buffer.h" ]
+  deps = [
+    "../../../../api:array_view",
+    "../../../../rtc_base:checks",
+    "../../../../rtc_base:safe_compare",
+  ]
+}
+
+if (rtc_include_tests) {
+  rtc_library("test_utils") {
+    testonly = true
+    sources = [
+      "test_utils.cc",
+      "test_utils.h",
+    ]
+    deps = [
+      ":rnn_vad",
+      ":rnn_vad_common",
+      "../../../../api:array_view",
+      "../../../../api:scoped_refptr",
+      "../../../../rtc_base:checks",
+      "../../../../rtc_base:safe_compare",
+      "../../../../test:fileutils",
+      "../../../../test:test_support",
+    ]
+  }
+
+  unittest_resources = [
+    "../../../../resources/audio_processing/agc2/rnn_vad/band_energies.dat",
+    "../../../../resources/audio_processing/agc2/rnn_vad/pitch_buf_24k.dat",
+    "../../../../resources/audio_processing/agc2/rnn_vad/pitch_lp_res.dat",
+    "../../../../resources/audio_processing/agc2/rnn_vad/pitch_search_int.dat",
+    "../../../../resources/audio_processing/agc2/rnn_vad/samples.pcm",
+    "../../../../resources/audio_processing/agc2/rnn_vad/vad_prob.dat",
+  ]
+
+  if (is_ios) {
+    bundle_data("unittests_bundle_data") {
+      testonly = true
+      sources = unittest_resources
+      outputs = [ "{{bundle_resources_dir}}/{{source_file_part}}" ]
+    }
+  }
+
+  rtc_library("unittests") {
+    testonly = true
+    sources = [
+      "auto_correlation_unittest.cc",
+      "features_extraction_unittest.cc",
+      "lp_residual_unittest.cc",
+      "pitch_search_internal_unittest.cc",
+      "pitch_search_unittest.cc",
+      "ring_buffer_unittest.cc",
+      "rnn_fc_unittest.cc",
+      "rnn_gru_unittest.cc",
+      "rnn_unittest.cc",
+      "rnn_vad_unittest.cc",
+      "sequence_buffer_unittest.cc",
+      "spectral_features_internal_unittest.cc",
+      "spectral_features_unittest.cc",
+      "symmetric_matrix_buffer_unittest.cc",
+      "vector_math_unittest.cc",
+    ]
+
+    defines = []
+    if (rtc_build_with_neon && current_cpu != "arm64") {
+      suppressed_configs += [ "//build/config/compiler:compiler_arm_fpu" ]
+      cflags = [ "-mfpu=neon" ]
+    }
+
+    deps = [
+      ":rnn_vad",
+      ":rnn_vad_auto_correlation",
+      ":rnn_vad_common",
+      ":rnn_vad_layers",
+      ":rnn_vad_lp_residual",
+      ":rnn_vad_pitch",
+      ":rnn_vad_ring_buffer",
+      ":rnn_vad_sequence_buffer",
+      ":rnn_vad_spectral_features",
+      ":rnn_vad_symmetric_matrix_buffer",
+      ":test_utils",
+      ":vector_math",
+      "..:cpu_features",
+      "../..:audioproc_test_utils",
+      "../../../../api:array_view",
+      "../../../../common_audio/",
+      "../../../../rtc_base:checks",
+      "../../../../rtc_base:logging",
+      "../../../../rtc_base:safe_compare",
+      "../../../../rtc_base:safe_conversions",
+      "../../../../rtc_base:stringutils",
+      "../../../../rtc_base/system:arch",
+      "../../../../test:test_support",
+      "../../utility:pffft_wrapper",
+      "//third_party/rnnoise:rnn_vad",
+    ]
+    if (current_cpu == "x86" || current_cpu == "x64") {
+      deps += [ ":vector_math_avx2" ]
+    }
+    absl_deps = [ "//third_party/abseil-cpp/absl/memory" ]
+    data = unittest_resources
+    if (is_ios) {
+      deps += [ ":unittests_bundle_data" ]
+    }
+  }
+
+  if (!build_with_chromium) {
+    rtc_executable("rnn_vad_tool") {
+      testonly = true
+      sources = [ "rnn_vad_tool.cc" ]
+      deps = [
+        ":rnn_vad",
+        ":rnn_vad_common",
+        "..:cpu_features",
+        "../../../../api:array_view",
+        "../../../../common_audio",
+        "../../../../rtc_base:rtc_base_approved",
+        "../../../../rtc_base:safe_compare",
+        "../../../../test:test_support",
+        "//third_party/abseil-cpp/absl/flags:flag",
+        "//third_party/abseil-cpp/absl/flags:parse",
+      ]
+    }
+  }
+}
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/DEPS b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/DEPS
new file mode 100644
index 0000000..773c2d7
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/DEPS
@@ -0,0 +1,3 @@
+include_rules = [
+  "+third_party/rnnoise",
+]
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/auto_correlation.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/auto_correlation.cc
new file mode 100644
index 0000000..431c01f
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/auto_correlation.cc
@@ -0,0 +1,91 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/auto_correlation.h"
+
+#include <algorithm>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+constexpr int kAutoCorrelationFftOrder = 9;  // Length-512 FFT.
+static_assert(1 << kAutoCorrelationFftOrder >
+                  kNumLags12kHz + kBufSize12kHz - kMaxPitch12kHz,
+              "");
+
+}  // namespace
+
+AutoCorrelationCalculator::AutoCorrelationCalculator()
+    : fft_(1 << kAutoCorrelationFftOrder, Pffft::FftType::kReal),
+      tmp_(fft_.CreateBuffer()),
+      X_(fft_.CreateBuffer()),
+      H_(fft_.CreateBuffer()) {}
+
+AutoCorrelationCalculator::~AutoCorrelationCalculator() = default;
+
+// The auto-correlations coefficients are computed as follows:
+// |.........|...........|  <- pitch buffer
+//           [ x (fixed) ]
+// [   y_0   ]
+//         [ y_{m-1} ]
+// x and y are sub-array of equal length; x is never moved, whereas y slides.
+// The cross-correlation between y_0 and x corresponds to the auto-correlation
+// for the maximum pitch period. Hence, the first value in |auto_corr| has an
+// inverted lag equal to 0 that corresponds to a lag equal to the maximum
+// pitch period.
+void AutoCorrelationCalculator::ComputeOnPitchBuffer(
+    rtc::ArrayView<const float, kBufSize12kHz> pitch_buf,
+    rtc::ArrayView<float, kNumLags12kHz> auto_corr) {
+  RTC_DCHECK_LT(auto_corr.size(), kMaxPitch12kHz);
+  RTC_DCHECK_GT(pitch_buf.size(), kMaxPitch12kHz);
+  constexpr int kFftFrameSize = 1 << kAutoCorrelationFftOrder;
+  constexpr int kConvolutionLength = kBufSize12kHz - kMaxPitch12kHz;
+  static_assert(kConvolutionLength == kFrameSize20ms12kHz,
+                "Mismatch between pitch buffer size, frame size and maximum "
+                "pitch period.");
+  static_assert(kFftFrameSize > kNumLags12kHz + kConvolutionLength,
+                "The FFT length is not sufficiently big to avoid cyclic "
+                "convolution errors.");
+  auto tmp = tmp_->GetView();
+
+  // Compute the FFT for the reversed reference frame - i.e.,
+  // pitch_buf[-kConvolutionLength:].
+  std::reverse_copy(pitch_buf.end() - kConvolutionLength, pitch_buf.end(),
+                    tmp.begin());
+  std::fill(tmp.begin() + kConvolutionLength, tmp.end(), 0.f);
+  fft_.ForwardTransform(*tmp_, H_.get(), /*ordered=*/false);
+
+  // Compute the FFT for the sliding frames chunk. The sliding frames are
+  // defined as pitch_buf[i:i+kConvolutionLength] where i in
+  // [0, kNumLags12kHz). The chunk includes all of them, hence it is
+  // defined as pitch_buf[:kNumLags12kHz+kConvolutionLength].
+  std::copy(pitch_buf.begin(),
+            pitch_buf.begin() + kConvolutionLength + kNumLags12kHz,
+            tmp.begin());
+  std::fill(tmp.begin() + kNumLags12kHz + kConvolutionLength, tmp.end(), 0.f);
+  fft_.ForwardTransform(*tmp_, X_.get(), /*ordered=*/false);
+
+  // Convolve in the frequency domain.
+  constexpr float kScalingFactor = 1.f / static_cast<float>(kFftFrameSize);
+  std::fill(tmp.begin(), tmp.end(), 0.f);
+  fft_.FrequencyDomainConvolve(*X_, *H_, tmp_.get(), kScalingFactor);
+  fft_.BackwardTransform(*tmp_, tmp_.get(), /*ordered=*/false);
+
+  // Extract the auto-correlation coefficients.
+  std::copy(tmp.begin() + kConvolutionLength - 1,
+            tmp.begin() + kConvolutionLength + kNumLags12kHz - 1,
+            auto_corr.begin());
+}
+
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/auto_correlation.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/auto_correlation.h
new file mode 100644
index 0000000..d58558c
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/auto_correlation.h
@@ -0,0 +1,49 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_AUTO_CORRELATION_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_AUTO_CORRELATION_H_
+
+#include <memory>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/rnn_vad/common.h"
+#include "modules/audio_processing/utility/pffft_wrapper.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+// Class to compute the auto correlation on the pitch buffer for a target pitch
+// interval.
+class AutoCorrelationCalculator {
+ public:
+  AutoCorrelationCalculator();
+  AutoCorrelationCalculator(const AutoCorrelationCalculator&) = delete;
+  AutoCorrelationCalculator& operator=(const AutoCorrelationCalculator&) =
+      delete;
+  ~AutoCorrelationCalculator();
+
+  // Computes the auto-correlation coefficients for a target pitch interval.
+  // |auto_corr| indexes are inverted lags.
+  void ComputeOnPitchBuffer(
+      rtc::ArrayView<const float, kBufSize12kHz> pitch_buf,
+      rtc::ArrayView<float, kNumLags12kHz> auto_corr);
+
+ private:
+  Pffft fft_;
+  std::unique_ptr<Pffft::FloatBuffer> tmp_;
+  std::unique_ptr<Pffft::FloatBuffer> X_;
+  std::unique_ptr<Pffft::FloatBuffer> H_;
+};
+
+}  // namespace rnn_vad
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_AUTO_CORRELATION_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/auto_correlation_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/auto_correlation_unittest.cc
new file mode 100644
index 0000000..76001ed
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/auto_correlation_unittest.cc
@@ -0,0 +1,66 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/auto_correlation.h"
+
+#include "modules/audio_processing/agc2/rnn_vad/common.h"
+#include "modules/audio_processing/agc2/rnn_vad/pitch_search_internal.h"
+#include "modules/audio_processing/agc2/rnn_vad/test_utils.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+// Checks that the auto correlation function produces output within tolerance
+// given test input data.
+TEST(RnnVadTest, PitchBufferAutoCorrelationWithinTolerance) {
+  PitchTestData test_data;
+  std::array<float, kBufSize12kHz> pitch_buf_decimated;
+  Decimate2x(test_data.PitchBuffer24kHzView(), pitch_buf_decimated);
+  std::array<float, kNumLags12kHz> computed_output;
+  {
+    // TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+    // FloatingPointExceptionObserver fpe_observer;
+    AutoCorrelationCalculator auto_corr_calculator;
+    auto_corr_calculator.ComputeOnPitchBuffer(pitch_buf_decimated,
+                                              computed_output);
+  }
+  auto auto_corr_view = test_data.AutoCorrelation12kHzView();
+  ExpectNearAbsolute({auto_corr_view.data(), auto_corr_view.size()},
+                     computed_output, 3e-3f);
+}
+
+// Checks that the auto correlation function computes the right thing for a
+// simple use case.
+TEST(RnnVadTest, CheckAutoCorrelationOnConstantPitchBuffer) {
+  // Create constant signal with no pitch.
+  std::array<float, kBufSize12kHz> pitch_buf_decimated;
+  std::fill(pitch_buf_decimated.begin(), pitch_buf_decimated.end(), 1.f);
+  std::array<float, kNumLags12kHz> computed_output;
+  {
+    // TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+    // FloatingPointExceptionObserver fpe_observer;
+    AutoCorrelationCalculator auto_corr_calculator;
+    auto_corr_calculator.ComputeOnPitchBuffer(pitch_buf_decimated,
+                                              computed_output);
+  }
+  // The expected output is a vector filled with the same expected
+  // auto-correlation value. The latter equals the length of a 20 ms frame.
+  constexpr int kFrameSize20ms12kHz = kFrameSize20ms24kHz / 2;
+  std::array<float, kNumLags12kHz> expected_output;
+  std::fill(expected_output.begin(), expected_output.end(),
+            static_cast<float>(kFrameSize20ms12kHz));
+  ExpectNearAbsolute(expected_output, computed_output, 4e-5f);
+}
+
+}  // namespace
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/common.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/common.h
new file mode 100644
index 0000000..be5a2d5
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/common.h
@@ -0,0 +1,77 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_COMMON_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_COMMON_H_
+
+#include <stddef.h>
+
+namespace webrtc {
+namespace rnn_vad {
+
+constexpr double kPi = 3.14159265358979323846;
+
+constexpr int kSampleRate24kHz = 24000;
+constexpr int kFrameSize10ms24kHz = kSampleRate24kHz / 100;
+constexpr int kFrameSize20ms24kHz = kFrameSize10ms24kHz * 2;
+
+// Pitch buffer.
+constexpr int kMinPitch24kHz = kSampleRate24kHz / 800;   // 0.00125 s.
+constexpr int kMaxPitch24kHz = kSampleRate24kHz / 62.5;  // 0.016 s.
+constexpr int kBufSize24kHz = kMaxPitch24kHz + kFrameSize20ms24kHz;
+static_assert((kBufSize24kHz & 1) == 0, "The buffer size must be even.");
+
+// 24 kHz analysis.
+// Define a higher minimum pitch period for the initial search. This is used to
+// avoid searching for very short periods, for which a refinement step is
+// responsible.
+constexpr int kInitialMinPitch24kHz = 3 * kMinPitch24kHz;
+static_assert(kMinPitch24kHz < kInitialMinPitch24kHz, "");
+static_assert(kInitialMinPitch24kHz < kMaxPitch24kHz, "");
+static_assert(kMaxPitch24kHz > kInitialMinPitch24kHz, "");
+// Number of (inverted) lags during the initial pitch search phase at 24 kHz.
+constexpr int kInitialNumLags24kHz = kMaxPitch24kHz - kInitialMinPitch24kHz;
+// Number of (inverted) lags during the pitch search refinement phase at 24 kHz.
+constexpr int kRefineNumLags24kHz = kMaxPitch24kHz + 1;
+static_assert(
+    kRefineNumLags24kHz > kInitialNumLags24kHz,
+    "The refinement step must search the pitch in an extended pitch range.");
+
+// 12 kHz analysis.
+constexpr int kSampleRate12kHz = 12000;
+constexpr int kFrameSize10ms12kHz = kSampleRate12kHz / 100;
+constexpr int kFrameSize20ms12kHz = kFrameSize10ms12kHz * 2;
+constexpr int kBufSize12kHz = kBufSize24kHz / 2;
+constexpr int kInitialMinPitch12kHz = kInitialMinPitch24kHz / 2;
+constexpr int kMaxPitch12kHz = kMaxPitch24kHz / 2;
+static_assert(kMaxPitch12kHz > kInitialMinPitch12kHz, "");
+// The inverted lags for the pitch interval [|kInitialMinPitch12kHz|,
+// |kMaxPitch12kHz|] are in the range [0, |kNumLags12kHz|].
+constexpr int kNumLags12kHz = kMaxPitch12kHz - kInitialMinPitch12kHz;
+
+// 48 kHz constants.
+constexpr int kMinPitch48kHz = kMinPitch24kHz * 2;
+constexpr int kMaxPitch48kHz = kMaxPitch24kHz * 2;
+
+// Spectral features.
+constexpr int kNumBands = 22;
+constexpr int kNumLowerBands = 6;
+static_assert((0 < kNumLowerBands) && (kNumLowerBands < kNumBands), "");
+constexpr int kCepstralCoeffsHistorySize = 8;
+static_assert(kCepstralCoeffsHistorySize > 2,
+              "The history size must at least be 3 to compute first and second "
+              "derivatives.");
+
+constexpr int kFeatureVectorSize = 42;
+
+}  // namespace rnn_vad
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_COMMON_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/features_extraction.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/features_extraction.cc
new file mode 100644
index 0000000..f86eba7
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/features_extraction.cc
@@ -0,0 +1,89 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/features_extraction.h"
+
+#include <array>
+
+#include "modules/audio_processing/agc2/rnn_vad/lp_residual.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+// Generated via "B, A = scipy.signal.butter(2, 30/12000, btype='highpass')"
+const BiQuadFilter::BiQuadCoefficients kHpfConfig24k = {
+    {0.99446179f, -1.98892358f, 0.99446179f},
+    {-1.98889291f, 0.98895425f}};
+
+}  // namespace
+
+FeaturesExtractor::FeaturesExtractor(const AvailableCpuFeatures& cpu_features)
+    : use_high_pass_filter_(false),
+      pitch_buf_24kHz_(),
+      pitch_buf_24kHz_view_(pitch_buf_24kHz_.GetBufferView()),
+      lp_residual_(kBufSize24kHz),
+      lp_residual_view_(lp_residual_.data(), kBufSize24kHz),
+      pitch_estimator_(cpu_features),
+      reference_frame_view_(pitch_buf_24kHz_.GetMostRecentValuesView()) {
+  RTC_DCHECK_EQ(kBufSize24kHz, lp_residual_.size());
+  hpf_.Initialize(kHpfConfig24k);
+  Reset();
+}
+
+FeaturesExtractor::~FeaturesExtractor() = default;
+
+void FeaturesExtractor::Reset() {
+  pitch_buf_24kHz_.Reset();
+  spectral_features_extractor_.Reset();
+  if (use_high_pass_filter_)
+    hpf_.Reset();
+}
+
+bool FeaturesExtractor::CheckSilenceComputeFeatures(
+    rtc::ArrayView<const float, kFrameSize10ms24kHz> samples,
+    rtc::ArrayView<float, kFeatureVectorSize> feature_vector) {
+  // Pre-processing.
+  if (use_high_pass_filter_) {
+    std::array<float, kFrameSize10ms24kHz> samples_filtered;
+    hpf_.Process(samples, samples_filtered);
+    // Feed buffer with the pre-processed version of |samples|.
+    pitch_buf_24kHz_.Push(samples_filtered);
+  } else {
+    // Feed buffer with |samples|.
+    pitch_buf_24kHz_.Push(samples);
+  }
+  // Extract the LP residual.
+  float lpc_coeffs[kNumLpcCoefficients];
+  ComputeAndPostProcessLpcCoefficients(pitch_buf_24kHz_view_, lpc_coeffs);
+  ComputeLpResidual(lpc_coeffs, pitch_buf_24kHz_view_, lp_residual_view_);
+  // Estimate pitch on the LP-residual and write the normalized pitch period
+  // into the output vector (normalization based on training data stats).
+  pitch_period_48kHz_ = pitch_estimator_.Estimate(lp_residual_view_);
+  feature_vector[kFeatureVectorSize - 2] = 0.01f * (pitch_period_48kHz_ - 300);
+  // Extract lagged frames (according to the estimated pitch period).
+  RTC_DCHECK_LE(pitch_period_48kHz_ / 2, kMaxPitch24kHz);
+  auto lagged_frame = pitch_buf_24kHz_view_.subview(
+      kMaxPitch24kHz - pitch_period_48kHz_ / 2, kFrameSize20ms24kHz);
+  // Analyze reference and lagged frames checking if silence has been detected
+  // and write the feature vector.
+  return spectral_features_extractor_.CheckSilenceComputeFeatures(
+      reference_frame_view_, {lagged_frame.data(), kFrameSize20ms24kHz},
+      {feature_vector.data() + kNumLowerBands, kNumBands - kNumLowerBands},
+      {feature_vector.data(), kNumLowerBands},
+      {feature_vector.data() + kNumBands, kNumLowerBands},
+      {feature_vector.data() + kNumBands + kNumLowerBands, kNumLowerBands},
+      {feature_vector.data() + kNumBands + 2 * kNumLowerBands, kNumLowerBands},
+      &feature_vector[kFeatureVectorSize - 1]);
+}
+
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/features_extraction.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/features_extraction.h
new file mode 100644
index 0000000..f4cea7a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/features_extraction.h
@@ -0,0 +1,61 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_FEATURES_EXTRACTION_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_FEATURES_EXTRACTION_H_
+
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/biquad_filter.h"
+#include "modules/audio_processing/agc2/rnn_vad/common.h"
+#include "modules/audio_processing/agc2/rnn_vad/pitch_search.h"
+#include "modules/audio_processing/agc2/rnn_vad/sequence_buffer.h"
+#include "modules/audio_processing/agc2/rnn_vad/spectral_features.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+// Feature extractor to feed the VAD RNN.
+class FeaturesExtractor {
+ public:
+  explicit FeaturesExtractor(const AvailableCpuFeatures& cpu_features);
+  FeaturesExtractor(const FeaturesExtractor&) = delete;
+  FeaturesExtractor& operator=(const FeaturesExtractor&) = delete;
+  ~FeaturesExtractor();
+  void Reset();
+  // Analyzes the samples, computes the feature vector and returns true if
+  // silence is detected (false if not). When silence is detected,
+  // |feature_vector| is partially written and therefore must not be used to
+  // feed the VAD RNN.
+  bool CheckSilenceComputeFeatures(
+      rtc::ArrayView<const float, kFrameSize10ms24kHz> samples,
+      rtc::ArrayView<float, kFeatureVectorSize> feature_vector);
+
+ private:
+  const bool use_high_pass_filter_;
+  // TODO(bugs.webrtc.org/7494): Remove HPF depending on how AGC2 is used in APM
+  // and on whether an HPF is already used as pre-processing step in APM.
+  BiQuadFilter hpf_;
+  SequenceBuffer<float, kBufSize24kHz, kFrameSize10ms24kHz, kFrameSize20ms24kHz>
+      pitch_buf_24kHz_;
+  rtc::ArrayView<const float, kBufSize24kHz> pitch_buf_24kHz_view_;
+  std::vector<float> lp_residual_;
+  rtc::ArrayView<float, kBufSize24kHz> lp_residual_view_;
+  PitchEstimator pitch_estimator_;
+  rtc::ArrayView<const float, kFrameSize20ms24kHz> reference_frame_view_;
+  SpectralFeaturesExtractor spectral_features_extractor_;
+  int pitch_period_48kHz_;
+};
+
+}  // namespace rnn_vad
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_FEATURES_EXTRACTION_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/features_extraction_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/features_extraction_unittest.cc
new file mode 100644
index 0000000..98da39e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/features_extraction_unittest.cc
@@ -0,0 +1,103 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/features_extraction.h"
+
+#include <cmath>
+#include <vector>
+
+#include "modules/audio_processing/agc2/cpu_features.h"
+#include "rtc_base/numerics/safe_compare.h"
+#include "rtc_base/numerics/safe_conversions.h"
+// TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+// #include "test/fpe_observer.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+constexpr int ceil(int n, int m) {
+  return (n + m - 1) / m;
+}
+
+// Number of 10 ms frames required to fill a pitch buffer having size
+// |kBufSize24kHz|.
+constexpr int kNumTestDataFrames = ceil(kBufSize24kHz, kFrameSize10ms24kHz);
+// Number of samples for the test data.
+constexpr int kNumTestDataSize = kNumTestDataFrames * kFrameSize10ms24kHz;
+
+// Verifies that the pitch in Hz is in the detectable range.
+bool PitchIsValid(float pitch_hz) {
+  const int pitch_period = static_cast<float>(kSampleRate24kHz) / pitch_hz;
+  return kInitialMinPitch24kHz <= pitch_period &&
+         pitch_period <= kMaxPitch24kHz;
+}
+
+void CreatePureTone(float amplitude, float freq_hz, rtc::ArrayView<float> dst) {
+  for (int i = 0; rtc::SafeLt(i, dst.size()); ++i) {
+    dst[i] = amplitude * std::sin(2.f * kPi * freq_hz * i / kSampleRate24kHz);
+  }
+}
+
+// Feeds |features_extractor| with |samples| splitting it in 10 ms frames.
+// For every frame, the output is written into |feature_vector|. Returns true
+// if silence is detected in the last frame.
+bool FeedTestData(FeaturesExtractor& features_extractor,
+                  rtc::ArrayView<const float> samples,
+                  rtc::ArrayView<float, kFeatureVectorSize> feature_vector) {
+  // TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+  // FloatingPointExceptionObserver fpe_observer;
+  bool is_silence = true;
+  const int num_frames = samples.size() / kFrameSize10ms24kHz;
+  for (int i = 0; i < num_frames; ++i) {
+    is_silence = features_extractor.CheckSilenceComputeFeatures(
+        {samples.data() + i * kFrameSize10ms24kHz, kFrameSize10ms24kHz},
+        feature_vector);
+  }
+  return is_silence;
+}
+
+// Extracts the features for two pure tones and verifies that the pitch field
+// values reflect the known tone frequencies.
+TEST(RnnVadTest, FeatureExtractionLowHighPitch) {
+  constexpr float amplitude = 1000.f;
+  constexpr float low_pitch_hz = 150.f;
+  constexpr float high_pitch_hz = 250.f;
+  ASSERT_TRUE(PitchIsValid(low_pitch_hz));
+  ASSERT_TRUE(PitchIsValid(high_pitch_hz));
+
+  const AvailableCpuFeatures cpu_features = GetAvailableCpuFeatures();
+  FeaturesExtractor features_extractor(cpu_features);
+  std::vector<float> samples(kNumTestDataSize);
+  std::vector<float> feature_vector(kFeatureVectorSize);
+  ASSERT_EQ(kFeatureVectorSize, rtc::dchecked_cast<int>(feature_vector.size()));
+  rtc::ArrayView<float, kFeatureVectorSize> feature_vector_view(
+      feature_vector.data(), kFeatureVectorSize);
+
+  // Extract the normalized scalar feature that is proportional to the estimated
+  // pitch period.
+  constexpr int pitch_feature_index = kFeatureVectorSize - 2;
+  // Low frequency tone - i.e., high period.
+  CreatePureTone(amplitude, low_pitch_hz, samples);
+  ASSERT_FALSE(FeedTestData(features_extractor, samples, feature_vector_view));
+  float high_pitch_period = feature_vector_view[pitch_feature_index];
+  // High frequency tone - i.e., low period.
+  features_extractor.Reset();
+  CreatePureTone(amplitude, high_pitch_hz, samples);
+  ASSERT_FALSE(FeedTestData(features_extractor, samples, feature_vector_view));
+  float low_pitch_period = feature_vector_view[pitch_feature_index];
+  // Check.
+  EXPECT_LT(low_pitch_period, high_pitch_period);
+}
+
+}  // namespace
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/lp_residual.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/lp_residual.cc
new file mode 100644
index 0000000..c553aa2
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/lp_residual.cc
@@ -0,0 +1,141 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/lp_residual.h"
+
+#include <algorithm>
+#include <array>
+#include <cmath>
+#include <numeric>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_compare.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+// Computes auto-correlation coefficients for |x| and writes them in
+// |auto_corr|. The lag values are in {0, ..., max_lag - 1}, where max_lag
+// equals the size of |auto_corr|.
+void ComputeAutoCorrelation(
+    rtc::ArrayView<const float> x,
+    rtc::ArrayView<float, kNumLpcCoefficients> auto_corr) {
+  constexpr int max_lag = auto_corr.size();
+  RTC_DCHECK_LT(max_lag, x.size());
+  for (int lag = 0; lag < max_lag; ++lag) {
+    auto_corr[lag] =
+        std::inner_product(x.begin(), x.end() - lag, x.begin() + lag, 0.f);
+  }
+}
+
+// Applies denoising to the auto-correlation coefficients.
+void DenoiseAutoCorrelation(
+    rtc::ArrayView<float, kNumLpcCoefficients> auto_corr) {
+  // Assume -40 dB white noise floor.
+  auto_corr[0] *= 1.0001f;
+  // Hard-coded values obtained as
+  // [np.float32((0.008*0.008*i*i)) for i in range(1,5)].
+  auto_corr[1] -= auto_corr[1] * 0.000064f;
+  auto_corr[2] -= auto_corr[2] * 0.000256f;
+  auto_corr[3] -= auto_corr[3] * 0.000576f;
+  auto_corr[4] -= auto_corr[4] * 0.001024f;
+  static_assert(kNumLpcCoefficients == 5, "Update `auto_corr`.");
+}
+
+// Computes the initial inverse filter coefficients given the auto-correlation
+// coefficients of an input frame.
+void ComputeInitialInverseFilterCoefficients(
+    rtc::ArrayView<const float, kNumLpcCoefficients> auto_corr,
+    rtc::ArrayView<float, kNumLpcCoefficients - 1> lpc_coeffs) {
+  float error = auto_corr[0];
+  for (int i = 0; i < kNumLpcCoefficients - 1; ++i) {
+    float reflection_coeff = 0.f;
+    for (int j = 0; j < i; ++j) {
+      reflection_coeff += lpc_coeffs[j] * auto_corr[i - j];
+    }
+    reflection_coeff += auto_corr[i + 1];
+
+    // Avoid division by numbers close to zero.
+    constexpr float kMinErrorMagnitude = 1e-6f;
+    if (std::fabs(error) < kMinErrorMagnitude) {
+      error = std::copysign(kMinErrorMagnitude, error);
+    }
+
+    reflection_coeff /= -error;
+    // Update LPC coefficients and total error.
+    lpc_coeffs[i] = reflection_coeff;
+    for (int j = 0; j < ((i + 1) >> 1); ++j) {
+      const float tmp1 = lpc_coeffs[j];
+      const float tmp2 = lpc_coeffs[i - 1 - j];
+      lpc_coeffs[j] = tmp1 + reflection_coeff * tmp2;
+      lpc_coeffs[i - 1 - j] = tmp2 + reflection_coeff * tmp1;
+    }
+    error -= reflection_coeff * reflection_coeff * error;
+    if (error < 0.001f * auto_corr[0]) {
+      break;
+    }
+  }
+}
+
+}  // namespace
+
+void ComputeAndPostProcessLpcCoefficients(
+    rtc::ArrayView<const float> x,
+    rtc::ArrayView<float, kNumLpcCoefficients> lpc_coeffs) {
+  std::array<float, kNumLpcCoefficients> auto_corr;
+  ComputeAutoCorrelation(x, auto_corr);
+  if (auto_corr[0] == 0.f) {  // Empty frame.
+    std::fill(lpc_coeffs.begin(), lpc_coeffs.end(), 0);
+    return;
+  }
+  DenoiseAutoCorrelation(auto_corr);
+  std::array<float, kNumLpcCoefficients - 1> lpc_coeffs_pre{};
+  ComputeInitialInverseFilterCoefficients(auto_corr, lpc_coeffs_pre);
+  // LPC coefficients post-processing.
+  // TODO(bugs.webrtc.org/9076): Consider removing these steps.
+  lpc_coeffs_pre[0] *= 0.9f;
+  lpc_coeffs_pre[1] *= 0.9f * 0.9f;
+  lpc_coeffs_pre[2] *= 0.9f * 0.9f * 0.9f;
+  lpc_coeffs_pre[3] *= 0.9f * 0.9f * 0.9f * 0.9f;
+  constexpr float kC = 0.8f;
+  lpc_coeffs[0] = lpc_coeffs_pre[0] + kC;
+  lpc_coeffs[1] = lpc_coeffs_pre[1] + kC * lpc_coeffs_pre[0];
+  lpc_coeffs[2] = lpc_coeffs_pre[2] + kC * lpc_coeffs_pre[1];
+  lpc_coeffs[3] = lpc_coeffs_pre[3] + kC * lpc_coeffs_pre[2];
+  lpc_coeffs[4] = kC * lpc_coeffs_pre[3];
+  static_assert(kNumLpcCoefficients == 5, "Update `lpc_coeffs(_pre)`.");
+}
+
+void ComputeLpResidual(
+    rtc::ArrayView<const float, kNumLpcCoefficients> lpc_coeffs,
+    rtc::ArrayView<const float> x,
+    rtc::ArrayView<float> y) {
+  RTC_DCHECK_GT(x.size(), kNumLpcCoefficients);
+  RTC_DCHECK_EQ(x.size(), y.size());
+  // The code below implements the following operation:
+  // y[i] = x[i] + dot_product({x[i], ..., x[i - kNumLpcCoefficients + 1]},
+  //                           lpc_coeffs)
+  // Edge case: i < kNumLpcCoefficients.
+  y[0] = x[0];
+  for (int i = 1; i < kNumLpcCoefficients; ++i) {
+    y[i] =
+        std::inner_product(x.crend() - i, x.crend(), lpc_coeffs.cbegin(), x[i]);
+  }
+  // Regular case.
+  auto last = x.crend();
+  for (int i = kNumLpcCoefficients; rtc::SafeLt(i, y.size()); ++i, --last) {
+    y[i] = std::inner_product(last - kNumLpcCoefficients, last,
+                              lpc_coeffs.cbegin(), x[i]);
+  }
+}
+
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/lp_residual.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/lp_residual.h
new file mode 100644
index 0000000..380d9f6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/lp_residual.h
@@ -0,0 +1,41 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_LP_RESIDUAL_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_LP_RESIDUAL_H_
+
+#include <stddef.h>
+
+#include "api/array_view.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+// Linear predictive coding (LPC) inverse filter length.
+constexpr int kNumLpcCoefficients = 5;
+
+// Given a frame |x|, computes a post-processed version of LPC coefficients
+// tailored for pitch estimation.
+void ComputeAndPostProcessLpcCoefficients(
+    rtc::ArrayView<const float> x,
+    rtc::ArrayView<float, kNumLpcCoefficients> lpc_coeffs);
+
+// Computes the LP residual for the input frame |x| and the LPC coefficients
+// |lpc_coeffs|. |y| and |x| can point to the same array for in-place
+// computation.
+void ComputeLpResidual(
+    rtc::ArrayView<const float, kNumLpcCoefficients> lpc_coeffs,
+    rtc::ArrayView<const float> x,
+    rtc::ArrayView<float> y);
+
+}  // namespace rnn_vad
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_LP_RESIDUAL_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/lp_residual_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/lp_residual_unittest.cc
new file mode 100644
index 0000000..7b3a4a3
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/lp_residual_unittest.cc
@@ -0,0 +1,80 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/lp_residual.h"
+
+#include <algorithm>
+#include <array>
+#include <vector>
+
+#include "modules/audio_processing/agc2/rnn_vad/common.h"
+#include "modules/audio_processing/agc2/rnn_vad/test_utils.h"
+// TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+// #include "test/fpe_observer.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+// Checks that the LP residual can be computed on an empty frame.
+TEST(RnnVadTest, LpResidualOfEmptyFrame) {
+  // TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+  // FloatingPointExceptionObserver fpe_observer;
+
+  // Input frame (empty, i.e., all samples set to 0).
+  std::array<float, kFrameSize10ms24kHz> empty_frame;
+  empty_frame.fill(0.f);
+  // Compute inverse filter coefficients.
+  std::array<float, kNumLpcCoefficients> lpc;
+  ComputeAndPostProcessLpcCoefficients(empty_frame, lpc);
+  // Compute LP residual.
+  std::array<float, kFrameSize10ms24kHz> lp_residual;
+  ComputeLpResidual(lpc, empty_frame, lp_residual);
+}
+
+// Checks that the computed LP residual is bit-exact given test input data.
+TEST(RnnVadTest, LpResidualPipelineBitExactness) {
+  // Input and expected output readers.
+  ChunksFileReader pitch_buffer_reader = CreatePitchBuffer24kHzReader();
+  ChunksFileReader lp_pitch_reader = CreateLpResidualAndPitchInfoReader();
+
+  // Buffers.
+  std::vector<float> pitch_buffer_24kHz(kBufSize24kHz);
+  std::array<float, kNumLpcCoefficients> lpc;
+  std::vector<float> computed_lp_residual(kBufSize24kHz);
+  std::vector<float> expected_lp_residual(kBufSize24kHz);
+
+  // Test length.
+  const int num_frames =
+      std::min(pitch_buffer_reader.num_chunks, 300);  // Max 3 s.
+  ASSERT_GE(lp_pitch_reader.num_chunks, num_frames);
+
+  // TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+  // FloatingPointExceptionObserver fpe_observer;
+  for (int i = 0; i < num_frames; ++i) {
+    SCOPED_TRACE(i);
+    // Read input.
+    ASSERT_TRUE(pitch_buffer_reader.reader->ReadChunk(pitch_buffer_24kHz));
+    // Read expected output (ignore pitch gain and period).
+    ASSERT_TRUE(lp_pitch_reader.reader->ReadChunk(expected_lp_residual));
+    lp_pitch_reader.reader->SeekForward(2);  // Pitch period and strength.
+    // Check every 200 ms.
+    if (i % 20 == 0) {
+      ComputeAndPostProcessLpcCoefficients(pitch_buffer_24kHz, lpc);
+      ComputeLpResidual(lpc, pitch_buffer_24kHz, computed_lp_residual);
+      ExpectNearAbsolute(expected_lp_residual, computed_lp_residual, kFloatMin);
+    }
+  }
+}
+
+}  // namespace
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search.cc
new file mode 100644
index 0000000..77a1188
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search.cc
@@ -0,0 +1,70 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/pitch_search.h"
+
+#include <array>
+#include <cstddef>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+PitchEstimator::PitchEstimator(const AvailableCpuFeatures& cpu_features)
+    : cpu_features_(cpu_features),
+      y_energy_24kHz_(kRefineNumLags24kHz, 0.f),
+      pitch_buffer_12kHz_(kBufSize12kHz),
+      auto_correlation_12kHz_(kNumLags12kHz) {}
+
+PitchEstimator::~PitchEstimator() = default;
+
+int PitchEstimator::Estimate(
+    rtc::ArrayView<const float, kBufSize24kHz> pitch_buffer) {
+  rtc::ArrayView<float, kBufSize12kHz> pitch_buffer_12kHz_view(
+      pitch_buffer_12kHz_.data(), kBufSize12kHz);
+  RTC_DCHECK_EQ(pitch_buffer_12kHz_.size(), pitch_buffer_12kHz_view.size());
+  rtc::ArrayView<float, kNumLags12kHz> auto_correlation_12kHz_view(
+      auto_correlation_12kHz_.data(), kNumLags12kHz);
+  RTC_DCHECK_EQ(auto_correlation_12kHz_.size(),
+                auto_correlation_12kHz_view.size());
+
+  // TODO(bugs.chromium.org/10480): Use `cpu_features_` to estimate pitch.
+  // Perform the initial pitch search at 12 kHz.
+  Decimate2x(pitch_buffer, pitch_buffer_12kHz_view);
+  auto_corr_calculator_.ComputeOnPitchBuffer(pitch_buffer_12kHz_view,
+                                             auto_correlation_12kHz_view);
+  CandidatePitchPeriods pitch_periods = ComputePitchPeriod12kHz(
+      pitch_buffer_12kHz_view, auto_correlation_12kHz_view, cpu_features_);
+  // The refinement is done using the pitch buffer that contains 24 kHz samples.
+  // Therefore, adapt the inverted lags in |pitch_candidates_inv_lags| from 12
+  // to 24 kHz.
+  pitch_periods.best *= 2;
+  pitch_periods.second_best *= 2;
+
+  // Refine the initial pitch period estimation from 12 kHz to 48 kHz.
+  // Pre-compute frame energies at 24 kHz.
+  rtc::ArrayView<float, kRefineNumLags24kHz> y_energy_24kHz_view(
+      y_energy_24kHz_.data(), kRefineNumLags24kHz);
+  RTC_DCHECK_EQ(y_energy_24kHz_.size(), y_energy_24kHz_view.size());
+  ComputeSlidingFrameSquareEnergies24kHz(pitch_buffer, y_energy_24kHz_view,
+                                         cpu_features_);
+  // Estimation at 48 kHz.
+  const int pitch_lag_48kHz = ComputePitchPeriod48kHz(
+      pitch_buffer, y_energy_24kHz_view, pitch_periods, cpu_features_);
+  last_pitch_48kHz_ = ComputeExtendedPitchPeriod48kHz(
+      pitch_buffer, y_energy_24kHz_view,
+      /*initial_pitch_period_48kHz=*/kMaxPitch48kHz - pitch_lag_48kHz,
+      last_pitch_48kHz_, cpu_features_);
+  return last_pitch_48kHz_.period;
+}
+
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search.h
new file mode 100644
index 0000000..42c448e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search.h
@@ -0,0 +1,54 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_PITCH_SEARCH_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_PITCH_SEARCH_H_
+
+#include <memory>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/cpu_features.h"
+#include "modules/audio_processing/agc2/rnn_vad/auto_correlation.h"
+#include "modules/audio_processing/agc2/rnn_vad/common.h"
+#include "modules/audio_processing/agc2/rnn_vad/pitch_search_internal.h"
+#include "rtc_base/gtest_prod_util.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+// Pitch estimator.
+class PitchEstimator {
+ public:
+  explicit PitchEstimator(const AvailableCpuFeatures& cpu_features);
+  PitchEstimator(const PitchEstimator&) = delete;
+  PitchEstimator& operator=(const PitchEstimator&) = delete;
+  ~PitchEstimator();
+  // Returns the estimated pitch period at 48 kHz.
+  int Estimate(rtc::ArrayView<const float, kBufSize24kHz> pitch_buffer);
+
+ private:
+  FRIEND_TEST_ALL_PREFIXES(RnnVadTest, PitchSearchWithinTolerance);
+  float GetLastPitchStrengthForTesting() const {
+    return last_pitch_48kHz_.strength;
+  }
+
+  const AvailableCpuFeatures cpu_features_;
+  PitchInfo last_pitch_48kHz_{};
+  AutoCorrelationCalculator auto_corr_calculator_;
+  std::vector<float> y_energy_24kHz_;
+  std::vector<float> pitch_buffer_12kHz_;
+  std::vector<float> auto_correlation_12kHz_;
+};
+
+}  // namespace rnn_vad
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_PITCH_SEARCH_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search_internal.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search_internal.cc
new file mode 100644
index 0000000..0b8a77e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search_internal.cc
@@ -0,0 +1,513 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/pitch_search_internal.h"
+
+#include <stdlib.h>
+
+#include <algorithm>
+#include <cmath>
+#include <cstddef>
+#include <numeric>
+
+#include "modules/audio_processing/agc2/rnn_vad/common.h"
+#include "modules/audio_processing/agc2/rnn_vad/vector_math.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_compare.h"
+#include "rtc_base/numerics/safe_conversions.h"
+#include "rtc_base/system/arch.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+float ComputeAutoCorrelation(
+    int inverted_lag,
+    rtc::ArrayView<const float, kBufSize24kHz> pitch_buffer,
+    const VectorMath& vector_math) {
+  RTC_DCHECK_LT(inverted_lag, kBufSize24kHz);
+  RTC_DCHECK_LT(inverted_lag, kRefineNumLags24kHz);
+  static_assert(kMaxPitch24kHz < kBufSize24kHz, "");
+  return vector_math.DotProduct(
+      pitch_buffer.subview(/*offset=*/kMaxPitch24kHz),
+      pitch_buffer.subview(inverted_lag, kFrameSize20ms24kHz));
+}
+
+// Given an auto-correlation coefficient `curr_auto_correlation` and its
+// neighboring values `prev_auto_correlation` and `next_auto_correlation`
+// computes a pseudo-interpolation offset to be applied to the pitch period
+// associated to `curr`. The output is a lag in {-1, 0, +1}.
+// TODO(bugs.webrtc.org/9076): Consider removing this method.
+// `GetPitchPseudoInterpolationOffset()` it is relevant only if the spectral
+// analysis works at a sample rate that is twice as that of the pitch buffer;
+// In particular, it is not relevant for the estimated pitch period feature fed
+// into the RNN.
+int GetPitchPseudoInterpolationOffset(float prev_auto_correlation,
+                                      float curr_auto_correlation,
+                                      float next_auto_correlation) {
+  if ((next_auto_correlation - prev_auto_correlation) >
+      0.7f * (curr_auto_correlation - prev_auto_correlation)) {
+    return 1;  // |next_auto_correlation| is the largest auto-correlation
+               // coefficient.
+  } else if ((prev_auto_correlation - next_auto_correlation) >
+             0.7f * (curr_auto_correlation - next_auto_correlation)) {
+    return -1;  // |prev_auto_correlation| is the largest auto-correlation
+                // coefficient.
+  }
+  return 0;
+}
+
+// Refines a pitch period |lag| encoded as lag with pseudo-interpolation. The
+// output sample rate is twice as that of |lag|.
+int PitchPseudoInterpolationLagPitchBuf(
+    int lag,
+    rtc::ArrayView<const float, kBufSize24kHz> pitch_buffer,
+    const VectorMath& vector_math) {
+  int offset = 0;
+  // Cannot apply pseudo-interpolation at the boundaries.
+  if (lag > 0 && lag < kMaxPitch24kHz) {
+    const int inverted_lag = kMaxPitch24kHz - lag;
+    offset = GetPitchPseudoInterpolationOffset(
+        ComputeAutoCorrelation(inverted_lag + 1, pitch_buffer, vector_math),
+        ComputeAutoCorrelation(inverted_lag, pitch_buffer, vector_math),
+        ComputeAutoCorrelation(inverted_lag - 1, pitch_buffer, vector_math));
+  }
+  return 2 * lag + offset;
+}
+
+// Integer multipliers used in ComputeExtendedPitchPeriod48kHz() when
+// looking for sub-harmonics.
+// The values have been chosen to serve the following algorithm. Given the
+// initial pitch period T, we examine whether one of its harmonics is the true
+// fundamental frequency. We consider T/k with k in {2, ..., 15}. For each of
+// these harmonics, in addition to the pitch strength of itself, we choose one
+// multiple of its pitch period, n*T/k, to validate it (by averaging their pitch
+// strengths). The multiplier n is chosen so that n*T/k is used only one time
+// over all k. When for example k = 4, we should also expect a peak at 3*T/4.
+// When k = 8 instead we don't want to look at 2*T/8, since we have already
+// checked T/4 before. Instead, we look at T*3/8.
+// The array can be generate in Python as follows:
+//   from fractions import Fraction
+//   # Smallest positive integer not in X.
+//   def mex(X):
+//     for i in range(1, int(max(X)+2)):
+//       if i not in X:
+//         return i
+//   # Visited multiples of the period.
+//   S = {1}
+//   for n in range(2, 16):
+//     sn = mex({n * i for i in S} | {1})
+//     S = S | {Fraction(1, n), Fraction(sn, n)}
+//     print(sn, end=', ')
+constexpr std::array<int, 14> kSubHarmonicMultipliers = {
+    {3, 2, 3, 2, 5, 2, 3, 2, 3, 2, 5, 2, 3, 2}};
+
+struct Range {
+  int min;
+  int max;
+};
+
+// Number of analyzed pitches to the left(right) of a pitch candidate.
+constexpr int kPitchNeighborhoodRadius = 2;
+
+// Creates a pitch period interval centered in `inverted_lag` with hard-coded
+// radius. Clipping is applied so that the interval is always valid for a 24 kHz
+// pitch buffer.
+Range CreateInvertedLagRange(int inverted_lag) {
+  return {std::max(inverted_lag - kPitchNeighborhoodRadius, 0),
+          std::min(inverted_lag + kPitchNeighborhoodRadius,
+                   kInitialNumLags24kHz - 1)};
+}
+
+constexpr int kNumPitchCandidates = 2;  // Best and second best.
+// Maximum number of analyzed pitch periods.
+constexpr int kMaxPitchPeriods24kHz =
+    kNumPitchCandidates * (2 * kPitchNeighborhoodRadius + 1);
+
+// Collection of inverted lags.
+class InvertedLagsIndex {
+ public:
+  InvertedLagsIndex() : num_entries_(0) {}
+  // Adds an inverted lag to the index. Cannot add more than
+  // `kMaxPitchPeriods24kHz` values.
+  void Append(int inverted_lag) {
+    RTC_DCHECK_LT(num_entries_, kMaxPitchPeriods24kHz);
+    inverted_lags_[num_entries_++] = inverted_lag;
+  }
+  const int* data() const { return inverted_lags_.data(); }
+  int size() const { return num_entries_; }
+
+ private:
+  std::array<int, kMaxPitchPeriods24kHz> inverted_lags_;
+  int num_entries_;
+};
+
+// Computes the auto correlation coefficients for the inverted lags in the
+// closed interval `inverted_lags`. Updates `inverted_lags_index` by appending
+// the inverted lags for the computed auto correlation values.
+void ComputeAutoCorrelation(
+    Range inverted_lags,
+    rtc::ArrayView<const float, kBufSize24kHz> pitch_buffer,
+    rtc::ArrayView<float, kInitialNumLags24kHz> auto_correlation,
+    InvertedLagsIndex& inverted_lags_index,
+    const VectorMath& vector_math) {
+  // Check valid range.
+  RTC_DCHECK_LE(inverted_lags.min, inverted_lags.max);
+  // Trick to avoid zero initialization of `auto_correlation`.
+  // Needed by the pseudo-interpolation.
+  if (inverted_lags.min > 0) {
+    auto_correlation[inverted_lags.min - 1] = 0.f;
+  }
+  if (inverted_lags.max < kInitialNumLags24kHz - 1) {
+    auto_correlation[inverted_lags.max + 1] = 0.f;
+  }
+  // Check valid `inverted_lag` indexes.
+  RTC_DCHECK_GE(inverted_lags.min, 0);
+  RTC_DCHECK_LT(inverted_lags.max, kInitialNumLags24kHz);
+  for (int inverted_lag = inverted_lags.min; inverted_lag <= inverted_lags.max;
+       ++inverted_lag) {
+    auto_correlation[inverted_lag] =
+        ComputeAutoCorrelation(inverted_lag, pitch_buffer, vector_math);
+    inverted_lags_index.Append(inverted_lag);
+  }
+}
+
+// Searches the strongest pitch period at 24 kHz and returns its inverted lag at
+// 48 kHz.
+int ComputePitchPeriod48kHz(
+    rtc::ArrayView<const float, kBufSize24kHz> pitch_buffer,
+    rtc::ArrayView<const int> inverted_lags,
+    rtc::ArrayView<const float, kInitialNumLags24kHz> auto_correlation,
+    rtc::ArrayView<const float, kRefineNumLags24kHz> y_energy,
+    const VectorMath& vector_math) {
+  static_assert(kMaxPitch24kHz > kInitialNumLags24kHz, "");
+  static_assert(kMaxPitch24kHz < kBufSize24kHz, "");
+  int best_inverted_lag = 0;     // Pitch period.
+  float best_numerator = -1.f;   // Pitch strength numerator.
+  float best_denominator = 0.f;  // Pitch strength denominator.
+  for (int inverted_lag : inverted_lags) {
+    // A pitch candidate must have positive correlation.
+    if (auto_correlation[inverted_lag] > 0.f) {
+      // Auto-correlation energy normalized by frame energy.
+      const float numerator =
+          auto_correlation[inverted_lag] * auto_correlation[inverted_lag];
+      const float denominator = y_energy[inverted_lag];
+      // Compare numerator/denominator ratios without using divisions.
+      if (numerator * best_denominator > best_numerator * denominator) {
+        best_inverted_lag = inverted_lag;
+        best_numerator = numerator;
+        best_denominator = denominator;
+      }
+    }
+  }
+  // Pseudo-interpolation to transform `best_inverted_lag` (24 kHz pitch) to a
+  // 48 kHz pitch period.
+  if (best_inverted_lag == 0 || best_inverted_lag >= kInitialNumLags24kHz - 1) {
+    // Cannot apply pseudo-interpolation at the boundaries.
+    return best_inverted_lag * 2;
+  }
+  int offset = GetPitchPseudoInterpolationOffset(
+      auto_correlation[best_inverted_lag + 1],
+      auto_correlation[best_inverted_lag],
+      auto_correlation[best_inverted_lag - 1]);
+  // TODO(bugs.webrtc.org/9076): When retraining, check if |offset| below should
+  // be subtracted since |inverted_lag| is an inverted lag but offset is a lag.
+  return 2 * best_inverted_lag + offset;
+}
+
+// Returns an alternative pitch period for `pitch_period` given a `multiplier`
+// and a `divisor` of the period.
+constexpr int GetAlternativePitchPeriod(int pitch_period,
+                                        int multiplier,
+                                        int divisor) {
+  RTC_DCHECK_GT(divisor, 0);
+  // Same as `round(multiplier * pitch_period / divisor)`.
+  return (2 * multiplier * pitch_period + divisor) / (2 * divisor);
+}
+
+// Returns true if the alternative pitch period is stronger than the initial one
+// given the last estimated pitch and the value of `period_divisor` used to
+// compute the alternative pitch period via `GetAlternativePitchPeriod()`.
+bool IsAlternativePitchStrongerThanInitial(PitchInfo last,
+                                           PitchInfo initial,
+                                           PitchInfo alternative,
+                                           int period_divisor) {
+  // Initial pitch period candidate thresholds for a sample rate of 24 kHz.
+  // Computed as [5*k*k for k in range(16)].
+  constexpr std::array<int, 14> kInitialPitchPeriodThresholds = {
+      {20, 45, 80, 125, 180, 245, 320, 405, 500, 605, 720, 845, 980, 1125}};
+  static_assert(
+      kInitialPitchPeriodThresholds.size() == kSubHarmonicMultipliers.size(),
+      "");
+  RTC_DCHECK_GE(last.period, 0);
+  RTC_DCHECK_GE(initial.period, 0);
+  RTC_DCHECK_GE(alternative.period, 0);
+  RTC_DCHECK_GE(period_divisor, 2);
+  // Compute a term that lowers the threshold when |alternative.period| is close
+  // to the last estimated period |last.period| - i.e., pitch tracking.
+  float lower_threshold_term = 0.f;
+  if (std::abs(alternative.period - last.period) <= 1) {
+    // The candidate pitch period is within 1 sample from the last one.
+    // Make the candidate at |alternative.period| very easy to be accepted.
+    lower_threshold_term = last.strength;
+  } else if (std::abs(alternative.period - last.period) == 2 &&
+             initial.period >
+                 kInitialPitchPeriodThresholds[period_divisor - 2]) {
+    // The candidate pitch period is 2 samples far from the last one and the
+    // period |initial.period| (from which |alternative.period| has been
+    // derived) is greater than a threshold. Make |alternative.period| easy to
+    // be accepted.
+    lower_threshold_term = 0.5f * last.strength;
+  }
+  // Set the threshold based on the strength of the initial estimate
+  // |initial.period|. Also reduce the chance of false positives caused by a
+  // bias towards high frequencies (originating from short-term correlations).
+  float threshold =
+      std::max(0.3f, 0.7f * initial.strength - lower_threshold_term);
+  if (alternative.period < 3 * kMinPitch24kHz) {
+    // High frequency.
+    threshold = std::max(0.4f, 0.85f * initial.strength - lower_threshold_term);
+  } else if (alternative.period < 2 * kMinPitch24kHz) {
+    // Even higher frequency.
+    threshold = std::max(0.5f, 0.9f * initial.strength - lower_threshold_term);
+  }
+  return alternative.strength > threshold;
+}
+
+}  // namespace
+
+void Decimate2x(rtc::ArrayView<const float, kBufSize24kHz> src,
+                rtc::ArrayView<float, kBufSize12kHz> dst) {
+  // TODO(bugs.webrtc.org/9076): Consider adding anti-aliasing filter.
+  static_assert(2 * kBufSize12kHz == kBufSize24kHz, "");
+  for (int i = 0; i < kBufSize12kHz; ++i) {
+    dst[i] = src[2 * i];
+  }
+}
+
+void ComputeSlidingFrameSquareEnergies24kHz(
+    rtc::ArrayView<const float, kBufSize24kHz> pitch_buffer,
+    rtc::ArrayView<float, kRefineNumLags24kHz> y_energy,
+    AvailableCpuFeatures cpu_features) {
+  VectorMath vector_math(cpu_features);
+  static_assert(kFrameSize20ms24kHz < kBufSize24kHz, "");
+  const auto frame_20ms_view = pitch_buffer.subview(0, kFrameSize20ms24kHz);
+  float yy = vector_math.DotProduct(frame_20ms_view, frame_20ms_view);
+  y_energy[0] = yy;
+  static_assert(kMaxPitch24kHz - 1 + kFrameSize20ms24kHz < kBufSize24kHz, "");
+  static_assert(kMaxPitch24kHz < kRefineNumLags24kHz, "");
+  for (int inverted_lag = 0; inverted_lag < kMaxPitch24kHz; ++inverted_lag) {
+    yy -= pitch_buffer[inverted_lag] * pitch_buffer[inverted_lag];
+    yy += pitch_buffer[inverted_lag + kFrameSize20ms24kHz] *
+          pitch_buffer[inverted_lag + kFrameSize20ms24kHz];
+    yy = std::max(1.f, yy);
+    y_energy[inverted_lag + 1] = yy;
+  }
+}
+
+CandidatePitchPeriods ComputePitchPeriod12kHz(
+    rtc::ArrayView<const float, kBufSize12kHz> pitch_buffer,
+    rtc::ArrayView<const float, kNumLags12kHz> auto_correlation,
+    AvailableCpuFeatures cpu_features) {
+  static_assert(kMaxPitch12kHz > kNumLags12kHz, "");
+  static_assert(kMaxPitch12kHz < kBufSize12kHz, "");
+
+  // Stores a pitch candidate period and strength information.
+  struct PitchCandidate {
+    // Pitch period encoded as inverted lag.
+    int period_inverted_lag = 0;
+    // Pitch strength encoded as a ratio.
+    float strength_numerator = -1.f;
+    float strength_denominator = 0.f;
+    // Compare the strength of two pitch candidates.
+    bool HasStrongerPitchThan(const PitchCandidate& b) const {
+      // Comparing the numerator/denominator ratios without using divisions.
+      return strength_numerator * b.strength_denominator >
+             b.strength_numerator * strength_denominator;
+    }
+  };
+
+  VectorMath vector_math(cpu_features);
+  static_assert(kFrameSize20ms12kHz + 1 < kBufSize12kHz, "");
+  const auto frame_view = pitch_buffer.subview(0, kFrameSize20ms12kHz + 1);
+  float denominator = 1.f + vector_math.DotProduct(frame_view, frame_view);
+  // Search best and second best pitches by looking at the scaled
+  // auto-correlation.
+  PitchCandidate best;
+  PitchCandidate second_best;
+  second_best.period_inverted_lag = 1;
+  for (int inverted_lag = 0; inverted_lag < kNumLags12kHz; ++inverted_lag) {
+    // A pitch candidate must have positive correlation.
+    if (auto_correlation[inverted_lag] > 0.f) {
+      PitchCandidate candidate{
+          inverted_lag,
+          auto_correlation[inverted_lag] * auto_correlation[inverted_lag],
+          denominator};
+      if (candidate.HasStrongerPitchThan(second_best)) {
+        if (candidate.HasStrongerPitchThan(best)) {
+          second_best = best;
+          best = candidate;
+        } else {
+          second_best = candidate;
+        }
+      }
+    }
+    // Update |squared_energy_y| for the next inverted lag.
+    const float y_old = pitch_buffer[inverted_lag];
+    const float y_new = pitch_buffer[inverted_lag + kFrameSize20ms12kHz];
+    denominator -= y_old * y_old;
+    denominator += y_new * y_new;
+    denominator = std::max(0.f, denominator);
+  }
+  return {best.period_inverted_lag, second_best.period_inverted_lag};
+}
+
+int ComputePitchPeriod48kHz(
+    rtc::ArrayView<const float, kBufSize24kHz> pitch_buffer,
+    rtc::ArrayView<const float, kRefineNumLags24kHz> y_energy,
+    CandidatePitchPeriods pitch_candidates,
+    AvailableCpuFeatures cpu_features) {
+  // Compute the auto-correlation terms only for neighbors of the two pitch
+  // candidates (best and second best).
+  std::array<float, kInitialNumLags24kHz> auto_correlation;
+  InvertedLagsIndex inverted_lags_index;
+  // Create two inverted lag ranges so that `r1` precedes `r2`.
+  const bool swap_candidates =
+      pitch_candidates.best > pitch_candidates.second_best;
+  const Range r1 = CreateInvertedLagRange(
+      swap_candidates ? pitch_candidates.second_best : pitch_candidates.best);
+  const Range r2 = CreateInvertedLagRange(
+      swap_candidates ? pitch_candidates.best : pitch_candidates.second_best);
+  // Check valid ranges.
+  RTC_DCHECK_LE(r1.min, r1.max);
+  RTC_DCHECK_LE(r2.min, r2.max);
+  // Check `r1` precedes `r2`.
+  RTC_DCHECK_LE(r1.min, r2.min);
+  RTC_DCHECK_LE(r1.max, r2.max);
+  VectorMath vector_math(cpu_features);
+  if (r1.max + 1 >= r2.min) {
+    // Overlapping or adjacent ranges.
+    ComputeAutoCorrelation({r1.min, r2.max}, pitch_buffer, auto_correlation,
+                           inverted_lags_index, vector_math);
+  } else {
+    // Disjoint ranges.
+    ComputeAutoCorrelation(r1, pitch_buffer, auto_correlation,
+                           inverted_lags_index, vector_math);
+    ComputeAutoCorrelation(r2, pitch_buffer, auto_correlation,
+                           inverted_lags_index, vector_math);
+  }
+  return ComputePitchPeriod48kHz(pitch_buffer, inverted_lags_index,
+                                 auto_correlation, y_energy, vector_math);
+}
+
+PitchInfo ComputeExtendedPitchPeriod48kHz(
+    rtc::ArrayView<const float, kBufSize24kHz> pitch_buffer,
+    rtc::ArrayView<const float, kRefineNumLags24kHz> y_energy,
+    int initial_pitch_period_48kHz,
+    PitchInfo last_pitch_48kHz,
+    AvailableCpuFeatures cpu_features) {
+  RTC_DCHECK_LE(kMinPitch48kHz, initial_pitch_period_48kHz);
+  RTC_DCHECK_LE(initial_pitch_period_48kHz, kMaxPitch48kHz);
+
+  // Stores information for a refined pitch candidate.
+  struct RefinedPitchCandidate {
+    int period;
+    float strength;
+    // Additional strength data used for the final pitch estimation.
+    float xy;        // Auto-correlation.
+    float y_energy;  // Energy of the sliding frame `y`.
+  };
+
+  const float x_energy = y_energy[kMaxPitch24kHz];
+  const auto pitch_strength = [x_energy](float xy, float y_energy) {
+    RTC_DCHECK_GE(x_energy * y_energy, 0.f);
+    return xy / std::sqrt(1.f + x_energy * y_energy);
+  };
+  VectorMath vector_math(cpu_features);
+
+  // Initialize the best pitch candidate with `initial_pitch_period_48kHz`.
+  RefinedPitchCandidate best_pitch;
+  best_pitch.period =
+      std::min(initial_pitch_period_48kHz / 2, kMaxPitch24kHz - 1);
+  best_pitch.xy = ComputeAutoCorrelation(kMaxPitch24kHz - best_pitch.period,
+                                         pitch_buffer, vector_math);
+  best_pitch.y_energy = y_energy[kMaxPitch24kHz - best_pitch.period];
+  best_pitch.strength = pitch_strength(best_pitch.xy, best_pitch.y_energy);
+  // Keep a copy of the initial pitch candidate.
+  const PitchInfo initial_pitch{best_pitch.period, best_pitch.strength};
+  // 24 kHz version of the last estimated pitch.
+  const PitchInfo last_pitch{last_pitch_48kHz.period / 2,
+                             last_pitch_48kHz.strength};
+
+  // Find `max_period_divisor` such that the result of
+  // `GetAlternativePitchPeriod(initial_pitch_period, 1, max_period_divisor)`
+  // equals `kMinPitch24kHz`.
+  const int max_period_divisor =
+      (2 * initial_pitch.period) / (2 * kMinPitch24kHz - 1);
+  for (int period_divisor = 2; period_divisor <= max_period_divisor;
+       ++period_divisor) {
+    PitchInfo alternative_pitch;
+    alternative_pitch.period = GetAlternativePitchPeriod(
+        initial_pitch.period, /*multiplier=*/1, period_divisor);
+    RTC_DCHECK_GE(alternative_pitch.period, kMinPitch24kHz);
+    // When looking at |alternative_pitch.period|, we also look at one of its
+    // sub-harmonics. |kSubHarmonicMultipliers| is used to know where to look.
+    // |period_divisor| == 2 is a special case since |dual_alternative_period|
+    // might be greater than the maximum pitch period.
+    int dual_alternative_period = GetAlternativePitchPeriod(
+        initial_pitch.period, kSubHarmonicMultipliers[period_divisor - 2],
+        period_divisor);
+    RTC_DCHECK_GT(dual_alternative_period, 0);
+    if (period_divisor == 2 && dual_alternative_period > kMaxPitch24kHz) {
+      dual_alternative_period = initial_pitch.period;
+    }
+    RTC_DCHECK_NE(alternative_pitch.period, dual_alternative_period)
+        << "The lower pitch period and the additional sub-harmonic must not "
+           "coincide.";
+    // Compute an auto-correlation score for the primary pitch candidate
+    // |alternative_pitch.period| by also looking at its possible sub-harmonic
+    // |dual_alternative_period|.
+    const float xy_primary_period = ComputeAutoCorrelation(
+        kMaxPitch24kHz - alternative_pitch.period, pitch_buffer, vector_math);
+    // TODO(webrtc:10480): Copy `xy_primary_period` if the secondary period is
+    // equal to the primary one.
+    const float xy_secondary_period = ComputeAutoCorrelation(
+        kMaxPitch24kHz - dual_alternative_period, pitch_buffer, vector_math);
+    const float xy = 0.5f * (xy_primary_period + xy_secondary_period);
+    const float yy =
+        0.5f * (y_energy[kMaxPitch24kHz - alternative_pitch.period] +
+                y_energy[kMaxPitch24kHz - dual_alternative_period]);
+    alternative_pitch.strength = pitch_strength(xy, yy);
+
+    // Maybe update best period.
+    if (IsAlternativePitchStrongerThanInitial(
+            last_pitch, initial_pitch, alternative_pitch, period_divisor)) {
+      best_pitch = {alternative_pitch.period, alternative_pitch.strength, xy,
+                    yy};
+    }
+  }
+
+  // Final pitch strength and period.
+  best_pitch.xy = std::max(0.f, best_pitch.xy);
+  RTC_DCHECK_LE(0.f, best_pitch.y_energy);
+  float final_pitch_strength =
+      (best_pitch.y_energy <= best_pitch.xy)
+          ? 1.f
+          : best_pitch.xy / (best_pitch.y_energy + 1.f);
+  final_pitch_strength = std::min(best_pitch.strength, final_pitch_strength);
+  int final_pitch_period_48kHz = std::max(
+      kMinPitch48kHz, PitchPseudoInterpolationLagPitchBuf(
+                          best_pitch.period, pitch_buffer, vector_math));
+
+  return {final_pitch_period_48kHz, final_pitch_strength};
+}
+
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search_internal.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search_internal.h
new file mode 100644
index 0000000..aa2dd13
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search_internal.h
@@ -0,0 +1,114 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_PITCH_SEARCH_INTERNAL_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_PITCH_SEARCH_INTERNAL_H_
+
+#include <stddef.h>
+
+#include <array>
+#include <utility>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/cpu_features.h"
+#include "modules/audio_processing/agc2/rnn_vad/common.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+// Performs 2x decimation without any anti-aliasing filter.
+void Decimate2x(rtc::ArrayView<const float, kBufSize24kHz> src,
+                rtc::ArrayView<float, kBufSize12kHz> dst);
+
+// Key concepts and keywords used below in this file.
+//
+// The pitch estimation relies on a pitch buffer, which is an array-like data
+// structured designed as follows:
+//
+// |....A....|.....B.....|
+//
+// The part on the left, named `A` contains the oldest samples, whereas `B`
+// contains the most recent ones. The size of `A` corresponds to the maximum
+// pitch period, that of `B` to the analysis frame size (e.g., 16 ms and 20 ms
+// respectively).
+//
+// Pitch estimation is essentially based on the analysis of two 20 ms frames
+// extracted from the pitch buffer. One frame, called `x`, is kept fixed and
+// corresponds to `B` - i.e., the most recent 20 ms. The other frame, called
+// `y`, is extracted from different parts of the buffer instead.
+//
+// The offset between `x` and `y` corresponds to a specific pitch period.
+// For instance, if `y` is positioned at the beginning of the pitch buffer, then
+// the cross-correlation between `x` and `y` can be used as an indication of the
+// strength for the maximum pitch.
+//
+// Such an offset can be encoded in two ways:
+// - As a lag, which is the index in the pitch buffer for the first item in `y`
+// - As an inverted lag, which is the number of samples from the beginning of
+//   `x` and the end of `y`
+//
+// |---->| lag
+// |....A....|.....B.....|
+//       |<--| inverted lag
+//       |.....y.....| `y` 20 ms frame
+//
+// The inverted lag has the advantage of being directly proportional to the
+// corresponding pitch period.
+
+// Computes the sum of squared samples for every sliding frame `y` in the pitch
+// buffer. The indexes of `y_energy` are inverted lags.
+void ComputeSlidingFrameSquareEnergies24kHz(
+    rtc::ArrayView<const float, kBufSize24kHz> pitch_buffer,
+    rtc::ArrayView<float, kRefineNumLags24kHz> y_energy,
+    AvailableCpuFeatures cpu_features);
+
+// Top-2 pitch period candidates. Unit: number of samples - i.e., inverted lags.
+struct CandidatePitchPeriods {
+  int best;
+  int second_best;
+};
+
+// Computes the candidate pitch periods at 12 kHz given a view on the 12 kHz
+// pitch buffer and the auto-correlation values (having inverted lags as
+// indexes).
+CandidatePitchPeriods ComputePitchPeriod12kHz(
+    rtc::ArrayView<const float, kBufSize12kHz> pitch_buffer,
+    rtc::ArrayView<const float, kNumLags12kHz> auto_correlation,
+    AvailableCpuFeatures cpu_features);
+
+// Computes the pitch period at 48 kHz given a view on the 24 kHz pitch buffer,
+// the energies for the sliding frames `y` at 24 kHz and the pitch period
+// candidates at 24 kHz (encoded as inverted lag).
+int ComputePitchPeriod48kHz(
+    rtc::ArrayView<const float, kBufSize24kHz> pitch_buffer,
+    rtc::ArrayView<const float, kRefineNumLags24kHz> y_energy,
+    CandidatePitchPeriods pitch_candidates_24kHz,
+    AvailableCpuFeatures cpu_features);
+
+struct PitchInfo {
+  int period;
+  float strength;
+};
+
+// Computes the pitch period at 48 kHz searching in an extended pitch range
+// given a view on the 24 kHz pitch buffer, the energies for the sliding frames
+// `y` at 24 kHz, the initial 48 kHz estimation (computed by
+// `ComputePitchPeriod48kHz()`) and the last estimated pitch.
+PitchInfo ComputeExtendedPitchPeriod48kHz(
+    rtc::ArrayView<const float, kBufSize24kHz> pitch_buffer,
+    rtc::ArrayView<const float, kRefineNumLags24kHz> y_energy,
+    int initial_pitch_period_48kHz,
+    PitchInfo last_pitch_48kHz,
+    AvailableCpuFeatures cpu_features);
+
+}  // namespace rnn_vad
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_PITCH_SEARCH_INTERNAL_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search_internal_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search_internal_unittest.cc
new file mode 100644
index 0000000..2a6e68f
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search_internal_unittest.cc
@@ -0,0 +1,217 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/pitch_search_internal.h"
+
+#include <array>
+#include <string>
+#include <tuple>
+
+#include "modules/audio_processing/agc2/rnn_vad/test_utils.h"
+#include "rtc_base/strings/string_builder.h"
+// TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+// #include "test/fpe_observer.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+constexpr int kTestPitchPeriodsLow = 3 * kMinPitch48kHz / 2;
+constexpr int kTestPitchPeriodsHigh = (3 * kMinPitch48kHz + kMaxPitch48kHz) / 2;
+
+constexpr float kTestPitchStrengthLow = 0.35f;
+constexpr float kTestPitchStrengthHigh = 0.75f;
+
+template <class T>
+std::string PrintTestIndexAndCpuFeatures(
+    const ::testing::TestParamInfo<T>& info) {
+  rtc::StringBuilder builder;
+  builder << info.index << "_" << info.param.cpu_features.ToString();
+  return builder.str();
+}
+
+// Finds the relevant CPU features combinations to test.
+std::vector<AvailableCpuFeatures> GetCpuFeaturesToTest() {
+  std::vector<AvailableCpuFeatures> v;
+  v.push_back(NoAvailableCpuFeatures());
+  AvailableCpuFeatures available = GetAvailableCpuFeatures();
+  if (available.avx2) {
+    v.push_back({/*sse2=*/false, /*avx2=*/true, /*neon=*/false});
+  }
+  if (available.sse2) {
+    v.push_back({/*sse2=*/true, /*avx2=*/false, /*neon=*/false});
+  }
+  return v;
+}
+
+// Checks that the frame-wise sliding square energy function produces output
+// within tolerance given test input data.
+TEST(RnnVadTest, ComputeSlidingFrameSquareEnergies24kHzWithinTolerance) {
+  const AvailableCpuFeatures cpu_features = GetAvailableCpuFeatures();
+
+  PitchTestData test_data;
+  std::array<float, kRefineNumLags24kHz> computed_output;
+  // TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+  // FloatingPointExceptionObserver fpe_observer;
+  ComputeSlidingFrameSquareEnergies24kHz(test_data.PitchBuffer24kHzView(),
+                                         computed_output, cpu_features);
+  auto square_energies_view = test_data.SquareEnergies24kHzView();
+  ExpectNearAbsolute({square_energies_view.data(), square_energies_view.size()},
+                     computed_output, 1e-3f);
+}
+
+// Checks that the estimated pitch period is bit-exact given test input data.
+TEST(RnnVadTest, ComputePitchPeriod12kHzBitExactness) {
+  const AvailableCpuFeatures cpu_features = GetAvailableCpuFeatures();
+
+  PitchTestData test_data;
+  std::array<float, kBufSize12kHz> pitch_buf_decimated;
+  Decimate2x(test_data.PitchBuffer24kHzView(), pitch_buf_decimated);
+  CandidatePitchPeriods pitch_candidates;
+  // TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+  // FloatingPointExceptionObserver fpe_observer;
+  pitch_candidates = ComputePitchPeriod12kHz(
+      pitch_buf_decimated, test_data.AutoCorrelation12kHzView(), cpu_features);
+  EXPECT_EQ(pitch_candidates.best, 140);
+  EXPECT_EQ(pitch_candidates.second_best, 142);
+}
+
+// Checks that the refined pitch period is bit-exact given test input data.
+TEST(RnnVadTest, ComputePitchPeriod48kHzBitExactness) {
+  const AvailableCpuFeatures cpu_features = GetAvailableCpuFeatures();
+
+  PitchTestData test_data;
+  std::vector<float> y_energy(kRefineNumLags24kHz);
+  rtc::ArrayView<float, kRefineNumLags24kHz> y_energy_view(y_energy.data(),
+                                                           kRefineNumLags24kHz);
+  ComputeSlidingFrameSquareEnergies24kHz(test_data.PitchBuffer24kHzView(),
+                                         y_energy_view, cpu_features);
+  // TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+  // FloatingPointExceptionObserver fpe_observer;
+  EXPECT_EQ(
+      ComputePitchPeriod48kHz(test_data.PitchBuffer24kHzView(), y_energy_view,
+                              /*pitch_candidates=*/{280, 284}, cpu_features),
+      560);
+  EXPECT_EQ(
+      ComputePitchPeriod48kHz(test_data.PitchBuffer24kHzView(), y_energy_view,
+                              /*pitch_candidates=*/{260, 284}, cpu_features),
+      568);
+}
+
+struct PitchCandidatesParameters {
+  CandidatePitchPeriods pitch_candidates;
+  AvailableCpuFeatures cpu_features;
+};
+
+class PitchCandidatesParametrization
+    : public ::testing::TestWithParam<PitchCandidatesParameters> {};
+
+// Checks that the result of `ComputePitchPeriod48kHz()` does not depend on the
+// order of the input pitch candidates.
+TEST_P(PitchCandidatesParametrization,
+       ComputePitchPeriod48kHzOrderDoesNotMatter) {
+  const PitchCandidatesParameters params = GetParam();
+  const CandidatePitchPeriods swapped_pitch_candidates{
+      params.pitch_candidates.second_best, params.pitch_candidates.best};
+
+  PitchTestData test_data;
+  std::vector<float> y_energy(kRefineNumLags24kHz);
+  rtc::ArrayView<float, kRefineNumLags24kHz> y_energy_view(y_energy.data(),
+                                                           kRefineNumLags24kHz);
+  ComputeSlidingFrameSquareEnergies24kHz(test_data.PitchBuffer24kHzView(),
+                                         y_energy_view, params.cpu_features);
+  EXPECT_EQ(
+      ComputePitchPeriod48kHz(test_data.PitchBuffer24kHzView(), y_energy_view,
+                              params.pitch_candidates, params.cpu_features),
+      ComputePitchPeriod48kHz(test_data.PitchBuffer24kHzView(), y_energy_view,
+                              swapped_pitch_candidates, params.cpu_features));
+}
+
+std::vector<PitchCandidatesParameters> CreatePitchCandidatesParameters() {
+  std::vector<PitchCandidatesParameters> v;
+  for (AvailableCpuFeatures cpu_features : GetCpuFeaturesToTest()) {
+    v.push_back({{0, 2}, cpu_features});
+    v.push_back({{260, 284}, cpu_features});
+    v.push_back({{280, 284}, cpu_features});
+    v.push_back(
+        {{kInitialNumLags24kHz - 2, kInitialNumLags24kHz - 1}, cpu_features});
+  }
+  return v;
+}
+
+INSTANTIATE_TEST_SUITE_P(
+    RnnVadTest,
+    PitchCandidatesParametrization,
+    ::testing::ValuesIn(CreatePitchCandidatesParameters()),
+    PrintTestIndexAndCpuFeatures<PitchCandidatesParameters>);
+
+struct ExtendedPitchPeriodSearchParameters {
+  int initial_pitch_period;
+  PitchInfo last_pitch;
+  PitchInfo expected_pitch;
+  AvailableCpuFeatures cpu_features;
+};
+
+class ExtendedPitchPeriodSearchParametrizaion
+    : public ::testing::TestWithParam<ExtendedPitchPeriodSearchParameters> {};
+
+// Checks that the computed pitch period is bit-exact and that the computed
+// pitch strength is within tolerance given test input data.
+TEST_P(ExtendedPitchPeriodSearchParametrizaion,
+       PeriodBitExactnessGainWithinTolerance) {
+  const ExtendedPitchPeriodSearchParameters params = GetParam();
+
+  PitchTestData test_data;
+  std::vector<float> y_energy(kRefineNumLags24kHz);
+  rtc::ArrayView<float, kRefineNumLags24kHz> y_energy_view(y_energy.data(),
+                                                           kRefineNumLags24kHz);
+  ComputeSlidingFrameSquareEnergies24kHz(test_data.PitchBuffer24kHzView(),
+                                         y_energy_view, params.cpu_features);
+  // TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+  // FloatingPointExceptionObserver fpe_observer;
+  const auto computed_output = ComputeExtendedPitchPeriod48kHz(
+      test_data.PitchBuffer24kHzView(), y_energy_view,
+      params.initial_pitch_period, params.last_pitch, params.cpu_features);
+  EXPECT_EQ(params.expected_pitch.period, computed_output.period);
+  EXPECT_NEAR(params.expected_pitch.strength, computed_output.strength, 1e-6f);
+}
+
+std::vector<ExtendedPitchPeriodSearchParameters>
+CreateExtendedPitchPeriodSearchParameters() {
+  std::vector<ExtendedPitchPeriodSearchParameters> v;
+  for (AvailableCpuFeatures cpu_features : GetCpuFeaturesToTest()) {
+    for (int last_pitch_period :
+         {kTestPitchPeriodsLow, kTestPitchPeriodsHigh}) {
+      for (float last_pitch_strength :
+           {kTestPitchStrengthLow, kTestPitchStrengthHigh}) {
+        v.push_back({kTestPitchPeriodsLow,
+                     {last_pitch_period, last_pitch_strength},
+                     {91, -0.0188608f},
+                     cpu_features});
+        v.push_back({kTestPitchPeriodsHigh,
+                     {last_pitch_period, last_pitch_strength},
+                     {475, -0.0904344f},
+                     cpu_features});
+      }
+    }
+  }
+  return v;
+}
+
+INSTANTIATE_TEST_SUITE_P(
+    RnnVadTest,
+    ExtendedPitchPeriodSearchParametrizaion,
+    ::testing::ValuesIn(CreateExtendedPitchPeriodSearchParameters()),
+    PrintTestIndexAndCpuFeatures<ExtendedPitchPeriodSearchParameters>);
+
+}  // namespace
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search_unittest.cc
new file mode 100644
index 0000000..79b44b9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/pitch_search_unittest.cc
@@ -0,0 +1,53 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/pitch_search.h"
+
+#include <algorithm>
+#include <vector>
+
+#include "modules/audio_processing/agc2/cpu_features.h"
+#include "modules/audio_processing/agc2/rnn_vad/pitch_search_internal.h"
+#include "modules/audio_processing/agc2/rnn_vad/test_utils.h"
+// TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+// #include "test/fpe_observer.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+// Checks that the computed pitch period is bit-exact and that the computed
+// pitch gain is within tolerance given test input data.
+TEST(RnnVadTest, PitchSearchWithinTolerance) {
+  ChunksFileReader reader = CreateLpResidualAndPitchInfoReader();
+  const int num_frames = std::min(reader.num_chunks, 300);  // Max 3 s.
+  std::vector<float> lp_residual(kBufSize24kHz);
+  float expected_pitch_period, expected_pitch_strength;
+  const AvailableCpuFeatures cpu_features = GetAvailableCpuFeatures();
+  PitchEstimator pitch_estimator(cpu_features);
+  {
+    // TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+    // FloatingPointExceptionObserver fpe_observer;
+    for (int i = 0; i < num_frames; ++i) {
+      SCOPED_TRACE(i);
+      ASSERT_TRUE(reader.reader->ReadChunk(lp_residual));
+      ASSERT_TRUE(reader.reader->ReadValue(expected_pitch_period));
+      ASSERT_TRUE(reader.reader->ReadValue(expected_pitch_strength));
+      int pitch_period =
+          pitch_estimator.Estimate({lp_residual.data(), kBufSize24kHz});
+      EXPECT_EQ(expected_pitch_period, pitch_period);
+      EXPECT_NEAR(expected_pitch_strength,
+                  pitch_estimator.GetLastPitchStrengthForTesting(), 15e-6f);
+    }
+  }
+}
+
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/ring_buffer.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/ring_buffer.h
new file mode 100644
index 0000000..f0270af
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/ring_buffer.h
@@ -0,0 +1,65 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_RING_BUFFER_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_RING_BUFFER_H_
+
+#include <array>
+#include <cstring>
+#include <type_traits>
+
+#include "api/array_view.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+// Ring buffer for N arrays of type T each one with size S.
+template <typename T, int S, int N>
+class RingBuffer {
+  static_assert(S > 0, "");
+  static_assert(N > 0, "");
+  static_assert(std::is_arithmetic<T>::value,
+                "Integral or floating point required.");
+
+ public:
+  RingBuffer() : tail_(0) {}
+  RingBuffer(const RingBuffer&) = delete;
+  RingBuffer& operator=(const RingBuffer&) = delete;
+  ~RingBuffer() = default;
+  // Set the ring buffer values to zero.
+  void Reset() { buffer_.fill(0); }
+  // Replace the least recently pushed array in the buffer with |new_values|.
+  void Push(rtc::ArrayView<const T, S> new_values) {
+    std::memcpy(buffer_.data() + S * tail_, new_values.data(), S * sizeof(T));
+    tail_ += 1;
+    if (tail_ == N)
+      tail_ = 0;
+  }
+  // Return an array view onto the array with a given delay. A view on the last
+  // and least recently push array is returned when |delay| is 0 and N - 1
+  // respectively.
+  rtc::ArrayView<const T, S> GetArrayView(int delay) const {
+    RTC_DCHECK_LE(0, delay);
+    RTC_DCHECK_LT(delay, N);
+    int offset = tail_ - 1 - delay;
+    if (offset < 0)
+      offset += N;
+    return {buffer_.data() + S * offset, S};
+  }
+
+ private:
+  int tail_;  // Index of the least recently pushed sub-array.
+  std::array<T, S * N> buffer_{};
+};
+
+}  // namespace rnn_vad
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_RING_BUFFER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/ring_buffer_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/ring_buffer_unittest.cc
new file mode 100644
index 0000000..d11d4ea
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/ring_buffer_unittest.cc
@@ -0,0 +1,112 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/ring_buffer.h"
+
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+// Compare the elements of two given array views.
+template <typename T, std::ptrdiff_t S>
+void ExpectEq(rtc::ArrayView<const T, S> a, rtc::ArrayView<const T, S> b) {
+  for (int i = 0; i < S; ++i) {
+    SCOPED_TRACE(i);
+    EXPECT_EQ(a[i], b[i]);
+  }
+}
+
+// Test push/read sequences.
+template <typename T, int S, int N>
+void TestRingBuffer() {
+  SCOPED_TRACE(N);
+  SCOPED_TRACE(S);
+  std::array<T, S> prev_pushed_array;
+  std::array<T, S> pushed_array;
+  rtc::ArrayView<const T, S> pushed_array_view(pushed_array.data(), S);
+
+  // Init.
+  RingBuffer<T, S, N> ring_buf;
+  ring_buf.GetArrayView(0);
+  pushed_array.fill(0);
+  ring_buf.Push(pushed_array_view);
+  ExpectEq(pushed_array_view, ring_buf.GetArrayView(0));
+
+  // Push N times and check most recent and second most recent.
+  for (T v = 1; v <= static_cast<T>(N); ++v) {
+    SCOPED_TRACE(v);
+    prev_pushed_array = pushed_array;
+    pushed_array.fill(v);
+    ring_buf.Push(pushed_array_view);
+    ExpectEq(pushed_array_view, ring_buf.GetArrayView(0));
+    if (N > 1) {
+      pushed_array.fill(v - 1);
+      ExpectEq(pushed_array_view, ring_buf.GetArrayView(1));
+    }
+  }
+
+  // Check buffer.
+  for (int delay = 2; delay < N; ++delay) {
+    SCOPED_TRACE(delay);
+    T expected_value = N - static_cast<T>(delay);
+    pushed_array.fill(expected_value);
+    ExpectEq(pushed_array_view, ring_buf.GetArrayView(delay));
+  }
+}
+
+// Check that for different delays, different views are returned.
+TEST(RnnVadTest, RingBufferArrayViews) {
+  constexpr int s = 3;
+  constexpr int n = 4;
+  RingBuffer<int, s, n> ring_buf;
+  std::array<int, s> pushed_array;
+  pushed_array.fill(1);
+  for (int k = 0; k <= n; ++k) {  // Push data n + 1 times.
+    SCOPED_TRACE(k);
+    // Check array views.
+    for (int i = 0; i < n; ++i) {
+      SCOPED_TRACE(i);
+      auto view_i = ring_buf.GetArrayView(i);
+      for (int j = i + 1; j < n; ++j) {
+        SCOPED_TRACE(j);
+        auto view_j = ring_buf.GetArrayView(j);
+        EXPECT_NE(view_i, view_j);
+      }
+    }
+    ring_buf.Push(pushed_array);
+  }
+}
+
+TEST(RnnVadTest, RingBufferUnsigned) {
+  TestRingBuffer<uint8_t, 1, 1>();
+  TestRingBuffer<uint8_t, 2, 5>();
+  TestRingBuffer<uint8_t, 5, 2>();
+  TestRingBuffer<uint8_t, 5, 5>();
+}
+
+TEST(RnnVadTest, RingBufferSigned) {
+  TestRingBuffer<int, 1, 1>();
+  TestRingBuffer<int, 2, 5>();
+  TestRingBuffer<int, 5, 2>();
+  TestRingBuffer<int, 5, 5>();
+}
+
+TEST(RnnVadTest, RingBufferFloating) {
+  TestRingBuffer<float, 1, 1>();
+  TestRingBuffer<float, 2, 5>();
+  TestRingBuffer<float, 5, 2>();
+  TestRingBuffer<float, 5, 5>();
+}
+
+}  // namespace
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn.cc
new file mode 100644
index 0000000..475bef9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn.cc
@@ -0,0 +1,91 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/rnn.h"
+
+#include "rtc_base/checks.h"
+#include "third_party/rnnoise/src/rnn_vad_weights.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+using ::rnnoise::kInputLayerInputSize;
+static_assert(kFeatureVectorSize == kInputLayerInputSize, "");
+using ::rnnoise::kInputDenseBias;
+using ::rnnoise::kInputDenseWeights;
+using ::rnnoise::kInputLayerOutputSize;
+static_assert(kInputLayerOutputSize <= kFullyConnectedLayerMaxUnits, "");
+
+using ::rnnoise::kHiddenGruBias;
+using ::rnnoise::kHiddenGruRecurrentWeights;
+using ::rnnoise::kHiddenGruWeights;
+using ::rnnoise::kHiddenLayerOutputSize;
+static_assert(kHiddenLayerOutputSize <= kGruLayerMaxUnits, "");
+
+using ::rnnoise::kOutputDenseBias;
+using ::rnnoise::kOutputDenseWeights;
+using ::rnnoise::kOutputLayerOutputSize;
+static_assert(kOutputLayerOutputSize <= kFullyConnectedLayerMaxUnits, "");
+
+}  // namespace
+
+RnnVad::RnnVad(const AvailableCpuFeatures& cpu_features)
+    : input_(kInputLayerInputSize,
+             kInputLayerOutputSize,
+             kInputDenseBias,
+             kInputDenseWeights,
+             ActivationFunction::kTansigApproximated,
+             cpu_features,
+             /*layer_name=*/"FC1"),
+      hidden_(kInputLayerOutputSize,
+              kHiddenLayerOutputSize,
+              kHiddenGruBias,
+              kHiddenGruWeights,
+              kHiddenGruRecurrentWeights,
+              cpu_features,
+              /*layer_name=*/"GRU1"),
+      output_(kHiddenLayerOutputSize,
+              kOutputLayerOutputSize,
+              kOutputDenseBias,
+              kOutputDenseWeights,
+              ActivationFunction::kSigmoidApproximated,
+              // The output layer is just 24x1. The unoptimized code is faster.
+              NoAvailableCpuFeatures(),
+              /*layer_name=*/"FC2") {
+  // Input-output chaining size checks.
+  RTC_DCHECK_EQ(input_.size(), hidden_.input_size())
+      << "The input and the hidden layers sizes do not match.";
+  RTC_DCHECK_EQ(hidden_.size(), output_.input_size())
+      << "The hidden and the output layers sizes do not match.";
+}
+
+RnnVad::~RnnVad() = default;
+
+void RnnVad::Reset() {
+  hidden_.Reset();
+}
+
+float RnnVad::ComputeVadProbability(
+    rtc::ArrayView<const float, kFeatureVectorSize> feature_vector,
+    bool is_silence) {
+  if (is_silence) {
+    Reset();
+    return 0.f;
+  }
+  input_.ComputeOutput(feature_vector);
+  hidden_.ComputeOutput(input_);
+  output_.ComputeOutput(hidden_);
+  RTC_DCHECK_EQ(output_.size(), 1);
+  return output_.data()[0];
+}
+
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn.h
new file mode 100644
index 0000000..3148f1b
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn.h
@@ -0,0 +1,53 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_RNN_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_RNN_H_
+
+#include <stddef.h>
+#include <sys/types.h>
+
+#include <array>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/cpu_features.h"
+#include "modules/audio_processing/agc2/rnn_vad/common.h"
+#include "modules/audio_processing/agc2/rnn_vad/rnn_fc.h"
+#include "modules/audio_processing/agc2/rnn_vad/rnn_gru.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+// Recurrent network with hard-coded architecture and weights for voice activity
+// detection.
+class RnnVad {
+ public:
+  explicit RnnVad(const AvailableCpuFeatures& cpu_features);
+  RnnVad(const RnnVad&) = delete;
+  RnnVad& operator=(const RnnVad&) = delete;
+  ~RnnVad();
+  void Reset();
+  // Observes `feature_vector` and `is_silence`, updates the RNN and returns the
+  // current voice probability.
+  float ComputeVadProbability(
+      rtc::ArrayView<const float, kFeatureVectorSize> feature_vector,
+      bool is_silence);
+
+ private:
+  FullyConnectedLayer input_;
+  GatedRecurrentLayer hidden_;
+  FullyConnectedLayer output_;
+};
+
+}  // namespace rnn_vad
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_RNN_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_fc.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_fc.cc
new file mode 100644
index 0000000..b04807f
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_fc.cc
@@ -0,0 +1,105 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include <algorithm>
+#include <numeric>
+
+#include "modules/audio_processing/agc2/rnn_vad/rnn_fc.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_conversions.h"
+#include "third_party/rnnoise/src/rnn_activations.h"
+#include "third_party/rnnoise/src/rnn_vad_weights.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+std::vector<float> GetScaledParams(rtc::ArrayView<const int8_t> params) {
+  std::vector<float> scaled_params(params.size());
+  std::transform(params.begin(), params.end(), scaled_params.begin(),
+                 [](int8_t x) -> float {
+                   return ::rnnoise::kWeightsScale * static_cast<float>(x);
+                 });
+  return scaled_params;
+}
+
+// TODO(bugs.chromium.org/10480): Hard-code optimized layout and remove this
+// function to improve setup time.
+// Casts and scales |weights| and re-arranges the layout.
+std::vector<float> PreprocessWeights(rtc::ArrayView<const int8_t> weights,
+                                     int output_size) {
+  if (output_size == 1) {
+    return GetScaledParams(weights);
+  }
+  // Transpose, scale and cast.
+  const int input_size = rtc::CheckedDivExact(
+      rtc::dchecked_cast<int>(weights.size()), output_size);
+  std::vector<float> w(weights.size());
+  for (int o = 0; o < output_size; ++o) {
+    for (int i = 0; i < input_size; ++i) {
+      w[o * input_size + i] = rnnoise::kWeightsScale *
+                              static_cast<float>(weights[i * output_size + o]);
+    }
+  }
+  return w;
+}
+
+rtc::FunctionView<float(float)> GetActivationFunction(
+    ActivationFunction activation_function) {
+  switch (activation_function) {
+    case ActivationFunction::kTansigApproximated:
+      return ::rnnoise::TansigApproximated;
+      break;
+    case ActivationFunction::kSigmoidApproximated:
+      return ::rnnoise::SigmoidApproximated;
+      break;
+  }
+}
+
+}  // namespace
+
+FullyConnectedLayer::FullyConnectedLayer(
+    const int input_size,
+    const int output_size,
+    const rtc::ArrayView<const int8_t> bias,
+    const rtc::ArrayView<const int8_t> weights,
+    ActivationFunction activation_function,
+    const AvailableCpuFeatures& cpu_features,
+    absl::string_view layer_name)
+    : input_size_(input_size),
+      output_size_(output_size),
+      bias_(GetScaledParams(bias)),
+      weights_(PreprocessWeights(weights, output_size)),
+      vector_math_(cpu_features),
+      activation_function_(GetActivationFunction(activation_function)) {
+  RTC_DCHECK_LE(output_size_, kFullyConnectedLayerMaxUnits)
+      << "Insufficient FC layer over-allocation (" << layer_name << ").";
+  RTC_DCHECK_EQ(output_size_, bias_.size())
+      << "Mismatching output size and bias terms array size (" << layer_name
+      << ").";
+  RTC_DCHECK_EQ(input_size_ * output_size_, weights_.size())
+      << "Mismatching input-output size and weight coefficients array size ("
+      << layer_name << ").";
+}
+
+FullyConnectedLayer::~FullyConnectedLayer() = default;
+
+void FullyConnectedLayer::ComputeOutput(rtc::ArrayView<const float> input) {
+  RTC_DCHECK_EQ(input.size(), input_size_);
+  rtc::ArrayView<const float> weights(weights_);
+  for (int o = 0; o < output_size_; ++o) {
+    output_[o] = activation_function_(
+        bias_[o] + vector_math_.DotProduct(
+                       input, weights.subview(o * input_size_, input_size_)));
+  }
+}
+
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_fc.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_fc.h
new file mode 100644
index 0000000..d23957a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_fc.h
@@ -0,0 +1,72 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_RNN_FC_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_RNN_FC_H_
+
+#include <array>
+#include <vector>
+
+#include "absl/strings/string_view.h"
+#include "api/array_view.h"
+#include "api/function_view.h"
+#include "modules/audio_processing/agc2/cpu_features.h"
+#include "modules/audio_processing/agc2/rnn_vad/vector_math.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+// Activation function for a neural network cell.
+enum class ActivationFunction { kTansigApproximated, kSigmoidApproximated };
+
+// Maximum number of units for an FC layer.
+constexpr int kFullyConnectedLayerMaxUnits = 24;
+
+// Fully-connected layer with a custom activation function which owns the output
+// buffer.
+class FullyConnectedLayer {
+ public:
+  // Ctor. `output_size` cannot be greater than `kFullyConnectedLayerMaxUnits`.
+  FullyConnectedLayer(int input_size,
+                      int output_size,
+                      rtc::ArrayView<const int8_t> bias,
+                      rtc::ArrayView<const int8_t> weights,
+                      ActivationFunction activation_function,
+                      const AvailableCpuFeatures& cpu_features,
+                      absl::string_view layer_name);
+  FullyConnectedLayer(const FullyConnectedLayer&) = delete;
+  FullyConnectedLayer& operator=(const FullyConnectedLayer&) = delete;
+  ~FullyConnectedLayer();
+
+  // Returns the size of the input vector.
+  int input_size() const { return input_size_; }
+  // Returns the pointer to the first element of the output buffer.
+  const float* data() const { return output_.data(); }
+  // Returns the size of the output buffer.
+  int size() const { return output_size_; }
+
+  // Computes the fully-connected layer output.
+  void ComputeOutput(rtc::ArrayView<const float> input);
+
+ private:
+  const int input_size_;
+  const int output_size_;
+  const std::vector<float> bias_;
+  const std::vector<float> weights_;
+  const VectorMath vector_math_;
+  rtc::FunctionView<float(float)> activation_function_;
+  // Over-allocated array with size equal to `output_size_`.
+  std::array<float, kFullyConnectedLayerMaxUnits> output_;
+};
+
+}  // namespace rnn_vad
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_RNN_FC_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_fc_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_fc_unittest.cc
new file mode 100644
index 0000000..ff9bb18
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_fc_unittest.cc
@@ -0,0 +1,111 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/rnn_fc.h"
+
+#include <array>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/cpu_features.h"
+#include "modules/audio_processing/agc2/rnn_vad/test_utils.h"
+#include "modules/audio_processing/test/performance_timer.h"
+#include "rtc_base/logging.h"
+#include "rtc_base/system/arch.h"
+#include "test/gtest.h"
+#include "third_party/rnnoise/src/rnn_vad_weights.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+using ::rnnoise::kInputDenseBias;
+using ::rnnoise::kInputDenseWeights;
+using ::rnnoise::kInputLayerInputSize;
+using ::rnnoise::kInputLayerOutputSize;
+
+// Fully connected layer test data.
+constexpr std::array<float, 42> kFullyConnectedInputVector = {
+    -1.00131f,   -0.627069f, -7.81097f,  7.86285f,    -2.87145f,  3.32365f,
+    -0.653161f,  0.529839f,  -0.425307f, 0.25583f,    0.235094f,  0.230527f,
+    -0.144687f,  0.182785f,  0.57102f,   0.125039f,   0.479482f,  -0.0255439f,
+    -0.0073141f, -0.147346f, -0.217106f, -0.0846906f, -8.34943f,  3.09065f,
+    1.42628f,    -0.85235f,  -0.220207f, -0.811163f,  2.09032f,   -2.01425f,
+    -0.690268f,  -0.925327f, -0.541354f, 0.58455f,    -0.606726f, -0.0372358f,
+    0.565991f,   0.435854f,  0.420812f,  0.162198f,   -2.13f,     10.0089f};
+constexpr std::array<float, 24> kFullyConnectedExpectedOutput = {
+    -0.623293f, -0.988299f, 0.999378f,  0.967168f,  0.103087f,  -0.978545f,
+    -0.856347f, 0.346675f,  1.f,        -0.717442f, -0.544176f, 0.960363f,
+    0.983443f,  0.999991f,  -0.824335f, 0.984742f,  0.990208f,  0.938179f,
+    0.875092f,  0.999846f,  0.997707f,  -0.999382f, 0.973153f,  -0.966605f};
+
+class RnnFcParametrization
+    : public ::testing::TestWithParam<AvailableCpuFeatures> {};
+
+// Checks that the output of a fully connected layer is within tolerance given
+// test input data.
+TEST_P(RnnFcParametrization, CheckFullyConnectedLayerOutput) {
+  FullyConnectedLayer fc(kInputLayerInputSize, kInputLayerOutputSize,
+                         kInputDenseBias, kInputDenseWeights,
+                         ActivationFunction::kTansigApproximated,
+                         /*cpu_features=*/GetParam(),
+                         /*layer_name=*/"FC");
+  fc.ComputeOutput(kFullyConnectedInputVector);
+  ExpectNearAbsolute(kFullyConnectedExpectedOutput, fc, 1e-5f);
+}
+
+TEST_P(RnnFcParametrization, DISABLED_BenchmarkFullyConnectedLayer) {
+  const AvailableCpuFeatures cpu_features = GetParam();
+  FullyConnectedLayer fc(kInputLayerInputSize, kInputLayerOutputSize,
+                         kInputDenseBias, kInputDenseWeights,
+                         ActivationFunction::kTansigApproximated, cpu_features,
+                         /*layer_name=*/"FC");
+
+  constexpr int kNumTests = 10000;
+  ::webrtc::test::PerformanceTimer perf_timer(kNumTests);
+  for (int k = 0; k < kNumTests; ++k) {
+    perf_timer.StartTimer();
+    fc.ComputeOutput(kFullyConnectedInputVector);
+    perf_timer.StopTimer();
+  }
+  RTC_LOG(LS_INFO) << "CPU features: " << cpu_features.ToString() << " | "
+                   << (perf_timer.GetDurationAverage() / 1000) << " +/- "
+                   << (perf_timer.GetDurationStandardDeviation() / 1000)
+                   << " ms";
+}
+
+// Finds the relevant CPU features combinations to test.
+std::vector<AvailableCpuFeatures> GetCpuFeaturesToTest() {
+  std::vector<AvailableCpuFeatures> v;
+  v.push_back(NoAvailableCpuFeatures());
+  AvailableCpuFeatures available = GetAvailableCpuFeatures();
+  if (available.sse2) {
+    v.push_back({/*sse2=*/true, /*avx2=*/false, /*neon=*/false});
+  }
+  if (available.avx2) {
+    v.push_back({/*sse2=*/false, /*avx2=*/true, /*neon=*/false});
+  }
+  if (available.neon) {
+    v.push_back({/*sse2=*/false, /*avx2=*/false, /*neon=*/true});
+  }
+  return v;
+}
+
+INSTANTIATE_TEST_SUITE_P(
+    RnnVadTest,
+    RnnFcParametrization,
+    ::testing::ValuesIn(GetCpuFeaturesToTest()),
+    [](const ::testing::TestParamInfo<AvailableCpuFeatures>& info) {
+      return info.param.ToString();
+    });
+
+}  // namespace
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_gru.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_gru.cc
new file mode 100644
index 0000000..482016e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_gru.cc
@@ -0,0 +1,198 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/rnn_gru.h"
+
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_conversions.h"
+#include "third_party/rnnoise/src/rnn_activations.h"
+#include "third_party/rnnoise/src/rnn_vad_weights.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+constexpr int kNumGruGates = 3;  // Update, reset, output.
+
+std::vector<float> PreprocessGruTensor(rtc::ArrayView<const int8_t> tensor_src,
+                                       int output_size) {
+  // Transpose, cast and scale.
+  // |n| is the size of the first dimension of the 3-dim tensor |weights|.
+  const int n = rtc::CheckedDivExact(rtc::dchecked_cast<int>(tensor_src.size()),
+                                     output_size * kNumGruGates);
+  const int stride_src = kNumGruGates * output_size;
+  const int stride_dst = n * output_size;
+  std::vector<float> tensor_dst(tensor_src.size());
+  for (int g = 0; g < kNumGruGates; ++g) {
+    for (int o = 0; o < output_size; ++o) {
+      for (int i = 0; i < n; ++i) {
+        tensor_dst[g * stride_dst + o * n + i] =
+            ::rnnoise::kWeightsScale *
+            static_cast<float>(
+                tensor_src[i * stride_src + g * output_size + o]);
+      }
+    }
+  }
+  return tensor_dst;
+}
+
+// Computes the output for the update or the reset gate.
+// Operation: `g = sigmoid(W^Ti + R^Ts + b)` where
+// - `g`: output gate vector
+// - `W`: weights matrix
+// - `i`: input vector
+// - `R`: recurrent weights matrix
+// - `s`: state gate vector
+// - `b`: bias vector
+void ComputeUpdateResetGate(int input_size,
+                            int output_size,
+                            const VectorMath& vector_math,
+                            rtc::ArrayView<const float> input,
+                            rtc::ArrayView<const float> state,
+                            rtc::ArrayView<const float> bias,
+                            rtc::ArrayView<const float> weights,
+                            rtc::ArrayView<const float> recurrent_weights,
+                            rtc::ArrayView<float> gate) {
+  RTC_DCHECK_EQ(input.size(), input_size);
+  RTC_DCHECK_EQ(state.size(), output_size);
+  RTC_DCHECK_EQ(bias.size(), output_size);
+  RTC_DCHECK_EQ(weights.size(), input_size * output_size);
+  RTC_DCHECK_EQ(recurrent_weights.size(), output_size * output_size);
+  RTC_DCHECK_GE(gate.size(), output_size);  // `gate` is over-allocated.
+  for (int o = 0; o < output_size; ++o) {
+    float x = bias[o];
+    x += vector_math.DotProduct(input,
+                                weights.subview(o * input_size, input_size));
+    x += vector_math.DotProduct(
+        state, recurrent_weights.subview(o * output_size, output_size));
+    gate[o] = ::rnnoise::SigmoidApproximated(x);
+  }
+}
+
+// Computes the output for the state gate.
+// Operation: `s' = u .* s + (1 - u) .* ReLU(W^Ti + R^T(s .* r) + b)` where
+// - `s'`: output state gate vector
+// - `s`: previous state gate vector
+// - `u`: update gate vector
+// - `W`: weights matrix
+// - `i`: input vector
+// - `R`: recurrent weights matrix
+// - `r`: reset gate vector
+// - `b`: bias vector
+// - `.*` element-wise product
+void ComputeStateGate(int input_size,
+                      int output_size,
+                      const VectorMath& vector_math,
+                      rtc::ArrayView<const float> input,
+                      rtc::ArrayView<const float> update,
+                      rtc::ArrayView<const float> reset,
+                      rtc::ArrayView<const float> bias,
+                      rtc::ArrayView<const float> weights,
+                      rtc::ArrayView<const float> recurrent_weights,
+                      rtc::ArrayView<float> state) {
+  RTC_DCHECK_EQ(input.size(), input_size);
+  RTC_DCHECK_GE(update.size(), output_size);  // `update` is over-allocated.
+  RTC_DCHECK_GE(reset.size(), output_size);   // `reset` is over-allocated.
+  RTC_DCHECK_EQ(bias.size(), output_size);
+  RTC_DCHECK_EQ(weights.size(), input_size * output_size);
+  RTC_DCHECK_EQ(recurrent_weights.size(), output_size * output_size);
+  RTC_DCHECK_EQ(state.size(), output_size);
+  std::array<float, kGruLayerMaxUnits> reset_x_state;
+  for (int o = 0; o < output_size; ++o) {
+    reset_x_state[o] = state[o] * reset[o];
+  }
+  for (int o = 0; o < output_size; ++o) {
+    float x = bias[o];
+    x += vector_math.DotProduct(input,
+                                weights.subview(o * input_size, input_size));
+    x += vector_math.DotProduct(
+        {reset_x_state.data(), static_cast<size_t>(output_size)},
+        recurrent_weights.subview(o * output_size, output_size));
+    state[o] = update[o] * state[o] + (1.f - update[o]) * std::max(0.f, x);
+  }
+}
+
+}  // namespace
+
+GatedRecurrentLayer::GatedRecurrentLayer(
+    const int input_size,
+    const int output_size,
+    const rtc::ArrayView<const int8_t> bias,
+    const rtc::ArrayView<const int8_t> weights,
+    const rtc::ArrayView<const int8_t> recurrent_weights,
+    const AvailableCpuFeatures& cpu_features,
+    absl::string_view layer_name)
+    : input_size_(input_size),
+      output_size_(output_size),
+      bias_(PreprocessGruTensor(bias, output_size)),
+      weights_(PreprocessGruTensor(weights, output_size)),
+      recurrent_weights_(PreprocessGruTensor(recurrent_weights, output_size)),
+      vector_math_(cpu_features) {
+  RTC_DCHECK_LE(output_size_, kGruLayerMaxUnits)
+      << "Insufficient GRU layer over-allocation (" << layer_name << ").";
+  RTC_DCHECK_EQ(kNumGruGates * output_size_, bias_.size())
+      << "Mismatching output size and bias terms array size (" << layer_name
+      << ").";
+  RTC_DCHECK_EQ(kNumGruGates * input_size_ * output_size_, weights_.size())
+      << "Mismatching input-output size and weight coefficients array size ("
+      << layer_name << ").";
+  RTC_DCHECK_EQ(kNumGruGates * output_size_ * output_size_,
+                recurrent_weights_.size())
+      << "Mismatching input-output size and recurrent weight coefficients array"
+         " size ("
+      << layer_name << ").";
+  Reset();
+}
+
+GatedRecurrentLayer::~GatedRecurrentLayer() = default;
+
+void GatedRecurrentLayer::Reset() {
+  state_.fill(0.f);
+}
+
+void GatedRecurrentLayer::ComputeOutput(rtc::ArrayView<const float> input) {
+  RTC_DCHECK_EQ(input.size(), input_size_);
+
+  // The tensors below are organized as a sequence of flattened tensors for the
+  // `update`, `reset` and `state` gates.
+  rtc::ArrayView<const float> bias(bias_);
+  rtc::ArrayView<const float> weights(weights_);
+  rtc::ArrayView<const float> recurrent_weights(recurrent_weights_);
+  // Strides to access to the flattened tensors for a specific gate.
+  const int stride_weights = input_size_ * output_size_;
+  const int stride_recurrent_weights = output_size_ * output_size_;
+
+  rtc::ArrayView<float> state(state_.data(), output_size_);
+
+  // Update gate.
+  std::array<float, kGruLayerMaxUnits> update;
+  ComputeUpdateResetGate(
+      input_size_, output_size_, vector_math_, input, state,
+      bias.subview(0, output_size_), weights.subview(0, stride_weights),
+      recurrent_weights.subview(0, stride_recurrent_weights), update);
+  // Reset gate.
+  std::array<float, kGruLayerMaxUnits> reset;
+  ComputeUpdateResetGate(input_size_, output_size_, vector_math_, input, state,
+                         bias.subview(output_size_, output_size_),
+                         weights.subview(stride_weights, stride_weights),
+                         recurrent_weights.subview(stride_recurrent_weights,
+                                                   stride_recurrent_weights),
+                         reset);
+  // State gate.
+  ComputeStateGate(input_size_, output_size_, vector_math_, input, update,
+                   reset, bias.subview(2 * output_size_, output_size_),
+                   weights.subview(2 * stride_weights, stride_weights),
+                   recurrent_weights.subview(2 * stride_recurrent_weights,
+                                             stride_recurrent_weights),
+                   state);
+}
+
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_gru.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_gru.h
new file mode 100644
index 0000000..3407dfc
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_gru.h
@@ -0,0 +1,70 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_RNN_GRU_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_RNN_GRU_H_
+
+#include <array>
+#include <vector>
+
+#include "absl/strings/string_view.h"
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/cpu_features.h"
+#include "modules/audio_processing/agc2/rnn_vad/vector_math.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+// Maximum number of units for a GRU layer.
+constexpr int kGruLayerMaxUnits = 24;
+
+// Recurrent layer with gated recurrent units (GRUs) with sigmoid and ReLU as
+// activation functions for the update/reset and output gates respectively.
+class GatedRecurrentLayer {
+ public:
+  // Ctor. `output_size` cannot be greater than `kGruLayerMaxUnits`.
+  GatedRecurrentLayer(int input_size,
+                      int output_size,
+                      rtc::ArrayView<const int8_t> bias,
+                      rtc::ArrayView<const int8_t> weights,
+                      rtc::ArrayView<const int8_t> recurrent_weights,
+                      const AvailableCpuFeatures& cpu_features,
+                      absl::string_view layer_name);
+  GatedRecurrentLayer(const GatedRecurrentLayer&) = delete;
+  GatedRecurrentLayer& operator=(const GatedRecurrentLayer&) = delete;
+  ~GatedRecurrentLayer();
+
+  // Returns the size of the input vector.
+  int input_size() const { return input_size_; }
+  // Returns the pointer to the first element of the output buffer.
+  const float* data() const { return state_.data(); }
+  // Returns the size of the output buffer.
+  int size() const { return output_size_; }
+
+  // Resets the GRU state.
+  void Reset();
+  // Computes the recurrent layer output and updates the status.
+  void ComputeOutput(rtc::ArrayView<const float> input);
+
+ private:
+  const int input_size_;
+  const int output_size_;
+  const std::vector<float> bias_;
+  const std::vector<float> weights_;
+  const std::vector<float> recurrent_weights_;
+  const VectorMath vector_math_;
+  // Over-allocated array with size equal to `output_size_`.
+  std::array<float, kGruLayerMaxUnits> state_;
+};
+
+}  // namespace rnn_vad
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_RNN_GRU_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_gru_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_gru_unittest.cc
new file mode 100644
index 0000000..88ae728
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_gru_unittest.cc
@@ -0,0 +1,186 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/rnn_gru.h"
+
+#include <array>
+#include <memory>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/rnn_vad/test_utils.h"
+#include "modules/audio_processing/test/performance_timer.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+#include "test/gtest.h"
+#include "third_party/rnnoise/src/rnn_vad_weights.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+void TestGatedRecurrentLayer(
+    GatedRecurrentLayer& gru,
+    rtc::ArrayView<const float> input_sequence,
+    rtc::ArrayView<const float> expected_output_sequence) {
+  const int input_sequence_length = rtc::CheckedDivExact(
+      rtc::dchecked_cast<int>(input_sequence.size()), gru.input_size());
+  const int output_sequence_length = rtc::CheckedDivExact(
+      rtc::dchecked_cast<int>(expected_output_sequence.size()), gru.size());
+  ASSERT_EQ(input_sequence_length, output_sequence_length)
+      << "The test data length is invalid.";
+  // Feed the GRU layer and check the output at every step.
+  gru.Reset();
+  for (int i = 0; i < input_sequence_length; ++i) {
+    SCOPED_TRACE(i);
+    gru.ComputeOutput(
+        input_sequence.subview(i * gru.input_size(), gru.input_size()));
+    const auto expected_output =
+        expected_output_sequence.subview(i * gru.size(), gru.size());
+    ExpectNearAbsolute(expected_output, gru, 3e-6f);
+  }
+}
+
+// Gated recurrent units layer test data.
+constexpr int kGruInputSize = 5;
+constexpr int kGruOutputSize = 4;
+constexpr std::array<int8_t, 12> kGruBias = {96,   -99, -81, -114, 49,  119,
+                                             -118, 68,  -76, 91,   121, 125};
+constexpr std::array<int8_t, 60> kGruWeights = {
+    // Input 0.
+    124, 9, 1, 116,        // Update.
+    -66, -21, -118, -110,  // Reset.
+    104, 75, -23, -51,     // Output.
+    // Input 1.
+    -72, -111, 47, 93,   // Update.
+    77, -98, 41, -8,     // Reset.
+    40, -23, -43, -107,  // Output.
+    // Input 2.
+    9, -73, 30, -32,      // Update.
+    -2, 64, -26, 91,      // Reset.
+    -48, -24, -28, -104,  // Output.
+    // Input 3.
+    74, -46, 116, 15,    // Update.
+    32, 52, -126, -38,   // Reset.
+    -121, 12, -16, 110,  // Output.
+    // Input 4.
+    -95, 66, -103, -35,  // Update.
+    -38, 3, -126, -61,   // Reset.
+    28, 98, -117, -43    // Output.
+};
+constexpr std::array<int8_t, 48> kGruRecurrentWeights = {
+    // Output 0.
+    -3, 87, 50, 51,     // Update.
+    -22, 27, -39, 62,   // Reset.
+    31, -83, -52, -48,  // Output.
+    // Output 1.
+    -6, 83, -19, 104,  // Update.
+    105, 48, 23, 68,   // Reset.
+    23, 40, 7, -120,   // Output.
+    // Output 2.
+    64, -62, 117, 85,     // Update.
+    51, -43, 54, -105,    // Reset.
+    120, 56, -128, -107,  // Output.
+    // Output 3.
+    39, 50, -17, -47,   // Update.
+    -117, 14, 108, 12,  // Reset.
+    -7, -72, 103, -87,  // Output.
+};
+constexpr std::array<float, 20> kGruInputSequence = {
+    0.89395463f, 0.93224651f, 0.55788344f, 0.32341808f, 0.93355054f,
+    0.13475326f, 0.97370994f, 0.14253306f, 0.93710381f, 0.76093364f,
+    0.65780413f, 0.41657975f, 0.49403164f, 0.46843281f, 0.75138855f,
+    0.24517593f, 0.47657707f, 0.57064998f, 0.435184f,   0.19319285f};
+constexpr std::array<float, 16> kGruExpectedOutputSequence = {
+    0.0239123f,  0.5773077f,  0.f,         0.f,
+    0.01282811f, 0.64330572f, 0.f,         0.04863098f,
+    0.00781069f, 0.75267816f, 0.f,         0.02579715f,
+    0.00471378f, 0.59162533f, 0.11087593f, 0.01334511f};
+
+class RnnGruParametrization
+    : public ::testing::TestWithParam<AvailableCpuFeatures> {};
+
+// Checks that the output of a GRU layer is within tolerance given test input
+// data.
+TEST_P(RnnGruParametrization, CheckGatedRecurrentLayer) {
+  GatedRecurrentLayer gru(kGruInputSize, kGruOutputSize, kGruBias, kGruWeights,
+                          kGruRecurrentWeights,
+                          /*cpu_features=*/GetParam(),
+                          /*layer_name=*/"GRU");
+  TestGatedRecurrentLayer(gru, kGruInputSequence, kGruExpectedOutputSequence);
+}
+
+TEST_P(RnnGruParametrization, DISABLED_BenchmarkGatedRecurrentLayer) {
+  // Prefetch test data.
+  std::unique_ptr<FileReader> reader = CreateGruInputReader();
+  std::vector<float> gru_input_sequence(reader->size());
+  reader->ReadChunk(gru_input_sequence);
+
+  using ::rnnoise::kHiddenGruBias;
+  using ::rnnoise::kHiddenGruRecurrentWeights;
+  using ::rnnoise::kHiddenGruWeights;
+  using ::rnnoise::kHiddenLayerOutputSize;
+  using ::rnnoise::kInputLayerOutputSize;
+
+  GatedRecurrentLayer gru(kInputLayerOutputSize, kHiddenLayerOutputSize,
+                          kHiddenGruBias, kHiddenGruWeights,
+                          kHiddenGruRecurrentWeights,
+                          /*cpu_features=*/GetParam(),
+                          /*layer_name=*/"GRU");
+
+  rtc::ArrayView<const float> input_sequence(gru_input_sequence);
+  ASSERT_EQ(input_sequence.size() % kInputLayerOutputSize,
+            static_cast<size_t>(0));
+  const int input_sequence_length =
+      input_sequence.size() / kInputLayerOutputSize;
+
+  constexpr int kNumTests = 100;
+  ::webrtc::test::PerformanceTimer perf_timer(kNumTests);
+  for (int k = 0; k < kNumTests; ++k) {
+    perf_timer.StartTimer();
+    for (int i = 0; i < input_sequence_length; ++i) {
+      gru.ComputeOutput(
+          input_sequence.subview(i * gru.input_size(), gru.input_size()));
+    }
+    perf_timer.StopTimer();
+  }
+  RTC_LOG(LS_INFO) << (perf_timer.GetDurationAverage() / 1000) << " +/- "
+                   << (perf_timer.GetDurationStandardDeviation() / 1000)
+                   << " ms";
+}
+
+// Finds the relevant CPU features combinations to test.
+std::vector<AvailableCpuFeatures> GetCpuFeaturesToTest() {
+  std::vector<AvailableCpuFeatures> v;
+  v.push_back(NoAvailableCpuFeatures());
+  AvailableCpuFeatures available = GetAvailableCpuFeatures();
+  if (available.sse2) {
+    v.push_back({/*sse2=*/true, /*avx2=*/false, /*neon=*/false});
+  }
+  if (available.avx2) {
+    v.push_back({/*sse2=*/false, /*avx2=*/true, /*neon=*/false});
+  }
+  if (available.neon) {
+    v.push_back({/*sse2=*/false, /*avx2=*/false, /*neon=*/true});
+  }
+  return v;
+}
+
+INSTANTIATE_TEST_SUITE_P(
+    RnnVadTest,
+    RnnGruParametrization,
+    ::testing::ValuesIn(GetCpuFeaturesToTest()),
+    [](const ::testing::TestParamInfo<AvailableCpuFeatures>& info) {
+      return info.param.ToString();
+    });
+
+}  // namespace
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_unittest.cc
new file mode 100644
index 0000000..4c5409a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_unittest.cc
@@ -0,0 +1,70 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/rnn.h"
+
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/cpu_features.h"
+#include "modules/audio_processing/agc2/rnn_vad/common.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+constexpr std::array<float, kFeatureVectorSize> kFeatures = {
+    -1.00131f,   -0.627069f, -7.81097f,  7.86285f,    -2.87145f,  3.32365f,
+    -0.653161f,  0.529839f,  -0.425307f, 0.25583f,    0.235094f,  0.230527f,
+    -0.144687f,  0.182785f,  0.57102f,   0.125039f,   0.479482f,  -0.0255439f,
+    -0.0073141f, -0.147346f, -0.217106f, -0.0846906f, -8.34943f,  3.09065f,
+    1.42628f,    -0.85235f,  -0.220207f, -0.811163f,  2.09032f,   -2.01425f,
+    -0.690268f,  -0.925327f, -0.541354f, 0.58455f,    -0.606726f, -0.0372358f,
+    0.565991f,   0.435854f,  0.420812f,  0.162198f,   -2.13f,     10.0089f};
+
+void WarmUpRnnVad(RnnVad& rnn_vad) {
+  for (int i = 0; i < 10; ++i) {
+    rnn_vad.ComputeVadProbability(kFeatures, /*is_silence=*/false);
+  }
+}
+
+// Checks that the speech probability is zero with silence.
+TEST(RnnVadTest, CheckZeroProbabilityWithSilence) {
+  RnnVad rnn_vad(GetAvailableCpuFeatures());
+  WarmUpRnnVad(rnn_vad);
+  EXPECT_EQ(rnn_vad.ComputeVadProbability(kFeatures, /*is_silence=*/true), 0.f);
+}
+
+// Checks that the same output is produced after reset given the same input
+// sequence.
+TEST(RnnVadTest, CheckRnnVadReset) {
+  RnnVad rnn_vad(GetAvailableCpuFeatures());
+  WarmUpRnnVad(rnn_vad);
+  float pre = rnn_vad.ComputeVadProbability(kFeatures, /*is_silence=*/false);
+  rnn_vad.Reset();
+  WarmUpRnnVad(rnn_vad);
+  float post = rnn_vad.ComputeVadProbability(kFeatures, /*is_silence=*/false);
+  EXPECT_EQ(pre, post);
+}
+
+// Checks that the same output is produced after silence is observed given the
+// same input sequence.
+TEST(RnnVadTest, CheckRnnVadSilence) {
+  RnnVad rnn_vad(GetAvailableCpuFeatures());
+  WarmUpRnnVad(rnn_vad);
+  float pre = rnn_vad.ComputeVadProbability(kFeatures, /*is_silence=*/false);
+  rnn_vad.ComputeVadProbability(kFeatures, /*is_silence=*/true);
+  WarmUpRnnVad(rnn_vad);
+  float post = rnn_vad.ComputeVadProbability(kFeatures, /*is_silence=*/false);
+  EXPECT_EQ(pre, post);
+}
+
+}  // namespace
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_vad_tool.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_vad_tool.cc
new file mode 100644
index 0000000..a0e1242
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_vad_tool.cc
@@ -0,0 +1,123 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include <array>
+#include <string>
+#include <vector>
+
+#include "absl/flags/flag.h"
+#include "absl/flags/parse.h"
+#include "common_audio/resampler/push_sinc_resampler.h"
+#include "common_audio/wav_file.h"
+#include "modules/audio_processing/agc2/cpu_features.h"
+#include "modules/audio_processing/agc2/rnn_vad/common.h"
+#include "modules/audio_processing/agc2/rnn_vad/features_extraction.h"
+#include "modules/audio_processing/agc2/rnn_vad/rnn.h"
+#include "rtc_base/logging.h"
+#include "rtc_base/numerics/safe_compare.h"
+
+ABSL_FLAG(std::string, i, "", "Path to the input wav file");
+ABSL_FLAG(std::string, f, "", "Path to the output features file");
+ABSL_FLAG(std::string, o, "", "Path to the output VAD probabilities file");
+
+namespace webrtc {
+namespace rnn_vad {
+namespace test {
+
+int main(int argc, char* argv[]) {
+  absl::ParseCommandLine(argc, argv);
+  rtc::LogMessage::LogToDebug(rtc::LS_INFO);
+
+  // Open wav input file and check properties.
+  const std::string input_wav_file = absl::GetFlag(FLAGS_i);
+  WavReader wav_reader(input_wav_file);
+  if (wav_reader.num_channels() != 1) {
+    RTC_LOG(LS_ERROR) << "Only mono wav files are supported";
+    return 1;
+  }
+  if (wav_reader.sample_rate() % 100 != 0) {
+    RTC_LOG(LS_ERROR) << "The sample rate rate must allow 10 ms frames.";
+    return 1;
+  }
+  RTC_LOG(LS_INFO) << "Input sample rate: " << wav_reader.sample_rate();
+
+  // Init output files.
+  const std::string output_vad_probs_file = absl::GetFlag(FLAGS_o);
+  FILE* vad_probs_file = fopen(output_vad_probs_file.c_str(), "wb");
+  FILE* features_file = nullptr;
+  const std::string output_feature_file = absl::GetFlag(FLAGS_f);
+  if (!output_feature_file.empty()) {
+    features_file = fopen(output_feature_file.c_str(), "wb");
+  }
+
+  // Initialize.
+  const int frame_size_10ms =
+      rtc::CheckedDivExact(wav_reader.sample_rate(), 100);
+  std::vector<float> samples_10ms;
+  samples_10ms.resize(frame_size_10ms);
+  std::array<float, kFrameSize10ms24kHz> samples_10ms_24kHz;
+  PushSincResampler resampler(frame_size_10ms, kFrameSize10ms24kHz);
+  const AvailableCpuFeatures cpu_features = GetAvailableCpuFeatures();
+  FeaturesExtractor features_extractor(cpu_features);
+  std::array<float, kFeatureVectorSize> feature_vector;
+  RnnVad rnn_vad(cpu_features);
+
+  // Compute VAD probabilities.
+  while (true) {
+    // Read frame at the input sample rate.
+    const size_t read_samples =
+        wav_reader.ReadSamples(frame_size_10ms, samples_10ms.data());
+    if (rtc::SafeLt(read_samples, frame_size_10ms)) {
+      break;  // EOF.
+    }
+    // Resample input.
+    resampler.Resample(samples_10ms.data(), samples_10ms.size(),
+                       samples_10ms_24kHz.data(), samples_10ms_24kHz.size());
+
+    // Extract features and feed the RNN.
+    bool is_silence = features_extractor.CheckSilenceComputeFeatures(
+        samples_10ms_24kHz, feature_vector);
+    float vad_probability =
+        rnn_vad.ComputeVadProbability(feature_vector, is_silence);
+    // Write voice probability.
+    RTC_DCHECK_GE(vad_probability, 0.f);
+    RTC_DCHECK_GE(1.f, vad_probability);
+    fwrite(&vad_probability, sizeof(float), 1, vad_probs_file);
+    // Write features.
+    if (features_file) {
+      const float float_is_silence = is_silence ? 1.f : 0.f;
+      fwrite(&float_is_silence, sizeof(float), 1, features_file);
+      if (is_silence) {
+        // Do not write uninitialized values.
+        feature_vector.fill(0.f);
+      }
+      fwrite(feature_vector.data(), sizeof(float), kFeatureVectorSize,
+             features_file);
+    }
+  }
+
+  // Close output file(s).
+  fclose(vad_probs_file);
+  RTC_LOG(LS_INFO) << "VAD probabilities written to " << output_vad_probs_file;
+  if (features_file) {
+    fclose(features_file);
+    RTC_LOG(LS_INFO) << "features written to " << output_feature_file;
+  }
+
+  return 0;
+}
+
+}  // namespace test
+}  // namespace rnn_vad
+}  // namespace webrtc
+
+int main(int argc, char* argv[]) {
+  return webrtc::rnn_vad::test::main(argc, argv);
+}
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_vad_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_vad_unittest.cc
new file mode 100644
index 0000000..989b235
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/rnn_vad_unittest.cc
@@ -0,0 +1,185 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include <array>
+#include <memory>
+#include <string>
+#include <vector>
+
+#include "common_audio/resampler/push_sinc_resampler.h"
+#include "modules/audio_processing/agc2/cpu_features.h"
+#include "modules/audio_processing/agc2/rnn_vad/features_extraction.h"
+#include "modules/audio_processing/agc2/rnn_vad/rnn.h"
+#include "modules/audio_processing/agc2/rnn_vad/test_utils.h"
+#include "modules/audio_processing/test/performance_timer.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+#include "test/gtest.h"
+#include "third_party/rnnoise/src/rnn_activations.h"
+#include "third_party/rnnoise/src/rnn_vad_weights.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+constexpr int kFrameSize10ms48kHz = 480;
+
+void DumpPerfStats(int num_samples,
+                   int sample_rate,
+                   double average_us,
+                   double standard_deviation) {
+  float audio_track_length_ms =
+      1e3f * static_cast<float>(num_samples) / static_cast<float>(sample_rate);
+  float average_ms = static_cast<float>(average_us) / 1e3f;
+  float speed = audio_track_length_ms / average_ms;
+  RTC_LOG(LS_INFO) << "track duration (ms): " << audio_track_length_ms;
+  RTC_LOG(LS_INFO) << "average processing time (ms): " << average_ms << " +/- "
+                   << (standard_deviation / 1e3);
+  RTC_LOG(LS_INFO) << "speed: " << speed << "x";
+}
+
+// When the RNN VAD model is updated and the expected output changes, set the
+// constant below to true in order to write new expected output binary files.
+constexpr bool kWriteComputedOutputToFile = false;
+
+// Avoids that one forgets to set |kWriteComputedOutputToFile| back to false
+// when the expected output files are re-exported.
+TEST(RnnVadTest, CheckWriteComputedOutputIsFalse) {
+  ASSERT_FALSE(kWriteComputedOutputToFile)
+      << "Cannot land if kWriteComputedOutput is true.";
+}
+
+class RnnVadProbabilityParametrization
+    : public ::testing::TestWithParam<AvailableCpuFeatures> {};
+
+// Checks that the computed VAD probability for a test input sequence sampled at
+// 48 kHz is within tolerance.
+TEST_P(RnnVadProbabilityParametrization, RnnVadProbabilityWithinTolerance) {
+  // Init resampler, feature extractor and RNN.
+  PushSincResampler decimator(kFrameSize10ms48kHz, kFrameSize10ms24kHz);
+  const AvailableCpuFeatures cpu_features = GetParam();
+  FeaturesExtractor features_extractor(cpu_features);
+  RnnVad rnn_vad(cpu_features);
+
+  // Init input samples and expected output readers.
+  std::unique_ptr<FileReader> samples_reader = CreatePcmSamplesReader();
+  std::unique_ptr<FileReader> expected_vad_prob_reader = CreateVadProbsReader();
+
+  // Input length. The last incomplete frame is ignored.
+  const int num_frames = samples_reader->size() / kFrameSize10ms48kHz;
+
+  // Init buffers.
+  std::vector<float> samples_48k(kFrameSize10ms48kHz);
+  std::vector<float> samples_24k(kFrameSize10ms24kHz);
+  std::vector<float> feature_vector(kFeatureVectorSize);
+  std::vector<float> computed_vad_prob(num_frames);
+  std::vector<float> expected_vad_prob(num_frames);
+
+  // Read expected output.
+  ASSERT_TRUE(expected_vad_prob_reader->ReadChunk(expected_vad_prob));
+
+  // Compute VAD probabilities on the downsampled input.
+  float cumulative_error = 0.f;
+  for (int i = 0; i < num_frames; ++i) {
+    ASSERT_TRUE(samples_reader->ReadChunk(samples_48k));
+    decimator.Resample(samples_48k.data(), samples_48k.size(),
+                       samples_24k.data(), samples_24k.size());
+    bool is_silence = features_extractor.CheckSilenceComputeFeatures(
+        {samples_24k.data(), kFrameSize10ms24kHz},
+        {feature_vector.data(), kFeatureVectorSize});
+    computed_vad_prob[i] = rnn_vad.ComputeVadProbability(
+        {feature_vector.data(), kFeatureVectorSize}, is_silence);
+    EXPECT_NEAR(computed_vad_prob[i], expected_vad_prob[i], 1e-3f);
+    cumulative_error += std::abs(computed_vad_prob[i] - expected_vad_prob[i]);
+  }
+  // Check average error.
+  EXPECT_LT(cumulative_error / num_frames, 1e-4f);
+
+  if (kWriteComputedOutputToFile) {
+    FileWriter vad_prob_writer("new_vad_prob.dat");
+    vad_prob_writer.WriteChunk(computed_vad_prob);
+  }
+}
+
+// Performance test for the RNN VAD (pre-fetching and downsampling are
+// excluded). Keep disabled and only enable locally to measure performance as
+// follows:
+// - on desktop: run the this unit test adding "--logs";
+// - on android: run the this unit test adding "--logcat-output-file".
+TEST_P(RnnVadProbabilityParametrization, DISABLED_RnnVadPerformance) {
+  // PCM samples reader and buffers.
+  std::unique_ptr<FileReader> samples_reader = CreatePcmSamplesReader();
+  // The last incomplete frame is ignored.
+  const int num_frames = samples_reader->size() / kFrameSize10ms48kHz;
+  std::array<float, kFrameSize10ms48kHz> samples;
+  // Pre-fetch and decimate samples.
+  PushSincResampler decimator(kFrameSize10ms48kHz, kFrameSize10ms24kHz);
+  std::vector<float> prefetched_decimated_samples;
+  prefetched_decimated_samples.resize(num_frames * kFrameSize10ms24kHz);
+  for (int i = 0; i < num_frames; ++i) {
+    ASSERT_TRUE(samples_reader->ReadChunk(samples));
+    decimator.Resample(samples.data(), samples.size(),
+                       &prefetched_decimated_samples[i * kFrameSize10ms24kHz],
+                       kFrameSize10ms24kHz);
+  }
+  // Initialize.
+  const AvailableCpuFeatures cpu_features = GetParam();
+  FeaturesExtractor features_extractor(cpu_features);
+  std::array<float, kFeatureVectorSize> feature_vector;
+  RnnVad rnn_vad(cpu_features);
+  constexpr int number_of_tests = 100;
+  ::webrtc::test::PerformanceTimer perf_timer(number_of_tests);
+  for (int k = 0; k < number_of_tests; ++k) {
+    features_extractor.Reset();
+    rnn_vad.Reset();
+    // Process frames.
+    perf_timer.StartTimer();
+    for (int i = 0; i < num_frames; ++i) {
+      bool is_silence = features_extractor.CheckSilenceComputeFeatures(
+          {&prefetched_decimated_samples[i * kFrameSize10ms24kHz],
+           kFrameSize10ms24kHz},
+          feature_vector);
+      rnn_vad.ComputeVadProbability(feature_vector, is_silence);
+    }
+    perf_timer.StopTimer();
+  }
+  DumpPerfStats(num_frames * kFrameSize10ms24kHz, kSampleRate24kHz,
+                perf_timer.GetDurationAverage(),
+                perf_timer.GetDurationStandardDeviation());
+}
+
+// Finds the relevant CPU features combinations to test.
+std::vector<AvailableCpuFeatures> GetCpuFeaturesToTest() {
+  std::vector<AvailableCpuFeatures> v;
+  v.push_back(NoAvailableCpuFeatures());
+  AvailableCpuFeatures available = GetAvailableCpuFeatures();
+  if (available.avx2 && available.sse2) {
+    v.push_back({/*sse2=*/true, /*avx2=*/true, /*neon=*/false});
+  }
+  if (available.sse2) {
+    v.push_back({/*sse2=*/true, /*avx2=*/false, /*neon=*/false});
+  }
+  if (available.neon) {
+    v.push_back({/*sse2=*/false, /*avx2=*/false, /*neon=*/true});
+  }
+  return v;
+}
+
+INSTANTIATE_TEST_SUITE_P(
+    RnnVadTest,
+    RnnVadProbabilityParametrization,
+    ::testing::ValuesIn(GetCpuFeaturesToTest()),
+    [](const ::testing::TestParamInfo<AvailableCpuFeatures>& info) {
+      return info.param.ToString();
+    });
+
+}  // namespace
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/sequence_buffer.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/sequence_buffer.h
new file mode 100644
index 0000000..a740278
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/sequence_buffer.h
@@ -0,0 +1,79 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_SEQUENCE_BUFFER_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_SEQUENCE_BUFFER_H_
+
+#include <algorithm>
+#include <cstring>
+#include <type_traits>
+#include <vector>
+
+#include "api/array_view.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+// Linear buffer implementation to (i) push fixed size chunks of sequential data
+// and (ii) view contiguous parts of the buffer. The buffer and the pushed
+// chunks have size S and N respectively. For instance, when S = 2N the first
+// half of the sequence buffer is replaced with its second half, and the new N
+// values are written at the end of the buffer.
+// The class also provides a view on the most recent M values, where 0 < M <= S
+// and by default M = N.
+template <typename T, int S, int N, int M = N>
+class SequenceBuffer {
+  static_assert(N <= S,
+                "The new chunk size cannot be larger than the sequence buffer "
+                "size.");
+  static_assert(std::is_arithmetic<T>::value,
+                "Integral or floating point required.");
+
+ public:
+  SequenceBuffer() : buffer_(S) {
+    RTC_DCHECK_EQ(S, buffer_.size());
+    Reset();
+  }
+  SequenceBuffer(const SequenceBuffer&) = delete;
+  SequenceBuffer& operator=(const SequenceBuffer&) = delete;
+  ~SequenceBuffer() = default;
+  int size() const { return S; }
+  int chunks_size() const { return N; }
+  // Sets the sequence buffer values to zero.
+  void Reset() { std::fill(buffer_.begin(), buffer_.end(), 0); }
+  // Returns a view on the whole buffer.
+  rtc::ArrayView<const T, S> GetBufferView() const {
+    return {buffer_.data(), S};
+  }
+  // Returns a view on the M most recent values of the buffer.
+  rtc::ArrayView<const T, M> GetMostRecentValuesView() const {
+    static_assert(M <= S,
+                  "The number of most recent values cannot be larger than the "
+                  "sequence buffer size.");
+    return {buffer_.data() + S - M, M};
+  }
+  // Shifts left the buffer by N items and add new N items at the end.
+  void Push(rtc::ArrayView<const T, N> new_values) {
+    // Make space for the new values.
+    if (S > N)
+      std::memmove(buffer_.data(), buffer_.data() + N, (S - N) * sizeof(T));
+    // Copy the new values at the end of the buffer.
+    std::memcpy(buffer_.data() + S - N, new_values.data(), N * sizeof(T));
+  }
+
+ private:
+  std::vector<T> buffer_;
+};
+
+}  // namespace rnn_vad
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_SEQUENCE_BUFFER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/sequence_buffer_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/sequence_buffer_unittest.cc
new file mode 100644
index 0000000..f577571
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/sequence_buffer_unittest.cc
@@ -0,0 +1,102 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/sequence_buffer.h"
+
+#include <algorithm>
+#include <array>
+
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+template <typename T, int S, int N>
+void TestSequenceBufferPushOp() {
+  SCOPED_TRACE(S);
+  SCOPED_TRACE(N);
+  SequenceBuffer<T, S, N> seq_buf;
+  auto seq_buf_view = seq_buf.GetBufferView();
+  std::array<T, N> chunk;
+
+  // Check that a chunk is fully gone after ceil(S / N) push ops.
+  chunk.fill(1);
+  seq_buf.Push(chunk);
+  chunk.fill(0);
+  constexpr int required_push_ops = (S % N) ? S / N + 1 : S / N;
+  for (int i = 0; i < required_push_ops - 1; ++i) {
+    SCOPED_TRACE(i);
+    seq_buf.Push(chunk);
+    // Still in the buffer.
+    const auto* m = std::max_element(seq_buf_view.begin(), seq_buf_view.end());
+    EXPECT_EQ(1, *m);
+  }
+  // Gone after another push.
+  seq_buf.Push(chunk);
+  const auto* m = std::max_element(seq_buf_view.begin(), seq_buf_view.end());
+  EXPECT_EQ(0, *m);
+
+  // Check that the last item moves left by N positions after a push op.
+  if (S > N) {
+    // Fill in with non-zero values.
+    for (int i = 0; i < N; ++i)
+      chunk[i] = static_cast<T>(i + 1);
+    seq_buf.Push(chunk);
+    // With the next Push(), |last| will be moved left by N positions.
+    const T last = chunk[N - 1];
+    for (int i = 0; i < N; ++i)
+      chunk[i] = static_cast<T>(last + i + 1);
+    seq_buf.Push(chunk);
+    EXPECT_EQ(last, seq_buf_view[S - N - 1]);
+  }
+}
+
+TEST(RnnVadTest, SequenceBufferGetters) {
+  constexpr int buffer_size = 8;
+  constexpr int chunk_size = 8;
+  SequenceBuffer<int, buffer_size, chunk_size> seq_buf;
+  EXPECT_EQ(buffer_size, seq_buf.size());
+  EXPECT_EQ(chunk_size, seq_buf.chunks_size());
+  // Test view.
+  auto seq_buf_view = seq_buf.GetBufferView();
+  EXPECT_EQ(0, seq_buf_view[0]);
+  EXPECT_EQ(0, seq_buf_view[seq_buf_view.size() - 1]);
+  constexpr std::array<int, chunk_size> chunk = {10, 20, 30, 40,
+                                                 50, 60, 70, 80};
+  seq_buf.Push(chunk);
+  EXPECT_EQ(10, *seq_buf_view.begin());
+  EXPECT_EQ(80, *(seq_buf_view.end() - 1));
+}
+
+TEST(RnnVadTest, SequenceBufferPushOpsUnsigned) {
+  TestSequenceBufferPushOp<uint8_t, 32, 8>();   // Chunk size: 25%.
+  TestSequenceBufferPushOp<uint8_t, 32, 16>();  // Chunk size: 50%.
+  TestSequenceBufferPushOp<uint8_t, 32, 32>();  // Chunk size: 100%.
+  TestSequenceBufferPushOp<uint8_t, 23, 7>();   // Non-integer ratio.
+}
+
+TEST(RnnVadTest, SequenceBufferPushOpsSigned) {
+  TestSequenceBufferPushOp<int, 32, 8>();   // Chunk size: 25%.
+  TestSequenceBufferPushOp<int, 32, 16>();  // Chunk size: 50%.
+  TestSequenceBufferPushOp<int, 32, 32>();  // Chunk size: 100%.
+  TestSequenceBufferPushOp<int, 23, 7>();   // Non-integer ratio.
+}
+
+TEST(RnnVadTest, SequenceBufferPushOpsFloating) {
+  TestSequenceBufferPushOp<float, 32, 8>();   // Chunk size: 25%.
+  TestSequenceBufferPushOp<float, 32, 16>();  // Chunk size: 50%.
+  TestSequenceBufferPushOp<float, 32, 32>();  // Chunk size: 100%.
+  TestSequenceBufferPushOp<float, 23, 7>();   // Non-integer ratio.
+}
+
+}  // namespace
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features.cc
new file mode 100644
index 0000000..96086ba
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features.cc
@@ -0,0 +1,214 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/spectral_features.h"
+
+#include <algorithm>
+#include <cmath>
+#include <limits>
+#include <numeric>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_compare.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+constexpr float kSilenceThreshold = 0.04f;
+
+// Computes the new cepstral difference stats and pushes them into the passed
+// symmetric matrix buffer.
+void UpdateCepstralDifferenceStats(
+    rtc::ArrayView<const float, kNumBands> new_cepstral_coeffs,
+    const RingBuffer<float, kNumBands, kCepstralCoeffsHistorySize>& ring_buf,
+    SymmetricMatrixBuffer<float, kCepstralCoeffsHistorySize>* sym_matrix_buf) {
+  RTC_DCHECK(sym_matrix_buf);
+  // Compute the new cepstral distance stats.
+  std::array<float, kCepstralCoeffsHistorySize - 1> distances;
+  for (int i = 0; i < kCepstralCoeffsHistorySize - 1; ++i) {
+    const int delay = i + 1;
+    auto old_cepstral_coeffs = ring_buf.GetArrayView(delay);
+    distances[i] = 0.f;
+    for (int k = 0; k < kNumBands; ++k) {
+      const float c = new_cepstral_coeffs[k] - old_cepstral_coeffs[k];
+      distances[i] += c * c;
+    }
+  }
+  // Push the new spectral distance stats into the symmetric matrix buffer.
+  sym_matrix_buf->Push(distances);
+}
+
+// Computes the first half of the Vorbis window.
+std::array<float, kFrameSize20ms24kHz / 2> ComputeScaledHalfVorbisWindow(
+    float scaling = 1.f) {
+  constexpr int kHalfSize = kFrameSize20ms24kHz / 2;
+  std::array<float, kHalfSize> half_window{};
+  for (int i = 0; i < kHalfSize; ++i) {
+    half_window[i] =
+        scaling *
+        std::sin(0.5 * kPi * std::sin(0.5 * kPi * (i + 0.5) / kHalfSize) *
+                 std::sin(0.5 * kPi * (i + 0.5) / kHalfSize));
+  }
+  return half_window;
+}
+
+// Computes the forward FFT on a 20 ms frame to which a given window function is
+// applied. The Fourier coefficient corresponding to the Nyquist frequency is
+// set to zero (it is never used and this allows to simplify the code).
+void ComputeWindowedForwardFft(
+    rtc::ArrayView<const float, kFrameSize20ms24kHz> frame,
+    const std::array<float, kFrameSize20ms24kHz / 2>& half_window,
+    Pffft::FloatBuffer* fft_input_buffer,
+    Pffft::FloatBuffer* fft_output_buffer,
+    Pffft* fft) {
+  RTC_DCHECK_EQ(frame.size(), 2 * half_window.size());
+  // Apply windowing.
+  auto in = fft_input_buffer->GetView();
+  for (int i = 0, j = kFrameSize20ms24kHz - 1;
+       rtc::SafeLt(i, half_window.size()); ++i, --j) {
+    in[i] = frame[i] * half_window[i];
+    in[j] = frame[j] * half_window[i];
+  }
+  fft->ForwardTransform(*fft_input_buffer, fft_output_buffer, /*ordered=*/true);
+  // Set the Nyquist frequency coefficient to zero.
+  auto out = fft_output_buffer->GetView();
+  out[1] = 0.f;
+}
+
+}  // namespace
+
+SpectralFeaturesExtractor::SpectralFeaturesExtractor()
+    : half_window_(ComputeScaledHalfVorbisWindow(
+          1.f / static_cast<float>(kFrameSize20ms24kHz))),
+      fft_(kFrameSize20ms24kHz, Pffft::FftType::kReal),
+      fft_buffer_(fft_.CreateBuffer()),
+      reference_frame_fft_(fft_.CreateBuffer()),
+      lagged_frame_fft_(fft_.CreateBuffer()),
+      dct_table_(ComputeDctTable()) {}
+
+SpectralFeaturesExtractor::~SpectralFeaturesExtractor() = default;
+
+void SpectralFeaturesExtractor::Reset() {
+  cepstral_coeffs_ring_buf_.Reset();
+  cepstral_diffs_buf_.Reset();
+}
+
+bool SpectralFeaturesExtractor::CheckSilenceComputeFeatures(
+    rtc::ArrayView<const float, kFrameSize20ms24kHz> reference_frame,
+    rtc::ArrayView<const float, kFrameSize20ms24kHz> lagged_frame,
+    rtc::ArrayView<float, kNumBands - kNumLowerBands> higher_bands_cepstrum,
+    rtc::ArrayView<float, kNumLowerBands> average,
+    rtc::ArrayView<float, kNumLowerBands> first_derivative,
+    rtc::ArrayView<float, kNumLowerBands> second_derivative,
+    rtc::ArrayView<float, kNumLowerBands> bands_cross_corr,
+    float* variability) {
+  // Compute the Opus band energies for the reference frame.
+  ComputeWindowedForwardFft(reference_frame, half_window_, fft_buffer_.get(),
+                            reference_frame_fft_.get(), &fft_);
+  spectral_correlator_.ComputeAutoCorrelation(
+      reference_frame_fft_->GetConstView(), reference_frame_bands_energy_);
+  // Check if the reference frame has silence.
+  const float tot_energy =
+      std::accumulate(reference_frame_bands_energy_.begin(),
+                      reference_frame_bands_energy_.end(), 0.f);
+  if (tot_energy < kSilenceThreshold) {
+    return true;
+  }
+  // Compute the Opus band energies for the lagged frame.
+  ComputeWindowedForwardFft(lagged_frame, half_window_, fft_buffer_.get(),
+                            lagged_frame_fft_.get(), &fft_);
+  spectral_correlator_.ComputeAutoCorrelation(lagged_frame_fft_->GetConstView(),
+                                              lagged_frame_bands_energy_);
+  // Log of the band energies for the reference frame.
+  std::array<float, kNumBands> log_bands_energy;
+  ComputeSmoothedLogMagnitudeSpectrum(reference_frame_bands_energy_,
+                                      log_bands_energy);
+  // Reference frame cepstrum.
+  std::array<float, kNumBands> cepstrum;
+  ComputeDct(log_bands_energy, dct_table_, cepstrum);
+  // Ad-hoc correction terms for the first two cepstral coefficients.
+  cepstrum[0] -= 12.f;
+  cepstrum[1] -= 4.f;
+  // Update the ring buffer and the cepstral difference stats.
+  cepstral_coeffs_ring_buf_.Push(cepstrum);
+  UpdateCepstralDifferenceStats(cepstrum, cepstral_coeffs_ring_buf_,
+                                &cepstral_diffs_buf_);
+  // Write the higher bands cepstral coefficients.
+  RTC_DCHECK_EQ(cepstrum.size() - kNumLowerBands, higher_bands_cepstrum.size());
+  std::copy(cepstrum.begin() + kNumLowerBands, cepstrum.end(),
+            higher_bands_cepstrum.begin());
+  // Compute and write remaining features.
+  ComputeAvgAndDerivatives(average, first_derivative, second_derivative);
+  ComputeNormalizedCepstralCorrelation(bands_cross_corr);
+  RTC_DCHECK(variability);
+  *variability = ComputeVariability();
+  return false;
+}
+
+void SpectralFeaturesExtractor::ComputeAvgAndDerivatives(
+    rtc::ArrayView<float, kNumLowerBands> average,
+    rtc::ArrayView<float, kNumLowerBands> first_derivative,
+    rtc::ArrayView<float, kNumLowerBands> second_derivative) const {
+  auto curr = cepstral_coeffs_ring_buf_.GetArrayView(0);
+  auto prev1 = cepstral_coeffs_ring_buf_.GetArrayView(1);
+  auto prev2 = cepstral_coeffs_ring_buf_.GetArrayView(2);
+  RTC_DCHECK_EQ(average.size(), first_derivative.size());
+  RTC_DCHECK_EQ(first_derivative.size(), second_derivative.size());
+  RTC_DCHECK_LE(average.size(), curr.size());
+  for (int i = 0; rtc::SafeLt(i, average.size()); ++i) {
+    // Average, kernel: [1, 1, 1].
+    average[i] = curr[i] + prev1[i] + prev2[i];
+    // First derivative, kernel: [1, 0, - 1].
+    first_derivative[i] = curr[i] - prev2[i];
+    // Second derivative, Laplacian kernel: [1, -2, 1].
+    second_derivative[i] = curr[i] - 2 * prev1[i] + prev2[i];
+  }
+}
+
+void SpectralFeaturesExtractor::ComputeNormalizedCepstralCorrelation(
+    rtc::ArrayView<float, kNumLowerBands> bands_cross_corr) {
+  spectral_correlator_.ComputeCrossCorrelation(
+      reference_frame_fft_->GetConstView(), lagged_frame_fft_->GetConstView(),
+      bands_cross_corr_);
+  // Normalize.
+  for (int i = 0; rtc::SafeLt(i, bands_cross_corr_.size()); ++i) {
+    bands_cross_corr_[i] =
+        bands_cross_corr_[i] /
+        std::sqrt(0.001f + reference_frame_bands_energy_[i] *
+                               lagged_frame_bands_energy_[i]);
+  }
+  // Cepstrum.
+  ComputeDct(bands_cross_corr_, dct_table_, bands_cross_corr);
+  // Ad-hoc correction terms for the first two cepstral coefficients.
+  bands_cross_corr[0] -= 1.3f;
+  bands_cross_corr[1] -= 0.9f;
+}
+
+float SpectralFeaturesExtractor::ComputeVariability() const {
+  // Compute cepstral variability score.
+  float variability = 0.f;
+  for (int delay1 = 0; delay1 < kCepstralCoeffsHistorySize; ++delay1) {
+    float min_dist = std::numeric_limits<float>::max();
+    for (int delay2 = 0; delay2 < kCepstralCoeffsHistorySize; ++delay2) {
+      if (delay1 == delay2)  // The distance would be 0.
+        continue;
+      min_dist =
+          std::min(min_dist, cepstral_diffs_buf_.GetValue(delay1, delay2));
+    }
+    variability += min_dist;
+  }
+  // Normalize (based on training set stats).
+  // TODO(bugs.webrtc.org/10480): Isolate normalization from feature extraction.
+  return variability / kCepstralCoeffsHistorySize - 2.1f;
+}
+
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features.h
new file mode 100644
index 0000000..d327ef8
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features.h
@@ -0,0 +1,79 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_SPECTRAL_FEATURES_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_SPECTRAL_FEATURES_H_
+
+#include <array>
+#include <cstddef>
+#include <memory>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/rnn_vad/common.h"
+#include "modules/audio_processing/agc2/rnn_vad/ring_buffer.h"
+#include "modules/audio_processing/agc2/rnn_vad/spectral_features_internal.h"
+#include "modules/audio_processing/agc2/rnn_vad/symmetric_matrix_buffer.h"
+#include "modules/audio_processing/utility/pffft_wrapper.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+// Class to compute spectral features.
+class SpectralFeaturesExtractor {
+ public:
+  SpectralFeaturesExtractor();
+  SpectralFeaturesExtractor(const SpectralFeaturesExtractor&) = delete;
+  SpectralFeaturesExtractor& operator=(const SpectralFeaturesExtractor&) =
+      delete;
+  ~SpectralFeaturesExtractor();
+  // Resets the internal state of the feature extractor.
+  void Reset();
+  // Analyzes a pair of reference and lagged frames from the pitch buffer,
+  // detects silence and computes features. If silence is detected, the output
+  // is neither computed nor written.
+  bool CheckSilenceComputeFeatures(
+      rtc::ArrayView<const float, kFrameSize20ms24kHz> reference_frame,
+      rtc::ArrayView<const float, kFrameSize20ms24kHz> lagged_frame,
+      rtc::ArrayView<float, kNumBands - kNumLowerBands> higher_bands_cepstrum,
+      rtc::ArrayView<float, kNumLowerBands> average,
+      rtc::ArrayView<float, kNumLowerBands> first_derivative,
+      rtc::ArrayView<float, kNumLowerBands> second_derivative,
+      rtc::ArrayView<float, kNumLowerBands> bands_cross_corr,
+      float* variability);
+
+ private:
+  void ComputeAvgAndDerivatives(
+      rtc::ArrayView<float, kNumLowerBands> average,
+      rtc::ArrayView<float, kNumLowerBands> first_derivative,
+      rtc::ArrayView<float, kNumLowerBands> second_derivative) const;
+  void ComputeNormalizedCepstralCorrelation(
+      rtc::ArrayView<float, kNumLowerBands> bands_cross_corr);
+  float ComputeVariability() const;
+
+  const std::array<float, kFrameSize20ms24kHz / 2> half_window_;
+  Pffft fft_;
+  std::unique_ptr<Pffft::FloatBuffer> fft_buffer_;
+  std::unique_ptr<Pffft::FloatBuffer> reference_frame_fft_;
+  std::unique_ptr<Pffft::FloatBuffer> lagged_frame_fft_;
+  SpectralCorrelator spectral_correlator_;
+  std::array<float, kOpusBands24kHz> reference_frame_bands_energy_;
+  std::array<float, kOpusBands24kHz> lagged_frame_bands_energy_;
+  std::array<float, kOpusBands24kHz> bands_cross_corr_;
+  const std::array<float, kNumBands * kNumBands> dct_table_;
+  RingBuffer<float, kNumBands, kCepstralCoeffsHistorySize>
+      cepstral_coeffs_ring_buf_;
+  SymmetricMatrixBuffer<float, kCepstralCoeffsHistorySize> cepstral_diffs_buf_;
+};
+
+}  // namespace rnn_vad
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_SPECTRAL_FEATURES_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features_internal.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features_internal.cc
new file mode 100644
index 0000000..91c0086
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features_internal.cc
@@ -0,0 +1,188 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/spectral_features_internal.h"
+
+#include <algorithm>
+#include <cmath>
+#include <cstddef>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_compare.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+// Weights for each FFT coefficient for each Opus band (Nyquist frequency
+// excluded). The size of each band is specified in
+// |kOpusScaleNumBins24kHz20ms|.
+constexpr std::array<float, kFrameSize20ms24kHz / 2> kOpusBandWeights24kHz20ms =
+    {{
+        0.f,       0.25f,      0.5f,       0.75f,  // Band 0
+        0.f,       0.25f,      0.5f,       0.75f,  // Band 1
+        0.f,       0.25f,      0.5f,       0.75f,  // Band 2
+        0.f,       0.25f,      0.5f,       0.75f,  // Band 3
+        0.f,       0.25f,      0.5f,       0.75f,  // Band 4
+        0.f,       0.25f,      0.5f,       0.75f,  // Band 5
+        0.f,       0.25f,      0.5f,       0.75f,  // Band 6
+        0.f,       0.25f,      0.5f,       0.75f,  // Band 7
+        0.f,       0.125f,     0.25f,      0.375f,    0.5f,
+        0.625f,    0.75f,      0.875f,  // Band 8
+        0.f,       0.125f,     0.25f,      0.375f,    0.5f,
+        0.625f,    0.75f,      0.875f,  // Band 9
+        0.f,       0.125f,     0.25f,      0.375f,    0.5f,
+        0.625f,    0.75f,      0.875f,  // Band 10
+        0.f,       0.125f,     0.25f,      0.375f,    0.5f,
+        0.625f,    0.75f,      0.875f,  // Band 11
+        0.f,       0.0625f,    0.125f,     0.1875f,   0.25f,
+        0.3125f,   0.375f,     0.4375f,    0.5f,      0.5625f,
+        0.625f,    0.6875f,    0.75f,      0.8125f,   0.875f,
+        0.9375f,  // Band 12
+        0.f,       0.0625f,    0.125f,     0.1875f,   0.25f,
+        0.3125f,   0.375f,     0.4375f,    0.5f,      0.5625f,
+        0.625f,    0.6875f,    0.75f,      0.8125f,   0.875f,
+        0.9375f,  // Band 13
+        0.f,       0.0625f,    0.125f,     0.1875f,   0.25f,
+        0.3125f,   0.375f,     0.4375f,    0.5f,      0.5625f,
+        0.625f,    0.6875f,    0.75f,      0.8125f,   0.875f,
+        0.9375f,  // Band 14
+        0.f,       0.0416667f, 0.0833333f, 0.125f,    0.166667f,
+        0.208333f, 0.25f,      0.291667f,  0.333333f, 0.375f,
+        0.416667f, 0.458333f,  0.5f,       0.541667f, 0.583333f,
+        0.625f,    0.666667f,  0.708333f,  0.75f,     0.791667f,
+        0.833333f, 0.875f,     0.916667f,  0.958333f,  // Band 15
+        0.f,       0.0416667f, 0.0833333f, 0.125f,    0.166667f,
+        0.208333f, 0.25f,      0.291667f,  0.333333f, 0.375f,
+        0.416667f, 0.458333f,  0.5f,       0.541667f, 0.583333f,
+        0.625f,    0.666667f,  0.708333f,  0.75f,     0.791667f,
+        0.833333f, 0.875f,     0.916667f,  0.958333f,  // Band 16
+        0.f,       0.03125f,   0.0625f,    0.09375f,  0.125f,
+        0.15625f,  0.1875f,    0.21875f,   0.25f,     0.28125f,
+        0.3125f,   0.34375f,   0.375f,     0.40625f,  0.4375f,
+        0.46875f,  0.5f,       0.53125f,   0.5625f,   0.59375f,
+        0.625f,    0.65625f,   0.6875f,    0.71875f,  0.75f,
+        0.78125f,  0.8125f,    0.84375f,   0.875f,    0.90625f,
+        0.9375f,   0.96875f,  // Band 17
+        0.f,       0.0208333f, 0.0416667f, 0.0625f,   0.0833333f,
+        0.104167f, 0.125f,     0.145833f,  0.166667f, 0.1875f,
+        0.208333f, 0.229167f,  0.25f,      0.270833f, 0.291667f,
+        0.3125f,   0.333333f,  0.354167f,  0.375f,    0.395833f,
+        0.416667f, 0.4375f,    0.458333f,  0.479167f, 0.5f,
+        0.520833f, 0.541667f,  0.5625f,    0.583333f, 0.604167f,
+        0.625f,    0.645833f,  0.666667f,  0.6875f,   0.708333f,
+        0.729167f, 0.75f,      0.770833f,  0.791667f, 0.8125f,
+        0.833333f, 0.854167f,  0.875f,     0.895833f, 0.916667f,
+        0.9375f,   0.958333f,  0.979167f  // Band 18
+    }};
+
+}  // namespace
+
+SpectralCorrelator::SpectralCorrelator()
+    : weights_(kOpusBandWeights24kHz20ms.begin(),
+               kOpusBandWeights24kHz20ms.end()) {}
+
+SpectralCorrelator::~SpectralCorrelator() = default;
+
+void SpectralCorrelator::ComputeAutoCorrelation(
+    rtc::ArrayView<const float> x,
+    rtc::ArrayView<float, kOpusBands24kHz> auto_corr) const {
+  ComputeCrossCorrelation(x, x, auto_corr);
+}
+
+void SpectralCorrelator::ComputeCrossCorrelation(
+    rtc::ArrayView<const float> x,
+    rtc::ArrayView<const float> y,
+    rtc::ArrayView<float, kOpusBands24kHz> cross_corr) const {
+  RTC_DCHECK_EQ(x.size(), kFrameSize20ms24kHz);
+  RTC_DCHECK_EQ(x.size(), y.size());
+  RTC_DCHECK_EQ(x[1], 0.f) << "The Nyquist coefficient must be zeroed.";
+  RTC_DCHECK_EQ(y[1], 0.f) << "The Nyquist coefficient must be zeroed.";
+  constexpr auto kOpusScaleNumBins24kHz20ms = GetOpusScaleNumBins24kHz20ms();
+  int k = 0;  // Next Fourier coefficient index.
+  cross_corr[0] = 0.f;
+  for (int i = 0; i < kOpusBands24kHz - 1; ++i) {
+    cross_corr[i + 1] = 0.f;
+    for (int j = 0; j < kOpusScaleNumBins24kHz20ms[i]; ++j) {  // Band size.
+      const float v = x[2 * k] * y[2 * k] + x[2 * k + 1] * y[2 * k + 1];
+      const float tmp = weights_[k] * v;
+      cross_corr[i] += v - tmp;
+      cross_corr[i + 1] += tmp;
+      k++;
+    }
+  }
+  cross_corr[0] *= 2.f;  // The first band only gets half contribution.
+  RTC_DCHECK_EQ(k, kFrameSize20ms24kHz / 2);  // Nyquist coefficient never used.
+}
+
+void ComputeSmoothedLogMagnitudeSpectrum(
+    rtc::ArrayView<const float> bands_energy,
+    rtc::ArrayView<float, kNumBands> log_bands_energy) {
+  RTC_DCHECK_LE(bands_energy.size(), kNumBands);
+  constexpr float kOneByHundred = 1e-2f;
+  constexpr float kLogOneByHundred = -2.f;
+  // Init.
+  float log_max = kLogOneByHundred;
+  float follow = kLogOneByHundred;
+  const auto smooth = [&log_max, &follow](float x) {
+    x = std::max(log_max - 7.f, std::max(follow - 1.5f, x));
+    log_max = std::max(log_max, x);
+    follow = std::max(follow - 1.5f, x);
+    return x;
+  };
+  // Smoothing over the bands for which the band energy is defined.
+  for (int i = 0; rtc::SafeLt(i, bands_energy.size()); ++i) {
+    log_bands_energy[i] = smooth(std::log10(kOneByHundred + bands_energy[i]));
+  }
+  // Smoothing over the remaining bands (zero energy).
+  for (int i = bands_energy.size(); i < kNumBands; ++i) {
+    log_bands_energy[i] = smooth(kLogOneByHundred);
+  }
+}
+
+std::array<float, kNumBands * kNumBands> ComputeDctTable() {
+  std::array<float, kNumBands * kNumBands> dct_table;
+  const double k = std::sqrt(0.5);
+  for (int i = 0; i < kNumBands; ++i) {
+    for (int j = 0; j < kNumBands; ++j)
+      dct_table[i * kNumBands + j] = std::cos((i + 0.5) * j * kPi / kNumBands);
+    dct_table[i * kNumBands] *= k;
+  }
+  return dct_table;
+}
+
+void ComputeDct(rtc::ArrayView<const float> in,
+                rtc::ArrayView<const float, kNumBands * kNumBands> dct_table,
+                rtc::ArrayView<float> out) {
+  // DCT scaling factor - i.e., sqrt(2 / kNumBands).
+  constexpr float kDctScalingFactor = 0.301511345f;
+  constexpr float kDctScalingFactorError =
+      kDctScalingFactor * kDctScalingFactor -
+      2.f / static_cast<float>(kNumBands);
+  static_assert(
+      (kDctScalingFactorError >= 0.f && kDctScalingFactorError < 1e-1f) ||
+          (kDctScalingFactorError < 0.f && kDctScalingFactorError > -1e-1f),
+      "kNumBands changed and kDctScalingFactor has not been updated.");
+  RTC_DCHECK_NE(in.data(), out.data()) << "In-place DCT is not supported.";
+  RTC_DCHECK_LE(in.size(), kNumBands);
+  RTC_DCHECK_LE(1, out.size());
+  RTC_DCHECK_LE(out.size(), in.size());
+  for (int i = 0; rtc::SafeLt(i, out.size()); ++i) {
+    out[i] = 0.f;
+    for (int j = 0; rtc::SafeLt(j, in.size()); ++j) {
+      out[i] += in[j] * dct_table[j * kNumBands + i];
+    }
+    // TODO(bugs.webrtc.org/10480): Scaling factor in the DCT table.
+    out[i] *= kDctScalingFactor;
+  }
+}
+
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features_internal.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features_internal.h
new file mode 100644
index 0000000..aa7b1c6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features_internal.h
@@ -0,0 +1,100 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_SPECTRAL_FEATURES_INTERNAL_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_SPECTRAL_FEATURES_INTERNAL_H_
+
+#include <stddef.h>
+
+#include <array>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/rnn_vad/common.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+// At a sample rate of 24 kHz, the last 3 Opus bands are beyond the Nyquist
+// frequency. However, band #19 gets the contributions from band #18 because
+// of the symmetric triangular filter with peak response at 12 kHz.
+constexpr int kOpusBands24kHz = 20;
+static_assert(kOpusBands24kHz < kNumBands,
+              "The number of bands at 24 kHz must be less than those defined "
+              "in the Opus scale at 48 kHz.");
+
+// Number of FFT frequency bins covered by each band in the Opus scale at a
+// sample rate of 24 kHz for 20 ms frames.
+// Declared here for unit testing.
+constexpr std::array<int, kOpusBands24kHz - 1> GetOpusScaleNumBins24kHz20ms() {
+  return {4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 16, 16, 16, 24, 24, 32, 48};
+}
+
+// TODO(bugs.webrtc.org/10480): Move to a separate file.
+// Class to compute band-wise spectral features in the Opus perceptual scale
+// for 20 ms frames sampled at 24 kHz. The analysis methods apply triangular
+// filters with peak response at the each band boundary.
+class SpectralCorrelator {
+ public:
+  // Ctor.
+  SpectralCorrelator();
+  SpectralCorrelator(const SpectralCorrelator&) = delete;
+  SpectralCorrelator& operator=(const SpectralCorrelator&) = delete;
+  ~SpectralCorrelator();
+
+  // Computes the band-wise spectral auto-correlations.
+  // |x| must:
+  //  - have size equal to |kFrameSize20ms24kHz|;
+  //  - be encoded as vectors of interleaved real-complex FFT coefficients
+  //    where x[1] = y[1] = 0 (the Nyquist frequency coefficient is omitted).
+  void ComputeAutoCorrelation(
+      rtc::ArrayView<const float> x,
+      rtc::ArrayView<float, kOpusBands24kHz> auto_corr) const;
+
+  // Computes the band-wise spectral cross-correlations.
+  // |x| and |y| must:
+  //  - have size equal to |kFrameSize20ms24kHz|;
+  //  - be encoded as vectors of interleaved real-complex FFT coefficients where
+  //    x[1] = y[1] = 0 (the Nyquist frequency coefficient is omitted).
+  void ComputeCrossCorrelation(
+      rtc::ArrayView<const float> x,
+      rtc::ArrayView<const float> y,
+      rtc::ArrayView<float, kOpusBands24kHz> cross_corr) const;
+
+ private:
+  const std::vector<float> weights_;  // Weights for each Fourier coefficient.
+};
+
+// TODO(bugs.webrtc.org/10480): Move to anonymous namespace in
+// spectral_features.cc. Given a vector of Opus-bands energy coefficients,
+// computes the log magnitude spectrum applying smoothing both over time and
+// over frequency. Declared here for unit testing.
+void ComputeSmoothedLogMagnitudeSpectrum(
+    rtc::ArrayView<const float> bands_energy,
+    rtc::ArrayView<float, kNumBands> log_bands_energy);
+
+// TODO(bugs.webrtc.org/10480): Move to anonymous namespace in
+// spectral_features.cc. Creates a DCT table for arrays having size equal to
+// |kNumBands|. Declared here for unit testing.
+std::array<float, kNumBands * kNumBands> ComputeDctTable();
+
+// TODO(bugs.webrtc.org/10480): Move to anonymous namespace in
+// spectral_features.cc. Computes DCT for |in| given a pre-computed DCT table.
+// In-place computation is not allowed and |out| can be smaller than |in| in
+// order to only compute the first DCT coefficients. Declared here for unit
+// testing.
+void ComputeDct(rtc::ArrayView<const float> in,
+                rtc::ArrayView<const float, kNumBands * kNumBands> dct_table,
+                rtc::ArrayView<float> out);
+
+}  // namespace rnn_vad
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_SPECTRAL_FEATURES_INTERNAL_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features_internal_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features_internal_unittest.cc
new file mode 100644
index 0000000..11a44a5
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features_internal_unittest.cc
@@ -0,0 +1,160 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/spectral_features_internal.h"
+
+#include <algorithm>
+#include <array>
+#include <complex>
+#include <numeric>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/rnn_vad/test_utils.h"
+#include "modules/audio_processing/utility/pffft_wrapper.h"
+#include "rtc_base/numerics/safe_compare.h"
+// TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+// #include "test/fpe_observer.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+// Generates the values for the array named |kOpusBandWeights24kHz20ms| in the
+// anonymous namespace of the .cc file, which is the array of FFT coefficient
+// weights for the Opus scale triangular filters.
+std::vector<float> ComputeTriangularFiltersWeights() {
+  constexpr auto kOpusScaleNumBins24kHz20ms = GetOpusScaleNumBins24kHz20ms();
+  const auto& v = kOpusScaleNumBins24kHz20ms;  // Alias.
+  const int num_weights = std::accumulate(kOpusScaleNumBins24kHz20ms.begin(),
+                                          kOpusScaleNumBins24kHz20ms.end(), 0);
+  std::vector<float> weights(num_weights);
+  int next_fft_coeff_index = 0;
+  for (int band = 0; rtc::SafeLt(band, v.size()); ++band) {
+    const int band_size = v[band];
+    for (int j = 0; rtc::SafeLt(j, band_size); ++j) {
+      weights[next_fft_coeff_index + j] = static_cast<float>(j) / band_size;
+    }
+    next_fft_coeff_index += band_size;
+  }
+  return weights;
+}
+
+// Checks that the values returned by GetOpusScaleNumBins24kHz20ms() match the
+// Opus scale frequency boundaries.
+TEST(RnnVadTest, TestOpusScaleBoundaries) {
+  constexpr int kBandFrequencyBoundariesHz[kNumBands - 1] = {
+      200,  400,  600,  800,  1000, 1200, 1400, 1600,  2000,  2400, 2800,
+      3200, 4000, 4800, 5600, 6800, 8000, 9600, 12000, 15600, 20000};
+  constexpr auto kOpusScaleNumBins24kHz20ms = GetOpusScaleNumBins24kHz20ms();
+  int prev = 0;
+  for (int i = 0; rtc::SafeLt(i, kOpusScaleNumBins24kHz20ms.size()); ++i) {
+    int boundary =
+        kBandFrequencyBoundariesHz[i] * kFrameSize20ms24kHz / kSampleRate24kHz;
+    EXPECT_EQ(kOpusScaleNumBins24kHz20ms[i], boundary - prev);
+    prev = boundary;
+  }
+}
+
+// Checks that the computed triangular filters weights for the Opus scale are
+// monotonic withing each Opus band. This test should only be enabled when
+// ComputeTriangularFiltersWeights() is changed and |kOpusBandWeights24kHz20ms|
+// is updated accordingly.
+TEST(RnnVadTest, DISABLED_TestOpusScaleWeights) {
+  auto weights = ComputeTriangularFiltersWeights();
+  int i = 0;
+  for (int band_size : GetOpusScaleNumBins24kHz20ms()) {
+    SCOPED_TRACE(band_size);
+    rtc::ArrayView<float> band_weights(weights.data() + i, band_size);
+    float prev = -1.f;
+    for (float weight : band_weights) {
+      EXPECT_LT(prev, weight);
+      prev = weight;
+    }
+    i += band_size;
+  }
+}
+
+// Checks that the computed band-wise auto-correlation is non-negative for a
+// simple input vector of FFT coefficients.
+TEST(RnnVadTest, SpectralCorrelatorValidOutput) {
+  // Input: vector of (1, 1j) values.
+  Pffft fft(kFrameSize20ms24kHz, Pffft::FftType::kReal);
+  auto in = fft.CreateBuffer();
+  std::array<float, kOpusBands24kHz> out;
+  auto in_view = in->GetView();
+  std::fill(in_view.begin(), in_view.end(), 1.f);
+  in_view[1] = 0.f;  // Nyquist frequency.
+  // Compute and check output.
+  SpectralCorrelator e;
+  e.ComputeAutoCorrelation(in_view, out);
+  for (int i = 0; i < kOpusBands24kHz; ++i) {
+    SCOPED_TRACE(i);
+    EXPECT_GT(out[i], 0.f);
+  }
+}
+
+// Checks that the computed smoothed log magnitude spectrum is within tolerance
+// given hard-coded test input data.
+TEST(RnnVadTest, ComputeSmoothedLogMagnitudeSpectrumWithinTolerance) {
+  constexpr std::array<float, kNumBands> input = {
+      {86.060539245605f, 275.668334960938f, 43.406528472900f, 6.541896820068f,
+       17.964015960693f, 8.090919494629f,   1.261920094490f,  1.212702631950f,
+       1.619154453278f,  0.508935272694f,   0.346316039562f,  0.237035423517f,
+       0.172424271703f,  0.271657168865f,   0.126088857651f,  0.139967113733f,
+       0.207200810313f,  0.155893072486f,   0.091090843081f,  0.033391401172f,
+       0.013879744336f,  0.011973354965f}};
+  constexpr std::array<float, kNumBands> expected_output = {
+      {1.934854507446f,  2.440402746201f,  1.637655138969f,  0.816367030144f,
+       1.254645109177f,  0.908534288406f,  0.104459829628f,  0.087320849299f,
+       0.211962252855f,  -0.284886807203f, -0.448164641857f, -0.607240796089f,
+       -0.738917350769f, -0.550279200077f, -0.866177439690f, -0.824003994465f,
+       -0.663138568401f, -0.780171751976f, -0.995288193226f, -1.362596273422f,
+       -1.621970295906f, -1.658103585243f}};
+  std::array<float, kNumBands> computed_output;
+  {
+    // TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+    // FloatingPointExceptionObserver fpe_observer;
+    ComputeSmoothedLogMagnitudeSpectrum(input, computed_output);
+    ExpectNearAbsolute(expected_output, computed_output, 1e-5f);
+  }
+}
+
+// Checks that the computed DCT is within tolerance given hard-coded test input
+// data.
+TEST(RnnVadTest, ComputeDctWithinTolerance) {
+  constexpr std::array<float, kNumBands> input = {
+      {0.232155621052f,  0.678957760334f, 0.220818966627f,  -0.077363930643f,
+       -0.559227049351f, 0.432545185089f, 0.353900641203f,  0.398993015289f,
+       0.409774333239f,  0.454977899790f, 0.300520688295f,  -0.010286616161f,
+       0.272525429726f,  0.098067551851f, 0.083649002016f,  0.046226885170f,
+       -0.033228103071f, 0.144773483276f, -0.117661058903f, -0.005628800020f,
+       -0.009547689930f, -0.045382082462f}};
+  constexpr std::array<float, kNumBands> expected_output = {
+      {0.697072803974f,  0.442710995674f,  -0.293156713247f, -0.060711503029f,
+       0.292050391436f,  0.489301353693f,  0.402255415916f,  0.134404733777f,
+       -0.086305990815f, -0.199605688453f, -0.234511867166f, -0.413774639368f,
+       -0.388507157564f, -0.032798115164f, 0.044605545700f,  0.112466648221f,
+       -0.050096966326f, 0.045971218497f,  -0.029815061018f, -0.410366982222f,
+       -0.209233760834f, -0.128037497401f}};
+  auto dct_table = ComputeDctTable();
+  std::array<float, kNumBands> computed_output;
+  {
+    // TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+    // FloatingPointExceptionObserver fpe_observer;
+    ComputeDct(input, dct_table, computed_output);
+    ExpectNearAbsolute(expected_output, computed_output, 1e-5f);
+  }
+}
+
+}  // namespace
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features_unittest.cc
new file mode 100644
index 0000000..9f41e96
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/spectral_features_unittest.cc
@@ -0,0 +1,161 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/spectral_features.h"
+
+#include <algorithm>
+
+#include "modules/audio_processing/agc2/rnn_vad/test_utils.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_compare.h"
+// TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+// #include "test/fpe_observer.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+constexpr int kTestFeatureVectorSize = kNumBands + 3 * kNumLowerBands + 1;
+
+// Writes non-zero sample values.
+void WriteTestData(rtc::ArrayView<float> samples) {
+  for (int i = 0; rtc::SafeLt(i, samples.size()); ++i) {
+    samples[i] = i % 100;
+  }
+}
+
+rtc::ArrayView<float, kNumBands - kNumLowerBands> GetHigherBandsSpectrum(
+    std::array<float, kTestFeatureVectorSize>* feature_vector) {
+  return {feature_vector->data() + kNumLowerBands, kNumBands - kNumLowerBands};
+}
+
+rtc::ArrayView<float, kNumLowerBands> GetAverage(
+    std::array<float, kTestFeatureVectorSize>* feature_vector) {
+  return {feature_vector->data(), kNumLowerBands};
+}
+
+rtc::ArrayView<float, kNumLowerBands> GetFirstDerivative(
+    std::array<float, kTestFeatureVectorSize>* feature_vector) {
+  return {feature_vector->data() + kNumBands, kNumLowerBands};
+}
+
+rtc::ArrayView<float, kNumLowerBands> GetSecondDerivative(
+    std::array<float, kTestFeatureVectorSize>* feature_vector) {
+  return {feature_vector->data() + kNumBands + kNumLowerBands, kNumLowerBands};
+}
+
+rtc::ArrayView<float, kNumLowerBands> GetCepstralCrossCorrelation(
+    std::array<float, kTestFeatureVectorSize>* feature_vector) {
+  return {feature_vector->data() + kNumBands + 2 * kNumLowerBands,
+          kNumLowerBands};
+}
+
+float* GetCepstralVariability(
+    std::array<float, kTestFeatureVectorSize>* feature_vector) {
+  return feature_vector->data() + kNumBands + 3 * kNumLowerBands;
+}
+
+constexpr float kInitialFeatureVal = -9999.f;
+
+// Checks that silence is detected when the input signal is 0 and that the
+// feature vector is written only if the input signal is not tagged as silence.
+TEST(RnnVadTest, SpectralFeaturesWithAndWithoutSilence) {
+  // Initialize.
+  SpectralFeaturesExtractor sfe;
+  std::array<float, kFrameSize20ms24kHz> samples;
+  rtc::ArrayView<float, kFrameSize20ms24kHz> samples_view(samples);
+  bool is_silence;
+  std::array<float, kTestFeatureVectorSize> feature_vector;
+
+  // Write an initial value in the feature vector to detect changes.
+  std::fill(feature_vector.begin(), feature_vector.end(), kInitialFeatureVal);
+
+  // TODO(bugs.webrtc.org/8948): Add when the issue is fixed.
+  // FloatingPointExceptionObserver fpe_observer;
+
+  // With silence.
+  std::fill(samples.begin(), samples.end(), 0.f);
+  is_silence = sfe.CheckSilenceComputeFeatures(
+      samples_view, samples_view, GetHigherBandsSpectrum(&feature_vector),
+      GetAverage(&feature_vector), GetFirstDerivative(&feature_vector),
+      GetSecondDerivative(&feature_vector),
+      GetCepstralCrossCorrelation(&feature_vector),
+      GetCepstralVariability(&feature_vector));
+  // Silence is expected, the output won't be overwritten.
+  EXPECT_TRUE(is_silence);
+  EXPECT_TRUE(std::all_of(feature_vector.begin(), feature_vector.end(),
+                          [](float x) { return x == kInitialFeatureVal; }));
+
+  // With no silence.
+  WriteTestData(samples);
+  is_silence = sfe.CheckSilenceComputeFeatures(
+      samples_view, samples_view, GetHigherBandsSpectrum(&feature_vector),
+      GetAverage(&feature_vector), GetFirstDerivative(&feature_vector),
+      GetSecondDerivative(&feature_vector),
+      GetCepstralCrossCorrelation(&feature_vector),
+      GetCepstralVariability(&feature_vector));
+  // Silence is not expected, the output will be overwritten.
+  EXPECT_FALSE(is_silence);
+  EXPECT_FALSE(std::all_of(feature_vector.begin(), feature_vector.end(),
+                           [](float x) { return x == kInitialFeatureVal; }));
+}
+
+// Feeds a constant input signal and checks that:
+// - the cepstral coefficients average does not change;
+// - the derivatives are zero;
+// - the cepstral variability score does not change.
+TEST(RnnVadTest, CepstralFeaturesConstantAverageZeroDerivative) {
+  // Initialize.
+  SpectralFeaturesExtractor sfe;
+  std::array<float, kFrameSize20ms24kHz> samples;
+  rtc::ArrayView<float, kFrameSize20ms24kHz> samples_view(samples);
+  WriteTestData(samples);
+  bool is_silence;
+
+  // Fill the spectral features with test data.
+  std::array<float, kTestFeatureVectorSize> feature_vector;
+  for (int i = 0; i < kCepstralCoeffsHistorySize; ++i) {
+    is_silence = sfe.CheckSilenceComputeFeatures(
+        samples_view, samples_view, GetHigherBandsSpectrum(&feature_vector),
+        GetAverage(&feature_vector), GetFirstDerivative(&feature_vector),
+        GetSecondDerivative(&feature_vector),
+        GetCepstralCrossCorrelation(&feature_vector),
+        GetCepstralVariability(&feature_vector));
+  }
+
+  // Feed the test data one last time but using a different output vector.
+  std::array<float, kTestFeatureVectorSize> feature_vector_last;
+  is_silence = sfe.CheckSilenceComputeFeatures(
+      samples_view, samples_view, GetHigherBandsSpectrum(&feature_vector_last),
+      GetAverage(&feature_vector_last),
+      GetFirstDerivative(&feature_vector_last),
+      GetSecondDerivative(&feature_vector_last),
+      GetCepstralCrossCorrelation(&feature_vector_last),
+      GetCepstralVariability(&feature_vector_last));
+
+  // Average is unchanged.
+  ExpectEqualFloatArray({feature_vector.data(), kNumLowerBands},
+                        {feature_vector_last.data(), kNumLowerBands});
+  // First and second derivatives are zero.
+  constexpr std::array<float, kNumLowerBands> zeros{};
+  ExpectEqualFloatArray(
+      {feature_vector_last.data() + kNumBands, kNumLowerBands}, zeros);
+  ExpectEqualFloatArray(
+      {feature_vector_last.data() + kNumBands + kNumLowerBands, kNumLowerBands},
+      zeros);
+  // Variability is unchanged.
+  EXPECT_FLOAT_EQ(feature_vector[kNumBands + 3 * kNumLowerBands],
+                  feature_vector_last[kNumBands + 3 * kNumLowerBands]);
+}
+
+}  // namespace
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/symmetric_matrix_buffer.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/symmetric_matrix_buffer.h
new file mode 100644
index 0000000..dd3b62a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/symmetric_matrix_buffer.h
@@ -0,0 +1,95 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_SYMMETRIC_MATRIX_BUFFER_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_SYMMETRIC_MATRIX_BUFFER_H_
+
+#include <algorithm>
+#include <array>
+#include <cstring>
+#include <utility>
+
+#include "api/array_view.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_compare.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+// Data structure to buffer the results of pair-wise comparisons between items
+// stored in a ring buffer. Every time that the oldest item is replaced in the
+// ring buffer, the new one is compared to the remaining items in the ring
+// buffer. The results of such comparisons need to be buffered and automatically
+// removed when one of the two corresponding items that have been compared is
+// removed from the ring buffer. It is assumed that the comparison is symmetric
+// and that comparing an item with itself is not needed.
+template <typename T, int S>
+class SymmetricMatrixBuffer {
+  static_assert(S > 2, "");
+
+ public:
+  SymmetricMatrixBuffer() = default;
+  SymmetricMatrixBuffer(const SymmetricMatrixBuffer&) = delete;
+  SymmetricMatrixBuffer& operator=(const SymmetricMatrixBuffer&) = delete;
+  ~SymmetricMatrixBuffer() = default;
+  // Sets the buffer values to zero.
+  void Reset() {
+    static_assert(std::is_arithmetic<T>::value,
+                  "Integral or floating point required.");
+    buf_.fill(0);
+  }
+  // Pushes the results from the comparison between the most recent item and
+  // those that are still in the ring buffer. The first element in |values| must
+  // correspond to the comparison between the most recent item and the second
+  // most recent one in the ring buffer, whereas the last element in |values|
+  // must correspond to the comparison between the most recent item and the
+  // oldest one in the ring buffer.
+  void Push(rtc::ArrayView<T, S - 1> values) {
+    // Move the lower-right sub-matrix of size (S-2) x (S-2) one row up and one
+    // column left.
+    std::memmove(buf_.data(), buf_.data() + S, (buf_.size() - S) * sizeof(T));
+    // Copy new values in the last column in the right order.
+    for (int i = 0; rtc::SafeLt(i, values.size()); ++i) {
+      const int index = (S - 1 - i) * (S - 1) - 1;
+      RTC_DCHECK_GE(index, 0);
+      RTC_DCHECK_LT(index, buf_.size());
+      buf_[index] = values[i];
+    }
+  }
+  // Reads the value that corresponds to comparison of two items in the ring
+  // buffer having delay |delay1| and |delay2|. The two arguments must not be
+  // equal and both must be in {0, ..., S - 1}.
+  T GetValue(int delay1, int delay2) const {
+    int row = S - 1 - delay1;
+    int col = S - 1 - delay2;
+    RTC_DCHECK_NE(row, col) << "The diagonal cannot be accessed.";
+    if (row > col)
+      std::swap(row, col);  // Swap to access the upper-right triangular part.
+    RTC_DCHECK_LE(0, row);
+    RTC_DCHECK_LT(row, S - 1) << "Not enforcing row < col and row != col.";
+    RTC_DCHECK_LE(1, col) << "Not enforcing row < col and row != col.";
+    RTC_DCHECK_LT(col, S);
+    const int index = row * (S - 1) + (col - 1);
+    RTC_DCHECK_LE(0, index);
+    RTC_DCHECK_LT(index, buf_.size());
+    return buf_[index];
+  }
+
+ private:
+  // Encode an upper-right triangular matrix (excluding its diagonal) using a
+  // square matrix. This allows to move the data in Push() with one single
+  // operation.
+  std::array<T, (S - 1) * (S - 1)> buf_{};
+};
+
+}  // namespace rnn_vad
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_SYMMETRIC_MATRIX_BUFFER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/symmetric_matrix_buffer_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/symmetric_matrix_buffer_unittest.cc
new file mode 100644
index 0000000..6f61c87
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/symmetric_matrix_buffer_unittest.cc
@@ -0,0 +1,107 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/symmetric_matrix_buffer.h"
+
+#include "modules/audio_processing/agc2/rnn_vad/ring_buffer.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+template <typename T, int S>
+void CheckSymmetry(const SymmetricMatrixBuffer<T, S>* sym_matrix_buf) {
+  for (int row = 0; row < S - 1; ++row)
+    for (int col = row + 1; col < S; ++col)
+      EXPECT_EQ(sym_matrix_buf->GetValue(row, col),
+                sym_matrix_buf->GetValue(col, row));
+}
+
+using PairType = std::pair<int, int>;
+
+// Checks that the symmetric matrix buffer contains any pair with a value equal
+// to the given one.
+template <int S>
+bool CheckPairsWithValueExist(
+    const SymmetricMatrixBuffer<PairType, S>* sym_matrix_buf,
+    const int value) {
+  for (int row = 0; row < S - 1; ++row) {
+    for (int col = row + 1; col < S; ++col) {
+      auto p = sym_matrix_buf->GetValue(row, col);
+      if (p.first == value || p.second == value)
+        return true;
+    }
+  }
+  return false;
+}
+
+// Test that shows how to combine RingBuffer and SymmetricMatrixBuffer to
+// efficiently compute pair-wise scores. This test verifies that the evolution
+// of a SymmetricMatrixBuffer instance follows that of RingBuffer.
+TEST(RnnVadTest, SymmetricMatrixBufferUseCase) {
+  // Instance a ring buffer which will be fed with a series of integer values.
+  constexpr int kRingBufSize = 10;
+  RingBuffer<int, 1, kRingBufSize> ring_buf;
+  // Instance a symmetric matrix buffer for the ring buffer above. It stores
+  // pairs of integers with which this test can easily check that the evolution
+  // of RingBuffer and SymmetricMatrixBuffer match.
+  SymmetricMatrixBuffer<PairType, kRingBufSize> sym_matrix_buf;
+  for (int t = 1; t <= 100; ++t) {  // Evolution steps.
+    SCOPED_TRACE(t);
+    const int t_removed = ring_buf.GetArrayView(kRingBufSize - 1)[0];
+    ring_buf.Push({&t, 1});
+    // The head of the ring buffer is |t|.
+    ASSERT_EQ(t, ring_buf.GetArrayView(0)[0]);
+    // Create the comparisons between |t| and the older elements in the ring
+    // buffer.
+    std::array<PairType, kRingBufSize - 1> new_comparions;
+    for (int i = 0; i < kRingBufSize - 1; ++i) {
+      // Start comparing |t| to the second newest element in the ring buffer.
+      const int delay = i + 1;
+      const auto t_prev = ring_buf.GetArrayView(delay)[0];
+      ASSERT_EQ(std::max(0, t - delay), t_prev);
+      // Compare the last element |t| with |t_prev|.
+      new_comparions[i].first = t_prev;
+      new_comparions[i].second = t;
+    }
+    // Push the new comparisons in the symmetric matrix buffer.
+    sym_matrix_buf.Push({new_comparions.data(), new_comparions.size()});
+    // Tests.
+    CheckSymmetry(&sym_matrix_buf);
+    // Check that the pairs resulting from the content in the ring buffer are
+    // in the right position.
+    for (int delay1 = 0; delay1 < kRingBufSize - 1; ++delay1) {
+      for (int delay2 = delay1 + 1; delay2 < kRingBufSize; ++delay2) {
+        const auto t1 = ring_buf.GetArrayView(delay1)[0];
+        const auto t2 = ring_buf.GetArrayView(delay2)[0];
+        ASSERT_LE(t2, t1);
+        const auto p = sym_matrix_buf.GetValue(delay1, delay2);
+        EXPECT_EQ(p.first, t2);
+        EXPECT_EQ(p.second, t1);
+      }
+    }
+    // Check that every older element in the ring buffer still has a
+    // corresponding pair in the symmetric matrix buffer.
+    for (int delay = 1; delay < kRingBufSize; ++delay) {
+      const auto t_prev = ring_buf.GetArrayView(delay)[0];
+      EXPECT_TRUE(CheckPairsWithValueExist(&sym_matrix_buf, t_prev));
+    }
+    // Check that the element removed from the ring buffer has no corresponding
+    // pairs in the symmetric matrix buffer.
+    if (t > kRingBufSize - 1) {
+      EXPECT_FALSE(CheckPairsWithValueExist(&sym_matrix_buf, t_removed));
+    }
+  }
+}
+
+}  // namespace
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/test_utils.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/test_utils.cc
new file mode 100644
index 0000000..b8ca9c3
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/test_utils.cc
@@ -0,0 +1,141 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/test_utils.h"
+
+#include <algorithm>
+#include <fstream>
+#include <memory>
+#include <type_traits>
+#include <vector>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_compare.h"
+#include "test/gtest.h"
+#include "test/testsupport/file_utils.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+// File reader for binary files that contain a sequence of values with
+// arithmetic type `T`. The values of type `T` that are read are cast to float.
+template <typename T>
+class FloatFileReader : public FileReader {
+ public:
+  static_assert(std::is_arithmetic<T>::value, "");
+  FloatFileReader(const std::string& filename)
+      : is_(filename, std::ios::binary | std::ios::ate),
+        size_(is_.tellg() / sizeof(T)) {
+    RTC_CHECK(is_);
+    SeekBeginning();
+  }
+  FloatFileReader(const FloatFileReader&) = delete;
+  FloatFileReader& operator=(const FloatFileReader&) = delete;
+  ~FloatFileReader() = default;
+
+  int size() const override { return size_; }
+  bool ReadChunk(rtc::ArrayView<float> dst) override {
+    const std::streamsize bytes_to_read = dst.size() * sizeof(T);
+    if (std::is_same<T, float>::value) {
+      is_.read(reinterpret_cast<char*>(dst.data()), bytes_to_read);
+    } else {
+      buffer_.resize(dst.size());
+      is_.read(reinterpret_cast<char*>(buffer_.data()), bytes_to_read);
+      std::transform(buffer_.begin(), buffer_.end(), dst.begin(),
+                     [](const T& v) -> float { return static_cast<float>(v); });
+    }
+    return is_.gcount() == bytes_to_read;
+  }
+  bool ReadValue(float& dst) override { return ReadChunk({&dst, 1}); }
+  void SeekForward(int hop) override { is_.seekg(hop * sizeof(T), is_.cur); }
+  void SeekBeginning() override { is_.seekg(0, is_.beg); }
+
+ private:
+  std::ifstream is_;
+  const int size_;
+  std::vector<T> buffer_;
+};
+
+}  // namespace
+
+using webrtc::test::ResourcePath;
+
+void ExpectEqualFloatArray(rtc::ArrayView<const float> expected,
+                           rtc::ArrayView<const float> computed) {
+  ASSERT_EQ(expected.size(), computed.size());
+  for (int i = 0; rtc::SafeLt(i, expected.size()); ++i) {
+    SCOPED_TRACE(i);
+    EXPECT_FLOAT_EQ(expected[i], computed[i]);
+  }
+}
+
+void ExpectNearAbsolute(rtc::ArrayView<const float> expected,
+                        rtc::ArrayView<const float> computed,
+                        float tolerance) {
+  ASSERT_EQ(expected.size(), computed.size());
+  for (int i = 0; rtc::SafeLt(i, expected.size()); ++i) {
+    SCOPED_TRACE(i);
+    EXPECT_NEAR(expected[i], computed[i], tolerance);
+  }
+}
+
+std::unique_ptr<FileReader> CreatePcmSamplesReader() {
+  return std::make_unique<FloatFileReader<int16_t>>(
+      /*filename=*/test::ResourcePath("audio_processing/agc2/rnn_vad/samples",
+                                      "pcm"));
+}
+
+ChunksFileReader CreatePitchBuffer24kHzReader() {
+  auto reader = std::make_unique<FloatFileReader<float>>(
+      /*filename=*/test::ResourcePath(
+          "audio_processing/agc2/rnn_vad/pitch_buf_24k", "dat"));
+  const int num_chunks = rtc::CheckedDivExact(reader->size(), kBufSize24kHz);
+  return {/*chunk_size=*/kBufSize24kHz, num_chunks, std::move(reader)};
+}
+
+ChunksFileReader CreateLpResidualAndPitchInfoReader() {
+  constexpr int kPitchInfoSize = 2;  // Pitch period and strength.
+  constexpr int kChunkSize = kBufSize24kHz + kPitchInfoSize;
+  auto reader = std::make_unique<FloatFileReader<float>>(
+      /*filename=*/test::ResourcePath(
+          "audio_processing/agc2/rnn_vad/pitch_lp_res", "dat"));
+  const int num_chunks = rtc::CheckedDivExact(reader->size(), kChunkSize);
+  return {kChunkSize, num_chunks, std::move(reader)};
+}
+
+std::unique_ptr<FileReader> CreateGruInputReader() {
+  return std::make_unique<FloatFileReader<float>>(
+      /*filename=*/test::ResourcePath("audio_processing/agc2/rnn_vad/gru_in",
+                                      "dat"));
+}
+
+std::unique_ptr<FileReader> CreateVadProbsReader() {
+  return std::make_unique<FloatFileReader<float>>(
+      /*filename=*/test::ResourcePath("audio_processing/agc2/rnn_vad/vad_prob",
+                                      "dat"));
+}
+
+PitchTestData::PitchTestData() {
+  FloatFileReader<float> reader(
+      /*filename=*/ResourcePath(
+          "audio_processing/agc2/rnn_vad/pitch_search_int", "dat"));
+  reader.ReadChunk(pitch_buffer_24k_);
+  reader.ReadChunk(square_energies_24k_);
+  reader.ReadChunk(auto_correlation_12k_);
+  // Reverse the order of the squared energy values.
+  // Required after the WebRTC CL 191703 which switched to forward computation.
+  std::reverse(square_energies_24k_.begin(), square_energies_24k_.end());
+}
+
+PitchTestData::~PitchTestData() = default;
+
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/test_utils.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/test_utils.h
new file mode 100644
index 0000000..e366e18
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/test_utils.h
@@ -0,0 +1,129 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_TEST_UTILS_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_TEST_UTILS_H_
+
+#include <array>
+#include <fstream>
+#include <memory>
+#include <string>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/rnn_vad/common.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_compare.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+constexpr float kFloatMin = std::numeric_limits<float>::min();
+
+// Fails for every pair from two equally sized rtc::ArrayView<float> views such
+// that the values in the pair do not match.
+void ExpectEqualFloatArray(rtc::ArrayView<const float> expected,
+                           rtc::ArrayView<const float> computed);
+
+// Fails for every pair from two equally sized rtc::ArrayView<float> views such
+// that their absolute error is above a given threshold.
+void ExpectNearAbsolute(rtc::ArrayView<const float> expected,
+                        rtc::ArrayView<const float> computed,
+                        float tolerance);
+
+// File reader interface.
+class FileReader {
+ public:
+  virtual ~FileReader() = default;
+  // Number of values in the file.
+  virtual int size() const = 0;
+  // Reads `dst.size()` float values into `dst`, advances the internal file
+  // position according to the number of read bytes and returns true if the
+  // values are correctly read. If the number of remaining bytes in the file is
+  // not sufficient to read `dst.size()` float values, `dst` is partially
+  // modified and false is returned.
+  virtual bool ReadChunk(rtc::ArrayView<float> dst) = 0;
+  // Reads a single float value, advances the internal file position according
+  // to the number of read bytes and returns true if the value is correctly
+  // read. If the number of remaining bytes in the file is not sufficient to
+  // read one float, `dst` is not modified and false is returned.
+  virtual bool ReadValue(float& dst) = 0;
+  // Advances the internal file position by `hop` float values.
+  virtual void SeekForward(int hop) = 0;
+  // Resets the internal file position to BOF.
+  virtual void SeekBeginning() = 0;
+};
+
+// File reader for files that contain `num_chunks` chunks with size equal to
+// `chunk_size`.
+struct ChunksFileReader {
+  const int chunk_size;
+  const int num_chunks;
+  std::unique_ptr<FileReader> reader;
+};
+
+// Creates a reader for the PCM S16 samples file.
+std::unique_ptr<FileReader> CreatePcmSamplesReader();
+
+// Creates a reader for the 24 kHz pitch buffer test data.
+ChunksFileReader CreatePitchBuffer24kHzReader();
+
+// Creates a reader for the LP residual and pitch information test data.
+ChunksFileReader CreateLpResidualAndPitchInfoReader();
+
+// Creates a reader for the sequence of GRU input vectors.
+std::unique_ptr<FileReader> CreateGruInputReader();
+
+// Creates a reader for the VAD probabilities test data.
+std::unique_ptr<FileReader> CreateVadProbsReader();
+
+// Class to retrieve a test pitch buffer content and the expected output for the
+// analysis steps.
+class PitchTestData {
+ public:
+  PitchTestData();
+  ~PitchTestData();
+  rtc::ArrayView<const float, kBufSize24kHz> PitchBuffer24kHzView() const {
+    return pitch_buffer_24k_;
+  }
+  rtc::ArrayView<const float, kRefineNumLags24kHz> SquareEnergies24kHzView()
+      const {
+    return square_energies_24k_;
+  }
+  rtc::ArrayView<const float, kNumLags12kHz> AutoCorrelation12kHzView() const {
+    return auto_correlation_12k_;
+  }
+
+ private:
+  std::array<float, kBufSize24kHz> pitch_buffer_24k_;
+  std::array<float, kRefineNumLags24kHz> square_energies_24k_;
+  std::array<float, kNumLags12kHz> auto_correlation_12k_;
+};
+
+// Writer for binary files.
+class FileWriter {
+ public:
+  explicit FileWriter(const std::string& file_path)
+      : os_(file_path, std::ios::binary) {}
+  FileWriter(const FileWriter&) = delete;
+  FileWriter& operator=(const FileWriter&) = delete;
+  ~FileWriter() = default;
+  void WriteChunk(rtc::ArrayView<const float> value) {
+    const std::streamsize bytes_to_write = value.size() * sizeof(float);
+    os_.write(reinterpret_cast<const char*>(value.data()), bytes_to_write);
+  }
+
+ private:
+  std::ofstream os_;
+};
+
+}  // namespace rnn_vad
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_TEST_UTILS_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/vector_math.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/vector_math.h
new file mode 100644
index 0000000..47f6811
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/vector_math.h
@@ -0,0 +1,114 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_VECTOR_MATH_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_VECTOR_MATH_H_
+
+// Defines WEBRTC_ARCH_X86_FAMILY, used below.
+#include "rtc_base/system/arch.h"
+
+#if defined(WEBRTC_HAS_NEON)
+#include <arm_neon.h>
+#endif
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+#include <emmintrin.h>
+#endif
+
+#include <numeric>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/cpu_features.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_conversions.h"
+#include "rtc_base/system/arch.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+// Provides optimizations for mathematical operations having vectors as
+// operand(s).
+class VectorMath {
+ public:
+  explicit VectorMath(AvailableCpuFeatures cpu_features)
+      : cpu_features_(cpu_features) {}
+
+  // Computes the dot product between two equally sized vectors.
+  float DotProduct(rtc::ArrayView<const float> x,
+                   rtc::ArrayView<const float> y) const {
+    RTC_DCHECK_EQ(x.size(), y.size());
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+    if (cpu_features_.avx2) {
+      return DotProductAvx2(x, y);
+    } else if (cpu_features_.sse2) {
+      __m128 accumulator = _mm_setzero_ps();
+      constexpr int kBlockSizeLog2 = 2;
+      constexpr int kBlockSize = 1 << kBlockSizeLog2;
+      const int incomplete_block_index = (x.size() >> kBlockSizeLog2)
+                                         << kBlockSizeLog2;
+      for (int i = 0; i < incomplete_block_index; i += kBlockSize) {
+        RTC_DCHECK_LE(i + kBlockSize, x.size());
+        const __m128 x_i = _mm_loadu_ps(&x[i]);
+        const __m128 y_i = _mm_loadu_ps(&y[i]);
+        // Multiply-add.
+        const __m128 z_j = _mm_mul_ps(x_i, y_i);
+        accumulator = _mm_add_ps(accumulator, z_j);
+      }
+      // Reduce `accumulator` by addition.
+      __m128 high = _mm_movehl_ps(accumulator, accumulator);
+      accumulator = _mm_add_ps(accumulator, high);
+      high = _mm_shuffle_ps(accumulator, accumulator, 1);
+      accumulator = _mm_add_ps(accumulator, high);
+      float dot_product = _mm_cvtss_f32(accumulator);
+      // Add the result for the last block if incomplete.
+      for (int i = incomplete_block_index;
+           i < rtc::dchecked_cast<int>(x.size()); ++i) {
+        dot_product += x[i] * y[i];
+      }
+      return dot_product;
+    }
+#elif defined(WEBRTC_HAS_NEON) && defined(WEBRTC_ARCH_ARM64)
+    if (cpu_features_.neon) {
+      float32x4_t accumulator = vdupq_n_f32(0.f);
+      constexpr int kBlockSizeLog2 = 2;
+      constexpr int kBlockSize = 1 << kBlockSizeLog2;
+      const int incomplete_block_index = (x.size() >> kBlockSizeLog2)
+                                         << kBlockSizeLog2;
+      for (int i = 0; i < incomplete_block_index; i += kBlockSize) {
+        RTC_DCHECK_LE(i + kBlockSize, x.size());
+        const float32x4_t x_i = vld1q_f32(&x[i]);
+        const float32x4_t y_i = vld1q_f32(&y[i]);
+        accumulator = vfmaq_f32(accumulator, x_i, y_i);
+      }
+      // Reduce `accumulator` by addition.
+      const float32x2_t tmp =
+          vpadd_f32(vget_low_f32(accumulator), vget_high_f32(accumulator));
+      float dot_product = vget_lane_f32(vpadd_f32(tmp, vrev64_f32(tmp)), 0);
+      // Add the result for the last block if incomplete.
+      for (int i = incomplete_block_index;
+           i < rtc::dchecked_cast<int>(x.size()); ++i) {
+        dot_product += x[i] * y[i];
+      }
+      return dot_product;
+    }
+#endif
+    return std::inner_product(x.begin(), x.end(), y.begin(), 0.f);
+  }
+
+ private:
+  float DotProductAvx2(rtc::ArrayView<const float> x,
+                       rtc::ArrayView<const float> y) const;
+
+  const AvailableCpuFeatures cpu_features_;
+};
+
+}  // namespace rnn_vad
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_RNN_VAD_VECTOR_MATH_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/vector_math_avx2.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/vector_math_avx2.cc
new file mode 100644
index 0000000..e4d246d
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/vector_math_avx2.cc
@@ -0,0 +1,55 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/vector_math.h"
+
+#include <immintrin.h>
+
+#include "api/array_view.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_conversions.h"
+
+namespace webrtc {
+namespace rnn_vad {
+
+float VectorMath::DotProductAvx2(rtc::ArrayView<const float> x,
+                                 rtc::ArrayView<const float> y) const {
+  RTC_DCHECK(cpu_features_.avx2);
+  RTC_DCHECK_EQ(x.size(), y.size());
+  __m256 accumulator = _mm256_setzero_ps();
+  constexpr int kBlockSizeLog2 = 3;
+  constexpr int kBlockSize = 1 << kBlockSizeLog2;
+  const int incomplete_block_index = (x.size() >> kBlockSizeLog2)
+                                     << kBlockSizeLog2;
+  for (int i = 0; i < incomplete_block_index; i += kBlockSize) {
+    RTC_DCHECK_LE(i + kBlockSize, x.size());
+    const __m256 x_i = _mm256_loadu_ps(&x[i]);
+    const __m256 y_i = _mm256_loadu_ps(&y[i]);
+    accumulator = _mm256_fmadd_ps(x_i, y_i, accumulator);
+  }
+  // Reduce `accumulator` by addition.
+  __m128 high = _mm256_extractf128_ps(accumulator, 1);
+  __m128 low = _mm256_extractf128_ps(accumulator, 0);
+  low = _mm_add_ps(high, low);
+  high = _mm_movehl_ps(high, low);
+  low = _mm_add_ps(high, low);
+  high = _mm_shuffle_ps(low, low, 1);
+  low = _mm_add_ss(high, low);
+  float dot_product = _mm_cvtss_f32(low);
+  // Add the result for the last block if incomplete.
+  for (int i = incomplete_block_index; i < rtc::dchecked_cast<int>(x.size());
+       ++i) {
+    dot_product += x[i] * y[i];
+  }
+  return dot_product;
+}
+
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/vector_math_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/vector_math_unittest.cc
new file mode 100644
index 0000000..45fd65d
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/rnn_vad/vector_math_unittest.cc
@@ -0,0 +1,71 @@
+/*
+ *  Copyright (c) 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/rnn_vad/vector_math.h"
+
+#include <vector>
+
+#include "modules/audio_processing/agc2/cpu_features.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace rnn_vad {
+namespace {
+
+constexpr int kSizeOfX = 19;
+constexpr float kX[kSizeOfX] = {
+    0.31593041f, 0.9350786f,   -0.25252445f, -0.86956251f, -0.9673632f,
+    0.54571901f, -0.72504495f, -0.79509912f, -0.25525012f, -0.73340473f,
+    0.15747377f, -0.04370565f, 0.76135145f,  -0.57239645f, 0.68616848f,
+    0.3740298f,  0.34710799f,  -0.92207423f, 0.10738454f};
+constexpr int kSizeOfXSubSpan = 16;
+static_assert(kSizeOfXSubSpan < kSizeOfX, "");
+constexpr float kEnergyOfX = 7.315563958160327f;
+constexpr float kEnergyOfXSubspan = 6.333327669592963f;
+
+class VectorMathParametrization
+    : public ::testing::TestWithParam<AvailableCpuFeatures> {};
+
+TEST_P(VectorMathParametrization, TestDotProduct) {
+  VectorMath vector_math(/*cpu_features=*/GetParam());
+  EXPECT_FLOAT_EQ(vector_math.DotProduct(kX, kX), kEnergyOfX);
+  EXPECT_FLOAT_EQ(
+      vector_math.DotProduct({kX, kSizeOfXSubSpan}, {kX, kSizeOfXSubSpan}),
+      kEnergyOfXSubspan);
+}
+
+// Finds the relevant CPU features combinations to test.
+std::vector<AvailableCpuFeatures> GetCpuFeaturesToTest() {
+  std::vector<AvailableCpuFeatures> v;
+  v.push_back({/*sse2=*/false, /*avx2=*/false, /*neon=*/false});
+  AvailableCpuFeatures available = GetAvailableCpuFeatures();
+  if (available.avx2) {
+    v.push_back({/*sse2=*/false, /*avx2=*/true, /*neon=*/false});
+  }
+  if (available.sse2) {
+    v.push_back({/*sse2=*/true, /*avx2=*/false, /*neon=*/false});
+  }
+  if (available.neon) {
+    v.push_back({/*sse2=*/false, /*avx2=*/false, /*neon=*/true});
+  }
+  return v;
+}
+
+INSTANTIATE_TEST_SUITE_P(
+    RnnVadTest,
+    VectorMathParametrization,
+    ::testing::ValuesIn(GetCpuFeaturesToTest()),
+    [](const ::testing::TestParamInfo<AvailableCpuFeatures>& info) {
+      return info.param.ToString();
+    });
+
+}  // namespace
+}  // namespace rnn_vad
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector.cc
new file mode 100644
index 0000000..d6f21ef
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector.cc
@@ -0,0 +1,188 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/saturation_protector.h"
+
+#include <memory>
+
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "modules/audio_processing/agc2/saturation_protector_buffer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_minmax.h"
+
+namespace webrtc {
+namespace {
+
+constexpr int kPeakEnveloperSuperFrameLengthMs = 400;
+constexpr float kMinMarginDb = 12.0f;
+constexpr float kMaxMarginDb = 25.0f;
+constexpr float kAttack = 0.9988493699365052f;
+constexpr float kDecay = 0.9997697679981565f;
+
+// Saturation protector state. Defined outside of `SaturationProtectorImpl` to
+// implement check-point and restore ops.
+struct SaturationProtectorState {
+  bool operator==(const SaturationProtectorState& s) const {
+    return headroom_db == s.headroom_db &&
+           peak_delay_buffer == s.peak_delay_buffer &&
+           max_peaks_dbfs == s.max_peaks_dbfs &&
+           time_since_push_ms == s.time_since_push_ms;
+  }
+  inline bool operator!=(const SaturationProtectorState& s) const {
+    return !(*this == s);
+  }
+
+  float headroom_db;
+  SaturationProtectorBuffer peak_delay_buffer;
+  float max_peaks_dbfs;
+  int time_since_push_ms;  // Time since the last ring buffer push operation.
+};
+
+// Resets the saturation protector state.
+void ResetSaturationProtectorState(float initial_headroom_db,
+                                   SaturationProtectorState& state) {
+  state.headroom_db = initial_headroom_db;
+  state.peak_delay_buffer.Reset();
+  state.max_peaks_dbfs = kMinLevelDbfs;
+  state.time_since_push_ms = 0;
+}
+
+// Updates `state` by analyzing the estimated speech level `speech_level_dbfs`
+// and the peak level `peak_dbfs` for an observed frame. `state` must not be
+// modified without calling this function.
+void UpdateSaturationProtectorState(float peak_dbfs,
+                                    float speech_level_dbfs,
+                                    SaturationProtectorState& state) {
+  // Get the max peak over `kPeakEnveloperSuperFrameLengthMs` ms.
+  state.max_peaks_dbfs = std::max(state.max_peaks_dbfs, peak_dbfs);
+  state.time_since_push_ms += kFrameDurationMs;
+  if (rtc::SafeGt(state.time_since_push_ms, kPeakEnveloperSuperFrameLengthMs)) {
+    // Push `max_peaks_dbfs` back into the ring buffer.
+    state.peak_delay_buffer.PushBack(state.max_peaks_dbfs);
+    // Reset.
+    state.max_peaks_dbfs = kMinLevelDbfs;
+    state.time_since_push_ms = 0;
+  }
+
+  // Update the headroom by comparing the estimated speech level and the delayed
+  // max speech peak.
+  const float delayed_peak_dbfs =
+      state.peak_delay_buffer.Front().value_or(state.max_peaks_dbfs);
+  const float difference_db = delayed_peak_dbfs - speech_level_dbfs;
+  if (difference_db > state.headroom_db) {
+    // Attack.
+    state.headroom_db =
+        state.headroom_db * kAttack + difference_db * (1.0f - kAttack);
+  } else {
+    // Decay.
+    state.headroom_db =
+        state.headroom_db * kDecay + difference_db * (1.0f - kDecay);
+  }
+
+  state.headroom_db =
+      rtc::SafeClamp<float>(state.headroom_db, kMinMarginDb, kMaxMarginDb);
+}
+
+// Saturation protector which recommends a headroom based on the recent peaks.
+class SaturationProtectorImpl : public SaturationProtector {
+ public:
+  explicit SaturationProtectorImpl(float initial_headroom_db,
+                                   float extra_headroom_db,
+                                   int adjacent_speech_frames_threshold,
+                                   ApmDataDumper* apm_data_dumper)
+      : apm_data_dumper_(apm_data_dumper),
+        initial_headroom_db_(initial_headroom_db),
+        extra_headroom_db_(extra_headroom_db),
+        adjacent_speech_frames_threshold_(adjacent_speech_frames_threshold) {
+    Reset();
+  }
+  SaturationProtectorImpl(const SaturationProtectorImpl&) = delete;
+  SaturationProtectorImpl& operator=(const SaturationProtectorImpl&) = delete;
+  ~SaturationProtectorImpl() = default;
+
+  float HeadroomDb() override { return headroom_db_; }
+
+  void Analyze(float speech_probability,
+               float peak_dbfs,
+               float speech_level_dbfs) override {
+    if (speech_probability < kVadConfidenceThreshold) {
+      // Not a speech frame.
+      if (adjacent_speech_frames_threshold_ > 1) {
+        // When two or more adjacent speech frames are required in order to
+        // update the state, we need to decide whether to discard or confirm the
+        // updates based on the speech sequence length.
+        if (num_adjacent_speech_frames_ >= adjacent_speech_frames_threshold_) {
+          // First non-speech frame after a long enough sequence of speech
+          // frames. Update the reliable state.
+          reliable_state_ = preliminary_state_;
+        } else if (num_adjacent_speech_frames_ > 0) {
+          // First non-speech frame after a too short sequence of speech frames.
+          // Reset to the last reliable state.
+          preliminary_state_ = reliable_state_;
+        }
+      }
+      num_adjacent_speech_frames_ = 0;
+    } else {
+      // Speech frame observed.
+      num_adjacent_speech_frames_++;
+
+      // Update preliminary level estimate.
+      UpdateSaturationProtectorState(peak_dbfs, speech_level_dbfs,
+                                     preliminary_state_);
+
+      if (num_adjacent_speech_frames_ >= adjacent_speech_frames_threshold_) {
+        // `preliminary_state_` is now reliable. Update the headroom.
+        headroom_db_ = preliminary_state_.headroom_db + extra_headroom_db_;
+      }
+    }
+    DumpDebugData();
+  }
+
+  void Reset() override {
+    num_adjacent_speech_frames_ = 0;
+    headroom_db_ = initial_headroom_db_ + extra_headroom_db_;
+    ResetSaturationProtectorState(initial_headroom_db_, preliminary_state_);
+    ResetSaturationProtectorState(initial_headroom_db_, reliable_state_);
+  }
+
+ private:
+  void DumpDebugData() {
+    apm_data_dumper_->DumpRaw(
+        "agc2_saturation_protector_preliminary_max_peak_dbfs",
+        preliminary_state_.max_peaks_dbfs);
+    apm_data_dumper_->DumpRaw(
+        "agc2_saturation_protector_reliable_max_peak_dbfs",
+        reliable_state_.max_peaks_dbfs);
+  }
+
+  ApmDataDumper* const apm_data_dumper_;
+  const float initial_headroom_db_;
+  const float extra_headroom_db_;
+  const int adjacent_speech_frames_threshold_;
+  int num_adjacent_speech_frames_;
+  float headroom_db_;
+  SaturationProtectorState preliminary_state_;
+  SaturationProtectorState reliable_state_;
+};
+
+}  // namespace
+
+std::unique_ptr<SaturationProtector> CreateSaturationProtector(
+    float initial_headroom_db,
+    float extra_headroom_db,
+    int adjacent_speech_frames_threshold,
+    ApmDataDumper* apm_data_dumper) {
+  return std::make_unique<SaturationProtectorImpl>(
+      initial_headroom_db, extra_headroom_db, adjacent_speech_frames_threshold,
+      apm_data_dumper);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector.h
new file mode 100644
index 0000000..0c384f1
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector.h
@@ -0,0 +1,47 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_SATURATION_PROTECTOR_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_SATURATION_PROTECTOR_H_
+
+#include <memory>
+
+namespace webrtc {
+class ApmDataDumper;
+
+// Saturation protector. Analyzes peak levels and recommends a headroom to
+// reduce the chances of clipping.
+class SaturationProtector {
+ public:
+  virtual ~SaturationProtector() = default;
+
+  // Returns the recommended headroom in dB.
+  virtual float HeadroomDb() = 0;
+
+  // Analyzes the peak level of a 10 ms frame along with its speech probability
+  // and the current speech level estimate to update the recommended headroom.
+  virtual void Analyze(float speech_probability,
+                       float peak_dbfs,
+                       float speech_level_dbfs) = 0;
+
+  // Resets the internal state.
+  virtual void Reset() = 0;
+};
+
+// Creates a saturation protector that starts at `initial_headroom_db`.
+std::unique_ptr<SaturationProtector> CreateSaturationProtector(
+    float initial_headroom_db,
+    float extra_headroom_db,
+    int adjacent_speech_frames_threshold,
+    ApmDataDumper* apm_data_dumper);
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_SATURATION_PROTECTOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector_buffer.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector_buffer.cc
new file mode 100644
index 0000000..41efdad
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector_buffer.cc
@@ -0,0 +1,77 @@
+/*
+ *  Copyright (c) 2021 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/saturation_protector_buffer.h"
+
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_compare.h"
+
+namespace webrtc {
+
+SaturationProtectorBuffer::SaturationProtectorBuffer() = default;
+
+SaturationProtectorBuffer::~SaturationProtectorBuffer() = default;
+
+bool SaturationProtectorBuffer::operator==(
+    const SaturationProtectorBuffer& b) const {
+  RTC_DCHECK_LE(size_, buffer_.size());
+  RTC_DCHECK_LE(b.size_, b.buffer_.size());
+  if (size_ != b.size_) {
+    return false;
+  }
+  for (int i = 0, i0 = FrontIndex(), i1 = b.FrontIndex(); i < size_;
+       ++i, ++i0, ++i1) {
+    if (buffer_[i0 % buffer_.size()] != b.buffer_[i1 % b.buffer_.size()]) {
+      return false;
+    }
+  }
+  return true;
+}
+
+int SaturationProtectorBuffer::Capacity() const {
+  return buffer_.size();
+}
+
+int SaturationProtectorBuffer::Size() const {
+  return size_;
+}
+
+void SaturationProtectorBuffer::Reset() {
+  next_ = 0;
+  size_ = 0;
+}
+
+void SaturationProtectorBuffer::PushBack(float v) {
+  RTC_DCHECK_GE(next_, 0);
+  RTC_DCHECK_GE(size_, 0);
+  RTC_DCHECK_LT(next_, buffer_.size());
+  RTC_DCHECK_LE(size_, buffer_.size());
+  buffer_[next_++] = v;
+  if (rtc::SafeEq(next_, buffer_.size())) {
+    next_ = 0;
+  }
+  if (rtc::SafeLt(size_, buffer_.size())) {
+    size_++;
+  }
+}
+
+absl::optional<float> SaturationProtectorBuffer::Front() const {
+  if (size_ == 0) {
+    return absl::nullopt;
+  }
+  RTC_DCHECK_LT(FrontIndex(), buffer_.size());
+  return buffer_[FrontIndex()];
+}
+
+int SaturationProtectorBuffer::FrontIndex() const {
+  return rtc::SafeEq(size_, buffer_.size()) ? next_ : 0;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector_buffer.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector_buffer.h
new file mode 100644
index 0000000..e17d099
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector_buffer.h
@@ -0,0 +1,59 @@
+/*
+ *  Copyright (c) 2021 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_SATURATION_PROTECTOR_BUFFER_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_SATURATION_PROTECTOR_BUFFER_H_
+
+#include <array>
+
+#include "absl/types/optional.h"
+#include "modules/audio_processing/agc2/agc2_common.h"
+
+namespace webrtc {
+
+// Ring buffer for the saturation protector which only supports (i) push back
+// and (ii) read oldest item.
+class SaturationProtectorBuffer {
+ public:
+  SaturationProtectorBuffer();
+  ~SaturationProtectorBuffer();
+
+  bool operator==(const SaturationProtectorBuffer& b) const;
+  inline bool operator!=(const SaturationProtectorBuffer& b) const {
+    return !(*this == b);
+  }
+
+  // Maximum number of values that the buffer can contain.
+  int Capacity() const;
+
+  // Number of values in the buffer.
+  int Size() const;
+
+  void Reset();
+
+  // Pushes back `v`. If the buffer is full, the oldest value is replaced.
+  void PushBack(float v);
+
+  // Returns the oldest item in the buffer. Returns an empty value if the
+  // buffer is empty.
+  absl::optional<float> Front() const;
+
+ private:
+  int FrontIndex() const;
+  // `buffer_` has `size_` elements (up to the size of `buffer_`) and `next_` is
+  // the position where the next new value is written in `buffer_`.
+  std::array<float, kSaturationProtectorBufferSize> buffer_;
+  int next_ = 0;
+  int size_ = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_SATURATION_PROTECTOR_BUFFER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector_buffer_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector_buffer_unittest.cc
new file mode 100644
index 0000000..22187bf
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector_buffer_unittest.cc
@@ -0,0 +1,73 @@
+/*
+ *  Copyright (c) 2021 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/saturation_protector_buffer.h"
+
+#include "test/gmock.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace {
+
+using ::testing::Eq;
+using ::testing::Optional;
+
+TEST(GainController2SaturationProtectorBuffer, Init) {
+  SaturationProtectorBuffer b;
+  EXPECT_EQ(b.Size(), 0);
+  EXPECT_FALSE(b.Front().has_value());
+}
+
+TEST(GainController2SaturationProtectorBuffer, PushBack) {
+  SaturationProtectorBuffer b;
+  constexpr float kValue = 123.0f;
+  b.PushBack(kValue);
+  EXPECT_EQ(b.Size(), 1);
+  EXPECT_THAT(b.Front(), Optional(Eq(kValue)));
+}
+
+TEST(GainController2SaturationProtectorBuffer, Reset) {
+  SaturationProtectorBuffer b;
+  b.PushBack(123.0f);
+  b.Reset();
+  EXPECT_EQ(b.Size(), 0);
+  EXPECT_FALSE(b.Front().has_value());
+}
+
+// Checks that the front value does not change until the ring buffer gets full.
+TEST(GainController2SaturationProtectorBuffer, FrontUntilBufferIsFull) {
+  SaturationProtectorBuffer b;
+  constexpr float kValue = 123.0f;
+  b.PushBack(kValue);
+  for (int i = 1; i < b.Capacity(); ++i) {
+    SCOPED_TRACE(i);
+    EXPECT_THAT(b.Front(), Optional(Eq(kValue)));
+    b.PushBack(kValue + i);
+  }
+}
+
+// Checks that when the buffer is full it behaves as a shift register.
+TEST(GainController2SaturationProtectorBuffer, FrontIsDelayed) {
+  SaturationProtectorBuffer b;
+  // Fill the buffer.
+  for (int i = 0; i < b.Capacity(); ++i) {
+    b.PushBack(i);
+  }
+  // The ring buffer should now behave as a shift register with a delay equal to
+  // its capacity.
+  for (int i = b.Capacity(); i < 2 * b.Capacity() + 1; ++i) {
+    SCOPED_TRACE(i);
+    EXPECT_THAT(b.Front(), Optional(Eq(i - b.Capacity())));
+    b.PushBack(i);
+  }
+}
+
+}  // namespace
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector_unittest.cc
new file mode 100644
index 0000000..dc16dc2
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/saturation_protector_unittest.cc
@@ -0,0 +1,175 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/saturation_protector.h"
+
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/gunit.h"
+
+namespace webrtc {
+namespace {
+
+constexpr float kInitialHeadroomDb = 20.0f;
+constexpr float kNoExtraHeadroomDb = 0.0f;
+constexpr int kNoAdjacentSpeechFramesRequired = 1;
+constexpr float kMaxSpeechProbability = 1.0f;
+
+// Calls `Analyze(speech_probability, peak_dbfs, speech_level_dbfs)`
+// `num_iterations` times on `saturation_protector` and return the largest
+// headroom difference between two consecutive calls.
+float RunOnConstantLevel(int num_iterations,
+                         float speech_probability,
+                         float peak_dbfs,
+                         float speech_level_dbfs,
+                         SaturationProtector& saturation_protector) {
+  float last_headroom = saturation_protector.HeadroomDb();
+  float max_difference = 0.0f;
+  for (int i = 0; i < num_iterations; ++i) {
+    saturation_protector.Analyze(speech_probability, peak_dbfs,
+                                 speech_level_dbfs);
+    const float new_headroom = saturation_protector.HeadroomDb();
+    max_difference =
+        std::max(max_difference, std::fabs(new_headroom - last_headroom));
+    last_headroom = new_headroom;
+  }
+  return max_difference;
+}
+
+// Checks that the returned headroom value is correctly reset.
+TEST(GainController2SaturationProtector, Reset) {
+  ApmDataDumper apm_data_dumper(0);
+  auto saturation_protector = CreateSaturationProtector(
+      kInitialHeadroomDb, kNoExtraHeadroomDb, kNoAdjacentSpeechFramesRequired,
+      &apm_data_dumper);
+  const float initial_headroom_db = saturation_protector->HeadroomDb();
+  RunOnConstantLevel(/*num_iterations=*/10, kMaxSpeechProbability,
+                     /*peak_dbfs=*/0.0f,
+                     /*speech_level_dbfs=*/-10.0f, *saturation_protector);
+  // Make sure that there are side-effects.
+  ASSERT_NE(initial_headroom_db, saturation_protector->HeadroomDb());
+  saturation_protector->Reset();
+  EXPECT_EQ(initial_headroom_db, saturation_protector->HeadroomDb());
+}
+
+// Checks that the estimate converges to the ratio between peaks and level
+// estimator values after a while.
+TEST(GainController2SaturationProtector, EstimatesCrestRatio) {
+  constexpr int kNumIterations = 2000;
+  constexpr float kPeakLevelDbfs = -20.0f;
+  constexpr float kCrestFactorDb = kInitialHeadroomDb + 1.0f;
+  constexpr float kSpeechLevelDbfs = kPeakLevelDbfs - kCrestFactorDb;
+  const float kMaxDifferenceDb =
+      0.5f * std::fabs(kInitialHeadroomDb - kCrestFactorDb);
+
+  ApmDataDumper apm_data_dumper(0);
+  auto saturation_protector = CreateSaturationProtector(
+      kInitialHeadroomDb, kNoExtraHeadroomDb, kNoAdjacentSpeechFramesRequired,
+      &apm_data_dumper);
+  RunOnConstantLevel(kNumIterations, kMaxSpeechProbability, kPeakLevelDbfs,
+                     kSpeechLevelDbfs, *saturation_protector);
+  EXPECT_NEAR(saturation_protector->HeadroomDb(), kCrestFactorDb,
+              kMaxDifferenceDb);
+}
+
+// Checks that the extra headroom is applied.
+TEST(GainController2SaturationProtector, ExtraHeadroomApplied) {
+  constexpr float kExtraHeadroomDb = 5.1234f;
+  constexpr int kNumIterations = 10;
+  constexpr float kPeakLevelDbfs = -20.0f;
+  constexpr float kSpeechLevelDbfs = kPeakLevelDbfs - 15.0f;
+
+  ApmDataDumper apm_data_dumper(0);
+
+  auto saturation_protector_no_extra = CreateSaturationProtector(
+      kInitialHeadroomDb, kNoExtraHeadroomDb, kNoAdjacentSpeechFramesRequired,
+      &apm_data_dumper);
+  for (int i = 0; i < kNumIterations; ++i) {
+    saturation_protector_no_extra->Analyze(kMaxSpeechProbability,
+                                           kPeakLevelDbfs, kSpeechLevelDbfs);
+  }
+
+  auto saturation_protector_extra = CreateSaturationProtector(
+      kInitialHeadroomDb, kExtraHeadroomDb, kNoAdjacentSpeechFramesRequired,
+      &apm_data_dumper);
+  for (int i = 0; i < kNumIterations; ++i) {
+    saturation_protector_extra->Analyze(kMaxSpeechProbability, kPeakLevelDbfs,
+                                        kSpeechLevelDbfs);
+  }
+
+  EXPECT_EQ(saturation_protector_no_extra->HeadroomDb() + kExtraHeadroomDb,
+            saturation_protector_extra->HeadroomDb());
+}
+
+// Checks that the headroom does not change too quickly.
+TEST(GainController2SaturationProtector, ChangeSlowly) {
+  constexpr int kNumIterations = 1000;
+  constexpr float kPeakLevelDbfs = -20.f;
+  constexpr float kCrestFactorDb = kInitialHeadroomDb - 5.f;
+  constexpr float kOtherCrestFactorDb = kInitialHeadroomDb;
+  constexpr float kSpeechLevelDbfs = kPeakLevelDbfs - kCrestFactorDb;
+  constexpr float kOtherSpeechLevelDbfs = kPeakLevelDbfs - kOtherCrestFactorDb;
+
+  ApmDataDumper apm_data_dumper(0);
+  auto saturation_protector = CreateSaturationProtector(
+      kInitialHeadroomDb, kNoExtraHeadroomDb, kNoAdjacentSpeechFramesRequired,
+      &apm_data_dumper);
+  float max_difference_db =
+      RunOnConstantLevel(kNumIterations, kMaxSpeechProbability, kPeakLevelDbfs,
+                         kSpeechLevelDbfs, *saturation_protector);
+  max_difference_db = std::max(
+      RunOnConstantLevel(kNumIterations, kMaxSpeechProbability, kPeakLevelDbfs,
+                         kOtherSpeechLevelDbfs, *saturation_protector),
+      max_difference_db);
+  constexpr float kMaxChangeSpeedDbPerSecond = 0.5f;  // 1 db / 2 seconds.
+  EXPECT_LE(max_difference_db,
+            kMaxChangeSpeedDbPerSecond / 1000 * kFrameDurationMs);
+}
+
+class SaturationProtectorParametrization
+    : public ::testing::TestWithParam<int> {
+ protected:
+  int adjacent_speech_frames_threshold() const { return GetParam(); }
+};
+
+TEST_P(SaturationProtectorParametrization, DoNotAdaptToShortSpeechSegments) {
+  ApmDataDumper apm_data_dumper(0);
+  auto saturation_protector = CreateSaturationProtector(
+      kInitialHeadroomDb, kNoExtraHeadroomDb,
+      adjacent_speech_frames_threshold(), &apm_data_dumper);
+  const float initial_headroom_db = saturation_protector->HeadroomDb();
+  RunOnConstantLevel(/*num_iterations=*/adjacent_speech_frames_threshold() - 1,
+                     kMaxSpeechProbability,
+                     /*peak_dbfs=*/0.0f,
+                     /*speech_level_dbfs=*/-10.0f, *saturation_protector);
+  // No adaptation expected.
+  EXPECT_EQ(initial_headroom_db, saturation_protector->HeadroomDb());
+}
+
+TEST_P(SaturationProtectorParametrization, AdaptToEnoughSpeechSegments) {
+  ApmDataDumper apm_data_dumper(0);
+  auto saturation_protector = CreateSaturationProtector(
+      kInitialHeadroomDb, kNoExtraHeadroomDb,
+      adjacent_speech_frames_threshold(), &apm_data_dumper);
+  const float initial_headroom_db = saturation_protector->HeadroomDb();
+  RunOnConstantLevel(/*num_iterations=*/adjacent_speech_frames_threshold() + 1,
+                     kMaxSpeechProbability,
+                     /*peak_dbfs=*/0.0f,
+                     /*speech_level_dbfs=*/-10.0f, *saturation_protector);
+  // Adaptation expected.
+  EXPECT_NE(initial_headroom_db, saturation_protector->HeadroomDb());
+}
+
+INSTANTIATE_TEST_SUITE_P(GainController2,
+                         SaturationProtectorParametrization,
+                         ::testing::Values(2, 9, 17));
+
+}  // namespace
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/signal_classifier.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/signal_classifier.cc
new file mode 100644
index 0000000..3ef8dd7
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/signal_classifier.cc
@@ -0,0 +1,177 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/signal_classifier.h"
+
+#include <algorithm>
+#include <numeric>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/agc2/down_sampler.h"
+#include "modules/audio_processing/agc2/noise_spectrum_estimator.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/checks.h"
+#include "system_wrappers/include/cpu_features_wrapper.h"
+
+namespace webrtc {
+namespace {
+
+bool IsSse2Available() {
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+  return GetCPUInfo(kSSE2) != 0;
+#else
+  return false;
+#endif
+}
+
+void RemoveDcLevel(rtc::ArrayView<float> x) {
+  RTC_DCHECK_LT(0, x.size());
+  float mean = std::accumulate(x.data(), x.data() + x.size(), 0.f);
+  mean /= x.size();
+
+  for (float& v : x) {
+    v -= mean;
+  }
+}
+
+void PowerSpectrum(const OouraFft* ooura_fft,
+                   rtc::ArrayView<const float> x,
+                   rtc::ArrayView<float> spectrum) {
+  RTC_DCHECK_EQ(65, spectrum.size());
+  RTC_DCHECK_EQ(128, x.size());
+  float X[128];
+  std::copy(x.data(), x.data() + x.size(), X);
+  ooura_fft->Fft(X);
+
+  float* X_p = X;
+  RTC_DCHECK_EQ(X_p, &X[0]);
+  spectrum[0] = (*X_p) * (*X_p);
+  ++X_p;
+  RTC_DCHECK_EQ(X_p, &X[1]);
+  spectrum[64] = (*X_p) * (*X_p);
+  for (int k = 1; k < 64; ++k) {
+    ++X_p;
+    RTC_DCHECK_EQ(X_p, &X[2 * k]);
+    spectrum[k] = (*X_p) * (*X_p);
+    ++X_p;
+    RTC_DCHECK_EQ(X_p, &X[2 * k + 1]);
+    spectrum[k] += (*X_p) * (*X_p);
+  }
+}
+
+webrtc::SignalClassifier::SignalType ClassifySignal(
+    rtc::ArrayView<const float> signal_spectrum,
+    rtc::ArrayView<const float> noise_spectrum,
+    ApmDataDumper* data_dumper) {
+  int num_stationary_bands = 0;
+  int num_highly_nonstationary_bands = 0;
+
+  // Detect stationary and highly nonstationary bands.
+  for (size_t k = 1; k < 40; k++) {
+    if (signal_spectrum[k] < 3 * noise_spectrum[k] &&
+        signal_spectrum[k] * 3 > noise_spectrum[k]) {
+      ++num_stationary_bands;
+    } else if (signal_spectrum[k] > 9 * noise_spectrum[k]) {
+      ++num_highly_nonstationary_bands;
+    }
+  }
+
+  data_dumper->DumpRaw("agc2_num_stationary_bands", 1, &num_stationary_bands);
+  data_dumper->DumpRaw("agc2_num_highly_nonstationary_bands", 1,
+                       &num_highly_nonstationary_bands);
+
+  // Use the detected number of bands to classify the overall signal
+  // stationarity.
+  if (num_stationary_bands > 15) {
+    return SignalClassifier::SignalType::kStationary;
+  } else {
+    return SignalClassifier::SignalType::kNonStationary;
+  }
+}
+
+}  // namespace
+
+SignalClassifier::FrameExtender::FrameExtender(size_t frame_size,
+                                               size_t extended_frame_size)
+    : x_old_(extended_frame_size - frame_size, 0.f) {}
+
+SignalClassifier::FrameExtender::~FrameExtender() = default;
+
+void SignalClassifier::FrameExtender::ExtendFrame(
+    rtc::ArrayView<const float> x,
+    rtc::ArrayView<float> x_extended) {
+  RTC_DCHECK_EQ(x_old_.size() + x.size(), x_extended.size());
+  std::copy(x_old_.data(), x_old_.data() + x_old_.size(), x_extended.data());
+  std::copy(x.data(), x.data() + x.size(), x_extended.data() + x_old_.size());
+  std::copy(x_extended.data() + x_extended.size() - x_old_.size(),
+            x_extended.data() + x_extended.size(), x_old_.data());
+}
+
+SignalClassifier::SignalClassifier(ApmDataDumper* data_dumper)
+    : data_dumper_(data_dumper),
+      down_sampler_(data_dumper_),
+      noise_spectrum_estimator_(data_dumper_),
+      ooura_fft_(IsSse2Available()) {
+  Initialize(48000);
+}
+SignalClassifier::~SignalClassifier() {}
+
+void SignalClassifier::Initialize(int sample_rate_hz) {
+  down_sampler_.Initialize(sample_rate_hz);
+  noise_spectrum_estimator_.Initialize();
+  frame_extender_.reset(new FrameExtender(80, 128));
+  sample_rate_hz_ = sample_rate_hz;
+  initialization_frames_left_ = 2;
+  consistent_classification_counter_ = 3;
+  last_signal_type_ = SignalClassifier::SignalType::kNonStationary;
+}
+
+SignalClassifier::SignalType SignalClassifier::Analyze(
+    rtc::ArrayView<const float> signal) {
+  RTC_DCHECK_EQ(signal.size(), sample_rate_hz_ / 100);
+
+  // Compute the signal power spectrum.
+  float downsampled_frame[80];
+  down_sampler_.DownSample(signal, downsampled_frame);
+  float extended_frame[128];
+  frame_extender_->ExtendFrame(downsampled_frame, extended_frame);
+  RemoveDcLevel(extended_frame);
+  float signal_spectrum[65];
+  PowerSpectrum(&ooura_fft_, extended_frame, signal_spectrum);
+
+  // Classify the signal based on the estimate of the noise spectrum and the
+  // signal spectrum estimate.
+  const SignalType signal_type = ClassifySignal(
+      signal_spectrum, noise_spectrum_estimator_.GetNoiseSpectrum(),
+      data_dumper_);
+
+  // Update the noise spectrum based on the signal spectrum.
+  noise_spectrum_estimator_.Update(signal_spectrum,
+                                   initialization_frames_left_ > 0);
+
+  // Update the number of frames until a reliable signal spectrum is achieved.
+  initialization_frames_left_ = std::max(0, initialization_frames_left_ - 1);
+
+  if (last_signal_type_ == signal_type) {
+    consistent_classification_counter_ =
+        std::max(0, consistent_classification_counter_ - 1);
+  } else {
+    last_signal_type_ = signal_type;
+    consistent_classification_counter_ = 3;
+  }
+
+  if (consistent_classification_counter_ > 0) {
+    return SignalClassifier::SignalType::kNonStationary;
+  }
+  return signal_type;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/signal_classifier.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/signal_classifier.h
new file mode 100644
index 0000000..20cce92
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/signal_classifier.h
@@ -0,0 +1,73 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_SIGNAL_CLASSIFIER_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_SIGNAL_CLASSIFIER_H_
+
+#include <memory>
+#include <vector>
+
+#include "api/array_view.h"
+#include "common_audio/third_party/ooura/fft_size_128/ooura_fft.h"
+#include "modules/audio_processing/agc2/down_sampler.h"
+#include "modules/audio_processing/agc2/noise_spectrum_estimator.h"
+
+namespace webrtc {
+
+class ApmDataDumper;
+class AudioBuffer;
+
+class SignalClassifier {
+ public:
+  enum class SignalType { kNonStationary, kStationary };
+
+  explicit SignalClassifier(ApmDataDumper* data_dumper);
+
+  SignalClassifier() = delete;
+  SignalClassifier(const SignalClassifier&) = delete;
+  SignalClassifier& operator=(const SignalClassifier&) = delete;
+
+  ~SignalClassifier();
+
+  void Initialize(int sample_rate_hz);
+  SignalType Analyze(rtc::ArrayView<const float> signal);
+
+ private:
+  class FrameExtender {
+   public:
+    FrameExtender(size_t frame_size, size_t extended_frame_size);
+
+    FrameExtender() = delete;
+    FrameExtender(const FrameExtender&) = delete;
+    FrameExtender& operator=(const FrameExtender&) = delete;
+
+    ~FrameExtender();
+
+    void ExtendFrame(rtc::ArrayView<const float> x,
+                     rtc::ArrayView<float> x_extended);
+
+   private:
+    std::vector<float> x_old_;
+  };
+
+  ApmDataDumper* const data_dumper_;
+  DownSampler down_sampler_;
+  std::unique_ptr<FrameExtender> frame_extender_;
+  NoiseSpectrumEstimator noise_spectrum_estimator_;
+  int sample_rate_hz_;
+  int initialization_frames_left_;
+  int consistent_classification_counter_;
+  SignalType last_signal_type_;
+  const OouraFft ooura_fft_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_SIGNAL_CLASSIFIER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/signal_classifier_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/signal_classifier_unittest.cc
new file mode 100644
index 0000000..f1a3a66
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/signal_classifier_unittest.cc
@@ -0,0 +1,86 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/signal_classifier.h"
+
+#include <array>
+#include <functional>
+#include <limits>
+
+#include "api/function_view.h"
+#include "modules/audio_processing/agc2/agc2_testing_common.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/gunit.h"
+#include "rtc_base/random.h"
+
+namespace webrtc {
+namespace {
+constexpr int kNumIterations = 100;
+
+// Runs the signal classifier on audio generated by 'sample_generator'
+// for kNumIterations. Returns the number of frames classified as noise.
+float RunClassifier(rtc::FunctionView<float()> sample_generator,
+                    int sample_rate_hz) {
+  ApmDataDumper data_dumper(0);
+  SignalClassifier classifier(&data_dumper);
+  std::array<float, 480> signal;
+  classifier.Initialize(sample_rate_hz);
+  const size_t samples_per_channel = rtc::CheckedDivExact(sample_rate_hz, 100);
+  int number_of_noise_frames = 0;
+  for (int i = 0; i < kNumIterations; ++i) {
+    for (size_t j = 0; j < samples_per_channel; ++j) {
+      signal[j] = sample_generator();
+    }
+    number_of_noise_frames +=
+        classifier.Analyze({&signal[0], samples_per_channel}) ==
+        SignalClassifier::SignalType::kStationary;
+  }
+  return number_of_noise_frames;
+}
+
+class SignalClassifierParametrization : public ::testing::TestWithParam<int> {
+ protected:
+  int sample_rate_hz() const { return GetParam(); }
+};
+
+// White random noise is stationary, but does not trigger the detector
+// every frame due to the randomness.
+TEST_P(SignalClassifierParametrization, WhiteNoise) {
+  test::WhiteNoiseGenerator gen(/*min_amplitude=*/test::kMinS16,
+                                /*max_amplitude=*/test::kMaxS16);
+  const int number_of_noise_frames = RunClassifier(gen, sample_rate_hz());
+  EXPECT_GT(number_of_noise_frames, kNumIterations / 2);
+}
+
+// Sine curves are (very) stationary. They trigger the detector all
+// the time. Except for a few initial frames.
+TEST_P(SignalClassifierParametrization, SineTone) {
+  test::SineGenerator gen(/*amplitude=*/test::kMaxS16, /*frequency_hz=*/600.0f,
+                          sample_rate_hz());
+  const int number_of_noise_frames = RunClassifier(gen, sample_rate_hz());
+  EXPECT_GE(number_of_noise_frames, kNumIterations - 5);
+}
+
+// Pulses are transient if they are far enough apart. They shouldn't
+// trigger the noise detector.
+TEST_P(SignalClassifierParametrization, PulseTone) {
+  test::PulseGenerator gen(/*pulse_amplitude=*/test::kMaxS16,
+                           /*no_pulse_amplitude=*/10.0f, /*frequency_hz=*/20.0f,
+                           sample_rate_hz());
+  const int number_of_noise_frames = RunClassifier(gen, sample_rate_hz());
+  EXPECT_EQ(number_of_noise_frames, 0);
+}
+
+INSTANTIATE_TEST_SUITE_P(GainController2SignalClassifier,
+                         SignalClassifierParametrization,
+                         ::testing::Values(8000, 16000, 32000, 48000));
+
+}  // namespace
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/vad_with_level.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/vad_with_level.cc
new file mode 100644
index 0000000..034f2b6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/vad_with_level.cc
@@ -0,0 +1,111 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/vad_with_level.h"
+
+#include <algorithm>
+#include <array>
+#include <cmath>
+
+#include "api/array_view.h"
+#include "common_audio/include/audio_util.h"
+#include "common_audio/resampler/include/push_resampler.h"
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "modules/audio_processing/agc2/rnn_vad/common.h"
+#include "modules/audio_processing/agc2/rnn_vad/features_extraction.h"
+#include "modules/audio_processing/agc2/rnn_vad/rnn.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+
+using VoiceActivityDetector = VadLevelAnalyzer::VoiceActivityDetector;
+
+// Default VAD that combines a resampler and the RNN VAD.
+// Computes the speech probability on the first channel.
+class Vad : public VoiceActivityDetector {
+ public:
+  explicit Vad(const AvailableCpuFeatures& cpu_features)
+      : features_extractor_(cpu_features), rnn_vad_(cpu_features) {}
+  Vad(const Vad&) = delete;
+  Vad& operator=(const Vad&) = delete;
+  ~Vad() = default;
+
+  void Reset() override { rnn_vad_.Reset(); }
+
+  float ComputeProbability(AudioFrameView<const float> frame) override {
+    // The source number of channels is 1, because we always use the 1st
+    // channel.
+    resampler_.InitializeIfNeeded(
+        /*sample_rate_hz=*/static_cast<int>(frame.samples_per_channel() * 100),
+        rnn_vad::kSampleRate24kHz,
+        /*num_channels=*/1);
+
+    std::array<float, rnn_vad::kFrameSize10ms24kHz> work_frame;
+    // Feed the 1st channel to the resampler.
+    resampler_.Resample(frame.channel(0).data(), frame.samples_per_channel(),
+                        work_frame.data(), rnn_vad::kFrameSize10ms24kHz);
+
+    std::array<float, rnn_vad::kFeatureVectorSize> feature_vector;
+    const bool is_silence = features_extractor_.CheckSilenceComputeFeatures(
+        work_frame, feature_vector);
+    return rnn_vad_.ComputeVadProbability(feature_vector, is_silence);
+  }
+
+ private:
+  PushResampler<float> resampler_;
+  rnn_vad::FeaturesExtractor features_extractor_;
+  rnn_vad::RnnVad rnn_vad_;
+};
+
+}  // namespace
+
+VadLevelAnalyzer::VadLevelAnalyzer()
+    : VadLevelAnalyzer(kDefaultVadRnnResetPeriodMs, GetAvailableCpuFeatures()) {
+}
+
+VadLevelAnalyzer::VadLevelAnalyzer(int vad_reset_period_ms,
+                                   const AvailableCpuFeatures& cpu_features)
+    : VadLevelAnalyzer(vad_reset_period_ms,
+                       std::make_unique<Vad>(cpu_features)) {}
+
+VadLevelAnalyzer::VadLevelAnalyzer(int vad_reset_period_ms,
+                                   std::unique_ptr<VoiceActivityDetector> vad)
+    : vad_(std::move(vad)),
+      vad_reset_period_frames_(
+          rtc::CheckedDivExact(vad_reset_period_ms, kFrameDurationMs)),
+      time_to_vad_reset_(vad_reset_period_frames_) {
+  RTC_DCHECK(vad_);
+  RTC_DCHECK_GT(vad_reset_period_frames_, 1);
+}
+
+VadLevelAnalyzer::~VadLevelAnalyzer() = default;
+
+VadLevelAnalyzer::Result VadLevelAnalyzer::AnalyzeFrame(
+    AudioFrameView<const float> frame) {
+  // Periodically reset the VAD.
+  time_to_vad_reset_--;
+  if (time_to_vad_reset_ <= 0) {
+    vad_->Reset();
+    time_to_vad_reset_ = vad_reset_period_frames_;
+  }
+  // Compute levels.
+  float peak = 0.0f;
+  float rms = 0.0f;
+  for (const auto& x : frame.channel(0)) {
+    peak = std::max(std::fabs(x), peak);
+    rms += x * x;
+  }
+  return {vad_->ComputeProbability(frame),
+          FloatS16ToDbfs(std::sqrt(rms / frame.samples_per_channel())),
+          FloatS16ToDbfs(peak)};
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/vad_with_level.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/vad_with_level.h
new file mode 100644
index 0000000..7cd93d6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/vad_with_level.h
@@ -0,0 +1,66 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_VAD_WITH_LEVEL_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_VAD_WITH_LEVEL_H_
+
+#include <memory>
+
+#include "modules/audio_processing/agc2/cpu_features.h"
+#include "modules/audio_processing/include/audio_frame_view.h"
+
+namespace webrtc {
+
+// Class to analyze voice activity and audio levels.
+class VadLevelAnalyzer {
+ public:
+  struct Result {
+    float speech_probability;  // Range: [0, 1].
+    float rms_dbfs;            // Root mean square power (dBFS).
+    float peak_dbfs;           // Peak power (dBFS).
+  };
+
+  // Voice Activity Detector (VAD) interface.
+  class VoiceActivityDetector {
+   public:
+    virtual ~VoiceActivityDetector() = default;
+    // Resets the internal state.
+    virtual void Reset() = 0;
+    // Analyzes an audio frame and returns the speech probability.
+    virtual float ComputeProbability(AudioFrameView<const float> frame) = 0;
+  };
+
+  // Ctor. Uses the default VAD with the default settings.
+  VadLevelAnalyzer();
+  // Ctor. `vad_reset_period_ms` indicates the period in milliseconds to call
+  // `VadLevelAnalyzer::Reset()`; it must be equal to or greater than the
+  // duration of two frames. Uses `cpu_features` to instantiate the default VAD.
+  VadLevelAnalyzer(int vad_reset_period_ms,
+                   const AvailableCpuFeatures& cpu_features);
+  // Ctor. Uses a custom `vad`.
+  VadLevelAnalyzer(int vad_reset_period_ms,
+                   std::unique_ptr<VoiceActivityDetector> vad);
+
+  VadLevelAnalyzer(const VadLevelAnalyzer&) = delete;
+  VadLevelAnalyzer& operator=(const VadLevelAnalyzer&) = delete;
+  ~VadLevelAnalyzer();
+
+  // Computes the speech probability and the level for `frame`.
+  Result AnalyzeFrame(AudioFrameView<const float> frame);
+
+ private:
+  std::unique_ptr<VoiceActivityDetector> vad_;
+  const int vad_reset_period_frames_;
+  int time_to_vad_reset_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_VAD_WITH_LEVEL_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/vad_with_level_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/vad_with_level_unittest.cc
new file mode 100644
index 0000000..99b0136
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/vad_with_level_unittest.cc
@@ -0,0 +1,139 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/vad_with_level.h"
+
+#include <limits>
+#include <memory>
+#include <vector>
+
+#include "modules/audio_processing/agc2/agc2_common.h"
+#include "modules/audio_processing/include/audio_frame_view.h"
+#include "rtc_base/gunit.h"
+#include "rtc_base/numerics/safe_compare.h"
+#include "test/gmock.h"
+
+namespace webrtc {
+namespace {
+
+using ::testing::AnyNumber;
+using ::testing::ReturnRoundRobin;
+
+constexpr int kNoVadPeriodicReset =
+    kFrameDurationMs * (std::numeric_limits<int>::max() / kFrameDurationMs);
+
+constexpr int kSampleRateHz = 8000;
+
+class MockVad : public VadLevelAnalyzer::VoiceActivityDetector {
+ public:
+  MOCK_METHOD(void, Reset, (), (override));
+  MOCK_METHOD(float,
+              ComputeProbability,
+              (AudioFrameView<const float> frame),
+              (override));
+};
+
+// Creates a `VadLevelAnalyzer` injecting a mock VAD which repeatedly returns
+// the next value from `speech_probabilities` until it reaches the end and will
+// restart from the beginning.
+std::unique_ptr<VadLevelAnalyzer> CreateVadLevelAnalyzerWithMockVad(
+    int vad_reset_period_ms,
+    const std::vector<float>& speech_probabilities,
+    int expected_vad_reset_calls = 0) {
+  auto vad = std::make_unique<MockVad>();
+  EXPECT_CALL(*vad, ComputeProbability)
+      .Times(AnyNumber())
+      .WillRepeatedly(ReturnRoundRobin(speech_probabilities));
+  if (expected_vad_reset_calls >= 0) {
+    EXPECT_CALL(*vad, Reset).Times(expected_vad_reset_calls);
+  }
+  return std::make_unique<VadLevelAnalyzer>(vad_reset_period_ms,
+                                            std::move(vad));
+}
+
+// 10 ms mono frame.
+struct FrameWithView {
+  // Ctor. Initializes the frame samples with `value`.
+  FrameWithView(float value = 0.0f)
+      : channel0(samples.data()),
+        view(&channel0, /*num_channels=*/1, samples.size()) {
+    samples.fill(value);
+  }
+  std::array<float, kSampleRateHz / 100> samples;
+  const float* const channel0;
+  const AudioFrameView<const float> view;
+};
+
+TEST(GainController2VadLevelAnalyzer, PeakLevelGreaterThanRmsLevel) {
+  // Handcrafted frame so that the average is lower than the peak value.
+  FrameWithView frame(1000.0f);  // Constant frame.
+  frame.samples[10] = 2000.0f;   // Except for one peak value.
+
+  // Compute audio frame levels (the VAD result is ignored).
+  VadLevelAnalyzer analyzer;
+  auto levels_and_vad_prob = analyzer.AnalyzeFrame(frame.view);
+
+  // Compare peak and RMS levels.
+  EXPECT_LT(levels_and_vad_prob.rms_dbfs, levels_and_vad_prob.peak_dbfs);
+}
+
+// Checks that the expect VAD probabilities are returned.
+TEST(GainController2VadLevelAnalyzer, NoSpeechProbabilitySmoothing) {
+  const std::vector<float> speech_probabilities{0.709f, 0.484f, 0.882f, 0.167f,
+                                                0.44f,  0.525f, 0.858f, 0.314f,
+                                                0.653f, 0.965f, 0.413f, 0.0f};
+  auto analyzer = CreateVadLevelAnalyzerWithMockVad(kNoVadPeriodicReset,
+                                                    speech_probabilities);
+  FrameWithView frame;
+  for (int i = 0; rtc::SafeLt(i, speech_probabilities.size()); ++i) {
+    SCOPED_TRACE(i);
+    EXPECT_EQ(speech_probabilities[i],
+              analyzer->AnalyzeFrame(frame.view).speech_probability);
+  }
+}
+
+// Checks that the VAD is not periodically reset.
+TEST(GainController2VadLevelAnalyzer, VadNoPeriodicReset) {
+  constexpr int kNumFrames = 19;
+  auto analyzer = CreateVadLevelAnalyzerWithMockVad(
+      kNoVadPeriodicReset, /*speech_probabilities=*/{1.0f},
+      /*expected_vad_reset_calls=*/0);
+  FrameWithView frame;
+  for (int i = 0; i < kNumFrames; ++i) {
+    analyzer->AnalyzeFrame(frame.view);
+  }
+}
+
+class VadPeriodResetParametrization
+    : public ::testing::TestWithParam<std::tuple<int, int>> {
+ protected:
+  int num_frames() const { return std::get<0>(GetParam()); }
+  int vad_reset_period_frames() const { return std::get<1>(GetParam()); }
+};
+
+// Checks that the VAD is periodically reset with the expected period.
+TEST_P(VadPeriodResetParametrization, VadPeriodicReset) {
+  auto analyzer = CreateVadLevelAnalyzerWithMockVad(
+      /*vad_reset_period_ms=*/vad_reset_period_frames() * kFrameDurationMs,
+      /*speech_probabilities=*/{1.0f},
+      /*expected_vad_reset_calls=*/num_frames() / vad_reset_period_frames());
+  FrameWithView frame;
+  for (int i = 0; i < num_frames(); ++i) {
+    analyzer->AnalyzeFrame(frame.view);
+  }
+}
+
+INSTANTIATE_TEST_SUITE_P(GainController2VadLevelAnalyzer,
+                         VadPeriodResetParametrization,
+                         ::testing::Combine(::testing::Values(1, 19, 123),
+                                            ::testing::Values(2, 5, 20, 53)));
+
+}  // namespace
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/vector_float_frame.cc b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/vector_float_frame.cc
new file mode 100644
index 0000000..a70d815
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/vector_float_frame.cc
@@ -0,0 +1,39 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/agc2/vector_float_frame.h"
+
+namespace webrtc {
+
+namespace {
+
+std::vector<float*> ConstructChannelPointers(
+    std::vector<std::vector<float>>* x) {
+  std::vector<float*> channel_ptrs;
+  for (auto& v : *x) {
+    channel_ptrs.push_back(v.data());
+  }
+  return channel_ptrs;
+}
+}  // namespace
+
+VectorFloatFrame::VectorFloatFrame(int num_channels,
+                                   int samples_per_channel,
+                                   float start_value)
+    : channels_(num_channels,
+                std::vector<float>(samples_per_channel, start_value)),
+      channel_ptrs_(ConstructChannelPointers(&channels_)),
+      float_frame_view_(channel_ptrs_.data(),
+                        channels_.size(),
+                        samples_per_channel) {}
+
+VectorFloatFrame::~VectorFloatFrame() = default;
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/agc2/vector_float_frame.h b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/vector_float_frame.h
new file mode 100644
index 0000000..b521f34
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/agc2/vector_float_frame.h
@@ -0,0 +1,42 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AGC2_VECTOR_FLOAT_FRAME_H_
+#define MODULES_AUDIO_PROCESSING_AGC2_VECTOR_FLOAT_FRAME_H_
+
+#include <vector>
+
+#include "modules/audio_processing/include/audio_frame_view.h"
+
+namespace webrtc {
+
+// A construct consisting of a multi-channel audio frame, and a FloatFrame view
+// of it.
+class VectorFloatFrame {
+ public:
+  VectorFloatFrame(int num_channels,
+                   int samples_per_channel,
+                   float start_value);
+  const AudioFrameView<float>& float_frame_view() { return float_frame_view_; }
+  AudioFrameView<const float> float_frame_view() const {
+    return float_frame_view_;
+  }
+
+  ~VectorFloatFrame();
+
+ private:
+  std::vector<std::vector<float>> channels_;
+  std::vector<float*> channel_ptrs_;
+  AudioFrameView<float> float_frame_view_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AGC2_VECTOR_FLOAT_FRAME_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/audio_buffer.cc b/third_party/webrtc_aec3/src/modules/audio_processing/audio_buffer.cc
new file mode 100644
index 0000000..ff6636d
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/audio_buffer.cc
@@ -0,0 +1,407 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/audio_buffer.h"
+
+#include <string.h>
+
+#include <cstdint>
+
+#include "common_audio/channel_buffer.h"
+#include "common_audio/include/audio_util.h"
+#include "common_audio/resampler/push_sinc_resampler.h"
+#include "modules/audio_processing/splitting_filter.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+
+constexpr size_t kSamplesPer32kHzChannel = 320;
+constexpr size_t kSamplesPer48kHzChannel = 480;
+constexpr size_t kMaxSamplesPerChannel = AudioBuffer::kMaxSampleRate / 100;
+
+size_t NumBandsFromFramesPerChannel(size_t num_frames) {
+  if (num_frames == kSamplesPer32kHzChannel) {
+    return 2;
+  }
+  if (num_frames == kSamplesPer48kHzChannel) {
+    return 3;
+  }
+  return 1;
+}
+
+}  // namespace
+
+AudioBuffer::AudioBuffer(size_t input_rate,
+                         size_t input_num_channels,
+                         size_t buffer_rate,
+                         size_t buffer_num_channels,
+                         size_t output_rate,
+                         size_t output_num_channels)
+    : AudioBuffer(static_cast<int>(input_rate) / 100,
+                  input_num_channels,
+                  static_cast<int>(buffer_rate) / 100,
+                  buffer_num_channels,
+                  static_cast<int>(output_rate) / 100) {}
+
+AudioBuffer::AudioBuffer(size_t input_num_frames,
+                         size_t input_num_channels,
+                         size_t buffer_num_frames,
+                         size_t buffer_num_channels,
+                         size_t output_num_frames)
+    : input_num_frames_(input_num_frames),
+      input_num_channels_(input_num_channels),
+      buffer_num_frames_(buffer_num_frames),
+      buffer_num_channels_(buffer_num_channels),
+      output_num_frames_(output_num_frames),
+      output_num_channels_(0),
+      num_channels_(buffer_num_channels),
+      num_bands_(NumBandsFromFramesPerChannel(buffer_num_frames_)),
+      num_split_frames_(rtc::CheckedDivExact(buffer_num_frames_, num_bands_)),
+      data_(
+          new ChannelBuffer<float>(buffer_num_frames_, buffer_num_channels_)) {
+  RTC_DCHECK_GT(input_num_frames_, 0);
+  RTC_DCHECK_GT(buffer_num_frames_, 0);
+  RTC_DCHECK_GT(output_num_frames_, 0);
+  RTC_DCHECK_GT(input_num_channels_, 0);
+  RTC_DCHECK_GT(buffer_num_channels_, 0);
+  RTC_DCHECK_LE(buffer_num_channels_, input_num_channels_);
+
+  const bool input_resampling_needed = input_num_frames_ != buffer_num_frames_;
+  const bool output_resampling_needed =
+      output_num_frames_ != buffer_num_frames_;
+  if (input_resampling_needed) {
+    for (size_t i = 0; i < buffer_num_channels_; ++i) {
+      input_resamplers_.push_back(std::unique_ptr<PushSincResampler>(
+          new PushSincResampler(input_num_frames_, buffer_num_frames_)));
+    }
+  }
+
+  if (output_resampling_needed) {
+    for (size_t i = 0; i < buffer_num_channels_; ++i) {
+      output_resamplers_.push_back(std::unique_ptr<PushSincResampler>(
+          new PushSincResampler(buffer_num_frames_, output_num_frames_)));
+    }
+  }
+
+  if (num_bands_ > 1) {
+    split_data_.reset(new ChannelBuffer<float>(
+        buffer_num_frames_, buffer_num_channels_, num_bands_));
+    splitting_filter_.reset(new SplittingFilter(
+        buffer_num_channels_, num_bands_, buffer_num_frames_));
+  }
+}
+
+AudioBuffer::~AudioBuffer() {}
+
+void AudioBuffer::set_downmixing_to_specific_channel(size_t channel) {
+  downmix_by_averaging_ = false;
+  RTC_DCHECK_GT(input_num_channels_, channel);
+  channel_for_downmixing_ = std::min(channel, input_num_channels_ - 1);
+}
+
+void AudioBuffer::set_downmixing_by_averaging() {
+  downmix_by_averaging_ = true;
+}
+
+void AudioBuffer::CopyFrom(const float* const* stacked_data,
+                           const StreamConfig& stream_config) {
+  RTC_DCHECK_EQ(stream_config.num_frames(), input_num_frames_);
+  RTC_DCHECK_EQ(stream_config.num_channels(), input_num_channels_);
+  RestoreNumChannels();
+  const bool downmix_needed = input_num_channels_ > 1 && num_channels_ == 1;
+
+  const bool resampling_needed = input_num_frames_ != buffer_num_frames_;
+
+  if (downmix_needed) {
+    RTC_DCHECK_GE(kMaxSamplesPerChannel, input_num_frames_);
+
+    std::array<float, kMaxSamplesPerChannel> downmix;
+    if (downmix_by_averaging_) {
+      const float kOneByNumChannels = 1.f / input_num_channels_;
+      for (size_t i = 0; i < input_num_frames_; ++i) {
+        float value = stacked_data[0][i];
+        for (size_t j = 1; j < input_num_channels_; ++j) {
+          value += stacked_data[j][i];
+        }
+        downmix[i] = value * kOneByNumChannels;
+      }
+    }
+    const float* downmixed_data = downmix_by_averaging_
+                                      ? downmix.data()
+                                      : stacked_data[channel_for_downmixing_];
+
+    if (resampling_needed) {
+      input_resamplers_[0]->Resample(downmixed_data, input_num_frames_,
+                                     data_->channels()[0], buffer_num_frames_);
+    }
+    const float* data_to_convert =
+        resampling_needed ? data_->channels()[0] : downmixed_data;
+    FloatToFloatS16(data_to_convert, buffer_num_frames_, data_->channels()[0]);
+  } else {
+    if (resampling_needed) {
+      for (size_t i = 0; i < num_channels_; ++i) {
+        input_resamplers_[i]->Resample(stacked_data[i], input_num_frames_,
+                                       data_->channels()[i],
+                                       buffer_num_frames_);
+        FloatToFloatS16(data_->channels()[i], buffer_num_frames_,
+                        data_->channels()[i]);
+      }
+    } else {
+      for (size_t i = 0; i < num_channels_; ++i) {
+        FloatToFloatS16(stacked_data[i], buffer_num_frames_,
+                        data_->channels()[i]);
+      }
+    }
+  }
+}
+
+void AudioBuffer::CopyTo(const StreamConfig& stream_config,
+                         float* const* stacked_data) {
+  RTC_DCHECK_EQ(stream_config.num_frames(), output_num_frames_);
+
+  const bool resampling_needed = output_num_frames_ != buffer_num_frames_;
+  if (resampling_needed) {
+    for (size_t i = 0; i < num_channels_; ++i) {
+      FloatS16ToFloat(data_->channels()[i], buffer_num_frames_,
+                      data_->channels()[i]);
+      output_resamplers_[i]->Resample(data_->channels()[i], buffer_num_frames_,
+                                      stacked_data[i], output_num_frames_);
+    }
+  } else {
+    for (size_t i = 0; i < num_channels_; ++i) {
+      FloatS16ToFloat(data_->channels()[i], buffer_num_frames_,
+                      stacked_data[i]);
+    }
+  }
+
+  for (size_t i = num_channels_; i < stream_config.num_channels(); ++i) {
+    memcpy(stacked_data[i], stacked_data[0],
+           output_num_frames_ * sizeof(**stacked_data));
+  }
+}
+
+void AudioBuffer::CopyTo(AudioBuffer* buffer) const {
+  RTC_DCHECK_EQ(buffer->num_frames(), output_num_frames_);
+
+  const bool resampling_needed = output_num_frames_ != buffer_num_frames_;
+  if (resampling_needed) {
+    for (size_t i = 0; i < num_channels_; ++i) {
+      output_resamplers_[i]->Resample(data_->channels()[i], buffer_num_frames_,
+                                      buffer->channels()[i],
+                                      buffer->num_frames());
+    }
+  } else {
+    for (size_t i = 0; i < num_channels_; ++i) {
+      memcpy(buffer->channels()[i], data_->channels()[i],
+             buffer_num_frames_ * sizeof(**buffer->channels()));
+    }
+  }
+
+  for (size_t i = num_channels_; i < buffer->num_channels(); ++i) {
+    memcpy(buffer->channels()[i], buffer->channels()[0],
+           output_num_frames_ * sizeof(**buffer->channels()));
+  }
+}
+
+void AudioBuffer::RestoreNumChannels() {
+  num_channels_ = buffer_num_channels_;
+  data_->set_num_channels(buffer_num_channels_);
+  if (split_data_.get()) {
+    split_data_->set_num_channels(buffer_num_channels_);
+  }
+}
+
+void AudioBuffer::set_num_channels(size_t num_channels) {
+  RTC_DCHECK_GE(buffer_num_channels_, num_channels);
+  num_channels_ = num_channels;
+  data_->set_num_channels(num_channels);
+  if (split_data_.get()) {
+    split_data_->set_num_channels(num_channels);
+  }
+}
+
+// The resampler is only for supporting 48kHz to 16kHz in the reverse stream.
+void AudioBuffer::CopyFrom(const int16_t* const interleaved_data,
+                           const StreamConfig& stream_config) {
+  RTC_DCHECK_EQ(stream_config.num_channels(), input_num_channels_);
+  RTC_DCHECK_EQ(stream_config.num_frames(), input_num_frames_);
+  RestoreNumChannels();
+
+  const bool resampling_required = input_num_frames_ != buffer_num_frames_;
+
+  const int16_t* interleaved = interleaved_data;
+  if (num_channels_ == 1) {
+    if (input_num_channels_ == 1) {
+      if (resampling_required) {
+        std::array<float, kMaxSamplesPerChannel> float_buffer;
+        S16ToFloatS16(interleaved, input_num_frames_, float_buffer.data());
+        input_resamplers_[0]->Resample(float_buffer.data(), input_num_frames_,
+                                       data_->channels()[0],
+                                       buffer_num_frames_);
+      } else {
+        S16ToFloatS16(interleaved, input_num_frames_, data_->channels()[0]);
+      }
+    } else {
+      std::array<float, kMaxSamplesPerChannel> float_buffer;
+      float* downmixed_data =
+          resampling_required ? float_buffer.data() : data_->channels()[0];
+      if (downmix_by_averaging_) {
+        for (size_t j = 0, k = 0; j < input_num_frames_; ++j) {
+          int32_t sum = 0;
+          for (size_t i = 0; i < input_num_channels_; ++i, ++k) {
+            sum += interleaved[k];
+          }
+          downmixed_data[j] = sum / static_cast<int16_t>(input_num_channels_);
+        }
+      } else {
+        for (size_t j = 0, k = channel_for_downmixing_; j < input_num_frames_;
+             ++j, k += input_num_channels_) {
+          downmixed_data[j] = interleaved[k];
+        }
+      }
+
+      if (resampling_required) {
+        input_resamplers_[0]->Resample(downmixed_data, input_num_frames_,
+                                       data_->channels()[0],
+                                       buffer_num_frames_);
+      }
+    }
+  } else {
+    auto deinterleave_channel = [](size_t channel, size_t num_channels,
+                                   size_t samples_per_channel, const int16_t* x,
+                                   float* y) {
+      for (size_t j = 0, k = channel; j < samples_per_channel;
+           ++j, k += num_channels) {
+        y[j] = x[k];
+      }
+    };
+
+    if (resampling_required) {
+      std::array<float, kMaxSamplesPerChannel> float_buffer;
+      for (size_t i = 0; i < num_channels_; ++i) {
+        deinterleave_channel(i, num_channels_, input_num_frames_, interleaved,
+                             float_buffer.data());
+        input_resamplers_[i]->Resample(float_buffer.data(), input_num_frames_,
+                                       data_->channels()[i],
+                                       buffer_num_frames_);
+      }
+    } else {
+      for (size_t i = 0; i < num_channels_; ++i) {
+        deinterleave_channel(i, num_channels_, input_num_frames_, interleaved,
+                             data_->channels()[i]);
+      }
+    }
+  }
+}
+
+void AudioBuffer::CopyTo(const StreamConfig& stream_config,
+                         int16_t* const interleaved_data) {
+  const size_t config_num_channels = stream_config.num_channels();
+
+  RTC_DCHECK(config_num_channels == num_channels_ || num_channels_ == 1);
+  RTC_DCHECK_EQ(stream_config.num_frames(), output_num_frames_);
+
+  const bool resampling_required = buffer_num_frames_ != output_num_frames_;
+
+  int16_t* interleaved = interleaved_data;
+  if (num_channels_ == 1) {
+    std::array<float, kMaxSamplesPerChannel> float_buffer;
+
+    if (resampling_required) {
+      output_resamplers_[0]->Resample(data_->channels()[0], buffer_num_frames_,
+                                      float_buffer.data(), output_num_frames_);
+    }
+    const float* deinterleaved =
+        resampling_required ? float_buffer.data() : data_->channels()[0];
+
+    if (config_num_channels == 1) {
+      for (size_t j = 0; j < output_num_frames_; ++j) {
+        interleaved[j] = FloatS16ToS16(deinterleaved[j]);
+      }
+    } else {
+      for (size_t i = 0, k = 0; i < output_num_frames_; ++i) {
+        float tmp = FloatS16ToS16(deinterleaved[i]);
+        for (size_t j = 0; j < config_num_channels; ++j, ++k) {
+          interleaved[k] = tmp;
+        }
+      }
+    }
+  } else {
+    auto interleave_channel = [](size_t channel, size_t num_channels,
+                                 size_t samples_per_channel, const float* x,
+                                 int16_t* y) {
+      for (size_t k = 0, j = channel; k < samples_per_channel;
+           ++k, j += num_channels) {
+        y[j] = FloatS16ToS16(x[k]);
+      }
+    };
+
+    if (resampling_required) {
+      for (size_t i = 0; i < num_channels_; ++i) {
+        std::array<float, kMaxSamplesPerChannel> float_buffer;
+        output_resamplers_[i]->Resample(data_->channels()[i],
+                                        buffer_num_frames_, float_buffer.data(),
+                                        output_num_frames_);
+        interleave_channel(i, config_num_channels, output_num_frames_,
+                           float_buffer.data(), interleaved);
+      }
+    } else {
+      for (size_t i = 0; i < num_channels_; ++i) {
+        interleave_channel(i, config_num_channels, output_num_frames_,
+                           data_->channels()[i], interleaved);
+      }
+    }
+
+    for (size_t i = num_channels_; i < config_num_channels; ++i) {
+      for (size_t j = 0, k = i, n = num_channels_; j < output_num_frames_;
+           ++j, k += config_num_channels, n += config_num_channels) {
+        interleaved[k] = interleaved[n];
+      }
+    }
+  }
+}
+
+void AudioBuffer::SplitIntoFrequencyBands() {
+  splitting_filter_->Analysis(data_.get(), split_data_.get());
+}
+
+void AudioBuffer::MergeFrequencyBands() {
+  splitting_filter_->Synthesis(split_data_.get(), data_.get());
+}
+
+void AudioBuffer::ExportSplitChannelData(
+    size_t channel,
+    int16_t* const* split_band_data) const {
+  for (size_t k = 0; k < num_bands(); ++k) {
+    const float* band_data = split_bands_const(channel)[k];
+
+    RTC_DCHECK(split_band_data[k]);
+    RTC_DCHECK(band_data);
+    for (size_t i = 0; i < num_frames_per_band(); ++i) {
+      split_band_data[k][i] = FloatS16ToS16(band_data[i]);
+    }
+  }
+}
+
+void AudioBuffer::ImportSplitChannelData(
+    size_t channel,
+    const int16_t* const* split_band_data) {
+  for (size_t k = 0; k < num_bands(); ++k) {
+    float* band_data = split_bands(channel)[k];
+    RTC_DCHECK(split_band_data[k]);
+    RTC_DCHECK(band_data);
+    for (size_t i = 0; i < num_frames_per_band(); ++i) {
+      band_data[i] = split_band_data[k][i];
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/audio_buffer.h b/third_party/webrtc_aec3/src/modules/audio_processing/audio_buffer.h
new file mode 100644
index 0000000..3eecf0d
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/audio_buffer.h
@@ -0,0 +1,178 @@
+/*
+ *  Copyright (c) 2011 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_AUDIO_BUFFER_H_
+#define MODULES_AUDIO_PROCESSING_AUDIO_BUFFER_H_
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include <memory>
+#include <vector>
+
+#include "common_audio/channel_buffer.h"
+#include "modules/audio_processing/include/audio_processing.h"
+
+namespace webrtc {
+
+class PushSincResampler;
+class SplittingFilter;
+
+enum Band { kBand0To8kHz = 0, kBand8To16kHz = 1, kBand16To24kHz = 2 };
+
+// Stores any audio data in a way that allows the audio processing module to
+// operate on it in a controlled manner.
+class AudioBuffer {
+ public:
+  static const int kSplitBandSize = 160;
+  static const size_t kMaxSampleRate = 384000;
+  AudioBuffer(size_t input_rate,
+              size_t input_num_channels,
+              size_t buffer_rate,
+              size_t buffer_num_channels,
+              size_t output_rate,
+              size_t output_num_channels);
+
+  // The constructor below will be deprecated.
+  AudioBuffer(size_t input_num_frames,
+              size_t input_num_channels,
+              size_t buffer_num_frames,
+              size_t buffer_num_channels,
+              size_t output_num_frames);
+  virtual ~AudioBuffer();
+
+  AudioBuffer(const AudioBuffer&) = delete;
+  AudioBuffer& operator=(const AudioBuffer&) = delete;
+
+  // Specify that downmixing should be done by selecting a single channel.
+  void set_downmixing_to_specific_channel(size_t channel);
+
+  // Specify that downmixing should be done by averaging all channels,.
+  void set_downmixing_by_averaging();
+
+  // Set the number of channels in the buffer. The specified number of channels
+  // cannot be larger than the specified buffer_num_channels. The number is also
+  // reset at each call to CopyFrom or InterleaveFrom.
+  void set_num_channels(size_t num_channels);
+
+  size_t num_channels() const { return num_channels_; }
+  size_t num_frames() const { return buffer_num_frames_; }
+  size_t num_frames_per_band() const { return num_split_frames_; }
+  size_t num_bands() const { return num_bands_; }
+
+  // Returns pointer arrays to the full-band channels.
+  // Usage:
+  // channels()[channel][sample].
+  // Where:
+  // 0 <= channel < |buffer_num_channels_|
+  // 0 <= sample < |buffer_num_frames_|
+  float* const* channels() { return data_->channels(); }
+  const float* const* channels_const() const { return data_->channels(); }
+
+  // Returns pointer arrays to the bands for a specific channel.
+  // Usage:
+  // split_bands(channel)[band][sample].
+  // Where:
+  // 0 <= channel < |buffer_num_channels_|
+  // 0 <= band < |num_bands_|
+  // 0 <= sample < |num_split_frames_|
+  const float* const* split_bands_const(size_t channel) const {
+    return split_data_.get() ? split_data_->bands(channel)
+                             : data_->bands(channel);
+  }
+  float* const* split_bands(size_t channel) {
+    return split_data_.get() ? split_data_->bands(channel)
+                             : data_->bands(channel);
+  }
+
+  // Returns a pointer array to the channels for a specific band.
+  // Usage:
+  // split_channels(band)[channel][sample].
+  // Where:
+  // 0 <= band < |num_bands_|
+  // 0 <= channel < |buffer_num_channels_|
+  // 0 <= sample < |num_split_frames_|
+  const float* const* split_channels_const(Band band) const {
+    if (split_data_.get()) {
+      return split_data_->channels(band);
+    } else {
+      return band == kBand0To8kHz ? data_->channels() : nullptr;
+    }
+  }
+
+  // Copies data into the buffer.
+  void CopyFrom(const int16_t* const interleaved_data,
+                const StreamConfig& stream_config);
+  void CopyFrom(const float* const* stacked_data,
+                const StreamConfig& stream_config);
+
+  // Copies data from the buffer.
+  void CopyTo(const StreamConfig& stream_config,
+              int16_t* const interleaved_data);
+  void CopyTo(const StreamConfig& stream_config, float* const* stacked_data);
+  void CopyTo(AudioBuffer* buffer) const;
+
+  // Splits the buffer data into frequency bands.
+  void SplitIntoFrequencyBands();
+
+  // Recombines the frequency bands into a full-band signal.
+  void MergeFrequencyBands();
+
+  // Copies the split bands data into the integer two-dimensional array.
+  void ExportSplitChannelData(size_t channel,
+                              int16_t* const* split_band_data) const;
+
+  // Copies the data in the integer two-dimensional array into the split_bands
+  // data.
+  void ImportSplitChannelData(size_t channel,
+                              const int16_t* const* split_band_data);
+
+  static const size_t kMaxSplitFrameLength = 160;
+  static const size_t kMaxNumBands = 3;
+
+  // Deprecated methods, will be removed soon.
+  float* const* channels_f() { return channels(); }
+  const float* const* channels_const_f() const { return channels_const(); }
+  const float* const* split_bands_const_f(size_t channel) const {
+    return split_bands_const(channel);
+  }
+  float* const* split_bands_f(size_t channel) { return split_bands(channel); }
+  const float* const* split_channels_const_f(Band band) const {
+    return split_channels_const(band);
+  }
+
+ private:
+  FRIEND_TEST_ALL_PREFIXES(AudioBufferTest,
+                           SetNumChannelsSetsChannelBuffersNumChannels);
+  void RestoreNumChannels();
+
+  const size_t input_num_frames_;
+  const size_t input_num_channels_;
+  const size_t buffer_num_frames_;
+  const size_t buffer_num_channels_;
+  const size_t output_num_frames_;
+  const size_t output_num_channels_;
+
+  size_t num_channels_;
+  size_t num_bands_;
+  size_t num_split_frames_;
+
+  std::unique_ptr<ChannelBuffer<float>> data_;
+  std::unique_ptr<ChannelBuffer<float>> split_data_;
+  std::unique_ptr<SplittingFilter> splitting_filter_;
+  std::vector<std::unique_ptr<PushSincResampler>> input_resamplers_;
+  std::vector<std::unique_ptr<PushSincResampler>> output_resamplers_;
+  bool downmix_by_averaging_ = true;
+  size_t channel_for_downmixing_ = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_AUDIO_BUFFER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/circular_buffer.cc b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/circular_buffer.cc
new file mode 100644
index 0000000..a6d10ed
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/circular_buffer.cc
@@ -0,0 +1,49 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/echo_detector/circular_buffer.h"
+
+#include <algorithm>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+CircularBuffer::CircularBuffer(size_t size) : buffer_(size) {}
+CircularBuffer::~CircularBuffer() = default;
+
+void CircularBuffer::Push(float value) {
+  buffer_[next_insertion_index_] = value;
+  ++next_insertion_index_;
+  next_insertion_index_ %= buffer_.size();
+  RTC_DCHECK_LT(next_insertion_index_, buffer_.size());
+  nr_elements_in_buffer_ = std::min(nr_elements_in_buffer_ + 1, buffer_.size());
+  RTC_DCHECK_LE(nr_elements_in_buffer_, buffer_.size());
+}
+
+absl::optional<float> CircularBuffer::Pop() {
+  if (nr_elements_in_buffer_ == 0) {
+    return absl::nullopt;
+  }
+  const size_t index =
+      (buffer_.size() + next_insertion_index_ - nr_elements_in_buffer_) %
+      buffer_.size();
+  RTC_DCHECK_LT(index, buffer_.size());
+  --nr_elements_in_buffer_;
+  return buffer_[index];
+}
+
+void CircularBuffer::Clear() {
+  std::fill(buffer_.begin(), buffer_.end(), 0.f);
+  next_insertion_index_ = 0;
+  nr_elements_in_buffer_ = 0;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/circular_buffer.h b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/circular_buffer.h
new file mode 100644
index 0000000..db1aeae
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/circular_buffer.h
@@ -0,0 +1,44 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_ECHO_DETECTOR_CIRCULAR_BUFFER_H_
+#define MODULES_AUDIO_PROCESSING_ECHO_DETECTOR_CIRCULAR_BUFFER_H_
+
+#include <stddef.h>
+
+#include <vector>
+
+#include "absl/types/optional.h"
+
+namespace webrtc {
+
+// Ring buffer containing floating point values.
+struct CircularBuffer {
+ public:
+  explicit CircularBuffer(size_t size);
+  ~CircularBuffer();
+
+  void Push(float value);
+  absl::optional<float> Pop();
+  size_t Size() const { return nr_elements_in_buffer_; }
+  // This function fills the buffer with zeros, but does not change its size.
+  void Clear();
+
+ private:
+  std::vector<float> buffer_;
+  size_t next_insertion_index_ = 0;
+  // This is the number of elements that have been pushed into the circular
+  // buffer, not the allocated buffer size.
+  size_t nr_elements_in_buffer_ = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_ECHO_DETECTOR_CIRCULAR_BUFFER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/circular_buffer_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/circular_buffer_unittest.cc
new file mode 100644
index 0000000..7a234d4
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/circular_buffer_unittest.cc
@@ -0,0 +1,53 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/echo_detector/circular_buffer.h"
+
+#include "test/gtest.h"
+
+namespace webrtc {
+
+TEST(CircularBufferTests, LessThanMaxTest) {
+  CircularBuffer test_buffer(3);
+  test_buffer.Push(1.f);
+  test_buffer.Push(2.f);
+  EXPECT_EQ(1.f, test_buffer.Pop());
+  EXPECT_EQ(2.f, test_buffer.Pop());
+}
+
+TEST(CircularBufferTests, FillTest) {
+  CircularBuffer test_buffer(3);
+  test_buffer.Push(1.f);
+  test_buffer.Push(2.f);
+  test_buffer.Push(3.f);
+  EXPECT_EQ(1.f, test_buffer.Pop());
+  EXPECT_EQ(2.f, test_buffer.Pop());
+  EXPECT_EQ(3.f, test_buffer.Pop());
+}
+
+TEST(CircularBufferTests, OverflowTest) {
+  CircularBuffer test_buffer(3);
+  test_buffer.Push(1.f);
+  test_buffer.Push(2.f);
+  test_buffer.Push(3.f);
+  test_buffer.Push(4.f);
+  // Because the circular buffer has a size of 3, the first insert should have
+  // been forgotten.
+  EXPECT_EQ(2.f, test_buffer.Pop());
+  EXPECT_EQ(3.f, test_buffer.Pop());
+  EXPECT_EQ(4.f, test_buffer.Pop());
+}
+
+TEST(CircularBufferTests, ReadFromEmpty) {
+  CircularBuffer test_buffer(3);
+  EXPECT_EQ(absl::nullopt, test_buffer.Pop());
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/mean_variance_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/mean_variance_estimator.cc
new file mode 100644
index 0000000..a857403
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/mean_variance_estimator.cc
@@ -0,0 +1,47 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/echo_detector/mean_variance_estimator.h"
+
+#include <math.h>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+
+// Parameter controlling the adaptation speed.
+constexpr float kAlpha = 0.001f;
+
+}  // namespace
+
+void MeanVarianceEstimator::Update(float value) {
+  mean_ = (1.f - kAlpha) * mean_ + kAlpha * value;
+  variance_ =
+      (1.f - kAlpha) * variance_ + kAlpha * (value - mean_) * (value - mean_);
+  RTC_DCHECK(isfinite(mean_));
+  RTC_DCHECK(isfinite(variance_));
+}
+
+float MeanVarianceEstimator::std_deviation() const {
+  RTC_DCHECK_GE(variance_, 0.f);
+  return sqrtf(variance_);
+}
+
+float MeanVarianceEstimator::mean() const {
+  return mean_;
+}
+
+void MeanVarianceEstimator::Clear() {
+  mean_ = 0.f;
+  variance_ = 0.f;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/mean_variance_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/mean_variance_estimator.h
new file mode 100644
index 0000000..7f793df
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/mean_variance_estimator.h
@@ -0,0 +1,33 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_ECHO_DETECTOR_MEAN_VARIANCE_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_ECHO_DETECTOR_MEAN_VARIANCE_ESTIMATOR_H_
+
+namespace webrtc {
+
+// This class iteratively estimates the mean and variance of a signal.
+class MeanVarianceEstimator {
+ public:
+  void Update(float value);
+  float std_deviation() const;
+  float mean() const;
+  void Clear();
+
+ private:
+  // Estimate of the expected value of the input values.
+  float mean_ = 0.f;
+  // Estimate of the variance of the input values.
+  float variance_ = 0.f;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_ECHO_DETECTOR_MEAN_VARIANCE_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/mean_variance_estimator_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/mean_variance_estimator_unittest.cc
new file mode 100644
index 0000000..8327d23
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/mean_variance_estimator_unittest.cc
@@ -0,0 +1,65 @@
+
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/echo_detector/mean_variance_estimator.h"
+
+#include "test/gtest.h"
+
+namespace webrtc {
+
+TEST(MeanVarianceEstimatorTests, InsertTwoValues) {
+  MeanVarianceEstimator test_estimator;
+  // Insert two values.
+  test_estimator.Update(3.f);
+  test_estimator.Update(5.f);
+
+  EXPECT_GT(test_estimator.mean(), 0.f);
+  EXPECT_GT(test_estimator.std_deviation(), 0.f);
+  // Test Clear method
+  test_estimator.Clear();
+  EXPECT_EQ(test_estimator.mean(), 0.f);
+  EXPECT_EQ(test_estimator.std_deviation(), 0.f);
+}
+
+TEST(MeanVarianceEstimatorTests, InsertZeroes) {
+  MeanVarianceEstimator test_estimator;
+  // Insert the same value many times.
+  for (size_t i = 0; i < 20000; i++) {
+    test_estimator.Update(0.f);
+  }
+  EXPECT_EQ(test_estimator.mean(), 0.f);
+  EXPECT_EQ(test_estimator.std_deviation(), 0.f);
+}
+
+TEST(MeanVarianceEstimatorTests, ConstantValueTest) {
+  MeanVarianceEstimator test_estimator;
+  for (size_t i = 0; i < 20000; i++) {
+    test_estimator.Update(3.f);
+  }
+  // The mean should be close to three, and the standard deviation should be
+  // close to zero.
+  EXPECT_NEAR(3.0f, test_estimator.mean(), 0.01f);
+  EXPECT_NEAR(0.0f, test_estimator.std_deviation(), 0.01f);
+}
+
+TEST(MeanVarianceEstimatorTests, AlternatingValueTest) {
+  MeanVarianceEstimator test_estimator;
+  for (size_t i = 0; i < 20000; i++) {
+    test_estimator.Update(1.f);
+    test_estimator.Update(-1.f);
+  }
+  // The mean should be close to zero, and the standard deviation should be
+  // close to one.
+  EXPECT_NEAR(0.0f, test_estimator.mean(), 0.01f);
+  EXPECT_NEAR(1.0f, test_estimator.std_deviation(), 0.01f);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/moving_max.cc b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/moving_max.cc
new file mode 100644
index 0000000..3054e98
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/moving_max.cc
@@ -0,0 +1,52 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/echo_detector/moving_max.h"
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+
+// Parameter for controlling how fast the estimated maximum decays after the
+// previous maximum is no longer valid. With a value of 0.99, the maximum will
+// decay to 1% of its former value after 460 updates.
+constexpr float kDecayFactor = 0.99f;
+
+}  // namespace
+
+MovingMax::MovingMax(size_t window_size) : window_size_(window_size) {
+  RTC_DCHECK_GT(window_size, 0);
+}
+
+MovingMax::~MovingMax() {}
+
+void MovingMax::Update(float value) {
+  if (counter_ >= window_size_ - 1) {
+    max_value_ *= kDecayFactor;
+  } else {
+    ++counter_;
+  }
+  if (value > max_value_) {
+    max_value_ = value;
+    counter_ = 0;
+  }
+}
+
+float MovingMax::max() const {
+  return max_value_;
+}
+
+void MovingMax::Clear() {
+  max_value_ = 0.f;
+  counter_ = 0;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/moving_max.h b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/moving_max.h
new file mode 100644
index 0000000..f7d8ee8
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/moving_max.h
@@ -0,0 +1,36 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_ECHO_DETECTOR_MOVING_MAX_H_
+#define MODULES_AUDIO_PROCESSING_ECHO_DETECTOR_MOVING_MAX_H_
+
+#include <stddef.h>
+
+namespace webrtc {
+
+class MovingMax {
+ public:
+  explicit MovingMax(size_t window_size);
+  ~MovingMax();
+
+  void Update(float value);
+  float max() const;
+  // Reset all of the state in this class.
+  void Clear();
+
+ private:
+  float max_value_ = 0.f;
+  size_t counter_ = 0;
+  size_t window_size_ = 1;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_ECHO_DETECTOR_MOVING_MAX_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/moving_max_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/moving_max_unittest.cc
new file mode 100644
index 0000000..9429127
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/moving_max_unittest.cc
@@ -0,0 +1,68 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/echo_detector/moving_max.h"
+
+#include "test/gtest.h"
+
+namespace webrtc {
+
+// Test if the maximum is correctly found.
+TEST(MovingMaxTests, SimpleTest) {
+  MovingMax test_moving_max(5);
+  test_moving_max.Update(1.0f);
+  test_moving_max.Update(1.1f);
+  test_moving_max.Update(1.9f);
+  test_moving_max.Update(1.87f);
+  test_moving_max.Update(1.89f);
+  EXPECT_EQ(1.9f, test_moving_max.max());
+}
+
+// Test if values fall out of the window when expected.
+TEST(MovingMaxTests, SlidingWindowTest) {
+  MovingMax test_moving_max(5);
+  test_moving_max.Update(1.0f);
+  test_moving_max.Update(1.9f);
+  test_moving_max.Update(1.7f);
+  test_moving_max.Update(1.87f);
+  test_moving_max.Update(1.89f);
+  test_moving_max.Update(1.3f);
+  test_moving_max.Update(1.2f);
+  EXPECT_LT(test_moving_max.max(), 1.9f);
+}
+
+// Test if Clear() works as expected.
+TEST(MovingMaxTests, ClearTest) {
+  MovingMax test_moving_max(5);
+  test_moving_max.Update(1.0f);
+  test_moving_max.Update(1.1f);
+  test_moving_max.Update(1.9f);
+  test_moving_max.Update(1.87f);
+  test_moving_max.Update(1.89f);
+  EXPECT_EQ(1.9f, test_moving_max.max());
+  test_moving_max.Clear();
+  EXPECT_EQ(0.f, test_moving_max.max());
+}
+
+// Test the decay of the estimated maximum.
+TEST(MovingMaxTests, DecayTest) {
+  MovingMax test_moving_max(1);
+  test_moving_max.Update(1.0f);
+  float previous_value = 1.0f;
+  for (int i = 0; i < 500; i++) {
+    test_moving_max.Update(0.0f);
+    EXPECT_LT(test_moving_max.max(), previous_value);
+    EXPECT_GT(test_moving_max.max(), 0.0f);
+    previous_value = test_moving_max.max();
+  }
+  EXPECT_LT(test_moving_max.max(), 0.01f);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/normalized_covariance_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/normalized_covariance_estimator.cc
new file mode 100644
index 0000000..8ec9fe9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/normalized_covariance_estimator.cc
@@ -0,0 +1,43 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/echo_detector/normalized_covariance_estimator.h"
+
+#include <math.h>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+
+// Parameter controlling the adaptation speed.
+constexpr float kAlpha = 0.001f;
+
+}  // namespace
+
+void NormalizedCovarianceEstimator::Update(float x,
+                                           float x_mean,
+                                           float x_sigma,
+                                           float y,
+                                           float y_mean,
+                                           float y_sigma) {
+  covariance_ =
+      (1.f - kAlpha) * covariance_ + kAlpha * (x - x_mean) * (y - y_mean);
+  normalized_cross_correlation_ = covariance_ / (x_sigma * y_sigma + .0001f);
+  RTC_DCHECK(isfinite(covariance_));
+  RTC_DCHECK(isfinite(normalized_cross_correlation_));
+}
+
+void NormalizedCovarianceEstimator::Clear() {
+  covariance_ = 0.f;
+  normalized_cross_correlation_ = 0.f;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/normalized_covariance_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/normalized_covariance_estimator.h
new file mode 100644
index 0000000..e3c36d8
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/normalized_covariance_estimator.h
@@ -0,0 +1,43 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_ECHO_DETECTOR_NORMALIZED_COVARIANCE_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_ECHO_DETECTOR_NORMALIZED_COVARIANCE_ESTIMATOR_H_
+
+namespace webrtc {
+
+// This class iteratively estimates the normalized covariance between two
+// signals.
+class NormalizedCovarianceEstimator {
+ public:
+  void Update(float x,
+              float x_mean,
+              float x_var,
+              float y,
+              float y_mean,
+              float y_var);
+  // This function returns an estimate of the Pearson product-moment correlation
+  // coefficient of the two signals.
+  float normalized_cross_correlation() const {
+    return normalized_cross_correlation_;
+  }
+  float covariance() const { return covariance_; }
+  // This function resets the estimated values to zero.
+  void Clear();
+
+ private:
+  float normalized_cross_correlation_ = 0.f;
+  // Estimate of the covariance value.
+  float covariance_ = 0.f;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_ECHO_DETECTOR_NORMALIZED_COVARIANCE_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/normalized_covariance_estimator_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/normalized_covariance_estimator_unittest.cc
new file mode 100644
index 0000000..89fb938
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/echo_detector/normalized_covariance_estimator_unittest.cc
@@ -0,0 +1,41 @@
+
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/echo_detector/normalized_covariance_estimator.h"
+
+#include "test/gtest.h"
+
+namespace webrtc {
+
+TEST(NormalizedCovarianceEstimatorTests, IdenticalSignalTest) {
+  NormalizedCovarianceEstimator test_estimator;
+  for (size_t i = 0; i < 10000; i++) {
+    test_estimator.Update(1.f, 0.f, 1.f, 1.f, 0.f, 1.f);
+    test_estimator.Update(-1.f, 0.f, 1.f, -1.f, 0.f, 1.f);
+  }
+  // A normalized covariance value close to 1 is expected.
+  EXPECT_NEAR(1.f, test_estimator.normalized_cross_correlation(), 0.01f);
+  test_estimator.Clear();
+  EXPECT_EQ(0.f, test_estimator.normalized_cross_correlation());
+}
+
+TEST(NormalizedCovarianceEstimatorTests, OppositeSignalTest) {
+  NormalizedCovarianceEstimator test_estimator;
+  // Insert the same value many times.
+  for (size_t i = 0; i < 10000; i++) {
+    test_estimator.Update(1.f, 0.f, 1.f, -1.f, 0.f, 1.f);
+    test_estimator.Update(-1.f, 0.f, 1.f, 1.f, 0.f, 1.f);
+  }
+  // A normalized covariance value close to -1 is expected.
+  EXPECT_NEAR(-1.f, test_estimator.normalized_cross_correlation(), 0.01f);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/gain_controller2.cc b/third_party/webrtc_aec3/src/modules/audio_processing/gain_controller2.cc
new file mode 100644
index 0000000..9e3e8e7
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/gain_controller2.cc
@@ -0,0 +1,117 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/gain_controller2.h"
+
+#include "common_audio/include/audio_util.h"
+#include "modules/audio_processing/audio_buffer.h"
+#include "modules/audio_processing/include/audio_frame_view.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/atomic_ops.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+#include "rtc_base/strings/string_builder.h"
+
+namespace webrtc {
+
+int GainController2::instance_count_ = 0;
+
+GainController2::GainController2()
+    : data_dumper_(rtc::AtomicOps::Increment(&instance_count_)),
+      gain_applier_(/*hard_clip_samples=*/false,
+                    /*initial_gain_factor=*/0.f),
+      limiter_(static_cast<size_t>(48000), &data_dumper_, "Agc2"),
+      calls_since_last_limiter_log_(0) {
+  if (config_.adaptive_digital.enabled) {
+    adaptive_agc_ = std::make_unique<AdaptiveAgc>(&data_dumper_);
+  }
+}
+
+GainController2::~GainController2() = default;
+
+void GainController2::Initialize(int sample_rate_hz) {
+  RTC_DCHECK(sample_rate_hz == AudioProcessing::kSampleRate8kHz ||
+             sample_rate_hz == AudioProcessing::kSampleRate16kHz ||
+             sample_rate_hz == AudioProcessing::kSampleRate32kHz ||
+             sample_rate_hz == AudioProcessing::kSampleRate48kHz);
+  limiter_.SetSampleRate(sample_rate_hz);
+  data_dumper_.InitiateNewSetOfRecordings();
+  data_dumper_.DumpRaw("sample_rate_hz", sample_rate_hz);
+  calls_since_last_limiter_log_ = 0;
+}
+
+void GainController2::Process(AudioBuffer* audio) {
+  data_dumper_.DumpRaw("agc2_notified_analog_level", analog_level_);
+  AudioFrameView<float> float_frame(audio->channels(), audio->num_channels(),
+                                    audio->num_frames());
+  // Apply fixed gain first, then the adaptive one.
+  gain_applier_.ApplyGain(float_frame);
+  if (adaptive_agc_) {
+    adaptive_agc_->Process(float_frame, limiter_.LastAudioLevel());
+  }
+  limiter_.Process(float_frame);
+
+  // Log limiter stats every 30 seconds.
+  ++calls_since_last_limiter_log_;
+  if (calls_since_last_limiter_log_ == 3000) {
+    calls_since_last_limiter_log_ = 0;
+    InterpolatedGainCurve::Stats stats = limiter_.GetGainCurveStats();
+    RTC_LOG(LS_INFO) << "AGC2 limiter stats"
+                     << " | identity: " << stats.look_ups_identity_region
+                     << " | knee: " << stats.look_ups_knee_region
+                     << " | limiter: " << stats.look_ups_limiter_region
+                     << " | saturation: " << stats.look_ups_saturation_region;
+  }
+}
+
+void GainController2::NotifyAnalogLevel(int level) {
+  if (analog_level_ != level && adaptive_agc_) {
+    adaptive_agc_->HandleInputGainChange();
+  }
+  analog_level_ = level;
+}
+
+void GainController2::ApplyConfig(
+    const AudioProcessing::Config::GainController2& config) {
+  RTC_DCHECK(Validate(config));
+
+  config_ = config;
+  if (config.fixed_digital.gain_db != config_.fixed_digital.gain_db) {
+    // Reset the limiter to quickly react on abrupt level changes caused by
+    // large changes of the fixed gain.
+    limiter_.Reset();
+  }
+  gain_applier_.SetGainFactor(DbToRatio(config_.fixed_digital.gain_db));
+  if (config_.adaptive_digital.enabled) {
+    adaptive_agc_ =
+        std::make_unique<AdaptiveAgc>(&data_dumper_, config_.adaptive_digital);
+  } else {
+    adaptive_agc_.reset();
+  }
+}
+
+bool GainController2::Validate(
+    const AudioProcessing::Config::GainController2& config) {
+  const auto& fixed = config.fixed_digital;
+  const auto& adaptive = config.adaptive_digital;
+  return fixed.gain_db >= 0.f && fixed.gain_db < 50.f &&
+         adaptive.vad_probability_attack > 0.f &&
+         adaptive.vad_probability_attack <= 1.f &&
+         adaptive.level_estimator_adjacent_speech_frames_threshold >= 1 &&
+         adaptive.initial_saturation_margin_db >= 0.f &&
+         adaptive.initial_saturation_margin_db <= 100.f &&
+         adaptive.extra_saturation_margin_db >= 0.f &&
+         adaptive.extra_saturation_margin_db <= 100.f &&
+         adaptive.gain_applier_adjacent_speech_frames_threshold >= 1 &&
+         adaptive.max_gain_change_db_per_second > 0.f &&
+         adaptive.max_output_noise_level_dbfs <= 0.f;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/gain_controller2.h b/third_party/webrtc_aec3/src/modules/audio_processing/gain_controller2.h
new file mode 100644
index 0000000..b62890d
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/gain_controller2.h
@@ -0,0 +1,57 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_GAIN_CONTROLLER2_H_
+#define MODULES_AUDIO_PROCESSING_GAIN_CONTROLLER2_H_
+
+#include <memory>
+#include <string>
+
+#include "modules/audio_processing/agc2/adaptive_agc.h"
+#include "modules/audio_processing/agc2/gain_applier.h"
+#include "modules/audio_processing/agc2/limiter.h"
+#include "modules/audio_processing/include/audio_processing.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+class AudioBuffer;
+
+// Gain Controller 2 aims to automatically adjust levels by acting on the
+// microphone gain and/or applying digital gain.
+class GainController2 {
+ public:
+  GainController2();
+  GainController2(const GainController2&) = delete;
+  GainController2& operator=(const GainController2&) = delete;
+  ~GainController2();
+
+  void Initialize(int sample_rate_hz);
+  void Process(AudioBuffer* audio);
+  void NotifyAnalogLevel(int level);
+
+  void ApplyConfig(const AudioProcessing::Config::GainController2& config);
+  static bool Validate(const AudioProcessing::Config::GainController2& config);
+
+ private:
+  static int instance_count_;
+  ApmDataDumper data_dumper_;
+  AudioProcessing::Config::GainController2 config_;
+  GainApplier gain_applier_;
+  std::unique_ptr<AdaptiveAgc> adaptive_agc_;
+  Limiter limiter_;
+  int calls_since_last_limiter_log_;
+  int analog_level_ = -1;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_GAIN_CONTROLLER2_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/high_pass_filter.cc b/third_party/webrtc_aec3/src/modules/audio_processing/high_pass_filter.cc
new file mode 100644
index 0000000..bff7209
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/high_pass_filter.cc
@@ -0,0 +1,115 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/high_pass_filter.h"
+
+#include "api/array_view.h"
+#include "modules/audio_processing/audio_buffer.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+namespace {
+// [B,A] = butter(2,100/8000,'high')
+constexpr CascadedBiQuadFilter::BiQuadCoefficients
+    kHighPassFilterCoefficients16kHz = {{0.97261f, -1.94523f, 0.97261f},
+                                        {-1.94448f, 0.94598f}};
+
+// [B,A] = butter(2,100/16000,'high')
+constexpr CascadedBiQuadFilter::BiQuadCoefficients
+    kHighPassFilterCoefficients32kHz = {{0.98621f, -1.97242f, 0.98621f},
+                                        {-1.97223f, 0.97261f}};
+
+// [B,A] = butter(2,100/24000,'high')
+constexpr CascadedBiQuadFilter::BiQuadCoefficients
+    kHighPassFilterCoefficients48kHz = {{0.99079f, -1.98157f, 0.99079f},
+                                        {-1.98149f, 0.98166f}};
+
+constexpr size_t kNumberOfHighPassBiQuads = 1;
+
+const CascadedBiQuadFilter::BiQuadCoefficients& ChooseCoefficients(
+    int sample_rate_hz) {
+  switch (sample_rate_hz) {
+    case 16000:
+      return kHighPassFilterCoefficients16kHz;
+    case 32000:
+      return kHighPassFilterCoefficients32kHz;
+    case 48000:
+      return kHighPassFilterCoefficients48kHz;
+    default:
+      RTC_NOTREACHED();
+  }
+  RTC_NOTREACHED();
+  return kHighPassFilterCoefficients16kHz;
+}
+
+}  // namespace
+
+HighPassFilter::HighPassFilter(int sample_rate_hz, size_t num_channels)
+    : sample_rate_hz_(sample_rate_hz) {
+  filters_.resize(num_channels);
+  const auto& coefficients = ChooseCoefficients(sample_rate_hz_);
+  for (size_t k = 0; k < filters_.size(); ++k) {
+    filters_[k].reset(
+        new CascadedBiQuadFilter(coefficients, kNumberOfHighPassBiQuads));
+  }
+}
+
+HighPassFilter::~HighPassFilter() = default;
+
+void HighPassFilter::Process(AudioBuffer* audio, bool use_split_band_data) {
+  RTC_DCHECK(audio);
+  RTC_DCHECK_EQ(filters_.size(), audio->num_channels());
+  if (use_split_band_data) {
+    for (size_t k = 0; k < audio->num_channels(); ++k) {
+      rtc::ArrayView<float> channel_data = rtc::ArrayView<float>(
+          audio->split_bands(k)[0], audio->num_frames_per_band());
+      filters_[k]->Process(channel_data);
+    }
+  } else {
+    for (size_t k = 0; k < audio->num_channels(); ++k) {
+      rtc::ArrayView<float> channel_data =
+          rtc::ArrayView<float>(&audio->channels()[k][0], audio->num_frames());
+      filters_[k]->Process(channel_data);
+    }
+  }
+}
+
+void HighPassFilter::Process(std::vector<std::vector<float>>* audio) {
+  RTC_DCHECK_EQ(filters_.size(), audio->size());
+  for (size_t k = 0; k < audio->size(); ++k) {
+    filters_[k]->Process((*audio)[k]);
+  }
+}
+
+void HighPassFilter::Reset() {
+  for (size_t k = 0; k < filters_.size(); ++k) {
+    filters_[k]->Reset();
+  }
+}
+
+void HighPassFilter::Reset(size_t num_channels) {
+  const size_t old_num_channels = filters_.size();
+  filters_.resize(num_channels);
+  if (filters_.size() < old_num_channels) {
+    Reset();
+  } else {
+    for (size_t k = 0; k < old_num_channels; ++k) {
+      filters_[k]->Reset();
+    }
+    const auto& coefficients = ChooseCoefficients(sample_rate_hz_);
+    for (size_t k = old_num_channels; k < filters_.size(); ++k) {
+      filters_[k].reset(
+          new CascadedBiQuadFilter(coefficients, kNumberOfHighPassBiQuads));
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/high_pass_filter.h b/third_party/webrtc_aec3/src/modules/audio_processing/high_pass_filter.h
new file mode 100644
index 0000000..7e7c370
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/high_pass_filter.h
@@ -0,0 +1,45 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_HIGH_PASS_FILTER_H_
+#define MODULES_AUDIO_PROCESSING_HIGH_PASS_FILTER_H_
+
+#include <memory>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/utility/cascaded_biquad_filter.h"
+
+namespace webrtc {
+
+class AudioBuffer;
+
+class HighPassFilter {
+ public:
+  HighPassFilter(int sample_rate_hz, size_t num_channels);
+  ~HighPassFilter();
+  HighPassFilter(const HighPassFilter&) = delete;
+  HighPassFilter& operator=(const HighPassFilter&) = delete;
+
+  void Process(AudioBuffer* audio, bool use_split_band_data);
+  void Process(std::vector<std::vector<float>>* audio);
+  void Reset();
+  void Reset(size_t num_channels);
+
+  int sample_rate_hz() const { return sample_rate_hz_; }
+  size_t num_channels() const { return filters_.size(); }
+
+ private:
+  const int sample_rate_hz_;
+  std::vector<std::unique_ptr<CascadedBiQuadFilter>> filters_;
+};
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_HIGH_PASS_FILTER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/include/audio_frame_view.h b/third_party/webrtc_aec3/src/modules/audio_processing/include/audio_frame_view.h
new file mode 100644
index 0000000..ab5779a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/include/audio_frame_view.h
@@ -0,0 +1,67 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_INCLUDE_AUDIO_FRAME_VIEW_H_
+#define MODULES_AUDIO_PROCESSING_INCLUDE_AUDIO_FRAME_VIEW_H_
+
+#include "api/array_view.h"
+
+namespace webrtc {
+
+// Class to pass audio data in T** format, where T is a numeric type.
+template <class T>
+class AudioFrameView {
+ public:
+  // |num_channels| and |channel_size| describe the T**
+  // |audio_samples|. |audio_samples| is assumed to point to a
+  // two-dimensional |num_channels * channel_size| array of floats.
+  AudioFrameView(T* const* audio_samples,
+                 size_t num_channels,
+                 size_t channel_size)
+      : audio_samples_(audio_samples),
+        num_channels_(num_channels),
+        channel_size_(channel_size) {}
+
+  // Implicit cast to allow converting Frame<float> to
+  // Frame<const float>.
+  template <class U>
+  AudioFrameView(AudioFrameView<U> other)
+      : audio_samples_(other.data()),
+        num_channels_(other.num_channels()),
+        channel_size_(other.samples_per_channel()) {}
+
+  AudioFrameView() = delete;
+
+  size_t num_channels() const { return num_channels_; }
+
+  size_t samples_per_channel() const { return channel_size_; }
+
+  rtc::ArrayView<T> channel(size_t idx) {
+    RTC_DCHECK_LE(0, idx);
+    RTC_DCHECK_LE(idx, num_channels_);
+    return rtc::ArrayView<T>(audio_samples_[idx], channel_size_);
+  }
+
+  rtc::ArrayView<const T> channel(size_t idx) const {
+    RTC_DCHECK_LE(0, idx);
+    RTC_DCHECK_LE(idx, num_channels_);
+    return rtc::ArrayView<const T>(audio_samples_[idx], channel_size_);
+  }
+
+  T* const* data() { return audio_samples_; }
+
+ private:
+  T* const* audio_samples_;
+  size_t num_channels_;
+  size_t channel_size_;
+};
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_INCLUDE_AUDIO_FRAME_VIEW_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/include/audio_processing.cc b/third_party/webrtc_aec3/src/modules/audio_processing/include/audio_processing.cc
new file mode 100644
index 0000000..fa45230
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/include/audio_processing.cc
@@ -0,0 +1,184 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/include/audio_processing.h"
+
+#include "rtc_base/strings/string_builder.h"
+#include "rtc_base/system/arch.h"
+
+namespace webrtc {
+namespace {
+
+using Agc1Config = AudioProcessing::Config::GainController1;
+using Agc2Config = AudioProcessing::Config::GainController2;
+
+std::string NoiseSuppressionLevelToString(
+    const AudioProcessing::Config::NoiseSuppression::Level& level) {
+  switch (level) {
+    case AudioProcessing::Config::NoiseSuppression::Level::kLow:
+      return "Low";
+    case AudioProcessing::Config::NoiseSuppression::Level::kModerate:
+      return "Moderate";
+    case AudioProcessing::Config::NoiseSuppression::Level::kHigh:
+      return "High";
+    case AudioProcessing::Config::NoiseSuppression::Level::kVeryHigh:
+      return "VeryHigh";
+  }
+  RTC_CHECK_NOTREACHED();
+}
+
+std::string GainController1ModeToString(const Agc1Config::Mode& mode) {
+  switch (mode) {
+    case Agc1Config::Mode::kAdaptiveAnalog:
+      return "AdaptiveAnalog";
+    case Agc1Config::Mode::kAdaptiveDigital:
+      return "AdaptiveDigital";
+    case Agc1Config::Mode::kFixedDigital:
+      return "FixedDigital";
+  }
+  RTC_CHECK_NOTREACHED();
+}
+
+std::string GainController2NoiseEstimatorToString(
+    const Agc2Config::NoiseEstimator& type) {
+  switch (type) {
+    case Agc2Config::NoiseEstimator::kStationaryNoise:
+      return "StationaryNoise";
+    case Agc2Config::NoiseEstimator::kNoiseFloor:
+      return "NoiseFloor";
+  }
+  RTC_CHECK_NOTREACHED();
+}
+
+}  // namespace
+
+constexpr int AudioProcessing::kNativeSampleRatesHz[];
+
+void CustomProcessing::SetRuntimeSetting(
+    AudioProcessing::RuntimeSetting setting) {}
+
+bool Agc1Config::operator==(const Agc1Config& rhs) const {
+  const auto& analog_lhs = analog_gain_controller;
+  const auto& analog_rhs = rhs.analog_gain_controller;
+  return enabled == rhs.enabled && mode == rhs.mode &&
+         target_level_dbfs == rhs.target_level_dbfs &&
+         compression_gain_db == rhs.compression_gain_db &&
+         enable_limiter == rhs.enable_limiter &&
+         analog_level_minimum == rhs.analog_level_minimum &&
+         analog_level_maximum == rhs.analog_level_maximum &&
+         analog_lhs.enabled == analog_rhs.enabled &&
+         analog_lhs.startup_min_volume == analog_rhs.startup_min_volume &&
+         analog_lhs.clipped_level_min == analog_rhs.clipped_level_min &&
+         analog_lhs.enable_digital_adaptive ==
+             analog_rhs.enable_digital_adaptive;
+}
+
+bool Agc2Config::operator==(const Agc2Config& rhs) const {
+  const auto& adaptive_lhs = adaptive_digital;
+  const auto& adaptive_rhs = rhs.adaptive_digital;
+
+  return enabled == rhs.enabled &&
+         fixed_digital.gain_db == rhs.fixed_digital.gain_db &&
+         adaptive_lhs.enabled == adaptive_rhs.enabled &&
+         adaptive_lhs.vad_probability_attack ==
+             adaptive_rhs.vad_probability_attack &&
+         adaptive_lhs.level_estimator == adaptive_rhs.level_estimator &&
+         adaptive_lhs.level_estimator_adjacent_speech_frames_threshold ==
+             adaptive_rhs.level_estimator_adjacent_speech_frames_threshold &&
+         adaptive_lhs.use_saturation_protector ==
+             adaptive_rhs.use_saturation_protector &&
+         adaptive_lhs.initial_saturation_margin_db ==
+             adaptive_rhs.initial_saturation_margin_db &&
+         adaptive_lhs.extra_saturation_margin_db ==
+             adaptive_rhs.extra_saturation_margin_db &&
+         adaptive_lhs.gain_applier_adjacent_speech_frames_threshold ==
+             adaptive_rhs.gain_applier_adjacent_speech_frames_threshold &&
+         adaptive_lhs.max_gain_change_db_per_second ==
+             adaptive_rhs.max_gain_change_db_per_second &&
+         adaptive_lhs.max_output_noise_level_dbfs ==
+             adaptive_rhs.max_output_noise_level_dbfs;
+}
+
+bool AudioProcessing::Config::CaptureLevelAdjustment::operator==(
+    const AudioProcessing::Config::CaptureLevelAdjustment& rhs) const {
+  return enabled == rhs.enabled && pre_gain_factor == rhs.pre_gain_factor &&
+         post_gain_factor && rhs.post_gain_factor &&
+         analog_mic_gain_emulation == rhs.analog_mic_gain_emulation;
+}
+
+bool AudioProcessing::Config::CaptureLevelAdjustment::AnalogMicGainEmulation::
+operator==(const AudioProcessing::Config::CaptureLevelAdjustment::
+               AnalogMicGainEmulation& rhs) const {
+  return enabled == rhs.enabled && initial_level == rhs.initial_level;
+}
+
+std::string AudioProcessing::Config::ToString() const {
+  char buf[2048];
+  rtc::SimpleStringBuilder builder(buf);
+  builder
+      << "AudioProcessing::Config{ "
+         "pipeline: { "
+         "maximum_internal_processing_rate: "
+      << pipeline.maximum_internal_processing_rate
+      << ", multi_channel_render: " << pipeline.multi_channel_render
+      << ", multi_channel_capture: " << pipeline.multi_channel_capture
+      << " }, pre_amplifier: { enabled: " << pre_amplifier.enabled
+      << ", fixed_gain_factor: " << pre_amplifier.fixed_gain_factor
+      << " },capture_level_adjustment: { enabled: "
+      << capture_level_adjustment.enabled
+      << ", pre_gain_factor: " << capture_level_adjustment.pre_gain_factor
+      << ", post_gain_factor: " << capture_level_adjustment.post_gain_factor
+      << ", analog_mic_gain_emulation: { enabled: "
+      << capture_level_adjustment.analog_mic_gain_emulation.enabled
+      << ", initial_level: "
+      << capture_level_adjustment.analog_mic_gain_emulation.initial_level
+      << " }}, high_pass_filter: { enabled: " << high_pass_filter.enabled
+      << " }, echo_canceller: { enabled: " << echo_canceller.enabled
+      << ", mobile_mode: " << echo_canceller.mobile_mode
+      << ", enforce_high_pass_filtering: "
+      << echo_canceller.enforce_high_pass_filtering
+      << " }, noise_suppression: { enabled: " << noise_suppression.enabled
+      << ", level: " << NoiseSuppressionLevelToString(noise_suppression.level)
+      << " }, transient_suppression: { enabled: "
+      << transient_suppression.enabled
+      << " }, voice_detection: { enabled: " << voice_detection.enabled
+      << " }, gain_controller1: { enabled: " << gain_controller1.enabled
+      << ", mode: " << GainController1ModeToString(gain_controller1.mode)
+      << ", target_level_dbfs: " << gain_controller1.target_level_dbfs
+      << ", compression_gain_db: " << gain_controller1.compression_gain_db
+      << ", enable_limiter: " << gain_controller1.enable_limiter
+      << ", analog_level_minimum: " << gain_controller1.analog_level_minimum
+      << ", analog_level_maximum: " << gain_controller1.analog_level_maximum
+      << " }, gain_controller2: { enabled: " << gain_controller2.enabled
+      << ", fixed_digital: { gain_db: "
+      << gain_controller2.fixed_digital.gain_db
+      << " }, adaptive_digital: { enabled: "
+      << gain_controller2.adaptive_digital.enabled << ", noise_estimator: "
+      << GainController2NoiseEstimatorToString(
+             gain_controller2.adaptive_digital.noise_estimator)
+      << ", vad_reset_period_ms: "
+      << gain_controller2.adaptive_digital.vad_reset_period_ms
+      << ", adjacent_speech_frames_threshold: "
+      << gain_controller2.adaptive_digital.adjacent_speech_frames_threshold
+      << ", max_gain_change_db_per_second: "
+      << gain_controller2.adaptive_digital.max_gain_change_db_per_second
+      << ", max_output_noise_level_dbfs: "
+      << gain_controller2.adaptive_digital.max_output_noise_level_dbfs
+      << ", sse2_allowed: " << gain_controller2.adaptive_digital.sse2_allowed
+      << ", avx2_allowed: " << gain_controller2.adaptive_digital.avx2_allowed
+      << ", neon_allowed: " << gain_controller2.adaptive_digital.neon_allowed
+      << "}}, residual_echo_detector: { enabled: "
+      << residual_echo_detector.enabled
+      << " }, level_estimation: { enabled: " << level_estimation.enabled
+      << " }}";
+  return builder.str();
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/include/audio_processing.h b/third_party/webrtc_aec3/src/modules/audio_processing/include/audio_processing.h
new file mode 100644
index 0000000..01bb7c3
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/include/audio_processing.h
@@ -0,0 +1,953 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_INCLUDE_AUDIO_PROCESSING_H_
+#define MODULES_AUDIO_PROCESSING_INCLUDE_AUDIO_PROCESSING_H_
+
+// MSVC++ requires this to be set before any other includes to get M_PI.
+#ifndef _USE_MATH_DEFINES
+#define _USE_MATH_DEFINES
+#endif
+
+#include <math.h>
+#include <stddef.h>  // size_t
+#include <stdio.h>   // FILE
+#include <string.h>
+
+#include <vector>
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#include "api/audio/echo_canceller3_config.h"
+#include "api/audio/echo_control.h"
+#include "api/scoped_refptr.h"
+#include "modules/audio_processing/include/audio_processing_statistics.h"
+#include "modules/audio_processing/include/config.h"
+#include "rtc_base/arraysize.h"
+#include "rtc_base/constructor_magic.h"
+#include "rtc_base/ref_count.h"
+#include "rtc_base/system/file_wrapper.h"
+#include "rtc_base/system/rtc_export.h"
+
+namespace rtc {
+class TaskQueue;
+}  // namespace rtc
+
+namespace webrtc {
+
+class AecDump;
+class AudioBuffer;
+
+class StreamConfig;
+class ProcessingConfig;
+
+class EchoDetector;
+class CustomAudioAnalyzer;
+class CustomProcessing;
+
+// Use to enable experimental gain control (AGC). At startup the experimental
+// AGC moves the microphone volume up to |startup_min_volume| if the current
+// microphone volume is set too low. The value is clamped to its operating range
+// [12, 255]. Here, 255 maps to 100%.
+//
+// Must be provided through AudioProcessingBuilder().Create(config).
+#if defined(WEBRTC_CHROMIUM_BUILD)
+static const int kAgcStartupMinVolume = 85;
+#else
+static const int kAgcStartupMinVolume = 0;
+#endif  // defined(WEBRTC_CHROMIUM_BUILD)
+static constexpr int kClippedLevelMin = 70;
+
+// To be deprecated: Please instead use the flag in the
+// AudioProcessing::Config::AnalogGainController.
+// TODO(webrtc:5298): Remove.
+struct ExperimentalAgc {
+  ExperimentalAgc() = default;
+  explicit ExperimentalAgc(bool enabled) : enabled(enabled) {}
+  ExperimentalAgc(bool enabled, int startup_min_volume)
+      : enabled(enabled), startup_min_volume(startup_min_volume) {}
+  static const ConfigOptionID identifier = ConfigOptionID::kExperimentalAgc;
+  bool enabled = true;
+  int startup_min_volume = kAgcStartupMinVolume;
+  // Lowest microphone level that will be applied in response to clipping.
+  int clipped_level_min = kClippedLevelMin;
+  bool digital_adaptive_disabled = false;
+};
+
+// To be deprecated: Please instead use the flag in the
+// AudioProcessing::Config::TransientSuppression.
+//
+// Use to enable experimental noise suppression. It can be set in the
+// constructor.
+// TODO(webrtc:5298): Remove.
+struct ExperimentalNs {
+  ExperimentalNs() : enabled(false) {}
+  explicit ExperimentalNs(bool enabled) : enabled(enabled) {}
+  static const ConfigOptionID identifier = ConfigOptionID::kExperimentalNs;
+  bool enabled;
+};
+
+// The Audio Processing Module (APM) provides a collection of voice processing
+// components designed for real-time communications software.
+//
+// APM operates on two audio streams on a frame-by-frame basis. Frames of the
+// primary stream, on which all processing is applied, are passed to
+// |ProcessStream()|. Frames of the reverse direction stream are passed to
+// |ProcessReverseStream()|. On the client-side, this will typically be the
+// near-end (capture) and far-end (render) streams, respectively. APM should be
+// placed in the signal chain as close to the audio hardware abstraction layer
+// (HAL) as possible.
+//
+// On the server-side, the reverse stream will normally not be used, with
+// processing occurring on each incoming stream.
+//
+// Component interfaces follow a similar pattern and are accessed through
+// corresponding getters in APM. All components are disabled at create-time,
+// with default settings that are recommended for most situations. New settings
+// can be applied without enabling a component. Enabling a component triggers
+// memory allocation and initialization to allow it to start processing the
+// streams.
+//
+// Thread safety is provided with the following assumptions to reduce locking
+// overhead:
+//   1. The stream getters and setters are called from the same thread as
+//      ProcessStream(). More precisely, stream functions are never called
+//      concurrently with ProcessStream().
+//   2. Parameter getters are never called concurrently with the corresponding
+//      setter.
+//
+// APM accepts only linear PCM audio data in chunks of 10 ms. The int16
+// interfaces use interleaved data, while the float interfaces use deinterleaved
+// data.
+//
+// Usage example, omitting error checking:
+// AudioProcessing* apm = AudioProcessingBuilder().Create();
+//
+// AudioProcessing::Config config;
+// config.echo_canceller.enabled = true;
+// config.echo_canceller.mobile_mode = false;
+//
+// config.gain_controller1.enabled = true;
+// config.gain_controller1.mode =
+// AudioProcessing::Config::GainController1::kAdaptiveAnalog;
+// config.gain_controller1.analog_level_minimum = 0;
+// config.gain_controller1.analog_level_maximum = 255;
+//
+// config.gain_controller2.enabled = true;
+//
+// config.high_pass_filter.enabled = true;
+//
+// config.voice_detection.enabled = true;
+//
+// apm->ApplyConfig(config)
+//
+// apm->noise_reduction()->set_level(kHighSuppression);
+// apm->noise_reduction()->Enable(true);
+//
+// // Start a voice call...
+//
+// // ... Render frame arrives bound for the audio HAL ...
+// apm->ProcessReverseStream(render_frame);
+//
+// // ... Capture frame arrives from the audio HAL ...
+// // Call required set_stream_ functions.
+// apm->set_stream_delay_ms(delay_ms);
+// apm->set_stream_analog_level(analog_level);
+//
+// apm->ProcessStream(capture_frame);
+//
+// // Call required stream_ functions.
+// analog_level = apm->recommended_stream_analog_level();
+// has_voice = apm->stream_has_voice();
+//
+// // Repeat render and capture processing for the duration of the call...
+// // Start a new call...
+// apm->Initialize();
+//
+// // Close the application...
+// delete apm;
+//
+class RTC_EXPORT AudioProcessing : public rtc::RefCountInterface {
+ public:
+  // The struct below constitutes the new parameter scheme for the audio
+  // processing. It is being introduced gradually and until it is fully
+  // introduced, it is prone to change.
+  // TODO(peah): Remove this comment once the new config scheme is fully rolled
+  // out.
+  //
+  // The parameters and behavior of the audio processing module are controlled
+  // by changing the default values in the AudioProcessing::Config struct.
+  // The config is applied by passing the struct to the ApplyConfig method.
+  //
+  // This config is intended to be used during setup, and to enable/disable
+  // top-level processing effects. Use during processing may cause undesired
+  // submodule resets, affecting the audio quality. Use the RuntimeSetting
+  // construct for runtime configuration.
+  struct RTC_EXPORT Config {
+
+    // Sets the properties of the audio processing pipeline.
+    struct RTC_EXPORT Pipeline {
+      // Maximum allowed processing rate used internally. May only be set to
+      // 32000 or 48000 and any differing values will be treated as 48000.
+      int maximum_internal_processing_rate = 48000;
+      // Allow multi-channel processing of render audio.
+      bool multi_channel_render = false;
+      // Allow multi-channel processing of capture audio when AEC3 is active
+      // or a custom AEC is injected..
+      bool multi_channel_capture = false;
+    } pipeline;
+
+    // Enabled the pre-amplifier. It amplifies the capture signal
+    // before any other processing is done.
+    // TODO(webrtc:5298): Deprecate and use the pre-gain functionality in
+    // capture_level_adjustment instead.
+    struct PreAmplifier {
+      bool enabled = false;
+      float fixed_gain_factor = 1.0f;
+    } pre_amplifier;
+
+    // Functionality for general level adjustment in the capture pipeline. This
+    // should not be used together with the legacy PreAmplifier functionality.
+    struct CaptureLevelAdjustment {
+      bool operator==(const CaptureLevelAdjustment& rhs) const;
+      bool operator!=(const CaptureLevelAdjustment& rhs) const {
+        return !(*this == rhs);
+      }
+      bool enabled = false;
+      // The `pre_gain_factor` scales the signal before any processing is done.
+      float pre_gain_factor = 1.0f;
+      // The `post_gain_factor` scales the signal after all processing is done.
+      float post_gain_factor = 1.0f;
+      struct AnalogMicGainEmulation {
+        bool operator==(const AnalogMicGainEmulation& rhs) const;
+        bool operator!=(const AnalogMicGainEmulation& rhs) const {
+          return !(*this == rhs);
+        }
+        bool enabled = false;
+        // Initial analog gain level to use for the emulated analog gain. Must
+        // be in the range [0...255].
+        int initial_level = 255;
+      } analog_mic_gain_emulation;
+    } capture_level_adjustment;
+
+    struct HighPassFilter {
+      bool enabled = false;
+      bool apply_in_full_band = true;
+    } high_pass_filter;
+
+    struct EchoCanceller {
+      bool enabled = false;
+      bool mobile_mode = false;
+      bool export_linear_aec_output = false;
+      // Enforce the highpass filter to be on (has no effect for the mobile
+      // mode).
+      bool enforce_high_pass_filtering = true;
+    } echo_canceller;
+
+    // Enables background noise suppression.
+    struct NoiseSuppression {
+      bool enabled = false;
+      enum Level { kLow, kModerate, kHigh, kVeryHigh };
+      Level level = kModerate;
+      bool analyze_linear_aec_output_when_available = false;
+    } noise_suppression;
+
+    // Enables transient suppression.
+    struct TransientSuppression {
+      bool enabled = false;
+    } transient_suppression;
+
+    // Enables reporting of |voice_detected| in webrtc::AudioProcessingStats.
+    struct VoiceDetection {
+      bool enabled = false;
+    } voice_detection;
+
+    // Enables automatic gain control (AGC) functionality.
+    // The automatic gain control (AGC) component brings the signal to an
+    // appropriate range. This is done by applying a digital gain directly and,
+    // in the analog mode, prescribing an analog gain to be applied at the audio
+    // HAL.
+    // Recommended to be enabled on the client-side.
+    struct GainController1 {
+      bool operator==(const GainController1& rhs) const;
+      bool operator!=(const GainController1& rhs) const {
+        return !(*this == rhs);
+      }
+
+      bool enabled = false;
+      enum Mode {
+        // Adaptive mode intended for use if an analog volume control is
+        // available on the capture device. It will require the user to provide
+        // coupling between the OS mixer controls and AGC through the
+        // stream_analog_level() functions.
+        // It consists of an analog gain prescription for the audio device and a
+        // digital compression stage.
+        kAdaptiveAnalog,
+        // Adaptive mode intended for situations in which an analog volume
+        // control is unavailable. It operates in a similar fashion to the
+        // adaptive analog mode, but with scaling instead applied in the digital
+        // domain. As with the analog mode, it additionally uses a digital
+        // compression stage.
+        kAdaptiveDigital,
+        // Fixed mode which enables only the digital compression stage also used
+        // by the two adaptive modes.
+        // It is distinguished from the adaptive modes by considering only a
+        // short time-window of the input signal. It applies a fixed gain
+        // through most of the input level range, and compresses (gradually
+        // reduces gain with increasing level) the input signal at higher
+        // levels. This mode is preferred on embedded devices where the capture
+        // signal level is predictable, so that a known gain can be applied.
+        kFixedDigital
+      };
+      Mode mode = kAdaptiveAnalog;
+      // Sets the target peak level (or envelope) of the AGC in dBFs (decibels
+      // from digital full-scale). The convention is to use positive values. For
+      // instance, passing in a value of 3 corresponds to -3 dBFs, or a target
+      // level 3 dB below full-scale. Limited to [0, 31].
+      int target_level_dbfs = 3;
+      // Sets the maximum gain the digital compression stage may apply, in dB. A
+      // higher number corresponds to greater compression, while a value of 0
+      // will leave the signal uncompressed. Limited to [0, 90].
+      // For updates after APM setup, use a RuntimeSetting instead.
+      int compression_gain_db = 9;
+      // When enabled, the compression stage will hard limit the signal to the
+      // target level. Otherwise, the signal will be compressed but not limited
+      // above the target level.
+      bool enable_limiter = true;
+      // Sets the minimum and maximum analog levels of the audio capture device.
+      // Must be set if an analog mode is used. Limited to [0, 65535].
+      int analog_level_minimum = 0;
+      int analog_level_maximum = 255;
+
+      // Enables the analog gain controller functionality.
+      struct AnalogGainController {
+        bool enabled = true;
+        int startup_min_volume = kAgcStartupMinVolume;
+        // Lowest analog microphone level that will be applied in response to
+        // clipping.
+        int clipped_level_min = kClippedLevelMin;
+        bool enable_digital_adaptive = true;
+      } analog_gain_controller;
+    } gain_controller1;
+
+    // Enables the next generation AGC functionality. This feature replaces the
+    // standard methods of gain control in the previous AGC. Enabling this
+    // submodule enables an adaptive digital AGC followed by a limiter. By
+    // setting |fixed_gain_db|, the limiter can be turned into a compressor that
+    // first applies a fixed gain. The adaptive digital AGC can be turned off by
+    // setting |adaptive_digital_mode=false|.
+    struct GainController2 {
+      bool operator==(const GainController2& rhs) const;
+      bool operator!=(const GainController2& rhs) const {
+        return !(*this == rhs);
+      }
+
+      // TODO(crbug.com/webrtc/7494): Remove `LevelEstimator`.
+      enum LevelEstimator { kRms, kPeak };
+      enum NoiseEstimator { kStationaryNoise, kNoiseFloor };
+      bool enabled = false;
+      struct FixedDigital {
+        float gain_db = 0.0f;
+      } fixed_digital;
+      struct AdaptiveDigital {
+        bool enabled = false;
+        NoiseEstimator noise_estimator = kNoiseFloor;
+        int vad_reset_period_ms = 1500;
+        int adjacent_speech_frames_threshold = 12;
+        float max_gain_change_db_per_second = 3.0f;
+        float max_output_noise_level_dbfs = -50.0f;
+        bool sse2_allowed = true;
+        bool avx2_allowed = true;
+        bool neon_allowed = true;
+        // TODO(crbug.com/webrtc/7494): Remove deprecated settings below.
+        float vad_probability_attack = 1.0f;
+        LevelEstimator level_estimator = kRms;
+        int level_estimator_adjacent_speech_frames_threshold = 12;
+        bool use_saturation_protector = true;
+        float initial_saturation_margin_db = 25.0f;
+        float extra_saturation_margin_db = 5.0f;
+        int gain_applier_adjacent_speech_frames_threshold = 12;
+      } adaptive_digital;
+    } gain_controller2;
+
+    struct ResidualEchoDetector {
+      bool enabled = true;
+    } residual_echo_detector;
+
+    // Enables reporting of |output_rms_dbfs| in webrtc::AudioProcessingStats.
+    struct LevelEstimation {
+      bool enabled = false;
+    } level_estimation;
+
+    std::string ToString() const;
+  };
+
+  // TODO(mgraczyk): Remove once all methods that use ChannelLayout are gone.
+  enum ChannelLayout {
+    kMono,
+    // Left, right.
+    kStereo,
+    // Mono, keyboard, and mic.
+    kMonoAndKeyboard,
+    // Left, right, keyboard, and mic.
+    kStereoAndKeyboard
+  };
+
+  // Specifies the properties of a setting to be passed to AudioProcessing at
+  // runtime.
+  class RuntimeSetting {
+   public:
+    enum class Type {
+      kNotSpecified,
+      kCapturePreGain,
+      kCaptureCompressionGain,
+      kCaptureFixedPostGain,
+      kPlayoutVolumeChange,
+      kCustomRenderProcessingRuntimeSetting,
+      kPlayoutAudioDeviceChange,
+      kCapturePostGain,
+      kCaptureOutputUsed
+    };
+
+    // Play-out audio device properties.
+    struct PlayoutAudioDeviceInfo {
+      int id;          // Identifies the audio device.
+      int max_volume;  // Maximum play-out volume.
+    };
+
+    RuntimeSetting() : type_(Type::kNotSpecified), value_(0.0f) {}
+    ~RuntimeSetting() = default;
+
+    static RuntimeSetting CreateCapturePreGain(float gain) {
+      return {Type::kCapturePreGain, gain};
+    }
+
+    static RuntimeSetting CreateCapturePostGain(float gain) {
+      return {Type::kCapturePostGain, gain};
+    }
+
+    // Corresponds to Config::GainController1::compression_gain_db, but for
+    // runtime configuration.
+    static RuntimeSetting CreateCompressionGainDb(int gain_db) {
+      RTC_DCHECK_GE(gain_db, 0);
+      RTC_DCHECK_LE(gain_db, 90);
+      return {Type::kCaptureCompressionGain, static_cast<float>(gain_db)};
+    }
+
+    // Corresponds to Config::GainController2::fixed_digital::gain_db, but for
+    // runtime configuration.
+    static RuntimeSetting CreateCaptureFixedPostGain(float gain_db) {
+      RTC_DCHECK_GE(gain_db, 0.0f);
+      RTC_DCHECK_LE(gain_db, 90.0f);
+      return {Type::kCaptureFixedPostGain, gain_db};
+    }
+
+    // Creates a runtime setting to notify play-out (aka render) audio device
+    // changes.
+    static RuntimeSetting CreatePlayoutAudioDeviceChange(
+        PlayoutAudioDeviceInfo audio_device) {
+      return {Type::kPlayoutAudioDeviceChange, audio_device};
+    }
+
+    // Creates a runtime setting to notify play-out (aka render) volume changes.
+    // |volume| is the unnormalized volume, the maximum of which
+    static RuntimeSetting CreatePlayoutVolumeChange(int volume) {
+      return {Type::kPlayoutVolumeChange, volume};
+    }
+
+    static RuntimeSetting CreateCustomRenderSetting(float payload) {
+      return {Type::kCustomRenderProcessingRuntimeSetting, payload};
+    }
+
+    static RuntimeSetting CreateCaptureOutputUsedSetting(
+        bool capture_output_used) {
+      return {Type::kCaptureOutputUsed, capture_output_used};
+    }
+
+    Type type() const { return type_; }
+    // Getters do not return a value but instead modify the argument to protect
+    // from implicit casting.
+    void GetFloat(float* value) const {
+      RTC_DCHECK(value);
+      *value = value_.float_value;
+    }
+    void GetInt(int* value) const {
+      RTC_DCHECK(value);
+      *value = value_.int_value;
+    }
+    void GetBool(bool* value) const {
+      RTC_DCHECK(value);
+      *value = value_.bool_value;
+    }
+    void GetPlayoutAudioDeviceInfo(PlayoutAudioDeviceInfo* value) const {
+      RTC_DCHECK(value);
+      *value = value_.playout_audio_device_info;
+    }
+
+   private:
+    RuntimeSetting(Type id, float value) : type_(id), value_(value) {}
+    RuntimeSetting(Type id, int value) : type_(id), value_(value) {}
+    RuntimeSetting(Type id, PlayoutAudioDeviceInfo value)
+        : type_(id), value_(value) {}
+    Type type_;
+    union U {
+      U() {}
+      U(int value) : int_value(value) {}
+      U(float value) : float_value(value) {}
+      U(PlayoutAudioDeviceInfo value) : playout_audio_device_info(value) {}
+      float float_value;
+      int int_value;
+      bool bool_value;
+      PlayoutAudioDeviceInfo playout_audio_device_info;
+    } value_;
+  };
+
+  ~AudioProcessing() override {}
+
+  // Initializes internal states, while retaining all user settings. This
+  // should be called before beginning to process a new audio stream. However,
+  // it is not necessary to call before processing the first stream after
+  // creation.
+  //
+  // It is also not necessary to call if the audio parameters (sample
+  // rate and number of channels) have changed. Passing updated parameters
+  // directly to |ProcessStream()| and |ProcessReverseStream()| is permissible.
+  // If the parameters are known at init-time though, they may be provided.
+  // TODO(webrtc:5298): Change to return void.
+  virtual int Initialize() = 0;
+
+  // The int16 interfaces require:
+  //   - only |NativeRate|s be used
+  //   - that the input, output and reverse rates must match
+  //   - that |processing_config.output_stream()| matches
+  //     |processing_config.input_stream()|.
+  //
+  // The float interfaces accept arbitrary rates and support differing input and
+  // output layouts, but the output must have either one channel or the same
+  // number of channels as the input.
+  virtual int Initialize(const ProcessingConfig& processing_config) = 0;
+
+  // Initialize with unpacked parameters. See Initialize() above for details.
+  //
+  // TODO(mgraczyk): Remove once clients are updated to use the new interface.
+  virtual int Initialize(int capture_input_sample_rate_hz,
+                         int capture_output_sample_rate_hz,
+                         int render_sample_rate_hz,
+                         ChannelLayout capture_input_layout,
+                         ChannelLayout capture_output_layout,
+                         ChannelLayout render_input_layout) = 0;
+
+  // TODO(peah): This method is a temporary solution used to take control
+  // over the parameters in the audio processing module and is likely to change.
+  virtual void ApplyConfig(const Config& config) = 0;
+
+  // TODO(ajm): Only intended for internal use. Make private and friend the
+  // necessary classes?
+  virtual int proc_sample_rate_hz() const = 0;
+  virtual int proc_split_sample_rate_hz() const = 0;
+  virtual size_t num_input_channels() const = 0;
+  virtual size_t num_proc_channels() const = 0;
+  virtual size_t num_output_channels() const = 0;
+  virtual size_t num_reverse_channels() const = 0;
+
+  // Set to true when the output of AudioProcessing will be muted or in some
+  // other way not used. Ideally, the captured audio would still be processed,
+  // but some components may change behavior based on this information.
+  // Default false. This method takes a lock. To achieve this in a lock-less
+  // manner the PostRuntimeSetting can instead be used.
+  virtual void set_output_will_be_muted(bool muted) = 0;
+
+  // Enqueues a runtime setting.
+  virtual void SetRuntimeSetting(RuntimeSetting setting) = 0;
+
+  // Enqueues a runtime setting. Returns a bool indicating whether the
+  // enqueueing was successfull.
+  virtual bool PostRuntimeSetting(RuntimeSetting setting) = 0;
+
+  // Accepts and produces a 10 ms frame interleaved 16 bit integer audio as
+  // specified in |input_config| and |output_config|. |src| and |dest| may use
+  // the same memory, if desired.
+  virtual int ProcessStream(const int16_t* const src,
+                            const StreamConfig& input_config,
+                            const StreamConfig& output_config,
+                            int16_t* const dest) = 0;
+
+  // Accepts deinterleaved float audio with the range [-1, 1]. Each element of
+  // |src| points to a channel buffer, arranged according to |input_stream|. At
+  // output, the channels will be arranged according to |output_stream| in
+  // |dest|.
+  //
+  // The output must have one channel or as many channels as the input. |src|
+  // and |dest| may use the same memory, if desired.
+  virtual int ProcessStream(const float* const* src,
+                            const StreamConfig& input_config,
+                            const StreamConfig& output_config,
+                            float* const* dest) = 0;
+
+  // Accepts and produces a 10 ms frame of interleaved 16 bit integer audio for
+  // the reverse direction audio stream as specified in |input_config| and
+  // |output_config|. |src| and |dest| may use the same memory, if desired.
+  virtual int ProcessReverseStream(const int16_t* const src,
+                                   const StreamConfig& input_config,
+                                   const StreamConfig& output_config,
+                                   int16_t* const dest) = 0;
+
+  // Accepts deinterleaved float audio with the range [-1, 1]. Each element of
+  // |data| points to a channel buffer, arranged according to |reverse_config|.
+  virtual int ProcessReverseStream(const float* const* src,
+                                   const StreamConfig& input_config,
+                                   const StreamConfig& output_config,
+                                   float* const* dest) = 0;
+
+  // Accepts deinterleaved float audio with the range [-1, 1]. Each element
+  // of |data| points to a channel buffer, arranged according to
+  // |reverse_config|.
+  virtual int AnalyzeReverseStream(const float* const* data,
+                                   const StreamConfig& reverse_config) = 0;
+
+  // Returns the most recently produced 10 ms of the linear AEC output at a rate
+  // of 16 kHz. If there is more than one capture channel, a mono representation
+  // of the input is returned. Returns true/false to indicate whether an output
+  // returned.
+  virtual bool GetLinearAecOutput(
+      rtc::ArrayView<std::array<float, 160>> linear_output) const = 0;
+
+  // This must be called prior to ProcessStream() if and only if adaptive analog
+  // gain control is enabled, to pass the current analog level from the audio
+  // HAL. Must be within the range provided in Config::GainController1.
+  virtual void set_stream_analog_level(int level) = 0;
+
+  // When an analog mode is set, this should be called after ProcessStream()
+  // to obtain the recommended new analog level for the audio HAL. It is the
+  // user's responsibility to apply this level.
+  virtual int recommended_stream_analog_level() const = 0;
+
+  // This must be called if and only if echo processing is enabled.
+  //
+  // Sets the |delay| in ms between ProcessReverseStream() receiving a far-end
+  // frame and ProcessStream() receiving a near-end frame containing the
+  // corresponding echo. On the client-side this can be expressed as
+  //   delay = (t_render - t_analyze) + (t_process - t_capture)
+  // where,
+  //   - t_analyze is the time a frame is passed to ProcessReverseStream() and
+  //     t_render is the time the first sample of the same frame is rendered by
+  //     the audio hardware.
+  //   - t_capture is the time the first sample of a frame is captured by the
+  //     audio hardware and t_process is the time the same frame is passed to
+  //     ProcessStream().
+  virtual int set_stream_delay_ms(int delay) = 0;
+  virtual int stream_delay_ms() const = 0;
+
+  // Call to signal that a key press occurred (true) or did not occur (false)
+  // with this chunk of audio.
+  virtual void set_stream_key_pressed(bool key_pressed) = 0;
+
+  // Creates and attaches an webrtc::AecDump for recording debugging
+  // information.
+  // The |worker_queue| may not be null and must outlive the created
+  // AecDump instance. |max_log_size_bytes == -1| means the log size
+  // will be unlimited. |handle| may not be null. The AecDump takes
+  // responsibility for |handle| and closes it in the destructor. A
+  // return value of true indicates that the file has been
+  // sucessfully opened, while a value of false indicates that
+  // opening the file failed.
+  virtual bool CreateAndAttachAecDump(const std::string& file_name,
+                                      int64_t max_log_size_bytes,
+                                      rtc::TaskQueue* worker_queue) = 0;
+  virtual bool CreateAndAttachAecDump(FILE* handle,
+                                      int64_t max_log_size_bytes,
+                                      rtc::TaskQueue* worker_queue) = 0;
+
+  // TODO(webrtc:5298) Deprecated variant.
+  // Attaches provided webrtc::AecDump for recording debugging
+  // information. Log file and maximum file size logic is supposed to
+  // be handled by implementing instance of AecDump. Calling this
+  // method when another AecDump is attached resets the active AecDump
+  // with a new one. This causes the d-tor of the earlier AecDump to
+  // be called. The d-tor call may block until all pending logging
+  // tasks are completed.
+  virtual void AttachAecDump(std::unique_ptr<AecDump> aec_dump) = 0;
+
+  // If no AecDump is attached, this has no effect. If an AecDump is
+  // attached, it's destructor is called. The d-tor may block until
+  // all pending logging tasks are completed.
+  virtual void DetachAecDump() = 0;
+
+  // Get audio processing statistics.
+  virtual AudioProcessingStats GetStatistics() = 0;
+  // TODO(webrtc:5298) Deprecated variant. The |has_remote_tracks| argument
+  // should be set if there are active remote tracks (this would usually be true
+  // during a call). If there are no remote tracks some of the stats will not be
+  // set by AudioProcessing, because they only make sense if there is at least
+  // one remote track.
+  virtual AudioProcessingStats GetStatistics(bool has_remote_tracks) = 0;
+
+  // Returns the last applied configuration.
+  virtual AudioProcessing::Config GetConfig() const = 0;
+
+  enum Error {
+    // Fatal errors.
+    kNoError = 0,
+    kUnspecifiedError = -1,
+    kCreationFailedError = -2,
+    kUnsupportedComponentError = -3,
+    kUnsupportedFunctionError = -4,
+    kNullPointerError = -5,
+    kBadParameterError = -6,
+    kBadSampleRateError = -7,
+    kBadDataLengthError = -8,
+    kBadNumberChannelsError = -9,
+    kFileError = -10,
+    kStreamParameterNotSetError = -11,
+    kNotEnabledError = -12,
+
+    // Warnings are non-fatal.
+    // This results when a set_stream_ parameter is out of range. Processing
+    // will continue, but the parameter may have been truncated.
+    kBadStreamParameterWarning = -13
+  };
+
+  // Native rates supported by the integer interfaces.
+  enum NativeRate {
+    kSampleRate8kHz = 8000,
+    kSampleRate16kHz = 16000,
+    kSampleRate32kHz = 32000,
+    kSampleRate48kHz = 48000
+  };
+
+  // TODO(kwiberg): We currently need to support a compiler (Visual C++) that
+  // complains if we don't explicitly state the size of the array here. Remove
+  // the size when that's no longer the case.
+  static constexpr int kNativeSampleRatesHz[4] = {
+      kSampleRate8kHz, kSampleRate16kHz, kSampleRate32kHz, kSampleRate48kHz};
+  static constexpr size_t kNumNativeSampleRates =
+      arraysize(kNativeSampleRatesHz);
+  static constexpr int kMaxNativeSampleRateHz =
+      kNativeSampleRatesHz[kNumNativeSampleRates - 1];
+
+  static constexpr int kChunkSizeMs = 10;
+};
+
+class RTC_EXPORT AudioProcessingBuilder {
+ public:
+  AudioProcessingBuilder();
+  ~AudioProcessingBuilder();
+  // The AudioProcessingBuilder takes ownership of the echo_control_factory.
+  AudioProcessingBuilder& SetEchoControlFactory(
+      std::unique_ptr<EchoControlFactory> echo_control_factory) {
+    echo_control_factory_ = std::move(echo_control_factory);
+    return *this;
+  }
+  // The AudioProcessingBuilder takes ownership of the capture_post_processing.
+  AudioProcessingBuilder& SetCapturePostProcessing(
+      std::unique_ptr<CustomProcessing> capture_post_processing) {
+    capture_post_processing_ = std::move(capture_post_processing);
+    return *this;
+  }
+  // The AudioProcessingBuilder takes ownership of the render_pre_processing.
+  AudioProcessingBuilder& SetRenderPreProcessing(
+      std::unique_ptr<CustomProcessing> render_pre_processing) {
+    render_pre_processing_ = std::move(render_pre_processing);
+    return *this;
+  }
+  // The AudioProcessingBuilder takes ownership of the echo_detector.
+  AudioProcessingBuilder& SetEchoDetector(
+      rtc::scoped_refptr<EchoDetector> echo_detector) {
+    echo_detector_ = std::move(echo_detector);
+    return *this;
+  }
+  // The AudioProcessingBuilder takes ownership of the capture_analyzer.
+  AudioProcessingBuilder& SetCaptureAnalyzer(
+      std::unique_ptr<CustomAudioAnalyzer> capture_analyzer) {
+    capture_analyzer_ = std::move(capture_analyzer);
+    return *this;
+  }
+  // This creates an APM instance using the previously set components. Calling
+  // the Create function resets the AudioProcessingBuilder to its initial state.
+  AudioProcessing* Create();
+  AudioProcessing* Create(const webrtc::Config& config);
+
+ private:
+  std::unique_ptr<EchoControlFactory> echo_control_factory_;
+  std::unique_ptr<CustomProcessing> capture_post_processing_;
+  std::unique_ptr<CustomProcessing> render_pre_processing_;
+  rtc::scoped_refptr<EchoDetector> echo_detector_;
+  std::unique_ptr<CustomAudioAnalyzer> capture_analyzer_;
+  RTC_DISALLOW_COPY_AND_ASSIGN(AudioProcessingBuilder);
+};
+
+class StreamConfig {
+ public:
+  // sample_rate_hz: The sampling rate of the stream.
+  //
+  // num_channels: The number of audio channels in the stream, excluding the
+  //               keyboard channel if it is present. When passing a
+  //               StreamConfig with an array of arrays T*[N],
+  //
+  //                N == {num_channels + 1  if  has_keyboard
+  //                     {num_channels      if  !has_keyboard
+  //
+  // has_keyboard: True if the stream has a keyboard channel. When has_keyboard
+  //               is true, the last channel in any corresponding list of
+  //               channels is the keyboard channel.
+  StreamConfig(int sample_rate_hz = 0,
+               size_t num_channels = 0,
+               bool has_keyboard = false)
+      : sample_rate_hz_(sample_rate_hz),
+        num_channels_(num_channels),
+        has_keyboard_(has_keyboard),
+        num_frames_(calculate_frames(sample_rate_hz)) {}
+
+  void set_sample_rate_hz(int value) {
+    sample_rate_hz_ = value;
+    num_frames_ = calculate_frames(value);
+  }
+  void set_num_channels(size_t value) { num_channels_ = value; }
+  void set_has_keyboard(bool value) { has_keyboard_ = value; }
+
+  int sample_rate_hz() const { return sample_rate_hz_; }
+
+  // The number of channels in the stream, not including the keyboard channel if
+  // present.
+  size_t num_channels() const { return num_channels_; }
+
+  bool has_keyboard() const { return has_keyboard_; }
+  size_t num_frames() const { return num_frames_; }
+  size_t num_samples() const { return num_channels_ * num_frames_; }
+
+  bool operator==(const StreamConfig& other) const {
+    return sample_rate_hz_ == other.sample_rate_hz_ &&
+           num_channels_ == other.num_channels_ &&
+           has_keyboard_ == other.has_keyboard_;
+  }
+
+  bool operator!=(const StreamConfig& other) const { return !(*this == other); }
+
+ private:
+  static size_t calculate_frames(int sample_rate_hz) {
+    return static_cast<size_t>(AudioProcessing::kChunkSizeMs * sample_rate_hz /
+                               1000);
+  }
+
+  int sample_rate_hz_;
+  size_t num_channels_;
+  bool has_keyboard_;
+  size_t num_frames_;
+};
+
+class ProcessingConfig {
+ public:
+  enum StreamName {
+    kInputStream,
+    kOutputStream,
+    kReverseInputStream,
+    kReverseOutputStream,
+    kNumStreamNames,
+  };
+
+  const StreamConfig& input_stream() const {
+    return streams[StreamName::kInputStream];
+  }
+  const StreamConfig& output_stream() const {
+    return streams[StreamName::kOutputStream];
+  }
+  const StreamConfig& reverse_input_stream() const {
+    return streams[StreamName::kReverseInputStream];
+  }
+  const StreamConfig& reverse_output_stream() const {
+    return streams[StreamName::kReverseOutputStream];
+  }
+
+  StreamConfig& input_stream() { return streams[StreamName::kInputStream]; }
+  StreamConfig& output_stream() { return streams[StreamName::kOutputStream]; }
+  StreamConfig& reverse_input_stream() {
+    return streams[StreamName::kReverseInputStream];
+  }
+  StreamConfig& reverse_output_stream() {
+    return streams[StreamName::kReverseOutputStream];
+  }
+
+  bool operator==(const ProcessingConfig& other) const {
+    for (int i = 0; i < StreamName::kNumStreamNames; ++i) {
+      if (this->streams[i] != other.streams[i]) {
+        return false;
+      }
+    }
+    return true;
+  }
+
+  bool operator!=(const ProcessingConfig& other) const {
+    return !(*this == other);
+  }
+
+  StreamConfig streams[StreamName::kNumStreamNames];
+};
+
+// Experimental interface for a custom analysis submodule.
+class CustomAudioAnalyzer {
+ public:
+  // (Re-) Initializes the submodule.
+  virtual void Initialize(int sample_rate_hz, int num_channels) = 0;
+  // Analyzes the given capture or render signal.
+  virtual void Analyze(const AudioBuffer* audio) = 0;
+  // Returns a string representation of the module state.
+  virtual std::string ToString() const = 0;
+
+  virtual ~CustomAudioAnalyzer() {}
+};
+
+// Interface for a custom processing submodule.
+class CustomProcessing {
+ public:
+  // (Re-)Initializes the submodule.
+  virtual void Initialize(int sample_rate_hz, int num_channels) = 0;
+  // Processes the given capture or render signal.
+  virtual void Process(AudioBuffer* audio) = 0;
+  // Returns a string representation of the module state.
+  virtual std::string ToString() const = 0;
+  // Handles RuntimeSettings. TODO(webrtc:9262): make pure virtual
+  // after updating dependencies.
+  virtual void SetRuntimeSetting(AudioProcessing::RuntimeSetting setting);
+
+  virtual ~CustomProcessing() {}
+};
+
+// Interface for an echo detector submodule.
+class EchoDetector : public rtc::RefCountInterface {
+ public:
+  // (Re-)Initializes the submodule.
+  virtual void Initialize(int capture_sample_rate_hz,
+                          int num_capture_channels,
+                          int render_sample_rate_hz,
+                          int num_render_channels) = 0;
+
+  // Analysis (not changing) of the render signal.
+  virtual void AnalyzeRenderAudio(rtc::ArrayView<const float> render_audio) = 0;
+
+  // Analysis (not changing) of the capture signal.
+  virtual void AnalyzeCaptureAudio(
+      rtc::ArrayView<const float> capture_audio) = 0;
+
+  // Pack an AudioBuffer into a vector<float>.
+  static void PackRenderAudioBuffer(AudioBuffer* audio,
+                                    std::vector<float>* packed_buffer);
+
+  struct Metrics {
+    absl::optional<double> echo_likelihood;
+    absl::optional<double> echo_likelihood_recent_max;
+  };
+
+  // Collect current metrics from the echo detector.
+  virtual Metrics GetMetrics() const = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_INCLUDE_AUDIO_PROCESSING_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/include/audio_processing_statistics.cc b/third_party/webrtc_aec3/src/modules/audio_processing/include/audio_processing_statistics.cc
new file mode 100644
index 0000000..7139ee5
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/include/audio_processing_statistics.cc
@@ -0,0 +1,22 @@
+/*
+ *  Copyright 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/include/audio_processing_statistics.h"
+
+namespace webrtc {
+
+AudioProcessingStats::AudioProcessingStats() = default;
+
+AudioProcessingStats::AudioProcessingStats(const AudioProcessingStats& other) =
+    default;
+
+AudioProcessingStats::~AudioProcessingStats() = default;
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/include/audio_processing_statistics.h b/third_party/webrtc_aec3/src/modules/audio_processing/include/audio_processing_statistics.h
new file mode 100644
index 0000000..87babee
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/include/audio_processing_statistics.h
@@ -0,0 +1,73 @@
+/*
+ *  Copyright 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_INCLUDE_AUDIO_PROCESSING_STATISTICS_H_
+#define MODULES_AUDIO_PROCESSING_INCLUDE_AUDIO_PROCESSING_STATISTICS_H_
+
+#include <stdint.h>
+
+#include "absl/types/optional.h"
+#include "rtc_base/system/rtc_export.h"
+
+namespace webrtc {
+// This version of the stats uses Optionals, it will replace the regular
+// AudioProcessingStatistics struct.
+struct RTC_EXPORT AudioProcessingStats {
+  AudioProcessingStats();
+  AudioProcessingStats(const AudioProcessingStats& other);
+  ~AudioProcessingStats();
+
+  // The root mean square (RMS) level in dBFS (decibels from digital
+  // full-scale) of the last capture frame, after processing. It is
+  // constrained to [-127, 0].
+  // The computation follows: https://tools.ietf.org/html/rfc6465
+  // with the intent that it can provide the RTP audio level indication.
+  // Only reported if level estimation is enabled in AudioProcessing::Config.
+  absl::optional<int> output_rms_dbfs;
+
+  // True if voice is detected in the last capture frame, after processing.
+  // It is conservative in flagging audio as speech, with low likelihood of
+  // incorrectly flagging a frame as voice.
+  // Only reported if voice detection is enabled in AudioProcessing::Config.
+  absl::optional<bool> voice_detected;
+
+  // AEC Statistics.
+  // ERL = 10log_10(P_far / P_echo)
+  absl::optional<double> echo_return_loss;
+  // ERLE = 10log_10(P_echo / P_out)
+  absl::optional<double> echo_return_loss_enhancement;
+  // Fraction of time that the AEC linear filter is divergent, in a 1-second
+  // non-overlapped aggregation window.
+  absl::optional<double> divergent_filter_fraction;
+
+  // The delay metrics consists of the delay median and standard deviation. It
+  // also consists of the fraction of delay estimates that can make the echo
+  // cancellation perform poorly. The values are aggregated until the first
+  // call to |GetStatistics()| and afterwards aggregated and updated every
+  // second. Note that if there are several clients pulling metrics from
+  // |GetStatistics()| during a session the first call from any of them will
+  // change to one second aggregation window for all.
+  absl::optional<int32_t> delay_median_ms;
+  absl::optional<int32_t> delay_standard_deviation_ms;
+
+  // Residual echo detector likelihood.
+  absl::optional<double> residual_echo_likelihood;
+  // Maximum residual echo likelihood from the last time period.
+  absl::optional<double> residual_echo_likelihood_recent_max;
+
+  // The instantaneous delay estimate produced in the AEC. The unit is in
+  // milliseconds and the value is the instantaneous value at the time of the
+  // call to |GetStatistics()|.
+  absl::optional<int32_t> delay_ms;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_INCLUDE_AUDIO_PROCESSING_STATISTICS_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/include/config.cc b/third_party/webrtc_aec3/src/modules/audio_processing/include/config.cc
new file mode 100644
index 0000000..14240db
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/include/config.cc
@@ -0,0 +1,23 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/include/config.h"
+
+namespace webrtc {
+
+Config::Config() {}
+
+Config::~Config() {
+  for (OptionMap::iterator it = options_.begin(); it != options_.end(); ++it) {
+    delete it->second;
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/include/config.h b/third_party/webrtc_aec3/src/modules/audio_processing/include/config.h
new file mode 100644
index 0000000..7fab178
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/include/config.h
@@ -0,0 +1,131 @@
+/*
+ *  Copyright (c) 2013 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_INCLUDE_CONFIG_H_
+#define MODULES_AUDIO_PROCESSING_INCLUDE_CONFIG_H_
+
+#include <map>
+
+#include "rtc_base/system/rtc_export.h"
+
+namespace webrtc {
+
+// Only add new values to the end of the enumeration and never remove (only
+// deprecate) to maintain binary compatibility.
+enum class ConfigOptionID {
+  kMyExperimentForTest,
+  kAlgo1CostFunctionForTest,
+  kTemporalLayersFactory,  // Deprecated
+  kNetEqCapacityConfig,    // Deprecated
+  kNetEqFastAccelerate,    // Deprecated
+  kVoicePacing,            // Deprecated
+  kExtendedFilter,         // Deprecated
+  kDelayAgnostic,          // Deprecated
+  kExperimentalAgc,
+  kExperimentalNs,
+  kBeamforming,               // Deprecated
+  kIntelligibility,           // Deprecated
+  kEchoCanceller3,            // Deprecated
+  kAecRefinedAdaptiveFilter,  // Deprecated
+  kLevelControl               // Deprecated
+};
+
+// Class Config is designed to ease passing a set of options across webrtc code.
+// Options are identified by typename in order to avoid incorrect casts.
+//
+// Usage:
+// * declaring an option:
+//    struct Algo1_CostFunction {
+//      virtual float cost(int x) const { return x; }
+//      virtual ~Algo1_CostFunction() {}
+//    };
+//
+// * accessing an option:
+//    config.Get<Algo1_CostFunction>().cost(value);
+//
+// * setting an option:
+//    struct SqrCost : Algo1_CostFunction {
+//      virtual float cost(int x) const { return x*x; }
+//    };
+//    config.Set<Algo1_CostFunction>(new SqrCost());
+//
+// Note: This class is thread-compatible (like STL containers).
+class RTC_EXPORT Config {
+ public:
+  // Returns the option if set or a default constructed one.
+  // Callers that access options too often are encouraged to cache the result.
+  // Returned references are owned by this.
+  //
+  // Requires std::is_default_constructible<T>
+  template <typename T>
+  const T& Get() const;
+
+  // Set the option, deleting any previous instance of the same.
+  // This instance gets ownership of the newly set value.
+  template <typename T>
+  void Set(T* value);
+
+  Config();
+  ~Config();
+
+ private:
+  struct BaseOption {
+    virtual ~BaseOption() {}
+  };
+
+  template <typename T>
+  struct Option : BaseOption {
+    explicit Option(T* v) : value(v) {}
+    ~Option() { delete value; }
+    T* value;
+  };
+
+  template <typename T>
+  static ConfigOptionID identifier() {
+    return T::identifier;
+  }
+
+  // Used to instantiate a default constructed object that doesn't needs to be
+  // owned. This allows Get<T> to be implemented without requiring explicitly
+  // locks.
+  template <typename T>
+  static const T& default_value() {
+    static const T* const def = new T();
+    return *def;
+  }
+
+  typedef std::map<ConfigOptionID, BaseOption*> OptionMap;
+  OptionMap options_;
+
+  Config(const Config&);
+  void operator=(const Config&);
+};
+
+template <typename T>
+const T& Config::Get() const {
+  OptionMap::const_iterator it = options_.find(identifier<T>());
+  if (it != options_.end()) {
+    const T* t = static_cast<Option<T>*>(it->second)->value;
+    if (t) {
+      return *t;
+    }
+  }
+  return default_value<T>();
+}
+
+template <typename T>
+void Config::Set(T* value) {
+  BaseOption*& it = options_[identifier<T>()];
+  delete it;
+  it = new Option<T>(value);
+}
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_INCLUDE_CONFIG_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/logging/apm_data_dumper.cc b/third_party/webrtc_aec3/src/modules/audio_processing/logging/apm_data_dumper.cc
new file mode 100644
index 0000000..445248b
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/logging/apm_data_dumper.cc
@@ -0,0 +1,93 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+
+#include "rtc_base/strings/string_builder.h"
+
+// Check to verify that the define is properly set.
+#if !defined(WEBRTC_APM_DEBUG_DUMP) || \
+    (WEBRTC_APM_DEBUG_DUMP != 0 && WEBRTC_APM_DEBUG_DUMP != 1)
+#error "Set WEBRTC_APM_DEBUG_DUMP to either 0 or 1"
+#endif
+
+namespace webrtc {
+namespace {
+
+#if WEBRTC_APM_DEBUG_DUMP == 1
+
+#if defined(WEBRTC_WIN)
+constexpr char kPathDelimiter = '\\';
+#else
+constexpr char kPathDelimiter = '/';
+#endif
+
+std::string FormFileName(const char* output_dir,
+                         const char* name,
+                         int instance_index,
+                         int reinit_index,
+                         const std::string& suffix) {
+  char buf[1024];
+  rtc::SimpleStringBuilder ss(buf);
+  const size_t output_dir_size = strlen(output_dir);
+  if (output_dir_size > 0) {
+    ss << output_dir;
+    if (output_dir[output_dir_size - 1] != kPathDelimiter) {
+      ss << kPathDelimiter;
+    }
+  }
+  ss << name << "_" << instance_index << "-" << reinit_index << suffix;
+  return ss.str();
+}
+#endif
+
+}  // namespace
+
+#if WEBRTC_APM_DEBUG_DUMP == 1
+ApmDataDumper::ApmDataDumper(int instance_index)
+    : instance_index_(instance_index) {}
+#else
+ApmDataDumper::ApmDataDumper(int instance_index) {}
+#endif
+
+ApmDataDumper::~ApmDataDumper() = default;
+
+#if WEBRTC_APM_DEBUG_DUMP == 1
+bool ApmDataDumper::recording_activated_ = false;
+absl::optional<int> ApmDataDumper::dump_set_to_use_;
+char ApmDataDumper::output_dir_[] = "";
+
+FILE* ApmDataDumper::GetRawFile(const char* name) {
+  std::string filename = FormFileName(output_dir_, name, instance_index_,
+                                      recording_set_index_, ".dat");
+  auto& f = raw_files_[filename];
+  if (!f) {
+    f.reset(fopen(filename.c_str(), "wb"));
+    RTC_CHECK(f.get()) << "Cannot write to " << filename << ".";
+  }
+  return f.get();
+}
+
+WavWriter* ApmDataDumper::GetWavFile(const char* name,
+                                     int sample_rate_hz,
+                                     int num_channels,
+                                     WavFile::SampleFormat format) {
+  std::string filename = FormFileName(output_dir_, name, instance_index_,
+                                      recording_set_index_, ".wav");
+  auto& f = wav_files_[filename];
+  if (!f) {
+    f.reset(
+        new WavWriter(filename.c_str(), sample_rate_hz, num_channels, format));
+  }
+  return f.get();
+}
+#endif
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/logging/apm_data_dumper.h b/third_party/webrtc_aec3/src/modules/audio_processing/logging/apm_data_dumper.h
new file mode 100644
index 0000000..6d32b32
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/logging/apm_data_dumper.h
@@ -0,0 +1,393 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_LOGGING_APM_DATA_DUMPER_H_
+#define MODULES_AUDIO_PROCESSING_LOGGING_APM_DATA_DUMPER_H_
+
+#include <stdint.h>
+#include <stdio.h>
+#include <string.h>
+
+#include <string>
+#if WEBRTC_APM_DEBUG_DUMP == 1
+#include <memory>
+#include <unordered_map>
+#endif
+
+#include "absl/types/optional.h"
+#include "api/array_view.h"
+#if WEBRTC_APM_DEBUG_DUMP == 1
+#include "common_audio/wav_file.h"
+#include "rtc_base/checks.h"
+#endif
+
+// Check to verify that the define is properly set.
+#if !defined(WEBRTC_APM_DEBUG_DUMP) || \
+    (WEBRTC_APM_DEBUG_DUMP != 0 && WEBRTC_APM_DEBUG_DUMP != 1)
+#error "Set WEBRTC_APM_DEBUG_DUMP to either 0 or 1"
+#endif
+
+namespace webrtc {
+
+#if WEBRTC_APM_DEBUG_DUMP == 1
+// Functor used to use as a custom deleter in the map of file pointers to raw
+// files.
+struct RawFileCloseFunctor {
+  void operator()(FILE* f) const { fclose(f); }
+};
+#endif
+
+// Class that handles dumping of variables into files.
+class ApmDataDumper {
+ public:
+  // Constructor that takes an instance index that may
+  // be used to distinguish data dumped from different
+  // instances of the code.
+  explicit ApmDataDumper(int instance_index);
+
+  ApmDataDumper() = delete;
+  ApmDataDumper(const ApmDataDumper&) = delete;
+  ApmDataDumper& operator=(const ApmDataDumper&) = delete;
+
+  ~ApmDataDumper();
+
+  // Activates or deactivate the dumping functionality.
+  static void SetActivated(bool activated) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    recording_activated_ = activated;
+#endif
+  }
+
+  // Default dump set.
+  static constexpr size_t kDefaultDumpSet = 0;
+
+  // Specifies what dump set to use. All dump commands with a different dump set
+  // than the one specified will be discarded. If not specificed, all dump sets
+  // will be used.
+  static void SetDumpSetToUse(int dump_set_to_use) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    dump_set_to_use_ = dump_set_to_use;
+#endif
+  }
+
+  // Set an optional output directory.
+  static void SetOutputDirectory(const std::string& output_dir) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    RTC_CHECK_LT(output_dir.size(), kOutputDirMaxLength);
+    strncpy(output_dir_, output_dir.c_str(), output_dir.size());
+#endif
+  }
+
+  // Reinitializes the data dumping such that new versions
+  // of all files being dumped to are created.
+  void InitiateNewSetOfRecordings() {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    ++recording_set_index_;
+#endif
+  }
+
+  // Methods for performing dumping of data of various types into
+  // various formats.
+  void DumpRaw(const char* name, double v, int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      FILE* file = GetRawFile(name);
+      fwrite(&v, sizeof(v), 1, file);
+    }
+#endif
+  }
+
+  void DumpRaw(const char* name,
+               size_t v_length,
+               const double* v,
+               int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      FILE* file = GetRawFile(name);
+      fwrite(v, sizeof(v[0]), v_length, file);
+    }
+#endif
+  }
+
+  void DumpRaw(const char* name,
+               rtc::ArrayView<const double> v,
+               int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      DumpRaw(name, v.size(), v.data());
+    }
+#endif
+  }
+
+  void DumpRaw(const char* name, float v, int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      FILE* file = GetRawFile(name);
+      fwrite(&v, sizeof(v), 1, file);
+    }
+#endif
+  }
+
+  void DumpRaw(const char* name,
+               size_t v_length,
+               const float* v,
+               int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      FILE* file = GetRawFile(name);
+      fwrite(v, sizeof(v[0]), v_length, file);
+    }
+#endif
+  }
+
+  void DumpRaw(const char* name,
+               rtc::ArrayView<const float> v,
+               int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      DumpRaw(name, v.size(), v.data());
+    }
+#endif
+  }
+
+  void DumpRaw(const char* name, bool v, int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      DumpRaw(name, static_cast<int16_t>(v));
+    }
+#endif
+  }
+
+  void DumpRaw(const char* name,
+               size_t v_length,
+               const bool* v,
+               int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      FILE* file = GetRawFile(name);
+      for (size_t k = 0; k < v_length; ++k) {
+        int16_t value = static_cast<int16_t>(v[k]);
+        fwrite(&value, sizeof(value), 1, file);
+      }
+    }
+#endif
+  }
+
+  void DumpRaw(const char* name,
+               rtc::ArrayView<const bool> v,
+               int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      DumpRaw(name, v.size(), v.data());
+    }
+#endif
+  }
+
+  void DumpRaw(const char* name, int16_t v, int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      FILE* file = GetRawFile(name);
+      fwrite(&v, sizeof(v), 1, file);
+    }
+#endif
+  }
+
+  void DumpRaw(const char* name,
+               size_t v_length,
+               const int16_t* v,
+               int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      FILE* file = GetRawFile(name);
+      fwrite(v, sizeof(v[0]), v_length, file);
+    }
+#endif
+  }
+
+  void DumpRaw(const char* name,
+               rtc::ArrayView<const int16_t> v,
+               int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      DumpRaw(name, v.size(), v.data());
+    }
+#endif
+  }
+
+  void DumpRaw(const char* name, int32_t v, int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      FILE* file = GetRawFile(name);
+      fwrite(&v, sizeof(v), 1, file);
+    }
+#endif
+  }
+
+  void DumpRaw(const char* name,
+               size_t v_length,
+               const int32_t* v,
+               int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      FILE* file = GetRawFile(name);
+      fwrite(v, sizeof(v[0]), v_length, file);
+    }
+#endif
+  }
+
+  void DumpRaw(const char* name, size_t v, int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      FILE* file = GetRawFile(name);
+      fwrite(&v, sizeof(v), 1, file);
+    }
+#endif
+  }
+
+  void DumpRaw(const char* name,
+               size_t v_length,
+               const size_t* v,
+               int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      FILE* file = GetRawFile(name);
+      fwrite(v, sizeof(v[0]), v_length, file);
+    }
+#endif
+  }
+
+  void DumpRaw(const char* name,
+               rtc::ArrayView<const int32_t> v,
+               int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      DumpRaw(name, v.size(), v.data());
+    }
+#endif
+  }
+
+  void DumpRaw(const char* name,
+               rtc::ArrayView<const size_t> v,
+               int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    DumpRaw(name, v.size(), v.data());
+#endif
+  }
+
+  void DumpWav(const char* name,
+               size_t v_length,
+               const float* v,
+               int sample_rate_hz,
+               int num_channels,
+               int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      WavWriter* file = GetWavFile(name, sample_rate_hz, num_channels,
+                                   WavFile::SampleFormat::kFloat);
+      file->WriteSamples(v, v_length);
+    }
+#endif
+  }
+
+  void DumpWav(const char* name,
+               rtc::ArrayView<const float> v,
+               int sample_rate_hz,
+               int num_channels,
+               int dump_set = kDefaultDumpSet) {
+#if WEBRTC_APM_DEBUG_DUMP == 1
+    if (dump_set_to_use_ && *dump_set_to_use_ != dump_set)
+      return;
+
+    if (recording_activated_) {
+      DumpWav(name, v.size(), v.data(), sample_rate_hz, num_channels);
+    }
+#endif
+  }
+
+ private:
+#if WEBRTC_APM_DEBUG_DUMP == 1
+  static bool recording_activated_;
+  static absl::optional<int> dump_set_to_use_;
+  static constexpr size_t kOutputDirMaxLength = 1024;
+  static char output_dir_[kOutputDirMaxLength];
+  const int instance_index_;
+  int recording_set_index_ = 0;
+  std::unordered_map<std::string, std::unique_ptr<FILE, RawFileCloseFunctor>>
+      raw_files_;
+  std::unordered_map<std::string, std::unique_ptr<WavWriter>> wav_files_;
+
+  FILE* GetRawFile(const char* name);
+  WavWriter* GetWavFile(const char* name,
+                        int sample_rate_hz,
+                        int num_channels,
+                        WavFile::SampleFormat format);
+#endif
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_LOGGING_APM_DATA_DUMPER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/BUILD.gn b/third_party/webrtc_aec3/src/modules/audio_processing/ns/BUILD.gn
new file mode 100644
index 0000000..eb99c77
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/BUILD.gn
@@ -0,0 +1,105 @@
+# Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+#
+# Use of this source code is governed by a BSD-style license
+# that can be found in the LICENSE file in the root of the source
+# tree. An additional intellectual property rights grant can be found
+# in the file PATENTS.  All contributing project authors may
+# be found in the AUTHORS file in the root of the source tree.
+
+import("../../../webrtc.gni")
+
+rtc_static_library("ns") {
+  visibility = [ "*" ]
+  configs += [ "..:apm_debug_dump" ]
+  sources = [
+    "fast_math.cc",
+    "fast_math.h",
+    "histograms.cc",
+    "histograms.h",
+    "noise_estimator.cc",
+    "noise_estimator.h",
+    "noise_suppressor.cc",
+    "noise_suppressor.h",
+    "ns_common.h",
+    "ns_config.h",
+    "ns_fft.cc",
+    "ns_fft.h",
+    "prior_signal_model.cc",
+    "prior_signal_model.h",
+    "prior_signal_model_estimator.cc",
+    "prior_signal_model_estimator.h",
+    "quantile_noise_estimator.cc",
+    "quantile_noise_estimator.h",
+    "signal_model.cc",
+    "signal_model.h",
+    "signal_model_estimator.cc",
+    "signal_model_estimator.h",
+    "speech_probability_estimator.cc",
+    "speech_probability_estimator.h",
+    "suppression_params.cc",
+    "suppression_params.h",
+    "wiener_filter.cc",
+    "wiener_filter.h",
+  ]
+
+  defines = []
+  if (rtc_build_with_neon && current_cpu != "arm64") {
+    suppressed_configs += [ "//build/config/compiler:compiler_arm_fpu" ]
+    cflags = [ "-mfpu=neon" ]
+  }
+
+  deps = [
+    "..:apm_logging",
+    "..:audio_buffer",
+    "..:high_pass_filter",
+    "../../../api:array_view",
+    "../../../common_audio:common_audio_c",
+    "../../../common_audio/third_party/ooura:fft_size_128",
+    "../../../common_audio/third_party/ooura:fft_size_256",
+    "../../../rtc_base:checks",
+    "../../../rtc_base:rtc_base_approved",
+    "../../../rtc_base:safe_minmax",
+    "../../../rtc_base/system:arch",
+    "../../../system_wrappers",
+    "../../../system_wrappers:field_trial",
+    "../../../system_wrappers:metrics",
+    "../utility:cascaded_biquad_filter",
+  ]
+  absl_deps = [ "//third_party/abseil-cpp/absl/types:optional" ]
+}
+
+if (rtc_include_tests) {
+  rtc_source_set("ns_unittests") {
+    testonly = true
+
+    configs += [ "..:apm_debug_dump" ]
+    sources = [ "noise_suppressor_unittest.cc" ]
+
+    deps = [
+      ":ns",
+      "..:apm_logging",
+      "..:audio_buffer",
+      "..:audio_processing",
+      "..:high_pass_filter",
+      "../../../api:array_view",
+      "../../../rtc_base:checks",
+      "../../../rtc_base:rtc_base_approved",
+      "../../../rtc_base:safe_minmax",
+      "../../../rtc_base/system:arch",
+      "../../../system_wrappers",
+      "../../../test:test_support",
+      "../utility:cascaded_biquad_filter",
+    ]
+    absl_deps = [ "//third_party/abseil-cpp/absl/types:optional" ]
+
+    defines = []
+
+    if (rtc_enable_protobuf) {
+      sources += []
+    }
+
+    if (!build_with_chromium) {
+      deps += [ "..:audio_processing_unittests" ]
+    }
+  }
+}
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/fast_math.cc b/third_party/webrtc_aec3/src/modules/audio_processing/ns/fast_math.cc
new file mode 100644
index 0000000..d13110c
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/fast_math.cc
@@ -0,0 +1,84 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/ns/fast_math.h"
+
+#include <math.h>
+#include <stdint.h>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+namespace {
+
+float FastLog2f(float in) {
+  RTC_DCHECK_GT(in, .0f);
+  // Read and interpret float as uint32_t and then cast to float.
+  // This is done to extract the exponent (bits 30 - 23).
+  // "Right shift" of the exponent is then performed by multiplying
+  // with the constant (1/2^23). Finally, we subtract a constant to
+  // remove the bias (https://en.wikipedia.org/wiki/Exponent_bias).
+  union {
+    float dummy;
+    uint32_t a;
+  } x = {in};
+  float out = x.a;
+  out *= 1.1920929e-7f;  // 1/2^23
+  out -= 126.942695f;    // Remove bias.
+  return out;
+}
+
+}  // namespace
+
+float SqrtFastApproximation(float f) {
+  // TODO(peah): Add fast approximate implementation.
+  return sqrtf(f);
+}
+
+float Pow2Approximation(float p) {
+  // TODO(peah): Add fast approximate implementation.
+  return powf(2.f, p);
+}
+
+float PowApproximation(float x, float p) {
+  return Pow2Approximation(p * FastLog2f(x));
+}
+
+float LogApproximation(float x) {
+  constexpr float kLogOf2 = 0.69314718056f;
+  return FastLog2f(x) * kLogOf2;
+}
+
+void LogApproximation(rtc::ArrayView<const float> x, rtc::ArrayView<float> y) {
+  for (size_t k = 0; k < x.size(); ++k) {
+    y[k] = LogApproximation(x[k]);
+  }
+}
+
+float ExpApproximation(float x) {
+  constexpr float kLog10Ofe = 0.4342944819f;
+  return PowApproximation(10.f, x * kLog10Ofe);
+}
+
+void ExpApproximation(rtc::ArrayView<const float> x, rtc::ArrayView<float> y) {
+  for (size_t k = 0; k < x.size(); ++k) {
+    y[k] = ExpApproximation(x[k]);
+  }
+}
+
+void ExpApproximationSignFlip(rtc::ArrayView<const float> x,
+                              rtc::ArrayView<float> y) {
+  for (size_t k = 0; k < x.size(); ++k) {
+    y[k] = ExpApproximation(-x[k]);
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/fast_math.h b/third_party/webrtc_aec3/src/modules/audio_processing/ns/fast_math.h
new file mode 100644
index 0000000..0aefee9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/fast_math.h
@@ -0,0 +1,38 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_NS_FAST_MATH_H_
+#define MODULES_AUDIO_PROCESSING_NS_FAST_MATH_H_
+
+#include "api/array_view.h"
+
+namespace webrtc {
+
+// Sqrt approximation.
+float SqrtFastApproximation(float f);
+
+// Log base conversion log(x) = log2(x)/log2(e).
+float LogApproximation(float x);
+void LogApproximation(rtc::ArrayView<const float> x, rtc::ArrayView<float> y);
+
+// 2^x approximation.
+float Pow2Approximation(float p);
+
+// x^p approximation.
+float PowApproximation(float x, float p);
+
+// e^x approximation.
+float ExpApproximation(float x);
+void ExpApproximation(rtc::ArrayView<const float> x, rtc::ArrayView<float> y);
+void ExpApproximationSignFlip(rtc::ArrayView<const float> x,
+                              rtc::ArrayView<float> y);
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_NS_FAST_MATH_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/histograms.cc b/third_party/webrtc_aec3/src/modules/audio_processing/ns/histograms.cc
new file mode 100644
index 0000000..1d4f459
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/histograms.cc
@@ -0,0 +1,47 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/ns/histograms.h"
+
+namespace webrtc {
+
+Histograms::Histograms() {
+  Clear();
+}
+
+void Histograms::Clear() {
+  lrt_.fill(0);
+  spectral_flatness_.fill(0);
+  spectral_diff_.fill(0);
+}
+
+void Histograms::Update(const SignalModel& features_) {
+  // Update the histogram for the LRT.
+  constexpr float kOneByBinSizeLrt = 1.f / kBinSizeLrt;
+  if (features_.lrt < kHistogramSize * kBinSizeLrt && features_.lrt >= 0.f) {
+    ++lrt_[kOneByBinSizeLrt * features_.lrt];
+  }
+
+  // Update histogram for the spectral flatness.
+  constexpr float kOneByBinSizeSpecFlat = 1.f / kBinSizeSpecFlat;
+  if (features_.spectral_flatness < kHistogramSize * kBinSizeSpecFlat &&
+      features_.spectral_flatness >= 0.f) {
+    ++spectral_flatness_[features_.spectral_flatness * kOneByBinSizeSpecFlat];
+  }
+
+  // Update histogram for the spectral difference.
+  constexpr float kOneByBinSizeSpecDiff = 1.f / kBinSizeSpecDiff;
+  if (features_.spectral_diff < kHistogramSize * kBinSizeSpecDiff &&
+      features_.spectral_diff >= 0.f) {
+    ++spectral_diff_[features_.spectral_diff * kOneByBinSizeSpecDiff];
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/histograms.h b/third_party/webrtc_aec3/src/modules/audio_processing/ns/histograms.h
new file mode 100644
index 0000000..9640e74
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/histograms.h
@@ -0,0 +1,55 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_NS_HISTOGRAMS_H_
+#define MODULES_AUDIO_PROCESSING_NS_HISTOGRAMS_H_
+
+#include <array>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/ns/ns_common.h"
+#include "modules/audio_processing/ns/signal_model.h"
+
+namespace webrtc {
+
+constexpr int kHistogramSize = 1000;
+
+// Class for handling the updating of histograms.
+class Histograms {
+ public:
+  Histograms();
+  Histograms(const Histograms&) = delete;
+  Histograms& operator=(const Histograms&) = delete;
+
+  // Clears the histograms.
+  void Clear();
+
+  // Extracts thresholds for feature parameters and updates the corresponding
+  // histogram.
+  void Update(const SignalModel& features_);
+
+  // Methods for accessing the histograms.
+  rtc::ArrayView<const int, kHistogramSize> get_lrt() const { return lrt_; }
+  rtc::ArrayView<const int, kHistogramSize> get_spectral_flatness() const {
+    return spectral_flatness_;
+  }
+  rtc::ArrayView<const int, kHistogramSize> get_spectral_diff() const {
+    return spectral_diff_;
+  }
+
+ private:
+  std::array<int, kHistogramSize> lrt_;
+  std::array<int, kHistogramSize> spectral_flatness_;
+  std::array<int, kHistogramSize> spectral_diff_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_NS_HISTOGRAMS_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/noise_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/ns/noise_estimator.cc
new file mode 100644
index 0000000..5367545
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/noise_estimator.cc
@@ -0,0 +1,195 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/ns/noise_estimator.h"
+
+#include <algorithm>
+
+#include "modules/audio_processing/ns/fast_math.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+namespace {
+
+// Log(i).
+constexpr std::array<float, 129> log_table = {
+    0.f,       0.f,       0.f,       0.f,       0.f,       1.609438f, 1.791759f,
+    1.945910f, 2.079442f, 2.197225f, 2.302585f, 2.397895f, 2.484907f, 2.564949f,
+    2.639057f, 2.708050f, 2.772589f, 2.833213f, 2.890372f, 2.944439f, 2.995732f,
+    3.044522f, 3.091043f, 3.135494f, 3.178054f, 3.218876f, 3.258097f, 3.295837f,
+    3.332205f, 3.367296f, 3.401197f, 3.433987f, 3.465736f, 3.496507f, 3.526361f,
+    3.555348f, 3.583519f, 3.610918f, 3.637586f, 3.663562f, 3.688879f, 3.713572f,
+    3.737669f, 3.761200f, 3.784190f, 3.806663f, 3.828641f, 3.850147f, 3.871201f,
+    3.891820f, 3.912023f, 3.931826f, 3.951244f, 3.970292f, 3.988984f, 4.007333f,
+    4.025352f, 4.043051f, 4.060443f, 4.077538f, 4.094345f, 4.110874f, 4.127134f,
+    4.143135f, 4.158883f, 4.174387f, 4.189655f, 4.204693f, 4.219508f, 4.234107f,
+    4.248495f, 4.262680f, 4.276666f, 4.290460f, 4.304065f, 4.317488f, 4.330733f,
+    4.343805f, 4.356709f, 4.369448f, 4.382027f, 4.394449f, 4.406719f, 4.418841f,
+    4.430817f, 4.442651f, 4.454347f, 4.465908f, 4.477337f, 4.488636f, 4.499810f,
+    4.510859f, 4.521789f, 4.532599f, 4.543295f, 4.553877f, 4.564348f, 4.574711f,
+    4.584968f, 4.595119f, 4.605170f, 4.615121f, 4.624973f, 4.634729f, 4.644391f,
+    4.653960f, 4.663439f, 4.672829f, 4.682131f, 4.691348f, 4.700480f, 4.709530f,
+    4.718499f, 4.727388f, 4.736198f, 4.744932f, 4.753591f, 4.762174f, 4.770685f,
+    4.779124f, 4.787492f, 4.795791f, 4.804021f, 4.812184f, 4.820282f, 4.828314f,
+    4.836282f, 4.844187f, 4.852030f};
+
+}  // namespace
+
+NoiseEstimator::NoiseEstimator(const SuppressionParams& suppression_params)
+    : suppression_params_(suppression_params) {
+  noise_spectrum_.fill(0.f);
+  prev_noise_spectrum_.fill(0.f);
+  conservative_noise_spectrum_.fill(0.f);
+  parametric_noise_spectrum_.fill(0.f);
+}
+
+void NoiseEstimator::PrepareAnalysis() {
+  std::copy(noise_spectrum_.begin(), noise_spectrum_.end(),
+            prev_noise_spectrum_.begin());
+}
+
+void NoiseEstimator::PreUpdate(
+    int32_t num_analyzed_frames,
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> signal_spectrum,
+    float signal_spectral_sum) {
+  quantile_noise_estimator_.Estimate(signal_spectrum, noise_spectrum_);
+
+  if (num_analyzed_frames < kShortStartupPhaseBlocks) {
+    // Compute simplified noise model during startup.
+    const size_t kStartBand = 5;
+    float sum_log_i_log_magn = 0.f;
+    float sum_log_i = 0.f;
+    float sum_log_i_square = 0.f;
+    float sum_log_magn = 0.f;
+    for (size_t i = kStartBand; i < kFftSizeBy2Plus1; ++i) {
+      float log_i = log_table[i];
+      sum_log_i += log_i;
+      sum_log_i_square += log_i * log_i;
+      float log_signal = LogApproximation(signal_spectrum[i]);
+      sum_log_magn += log_signal;
+      sum_log_i_log_magn += log_i * log_signal;
+    }
+
+    // Estimate the parameter for the level of the white noise.
+    constexpr float kOneByFftSizeBy2Plus1 = 1.f / kFftSizeBy2Plus1;
+    white_noise_level_ += signal_spectral_sum * kOneByFftSizeBy2Plus1 *
+                          suppression_params_.over_subtraction_factor;
+
+    // Estimate pink noise parameters.
+    float denom = sum_log_i_square * (kFftSizeBy2Plus1 - kStartBand) -
+                  sum_log_i * sum_log_i;
+    float num =
+        sum_log_i_square * sum_log_magn - sum_log_i * sum_log_i_log_magn;
+    RTC_DCHECK_NE(denom, 0.f);
+    float pink_noise_adjustment = num / denom;
+
+    // Constrain the estimated spectrum to be positive.
+    pink_noise_adjustment = std::max(pink_noise_adjustment, 0.f);
+    pink_noise_numerator_ += pink_noise_adjustment;
+    num = sum_log_i * sum_log_magn -
+          (kFftSizeBy2Plus1 - kStartBand) * sum_log_i_log_magn;
+    RTC_DCHECK_NE(denom, 0.f);
+    pink_noise_adjustment = num / denom;
+
+    // Constrain the pink noise power to be in the interval [0, 1].
+    pink_noise_adjustment = std::max(std::min(pink_noise_adjustment, 1.f), 0.f);
+
+    pink_noise_exp_ += pink_noise_adjustment;
+
+    const float one_by_num_analyzed_frames_plus_1 =
+        1.f / (num_analyzed_frames + 1.f);
+
+    // Calculate the frequency-independent parts of parametric noise estimate.
+    float parametric_exp = 0.f;
+    float parametric_num = 0.f;
+    if (pink_noise_exp_ > 0.f) {
+      // Use pink noise estimate.
+      parametric_num = ExpApproximation(pink_noise_numerator_ *
+                                        one_by_num_analyzed_frames_plus_1);
+      parametric_num *= num_analyzed_frames + 1.f;
+      parametric_exp = pink_noise_exp_ * one_by_num_analyzed_frames_plus_1;
+    }
+
+    constexpr float kOneByShortStartupPhaseBlocks =
+        1.f / kShortStartupPhaseBlocks;
+    for (size_t i = 0; i < kFftSizeBy2Plus1; ++i) {
+      // Estimate the background noise using the white and pink noise
+      // parameters.
+      if (pink_noise_exp_ == 0.f) {
+        // Use white noise estimate.
+        parametric_noise_spectrum_[i] = white_noise_level_;
+      } else {
+        // Use pink noise estimate.
+        float use_band = i < kStartBand ? kStartBand : i;
+        float denom = PowApproximation(use_band, parametric_exp);
+        RTC_DCHECK_NE(denom, 0.f);
+        parametric_noise_spectrum_[i] = parametric_num / denom;
+      }
+    }
+
+    // Weight quantile noise with modeled noise.
+    for (size_t i = 0; i < kFftSizeBy2Plus1; ++i) {
+      noise_spectrum_[i] *= num_analyzed_frames;
+      float tmp = parametric_noise_spectrum_[i] *
+                  (kShortStartupPhaseBlocks - num_analyzed_frames);
+      noise_spectrum_[i] += tmp * one_by_num_analyzed_frames_plus_1;
+      noise_spectrum_[i] *= kOneByShortStartupPhaseBlocks;
+    }
+  }
+}
+
+void NoiseEstimator::PostUpdate(
+    rtc::ArrayView<const float> speech_probability,
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> signal_spectrum) {
+  // Time-avg parameter for noise_spectrum update.
+  constexpr float kNoiseUpdate = 0.9f;
+
+  float gamma = kNoiseUpdate;
+  for (size_t i = 0; i < kFftSizeBy2Plus1; ++i) {
+    const float prob_speech = speech_probability[i];
+    const float prob_non_speech = 1.f - prob_speech;
+
+    // Temporary noise update used for speech frames if update value is less
+    // than previous.
+    float noise_update_tmp =
+        gamma * prev_noise_spectrum_[i] +
+        (1.f - gamma) * (prob_non_speech * signal_spectrum[i] +
+                         prob_speech * prev_noise_spectrum_[i]);
+
+    // Time-constant based on speech/noise_spectrum state.
+    float gamma_old = gamma;
+
+    // Increase gamma for frame likely to be seech.
+    constexpr float kProbRange = .2f;
+    gamma = prob_speech > kProbRange ? .99f : kNoiseUpdate;
+
+    // Conservative noise_spectrum update.
+    if (prob_speech < kProbRange) {
+      conservative_noise_spectrum_[i] +=
+          0.05f * (signal_spectrum[i] - conservative_noise_spectrum_[i]);
+    }
+
+    // Noise_spectrum update.
+    if (gamma == gamma_old) {
+      noise_spectrum_[i] = noise_update_tmp;
+    } else {
+      noise_spectrum_[i] =
+          gamma * prev_noise_spectrum_[i] +
+          (1.f - gamma) * (prob_non_speech * signal_spectrum[i] +
+                           prob_speech * prev_noise_spectrum_[i]);
+      // Allow for noise_spectrum update downwards: If noise_spectrum update
+      // decreases the noise_spectrum, it is safe, so allow it to happen.
+      noise_spectrum_[i] = std::min(noise_spectrum_[i], noise_update_tmp);
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/noise_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/ns/noise_estimator.h
new file mode 100644
index 0000000..0c0466a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/noise_estimator.h
@@ -0,0 +1,77 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_NS_NOISE_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_NS_NOISE_ESTIMATOR_H_
+
+#include <array>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/ns/ns_common.h"
+#include "modules/audio_processing/ns/quantile_noise_estimator.h"
+#include "modules/audio_processing/ns/suppression_params.h"
+
+namespace webrtc {
+
+// Class for estimating the spectral characteristics of the noise in an incoming
+// signal.
+class NoiseEstimator {
+ public:
+  explicit NoiseEstimator(const SuppressionParams& suppression_params);
+
+  // Prepare the estimator for analysis of a new frame.
+  void PrepareAnalysis();
+
+  // Performs the first step of the estimator update.
+  void PreUpdate(int32_t num_analyzed_frames,
+                 rtc::ArrayView<const float, kFftSizeBy2Plus1> signal_spectrum,
+                 float signal_spectral_sum);
+
+  // Performs the second step of the estimator update.
+  void PostUpdate(
+      rtc::ArrayView<const float> speech_probability,
+      rtc::ArrayView<const float, kFftSizeBy2Plus1> signal_spectrum);
+
+  // Returns the noise spectral estimate.
+  rtc::ArrayView<const float, kFftSizeBy2Plus1> get_noise_spectrum() const {
+    return noise_spectrum_;
+  }
+
+  // Returns the noise from the previous frame.
+  rtc::ArrayView<const float, kFftSizeBy2Plus1> get_prev_noise_spectrum()
+      const {
+    return prev_noise_spectrum_;
+  }
+
+  // Returns a noise spectral estimate based on white and pink noise parameters.
+  rtc::ArrayView<const float, kFftSizeBy2Plus1> get_parametric_noise_spectrum()
+      const {
+    return parametric_noise_spectrum_;
+  }
+  rtc::ArrayView<const float, kFftSizeBy2Plus1>
+  get_conservative_noise_spectrum() const {
+    return conservative_noise_spectrum_;
+  }
+
+ private:
+  const SuppressionParams& suppression_params_;
+  float white_noise_level_ = 0.f;
+  float pink_noise_numerator_ = 0.f;
+  float pink_noise_exp_ = 0.f;
+  std::array<float, kFftSizeBy2Plus1> prev_noise_spectrum_;
+  std::array<float, kFftSizeBy2Plus1> conservative_noise_spectrum_;
+  std::array<float, kFftSizeBy2Plus1> parametric_noise_spectrum_;
+  std::array<float, kFftSizeBy2Plus1> noise_spectrum_;
+  QuantileNoiseEstimator quantile_noise_estimator_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_NS_NOISE_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/noise_suppressor.cc b/third_party/webrtc_aec3/src/modules/audio_processing/ns/noise_suppressor.cc
new file mode 100644
index 0000000..d66faa6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/noise_suppressor.cc
@@ -0,0 +1,555 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/ns/noise_suppressor.h"
+
+#include <math.h>
+#include <stdlib.h>
+#include <string.h>
+#include <algorithm>
+
+#include "modules/audio_processing/ns/fast_math.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+namespace {
+
+// Maps sample rate to number of bands.
+size_t NumBandsForRate(size_t sample_rate_hz) {
+  RTC_DCHECK(sample_rate_hz == 16000 || sample_rate_hz == 32000 ||
+             sample_rate_hz == 48000);
+  return sample_rate_hz / 16000;
+}
+
+// Maximum number of channels for which the channel data is stored on
+// the stack. If the number of channels are larger than this, they are stored
+// using scratch memory that is pre-allocated on the heap. The reason for this
+// partitioning is not to waste heap space for handling the more common numbers
+// of channels, while at the same time not limiting the support for higher
+// numbers of channels by enforcing the channel data to be stored on the
+// stack using a fixed maximum value.
+constexpr size_t kMaxNumChannelsOnStack = 2;
+
+// Chooses the number of channels to store on the heap when that is required due
+// to the number of channels being larger than the pre-defined number
+// of channels to store on the stack.
+size_t NumChannelsOnHeap(size_t num_channels) {
+  return num_channels > kMaxNumChannelsOnStack ? num_channels : 0;
+}
+
+// Hybrib Hanning and flat window for the filterbank.
+constexpr std::array<float, 96> kBlocks160w256FirstHalf = {
+    0.00000000f, 0.01636173f, 0.03271908f, 0.04906767f, 0.06540313f,
+    0.08172107f, 0.09801714f, 0.11428696f, 0.13052619f, 0.14673047f,
+    0.16289547f, 0.17901686f, 0.19509032f, 0.21111155f, 0.22707626f,
+    0.24298018f, 0.25881905f, 0.27458862f, 0.29028468f, 0.30590302f,
+    0.32143947f, 0.33688985f, 0.35225005f, 0.36751594f, 0.38268343f,
+    0.39774847f, 0.41270703f, 0.42755509f, 0.44228869f, 0.45690388f,
+    0.47139674f, 0.48576339f, 0.50000000f, 0.51410274f, 0.52806785f,
+    0.54189158f, 0.55557023f, 0.56910015f, 0.58247770f, 0.59569930f,
+    0.60876143f, 0.62166057f, 0.63439328f, 0.64695615f, 0.65934582f,
+    0.67155895f, 0.68359230f, 0.69544264f, 0.70710678f, 0.71858162f,
+    0.72986407f, 0.74095113f, 0.75183981f, 0.76252720f, 0.77301045f,
+    0.78328675f, 0.79335334f, 0.80320753f, 0.81284668f, 0.82226822f,
+    0.83146961f, 0.84044840f, 0.84920218f, 0.85772861f, 0.86602540f,
+    0.87409034f, 0.88192126f, 0.88951608f, 0.89687274f, 0.90398929f,
+    0.91086382f, 0.91749450f, 0.92387953f, 0.93001722f, 0.93590593f,
+    0.94154407f, 0.94693013f, 0.95206268f, 0.95694034f, 0.96156180f,
+    0.96592583f, 0.97003125f, 0.97387698f, 0.97746197f, 0.98078528f,
+    0.98384601f, 0.98664333f, 0.98917651f, 0.99144486f, 0.99344778f,
+    0.99518473f, 0.99665524f, 0.99785892f, 0.99879546f, 0.99946459f,
+    0.99986614f};
+
+// Applies the filterbank window to a buffer.
+void ApplyFilterBankWindow(rtc::ArrayView<float, kFftSize> x) {
+  for (size_t i = 0; i < 96; ++i) {
+    x[i] = kBlocks160w256FirstHalf[i] * x[i];
+  }
+
+  for (size_t i = 161, k = 95; i < kFftSize; ++i, --k) {
+    RTC_DCHECK_NE(0, k);
+    x[i] = kBlocks160w256FirstHalf[k] * x[i];
+  }
+}
+
+// Extends a frame with previous data.
+void FormExtendedFrame(rtc::ArrayView<const float, kNsFrameSize> frame,
+                       rtc::ArrayView<float, kFftSize - kNsFrameSize> old_data,
+                       rtc::ArrayView<float, kFftSize> extended_frame) {
+  std::copy(old_data.begin(), old_data.end(), extended_frame.begin());
+  std::copy(frame.begin(), frame.end(),
+            extended_frame.begin() + old_data.size());
+  std::copy(extended_frame.end() - old_data.size(), extended_frame.end(),
+            old_data.begin());
+}
+
+// Uses overlap-and-add to produce an output frame.
+void OverlapAndAdd(rtc::ArrayView<const float, kFftSize> extended_frame,
+                   rtc::ArrayView<float, kOverlapSize> overlap_memory,
+                   rtc::ArrayView<float, kNsFrameSize> output_frame) {
+  for (size_t i = 0; i < kOverlapSize; ++i) {
+    output_frame[i] = overlap_memory[i] + extended_frame[i];
+  }
+  std::copy(extended_frame.begin() + kOverlapSize,
+            extended_frame.begin() + kNsFrameSize,
+            output_frame.begin() + kOverlapSize);
+  std::copy(extended_frame.begin() + kNsFrameSize, extended_frame.end(),
+            overlap_memory.begin());
+}
+
+// Produces a delayed frame.
+void DelaySignal(rtc::ArrayView<const float, kNsFrameSize> frame,
+                 rtc::ArrayView<float, kFftSize - kNsFrameSize> delay_buffer,
+                 rtc::ArrayView<float, kNsFrameSize> delayed_frame) {
+  constexpr size_t kSamplesFromFrame = kNsFrameSize - (kFftSize - kNsFrameSize);
+  std::copy(delay_buffer.begin(), delay_buffer.end(), delayed_frame.begin());
+  std::copy(frame.begin(), frame.begin() + kSamplesFromFrame,
+            delayed_frame.begin() + delay_buffer.size());
+
+  std::copy(frame.begin() + kSamplesFromFrame, frame.end(),
+            delay_buffer.begin());
+}
+
+// Computes the energy of an extended frame.
+float ComputeEnergyOfExtendedFrame(rtc::ArrayView<const float, kFftSize> x) {
+  float energy = 0.f;
+  for (float x_k : x) {
+    energy += x_k * x_k;
+  }
+
+  return energy;
+}
+
+// Computes the energy of an extended frame based on its subcomponents.
+float ComputeEnergyOfExtendedFrame(
+    rtc::ArrayView<const float, kNsFrameSize> frame,
+    rtc::ArrayView<float, kFftSize - kNsFrameSize> old_data) {
+  float energy = 0.f;
+  for (float v : old_data) {
+    energy += v * v;
+  }
+  for (float v : frame) {
+    energy += v * v;
+  }
+
+  return energy;
+}
+
+// Computes the magnitude spectrum based on an FFT output.
+void ComputeMagnitudeSpectrum(
+    rtc::ArrayView<const float, kFftSize> real,
+    rtc::ArrayView<const float, kFftSize> imag,
+    rtc::ArrayView<float, kFftSizeBy2Plus1> signal_spectrum) {
+  signal_spectrum[0] = fabsf(real[0]) + 1.f;
+  signal_spectrum[kFftSizeBy2Plus1 - 1] =
+      fabsf(real[kFftSizeBy2Plus1 - 1]) + 1.f;
+
+  for (size_t i = 1; i < kFftSizeBy2Plus1 - 1; ++i) {
+    signal_spectrum[i] =
+        SqrtFastApproximation(real[i] * real[i] + imag[i] * imag[i]) + 1.f;
+  }
+}
+
+// Compute prior and post SNR.
+void ComputeSnr(rtc::ArrayView<const float, kFftSizeBy2Plus1> filter,
+                rtc::ArrayView<const float> prev_signal_spectrum,
+                rtc::ArrayView<const float> signal_spectrum,
+                rtc::ArrayView<const float> prev_noise_spectrum,
+                rtc::ArrayView<const float> noise_spectrum,
+                rtc::ArrayView<float> prior_snr,
+                rtc::ArrayView<float> post_snr) {
+  for (size_t i = 0; i < kFftSizeBy2Plus1; ++i) {
+    // Previous post SNR.
+    // Previous estimate: based on previous frame with gain filter.
+    float prev_estimate = prev_signal_spectrum[i] /
+                          (prev_noise_spectrum[i] + 0.0001f) * filter[i];
+    // Post SNR.
+    if (signal_spectrum[i] > noise_spectrum[i]) {
+      post_snr[i] = signal_spectrum[i] / (noise_spectrum[i] + 0.0001f) - 1.f;
+    } else {
+      post_snr[i] = 0.f;
+    }
+    // The directed decision estimate of the prior SNR is a sum the current and
+    // previous estimates.
+    prior_snr[i] = 0.98f * prev_estimate + (1.f - 0.98f) * post_snr[i];
+  }
+}
+
+// Computes the attenuating gain for the noise suppression of the upper bands.
+float ComputeUpperBandsGain(
+    float minimum_attenuating_gain,
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> filter,
+    rtc::ArrayView<const float> speech_probability,
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> prev_analysis_signal_spectrum,
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> signal_spectrum) {
+  // Average speech prob and filter gain for the end of the lowest band.
+  constexpr int kNumAvgBins = 32;
+  constexpr float kOneByNumAvgBins = 1.f / kNumAvgBins;
+
+  float avg_prob_speech = 0.f;
+  float avg_filter_gain = 0.f;
+  for (size_t i = kFftSizeBy2Plus1 - kNumAvgBins - 1; i < kFftSizeBy2Plus1 - 1;
+       i++) {
+    avg_prob_speech += speech_probability[i];
+    avg_filter_gain += filter[i];
+  }
+  avg_prob_speech = avg_prob_speech * kOneByNumAvgBins;
+  avg_filter_gain = avg_filter_gain * kOneByNumAvgBins;
+
+  // If the speech was suppressed by a component between Analyze and Process, an
+  // example being by an AEC, it should not be considered speech for the purpose
+  // of high band suppression. To that end, the speech probability is scaled
+  // accordingly.
+  float sum_analysis_spectrum = 0.f;
+  float sum_processing_spectrum = 0.f;
+  for (size_t i = 0; i < kFftSizeBy2Plus1; ++i) {
+    sum_analysis_spectrum += prev_analysis_signal_spectrum[i];
+    sum_processing_spectrum += signal_spectrum[i];
+  }
+
+  // The magnitude spectrum computation enforces the spectrum to be strictly
+  // positive.
+  RTC_DCHECK_GT(sum_analysis_spectrum, 0.f);
+  avg_prob_speech *= sum_processing_spectrum / sum_analysis_spectrum;
+
+  // Compute gain based on speech probability.
+  float gain =
+      0.5f * (1.f + static_cast<float>(tanh(2.f * avg_prob_speech - 1.f)));
+
+  // Combine gain with low band gain.
+  if (avg_prob_speech >= 0.5f) {
+    gain = 0.25f * gain + 0.75f * avg_filter_gain;
+  } else {
+    gain = 0.5f * gain + 0.5f * avg_filter_gain;
+  }
+
+  // Make sure gain is within flooring range.
+  return std::min(std::max(gain, minimum_attenuating_gain), 1.f);
+}
+
+}  // namespace
+
+NoiseSuppressor::ChannelState::ChannelState(
+    const SuppressionParams& suppression_params,
+    size_t num_bands)
+    : wiener_filter(suppression_params),
+      noise_estimator(suppression_params),
+      process_delay_memory(num_bands > 1 ? num_bands - 1 : 0) {
+  analyze_analysis_memory.fill(0.f);
+  prev_analysis_signal_spectrum.fill(1.f);
+  process_analysis_memory.fill(0.f);
+  process_synthesis_memory.fill(0.f);
+  for (auto& d : process_delay_memory) {
+    d.fill(0.f);
+  }
+}
+
+NoiseSuppressor::NoiseSuppressor(const NsConfig& config,
+                                 size_t sample_rate_hz,
+                                 size_t num_channels)
+    : num_bands_(NumBandsForRate(sample_rate_hz)),
+      num_channels_(num_channels),
+      suppression_params_(config.target_level),
+      filter_bank_states_heap_(NumChannelsOnHeap(num_channels_)),
+      upper_band_gains_heap_(NumChannelsOnHeap(num_channels_)),
+      energies_before_filtering_heap_(NumChannelsOnHeap(num_channels_)),
+      gain_adjustments_heap_(NumChannelsOnHeap(num_channels_)),
+      channels_(num_channels_) {
+  for (size_t ch = 0; ch < num_channels_; ++ch) {
+    channels_[ch] =
+        std::make_unique<ChannelState>(suppression_params_, num_bands_);
+  }
+}
+
+void NoiseSuppressor::AggregateWienerFilters(
+    rtc::ArrayView<float, kFftSizeBy2Plus1> filter) const {
+  rtc::ArrayView<const float, kFftSizeBy2Plus1> filter0 =
+      channels_[0]->wiener_filter.get_filter();
+  std::copy(filter0.begin(), filter0.end(), filter.begin());
+
+  for (size_t ch = 1; ch < num_channels_; ++ch) {
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> filter_ch =
+        channels_[ch]->wiener_filter.get_filter();
+
+    for (size_t k = 0; k < kFftSizeBy2Plus1; ++k) {
+      filter[k] = std::min(filter[k], filter_ch[k]);
+    }
+  }
+}
+
+void NoiseSuppressor::Analyze(const AudioBuffer& audio) {
+  // Prepare the noise estimator for the analysis stage.
+  for (size_t ch = 0; ch < num_channels_; ++ch) {
+    channels_[ch]->noise_estimator.PrepareAnalysis();
+  }
+
+  // Check for zero frames.
+  bool zero_frame = true;
+  for (size_t ch = 0; ch < num_channels_; ++ch) {
+    rtc::ArrayView<const float, kNsFrameSize> y_band0(
+        &audio.split_bands_const(ch)[0][0], kNsFrameSize);
+    float energy = ComputeEnergyOfExtendedFrame(
+        y_band0, channels_[ch]->analyze_analysis_memory);
+    if (energy > 0.f) {
+      zero_frame = false;
+      break;
+    }
+  }
+
+  if (zero_frame) {
+    // We want to avoid updating statistics in this case:
+    // Updating feature statistics when we have zeros only will cause
+    // thresholds to move towards zero signal situations. This in turn has the
+    // effect that once the signal is "turned on" (non-zero values) everything
+    // will be treated as speech and there is no noise suppression effect.
+    // Depending on the duration of the inactive signal it takes a
+    // considerable amount of time for the system to learn what is noise and
+    // what is speech.
+    return;
+  }
+
+  // Only update analysis counter for frames that are properly analyzed.
+  if (++num_analyzed_frames_ < 0) {
+    num_analyzed_frames_ = 0;
+  }
+
+  // Analyze all channels.
+  for (size_t ch = 0; ch < num_channels_; ++ch) {
+    std::unique_ptr<ChannelState>& ch_p = channels_[ch];
+    rtc::ArrayView<const float, kNsFrameSize> y_band0(
+        &audio.split_bands_const(ch)[0][0], kNsFrameSize);
+
+    // Form an extended frame and apply analysis filter bank windowing.
+    std::array<float, kFftSize> extended_frame;
+    FormExtendedFrame(y_band0, ch_p->analyze_analysis_memory, extended_frame);
+    ApplyFilterBankWindow(extended_frame);
+
+    // Compute the magnitude spectrum.
+    std::array<float, kFftSize> real;
+    std::array<float, kFftSize> imag;
+    fft_.Fft(extended_frame, real, imag);
+
+    std::array<float, kFftSizeBy2Plus1> signal_spectrum;
+    ComputeMagnitudeSpectrum(real, imag, signal_spectrum);
+
+    // Compute energies.
+    float signal_energy = 0.f;
+    for (size_t i = 0; i < kFftSizeBy2Plus1; ++i) {
+      signal_energy += real[i] * real[i] + imag[i] * imag[i];
+    }
+    signal_energy /= kFftSizeBy2Plus1;
+
+    float signal_spectral_sum = 0.f;
+    for (size_t i = 0; i < kFftSizeBy2Plus1; ++i) {
+      signal_spectral_sum += signal_spectrum[i];
+    }
+
+    // Estimate the noise spectra and the probability estimates of speech
+    // presence.
+    ch_p->noise_estimator.PreUpdate(num_analyzed_frames_, signal_spectrum,
+                                    signal_spectral_sum);
+
+    std::array<float, kFftSizeBy2Plus1> post_snr;
+    std::array<float, kFftSizeBy2Plus1> prior_snr;
+    ComputeSnr(ch_p->wiener_filter.get_filter(),
+               ch_p->prev_analysis_signal_spectrum, signal_spectrum,
+               ch_p->noise_estimator.get_prev_noise_spectrum(),
+               ch_p->noise_estimator.get_noise_spectrum(), prior_snr, post_snr);
+
+    ch_p->speech_probability_estimator.Update(
+        num_analyzed_frames_, prior_snr, post_snr,
+        ch_p->noise_estimator.get_conservative_noise_spectrum(),
+        signal_spectrum, signal_spectral_sum, signal_energy);
+
+    ch_p->noise_estimator.PostUpdate(
+        ch_p->speech_probability_estimator.get_probability(), signal_spectrum);
+
+    // Store the magnitude spectrum to make it avalilable for the process
+    // method.
+    std::copy(signal_spectrum.begin(), signal_spectrum.end(),
+              ch_p->prev_analysis_signal_spectrum.begin());
+  }
+}
+
+void NoiseSuppressor::Process(AudioBuffer* audio) {
+  // Select the space for storing data during the processing.
+  std::array<FilterBankState, kMaxNumChannelsOnStack> filter_bank_states_stack;
+  rtc::ArrayView<FilterBankState> filter_bank_states(
+      filter_bank_states_stack.data(), num_channels_);
+  std::array<float, kMaxNumChannelsOnStack> upper_band_gains_stack;
+  rtc::ArrayView<float> upper_band_gains(upper_band_gains_stack.data(),
+                                         num_channels_);
+  std::array<float, kMaxNumChannelsOnStack> energies_before_filtering_stack;
+  rtc::ArrayView<float> energies_before_filtering(
+      energies_before_filtering_stack.data(), num_channels_);
+  std::array<float, kMaxNumChannelsOnStack> gain_adjustments_stack;
+  rtc::ArrayView<float> gain_adjustments(gain_adjustments_stack.data(),
+                                         num_channels_);
+  if (NumChannelsOnHeap(num_channels_) > 0) {
+    // If the stack-allocated space is too small, use the heap for storing the
+    // data.
+    filter_bank_states = rtc::ArrayView<FilterBankState>(
+        filter_bank_states_heap_.data(), num_channels_);
+    upper_band_gains =
+        rtc::ArrayView<float>(upper_band_gains_heap_.data(), num_channels_);
+    energies_before_filtering = rtc::ArrayView<float>(
+        energies_before_filtering_heap_.data(), num_channels_);
+    gain_adjustments =
+        rtc::ArrayView<float>(gain_adjustments_heap_.data(), num_channels_);
+  }
+
+  // Compute the suppression filters for all channels.
+  for (size_t ch = 0; ch < num_channels_; ++ch) {
+    // Form an extended frame and apply analysis filter bank windowing.
+    rtc::ArrayView<float, kNsFrameSize> y_band0(&audio->split_bands(ch)[0][0],
+                                                kNsFrameSize);
+
+    FormExtendedFrame(y_band0, channels_[ch]->process_analysis_memory,
+                      filter_bank_states[ch].extended_frame);
+
+    ApplyFilterBankWindow(filter_bank_states[ch].extended_frame);
+
+    energies_before_filtering[ch] =
+        ComputeEnergyOfExtendedFrame(filter_bank_states[ch].extended_frame);
+
+    // Perform filter bank analysis and compute the magnitude spectrum.
+    fft_.Fft(filter_bank_states[ch].extended_frame, filter_bank_states[ch].real,
+             filter_bank_states[ch].imag);
+
+    std::array<float, kFftSizeBy2Plus1> signal_spectrum;
+    ComputeMagnitudeSpectrum(filter_bank_states[ch].real,
+                             filter_bank_states[ch].imag, signal_spectrum);
+
+    // Compute the frequency domain gain filter for noise attenuation.
+    channels_[ch]->wiener_filter.Update(
+        num_analyzed_frames_,
+        channels_[ch]->noise_estimator.get_noise_spectrum(),
+        channels_[ch]->noise_estimator.get_prev_noise_spectrum(),
+        channels_[ch]->noise_estimator.get_parametric_noise_spectrum(),
+        signal_spectrum);
+
+    if (num_bands_ > 1) {
+      // Compute the time-domain gain for attenuating the noise in the upper
+      // bands.
+
+      upper_band_gains[ch] = ComputeUpperBandsGain(
+          suppression_params_.minimum_attenuating_gain,
+          channels_[ch]->wiener_filter.get_filter(),
+          channels_[ch]->speech_probability_estimator.get_probability(),
+          channels_[ch]->prev_analysis_signal_spectrum, signal_spectrum);
+    }
+  }
+
+  // Only do the below processing if the output of the audio processing module
+  // is used.
+  if (!capture_output_used_) {
+    return;
+  }
+
+  // Aggregate the Wiener filters for all channels.
+  std::array<float, kFftSizeBy2Plus1> filter_data;
+  rtc::ArrayView<const float, kFftSizeBy2Plus1> filter = filter_data;
+  if (num_channels_ == 1) {
+    filter = channels_[0]->wiener_filter.get_filter();
+  } else {
+    AggregateWienerFilters(filter_data);
+  }
+
+  for (size_t ch = 0; ch < num_channels_; ++ch) {
+    // Apply the filter to the lower band.
+    for (size_t i = 0; i < kFftSizeBy2Plus1; ++i) {
+      filter_bank_states[ch].real[i] *= filter[i];
+      filter_bank_states[ch].imag[i] *= filter[i];
+    }
+  }
+
+  // Perform filter bank synthesis
+  for (size_t ch = 0; ch < num_channels_; ++ch) {
+    fft_.Ifft(filter_bank_states[ch].real, filter_bank_states[ch].imag,
+              filter_bank_states[ch].extended_frame);
+  }
+
+  for (size_t ch = 0; ch < num_channels_; ++ch) {
+    const float energy_after_filtering =
+        ComputeEnergyOfExtendedFrame(filter_bank_states[ch].extended_frame);
+
+    // Apply synthesis window.
+    ApplyFilterBankWindow(filter_bank_states[ch].extended_frame);
+
+    // Compute the adjustment of the noise attenuation filter based on the
+    // effect of the attenuation.
+    gain_adjustments[ch] =
+        channels_[ch]->wiener_filter.ComputeOverallScalingFactor(
+            num_analyzed_frames_,
+            channels_[ch]->speech_probability_estimator.get_prior_probability(),
+            energies_before_filtering[ch], energy_after_filtering);
+  }
+
+  // Select and apply adjustment of the noise attenuation filter based on the
+  // effect of the attenuation.
+  float gain_adjustment = gain_adjustments[0];
+  for (size_t ch = 1; ch < num_channels_; ++ch) {
+    gain_adjustment = std::min(gain_adjustment, gain_adjustments[ch]);
+  }
+  for (size_t ch = 0; ch < num_channels_; ++ch) {
+    for (size_t i = 0; i < kFftSize; ++i) {
+      filter_bank_states[ch].extended_frame[i] =
+          gain_adjustment * filter_bank_states[ch].extended_frame[i];
+    }
+  }
+
+  // Use overlap-and-add to form the output frame of the lowest band.
+  for (size_t ch = 0; ch < num_channels_; ++ch) {
+    rtc::ArrayView<float, kNsFrameSize> y_band0(&audio->split_bands(ch)[0][0],
+                                                kNsFrameSize);
+    OverlapAndAdd(filter_bank_states[ch].extended_frame,
+                  channels_[ch]->process_synthesis_memory, y_band0);
+  }
+
+  if (num_bands_ > 1) {
+    // Select the noise attenuating gain to apply to the upper band.
+    float upper_band_gain = upper_band_gains[0];
+    for (size_t ch = 1; ch < num_channels_; ++ch) {
+      upper_band_gain = std::min(upper_band_gain, upper_band_gains[ch]);
+    }
+
+    // Process the upper bands.
+    for (size_t ch = 0; ch < num_channels_; ++ch) {
+      for (size_t b = 1; b < num_bands_; ++b) {
+        // Delay the upper bands to match the delay of the filterbank applied to
+        // the lowest band.
+        rtc::ArrayView<float, kNsFrameSize> y_band(
+            &audio->split_bands(ch)[b][0], kNsFrameSize);
+        std::array<float, kNsFrameSize> delayed_frame;
+        DelaySignal(y_band, channels_[ch]->process_delay_memory[b - 1],
+                    delayed_frame);
+
+        // Apply the time-domain noise-attenuating gain.
+        for (size_t j = 0; j < kNsFrameSize; j++) {
+          y_band[j] = upper_band_gain * delayed_frame[j];
+        }
+      }
+    }
+  }
+
+  // Limit the output the allowed range.
+  for (size_t ch = 0; ch < num_channels_; ++ch) {
+    for (size_t b = 0; b < num_bands_; ++b) {
+      rtc::ArrayView<float, kNsFrameSize> y_band(&audio->split_bands(ch)[b][0],
+                                                 kNsFrameSize);
+      for (size_t j = 0; j < kNsFrameSize; j++) {
+        y_band[j] = std::min(std::max(y_band[j], -32768.f), 32767.f);
+      }
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/noise_suppressor.h b/third_party/webrtc_aec3/src/modules/audio_processing/ns/noise_suppressor.h
new file mode 100644
index 0000000..1e321cf
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/noise_suppressor.h
@@ -0,0 +1,92 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_NS_NOISE_SUPPRESSOR_H_
+#define MODULES_AUDIO_PROCESSING_NS_NOISE_SUPPRESSOR_H_
+
+#include <memory>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/audio_buffer.h"
+#include "modules/audio_processing/ns/noise_estimator.h"
+#include "modules/audio_processing/ns/ns_common.h"
+#include "modules/audio_processing/ns/ns_config.h"
+#include "modules/audio_processing/ns/ns_fft.h"
+#include "modules/audio_processing/ns/speech_probability_estimator.h"
+#include "modules/audio_processing/ns/wiener_filter.h"
+
+namespace webrtc {
+
+// Class for suppressing noise in a signal.
+class NoiseSuppressor {
+ public:
+  NoiseSuppressor(const NsConfig& config,
+                  size_t sample_rate_hz,
+                  size_t num_channels);
+  NoiseSuppressor(const NoiseSuppressor&) = delete;
+  NoiseSuppressor& operator=(const NoiseSuppressor&) = delete;
+
+  // Analyses the signal (typically applied before the AEC to avoid analyzing
+  // any comfort noise signal).
+  void Analyze(const AudioBuffer& audio);
+
+  // Applies noise suppression.
+  void Process(AudioBuffer* audio);
+
+  // Specifies whether the capture output will be used. The purpose of this is
+  // to allow the noise suppressor to deactivate some of the processing when the
+  // resulting output is anyway not used, for instance when the endpoint is
+  // muted.
+  void SetCaptureOutputUsage(bool capture_output_used) {
+    capture_output_used_ = capture_output_used;
+  }
+
+ private:
+  const size_t num_bands_;
+  const size_t num_channels_;
+  const SuppressionParams suppression_params_;
+  int32_t num_analyzed_frames_ = -1;
+  NrFft fft_;
+  bool capture_output_used_ = true;
+
+  struct ChannelState {
+    ChannelState(const SuppressionParams& suppression_params, size_t num_bands);
+
+    SpeechProbabilityEstimator speech_probability_estimator;
+    WienerFilter wiener_filter;
+    NoiseEstimator noise_estimator;
+    std::array<float, kFftSizeBy2Plus1> prev_analysis_signal_spectrum;
+    std::array<float, kFftSize - kNsFrameSize> analyze_analysis_memory;
+    std::array<float, kOverlapSize> process_analysis_memory;
+    std::array<float, kOverlapSize> process_synthesis_memory;
+    std::vector<std::array<float, kOverlapSize>> process_delay_memory;
+  };
+
+  struct FilterBankState {
+    std::array<float, kFftSize> real;
+    std::array<float, kFftSize> imag;
+    std::array<float, kFftSize> extended_frame;
+  };
+
+  std::vector<FilterBankState> filter_bank_states_heap_;
+  std::vector<float> upper_band_gains_heap_;
+  std::vector<float> energies_before_filtering_heap_;
+  std::vector<float> gain_adjustments_heap_;
+  std::vector<std::unique_ptr<ChannelState>> channels_;
+
+  // Aggregates the Wiener filters into a single filter to use.
+  void AggregateWienerFilters(
+      rtc::ArrayView<float, kFftSizeBy2Plus1> filter) const;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_NS_NOISE_SUPPRESSOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/noise_suppressor_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/ns/noise_suppressor_unittest.cc
new file mode 100644
index 0000000..28ea63a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/noise_suppressor_unittest.cc
@@ -0,0 +1,102 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/ns/noise_suppressor.h"
+
+#include <deque>
+#include <memory>
+#include <string>
+#include <utility>
+#include <vector>
+
+#include "rtc_base/strings/string_builder.h"
+#include "test/gmock.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+namespace {
+
+std::string ProduceDebugText(int sample_rate_hz,
+                             size_t num_channels,
+                             NsConfig::SuppressionLevel level) {
+  rtc::StringBuilder ss;
+  ss << "Sample rate: " << sample_rate_hz << ", num_channels: " << num_channels
+     << ", level: " << static_cast<int>(level);
+  return ss.Release();
+}
+
+void PopulateInputFrameWithIdenticalChannels(size_t num_channels,
+                                             size_t num_bands,
+                                             size_t frame_index,
+                                             AudioBuffer* audio) {
+  for (size_t ch = 0; ch < num_channels; ++ch) {
+    for (size_t b = 0; b < num_bands; ++b) {
+      for (size_t i = 0; i < 160; ++i) {
+        float value = static_cast<int>(frame_index * 160 + i);
+        audio->split_bands(ch)[b][i] = (value > 0 ? 5000 * b + value : 0);
+      }
+    }
+  }
+}
+
+void VerifyIdenticalChannels(size_t num_channels,
+                             size_t num_bands,
+                             size_t frame_index,
+                             const AudioBuffer& audio) {
+  EXPECT_GT(num_channels, 1u);
+  for (size_t ch = 1; ch < num_channels; ++ch) {
+    for (size_t b = 0; b < num_bands; ++b) {
+      for (size_t i = 0; i < 160; ++i) {
+        EXPECT_EQ(audio.split_bands_const(ch)[b][i],
+                  audio.split_bands_const(0)[b][i]);
+      }
+    }
+  }
+}
+
+}  // namespace
+
+// Verifies that the same noise reduction effect is applied to all channels.
+TEST(NoiseSuppressor, IdenticalChannelEffects) {
+  for (auto rate : {16000, 32000, 48000}) {
+    for (auto num_channels : {1, 4, 8}) {
+      for (auto level :
+           {NsConfig::SuppressionLevel::k6dB, NsConfig::SuppressionLevel::k12dB,
+            NsConfig::SuppressionLevel::k18dB,
+            NsConfig::SuppressionLevel::k21dB}) {
+        SCOPED_TRACE(ProduceDebugText(rate, num_channels, level));
+
+        const size_t num_bands = rate / 16000;
+        // const int frame_length = rtc::CheckedDivExact(rate, 100);
+        AudioBuffer audio(rate, num_channels, rate, num_channels, rate,
+                          num_channels);
+        NsConfig cfg;
+        NoiseSuppressor ns(cfg, rate, num_channels);
+        for (size_t frame_index = 0; frame_index < 1000; ++frame_index) {
+          if (rate > 16000) {
+            audio.SplitIntoFrequencyBands();
+          }
+
+          PopulateInputFrameWithIdenticalChannels(num_channels, num_bands,
+                                                  frame_index, &audio);
+
+          ns.Analyze(audio);
+          ns.Process(&audio);
+          if (num_channels > 1) {
+            VerifyIdenticalChannels(num_channels, num_bands, frame_index,
+                                    audio);
+          }
+        }
+      }
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/ns_common.h b/third_party/webrtc_aec3/src/modules/audio_processing/ns/ns_common.h
new file mode 100644
index 0000000..d6149f7
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/ns_common.h
@@ -0,0 +1,34 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_NS_NS_COMMON_H_
+#define MODULES_AUDIO_PROCESSING_NS_NS_COMMON_H_
+
+#include <cstddef>
+
+namespace webrtc {
+
+constexpr size_t kFftSize = 256;
+constexpr size_t kFftSizeBy2Plus1 = kFftSize / 2 + 1;
+constexpr size_t kNsFrameSize = 160;
+constexpr size_t kOverlapSize = kFftSize - kNsFrameSize;
+
+constexpr int kShortStartupPhaseBlocks = 50;
+constexpr int kLongStartupPhaseBlocks = 200;
+constexpr int kFeatureUpdateWindowSize = 500;
+
+constexpr float kLtrFeatureThr = 0.5f;
+constexpr float kBinSizeLrt = 0.1f;
+constexpr float kBinSizeSpecFlat = 0.05f;
+constexpr float kBinSizeSpecDiff = 0.1f;
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_NS_NS_COMMON_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/ns_config.h b/third_party/webrtc_aec3/src/modules/audio_processing/ns/ns_config.h
new file mode 100644
index 0000000..0a285e9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/ns_config.h
@@ -0,0 +1,24 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_NS_NS_CONFIG_H_
+#define MODULES_AUDIO_PROCESSING_NS_NS_CONFIG_H_
+
+namespace webrtc {
+
+// Config struct for the noise suppressor
+struct NsConfig {
+  enum class SuppressionLevel { k6dB, k12dB, k18dB, k21dB };
+  SuppressionLevel target_level = SuppressionLevel::k12dB;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_NS_NS_CONFIG_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/ns_fft.cc b/third_party/webrtc_aec3/src/modules/audio_processing/ns/ns_fft.cc
new file mode 100644
index 0000000..264c469
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/ns_fft.cc
@@ -0,0 +1,64 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/ns/ns_fft.h"
+
+#include "common_audio/third_party/ooura/fft_size_256/fft4g.h"
+
+namespace webrtc {
+
+NrFft::NrFft() : bit_reversal_state_(kFftSize / 2), tables_(kFftSize / 2) {
+  // Initialize WebRtc_rdt (setting (bit_reversal_state_[0] to 0 triggers
+  // initialization)
+  bit_reversal_state_[0] = 0.f;
+  std::array<float, kFftSize> tmp_buffer;
+  tmp_buffer.fill(0.f);
+  WebRtc_rdft(kFftSize, 1, tmp_buffer.data(), bit_reversal_state_.data(),
+              tables_.data());
+}
+
+void NrFft::Fft(rtc::ArrayView<float, kFftSize> time_data,
+                rtc::ArrayView<float, kFftSize> real,
+                rtc::ArrayView<float, kFftSize> imag) {
+  WebRtc_rdft(kFftSize, 1, time_data.data(), bit_reversal_state_.data(),
+              tables_.data());
+
+  imag[0] = 0;
+  real[0] = time_data[0];
+
+  imag[kFftSizeBy2Plus1 - 1] = 0;
+  real[kFftSizeBy2Plus1 - 1] = time_data[1];
+
+  for (size_t i = 1; i < kFftSizeBy2Plus1 - 1; ++i) {
+    real[i] = time_data[2 * i];
+    imag[i] = time_data[2 * i + 1];
+  }
+}
+
+void NrFft::Ifft(rtc::ArrayView<const float> real,
+                 rtc::ArrayView<const float> imag,
+                 rtc::ArrayView<float> time_data) {
+  time_data[0] = real[0];
+  time_data[1] = real[kFftSizeBy2Plus1 - 1];
+  for (size_t i = 1; i < kFftSizeBy2Plus1 - 1; ++i) {
+    time_data[2 * i] = real[i];
+    time_data[2 * i + 1] = imag[i];
+  }
+  WebRtc_rdft(kFftSize, -1, time_data.data(), bit_reversal_state_.data(),
+              tables_.data());
+
+  // Scale the output
+  constexpr float kScaling = 2.f / kFftSize;
+  for (float& d : time_data) {
+    d *= kScaling;
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/ns_fft.h b/third_party/webrtc_aec3/src/modules/audio_processing/ns/ns_fft.h
new file mode 100644
index 0000000..539251e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/ns_fft.h
@@ -0,0 +1,45 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_NS_NS_FFT_H_
+#define MODULES_AUDIO_PROCESSING_NS_NS_FFT_H_
+
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/ns/ns_common.h"
+
+namespace webrtc {
+
+// Wrapper class providing 256 point FFT functionality.
+class NrFft {
+ public:
+  NrFft();
+  NrFft(const NrFft&) = delete;
+  NrFft& operator=(const NrFft&) = delete;
+
+  // Transforms the signal from time to frequency domain.
+  void Fft(rtc::ArrayView<float, kFftSize> time_data,
+           rtc::ArrayView<float, kFftSize> real,
+           rtc::ArrayView<float, kFftSize> imag);
+
+  // Transforms the signal from frequency to time domain.
+  void Ifft(rtc::ArrayView<const float> real,
+            rtc::ArrayView<const float> imag,
+            rtc::ArrayView<float> time_data);
+
+ private:
+  std::vector<size_t> bit_reversal_state_;
+  std::vector<float> tables_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_NS_NS_FFT_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/prior_signal_model.cc b/third_party/webrtc_aec3/src/modules/audio_processing/ns/prior_signal_model.cc
new file mode 100644
index 0000000..f25a1e2
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/prior_signal_model.cc
@@ -0,0 +1,18 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/ns/prior_signal_model.h"
+
+namespace webrtc {
+
+PriorSignalModel::PriorSignalModel(float lrt_initial_value)
+    : lrt(lrt_initial_value) {}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/prior_signal_model.h b/third_party/webrtc_aec3/src/modules/audio_processing/ns/prior_signal_model.h
new file mode 100644
index 0000000..dcfa7ea
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/prior_signal_model.h
@@ -0,0 +1,32 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_NS_PRIOR_SIGNAL_MODEL_H_
+#define MODULES_AUDIO_PROCESSING_NS_PRIOR_SIGNAL_MODEL_H_
+
+namespace webrtc {
+
+// Struct for storing the prior signal model parameters.
+struct PriorSignalModel {
+  explicit PriorSignalModel(float lrt_initial_value);
+  PriorSignalModel(const PriorSignalModel&) = delete;
+  PriorSignalModel& operator=(const PriorSignalModel&) = delete;
+
+  float lrt;
+  float flatness_threshold = .5f;
+  float template_diff_threshold = .5f;
+  float lrt_weighting = 1.f;
+  float flatness_weighting = 0.f;
+  float difference_weighting = 0.f;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_NS_PRIOR_SIGNAL_MODEL_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/prior_signal_model_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/ns/prior_signal_model_estimator.cc
new file mode 100644
index 0000000..c814658
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/prior_signal_model_estimator.cc
@@ -0,0 +1,170 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/ns/prior_signal_model_estimator.h"
+
+#include <math.h>
+#include <algorithm>
+
+#include "modules/audio_processing/ns/fast_math.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+namespace {
+
+// Identifies the first of the two largest peaks in the histogram.
+void FindFirstOfTwoLargestPeaks(
+    float bin_size,
+    rtc::ArrayView<const int, kHistogramSize> spectral_flatness,
+    float* peak_position,
+    int* peak_weight) {
+  RTC_DCHECK(peak_position);
+  RTC_DCHECK(peak_weight);
+
+  int peak_value = 0;
+  int secondary_peak_value = 0;
+  *peak_position = 0.f;
+  float secondary_peak_position = 0.f;
+  *peak_weight = 0;
+  int secondary_peak_weight = 0;
+
+  // Identify the two largest peaks.
+  for (int i = 0; i < kHistogramSize; ++i) {
+    const float bin_mid = (i + 0.5f) * bin_size;
+    if (spectral_flatness[i] > peak_value) {
+      // Found new "first" peak candidate.
+      secondary_peak_value = peak_value;
+      secondary_peak_weight = *peak_weight;
+      secondary_peak_position = *peak_position;
+
+      peak_value = spectral_flatness[i];
+      *peak_weight = spectral_flatness[i];
+      *peak_position = bin_mid;
+    } else if (spectral_flatness[i] > secondary_peak_value) {
+      // Found new "second" peak candidate.
+      secondary_peak_value = spectral_flatness[i];
+      secondary_peak_weight = spectral_flatness[i];
+      secondary_peak_position = bin_mid;
+    }
+  }
+
+  // Merge the peaks if they are close.
+  if ((fabs(secondary_peak_position - *peak_position) < 2 * bin_size) &&
+      (secondary_peak_weight > 0.5f * (*peak_weight))) {
+    *peak_weight += secondary_peak_weight;
+    *peak_position = 0.5f * (*peak_position + secondary_peak_position);
+  }
+}
+
+void UpdateLrt(rtc::ArrayView<const int, kHistogramSize> lrt_histogram,
+               float* prior_model_lrt,
+               bool* low_lrt_fluctuations) {
+  RTC_DCHECK(prior_model_lrt);
+  RTC_DCHECK(low_lrt_fluctuations);
+
+  float average = 0.f;
+  float average_compl = 0.f;
+  float average_squared = 0.f;
+  int count = 0;
+
+  for (int i = 0; i < 10; ++i) {
+    float bin_mid = (i + 0.5f) * kBinSizeLrt;
+    average += lrt_histogram[i] * bin_mid;
+    count += lrt_histogram[i];
+  }
+  if (count > 0) {
+    average = average / count;
+  }
+
+  for (int i = 0; i < kHistogramSize; ++i) {
+    float bin_mid = (i + 0.5f) * kBinSizeLrt;
+    average_squared += lrt_histogram[i] * bin_mid * bin_mid;
+    average_compl += lrt_histogram[i] * bin_mid;
+  }
+  constexpr float kOneFeatureUpdateWindowSize = 1.f / kFeatureUpdateWindowSize;
+  average_squared = average_squared * kOneFeatureUpdateWindowSize;
+  average_compl = average_compl * kOneFeatureUpdateWindowSize;
+
+  // Fluctuation limit of LRT feature.
+  *low_lrt_fluctuations = average_squared - average * average_compl < 0.05f;
+
+  // Get threshold for LRT feature.
+  constexpr float kMaxLrt = 1.f;
+  constexpr float kMinLrt = .2f;
+  if (*low_lrt_fluctuations) {
+    // Very low fluctuation, so likely noise.
+    *prior_model_lrt = kMaxLrt;
+  } else {
+    *prior_model_lrt = std::min(kMaxLrt, std::max(kMinLrt, 1.2f * average));
+  }
+}
+
+}  // namespace
+
+PriorSignalModelEstimator::PriorSignalModelEstimator(float lrt_initial_value)
+    : prior_model_(lrt_initial_value) {}
+
+// Extract thresholds for feature parameters and computes the threshold/weights.
+void PriorSignalModelEstimator::Update(const Histograms& histograms) {
+  bool low_lrt_fluctuations;
+  UpdateLrt(histograms.get_lrt(), &prior_model_.lrt, &low_lrt_fluctuations);
+
+  // For spectral flatness and spectral difference: compute the main peaks of
+  // the histograms.
+  float spectral_flatness_peak_position;
+  int spectral_flatness_peak_weight;
+  FindFirstOfTwoLargestPeaks(
+      kBinSizeSpecFlat, histograms.get_spectral_flatness(),
+      &spectral_flatness_peak_position, &spectral_flatness_peak_weight);
+
+  float spectral_diff_peak_position = 0.f;
+  int spectral_diff_peak_weight = 0;
+  FindFirstOfTwoLargestPeaks(kBinSizeSpecDiff, histograms.get_spectral_diff(),
+                             &spectral_diff_peak_position,
+                             &spectral_diff_peak_weight);
+
+  // Reject if weight of peaks is not large enough, or peak value too small.
+  // Peak limit for spectral flatness (varies between 0 and 1).
+  const int use_spec_flat = spectral_flatness_peak_weight < 0.3f * 500 ||
+                                    spectral_flatness_peak_position < 0.6f
+                                ? 0
+                                : 1;
+
+  // Reject if weight of peaks is not large enough or if fluctuation of the LRT
+  // feature are very low, indicating a noise state.
+  const int use_spec_diff =
+      spectral_diff_peak_weight < 0.3f * 500 || low_lrt_fluctuations ? 0 : 1;
+
+  // Update the model.
+  prior_model_.template_diff_threshold = 1.2f * spectral_diff_peak_position;
+  prior_model_.template_diff_threshold =
+      std::min(1.f, std::max(0.16f, prior_model_.template_diff_threshold));
+
+  float one_by_feature_sum = 1.f / (1.f + use_spec_flat + use_spec_diff);
+  prior_model_.lrt_weighting = one_by_feature_sum;
+
+  if (use_spec_flat == 1) {
+    prior_model_.flatness_threshold = 0.9f * spectral_flatness_peak_position;
+    prior_model_.flatness_threshold =
+        std::min(.95f, std::max(0.1f, prior_model_.flatness_threshold));
+    prior_model_.flatness_weighting = one_by_feature_sum;
+  } else {
+    prior_model_.flatness_weighting = 0.f;
+  }
+
+  if (use_spec_diff == 1) {
+    prior_model_.difference_weighting = one_by_feature_sum;
+  } else {
+    prior_model_.difference_weighting = 0.f;
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/prior_signal_model_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/ns/prior_signal_model_estimator.h
new file mode 100644
index 0000000..d178323
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/prior_signal_model_estimator.h
@@ -0,0 +1,39 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_NS_PRIOR_SIGNAL_MODEL_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_NS_PRIOR_SIGNAL_MODEL_ESTIMATOR_H_
+
+#include "modules/audio_processing/ns/histograms.h"
+#include "modules/audio_processing/ns/prior_signal_model.h"
+
+namespace webrtc {
+
+// Estimator of the prior signal model parameters.
+class PriorSignalModelEstimator {
+ public:
+  explicit PriorSignalModelEstimator(float lrt_initial_value);
+  PriorSignalModelEstimator(const PriorSignalModelEstimator&) = delete;
+  PriorSignalModelEstimator& operator=(const PriorSignalModelEstimator&) =
+      delete;
+
+  // Updates the model estimate.
+  void Update(const Histograms& h);
+
+  // Returns the estimated model.
+  const PriorSignalModel& get_prior_model() const { return prior_model_; }
+
+ private:
+  PriorSignalModel prior_model_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_NS_PRIOR_SIGNAL_MODEL_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/quantile_noise_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/ns/quantile_noise_estimator.cc
new file mode 100644
index 0000000..bab494f
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/quantile_noise_estimator.cc
@@ -0,0 +1,88 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/ns/quantile_noise_estimator.h"
+
+#include <algorithm>
+
+#include "modules/audio_processing/ns/fast_math.h"
+
+namespace webrtc {
+
+QuantileNoiseEstimator::QuantileNoiseEstimator() {
+  quantile_.fill(0.f);
+  density_.fill(0.3f);
+  log_quantile_.fill(8.f);
+
+  constexpr float kOneBySimult = 1.f / kSimult;
+  for (size_t i = 0; i < kSimult; ++i) {
+    counter_[i] = floor(kLongStartupPhaseBlocks * (i + 1.f) * kOneBySimult);
+  }
+}
+
+void QuantileNoiseEstimator::Estimate(
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> signal_spectrum,
+    rtc::ArrayView<float, kFftSizeBy2Plus1> noise_spectrum) {
+  std::array<float, kFftSizeBy2Plus1> log_spectrum;
+  LogApproximation(signal_spectrum, log_spectrum);
+
+  int quantile_index_to_return = -1;
+  // Loop over simultaneous estimates.
+  for (int s = 0, k = 0; s < kSimult;
+       ++s, k += static_cast<int>(kFftSizeBy2Plus1)) {
+    const float one_by_counter_plus_1 = 1.f / (counter_[s] + 1.f);
+    for (int i = 0, j = k; i < static_cast<int>(kFftSizeBy2Plus1); ++i, ++j) {
+      // Update log quantile estimate.
+      const float delta = density_[j] > 1.f ? 40.f / density_[j] : 40.f;
+
+      const float multiplier = delta * one_by_counter_plus_1;
+      if (log_spectrum[i] > log_quantile_[j]) {
+        log_quantile_[j] += 0.25f * multiplier;
+      } else {
+        log_quantile_[j] -= 0.75f * multiplier;
+      }
+
+      // Update density estimate.
+      constexpr float kWidth = 0.01f;
+      constexpr float kOneByWidthPlus2 = 1.f / (2.f * kWidth);
+      if (fabs(log_spectrum[i] - log_quantile_[j]) < kWidth) {
+        density_[j] = (counter_[s] * density_[j] + kOneByWidthPlus2) *
+                      one_by_counter_plus_1;
+      }
+    }
+
+    if (counter_[s] >= kLongStartupPhaseBlocks) {
+      counter_[s] = 0;
+      if (num_updates_ >= kLongStartupPhaseBlocks) {
+        quantile_index_to_return = k;
+      }
+    }
+
+    ++counter_[s];
+  }
+
+  // Sequentially update the noise during startup.
+  if (num_updates_ < kLongStartupPhaseBlocks) {
+    // Use the last "s" to get noise during startup that differ from zero.
+    quantile_index_to_return = kFftSizeBy2Plus1 * (kSimult - 1);
+    ++num_updates_;
+  }
+
+  if (quantile_index_to_return >= 0) {
+    ExpApproximation(
+        rtc::ArrayView<const float>(&log_quantile_[quantile_index_to_return],
+                                    kFftSizeBy2Plus1),
+        quantile_);
+  }
+
+  std::copy(quantile_.begin(), quantile_.end(), noise_spectrum.begin());
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/quantile_noise_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/ns/quantile_noise_estimator.h
new file mode 100644
index 0000000..67d1512
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/quantile_noise_estimator.h
@@ -0,0 +1,45 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_NS_QUANTILE_NOISE_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_NS_QUANTILE_NOISE_ESTIMATOR_H_
+
+#include <math.h>
+#include <array>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/ns/ns_common.h"
+
+namespace webrtc {
+
+constexpr int kSimult = 3;
+
+// For quantile noise estimation.
+class QuantileNoiseEstimator {
+ public:
+  QuantileNoiseEstimator();
+  QuantileNoiseEstimator(const QuantileNoiseEstimator&) = delete;
+  QuantileNoiseEstimator& operator=(const QuantileNoiseEstimator&) = delete;
+
+  // Estimate noise.
+  void Estimate(rtc::ArrayView<const float, kFftSizeBy2Plus1> signal_spectrum,
+                rtc::ArrayView<float, kFftSizeBy2Plus1> noise_spectrum);
+
+ private:
+  std::array<float, kSimult * kFftSizeBy2Plus1> density_;
+  std::array<float, kSimult * kFftSizeBy2Plus1> log_quantile_;
+  std::array<float, kFftSizeBy2Plus1> quantile_;
+  std::array<int, kSimult> counter_;
+  int num_updates_ = 1;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_NS_QUANTILE_NOISE_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/signal_model.cc b/third_party/webrtc_aec3/src/modules/audio_processing/ns/signal_model.cc
new file mode 100644
index 0000000..364bfd0
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/signal_model.cc
@@ -0,0 +1,24 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/ns/signal_model.h"
+
+namespace webrtc {
+
+SignalModel::SignalModel() {
+  constexpr float kSfFeatureThr = 0.5f;
+
+  lrt = kLtrFeatureThr;
+  spectral_flatness = kSfFeatureThr;
+  spectral_diff = kSfFeatureThr;
+  avg_log_lrt.fill(kLtrFeatureThr);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/signal_model.h b/third_party/webrtc_aec3/src/modules/audio_processing/ns/signal_model.h
new file mode 100644
index 0000000..6614d38
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/signal_model.h
@@ -0,0 +1,34 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_NS_SIGNAL_MODEL_H_
+#define MODULES_AUDIO_PROCESSING_NS_SIGNAL_MODEL_H_
+
+#include <array>
+
+#include "modules/audio_processing/ns/ns_common.h"
+
+namespace webrtc {
+
+struct SignalModel {
+  SignalModel();
+  SignalModel(const SignalModel&) = delete;
+  SignalModel& operator=(const SignalModel&) = delete;
+
+  float lrt;
+  float spectral_diff;
+  float spectral_flatness;
+  // Log LRT factor with time-smoothing.
+  std::array<float, kFftSizeBy2Plus1> avg_log_lrt;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_NS_SIGNAL_MODEL_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/signal_model_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/ns/signal_model_estimator.cc
new file mode 100644
index 0000000..67dd3bb
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/signal_model_estimator.cc
@@ -0,0 +1,175 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/ns/signal_model_estimator.h"
+
+#include "modules/audio_processing/ns/fast_math.h"
+
+namespace webrtc {
+
+namespace {
+
+constexpr float kOneByFftSizeBy2Plus1 = 1.f / kFftSizeBy2Plus1;
+
+// Computes the difference measure between input spectrum and a template/learned
+// noise spectrum.
+float ComputeSpectralDiff(
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> conservative_noise_spectrum,
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> signal_spectrum,
+    float signal_spectral_sum,
+    float diff_normalization) {
+  // spectral_diff = var(signal_spectrum) - cov(signal_spectrum, magnAvgPause)^2
+  // / var(magnAvgPause)
+
+  // Compute average quantities.
+  float noise_average = 0.f;
+  for (size_t i = 0; i < kFftSizeBy2Plus1; ++i) {
+    // Conservative smooth noise spectrum from pause frames.
+    noise_average += conservative_noise_spectrum[i];
+  }
+  noise_average = noise_average * kOneByFftSizeBy2Plus1;
+  float signal_average = signal_spectral_sum * kOneByFftSizeBy2Plus1;
+
+  // Compute variance and covariance quantities.
+  float covariance = 0.f;
+  float noise_variance = 0.f;
+  float signal_variance = 0.f;
+  for (size_t i = 0; i < kFftSizeBy2Plus1; ++i) {
+    float signal_diff = signal_spectrum[i] - signal_average;
+    float noise_diff = conservative_noise_spectrum[i] - noise_average;
+    covariance += signal_diff * noise_diff;
+    noise_variance += noise_diff * noise_diff;
+    signal_variance += signal_diff * signal_diff;
+  }
+  covariance *= kOneByFftSizeBy2Plus1;
+  noise_variance *= kOneByFftSizeBy2Plus1;
+  signal_variance *= kOneByFftSizeBy2Plus1;
+
+  // Update of average magnitude spectrum.
+  float spectral_diff =
+      signal_variance - (covariance * covariance) / (noise_variance + 0.0001f);
+  // Normalize.
+  return spectral_diff / (diff_normalization + 0.0001f);
+}
+
+// Updates the spectral flatness based on the input spectrum.
+void UpdateSpectralFlatness(
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> signal_spectrum,
+    float signal_spectral_sum,
+    float* spectral_flatness) {
+  RTC_DCHECK(spectral_flatness);
+
+  // Compute log of ratio of the geometric to arithmetic mean (handle the log(0)
+  // separately).
+  constexpr float kAveraging = 0.3f;
+  float avg_spect_flatness_num = 0.f;
+  for (size_t i = 1; i < kFftSizeBy2Plus1; ++i) {
+    if (signal_spectrum[i] == 0.f) {
+      *spectral_flatness -= kAveraging * (*spectral_flatness);
+      return;
+    }
+  }
+
+  for (size_t i = 1; i < kFftSizeBy2Plus1; ++i) {
+    avg_spect_flatness_num += LogApproximation(signal_spectrum[i]);
+  }
+
+  float avg_spect_flatness_denom = signal_spectral_sum - signal_spectrum[0];
+
+  avg_spect_flatness_denom = avg_spect_flatness_denom * kOneByFftSizeBy2Plus1;
+  avg_spect_flatness_num = avg_spect_flatness_num * kOneByFftSizeBy2Plus1;
+
+  float spectral_tmp =
+      ExpApproximation(avg_spect_flatness_num) / avg_spect_flatness_denom;
+
+  // Time-avg update of spectral flatness feature.
+  *spectral_flatness += kAveraging * (spectral_tmp - *spectral_flatness);
+}
+
+// Updates the log LRT measures.
+void UpdateSpectralLrt(rtc::ArrayView<const float, kFftSizeBy2Plus1> prior_snr,
+                       rtc::ArrayView<const float, kFftSizeBy2Plus1> post_snr,
+                       rtc::ArrayView<float, kFftSizeBy2Plus1> avg_log_lrt,
+                       float* lrt) {
+  RTC_DCHECK(lrt);
+
+  for (size_t i = 0; i < kFftSizeBy2Plus1; ++i) {
+    float tmp1 = 1.f + 2.f * prior_snr[i];
+    float tmp2 = 2.f * prior_snr[i] / (tmp1 + 0.0001f);
+    float bessel_tmp = (post_snr[i] + 1.f) * tmp2;
+    avg_log_lrt[i] +=
+        .5f * (bessel_tmp - LogApproximation(tmp1) - avg_log_lrt[i]);
+  }
+
+  float log_lrt_time_avg_k_sum = 0.f;
+  for (size_t i = 0; i < kFftSizeBy2Plus1; ++i) {
+    log_lrt_time_avg_k_sum += avg_log_lrt[i];
+  }
+  *lrt = log_lrt_time_avg_k_sum * kOneByFftSizeBy2Plus1;
+}
+
+}  // namespace
+
+SignalModelEstimator::SignalModelEstimator()
+    : prior_model_estimator_(kLtrFeatureThr) {}
+
+void SignalModelEstimator::AdjustNormalization(int32_t num_analyzed_frames,
+                                               float signal_energy) {
+  diff_normalization_ *= num_analyzed_frames;
+  diff_normalization_ += signal_energy;
+  diff_normalization_ /= (num_analyzed_frames + 1);
+}
+
+// Update the noise features.
+void SignalModelEstimator::Update(
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> prior_snr,
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> post_snr,
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> conservative_noise_spectrum,
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> signal_spectrum,
+    float signal_spectral_sum,
+    float signal_energy) {
+  // Compute spectral flatness on input spectrum.
+  UpdateSpectralFlatness(signal_spectrum, signal_spectral_sum,
+                         &features_.spectral_flatness);
+
+  // Compute difference of input spectrum with learned/estimated noise spectrum.
+  float spectral_diff =
+      ComputeSpectralDiff(conservative_noise_spectrum, signal_spectrum,
+                          signal_spectral_sum, diff_normalization_);
+  // Compute time-avg update of difference feature.
+  features_.spectral_diff += 0.3f * (spectral_diff - features_.spectral_diff);
+
+  signal_energy_sum_ += signal_energy;
+
+  // Compute histograms for parameter decisions (thresholds and weights for
+  // features). Parameters are extracted periodically.
+  if (--histogram_analysis_counter_ > 0) {
+    histograms_.Update(features_);
+  } else {
+    // Compute model parameters.
+    prior_model_estimator_.Update(histograms_);
+
+    // Clear histograms for next update.
+    histograms_.Clear();
+
+    histogram_analysis_counter_ = kFeatureUpdateWindowSize;
+
+    // Update every window:
+    // Compute normalization for the spectral difference for next estimation.
+    signal_energy_sum_ = signal_energy_sum_ / kFeatureUpdateWindowSize;
+    diff_normalization_ = 0.5f * (signal_energy_sum_ + diff_normalization_);
+    signal_energy_sum_ = 0.f;
+  }
+
+  // Compute the LRT.
+  UpdateSpectralLrt(prior_snr, post_snr, features_.avg_log_lrt, &features_.lrt);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/signal_model_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/ns/signal_model_estimator.h
new file mode 100644
index 0000000..58ce00a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/signal_model_estimator.h
@@ -0,0 +1,58 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_NS_SIGNAL_MODEL_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_NS_SIGNAL_MODEL_ESTIMATOR_H_
+
+#include <array>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/ns/histograms.h"
+#include "modules/audio_processing/ns/ns_common.h"
+#include "modules/audio_processing/ns/prior_signal_model.h"
+#include "modules/audio_processing/ns/prior_signal_model_estimator.h"
+#include "modules/audio_processing/ns/signal_model.h"
+
+namespace webrtc {
+
+class SignalModelEstimator {
+ public:
+  SignalModelEstimator();
+  SignalModelEstimator(const SignalModelEstimator&) = delete;
+  SignalModelEstimator& operator=(const SignalModelEstimator&) = delete;
+
+  // Compute signal normalization during the initial startup phase.
+  void AdjustNormalization(int32_t num_analyzed_frames, float signal_energy);
+
+  void Update(
+      rtc::ArrayView<const float, kFftSizeBy2Plus1> prior_snr,
+      rtc::ArrayView<const float, kFftSizeBy2Plus1> post_snr,
+      rtc::ArrayView<const float, kFftSizeBy2Plus1> conservative_noise_spectrum,
+      rtc::ArrayView<const float, kFftSizeBy2Plus1> signal_spectrum,
+      float signal_spectral_sum,
+      float signal_energy);
+
+  const PriorSignalModel& get_prior_model() const {
+    return prior_model_estimator_.get_prior_model();
+  }
+  const SignalModel& get_model() { return features_; }
+
+ private:
+  float diff_normalization_ = 0.f;
+  float signal_energy_sum_ = 0.f;
+  Histograms histograms_;
+  int histogram_analysis_counter_ = 500;
+  PriorSignalModelEstimator prior_model_estimator_;
+  SignalModel features_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_NS_SIGNAL_MODEL_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/speech_probability_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/ns/speech_probability_estimator.cc
new file mode 100644
index 0000000..fce9bc8
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/speech_probability_estimator.cc
@@ -0,0 +1,103 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/ns/speech_probability_estimator.h"
+
+#include <math.h>
+#include <algorithm>
+
+#include "modules/audio_processing/ns/fast_math.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+SpeechProbabilityEstimator::SpeechProbabilityEstimator() {
+  speech_probability_.fill(0.f);
+}
+
+void SpeechProbabilityEstimator::Update(
+    int32_t num_analyzed_frames,
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> prior_snr,
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> post_snr,
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> conservative_noise_spectrum,
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> signal_spectrum,
+    float signal_spectral_sum,
+    float signal_energy) {
+  // Update models.
+  if (num_analyzed_frames < kLongStartupPhaseBlocks) {
+    signal_model_estimator_.AdjustNormalization(num_analyzed_frames,
+                                                signal_energy);
+  }
+  signal_model_estimator_.Update(prior_snr, post_snr,
+                                 conservative_noise_spectrum, signal_spectrum,
+                                 signal_spectral_sum, signal_energy);
+
+  const SignalModel& model = signal_model_estimator_.get_model();
+  const PriorSignalModel& prior_model =
+      signal_model_estimator_.get_prior_model();
+
+  // Width parameter in sigmoid map for prior model.
+  constexpr float kWidthPrior0 = 4.f;
+  // Width for pause region: lower range, so increase width in tanh map.
+  constexpr float kWidthPrior1 = 2.f * kWidthPrior0;
+
+  // Average LRT feature: use larger width in tanh map for pause regions.
+  float width_prior = model.lrt < prior_model.lrt ? kWidthPrior1 : kWidthPrior0;
+
+  // Compute indicator function: sigmoid map.
+  float indicator0 =
+      0.5f * (tanh(width_prior * (model.lrt - prior_model.lrt)) + 1.f);
+
+  // Spectral flatness feature: use larger width in tanh map for pause regions.
+  width_prior = model.spectral_flatness > prior_model.flatness_threshold
+                    ? kWidthPrior1
+                    : kWidthPrior0;
+
+  // Compute indicator function: sigmoid map.
+  float indicator1 =
+      0.5f * (tanh(1.f * width_prior *
+                   (prior_model.flatness_threshold - model.spectral_flatness)) +
+              1.f);
+
+  // For template spectrum-difference : use larger width in tanh map for pause
+  // regions.
+  width_prior = model.spectral_diff < prior_model.template_diff_threshold
+                    ? kWidthPrior1
+                    : kWidthPrior0;
+
+  // Compute indicator function: sigmoid map.
+  float indicator2 =
+      0.5f * (tanh(width_prior * (model.spectral_diff -
+                                  prior_model.template_diff_threshold)) +
+              1.f);
+
+  // Combine the indicator function with the feature weights.
+  float ind_prior = prior_model.lrt_weighting * indicator0 +
+                    prior_model.flatness_weighting * indicator1 +
+                    prior_model.difference_weighting * indicator2;
+
+  // Compute the prior probability.
+  prior_speech_prob_ += 0.1f * (ind_prior - prior_speech_prob_);
+
+  // Make sure probabilities are within range: keep floor to 0.01.
+  prior_speech_prob_ = std::max(std::min(prior_speech_prob_, 1.f), 0.01f);
+
+  // Final speech probability: combine prior model with LR factor:.
+  float gain_prior =
+      (1.f - prior_speech_prob_) / (prior_speech_prob_ + 0.0001f);
+
+  std::array<float, kFftSizeBy2Plus1> inv_lrt;
+  ExpApproximationSignFlip(model.avg_log_lrt, inv_lrt);
+  for (size_t i = 0; i < kFftSizeBy2Plus1; ++i) {
+    speech_probability_[i] = 1.f / (1.f + gain_prior * inv_lrt[i]);
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/speech_probability_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/ns/speech_probability_estimator.h
new file mode 100644
index 0000000..259c3b6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/speech_probability_estimator.h
@@ -0,0 +1,51 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_NS_SPEECH_PROBABILITY_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_NS_SPEECH_PROBABILITY_ESTIMATOR_H_
+
+#include <array>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/ns/ns_common.h"
+#include "modules/audio_processing/ns/signal_model_estimator.h"
+
+namespace webrtc {
+
+// Class for estimating the probability of speech.
+class SpeechProbabilityEstimator {
+ public:
+  SpeechProbabilityEstimator();
+  SpeechProbabilityEstimator(const SpeechProbabilityEstimator&) = delete;
+  SpeechProbabilityEstimator& operator=(const SpeechProbabilityEstimator&) =
+      delete;
+
+  // Compute speech probability.
+  void Update(
+      int32_t num_analyzed_frames,
+      rtc::ArrayView<const float, kFftSizeBy2Plus1> prior_snr,
+      rtc::ArrayView<const float, kFftSizeBy2Plus1> post_snr,
+      rtc::ArrayView<const float, kFftSizeBy2Plus1> conservative_noise_spectrum,
+      rtc::ArrayView<const float, kFftSizeBy2Plus1> signal_spectrum,
+      float signal_spectral_sum,
+      float signal_energy);
+
+  float get_prior_probability() const { return prior_speech_prob_; }
+  rtc::ArrayView<const float> get_probability() { return speech_probability_; }
+
+ private:
+  SignalModelEstimator signal_model_estimator_;
+  float prior_speech_prob_ = .5f;
+  std::array<float, kFftSizeBy2Plus1> speech_probability_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_NS_SPEECH_PROBABILITY_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/suppression_params.cc b/third_party/webrtc_aec3/src/modules/audio_processing/ns/suppression_params.cc
new file mode 100644
index 0000000..9a6bd5a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/suppression_params.cc
@@ -0,0 +1,49 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/ns/suppression_params.h"
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+SuppressionParams::SuppressionParams(
+    NsConfig::SuppressionLevel suppression_level) {
+  switch (suppression_level) {
+    case NsConfig::SuppressionLevel::k6dB:
+      over_subtraction_factor = 1.f;
+      // 6 dB attenuation.
+      minimum_attenuating_gain = 0.5f;
+      use_attenuation_adjustment = false;
+      break;
+    case NsConfig::SuppressionLevel::k12dB:
+      over_subtraction_factor = 1.f;
+      // 12 dB attenuation.
+      minimum_attenuating_gain = 0.25f;
+      use_attenuation_adjustment = true;
+      break;
+    case NsConfig::SuppressionLevel::k18dB:
+      over_subtraction_factor = 1.1f;
+      // 18 dB attenuation.
+      minimum_attenuating_gain = 0.125f;
+      use_attenuation_adjustment = true;
+      break;
+    case NsConfig::SuppressionLevel::k21dB:
+      over_subtraction_factor = 1.25f;
+      // 20.9 dB attenuation.
+      minimum_attenuating_gain = 0.09f;
+      use_attenuation_adjustment = true;
+      break;
+    default:
+      RTC_NOTREACHED();
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/suppression_params.h b/third_party/webrtc_aec3/src/modules/audio_processing/ns/suppression_params.h
new file mode 100644
index 0000000..ad11977
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/suppression_params.h
@@ -0,0 +1,30 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_NS_SUPPRESSION_PARAMS_H_
+#define MODULES_AUDIO_PROCESSING_NS_SUPPRESSION_PARAMS_H_
+
+#include "modules/audio_processing/ns/ns_config.h"
+
+namespace webrtc {
+
+struct SuppressionParams {
+  explicit SuppressionParams(NsConfig::SuppressionLevel suppression_level);
+  SuppressionParams(const SuppressionParams&) = delete;
+  SuppressionParams& operator=(const SuppressionParams&) = delete;
+
+  float over_subtraction_factor;
+  float minimum_attenuating_gain;
+  bool use_attenuation_adjustment;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_NS_SUPPRESSION_PARAMS_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/wiener_filter.cc b/third_party/webrtc_aec3/src/modules/audio_processing/ns/wiener_filter.cc
new file mode 100644
index 0000000..e14b797
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/wiener_filter.cc
@@ -0,0 +1,120 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/ns/wiener_filter.h"
+
+#include <math.h>
+#include <stdlib.h>
+#include <string.h>
+#include <algorithm>
+
+#include "modules/audio_processing/ns/fast_math.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+WienerFilter::WienerFilter(const SuppressionParams& suppression_params)
+    : suppression_params_(suppression_params) {
+  filter_.fill(1.f);
+  initial_spectral_estimate_.fill(0.f);
+  spectrum_prev_process_.fill(0.f);
+}
+
+void WienerFilter::Update(
+    int32_t num_analyzed_frames,
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> noise_spectrum,
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> prev_noise_spectrum,
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> parametric_noise_spectrum,
+    rtc::ArrayView<const float, kFftSizeBy2Plus1> signal_spectrum) {
+  for (size_t i = 0; i < kFftSizeBy2Plus1; ++i) {
+    // Previous estimate based on previous frame with gain filter.
+    float prev_tsa = spectrum_prev_process_[i] /
+                     (prev_noise_spectrum[i] + 0.0001f) * filter_[i];
+
+    // Current estimate.
+    float current_tsa;
+    if (signal_spectrum[i] > noise_spectrum[i]) {
+      current_tsa = signal_spectrum[i] / (noise_spectrum[i] + 0.0001f) - 1.f;
+    } else {
+      current_tsa = 0.f;
+    }
+
+    // Directed decision estimate is sum of two terms: current estimate and
+    // previous estimate.
+    float snr_prior = 0.98f * prev_tsa + (1.f - 0.98f) * current_tsa;
+    filter_[i] =
+        snr_prior / (suppression_params_.over_subtraction_factor + snr_prior);
+    filter_[i] = std::max(std::min(filter_[i], 1.f),
+                          suppression_params_.minimum_attenuating_gain);
+  }
+
+  if (num_analyzed_frames < kShortStartupPhaseBlocks) {
+    for (size_t i = 0; i < kFftSizeBy2Plus1; ++i) {
+      initial_spectral_estimate_[i] += signal_spectrum[i];
+      float filter_initial = initial_spectral_estimate_[i] -
+                             suppression_params_.over_subtraction_factor *
+                                 parametric_noise_spectrum[i];
+      filter_initial /= initial_spectral_estimate_[i] + 0.0001f;
+
+      filter_initial = std::max(std::min(filter_initial, 1.f),
+                                suppression_params_.minimum_attenuating_gain);
+
+      // Weight the two suppression filters.
+      constexpr float kOnyByShortStartupPhaseBlocks =
+          1.f / kShortStartupPhaseBlocks;
+      filter_initial *= kShortStartupPhaseBlocks - num_analyzed_frames;
+      filter_[i] *= num_analyzed_frames;
+      filter_[i] += filter_initial;
+      filter_[i] *= kOnyByShortStartupPhaseBlocks;
+    }
+  }
+
+  std::copy(signal_spectrum.begin(), signal_spectrum.end(),
+            spectrum_prev_process_.begin());
+}
+
+float WienerFilter::ComputeOverallScalingFactor(
+    int32_t num_analyzed_frames,
+    float prior_speech_probability,
+    float energy_before_filtering,
+    float energy_after_filtering) const {
+  if (!suppression_params_.use_attenuation_adjustment ||
+      num_analyzed_frames <= kLongStartupPhaseBlocks) {
+    return 1.f;
+  }
+
+  float gain = SqrtFastApproximation(energy_after_filtering /
+                                     (energy_before_filtering + 1.f));
+
+  // Scaling for new version. Threshold in final energy gain factor calculation.
+  constexpr float kBLim = 0.5f;
+  float scale_factor1 = 1.f;
+  if (gain > kBLim) {
+    scale_factor1 = 1.f + 1.3f * (gain - kBLim);
+    if (gain * scale_factor1 > 1.f) {
+      scale_factor1 = 1.f / gain;
+    }
+  }
+
+  float scale_factor2 = 1.f;
+  if (gain < kBLim) {
+    // Do not reduce scale too much for pause regions: attenuation here should
+    // be controlled by flooring.
+    gain = std::max(gain, suppression_params_.minimum_attenuating_gain);
+    scale_factor2 = 1.f - 0.3f * (kBLim - gain);
+  }
+
+  // Combine both scales with speech/noise prob: note prior
+  // (prior_speech_probability) is not frequency dependent.
+  return prior_speech_probability * scale_factor1 +
+         (1.f - prior_speech_probability) * scale_factor2;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/ns/wiener_filter.h b/third_party/webrtc_aec3/src/modules/audio_processing/ns/wiener_filter.h
new file mode 100644
index 0000000..b55c5dc
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/ns/wiener_filter.h
@@ -0,0 +1,57 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_NS_WIENER_FILTER_H_
+#define MODULES_AUDIO_PROCESSING_NS_WIENER_FILTER_H_
+
+#include <array>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/ns/ns_common.h"
+#include "modules/audio_processing/ns/suppression_params.h"
+
+namespace webrtc {
+
+// Estimates a Wiener-filter based frequency domain noise reduction filter.
+class WienerFilter {
+ public:
+  explicit WienerFilter(const SuppressionParams& suppression_params);
+  WienerFilter(const WienerFilter&) = delete;
+  WienerFilter& operator=(const WienerFilter&) = delete;
+
+  // Updates the filter estimate.
+  void Update(
+      int32_t num_analyzed_frames,
+      rtc::ArrayView<const float, kFftSizeBy2Plus1> noise_spectrum,
+      rtc::ArrayView<const float, kFftSizeBy2Plus1> prev_noise_spectrum,
+      rtc::ArrayView<const float, kFftSizeBy2Plus1> parametric_noise_spectrum,
+      rtc::ArrayView<const float, kFftSizeBy2Plus1> signal_spectrum);
+
+  // Compute an overall gain scaling factor.
+  float ComputeOverallScalingFactor(int32_t num_analyzed_frames,
+                                    float prior_speech_probability,
+                                    float energy_before_filtering,
+                                    float energy_after_filtering) const;
+
+  // Returns the filter.
+  rtc::ArrayView<const float, kFftSizeBy2Plus1> get_filter() const {
+    return filter_;
+  }
+
+ private:
+  const SuppressionParams& suppression_params_;
+  std::array<float, kFftSizeBy2Plus1> spectrum_prev_process_;
+  std::array<float, kFftSizeBy2Plus1> initial_spectral_estimate_;
+  std::array<float, kFftSizeBy2Plus1> filter_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_NS_WIENER_FILTER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/residual_echo_detector.cc b/third_party/webrtc_aec3/src/modules/audio_processing/residual_echo_detector.cc
new file mode 100644
index 0000000..6188883
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/residual_echo_detector.cc
@@ -0,0 +1,215 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/residual_echo_detector.h"
+
+#include <algorithm>
+#include <numeric>
+
+#include "absl/types/optional.h"
+#include "modules/audio_processing/audio_buffer.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/atomic_ops.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+#include "system_wrappers/include/metrics.h"
+
+namespace {
+
+float Power(rtc::ArrayView<const float> input) {
+  if (input.empty()) {
+    return 0.f;
+  }
+  return std::inner_product(input.begin(), input.end(), input.begin(), 0.f) /
+         input.size();
+}
+
+constexpr size_t kLookbackFrames = 650;
+// TODO(ivoc): Verify the size of this buffer.
+constexpr size_t kRenderBufferSize = 30;
+constexpr float kAlpha = 0.001f;
+// 10 seconds of data, updated every 10 ms.
+constexpr size_t kAggregationBufferSize = 10 * 100;
+
+}  // namespace
+
+namespace webrtc {
+
+int ResidualEchoDetector::instance_count_ = 0;
+
+ResidualEchoDetector::ResidualEchoDetector()
+    : data_dumper_(
+          new ApmDataDumper(rtc::AtomicOps::Increment(&instance_count_))),
+      render_buffer_(kRenderBufferSize),
+      render_power_(kLookbackFrames),
+      render_power_mean_(kLookbackFrames),
+      render_power_std_dev_(kLookbackFrames),
+      covariances_(kLookbackFrames),
+      recent_likelihood_max_(kAggregationBufferSize) {}
+
+ResidualEchoDetector::~ResidualEchoDetector() = default;
+
+void ResidualEchoDetector::AnalyzeRenderAudio(
+    rtc::ArrayView<const float> render_audio) {
+  // Dump debug data assuming 48 kHz sample rate (if this assumption is not
+  // valid the dumped audio will need to be converted offline accordingly).
+  data_dumper_->DumpWav("ed_render", render_audio.size(), render_audio.data(),
+                        48000, 1);
+
+  if (render_buffer_.Size() == 0) {
+    frames_since_zero_buffer_size_ = 0;
+  } else if (frames_since_zero_buffer_size_ >= kRenderBufferSize) {
+    // This can happen in a few cases: at the start of a call, due to a glitch
+    // or due to clock drift. The excess capture value will be ignored.
+    // TODO(ivoc): Include how often this happens in APM stats.
+    render_buffer_.Pop();
+    frames_since_zero_buffer_size_ = 0;
+  }
+  ++frames_since_zero_buffer_size_;
+  float power = Power(render_audio);
+  render_buffer_.Push(power);
+}
+
+void ResidualEchoDetector::AnalyzeCaptureAudio(
+    rtc::ArrayView<const float> capture_audio) {
+  // Dump debug data assuming 48 kHz sample rate (if this assumption is not
+  // valid the dumped audio will need to be converted offline accordingly).
+  data_dumper_->DumpWav("ed_capture", capture_audio.size(),
+                        capture_audio.data(), 48000, 1);
+
+  if (first_process_call_) {
+    // On the first process call (so the start of a call), we must flush the
+    // render buffer, otherwise the render data will be delayed.
+    render_buffer_.Clear();
+    first_process_call_ = false;
+  }
+
+  // Get the next render value.
+  const absl::optional<float> buffered_render_power = render_buffer_.Pop();
+  if (!buffered_render_power) {
+    // This can happen in a few cases: at the start of a call, due to a glitch
+    // or due to clock drift. The excess capture value will be ignored.
+    // TODO(ivoc): Include how often this happens in APM stats.
+    return;
+  }
+  // Update the render statistics, and store the statistics in circular buffers.
+  render_statistics_.Update(*buffered_render_power);
+  RTC_DCHECK_LT(next_insertion_index_, kLookbackFrames);
+  render_power_[next_insertion_index_] = *buffered_render_power;
+  render_power_mean_[next_insertion_index_] = render_statistics_.mean();
+  render_power_std_dev_[next_insertion_index_] =
+      render_statistics_.std_deviation();
+
+  // Get the next capture value, update capture statistics and add the relevant
+  // values to the buffers.
+  const float capture_power = Power(capture_audio);
+  capture_statistics_.Update(capture_power);
+  const float capture_mean = capture_statistics_.mean();
+  const float capture_std_deviation = capture_statistics_.std_deviation();
+
+  // Update the covariance values and determine the new echo likelihood.
+  echo_likelihood_ = 0.f;
+  size_t read_index = next_insertion_index_;
+
+  int best_delay = -1;
+  for (size_t delay = 0; delay < covariances_.size(); ++delay) {
+    RTC_DCHECK_LT(read_index, render_power_.size());
+    covariances_[delay].Update(capture_power, capture_mean,
+                               capture_std_deviation, render_power_[read_index],
+                               render_power_mean_[read_index],
+                               render_power_std_dev_[read_index]);
+    read_index = read_index > 0 ? read_index - 1 : kLookbackFrames - 1;
+
+    if (covariances_[delay].normalized_cross_correlation() > echo_likelihood_) {
+      echo_likelihood_ = covariances_[delay].normalized_cross_correlation();
+      best_delay = static_cast<int>(delay);
+    }
+  }
+  // This is a temporary log message to help find the underlying cause for echo
+  // likelihoods > 1.0.
+  // TODO(ivoc): Remove once the issue is resolved.
+  if (echo_likelihood_ > 1.1f) {
+    // Make sure we don't spam the log.
+    if (log_counter_ < 5 && best_delay != -1) {
+      size_t read_index = kLookbackFrames + next_insertion_index_ - best_delay;
+      if (read_index >= kLookbackFrames) {
+        read_index -= kLookbackFrames;
+      }
+      RTC_DCHECK_LT(read_index, render_power_.size());
+      RTC_LOG_F(LS_ERROR) << "Echo detector internal state: {"
+                             "Echo likelihood: "
+                          << echo_likelihood_ << ", Best Delay: " << best_delay
+                          << ", Covariance: "
+                          << covariances_[best_delay].covariance()
+                          << ", Last capture power: " << capture_power
+                          << ", Capture mean: " << capture_mean
+                          << ", Capture_standard deviation: "
+                          << capture_std_deviation << ", Last render power: "
+                          << render_power_[read_index]
+                          << ", Render mean: " << render_power_mean_[read_index]
+                          << ", Render standard deviation: "
+                          << render_power_std_dev_[read_index]
+                          << ", Reliability: " << reliability_ << "}";
+      log_counter_++;
+    }
+  }
+  RTC_DCHECK_LT(echo_likelihood_, 1.1f);
+
+  reliability_ = (1.0f - kAlpha) * reliability_ + kAlpha * 1.0f;
+  echo_likelihood_ *= reliability_;
+  // This is a temporary fix to prevent echo likelihood values > 1.0.
+  // TODO(ivoc): Find the root cause of this issue and fix it.
+  echo_likelihood_ = std::min(echo_likelihood_, 1.0f);
+  int echo_percentage = static_cast<int>(echo_likelihood_ * 100);
+  RTC_HISTOGRAM_COUNTS("WebRTC.Audio.ResidualEchoDetector.EchoLikelihood",
+                       echo_percentage, 0, 100, 100 /* number of bins */);
+
+  // Update the buffer of recent likelihood values.
+  recent_likelihood_max_.Update(echo_likelihood_);
+
+  // Update the next insertion index.
+  next_insertion_index_ = next_insertion_index_ < (kLookbackFrames - 1)
+                              ? next_insertion_index_ + 1
+                              : 0;
+}
+
+void ResidualEchoDetector::Initialize(int /*capture_sample_rate_hz*/,
+                                      int /*num_capture_channels*/,
+                                      int /*render_sample_rate_hz*/,
+                                      int /*num_render_channels*/) {
+  render_buffer_.Clear();
+  std::fill(render_power_.begin(), render_power_.end(), 0.f);
+  std::fill(render_power_mean_.begin(), render_power_mean_.end(), 0.f);
+  std::fill(render_power_std_dev_.begin(), render_power_std_dev_.end(), 0.f);
+  render_statistics_.Clear();
+  capture_statistics_.Clear();
+  recent_likelihood_max_.Clear();
+  for (auto& cov : covariances_) {
+    cov.Clear();
+  }
+  echo_likelihood_ = 0.f;
+  next_insertion_index_ = 0;
+  reliability_ = 0.f;
+}
+
+void EchoDetector::PackRenderAudioBuffer(AudioBuffer* audio,
+                                         std::vector<float>* packed_buffer) {
+  packed_buffer->clear();
+  packed_buffer->insert(packed_buffer->end(), audio->channels()[0],
+                        audio->channels()[0] + audio->num_frames());
+}
+
+EchoDetector::Metrics ResidualEchoDetector::GetMetrics() const {
+  EchoDetector::Metrics metrics;
+  metrics.echo_likelihood = echo_likelihood_;
+  metrics.echo_likelihood_recent_max = recent_likelihood_max_.max();
+  return metrics;
+}
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/residual_echo_detector.h b/third_party/webrtc_aec3/src/modules/audio_processing/residual_echo_detector.h
new file mode 100644
index 0000000..5d18ecb
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/residual_echo_detector.h
@@ -0,0 +1,90 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_RESIDUAL_ECHO_DETECTOR_H_
+#define MODULES_AUDIO_PROCESSING_RESIDUAL_ECHO_DETECTOR_H_
+
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/echo_detector/circular_buffer.h"
+#include "modules/audio_processing/echo_detector/mean_variance_estimator.h"
+#include "modules/audio_processing/echo_detector/moving_max.h"
+#include "modules/audio_processing/echo_detector/normalized_covariance_estimator.h"
+#include "modules/audio_processing/include/audio_processing.h"
+
+namespace webrtc {
+
+class ApmDataDumper;
+class AudioBuffer;
+
+class ResidualEchoDetector : public EchoDetector {
+ public:
+  ResidualEchoDetector();
+  ~ResidualEchoDetector() override;
+
+  // This function should be called while holding the render lock.
+  void AnalyzeRenderAudio(rtc::ArrayView<const float> render_audio) override;
+
+  // This function should be called while holding the capture lock.
+  void AnalyzeCaptureAudio(rtc::ArrayView<const float> capture_audio) override;
+
+  // This function should be called while holding the capture lock.
+  void Initialize(int capture_sample_rate_hz,
+                  int num_capture_channels,
+                  int render_sample_rate_hz,
+                  int num_render_channels) override;
+
+  // This function is for testing purposes only.
+  void SetReliabilityForTest(float value) { reliability_ = value; }
+
+  // This function should be called while holding the capture lock.
+  EchoDetector::Metrics GetMetrics() const override;
+
+ private:
+  static int instance_count_;
+  std::unique_ptr<ApmDataDumper> data_dumper_;
+  // Keep track if the |Process| function has been previously called.
+  bool first_process_call_ = true;
+  // Buffer for storing the power of incoming farend buffers. This is needed for
+  // cases where calls to BufferFarend and Process are jittery.
+  CircularBuffer render_buffer_;
+  // Count how long ago it was that the size of |render_buffer_| was zero. This
+  // value is also reset to zero when clock drift is detected and a value from
+  // the renderbuffer is discarded, even though the buffer is not actually zero
+  // at that point. This is done to avoid repeatedly removing elements in this
+  // situation.
+  size_t frames_since_zero_buffer_size_ = 0;
+
+  // Circular buffers containing delayed versions of the power, mean and
+  // standard deviation, for calculating the delayed covariance values.
+  std::vector<float> render_power_;
+  std::vector<float> render_power_mean_;
+  std::vector<float> render_power_std_dev_;
+  // Covariance estimates for different delay values.
+  std::vector<NormalizedCovarianceEstimator> covariances_;
+  // Index where next element should be inserted in all of the above circular
+  // buffers.
+  size_t next_insertion_index_ = 0;
+
+  MeanVarianceEstimator render_statistics_;
+  MeanVarianceEstimator capture_statistics_;
+  // Current echo likelihood.
+  float echo_likelihood_ = 0.f;
+  // Reliability of the current likelihood.
+  float reliability_ = 0.f;
+  MovingMax recent_likelihood_max_;
+
+  int log_counter_ = 0;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_RESIDUAL_ECHO_DETECTOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/splitting_filter.cc b/third_party/webrtc_aec3/src/modules/audio_processing/splitting_filter.cc
new file mode 100644
index 0000000..d47090b
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/splitting_filter.cc
@@ -0,0 +1,144 @@
+/*
+ *  Copyright (c) 2014 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/splitting_filter.h"
+
+#include <array>
+
+#include "api/array_view.h"
+#include "common_audio/channel_buffer.h"
+#include "common_audio/signal_processing/include/signal_processing_library.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+
+constexpr size_t kSamplesPerBand = 160;
+constexpr size_t kTwoBandFilterSamplesPerFrame = 320;
+
+}  // namespace
+
+SplittingFilter::SplittingFilter(size_t num_channels,
+                                 size_t num_bands,
+                                 size_t num_frames)
+    : num_bands_(num_bands),
+      two_bands_states_(num_bands_ == 2 ? num_channels : 0),
+      three_band_filter_banks_(num_bands_ == 3 ? num_channels : 0) {
+  RTC_CHECK(num_bands_ == 2 || num_bands_ == 3);
+}
+
+SplittingFilter::~SplittingFilter() = default;
+
+void SplittingFilter::Analysis(const ChannelBuffer<float>* data,
+                               ChannelBuffer<float>* bands) {
+  RTC_DCHECK_EQ(num_bands_, bands->num_bands());
+  RTC_DCHECK_EQ(data->num_channels(), bands->num_channels());
+  RTC_DCHECK_EQ(data->num_frames(),
+                bands->num_frames_per_band() * bands->num_bands());
+  if (bands->num_bands() == 2) {
+    TwoBandsAnalysis(data, bands);
+  } else if (bands->num_bands() == 3) {
+    ThreeBandsAnalysis(data, bands);
+  }
+}
+
+void SplittingFilter::Synthesis(const ChannelBuffer<float>* bands,
+                                ChannelBuffer<float>* data) {
+  RTC_DCHECK_EQ(num_bands_, bands->num_bands());
+  RTC_DCHECK_EQ(data->num_channels(), bands->num_channels());
+  RTC_DCHECK_EQ(data->num_frames(),
+                bands->num_frames_per_band() * bands->num_bands());
+  if (bands->num_bands() == 2) {
+    TwoBandsSynthesis(bands, data);
+  } else if (bands->num_bands() == 3) {
+    ThreeBandsSynthesis(bands, data);
+  }
+}
+
+void SplittingFilter::TwoBandsAnalysis(const ChannelBuffer<float>* data,
+                                       ChannelBuffer<float>* bands) {
+  RTC_DCHECK_EQ(two_bands_states_.size(), data->num_channels());
+  RTC_DCHECK_EQ(data->num_frames(), kTwoBandFilterSamplesPerFrame);
+
+  for (size_t i = 0; i < two_bands_states_.size(); ++i) {
+    std::array<std::array<int16_t, kSamplesPerBand>, 2> bands16;
+    std::array<int16_t, kTwoBandFilterSamplesPerFrame> full_band16;
+    FloatS16ToS16(data->channels(0)[i], full_band16.size(), full_band16.data());
+    WebRtcSpl_AnalysisQMF(full_band16.data(), data->num_frames(),
+                          bands16[0].data(), bands16[1].data(),
+                          two_bands_states_[i].analysis_state1,
+                          two_bands_states_[i].analysis_state2);
+    S16ToFloatS16(bands16[0].data(), bands16[0].size(), bands->channels(0)[i]);
+    S16ToFloatS16(bands16[1].data(), bands16[1].size(), bands->channels(1)[i]);
+  }
+}
+
+void SplittingFilter::TwoBandsSynthesis(const ChannelBuffer<float>* bands,
+                                        ChannelBuffer<float>* data) {
+  RTC_DCHECK_LE(data->num_channels(), two_bands_states_.size());
+  RTC_DCHECK_EQ(data->num_frames(), kTwoBandFilterSamplesPerFrame);
+  for (size_t i = 0; i < data->num_channels(); ++i) {
+    std::array<std::array<int16_t, kSamplesPerBand>, 2> bands16;
+    std::array<int16_t, kTwoBandFilterSamplesPerFrame> full_band16;
+    FloatS16ToS16(bands->channels(0)[i], bands16[0].size(), bands16[0].data());
+    FloatS16ToS16(bands->channels(1)[i], bands16[1].size(), bands16[1].data());
+    WebRtcSpl_SynthesisQMF(bands16[0].data(), bands16[1].data(),
+                           bands->num_frames_per_band(), full_band16.data(),
+                           two_bands_states_[i].synthesis_state1,
+                           two_bands_states_[i].synthesis_state2);
+    S16ToFloatS16(full_band16.data(), full_band16.size(), data->channels(0)[i]);
+  }
+}
+
+void SplittingFilter::ThreeBandsAnalysis(const ChannelBuffer<float>* data,
+                                         ChannelBuffer<float>* bands) {
+  RTC_DCHECK_EQ(three_band_filter_banks_.size(), data->num_channels());
+  RTC_DCHECK_LE(data->num_channels(), three_band_filter_banks_.size());
+  RTC_DCHECK_LE(data->num_channels(), bands->num_channels());
+  RTC_DCHECK_EQ(data->num_frames(), ThreeBandFilterBank::kFullBandSize);
+  RTC_DCHECK_EQ(bands->num_frames(), ThreeBandFilterBank::kFullBandSize);
+  RTC_DCHECK_EQ(bands->num_bands(), ThreeBandFilterBank::kNumBands);
+  RTC_DCHECK_EQ(bands->num_frames_per_band(),
+                ThreeBandFilterBank::kSplitBandSize);
+
+  for (size_t i = 0; i < three_band_filter_banks_.size(); ++i) {
+    three_band_filter_banks_[i].Analysis(
+        rtc::ArrayView<const float, ThreeBandFilterBank::kFullBandSize>(
+            data->channels_view()[i].data(),
+            ThreeBandFilterBank::kFullBandSize),
+        rtc::ArrayView<const rtc::ArrayView<float>,
+                       ThreeBandFilterBank::kNumBands>(
+            bands->bands_view(i).data(), ThreeBandFilterBank::kNumBands));
+  }
+}
+
+void SplittingFilter::ThreeBandsSynthesis(const ChannelBuffer<float>* bands,
+                                          ChannelBuffer<float>* data) {
+  RTC_DCHECK_LE(data->num_channels(), three_band_filter_banks_.size());
+  RTC_DCHECK_LE(data->num_channels(), bands->num_channels());
+  RTC_DCHECK_LE(data->num_channels(), three_band_filter_banks_.size());
+  RTC_DCHECK_EQ(data->num_frames(), ThreeBandFilterBank::kFullBandSize);
+  RTC_DCHECK_EQ(bands->num_frames(), ThreeBandFilterBank::kFullBandSize);
+  RTC_DCHECK_EQ(bands->num_bands(), ThreeBandFilterBank::kNumBands);
+  RTC_DCHECK_EQ(bands->num_frames_per_band(),
+                ThreeBandFilterBank::kSplitBandSize);
+
+  for (size_t i = 0; i < data->num_channels(); ++i) {
+    three_band_filter_banks_[i].Synthesis(
+        rtc::ArrayView<const rtc::ArrayView<float>,
+                       ThreeBandFilterBank::kNumBands>(
+            bands->bands_view(i).data(), ThreeBandFilterBank::kNumBands),
+        rtc::ArrayView<float, ThreeBandFilterBank::kFullBandSize>(
+            data->channels_view()[i].data(),
+            ThreeBandFilterBank::kFullBandSize));
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/splitting_filter.h b/third_party/webrtc_aec3/src/modules/audio_processing/splitting_filter.h
new file mode 100644
index 0000000..e578dd0
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/splitting_filter.h
@@ -0,0 +1,72 @@
+/*
+ *  Copyright (c) 2014 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_SPLITTING_FILTER_H_
+#define MODULES_AUDIO_PROCESSING_SPLITTING_FILTER_H_
+
+#include <cstring>
+#include <memory>
+#include <vector>
+
+#include "common_audio/channel_buffer.h"
+#include "modules/audio_processing/three_band_filter_bank.h"
+
+namespace webrtc {
+
+struct TwoBandsStates {
+  TwoBandsStates() {
+    memset(analysis_state1, 0, sizeof(analysis_state1));
+    memset(analysis_state2, 0, sizeof(analysis_state2));
+    memset(synthesis_state1, 0, sizeof(synthesis_state1));
+    memset(synthesis_state2, 0, sizeof(synthesis_state2));
+  }
+
+  static const int kStateSize = 6;
+  int analysis_state1[kStateSize];
+  int analysis_state2[kStateSize];
+  int synthesis_state1[kStateSize];
+  int synthesis_state2[kStateSize];
+};
+
+// Splitting filter which is able to split into and merge from 2 or 3 frequency
+// bands. The number of channels needs to be provided at construction time.
+//
+// For each block, Analysis() is called to split into bands and then Synthesis()
+// to merge these bands again. The input and output signals are contained in
+// ChannelBuffers and for the different bands an array of ChannelBuffers is
+// used.
+class SplittingFilter {
+ public:
+  SplittingFilter(size_t num_channels, size_t num_bands, size_t num_frames);
+  ~SplittingFilter();
+
+  void Analysis(const ChannelBuffer<float>* data, ChannelBuffer<float>* bands);
+  void Synthesis(const ChannelBuffer<float>* bands, ChannelBuffer<float>* data);
+
+ private:
+  // Two-band analysis and synthesis work for 640 samples or less.
+  void TwoBandsAnalysis(const ChannelBuffer<float>* data,
+                        ChannelBuffer<float>* bands);
+  void TwoBandsSynthesis(const ChannelBuffer<float>* bands,
+                         ChannelBuffer<float>* data);
+  void ThreeBandsAnalysis(const ChannelBuffer<float>* data,
+                          ChannelBuffer<float>* bands);
+  void ThreeBandsSynthesis(const ChannelBuffer<float>* bands,
+                           ChannelBuffer<float>* data);
+  void InitBuffers();
+
+  const size_t num_bands_;
+  std::vector<TwoBandsStates> two_bands_states_;
+  std::vector<ThreeBandFilterBank> three_band_filter_banks_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_SPLITTING_FILTER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/three_band_filter_bank.cc b/third_party/webrtc_aec3/src/modules/audio_processing/three_band_filter_bank.cc
new file mode 100644
index 0000000..2a7d272
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/three_band_filter_bank.cc
@@ -0,0 +1,276 @@
+/*
+ *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// An implementation of a 3-band FIR filter-bank with DCT modulation, similar to
+// the proposed in "Multirate Signal Processing for Communication Systems" by
+// Fredric J Harris.
+//
+// The idea is to take a heterodyne system and change the order of the
+// components to get something which is efficient to implement digitally.
+//
+// It is possible to separate the filter using the noble identity as follows:
+//
+// H(z) = H0(z^3) + z^-1 * H1(z^3) + z^-2 * H2(z^3)
+//
+// This is used in the analysis stage to first downsample serial to parallel
+// and then filter each branch with one of these polyphase decompositions of the
+// lowpass prototype. Because each filter is only a modulation of the prototype,
+// it is enough to multiply each coefficient by the respective cosine value to
+// shift it to the desired band. But because the cosine period is 12 samples,
+// it requires separating the prototype even further using the noble identity.
+// After filtering and modulating for each band, the output of all filters is
+// accumulated to get the downsampled bands.
+//
+// A similar logic can be applied to the synthesis stage.
+
+#include "modules/audio_processing/three_band_filter_bank.h"
+
+#include <array>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+
+// Factors to take into account when choosing |kFilterSize|:
+//   1. Higher |kFilterSize|, means faster transition, which ensures less
+//      aliasing. This is especially important when there is non-linear
+//      processing between the splitting and merging.
+//   2. The delay that this filter bank introduces is
+//      |kNumBands| * |kSparsity| * |kFilterSize| / 2, so it increases linearly
+//      with |kFilterSize|.
+//   3. The computation complexity also increases linearly with |kFilterSize|.
+
+// The Matlab code to generate these |kFilterCoeffs| is:
+//
+// N = kNumBands * kSparsity * kFilterSize - 1;
+// h = fir1(N, 1 / (2 * kNumBands), kaiser(N + 1, 3.5));
+// reshape(h, kNumBands * kSparsity, kFilterSize);
+//
+// The code below uses the values of kFilterSize, kNumBands and kSparsity
+// specified in the header.
+
+// Because the total bandwidth of the lower and higher band is double the middle
+// one (because of the spectrum parity), the low-pass prototype is half the
+// bandwidth of 1 / (2 * |kNumBands|) and is then shifted with cosine modulation
+// to the right places.
+// A Kaiser window is used because of its flexibility and the alpha is set to
+// 3.5, since that sets a stop band attenuation of 40dB ensuring a fast
+// transition.
+
+constexpr int kSubSampling = ThreeBandFilterBank::kNumBands;
+constexpr int kDctSize = ThreeBandFilterBank::kNumBands;
+static_assert(ThreeBandFilterBank::kNumBands *
+                      ThreeBandFilterBank::kSplitBandSize ==
+                  ThreeBandFilterBank::kFullBandSize,
+              "The full band must be split in equally sized subbands");
+
+const float
+    kFilterCoeffs[ThreeBandFilterBank::kNumNonZeroFilters][kFilterSize] = {
+        {-0.00047749f, -0.00496888f, +0.16547118f, +0.00425496f},
+        {-0.00173287f, -0.01585778f, +0.14989004f, +0.00994113f},
+        {-0.00304815f, -0.02536082f, +0.12154542f, +0.01157993f},
+        {-0.00346946f, -0.02587886f, +0.04760441f, +0.00607594f},
+        {-0.00154717f, -0.01136076f, +0.01387458f, +0.00186353f},
+        {+0.00186353f, +0.01387458f, -0.01136076f, -0.00154717f},
+        {+0.00607594f, +0.04760441f, -0.02587886f, -0.00346946f},
+        {+0.00983212f, +0.08543175f, -0.02982767f, -0.00383509f},
+        {+0.00994113f, +0.14989004f, -0.01585778f, -0.00173287f},
+        {+0.00425496f, +0.16547118f, -0.00496888f, -0.00047749f}};
+
+constexpr int kZeroFilterIndex1 = 3;
+constexpr int kZeroFilterIndex2 = 9;
+
+const float kDctModulation[ThreeBandFilterBank::kNumNonZeroFilters][kDctSize] =
+    {{2.f, 2.f, 2.f},
+     {1.73205077f, 0.f, -1.73205077f},
+     {1.f, -2.f, 1.f},
+     {-1.f, 2.f, -1.f},
+     {-1.73205077f, 0.f, 1.73205077f},
+     {-2.f, -2.f, -2.f},
+     {-1.73205077f, 0.f, 1.73205077f},
+     {-1.f, 2.f, -1.f},
+     {1.f, -2.f, 1.f},
+     {1.73205077f, 0.f, -1.73205077f}};
+
+// Filters the input signal |in| with the filter |filter| using a shift by
+// |in_shift|, taking into account the previous state.
+void FilterCore(
+    rtc::ArrayView<const float, kFilterSize> filter,
+    rtc::ArrayView<const float, ThreeBandFilterBank::kSplitBandSize> in,
+    const int in_shift,
+    rtc::ArrayView<float, ThreeBandFilterBank::kSplitBandSize> out,
+    rtc::ArrayView<float, kMemorySize> state) {
+  constexpr int kMaxInShift = (kStride - 1);
+  RTC_DCHECK_GE(in_shift, 0);
+  RTC_DCHECK_LE(in_shift, kMaxInShift);
+  std::fill(out.begin(), out.end(), 0.f);
+
+  for (int k = 0; k < in_shift; ++k) {
+    for (int i = 0, j = kMemorySize + k - in_shift; i < kFilterSize;
+         ++i, j -= kStride) {
+      out[k] += state[j] * filter[i];
+    }
+  }
+
+  for (int k = in_shift, shift = 0; k < kFilterSize * kStride; ++k, ++shift) {
+    RTC_DCHECK_GE(shift, 0);
+    const int loop_limit = std::min(kFilterSize, 1 + (shift >> kStrideLog2));
+    for (int i = 0, j = shift; i < loop_limit; ++i, j -= kStride) {
+      out[k] += in[j] * filter[i];
+    }
+    for (int i = loop_limit, j = kMemorySize + shift - loop_limit * kStride;
+         i < kFilterSize; ++i, j -= kStride) {
+      out[k] += state[j] * filter[i];
+    }
+  }
+
+  for (int k = kFilterSize * kStride, shift = kFilterSize * kStride - in_shift;
+       k < ThreeBandFilterBank::kSplitBandSize; ++k, ++shift) {
+    for (int i = 0, j = shift; i < kFilterSize; ++i, j -= kStride) {
+      out[k] += in[j] * filter[i];
+    }
+  }
+
+  // Update current state.
+  std::copy(in.begin() + ThreeBandFilterBank::kSplitBandSize - kMemorySize,
+            in.end(), state.begin());
+}
+
+}  // namespace
+
+// Because the low-pass filter prototype has half bandwidth it is possible to
+// use a DCT to shift it in both directions at the same time, to the center
+// frequencies [1 / 12, 3 / 12, 5 / 12].
+ThreeBandFilterBank::ThreeBandFilterBank() {
+  RTC_DCHECK_EQ(state_analysis_.size(), kNumNonZeroFilters);
+  RTC_DCHECK_EQ(state_synthesis_.size(), kNumNonZeroFilters);
+  for (int k = 0; k < kNumNonZeroFilters; ++k) {
+    RTC_DCHECK_EQ(state_analysis_[k].size(), kMemorySize);
+    RTC_DCHECK_EQ(state_synthesis_[k].size(), kMemorySize);
+
+    state_analysis_[k].fill(0.f);
+    state_synthesis_[k].fill(0.f);
+  }
+}
+
+ThreeBandFilterBank::~ThreeBandFilterBank() = default;
+
+// The analysis can be separated in these steps:
+//   1. Serial to parallel downsampling by a factor of |kNumBands|.
+//   2. Filtering of |kSparsity| different delayed signals with polyphase
+//      decomposition of the low-pass prototype filter and upsampled by a factor
+//      of |kSparsity|.
+//   3. Modulating with cosines and accumulating to get the desired band.
+void ThreeBandFilterBank::Analysis(
+    rtc::ArrayView<const float, kFullBandSize> in,
+    rtc::ArrayView<const rtc::ArrayView<float>, ThreeBandFilterBank::kNumBands>
+        out) {
+  // Initialize the output to zero.
+  for (int band = 0; band < ThreeBandFilterBank::kNumBands; ++band) {
+    RTC_DCHECK_EQ(out[band].size(), kSplitBandSize);
+    std::fill(out[band].begin(), out[band].end(), 0);
+  }
+
+  for (int downsampling_index = 0; downsampling_index < kSubSampling;
+       ++downsampling_index) {
+    // Downsample to form the filter input.
+    std::array<float, kSplitBandSize> in_subsampled;
+    for (int k = 0; k < kSplitBandSize; ++k) {
+      in_subsampled[k] =
+          in[(kSubSampling - 1) - downsampling_index + kSubSampling * k];
+    }
+
+    for (int in_shift = 0; in_shift < kStride; ++in_shift) {
+      // Choose filter, skip zero filters.
+      const int index = downsampling_index + in_shift * kSubSampling;
+      if (index == kZeroFilterIndex1 || index == kZeroFilterIndex2) {
+        continue;
+      }
+      const int filter_index =
+          index < kZeroFilterIndex1
+              ? index
+              : (index < kZeroFilterIndex2 ? index - 1 : index - 2);
+
+      rtc::ArrayView<const float, kFilterSize> filter(
+          kFilterCoeffs[filter_index]);
+      rtc::ArrayView<const float, kDctSize> dct_modulation(
+          kDctModulation[filter_index]);
+      rtc::ArrayView<float, kMemorySize> state(state_analysis_[filter_index]);
+
+      // Filter.
+      std::array<float, kSplitBandSize> out_subsampled;
+      FilterCore(filter, in_subsampled, in_shift, out_subsampled, state);
+
+      // Band and modulate the output.
+      for (int band = 0; band < ThreeBandFilterBank::kNumBands; ++band) {
+        for (int n = 0; n < kSplitBandSize; ++n) {
+          out[band][n] += dct_modulation[band] * out_subsampled[n];
+        }
+      }
+    }
+  }
+}
+
+// The synthesis can be separated in these steps:
+//   1. Modulating with cosines.
+//   2. Filtering each one with a polyphase decomposition of the low-pass
+//      prototype filter upsampled by a factor of |kSparsity| and accumulating
+//      |kSparsity| signals with different delays.
+//   3. Parallel to serial upsampling by a factor of |kNumBands|.
+void ThreeBandFilterBank::Synthesis(
+    rtc::ArrayView<const rtc::ArrayView<float>, ThreeBandFilterBank::kNumBands>
+        in,
+    rtc::ArrayView<float, kFullBandSize> out) {
+  std::fill(out.begin(), out.end(), 0);
+  for (int upsampling_index = 0; upsampling_index < kSubSampling;
+       ++upsampling_index) {
+    for (int in_shift = 0; in_shift < kStride; ++in_shift) {
+      // Choose filter, skip zero filters.
+      const int index = upsampling_index + in_shift * kSubSampling;
+      if (index == kZeroFilterIndex1 || index == kZeroFilterIndex2) {
+        continue;
+      }
+      const int filter_index =
+          index < kZeroFilterIndex1
+              ? index
+              : (index < kZeroFilterIndex2 ? index - 1 : index - 2);
+
+      rtc::ArrayView<const float, kFilterSize> filter(
+          kFilterCoeffs[filter_index]);
+      rtc::ArrayView<const float, kDctSize> dct_modulation(
+          kDctModulation[filter_index]);
+      rtc::ArrayView<float, kMemorySize> state(state_synthesis_[filter_index]);
+
+      // Prepare filter input by modulating the banded input.
+      std::array<float, kSplitBandSize> in_subsampled;
+      std::fill(in_subsampled.begin(), in_subsampled.end(), 0.f);
+      for (int band = 0; band < ThreeBandFilterBank::kNumBands; ++band) {
+        RTC_DCHECK_EQ(in[band].size(), kSplitBandSize);
+        for (int n = 0; n < kSplitBandSize; ++n) {
+          in_subsampled[n] += dct_modulation[band] * in[band][n];
+        }
+      }
+
+      // Filter.
+      std::array<float, kSplitBandSize> out_subsampled;
+      FilterCore(filter, in_subsampled, in_shift, out_subsampled, state);
+
+      // Upsample.
+      constexpr float kUpsamplingScaling = kSubSampling;
+      for (int k = 0; k < kSplitBandSize; ++k) {
+        out[upsampling_index + kSubSampling * k] +=
+            kUpsamplingScaling * out_subsampled[k];
+      }
+    }
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/three_band_filter_bank.h b/third_party/webrtc_aec3/src/modules/audio_processing/three_band_filter_bank.h
new file mode 100644
index 0000000..e6346de
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/three_band_filter_bank.h
@@ -0,0 +1,77 @@
+/*
+ *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_THREE_BAND_FILTER_BANK_H_
+#define MODULES_AUDIO_PROCESSING_THREE_BAND_FILTER_BANK_H_
+
+#include <array>
+#include <cstring>
+#include <memory>
+#include <vector>
+
+#include "api/array_view.h"
+
+namespace webrtc {
+
+constexpr int kSparsity = 4;
+constexpr int kStrideLog2 = 2;
+constexpr int kStride = 1 << kStrideLog2;
+constexpr int kNumZeroFilters = 2;
+constexpr int kFilterSize = 4;
+constexpr int kMemorySize = kFilterSize * kStride - 1;
+static_assert(kMemorySize == 15,
+              "The memory size must be sufficient to provide memory for the "
+              "shifted filters");
+
+// An implementation of a 3-band FIR filter-bank with DCT modulation, similar to
+// the proposed in "Multirate Signal Processing for Communication Systems" by
+// Fredric J Harris.
+// The low-pass filter prototype has these characteristics:
+// * Pass-band ripple = 0.3dB
+// * Pass-band frequency = 0.147 (7kHz at 48kHz)
+// * Stop-band attenuation = 40dB
+// * Stop-band frequency = 0.192 (9.2kHz at 48kHz)
+// * Delay = 24 samples (500us at 48kHz)
+// * Linear phase
+// This filter bank does not satisfy perfect reconstruction. The SNR after
+// analysis and synthesis (with no processing in between) is approximately 9.5dB
+// depending on the input signal after compensating for the delay.
+class ThreeBandFilterBank final {
+ public:
+  static const int kNumBands = 3;
+  static const int kFullBandSize = 480;
+  static const int kSplitBandSize =
+      ThreeBandFilterBank::kFullBandSize / ThreeBandFilterBank::kNumBands;
+  static const int kNumNonZeroFilters =
+      kSparsity * ThreeBandFilterBank::kNumBands - kNumZeroFilters;
+
+  ThreeBandFilterBank();
+  ~ThreeBandFilterBank();
+
+  // Splits |in| of size kFullBandSize into 3 downsampled frequency bands in
+  // |out|, each of size 160.
+  void Analysis(rtc::ArrayView<const float, kFullBandSize> in,
+                rtc::ArrayView<const rtc::ArrayView<float>, kNumBands> out);
+
+  // Merges the 3 downsampled frequency bands in |in|, each of size 160, into
+  // |out|, which is of size kFullBandSize.
+  void Synthesis(rtc::ArrayView<const rtc::ArrayView<float>, kNumBands> in,
+                 rtc::ArrayView<float, kFullBandSize> out);
+
+ private:
+  std::array<std::array<float, kMemorySize>, kNumNonZeroFilters>
+      state_analysis_;
+  std::array<std::array<float, kMemorySize>, kNumNonZeroFilters>
+      state_synthesis_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_THREE_BAND_FILTER_BANK_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/utility/BUILD.gn b/third_party/webrtc_aec3/src/modules/audio_processing/utility/BUILD.gn
new file mode 100644
index 0000000..437b544
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/utility/BUILD.gn
@@ -0,0 +1,81 @@
+# Copyright (c) 2014 The WebRTC project authors. All Rights Reserved.
+#
+# Use of this source code is governed by a BSD-style license
+# that can be found in the LICENSE file in the root of the source
+# tree. An additional intellectual property rights grant can be found
+# in the file PATENTS.  All contributing project authors may
+# be found in the AUTHORS file in the root of the source tree.
+
+import("../../../webrtc.gni")
+
+rtc_library("cascaded_biquad_filter") {
+  sources = [
+    "cascaded_biquad_filter.cc",
+    "cascaded_biquad_filter.h",
+  ]
+  deps = [
+    "../../../api:array_view",
+    "../../../rtc_base:checks",
+  ]
+}
+
+rtc_library("legacy_delay_estimator") {
+  sources = [
+    "delay_estimator.cc",
+    "delay_estimator.h",
+    "delay_estimator_internal.h",
+    "delay_estimator_wrapper.cc",
+    "delay_estimator_wrapper.h",
+  ]
+  deps = [ "../../../rtc_base:checks" ]
+}
+
+rtc_library("pffft_wrapper") {
+  visibility = [ "../*" ]
+  sources = [
+    "pffft_wrapper.cc",
+    "pffft_wrapper.h",
+  ]
+  deps = [
+    "../../../api:array_view",
+    "../../../rtc_base:checks",
+    "//third_party/pffft",
+  ]
+}
+
+if (rtc_include_tests) {
+  rtc_library("cascaded_biquad_filter_unittest") {
+    testonly = true
+
+    sources = [ "cascaded_biquad_filter_unittest.cc" ]
+    deps = [
+      ":cascaded_biquad_filter",
+      "../../../rtc_base:rtc_base_approved",
+      "../../../test:test_support",
+      "//testing/gtest",
+    ]
+  }
+
+  rtc_library("legacy_delay_estimator_unittest") {
+    testonly = true
+
+    sources = [ "delay_estimator_unittest.cc" ]
+    deps = [
+      ":legacy_delay_estimator",
+      "../../../rtc_base:rtc_base_approved",
+      "../../../test:test_support",
+      "//testing/gtest",
+    ]
+  }
+
+  rtc_library("pffft_wrapper_unittest") {
+    testonly = true
+    sources = [ "pffft_wrapper_unittest.cc" ]
+    deps = [
+      ":pffft_wrapper",
+      "../../../test:test_support",
+      "//testing/gtest",
+      "//third_party/pffft",
+    ]
+  }
+}
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/utility/DEPS b/third_party/webrtc_aec3/src/modules/audio_processing/utility/DEPS
new file mode 100644
index 0000000..c72d810
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/utility/DEPS
@@ -0,0 +1,3 @@
+include_rules = [
+  "+third_party/pffft",
+]
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/utility/cascaded_biquad_filter.cc b/third_party/webrtc_aec3/src/modules/audio_processing/utility/cascaded_biquad_filter.cc
new file mode 100644
index 0000000..08b9464
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/utility/cascaded_biquad_filter.cc
@@ -0,0 +1,117 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "modules/audio_processing/utility/cascaded_biquad_filter.h"
+
+#include <algorithm>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+CascadedBiQuadFilter::BiQuadParam::BiQuadParam(std::complex<float> zero,
+                                               std::complex<float> pole,
+                                               float gain,
+                                               bool mirror_zero_along_i_axis)
+    : zero(zero),
+      pole(pole),
+      gain(gain),
+      mirror_zero_along_i_axis(mirror_zero_along_i_axis) {}
+
+CascadedBiQuadFilter::BiQuadParam::BiQuadParam(const BiQuadParam&) = default;
+
+CascadedBiQuadFilter::BiQuad::BiQuad(
+    const CascadedBiQuadFilter::BiQuadParam& param)
+    : x(), y() {
+  float z_r = std::real(param.zero);
+  float z_i = std::imag(param.zero);
+  float p_r = std::real(param.pole);
+  float p_i = std::imag(param.pole);
+  float gain = param.gain;
+
+  if (param.mirror_zero_along_i_axis) {
+    // Assuming zeroes at z_r and -z_r.
+    RTC_DCHECK(z_i == 0.f);
+    coefficients.b[0] = gain * 1.f;
+    coefficients.b[1] = 0.f;
+    coefficients.b[2] = gain * -(z_r * z_r);
+  } else {
+    // Assuming zeros at (z_r + z_i*i) and (z_r - z_i*i).
+    coefficients.b[0] = gain * 1.f;
+    coefficients.b[1] = gain * -2.f * z_r;
+    coefficients.b[2] = gain * (z_r * z_r + z_i * z_i);
+  }
+
+  // Assuming poles at (p_r + p_i*i) and (p_r - p_i*i).
+  coefficients.a[0] = -2.f * p_r;
+  coefficients.a[1] = p_r * p_r + p_i * p_i;
+}
+
+void CascadedBiQuadFilter::BiQuad::BiQuad::Reset() {
+  x[0] = x[1] = y[0] = y[1] = 0.f;
+}
+
+CascadedBiQuadFilter::CascadedBiQuadFilter(
+    const CascadedBiQuadFilter::BiQuadCoefficients& coefficients,
+    size_t num_biquads)
+    : biquads_(num_biquads, BiQuad(coefficients)) {}
+
+CascadedBiQuadFilter::CascadedBiQuadFilter(
+    const std::vector<CascadedBiQuadFilter::BiQuadParam>& biquad_params) {
+  for (const auto& param : biquad_params) {
+    biquads_.push_back(BiQuad(param));
+  }
+}
+
+CascadedBiQuadFilter::~CascadedBiQuadFilter() = default;
+
+void CascadedBiQuadFilter::Process(rtc::ArrayView<const float> x,
+                                   rtc::ArrayView<float> y) {
+  if (biquads_.size() > 0) {
+    ApplyBiQuad(x, y, &biquads_[0]);
+    for (size_t k = 1; k < biquads_.size(); ++k) {
+      ApplyBiQuad(y, y, &biquads_[k]);
+    }
+  } else {
+    std::copy(x.begin(), x.end(), y.begin());
+  }
+}
+
+void CascadedBiQuadFilter::Process(rtc::ArrayView<float> y) {
+  for (auto& biquad : biquads_) {
+    ApplyBiQuad(y, y, &biquad);
+  }
+}
+
+void CascadedBiQuadFilter::Reset() {
+  for (auto& biquad : biquads_) {
+    biquad.Reset();
+  }
+}
+
+void CascadedBiQuadFilter::ApplyBiQuad(rtc::ArrayView<const float> x,
+                                       rtc::ArrayView<float> y,
+                                       CascadedBiQuadFilter::BiQuad* biquad) {
+  RTC_DCHECK_EQ(x.size(), y.size());
+  const auto* c_b = biquad->coefficients.b;
+  const auto* c_a = biquad->coefficients.a;
+  auto* m_x = biquad->x;
+  auto* m_y = biquad->y;
+  for (size_t k = 0; k < x.size(); ++k) {
+    const float tmp = x[k];
+    y[k] = c_b[0] * tmp + c_b[1] * m_x[0] + c_b[2] * m_x[1] - c_a[0] * m_y[0] -
+           c_a[1] * m_y[1];
+    m_x[1] = m_x[0];
+    m_x[0] = tmp;
+    m_y[1] = m_y[0];
+    m_y[0] = y[k];
+  }
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/utility/cascaded_biquad_filter.h b/third_party/webrtc_aec3/src/modules/audio_processing/utility/cascaded_biquad_filter.h
new file mode 100644
index 0000000..120b52a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/utility/cascaded_biquad_filter.h
@@ -0,0 +1,80 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_UTILITY_CASCADED_BIQUAD_FILTER_H_
+#define MODULES_AUDIO_PROCESSING_UTILITY_CASCADED_BIQUAD_FILTER_H_
+
+#include <stddef.h>
+
+#include <complex>
+#include <vector>
+
+#include "api/array_view.h"
+
+namespace webrtc {
+
+// Applies a number of biquads in a cascaded manner. The filter implementation
+// is direct form 1.
+class CascadedBiQuadFilter {
+ public:
+  struct BiQuadParam {
+    BiQuadParam(std::complex<float> zero,
+                std::complex<float> pole,
+                float gain,
+                bool mirror_zero_along_i_axis = false);
+    explicit BiQuadParam(const BiQuadParam&);
+    std::complex<float> zero;
+    std::complex<float> pole;
+    float gain;
+    bool mirror_zero_along_i_axis;
+  };
+
+  struct BiQuadCoefficients {
+    float b[3];
+    float a[2];
+  };
+
+  struct BiQuad {
+    explicit BiQuad(const BiQuadCoefficients& coefficients)
+        : coefficients(coefficients), x(), y() {}
+    explicit BiQuad(const CascadedBiQuadFilter::BiQuadParam& param);
+    void Reset();
+    BiQuadCoefficients coefficients;
+    float x[2];
+    float y[2];
+  };
+
+  CascadedBiQuadFilter(
+      const CascadedBiQuadFilter::BiQuadCoefficients& coefficients,
+      size_t num_biquads);
+  explicit CascadedBiQuadFilter(
+      const std::vector<CascadedBiQuadFilter::BiQuadParam>& biquad_params);
+  ~CascadedBiQuadFilter();
+  CascadedBiQuadFilter(const CascadedBiQuadFilter&) = delete;
+  CascadedBiQuadFilter& operator=(const CascadedBiQuadFilter&) = delete;
+
+  // Applies the biquads on the values in x in order to form the output in y.
+  void Process(rtc::ArrayView<const float> x, rtc::ArrayView<float> y);
+  // Applies the biquads on the values in y in an in-place manner.
+  void Process(rtc::ArrayView<float> y);
+  // Resets the filter to its initial state.
+  void Reset();
+
+ private:
+  void ApplyBiQuad(rtc::ArrayView<const float> x,
+                   rtc::ArrayView<float> y,
+                   CascadedBiQuadFilter::BiQuad* biquad);
+
+  std::vector<BiQuad> biquads_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_UTILITY_CASCADED_BIQUAD_FILTER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/utility/cascaded_biquad_filter_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/utility/cascaded_biquad_filter_unittest.cc
new file mode 100644
index 0000000..ff7022d
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/utility/cascaded_biquad_filter_unittest.cc
@@ -0,0 +1,157 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/utility/cascaded_biquad_filter.h"
+
+#include <vector>
+
+#include "test/gtest.h"
+
+namespace webrtc {
+
+namespace {
+
+// Coefficients for a second order Butterworth high-pass filter with cutoff
+// frequency 100 Hz.
+const CascadedBiQuadFilter::BiQuadCoefficients kHighPassFilterCoefficients = {
+    {0.97261f, -1.94523f, 0.97261f},
+    {-1.94448f, 0.94598f}};
+
+const CascadedBiQuadFilter::BiQuadCoefficients kTransparentCoefficients = {
+    {1.f, 0.f, 0.f},
+    {0.f, 0.f}};
+
+const CascadedBiQuadFilter::BiQuadCoefficients kBlockingCoefficients = {
+    {0.f, 0.f, 0.f},
+    {0.f, 0.f}};
+
+std::vector<float> CreateInputWithIncreasingValues(size_t vector_length) {
+  std::vector<float> v(vector_length);
+  for (size_t k = 0; k < v.size(); ++k) {
+    v[k] = k;
+  }
+  return v;
+}
+
+}  // namespace
+
+// Verifies that the filter applies an effect which removes the input signal.
+// The test also verifies that the in-place Process API call works as intended.
+TEST(CascadedBiquadFilter, BlockingConfiguration) {
+  std::vector<float> values = CreateInputWithIncreasingValues(1000);
+
+  CascadedBiQuadFilter filter(kBlockingCoefficients, 1);
+  filter.Process(values);
+
+  EXPECT_EQ(std::vector<float>(1000, 0.f), values);
+}
+
+// Verifies that the filter is able to form a zero-mean output from a
+// non-zeromean input signal when coefficients for a high-pass filter are
+// applied. The test also verifies that the filter works with multiple biquads.
+TEST(CascadedBiquadFilter, HighPassConfiguration) {
+  std::vector<float> values(1000);
+  for (size_t k = 0; k < values.size(); ++k) {
+    values[k] = 1.f;
+  }
+
+  CascadedBiQuadFilter filter(kHighPassFilterCoefficients, 2);
+  filter.Process(values);
+
+  for (size_t k = values.size() / 2; k < values.size(); ++k) {
+    EXPECT_NEAR(0.f, values[k], 1e-4);
+  }
+}
+
+// Verifies that the reset functionality works as intended.
+TEST(CascadedBiquadFilter, HighPassConfigurationResetFunctionality) {
+  CascadedBiQuadFilter filter(kHighPassFilterCoefficients, 2);
+
+  std::vector<float> values1(100, 1.f);
+  filter.Process(values1);
+
+  filter.Reset();
+
+  std::vector<float> values2(100, 1.f);
+  filter.Process(values2);
+
+  for (size_t k = 0; k < values1.size(); ++k) {
+    EXPECT_EQ(values1[k], values2[k]);
+  }
+}
+
+// Verifies that the filter is able to produce a transparent effect with no
+// impact on the data when the proper coefficients are applied. The test also
+// verifies that the non-in-place Process API call works as intended.
+TEST(CascadedBiquadFilter, TransparentConfiguration) {
+  const std::vector<float> input = CreateInputWithIncreasingValues(1000);
+  std::vector<float> output(input.size());
+
+  CascadedBiQuadFilter filter(kTransparentCoefficients, 1);
+  filter.Process(input, output);
+
+  EXPECT_EQ(input, output);
+}
+
+#if RTC_DCHECK_IS_ON && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+// Verifies that the check of the lengths for the input and output works for the
+// non-in-place call.
+TEST(CascadedBiquadFilterDeathTest, InputSizeCheckVerification) {
+  const std::vector<float> input = CreateInputWithIncreasingValues(10);
+  std::vector<float> output(input.size() - 1);
+
+  CascadedBiQuadFilter filter(kTransparentCoefficients, 1);
+  EXPECT_DEATH(filter.Process(input, output), "");
+}
+#endif
+
+// Verifies the conversion from zero, pole, gain to filter coefficients for
+// lowpass filter.
+TEST(CascadedBiquadFilter, BiQuadParamLowPass) {
+  CascadedBiQuadFilter::BiQuadParam param(
+      {-1.0f, 0.0f}, {0.23146901f, 0.39514232f}, 0.1866943331163784f);
+  CascadedBiQuadFilter::BiQuad filter(param);
+  const float epsilon = 1e-6f;
+  EXPECT_NEAR(filter.coefficients.b[0], 0.18669433f, epsilon);
+  EXPECT_NEAR(filter.coefficients.b[1], 0.37338867f, epsilon);
+  EXPECT_NEAR(filter.coefficients.b[2], 0.18669433f, epsilon);
+  EXPECT_NEAR(filter.coefficients.a[0], -0.46293803f, epsilon);
+  EXPECT_NEAR(filter.coefficients.a[1], 0.20971536f, epsilon);
+}
+
+// Verifies the conversion from zero, pole, gain to filter coefficients for
+// highpass filter.
+TEST(CascadedBiquadFilter, BiQuadParamHighPass) {
+  CascadedBiQuadFilter::BiQuadParam param(
+      {1.0f, 0.0f}, {0.72712179f, 0.21296904f}, 0.75707637533388494f);
+  CascadedBiQuadFilter::BiQuad filter(param);
+  const float epsilon = 1e-6f;
+  EXPECT_NEAR(filter.coefficients.b[0], 0.75707638f, epsilon);
+  EXPECT_NEAR(filter.coefficients.b[1], -1.51415275f, epsilon);
+  EXPECT_NEAR(filter.coefficients.b[2], 0.75707638f, epsilon);
+  EXPECT_NEAR(filter.coefficients.a[0], -1.45424359f, epsilon);
+  EXPECT_NEAR(filter.coefficients.a[1], 0.57406192f, epsilon);
+}
+
+// Verifies the conversion from zero, pole, gain to filter coefficients for
+// bandpass filter.
+TEST(CascadedBiquadFilter, BiQuadParamBandPass) {
+  CascadedBiQuadFilter::BiQuadParam param(
+      {1.0f, 0.0f}, {1.11022302e-16f, 0.71381051f}, 0.2452372752527856f, true);
+  CascadedBiQuadFilter::BiQuad filter(param);
+  const float epsilon = 1e-6f;
+  EXPECT_NEAR(filter.coefficients.b[0], 0.24523728f, epsilon);
+  EXPECT_NEAR(filter.coefficients.b[1], 0.f, epsilon);
+  EXPECT_NEAR(filter.coefficients.b[2], -0.24523728f, epsilon);
+  EXPECT_NEAR(filter.coefficients.a[0], -2.22044605e-16f, epsilon);
+  EXPECT_NEAR(filter.coefficients.a[1], 5.09525449e-01f, epsilon);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator.cc b/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator.cc
new file mode 100644
index 0000000..73c70b0
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator.cc
@@ -0,0 +1,708 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/utility/delay_estimator.h"
+
+#include <stdlib.h>
+#include <string.h>
+
+#include <algorithm>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+namespace {
+
+// Number of right shifts for scaling is linearly depending on number of bits in
+// the far-end binary spectrum.
+static const int kShiftsAtZero = 13;  // Right shifts at zero binary spectrum.
+static const int kShiftsLinearSlope = 3;
+
+static const int32_t kProbabilityOffset = 1024;      // 2 in Q9.
+static const int32_t kProbabilityLowerLimit = 8704;  // 17 in Q9.
+static const int32_t kProbabilityMinSpread = 2816;   // 5.5 in Q9.
+
+// Robust validation settings
+static const float kHistogramMax = 3000.f;
+static const float kLastHistogramMax = 250.f;
+static const float kMinHistogramThreshold = 1.5f;
+static const int kMinRequiredHits = 10;
+static const int kMaxHitsWhenPossiblyNonCausal = 10;
+static const int kMaxHitsWhenPossiblyCausal = 1000;
+static const float kQ14Scaling = 1.f / (1 << 14);  // Scaling by 2^14 to get Q0.
+static const float kFractionSlope = 0.05f;
+static const float kMinFractionWhenPossiblyCausal = 0.5f;
+static const float kMinFractionWhenPossiblyNonCausal = 0.25f;
+
+}  // namespace
+
+// Counts and returns number of bits of a 32-bit word.
+static int BitCount(uint32_t u32) {
+  uint32_t tmp =
+      u32 - ((u32 >> 1) & 033333333333) - ((u32 >> 2) & 011111111111);
+  tmp = ((tmp + (tmp >> 3)) & 030707070707);
+  tmp = (tmp + (tmp >> 6));
+  tmp = (tmp + (tmp >> 12) + (tmp >> 24)) & 077;
+
+  return ((int)tmp);
+}
+
+// Compares the |binary_vector| with all rows of the |binary_matrix| and counts
+// per row the number of times they have the same value.
+//
+// Inputs:
+//      - binary_vector     : binary "vector" stored in a long
+//      - binary_matrix     : binary "matrix" stored as a vector of long
+//      - matrix_size       : size of binary "matrix"
+//
+// Output:
+//      - bit_counts        : "Vector" stored as a long, containing for each
+//                            row the number of times the matrix row and the
+//                            input vector have the same value
+//
+static void BitCountComparison(uint32_t binary_vector,
+                               const uint32_t* binary_matrix,
+                               int matrix_size,
+                               int32_t* bit_counts) {
+  int n = 0;
+
+  // Compare |binary_vector| with all rows of the |binary_matrix|
+  for (; n < matrix_size; n++) {
+    bit_counts[n] = (int32_t)BitCount(binary_vector ^ binary_matrix[n]);
+  }
+}
+
+// Collects necessary statistics for the HistogramBasedValidation().  This
+// function has to be called prior to calling HistogramBasedValidation().  The
+// statistics updated and used by the HistogramBasedValidation() are:
+//  1. the number of |candidate_hits|, which states for how long we have had the
+//     same |candidate_delay|
+//  2. the |histogram| of candidate delays over time.  This histogram is
+//     weighted with respect to a reliability measure and time-varying to cope
+//     with possible delay shifts.
+// For further description see commented code.
+//
+// Inputs:
+//  - candidate_delay   : The delay to validate.
+//  - valley_depth_q14  : The cost function has a valley/minimum at the
+//                        |candidate_delay| location.  |valley_depth_q14| is the
+//                        cost function difference between the minimum and
+//                        maximum locations.  The value is in the Q14 domain.
+//  - valley_level_q14  : Is the cost function value at the minimum, in Q14.
+static void UpdateRobustValidationStatistics(BinaryDelayEstimator* self,
+                                             int candidate_delay,
+                                             int32_t valley_depth_q14,
+                                             int32_t valley_level_q14) {
+  const float valley_depth = valley_depth_q14 * kQ14Scaling;
+  float decrease_in_last_set = valley_depth;
+  const int max_hits_for_slow_change = (candidate_delay < self->last_delay)
+                                           ? kMaxHitsWhenPossiblyNonCausal
+                                           : kMaxHitsWhenPossiblyCausal;
+  int i = 0;
+
+  RTC_DCHECK_EQ(self->history_size, self->farend->history_size);
+  // Reset |candidate_hits| if we have a new candidate.
+  if (candidate_delay != self->last_candidate_delay) {
+    self->candidate_hits = 0;
+    self->last_candidate_delay = candidate_delay;
+  }
+  self->candidate_hits++;
+
+  // The |histogram| is updated differently across the bins.
+  // 1. The |candidate_delay| histogram bin is increased with the
+  //    |valley_depth|, which is a simple measure of how reliable the
+  //    |candidate_delay| is.  The histogram is not increased above
+  //    |kHistogramMax|.
+  self->histogram[candidate_delay] += valley_depth;
+  if (self->histogram[candidate_delay] > kHistogramMax) {
+    self->histogram[candidate_delay] = kHistogramMax;
+  }
+  // 2. The histogram bins in the neighborhood of |candidate_delay| are
+  //    unaffected.  The neighborhood is defined as x + {-2, -1, 0, 1}.
+  // 3. The histogram bins in the neighborhood of |last_delay| are decreased
+  //    with |decrease_in_last_set|.  This value equals the difference between
+  //    the cost function values at the locations |candidate_delay| and
+  //    |last_delay| until we reach |max_hits_for_slow_change| consecutive hits
+  //    at the |candidate_delay|.  If we exceed this amount of hits the
+  //    |candidate_delay| is a "potential" candidate and we start decreasing
+  //    these histogram bins more rapidly with |valley_depth|.
+  if (self->candidate_hits < max_hits_for_slow_change) {
+    decrease_in_last_set =
+        (self->mean_bit_counts[self->compare_delay] - valley_level_q14) *
+        kQ14Scaling;
+  }
+  // 4. All other bins are decreased with |valley_depth|.
+  // TODO(bjornv): Investigate how to make this loop more efficient.  Split up
+  // the loop?  Remove parts that doesn't add too much.
+  for (i = 0; i < self->history_size; ++i) {
+    int is_in_last_set = (i >= self->last_delay - 2) &&
+                         (i <= self->last_delay + 1) && (i != candidate_delay);
+    int is_in_candidate_set =
+        (i >= candidate_delay - 2) && (i <= candidate_delay + 1);
+    self->histogram[i] -=
+        decrease_in_last_set * is_in_last_set +
+        valley_depth * (!is_in_last_set && !is_in_candidate_set);
+    // 5. No histogram bin can go below 0.
+    if (self->histogram[i] < 0) {
+      self->histogram[i] = 0;
+    }
+  }
+}
+
+// Validates the |candidate_delay|, estimated in WebRtc_ProcessBinarySpectrum(),
+// based on a mix of counting concurring hits with a modified histogram
+// of recent delay estimates.  In brief a candidate is valid (returns 1) if it
+// is the most likely according to the histogram.  There are a couple of
+// exceptions that are worth mentioning:
+//  1. If the |candidate_delay| < |last_delay| it can be that we are in a
+//     non-causal state, breaking a possible echo control algorithm.  Hence, we
+//     open up for a quicker change by allowing the change even if the
+//     |candidate_delay| is not the most likely one according to the histogram.
+//  2. There's a minimum number of hits (kMinRequiredHits) and the histogram
+//     value has to reached a minimum (kMinHistogramThreshold) to be valid.
+//  3. The action is also depending on the filter length used for echo control.
+//     If the delay difference is larger than what the filter can capture, we
+//     also move quicker towards a change.
+// For further description see commented code.
+//
+// Input:
+//  - candidate_delay     : The delay to validate.
+//
+// Return value:
+//  - is_histogram_valid  : 1 - The |candidate_delay| is valid.
+//                          0 - Otherwise.
+static int HistogramBasedValidation(const BinaryDelayEstimator* self,
+                                    int candidate_delay) {
+  float fraction = 1.f;
+  float histogram_threshold = self->histogram[self->compare_delay];
+  const int delay_difference = candidate_delay - self->last_delay;
+  int is_histogram_valid = 0;
+
+  // The histogram based validation of |candidate_delay| is done by comparing
+  // the |histogram| at bin |candidate_delay| with a |histogram_threshold|.
+  // This |histogram_threshold| equals a |fraction| of the |histogram| at bin
+  // |last_delay|.  The |fraction| is a piecewise linear function of the
+  // |delay_difference| between the |candidate_delay| and the |last_delay|
+  // allowing for a quicker move if
+  //  i) a potential echo control filter can not handle these large differences.
+  // ii) keeping |last_delay| instead of updating to |candidate_delay| could
+  //     force an echo control into a non-causal state.
+  // We further require the histogram to have reached a minimum value of
+  // |kMinHistogramThreshold|.  In addition, we also require the number of
+  // |candidate_hits| to be more than |kMinRequiredHits| to remove spurious
+  // values.
+
+  // Calculate a comparison histogram value (|histogram_threshold|) that is
+  // depending on the distance between the |candidate_delay| and |last_delay|.
+  // TODO(bjornv): How much can we gain by turning the fraction calculation
+  // into tables?
+  if (delay_difference > self->allowed_offset) {
+    fraction = 1.f - kFractionSlope * (delay_difference - self->allowed_offset);
+    fraction = (fraction > kMinFractionWhenPossiblyCausal
+                    ? fraction
+                    : kMinFractionWhenPossiblyCausal);
+  } else if (delay_difference < 0) {
+    fraction =
+        kMinFractionWhenPossiblyNonCausal - kFractionSlope * delay_difference;
+    fraction = (fraction > 1.f ? 1.f : fraction);
+  }
+  histogram_threshold *= fraction;
+  histogram_threshold =
+      (histogram_threshold > kMinHistogramThreshold ? histogram_threshold
+                                                    : kMinHistogramThreshold);
+
+  is_histogram_valid =
+      (self->histogram[candidate_delay] >= histogram_threshold) &&
+      (self->candidate_hits > kMinRequiredHits);
+
+  return is_histogram_valid;
+}
+
+// Performs a robust validation of the |candidate_delay| estimated in
+// WebRtc_ProcessBinarySpectrum().  The algorithm takes the
+// |is_instantaneous_valid| and the |is_histogram_valid| and combines them
+// into a robust validation.  The HistogramBasedValidation() has to be called
+// prior to this call.
+// For further description on how the combination is done, see commented code.
+//
+// Inputs:
+//  - candidate_delay         : The delay to validate.
+//  - is_instantaneous_valid  : The instantaneous validation performed in
+//                              WebRtc_ProcessBinarySpectrum().
+//  - is_histogram_valid      : The histogram based validation.
+//
+// Return value:
+//  - is_robust               : 1 - The candidate_delay is valid according to a
+//                                  combination of the two inputs.
+//                            : 0 - Otherwise.
+static int RobustValidation(const BinaryDelayEstimator* self,
+                            int candidate_delay,
+                            int is_instantaneous_valid,
+                            int is_histogram_valid) {
+  int is_robust = 0;
+
+  // The final robust validation is based on the two algorithms; 1) the
+  // |is_instantaneous_valid| and 2) the histogram based with result stored in
+  // |is_histogram_valid|.
+  //   i) Before we actually have a valid estimate (|last_delay| == -2), we say
+  //      a candidate is valid if either algorithm states so
+  //      (|is_instantaneous_valid| OR |is_histogram_valid|).
+  is_robust =
+      (self->last_delay < 0) && (is_instantaneous_valid || is_histogram_valid);
+  //  ii) Otherwise, we need both algorithms to be certain
+  //      (|is_instantaneous_valid| AND |is_histogram_valid|)
+  is_robust |= is_instantaneous_valid && is_histogram_valid;
+  // iii) With one exception, i.e., the histogram based algorithm can overrule
+  //      the instantaneous one if |is_histogram_valid| = 1 and the histogram
+  //      is significantly strong.
+  is_robust |= is_histogram_valid &&
+               (self->histogram[candidate_delay] > self->last_delay_histogram);
+
+  return is_robust;
+}
+
+void WebRtc_FreeBinaryDelayEstimatorFarend(BinaryDelayEstimatorFarend* self) {
+  if (self == NULL) {
+    return;
+  }
+
+  free(self->binary_far_history);
+  self->binary_far_history = NULL;
+
+  free(self->far_bit_counts);
+  self->far_bit_counts = NULL;
+
+  free(self);
+}
+
+BinaryDelayEstimatorFarend* WebRtc_CreateBinaryDelayEstimatorFarend(
+    int history_size) {
+  BinaryDelayEstimatorFarend* self = NULL;
+
+  if (history_size > 1) {
+    // Sanity conditions fulfilled.
+    self = static_cast<BinaryDelayEstimatorFarend*>(
+        malloc(sizeof(BinaryDelayEstimatorFarend)));
+  }
+  if (self == NULL) {
+    return NULL;
+  }
+
+  self->history_size = 0;
+  self->binary_far_history = NULL;
+  self->far_bit_counts = NULL;
+  if (WebRtc_AllocateFarendBufferMemory(self, history_size) == 0) {
+    WebRtc_FreeBinaryDelayEstimatorFarend(self);
+    self = NULL;
+  }
+  return self;
+}
+
+int WebRtc_AllocateFarendBufferMemory(BinaryDelayEstimatorFarend* self,
+                                      int history_size) {
+  RTC_DCHECK(self);
+  // (Re-)Allocate memory for history buffers.
+  self->binary_far_history = static_cast<uint32_t*>(
+      realloc(self->binary_far_history,
+              history_size * sizeof(*self->binary_far_history)));
+  self->far_bit_counts = static_cast<int*>(realloc(
+      self->far_bit_counts, history_size * sizeof(*self->far_bit_counts)));
+  if ((self->binary_far_history == NULL) || (self->far_bit_counts == NULL)) {
+    history_size = 0;
+  }
+  // Fill with zeros if we have expanded the buffers.
+  if (history_size > self->history_size) {
+    int size_diff = history_size - self->history_size;
+    memset(&self->binary_far_history[self->history_size], 0,
+           sizeof(*self->binary_far_history) * size_diff);
+    memset(&self->far_bit_counts[self->history_size], 0,
+           sizeof(*self->far_bit_counts) * size_diff);
+  }
+  self->history_size = history_size;
+
+  return self->history_size;
+}
+
+void WebRtc_InitBinaryDelayEstimatorFarend(BinaryDelayEstimatorFarend* self) {
+  RTC_DCHECK(self);
+  memset(self->binary_far_history, 0, sizeof(uint32_t) * self->history_size);
+  memset(self->far_bit_counts, 0, sizeof(int) * self->history_size);
+}
+
+void WebRtc_SoftResetBinaryDelayEstimatorFarend(
+    BinaryDelayEstimatorFarend* self,
+    int delay_shift) {
+  int abs_shift = abs(delay_shift);
+  int shift_size = 0;
+  int dest_index = 0;
+  int src_index = 0;
+  int padding_index = 0;
+
+  RTC_DCHECK(self);
+  shift_size = self->history_size - abs_shift;
+  RTC_DCHECK_GT(shift_size, 0);
+  if (delay_shift == 0) {
+    return;
+  } else if (delay_shift > 0) {
+    dest_index = abs_shift;
+  } else if (delay_shift < 0) {
+    src_index = abs_shift;
+    padding_index = shift_size;
+  }
+
+  // Shift and zero pad buffers.
+  memmove(&self->binary_far_history[dest_index],
+          &self->binary_far_history[src_index],
+          sizeof(*self->binary_far_history) * shift_size);
+  memset(&self->binary_far_history[padding_index], 0,
+         sizeof(*self->binary_far_history) * abs_shift);
+  memmove(&self->far_bit_counts[dest_index], &self->far_bit_counts[src_index],
+          sizeof(*self->far_bit_counts) * shift_size);
+  memset(&self->far_bit_counts[padding_index], 0,
+         sizeof(*self->far_bit_counts) * abs_shift);
+}
+
+void WebRtc_AddBinaryFarSpectrum(BinaryDelayEstimatorFarend* handle,
+                                 uint32_t binary_far_spectrum) {
+  RTC_DCHECK(handle);
+  // Shift binary spectrum history and insert current |binary_far_spectrum|.
+  memmove(&(handle->binary_far_history[1]), &(handle->binary_far_history[0]),
+          (handle->history_size - 1) * sizeof(uint32_t));
+  handle->binary_far_history[0] = binary_far_spectrum;
+
+  // Shift history of far-end binary spectrum bit counts and insert bit count
+  // of current |binary_far_spectrum|.
+  memmove(&(handle->far_bit_counts[1]), &(handle->far_bit_counts[0]),
+          (handle->history_size - 1) * sizeof(int));
+  handle->far_bit_counts[0] = BitCount(binary_far_spectrum);
+}
+
+void WebRtc_FreeBinaryDelayEstimator(BinaryDelayEstimator* self) {
+  if (self == NULL) {
+    return;
+  }
+
+  free(self->mean_bit_counts);
+  self->mean_bit_counts = NULL;
+
+  free(self->bit_counts);
+  self->bit_counts = NULL;
+
+  free(self->binary_near_history);
+  self->binary_near_history = NULL;
+
+  free(self->histogram);
+  self->histogram = NULL;
+
+  // BinaryDelayEstimator does not have ownership of |farend|, hence we do not
+  // free the memory here. That should be handled separately by the user.
+  self->farend = NULL;
+
+  free(self);
+}
+
+BinaryDelayEstimator* WebRtc_CreateBinaryDelayEstimator(
+    BinaryDelayEstimatorFarend* farend,
+    int max_lookahead) {
+  BinaryDelayEstimator* self = NULL;
+
+  if ((farend != NULL) && (max_lookahead >= 0)) {
+    // Sanity conditions fulfilled.
+    self = static_cast<BinaryDelayEstimator*>(
+        malloc(sizeof(BinaryDelayEstimator)));
+  }
+  if (self == NULL) {
+    return NULL;
+  }
+
+  self->farend = farend;
+  self->near_history_size = max_lookahead + 1;
+  self->history_size = 0;
+  self->robust_validation_enabled = 0;  // Disabled by default.
+  self->allowed_offset = 0;
+
+  self->lookahead = max_lookahead;
+
+  // Allocate memory for spectrum and history buffers.
+  self->mean_bit_counts = NULL;
+  self->bit_counts = NULL;
+  self->histogram = NULL;
+  self->binary_near_history = static_cast<uint32_t*>(
+      malloc((max_lookahead + 1) * sizeof(*self->binary_near_history)));
+  if (self->binary_near_history == NULL ||
+      WebRtc_AllocateHistoryBufferMemory(self, farend->history_size) == 0) {
+    WebRtc_FreeBinaryDelayEstimator(self);
+    self = NULL;
+  }
+
+  return self;
+}
+
+int WebRtc_AllocateHistoryBufferMemory(BinaryDelayEstimator* self,
+                                       int history_size) {
+  BinaryDelayEstimatorFarend* far = self->farend;
+  // (Re-)Allocate memory for spectrum and history buffers.
+  if (history_size != far->history_size) {
+    // Only update far-end buffers if we need.
+    history_size = WebRtc_AllocateFarendBufferMemory(far, history_size);
+  }
+  // The extra array element in |mean_bit_counts| and |histogram| is a dummy
+  // element only used while |last_delay| == -2, i.e., before we have a valid
+  // estimate.
+  self->mean_bit_counts = static_cast<int32_t*>(
+      realloc(self->mean_bit_counts,
+              (history_size + 1) * sizeof(*self->mean_bit_counts)));
+  self->bit_counts = static_cast<int32_t*>(
+      realloc(self->bit_counts, history_size * sizeof(*self->bit_counts)));
+  self->histogram = static_cast<float*>(
+      realloc(self->histogram, (history_size + 1) * sizeof(*self->histogram)));
+
+  if ((self->mean_bit_counts == NULL) || (self->bit_counts == NULL) ||
+      (self->histogram == NULL)) {
+    history_size = 0;
+  }
+  // Fill with zeros if we have expanded the buffers.
+  if (history_size > self->history_size) {
+    int size_diff = history_size - self->history_size;
+    memset(&self->mean_bit_counts[self->history_size], 0,
+           sizeof(*self->mean_bit_counts) * size_diff);
+    memset(&self->bit_counts[self->history_size], 0,
+           sizeof(*self->bit_counts) * size_diff);
+    memset(&self->histogram[self->history_size], 0,
+           sizeof(*self->histogram) * size_diff);
+  }
+  self->history_size = history_size;
+
+  return self->history_size;
+}
+
+void WebRtc_InitBinaryDelayEstimator(BinaryDelayEstimator* self) {
+  int i = 0;
+  RTC_DCHECK(self);
+
+  memset(self->bit_counts, 0, sizeof(int32_t) * self->history_size);
+  memset(self->binary_near_history, 0,
+         sizeof(uint32_t) * self->near_history_size);
+  for (i = 0; i <= self->history_size; ++i) {
+    self->mean_bit_counts[i] = (20 << 9);  // 20 in Q9.
+    self->histogram[i] = 0.f;
+  }
+  self->minimum_probability = kMaxBitCountsQ9;          // 32 in Q9.
+  self->last_delay_probability = (int)kMaxBitCountsQ9;  // 32 in Q9.
+
+  // Default return value if we're unable to estimate. -1 is used for errors.
+  self->last_delay = -2;
+
+  self->last_candidate_delay = -2;
+  self->compare_delay = self->history_size;
+  self->candidate_hits = 0;
+  self->last_delay_histogram = 0.f;
+}
+
+int WebRtc_SoftResetBinaryDelayEstimator(BinaryDelayEstimator* self,
+                                         int delay_shift) {
+  int lookahead = 0;
+  RTC_DCHECK(self);
+  lookahead = self->lookahead;
+  self->lookahead -= delay_shift;
+  if (self->lookahead < 0) {
+    self->lookahead = 0;
+  }
+  if (self->lookahead > self->near_history_size - 1) {
+    self->lookahead = self->near_history_size - 1;
+  }
+  return lookahead - self->lookahead;
+}
+
+int WebRtc_ProcessBinarySpectrum(BinaryDelayEstimator* self,
+                                 uint32_t binary_near_spectrum) {
+  int i = 0;
+  int candidate_delay = -1;
+  int valid_candidate = 0;
+
+  int32_t value_best_candidate = kMaxBitCountsQ9;
+  int32_t value_worst_candidate = 0;
+  int32_t valley_depth = 0;
+
+  RTC_DCHECK(self);
+  if (self->farend->history_size != self->history_size) {
+    // Non matching history sizes.
+    return -1;
+  }
+  if (self->near_history_size > 1) {
+    // If we apply lookahead, shift near-end binary spectrum history. Insert
+    // current |binary_near_spectrum| and pull out the delayed one.
+    memmove(&(self->binary_near_history[1]), &(self->binary_near_history[0]),
+            (self->near_history_size - 1) * sizeof(uint32_t));
+    self->binary_near_history[0] = binary_near_spectrum;
+    binary_near_spectrum = self->binary_near_history[self->lookahead];
+  }
+
+  // Compare with delayed spectra and store the |bit_counts| for each delay.
+  BitCountComparison(binary_near_spectrum, self->farend->binary_far_history,
+                     self->history_size, self->bit_counts);
+
+  // Update |mean_bit_counts|, which is the smoothed version of |bit_counts|.
+  for (i = 0; i < self->history_size; i++) {
+    // |bit_counts| is constrained to [0, 32], meaning we can smooth with a
+    // factor up to 2^26. We use Q9.
+    int32_t bit_count = (self->bit_counts[i] << 9);  // Q9.
+
+    // Update |mean_bit_counts| only when far-end signal has something to
+    // contribute. If |far_bit_counts| is zero the far-end signal is weak and
+    // we likely have a poor echo condition, hence don't update.
+    if (self->farend->far_bit_counts[i] > 0) {
+      // Make number of right shifts piecewise linear w.r.t. |far_bit_counts|.
+      int shifts = kShiftsAtZero;
+      shifts -= (kShiftsLinearSlope * self->farend->far_bit_counts[i]) >> 4;
+      WebRtc_MeanEstimatorFix(bit_count, shifts, &(self->mean_bit_counts[i]));
+    }
+  }
+
+  // Find |candidate_delay|, |value_best_candidate| and |value_worst_candidate|
+  // of |mean_bit_counts|.
+  for (i = 0; i < self->history_size; i++) {
+    if (self->mean_bit_counts[i] < value_best_candidate) {
+      value_best_candidate = self->mean_bit_counts[i];
+      candidate_delay = i;
+    }
+    if (self->mean_bit_counts[i] > value_worst_candidate) {
+      value_worst_candidate = self->mean_bit_counts[i];
+    }
+  }
+  valley_depth = value_worst_candidate - value_best_candidate;
+
+  // The |value_best_candidate| is a good indicator on the probability of
+  // |candidate_delay| being an accurate delay (a small |value_best_candidate|
+  // means a good binary match). In the following sections we make a decision
+  // whether to update |last_delay| or not.
+  // 1) If the difference bit counts between the best and the worst delay
+  //    candidates is too small we consider the situation to be unreliable and
+  //    don't update |last_delay|.
+  // 2) If the situation is reliable we update |last_delay| if the value of the
+  //    best candidate delay has a value less than
+  //     i) an adaptive threshold |minimum_probability|, or
+  //    ii) this corresponding value |last_delay_probability|, but updated at
+  //        this time instant.
+
+  // Update |minimum_probability|.
+  if ((self->minimum_probability > kProbabilityLowerLimit) &&
+      (valley_depth > kProbabilityMinSpread)) {
+    // The "hard" threshold can't be lower than 17 (in Q9).
+    // The valley in the curve also has to be distinct, i.e., the
+    // difference between |value_worst_candidate| and |value_best_candidate| has
+    // to be large enough.
+    int32_t threshold = value_best_candidate + kProbabilityOffset;
+    if (threshold < kProbabilityLowerLimit) {
+      threshold = kProbabilityLowerLimit;
+    }
+    if (self->minimum_probability > threshold) {
+      self->minimum_probability = threshold;
+    }
+  }
+  // Update |last_delay_probability|.
+  // We use a Markov type model, i.e., a slowly increasing level over time.
+  self->last_delay_probability++;
+  // Validate |candidate_delay|.  We have a reliable instantaneous delay
+  // estimate if
+  //  1) The valley is distinct enough (|valley_depth| > |kProbabilityOffset|)
+  // and
+  //  2) The depth of the valley is deep enough
+  //      (|value_best_candidate| < |minimum_probability|)
+  //     and deeper than the best estimate so far
+  //      (|value_best_candidate| < |last_delay_probability|)
+  valid_candidate = ((valley_depth > kProbabilityOffset) &&
+                     ((value_best_candidate < self->minimum_probability) ||
+                      (value_best_candidate < self->last_delay_probability)));
+
+  // Check for nonstationary farend signal.
+  const bool non_stationary_farend =
+      std::any_of(self->farend->far_bit_counts,
+                  self->farend->far_bit_counts + self->history_size,
+                  [](int a) { return a > 0; });
+
+  if (non_stationary_farend) {
+    // Only update the validation statistics when the farend is nonstationary
+    // as the underlying estimates are otherwise frozen.
+    UpdateRobustValidationStatistics(self, candidate_delay, valley_depth,
+                                     value_best_candidate);
+  }
+
+  if (self->robust_validation_enabled) {
+    int is_histogram_valid = HistogramBasedValidation(self, candidate_delay);
+    valid_candidate = RobustValidation(self, candidate_delay, valid_candidate,
+                                       is_histogram_valid);
+  }
+
+  // Only update the delay estimate when the farend is nonstationary and when
+  // a valid delay candidate is available.
+  if (non_stationary_farend && valid_candidate) {
+    if (candidate_delay != self->last_delay) {
+      self->last_delay_histogram =
+          (self->histogram[candidate_delay] > kLastHistogramMax
+               ? kLastHistogramMax
+               : self->histogram[candidate_delay]);
+      // Adjust the histogram if we made a change to |last_delay|, though it was
+      // not the most likely one according to the histogram.
+      if (self->histogram[candidate_delay] <
+          self->histogram[self->compare_delay]) {
+        self->histogram[self->compare_delay] = self->histogram[candidate_delay];
+      }
+    }
+    self->last_delay = candidate_delay;
+    if (value_best_candidate < self->last_delay_probability) {
+      self->last_delay_probability = value_best_candidate;
+    }
+    self->compare_delay = self->last_delay;
+  }
+
+  return self->last_delay;
+}
+
+int WebRtc_binary_last_delay(BinaryDelayEstimator* self) {
+  RTC_DCHECK(self);
+  return self->last_delay;
+}
+
+float WebRtc_binary_last_delay_quality(BinaryDelayEstimator* self) {
+  float quality = 0;
+  RTC_DCHECK(self);
+
+  if (self->robust_validation_enabled) {
+    // Simply a linear function of the histogram height at delay estimate.
+    quality = self->histogram[self->compare_delay] / kHistogramMax;
+  } else {
+    // Note that |last_delay_probability| states how deep the minimum of the
+    // cost function is, so it is rather an error probability.
+    quality = (float)(kMaxBitCountsQ9 - self->last_delay_probability) /
+              kMaxBitCountsQ9;
+    if (quality < 0) {
+      quality = 0;
+    }
+  }
+  return quality;
+}
+
+void WebRtc_MeanEstimatorFix(int32_t new_value,
+                             int factor,
+                             int32_t* mean_value) {
+  int32_t diff = new_value - *mean_value;
+
+  // mean_new = mean_value + ((new_value - mean_value) >> factor);
+  if (diff < 0) {
+    diff = -((-diff) >> factor);
+  } else {
+    diff = (diff >> factor);
+  }
+  *mean_value += diff;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator.h b/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator.h
new file mode 100644
index 0000000..df281bc
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator.h
@@ -0,0 +1,257 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// Performs delay estimation on binary converted spectra.
+// The return value is  0 - OK and -1 - Error, unless otherwise stated.
+
+#ifndef MODULES_AUDIO_PROCESSING_UTILITY_DELAY_ESTIMATOR_H_
+#define MODULES_AUDIO_PROCESSING_UTILITY_DELAY_ESTIMATOR_H_
+
+#include <stdint.h>
+
+namespace webrtc {
+
+static const int32_t kMaxBitCountsQ9 = (32 << 9);  // 32 matching bits in Q9.
+
+typedef struct {
+  // Pointer to bit counts.
+  int* far_bit_counts;
+  // Binary history variables.
+  uint32_t* binary_far_history;
+  int history_size;
+} BinaryDelayEstimatorFarend;
+
+typedef struct {
+  // Pointer to bit counts.
+  int32_t* mean_bit_counts;
+  // Array only used locally in ProcessBinarySpectrum() but whose size is
+  // determined at run-time.
+  int32_t* bit_counts;
+
+  // Binary history variables.
+  uint32_t* binary_near_history;
+  int near_history_size;
+  int history_size;
+
+  // Delay estimation variables.
+  int32_t minimum_probability;
+  int last_delay_probability;
+
+  // Delay memory.
+  int last_delay;
+
+  // Robust validation
+  int robust_validation_enabled;
+  int allowed_offset;
+  int last_candidate_delay;
+  int compare_delay;
+  int candidate_hits;
+  float* histogram;
+  float last_delay_histogram;
+
+  // For dynamically changing the lookahead when using SoftReset...().
+  int lookahead;
+
+  // Far-end binary spectrum history buffer etc.
+  BinaryDelayEstimatorFarend* farend;
+} BinaryDelayEstimator;
+
+// Releases the memory allocated by
+// WebRtc_CreateBinaryDelayEstimatorFarend(...).
+// Input:
+//    - self              : Pointer to the binary delay estimation far-end
+//                          instance which is the return value of
+//                          WebRtc_CreateBinaryDelayEstimatorFarend().
+//
+void WebRtc_FreeBinaryDelayEstimatorFarend(BinaryDelayEstimatorFarend* self);
+
+// Allocates the memory needed by the far-end part of the binary delay
+// estimation. The memory needs to be initialized separately through
+// WebRtc_InitBinaryDelayEstimatorFarend(...).
+//
+// Inputs:
+//      - history_size    : Size of the far-end binary spectrum history.
+//
+// Return value:
+//      - BinaryDelayEstimatorFarend*
+//                        : Created |handle|. If the memory can't be allocated
+//                          or if any of the input parameters are invalid NULL
+//                          is returned.
+//
+BinaryDelayEstimatorFarend* WebRtc_CreateBinaryDelayEstimatorFarend(
+    int history_size);
+
+// Re-allocates the buffers.
+//
+// Inputs:
+//      - self            : Pointer to the binary estimation far-end instance
+//                          which is the return value of
+//                          WebRtc_CreateBinaryDelayEstimatorFarend().
+//      - history_size    : Size of the far-end binary spectrum history.
+//
+// Return value:
+//      - history_size    : The history size allocated.
+int WebRtc_AllocateFarendBufferMemory(BinaryDelayEstimatorFarend* self,
+                                      int history_size);
+
+// Initializes the delay estimation far-end instance created with
+// WebRtc_CreateBinaryDelayEstimatorFarend(...).
+//
+// Input:
+//    - self              : Pointer to the delay estimation far-end instance.
+//
+// Output:
+//    - self              : Initialized far-end instance.
+//
+void WebRtc_InitBinaryDelayEstimatorFarend(BinaryDelayEstimatorFarend* self);
+
+// Soft resets the delay estimation far-end instance created with
+// WebRtc_CreateBinaryDelayEstimatorFarend(...).
+//
+// Input:
+//    - delay_shift   : The amount of blocks to shift history buffers.
+//
+void WebRtc_SoftResetBinaryDelayEstimatorFarend(
+    BinaryDelayEstimatorFarend* self,
+    int delay_shift);
+
+// Adds the binary far-end spectrum to the internal far-end history buffer. This
+// spectrum is used as reference when calculating the delay using
+// WebRtc_ProcessBinarySpectrum().
+//
+// Inputs:
+//    - self                  : Pointer to the delay estimation far-end
+//                              instance.
+//    - binary_far_spectrum   : Far-end binary spectrum.
+//
+// Output:
+//    - self                  : Updated far-end instance.
+//
+void WebRtc_AddBinaryFarSpectrum(BinaryDelayEstimatorFarend* self,
+                                 uint32_t binary_far_spectrum);
+
+// Releases the memory allocated by WebRtc_CreateBinaryDelayEstimator(...).
+//
+// Note that BinaryDelayEstimator utilizes BinaryDelayEstimatorFarend, but does
+// not take ownership of it, hence the BinaryDelayEstimator has to be torn down
+// before the far-end.
+//
+// Input:
+//    - self              : Pointer to the binary delay estimation instance
+//                          which is the return value of
+//                          WebRtc_CreateBinaryDelayEstimator().
+//
+void WebRtc_FreeBinaryDelayEstimator(BinaryDelayEstimator* self);
+
+// Allocates the memory needed by the binary delay estimation. The memory needs
+// to be initialized separately through WebRtc_InitBinaryDelayEstimator(...).
+//
+// See WebRtc_CreateDelayEstimator(..) in delay_estimator_wrapper.c for detailed
+// description.
+BinaryDelayEstimator* WebRtc_CreateBinaryDelayEstimator(
+    BinaryDelayEstimatorFarend* farend,
+    int max_lookahead);
+
+// Re-allocates |history_size| dependent buffers. The far-end buffers will be
+// updated at the same time if needed.
+//
+// Input:
+//      - self            : Pointer to the binary estimation instance which is
+//                          the return value of
+//                          WebRtc_CreateBinaryDelayEstimator().
+//      - history_size    : Size of the history buffers.
+//
+// Return value:
+//      - history_size    : The history size allocated.
+int WebRtc_AllocateHistoryBufferMemory(BinaryDelayEstimator* self,
+                                       int history_size);
+
+// Initializes the delay estimation instance created with
+// WebRtc_CreateBinaryDelayEstimator(...).
+//
+// Input:
+//    - self              : Pointer to the delay estimation instance.
+//
+// Output:
+//    - self              : Initialized instance.
+//
+void WebRtc_InitBinaryDelayEstimator(BinaryDelayEstimator* self);
+
+// Soft resets the delay estimation instance created with
+// WebRtc_CreateBinaryDelayEstimator(...).
+//
+// Input:
+//    - delay_shift   : The amount of blocks to shift history buffers.
+//
+// Return value:
+//    - actual_shifts : The actual number of shifts performed.
+//
+int WebRtc_SoftResetBinaryDelayEstimator(BinaryDelayEstimator* self,
+                                         int delay_shift);
+
+// Estimates and returns the delay between the binary far-end and binary near-
+// end spectra. It is assumed the binary far-end spectrum has been added using
+// WebRtc_AddBinaryFarSpectrum() prior to this call. The value will be offset by
+// the lookahead (i.e. the lookahead should be subtracted from the returned
+// value).
+//
+// Inputs:
+//    - self                  : Pointer to the delay estimation instance.
+//    - binary_near_spectrum  : Near-end binary spectrum of the current block.
+//
+// Output:
+//    - self                  : Updated instance.
+//
+// Return value:
+//    - delay                 :  >= 0 - Calculated delay value.
+//                              -2    - Insufficient data for estimation.
+//
+int WebRtc_ProcessBinarySpectrum(BinaryDelayEstimator* self,
+                                 uint32_t binary_near_spectrum);
+
+// Returns the last calculated delay updated by the function
+// WebRtc_ProcessBinarySpectrum(...).
+//
+// Input:
+//    - self                  : Pointer to the delay estimation instance.
+//
+// Return value:
+//    - delay                 :  >= 0 - Last calculated delay value
+//                              -2    - Insufficient data for estimation.
+//
+int WebRtc_binary_last_delay(BinaryDelayEstimator* self);
+
+// Returns the estimation quality of the last calculated delay updated by the
+// function WebRtc_ProcessBinarySpectrum(...). The estimation quality is a value
+// in the interval [0, 1].  The higher the value, the better the quality.
+//
+// Return value:
+//    - delay_quality         :  >= 0 - Estimation quality of last calculated
+//                                      delay value.
+float WebRtc_binary_last_delay_quality(BinaryDelayEstimator* self);
+
+// Updates the |mean_value| recursively with a step size of 2^-|factor|. This
+// function is used internally in the Binary Delay Estimator as well as the
+// Fixed point wrapper.
+//
+// Inputs:
+//    - new_value             : The new value the mean should be updated with.
+//    - factor                : The step size, in number of right shifts.
+//
+// Input/Output:
+//    - mean_value            : Pointer to the mean value.
+//
+void WebRtc_MeanEstimatorFix(int32_t new_value,
+                             int factor,
+                             int32_t* mean_value);
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_UTILITY_DELAY_ESTIMATOR_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator_internal.h b/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator_internal.h
new file mode 100644
index 0000000..fce95d8
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator_internal.h
@@ -0,0 +1,51 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// Header file including the delay estimator handle used for testing.
+
+#ifndef MODULES_AUDIO_PROCESSING_UTILITY_DELAY_ESTIMATOR_INTERNAL_H_
+#define MODULES_AUDIO_PROCESSING_UTILITY_DELAY_ESTIMATOR_INTERNAL_H_
+
+#include "modules/audio_processing/utility/delay_estimator.h"
+
+namespace webrtc {
+
+typedef union {
+  float float_;
+  int32_t int32_;
+} SpectrumType;
+
+typedef struct {
+  // Pointers to mean values of spectrum.
+  SpectrumType* mean_far_spectrum;
+  // |mean_far_spectrum| initialization indicator.
+  int far_spectrum_initialized;
+
+  int spectrum_size;
+
+  // Far-end part of binary spectrum based delay estimation.
+  BinaryDelayEstimatorFarend* binary_farend;
+} DelayEstimatorFarend;
+
+typedef struct {
+  // Pointers to mean values of spectrum.
+  SpectrumType* mean_near_spectrum;
+  // |mean_near_spectrum| initialization indicator.
+  int near_spectrum_initialized;
+
+  int spectrum_size;
+
+  // Binary spectrum based delay estimator
+  BinaryDelayEstimator* binary_handle;
+} DelayEstimator;
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_UTILITY_DELAY_ESTIMATOR_INTERNAL_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator_unittest.cc
new file mode 100644
index 0000000..65d8e14
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator_unittest.cc
@@ -0,0 +1,621 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/utility/delay_estimator.h"
+
+#include "modules/audio_processing/utility/delay_estimator_internal.h"
+#include "modules/audio_processing/utility/delay_estimator_wrapper.h"
+#include "test/gtest.h"
+
+namespace webrtc {
+
+namespace {
+
+enum { kSpectrumSize = 65 };
+// Delay history sizes.
+enum { kMaxDelay = 100 };
+enum { kLookahead = 10 };
+enum { kHistorySize = kMaxDelay + kLookahead };
+// Length of binary spectrum sequence.
+enum { kSequenceLength = 400 };
+
+const int kDifferentHistorySize = 3;
+const int kDifferentLookahead = 1;
+
+const int kEnable[] = {0, 1};
+const size_t kSizeEnable = sizeof(kEnable) / sizeof(*kEnable);
+
+class DelayEstimatorTest : public ::testing::Test {
+ protected:
+  DelayEstimatorTest();
+  void SetUp() override;
+  void TearDown() override;
+
+  void Init();
+  void InitBinary();
+  void VerifyDelay(BinaryDelayEstimator* binary_handle, int offset, int delay);
+  void RunBinarySpectra(BinaryDelayEstimator* binary1,
+                        BinaryDelayEstimator* binary2,
+                        int near_offset,
+                        int lookahead_offset,
+                        int far_offset);
+  void RunBinarySpectraTest(int near_offset,
+                            int lookahead_offset,
+                            int ref_robust_validation,
+                            int robust_validation);
+
+  void* handle_;
+  DelayEstimator* self_;
+  void* farend_handle_;
+  DelayEstimatorFarend* farend_self_;
+  BinaryDelayEstimator* binary_;
+  BinaryDelayEstimatorFarend* binary_farend_;
+  int spectrum_size_;
+  // Dummy input spectra.
+  float far_f_[kSpectrumSize];
+  float near_f_[kSpectrumSize];
+  uint16_t far_u16_[kSpectrumSize];
+  uint16_t near_u16_[kSpectrumSize];
+  uint32_t binary_spectrum_[kSequenceLength + kHistorySize];
+};
+
+DelayEstimatorTest::DelayEstimatorTest()
+    : handle_(NULL),
+      self_(NULL),
+      farend_handle_(NULL),
+      farend_self_(NULL),
+      binary_(NULL),
+      binary_farend_(NULL),
+      spectrum_size_(kSpectrumSize) {
+  // Dummy input data are set with more or less arbitrary non-zero values.
+  memset(far_f_, 1, sizeof(far_f_));
+  memset(near_f_, 2, sizeof(near_f_));
+  memset(far_u16_, 1, sizeof(far_u16_));
+  memset(near_u16_, 2, sizeof(near_u16_));
+  // Construct a sequence of binary spectra used to verify delay estimate. The
+  // |kSequenceLength| has to be long enough for the delay estimation to leave
+  // the initialized state.
+  binary_spectrum_[0] = 1;
+  for (int i = 1; i < (kSequenceLength + kHistorySize); i++) {
+    binary_spectrum_[i] = 3 * binary_spectrum_[i - 1];
+  }
+}
+
+void DelayEstimatorTest::SetUp() {
+  farend_handle_ =
+      WebRtc_CreateDelayEstimatorFarend(kSpectrumSize, kHistorySize);
+  ASSERT_TRUE(farend_handle_ != NULL);
+  farend_self_ = reinterpret_cast<DelayEstimatorFarend*>(farend_handle_);
+  handle_ = WebRtc_CreateDelayEstimator(farend_handle_, kLookahead);
+  ASSERT_TRUE(handle_ != NULL);
+  self_ = reinterpret_cast<DelayEstimator*>(handle_);
+  binary_farend_ = WebRtc_CreateBinaryDelayEstimatorFarend(kHistorySize);
+  ASSERT_TRUE(binary_farend_ != NULL);
+  binary_ = WebRtc_CreateBinaryDelayEstimator(binary_farend_, kLookahead);
+  ASSERT_TRUE(binary_ != NULL);
+}
+
+void DelayEstimatorTest::TearDown() {
+  WebRtc_FreeDelayEstimator(handle_);
+  handle_ = NULL;
+  self_ = NULL;
+  WebRtc_FreeDelayEstimatorFarend(farend_handle_);
+  farend_handle_ = NULL;
+  farend_self_ = NULL;
+  WebRtc_FreeBinaryDelayEstimator(binary_);
+  binary_ = NULL;
+  WebRtc_FreeBinaryDelayEstimatorFarend(binary_farend_);
+  binary_farend_ = NULL;
+}
+
+void DelayEstimatorTest::Init() {
+  // Initialize Delay Estimator
+  EXPECT_EQ(0, WebRtc_InitDelayEstimatorFarend(farend_handle_));
+  EXPECT_EQ(0, WebRtc_InitDelayEstimator(handle_));
+  // Verify initialization.
+  EXPECT_EQ(0, farend_self_->far_spectrum_initialized);
+  EXPECT_EQ(0, self_->near_spectrum_initialized);
+  EXPECT_EQ(-2, WebRtc_last_delay(handle_));  // Delay in initial state.
+  EXPECT_FLOAT_EQ(0, WebRtc_last_delay_quality(handle_));  // Zero quality.
+}
+
+void DelayEstimatorTest::InitBinary() {
+  // Initialize Binary Delay Estimator (far-end part).
+  WebRtc_InitBinaryDelayEstimatorFarend(binary_farend_);
+  // Initialize Binary Delay Estimator
+  WebRtc_InitBinaryDelayEstimator(binary_);
+  // Verify initialization. This does not guarantee a complete check, since
+  // |last_delay| may be equal to -2 before initialization if done on the fly.
+  EXPECT_EQ(-2, binary_->last_delay);
+}
+
+void DelayEstimatorTest::VerifyDelay(BinaryDelayEstimator* binary_handle,
+                                     int offset,
+                                     int delay) {
+  // Verify that we WebRtc_binary_last_delay() returns correct delay.
+  EXPECT_EQ(delay, WebRtc_binary_last_delay(binary_handle));
+
+  if (delay != -2) {
+    // Verify correct delay estimate. In the non-causal case the true delay
+    // is equivalent with the |offset|.
+    EXPECT_EQ(offset, delay);
+  }
+}
+
+void DelayEstimatorTest::RunBinarySpectra(BinaryDelayEstimator* binary1,
+                                          BinaryDelayEstimator* binary2,
+                                          int near_offset,
+                                          int lookahead_offset,
+                                          int far_offset) {
+  int different_validations =
+      binary1->robust_validation_enabled ^ binary2->robust_validation_enabled;
+  WebRtc_InitBinaryDelayEstimatorFarend(binary_farend_);
+  WebRtc_InitBinaryDelayEstimator(binary1);
+  WebRtc_InitBinaryDelayEstimator(binary2);
+  // Verify initialization. This does not guarantee a complete check, since
+  // |last_delay| may be equal to -2 before initialization if done on the fly.
+  EXPECT_EQ(-2, binary1->last_delay);
+  EXPECT_EQ(-2, binary2->last_delay);
+  for (int i = kLookahead; i < (kSequenceLength + kLookahead); i++) {
+    WebRtc_AddBinaryFarSpectrum(binary_farend_,
+                                binary_spectrum_[i + far_offset]);
+    int delay_1 = WebRtc_ProcessBinarySpectrum(binary1, binary_spectrum_[i]);
+    int delay_2 = WebRtc_ProcessBinarySpectrum(
+        binary2, binary_spectrum_[i - near_offset]);
+
+    VerifyDelay(binary1, far_offset + kLookahead, delay_1);
+    VerifyDelay(binary2,
+                far_offset + kLookahead + lookahead_offset + near_offset,
+                delay_2);
+    // Expect the two delay estimates to be offset by |lookahead_offset| +
+    // |near_offset| when we have left the initial state.
+    if ((delay_1 != -2) && (delay_2 != -2)) {
+      EXPECT_EQ(delay_1, delay_2 - lookahead_offset - near_offset);
+    }
+    // For the case of identical signals |delay_1| and |delay_2| should match
+    // all the time, unless one of them has robust validation turned on.  In
+    // that case the robust validation leaves the initial state faster.
+    if ((near_offset == 0) && (lookahead_offset == 0)) {
+      if (!different_validations) {
+        EXPECT_EQ(delay_1, delay_2);
+      } else {
+        if (binary1->robust_validation_enabled) {
+          EXPECT_GE(delay_1, delay_2);
+        } else {
+          EXPECT_GE(delay_2, delay_1);
+        }
+      }
+    }
+  }
+  // Verify that we have left the initialized state.
+  EXPECT_NE(-2, WebRtc_binary_last_delay(binary1));
+  EXPECT_LT(0, WebRtc_binary_last_delay_quality(binary1));
+  EXPECT_NE(-2, WebRtc_binary_last_delay(binary2));
+  EXPECT_LT(0, WebRtc_binary_last_delay_quality(binary2));
+}
+
+void DelayEstimatorTest::RunBinarySpectraTest(int near_offset,
+                                              int lookahead_offset,
+                                              int ref_robust_validation,
+                                              int robust_validation) {
+  BinaryDelayEstimator* binary2 = WebRtc_CreateBinaryDelayEstimator(
+      binary_farend_, kLookahead + lookahead_offset);
+  // Verify the delay for both causal and non-causal systems. For causal systems
+  // the delay is equivalent with a positive |offset| of the far-end sequence.
+  // For non-causal systems the delay is equivalent with a negative |offset| of
+  // the far-end sequence.
+  binary_->robust_validation_enabled = ref_robust_validation;
+  binary2->robust_validation_enabled = robust_validation;
+  for (int offset = -kLookahead;
+       offset < kMaxDelay - lookahead_offset - near_offset; offset++) {
+    RunBinarySpectra(binary_, binary2, near_offset, lookahead_offset, offset);
+  }
+  WebRtc_FreeBinaryDelayEstimator(binary2);
+  binary2 = NULL;
+  binary_->robust_validation_enabled = 0;  // Reset reference.
+}
+
+TEST_F(DelayEstimatorTest, CorrectErrorReturnsOfWrapper) {
+  // In this test we verify correct error returns on invalid API calls.
+
+  // WebRtc_CreateDelayEstimatorFarend() and WebRtc_CreateDelayEstimator()
+  // should return a NULL pointer on invalid input values.
+  // Make sure we have a non-NULL value at start, so we can detect NULL after
+  // create failure.
+  void* handle = farend_handle_;
+  handle = WebRtc_CreateDelayEstimatorFarend(33, kHistorySize);
+  EXPECT_TRUE(handle == NULL);
+  handle = WebRtc_CreateDelayEstimatorFarend(kSpectrumSize, 1);
+  EXPECT_TRUE(handle == NULL);
+
+  handle = handle_;
+  handle = WebRtc_CreateDelayEstimator(NULL, kLookahead);
+  EXPECT_TRUE(handle == NULL);
+  handle = WebRtc_CreateDelayEstimator(farend_handle_, -1);
+  EXPECT_TRUE(handle == NULL);
+
+  // WebRtc_InitDelayEstimatorFarend() and WebRtc_InitDelayEstimator() should
+  // return -1 if we have a NULL pointer as |handle|.
+  EXPECT_EQ(-1, WebRtc_InitDelayEstimatorFarend(NULL));
+  EXPECT_EQ(-1, WebRtc_InitDelayEstimator(NULL));
+
+  // WebRtc_AddFarSpectrumFloat() should return -1 if we have:
+  // 1) NULL pointer as |handle|.
+  // 2) NULL pointer as far-end spectrum.
+  // 3) Incorrect spectrum size.
+  EXPECT_EQ(-1, WebRtc_AddFarSpectrumFloat(NULL, far_f_, spectrum_size_));
+  // Use |farend_handle_| which is properly created at SetUp().
+  EXPECT_EQ(-1,
+            WebRtc_AddFarSpectrumFloat(farend_handle_, NULL, spectrum_size_));
+  EXPECT_EQ(-1, WebRtc_AddFarSpectrumFloat(farend_handle_, far_f_,
+                                           spectrum_size_ + 1));
+
+  // WebRtc_AddFarSpectrumFix() should return -1 if we have:
+  // 1) NULL pointer as |handle|.
+  // 2) NULL pointer as far-end spectrum.
+  // 3) Incorrect spectrum size.
+  // 4) Too high precision in far-end spectrum (Q-domain > 15).
+  EXPECT_EQ(-1, WebRtc_AddFarSpectrumFix(NULL, far_u16_, spectrum_size_, 0));
+  EXPECT_EQ(-1,
+            WebRtc_AddFarSpectrumFix(farend_handle_, NULL, spectrum_size_, 0));
+  EXPECT_EQ(-1, WebRtc_AddFarSpectrumFix(farend_handle_, far_u16_,
+                                         spectrum_size_ + 1, 0));
+  EXPECT_EQ(-1, WebRtc_AddFarSpectrumFix(farend_handle_, far_u16_,
+                                         spectrum_size_, 16));
+
+  // WebRtc_set_history_size() should return -1 if:
+  // 1) |handle| is a NULL.
+  // 2) |history_size| <= 1.
+  EXPECT_EQ(-1, WebRtc_set_history_size(NULL, 1));
+  EXPECT_EQ(-1, WebRtc_set_history_size(handle_, 1));
+  // WebRtc_history_size() should return -1 if:
+  // 1) NULL pointer input.
+  EXPECT_EQ(-1, WebRtc_history_size(NULL));
+  // 2) there is a mismatch between history size.
+  void* tmp_handle = WebRtc_CreateDelayEstimator(farend_handle_, kHistorySize);
+  EXPECT_EQ(0, WebRtc_InitDelayEstimator(tmp_handle));
+  EXPECT_EQ(kDifferentHistorySize,
+            WebRtc_set_history_size(tmp_handle, kDifferentHistorySize));
+  EXPECT_EQ(kDifferentHistorySize, WebRtc_history_size(tmp_handle));
+  EXPECT_EQ(kHistorySize, WebRtc_set_history_size(handle_, kHistorySize));
+  EXPECT_EQ(-1, WebRtc_history_size(tmp_handle));
+
+  // WebRtc_set_lookahead() should return -1 if we try a value outside the
+  /// buffer.
+  EXPECT_EQ(-1, WebRtc_set_lookahead(handle_, kLookahead + 1));
+  EXPECT_EQ(-1, WebRtc_set_lookahead(handle_, -1));
+
+  // WebRtc_set_allowed_offset() should return -1 if we have:
+  // 1) NULL pointer as |handle|.
+  // 2) |allowed_offset| < 0.
+  EXPECT_EQ(-1, WebRtc_set_allowed_offset(NULL, 0));
+  EXPECT_EQ(-1, WebRtc_set_allowed_offset(handle_, -1));
+
+  EXPECT_EQ(-1, WebRtc_get_allowed_offset(NULL));
+
+  // WebRtc_enable_robust_validation() should return -1 if we have:
+  // 1) NULL pointer as |handle|.
+  // 2) Incorrect |enable| value (not 0 or 1).
+  EXPECT_EQ(-1, WebRtc_enable_robust_validation(NULL, kEnable[0]));
+  EXPECT_EQ(-1, WebRtc_enable_robust_validation(handle_, -1));
+  EXPECT_EQ(-1, WebRtc_enable_robust_validation(handle_, 2));
+
+  // WebRtc_is_robust_validation_enabled() should return -1 if we have NULL
+  // pointer as |handle|.
+  EXPECT_EQ(-1, WebRtc_is_robust_validation_enabled(NULL));
+
+  // WebRtc_DelayEstimatorProcessFloat() should return -1 if we have:
+  // 1) NULL pointer as |handle|.
+  // 2) NULL pointer as near-end spectrum.
+  // 3) Incorrect spectrum size.
+  // 4) Non matching history sizes if multiple delay estimators using the same
+  //    far-end reference.
+  EXPECT_EQ(-1,
+            WebRtc_DelayEstimatorProcessFloat(NULL, near_f_, spectrum_size_));
+  // Use |handle_| which is properly created at SetUp().
+  EXPECT_EQ(-1,
+            WebRtc_DelayEstimatorProcessFloat(handle_, NULL, spectrum_size_));
+  EXPECT_EQ(-1, WebRtc_DelayEstimatorProcessFloat(handle_, near_f_,
+                                                  spectrum_size_ + 1));
+  // |tmp_handle| is already in a non-matching state.
+  EXPECT_EQ(-1, WebRtc_DelayEstimatorProcessFloat(tmp_handle, near_f_,
+                                                  spectrum_size_));
+
+  // WebRtc_DelayEstimatorProcessFix() should return -1 if we have:
+  // 1) NULL pointer as |handle|.
+  // 2) NULL pointer as near-end spectrum.
+  // 3) Incorrect spectrum size.
+  // 4) Too high precision in near-end spectrum (Q-domain > 15).
+  // 5) Non matching history sizes if multiple delay estimators using the same
+  //    far-end reference.
+  EXPECT_EQ(
+      -1, WebRtc_DelayEstimatorProcessFix(NULL, near_u16_, spectrum_size_, 0));
+  EXPECT_EQ(-1,
+            WebRtc_DelayEstimatorProcessFix(handle_, NULL, spectrum_size_, 0));
+  EXPECT_EQ(-1, WebRtc_DelayEstimatorProcessFix(handle_, near_u16_,
+                                                spectrum_size_ + 1, 0));
+  EXPECT_EQ(-1, WebRtc_DelayEstimatorProcessFix(handle_, near_u16_,
+                                                spectrum_size_, 16));
+  // |tmp_handle| is already in a non-matching state.
+  EXPECT_EQ(-1, WebRtc_DelayEstimatorProcessFix(tmp_handle, near_u16_,
+                                                spectrum_size_, 0));
+  WebRtc_FreeDelayEstimator(tmp_handle);
+
+  // WebRtc_last_delay() should return -1 if we have a NULL pointer as |handle|.
+  EXPECT_EQ(-1, WebRtc_last_delay(NULL));
+
+  // Free any local memory if needed.
+  WebRtc_FreeDelayEstimator(handle);
+}
+
+TEST_F(DelayEstimatorTest, VerifyAllowedOffset) {
+  // Is set to zero by default.
+  EXPECT_EQ(0, WebRtc_get_allowed_offset(handle_));
+  for (int i = 1; i >= 0; i--) {
+    EXPECT_EQ(0, WebRtc_set_allowed_offset(handle_, i));
+    EXPECT_EQ(i, WebRtc_get_allowed_offset(handle_));
+    Init();
+    // Unaffected over a reset.
+    EXPECT_EQ(i, WebRtc_get_allowed_offset(handle_));
+  }
+}
+
+TEST_F(DelayEstimatorTest, VerifyEnableRobustValidation) {
+  // Disabled by default.
+  EXPECT_EQ(0, WebRtc_is_robust_validation_enabled(handle_));
+  for (size_t i = 0; i < kSizeEnable; ++i) {
+    EXPECT_EQ(0, WebRtc_enable_robust_validation(handle_, kEnable[i]));
+    EXPECT_EQ(kEnable[i], WebRtc_is_robust_validation_enabled(handle_));
+    Init();
+    // Unaffected over a reset.
+    EXPECT_EQ(kEnable[i], WebRtc_is_robust_validation_enabled(handle_));
+  }
+}
+
+TEST_F(DelayEstimatorTest, InitializedSpectrumAfterProcess) {
+  // In this test we verify that the mean spectra are initialized after first
+  // time we call WebRtc_AddFarSpectrum() and Process() respectively. The test
+  // also verifies the state is not left for zero spectra.
+  const float kZerosFloat[kSpectrumSize] = {0.0};
+  const uint16_t kZerosU16[kSpectrumSize] = {0};
+
+  // For floating point operations, process one frame and verify initialization
+  // flag.
+  Init();
+  EXPECT_EQ(0, WebRtc_AddFarSpectrumFloat(farend_handle_, kZerosFloat,
+                                          spectrum_size_));
+  EXPECT_EQ(0, farend_self_->far_spectrum_initialized);
+  EXPECT_EQ(0,
+            WebRtc_AddFarSpectrumFloat(farend_handle_, far_f_, spectrum_size_));
+  EXPECT_EQ(1, farend_self_->far_spectrum_initialized);
+  EXPECT_EQ(-2, WebRtc_DelayEstimatorProcessFloat(handle_, kZerosFloat,
+                                                  spectrum_size_));
+  EXPECT_EQ(0, self_->near_spectrum_initialized);
+  EXPECT_EQ(
+      -2, WebRtc_DelayEstimatorProcessFloat(handle_, near_f_, spectrum_size_));
+  EXPECT_EQ(1, self_->near_spectrum_initialized);
+
+  // For fixed point operations, process one frame and verify initialization
+  // flag.
+  Init();
+  EXPECT_EQ(0, WebRtc_AddFarSpectrumFix(farend_handle_, kZerosU16,
+                                        spectrum_size_, 0));
+  EXPECT_EQ(0, farend_self_->far_spectrum_initialized);
+  EXPECT_EQ(
+      0, WebRtc_AddFarSpectrumFix(farend_handle_, far_u16_, spectrum_size_, 0));
+  EXPECT_EQ(1, farend_self_->far_spectrum_initialized);
+  EXPECT_EQ(-2, WebRtc_DelayEstimatorProcessFix(handle_, kZerosU16,
+                                                spectrum_size_, 0));
+  EXPECT_EQ(0, self_->near_spectrum_initialized);
+  EXPECT_EQ(-2, WebRtc_DelayEstimatorProcessFix(handle_, near_u16_,
+                                                spectrum_size_, 0));
+  EXPECT_EQ(1, self_->near_spectrum_initialized);
+}
+
+TEST_F(DelayEstimatorTest, CorrectLastDelay) {
+  // In this test we verify that we get the correct last delay upon valid call.
+  // We simply process the same data until we leave the initialized state
+  // (|last_delay| = -2). Then we compare the Process() output with the
+  // last_delay() call.
+
+  // TODO(bjornv): Update quality values for robust validation.
+  int last_delay = 0;
+  // Floating point operations.
+  Init();
+  for (int i = 0; i < 200; i++) {
+    EXPECT_EQ(
+        0, WebRtc_AddFarSpectrumFloat(farend_handle_, far_f_, spectrum_size_));
+    last_delay =
+        WebRtc_DelayEstimatorProcessFloat(handle_, near_f_, spectrum_size_);
+    if (last_delay != -2) {
+      EXPECT_EQ(last_delay, WebRtc_last_delay(handle_));
+      if (!WebRtc_is_robust_validation_enabled(handle_)) {
+        EXPECT_FLOAT_EQ(7203.f / kMaxBitCountsQ9,
+                        WebRtc_last_delay_quality(handle_));
+      }
+      break;
+    }
+  }
+  // Verify that we have left the initialized state.
+  EXPECT_NE(-2, WebRtc_last_delay(handle_));
+  EXPECT_LT(0, WebRtc_last_delay_quality(handle_));
+
+  // Fixed point operations.
+  Init();
+  for (int i = 0; i < 200; i++) {
+    EXPECT_EQ(0, WebRtc_AddFarSpectrumFix(farend_handle_, far_u16_,
+                                          spectrum_size_, 0));
+    last_delay =
+        WebRtc_DelayEstimatorProcessFix(handle_, near_u16_, spectrum_size_, 0);
+    if (last_delay != -2) {
+      EXPECT_EQ(last_delay, WebRtc_last_delay(handle_));
+      if (!WebRtc_is_robust_validation_enabled(handle_)) {
+        EXPECT_FLOAT_EQ(7203.f / kMaxBitCountsQ9,
+                        WebRtc_last_delay_quality(handle_));
+      }
+      break;
+    }
+  }
+  // Verify that we have left the initialized state.
+  EXPECT_NE(-2, WebRtc_last_delay(handle_));
+  EXPECT_LT(0, WebRtc_last_delay_quality(handle_));
+}
+
+TEST_F(DelayEstimatorTest, CorrectErrorReturnsOfBinaryEstimatorFarend) {
+  // In this test we verify correct output on invalid API calls to the Binary
+  // Delay Estimator (far-end part).
+
+  BinaryDelayEstimatorFarend* binary = binary_farend_;
+  // WebRtc_CreateBinaryDelayEstimatorFarend() should return -1 if the input
+  // history size is less than 2. This is to make sure the buffer shifting
+  // applies properly.
+  // Make sure we have a non-NULL value at start, so we can detect NULL after
+  // create failure.
+  binary = WebRtc_CreateBinaryDelayEstimatorFarend(1);
+  EXPECT_TRUE(binary == NULL);
+}
+
+TEST_F(DelayEstimatorTest, CorrectErrorReturnsOfBinaryEstimator) {
+  // In this test we verify correct output on invalid API calls to the Binary
+  // Delay Estimator.
+
+  BinaryDelayEstimator* binary_handle = binary_;
+  // WebRtc_CreateBinaryDelayEstimator() should return -1 if we have a NULL
+  // pointer as |binary_farend| or invalid input values. Upon failure, the
+  // |binary_handle| should be NULL.
+  // Make sure we have a non-NULL value at start, so we can detect NULL after
+  // create failure.
+  binary_handle = WebRtc_CreateBinaryDelayEstimator(NULL, kLookahead);
+  EXPECT_TRUE(binary_handle == NULL);
+  binary_handle = WebRtc_CreateBinaryDelayEstimator(binary_farend_, -1);
+  EXPECT_TRUE(binary_handle == NULL);
+}
+
+TEST_F(DelayEstimatorTest, MeanEstimatorFix) {
+  // In this test we verify that we update the mean value in correct direction
+  // only. With "direction" we mean increase or decrease.
+
+  int32_t mean_value = 4000;
+  int32_t mean_value_before = mean_value;
+  int32_t new_mean_value = mean_value * 2;
+
+  // Increasing |mean_value|.
+  WebRtc_MeanEstimatorFix(new_mean_value, 10, &mean_value);
+  EXPECT_LT(mean_value_before, mean_value);
+  EXPECT_GT(new_mean_value, mean_value);
+
+  // Decreasing |mean_value|.
+  new_mean_value = mean_value / 2;
+  mean_value_before = mean_value;
+  WebRtc_MeanEstimatorFix(new_mean_value, 10, &mean_value);
+  EXPECT_GT(mean_value_before, mean_value);
+  EXPECT_LT(new_mean_value, mean_value);
+}
+
+TEST_F(DelayEstimatorTest, ExactDelayEstimateMultipleNearSameSpectrum) {
+  // In this test we verify that we get the correct delay estimates if we shift
+  // the signal accordingly. We create two Binary Delay Estimators and feed them
+  // with the same signals, so they should output the same results.
+  // We verify both causal and non-causal delays.
+  // For these noise free signals, the robust validation should not have an
+  // impact, hence we turn robust validation on/off for both reference and
+  // delayed near end.
+
+  for (size_t i = 0; i < kSizeEnable; ++i) {
+    for (size_t j = 0; j < kSizeEnable; ++j) {
+      RunBinarySpectraTest(0, 0, kEnable[i], kEnable[j]);
+    }
+  }
+}
+
+TEST_F(DelayEstimatorTest, ExactDelayEstimateMultipleNearDifferentSpectrum) {
+  // In this test we use the same setup as above, but we now feed the two Binary
+  // Delay Estimators with different signals, so they should output different
+  // results.
+  // For these noise free signals, the robust validation should not have an
+  // impact, hence we turn robust validation on/off for both reference and
+  // delayed near end.
+
+  const int kNearOffset = 1;
+  for (size_t i = 0; i < kSizeEnable; ++i) {
+    for (size_t j = 0; j < kSizeEnable; ++j) {
+      RunBinarySpectraTest(kNearOffset, 0, kEnable[i], kEnable[j]);
+    }
+  }
+}
+
+TEST_F(DelayEstimatorTest, ExactDelayEstimateMultipleNearDifferentLookahead) {
+  // In this test we use the same setup as above, feeding the two Binary
+  // Delay Estimators with the same signals. The difference is that we create
+  // them with different lookahead.
+  // For these noise free signals, the robust validation should not have an
+  // impact, hence we turn robust validation on/off for both reference and
+  // delayed near end.
+
+  const int kLookaheadOffset = 1;
+  for (size_t i = 0; i < kSizeEnable; ++i) {
+    for (size_t j = 0; j < kSizeEnable; ++j) {
+      RunBinarySpectraTest(0, kLookaheadOffset, kEnable[i], kEnable[j]);
+    }
+  }
+}
+
+TEST_F(DelayEstimatorTest, AllowedOffsetNoImpactWhenRobustValidationDisabled) {
+  // The same setup as in ExactDelayEstimateMultipleNearSameSpectrum with the
+  // difference that |allowed_offset| is set for the reference binary delay
+  // estimator.
+
+  binary_->allowed_offset = 10;
+  RunBinarySpectraTest(0, 0, 0, 0);
+  binary_->allowed_offset = 0;  // Reset reference.
+}
+
+TEST_F(DelayEstimatorTest, VerifyLookaheadAtCreate) {
+  void* farend_handle =
+      WebRtc_CreateDelayEstimatorFarend(kSpectrumSize, kMaxDelay);
+  ASSERT_TRUE(farend_handle != NULL);
+  void* handle = WebRtc_CreateDelayEstimator(farend_handle, kLookahead);
+  ASSERT_TRUE(handle != NULL);
+  EXPECT_EQ(kLookahead, WebRtc_lookahead(handle));
+  WebRtc_FreeDelayEstimator(handle);
+  WebRtc_FreeDelayEstimatorFarend(farend_handle);
+}
+
+TEST_F(DelayEstimatorTest, VerifyLookaheadIsSetAndKeptAfterInit) {
+  EXPECT_EQ(kLookahead, WebRtc_lookahead(handle_));
+  EXPECT_EQ(kDifferentLookahead,
+            WebRtc_set_lookahead(handle_, kDifferentLookahead));
+  EXPECT_EQ(kDifferentLookahead, WebRtc_lookahead(handle_));
+  EXPECT_EQ(0, WebRtc_InitDelayEstimatorFarend(farend_handle_));
+  EXPECT_EQ(kDifferentLookahead, WebRtc_lookahead(handle_));
+  EXPECT_EQ(0, WebRtc_InitDelayEstimator(handle_));
+  EXPECT_EQ(kDifferentLookahead, WebRtc_lookahead(handle_));
+}
+
+TEST_F(DelayEstimatorTest, VerifyHistorySizeAtCreate) {
+  EXPECT_EQ(kHistorySize, WebRtc_history_size(handle_));
+}
+
+TEST_F(DelayEstimatorTest, VerifyHistorySizeIsSetAndKeptAfterInit) {
+  EXPECT_EQ(kHistorySize, WebRtc_history_size(handle_));
+  EXPECT_EQ(kDifferentHistorySize,
+            WebRtc_set_history_size(handle_, kDifferentHistorySize));
+  EXPECT_EQ(kDifferentHistorySize, WebRtc_history_size(handle_));
+  EXPECT_EQ(0, WebRtc_InitDelayEstimator(handle_));
+  EXPECT_EQ(kDifferentHistorySize, WebRtc_history_size(handle_));
+  EXPECT_EQ(0, WebRtc_InitDelayEstimatorFarend(farend_handle_));
+  EXPECT_EQ(kDifferentHistorySize, WebRtc_history_size(handle_));
+}
+
+// TODO(bjornv): Add tests for SoftReset...(...).
+
+}  // namespace
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator_wrapper.cc b/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator_wrapper.cc
new file mode 100644
index 0000000..8eac2f6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator_wrapper.cc
@@ -0,0 +1,489 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/utility/delay_estimator_wrapper.h"
+
+#include <stdlib.h>
+#include <string.h>
+
+#include "modules/audio_processing/utility/delay_estimator.h"
+#include "modules/audio_processing/utility/delay_estimator_internal.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+// Only bit |kBandFirst| through bit |kBandLast| are processed and
+// |kBandFirst| - |kBandLast| must be < 32.
+enum { kBandFirst = 12 };
+enum { kBandLast = 43 };
+
+static __inline uint32_t SetBit(uint32_t in, int pos) {
+  uint32_t mask = (1 << pos);
+  uint32_t out = (in | mask);
+
+  return out;
+}
+
+// Calculates the mean recursively. Same version as WebRtc_MeanEstimatorFix(),
+// but for float.
+//
+// Inputs:
+//    - new_value             : New additional value.
+//    - scale                 : Scale for smoothing (should be less than 1.0).
+//
+// Input/Output:
+//    - mean_value            : Pointer to the mean value for updating.
+//
+static void MeanEstimatorFloat(float new_value,
+                               float scale,
+                               float* mean_value) {
+  RTC_DCHECK_LT(scale, 1.0f);
+  *mean_value += (new_value - *mean_value) * scale;
+}
+
+// Computes the binary spectrum by comparing the input |spectrum| with a
+// |threshold_spectrum|. Float and fixed point versions.
+//
+// Inputs:
+//      - spectrum            : Spectrum of which the binary spectrum should be
+//                              calculated.
+//      - threshold_spectrum  : Threshold spectrum with which the input
+//                              spectrum is compared.
+// Return:
+//      - out                 : Binary spectrum.
+//
+static uint32_t BinarySpectrumFix(const uint16_t* spectrum,
+                                  SpectrumType* threshold_spectrum,
+                                  int q_domain,
+                                  int* threshold_initialized) {
+  int i = kBandFirst;
+  uint32_t out = 0;
+
+  RTC_DCHECK_LT(q_domain, 16);
+
+  if (!(*threshold_initialized)) {
+    // Set the |threshold_spectrum| to half the input |spectrum| as starting
+    // value. This speeds up the convergence.
+    for (i = kBandFirst; i <= kBandLast; i++) {
+      if (spectrum[i] > 0) {
+        // Convert input spectrum from Q(|q_domain|) to Q15.
+        int32_t spectrum_q15 = ((int32_t)spectrum[i]) << (15 - q_domain);
+        threshold_spectrum[i].int32_ = (spectrum_q15 >> 1);
+        *threshold_initialized = 1;
+      }
+    }
+  }
+  for (i = kBandFirst; i <= kBandLast; i++) {
+    // Convert input spectrum from Q(|q_domain|) to Q15.
+    int32_t spectrum_q15 = ((int32_t)spectrum[i]) << (15 - q_domain);
+    // Update the |threshold_spectrum|.
+    WebRtc_MeanEstimatorFix(spectrum_q15, 6, &(threshold_spectrum[i].int32_));
+    // Convert |spectrum| at current frequency bin to a binary value.
+    if (spectrum_q15 > threshold_spectrum[i].int32_) {
+      out = SetBit(out, i - kBandFirst);
+    }
+  }
+
+  return out;
+}
+
+static uint32_t BinarySpectrumFloat(const float* spectrum,
+                                    SpectrumType* threshold_spectrum,
+                                    int* threshold_initialized) {
+  int i = kBandFirst;
+  uint32_t out = 0;
+  const float kScale = 1 / 64.0;
+
+  if (!(*threshold_initialized)) {
+    // Set the |threshold_spectrum| to half the input |spectrum| as starting
+    // value. This speeds up the convergence.
+    for (i = kBandFirst; i <= kBandLast; i++) {
+      if (spectrum[i] > 0.0f) {
+        threshold_spectrum[i].float_ = (spectrum[i] / 2);
+        *threshold_initialized = 1;
+      }
+    }
+  }
+
+  for (i = kBandFirst; i <= kBandLast; i++) {
+    // Update the |threshold_spectrum|.
+    MeanEstimatorFloat(spectrum[i], kScale, &(threshold_spectrum[i].float_));
+    // Convert |spectrum| at current frequency bin to a binary value.
+    if (spectrum[i] > threshold_spectrum[i].float_) {
+      out = SetBit(out, i - kBandFirst);
+    }
+  }
+
+  return out;
+}
+
+void WebRtc_FreeDelayEstimatorFarend(void* handle) {
+  DelayEstimatorFarend* self = (DelayEstimatorFarend*)handle;
+
+  if (handle == NULL) {
+    return;
+  }
+
+  free(self->mean_far_spectrum);
+  self->mean_far_spectrum = NULL;
+
+  WebRtc_FreeBinaryDelayEstimatorFarend(self->binary_farend);
+  self->binary_farend = NULL;
+
+  free(self);
+}
+
+void* WebRtc_CreateDelayEstimatorFarend(int spectrum_size, int history_size) {
+  DelayEstimatorFarend* self = NULL;
+
+  // Check if the sub band used in the delay estimation is small enough to fit
+  // the binary spectra in a uint32_t.
+  static_assert(kBandLast - kBandFirst < 32, "");
+
+  if (spectrum_size >= kBandLast) {
+    self = static_cast<DelayEstimatorFarend*>(
+        malloc(sizeof(DelayEstimatorFarend)));
+  }
+
+  if (self != NULL) {
+    int memory_fail = 0;
+
+    // Allocate memory for the binary far-end spectrum handling.
+    self->binary_farend = WebRtc_CreateBinaryDelayEstimatorFarend(history_size);
+    memory_fail |= (self->binary_farend == NULL);
+
+    // Allocate memory for spectrum buffers.
+    self->mean_far_spectrum = static_cast<SpectrumType*>(
+        malloc(spectrum_size * sizeof(SpectrumType)));
+    memory_fail |= (self->mean_far_spectrum == NULL);
+
+    self->spectrum_size = spectrum_size;
+
+    if (memory_fail) {
+      WebRtc_FreeDelayEstimatorFarend(self);
+      self = NULL;
+    }
+  }
+
+  return self;
+}
+
+int WebRtc_InitDelayEstimatorFarend(void* handle) {
+  DelayEstimatorFarend* self = (DelayEstimatorFarend*)handle;
+
+  if (self == NULL) {
+    return -1;
+  }
+
+  // Initialize far-end part of binary delay estimator.
+  WebRtc_InitBinaryDelayEstimatorFarend(self->binary_farend);
+
+  // Set averaged far and near end spectra to zero.
+  memset(self->mean_far_spectrum, 0,
+         sizeof(SpectrumType) * self->spectrum_size);
+  // Reset initialization indicators.
+  self->far_spectrum_initialized = 0;
+
+  return 0;
+}
+
+void WebRtc_SoftResetDelayEstimatorFarend(void* handle, int delay_shift) {
+  DelayEstimatorFarend* self = (DelayEstimatorFarend*)handle;
+  RTC_DCHECK(self);
+  WebRtc_SoftResetBinaryDelayEstimatorFarend(self->binary_farend, delay_shift);
+}
+
+int WebRtc_AddFarSpectrumFix(void* handle,
+                             const uint16_t* far_spectrum,
+                             int spectrum_size,
+                             int far_q) {
+  DelayEstimatorFarend* self = (DelayEstimatorFarend*)handle;
+  uint32_t binary_spectrum = 0;
+
+  if (self == NULL) {
+    return -1;
+  }
+  if (far_spectrum == NULL) {
+    // Empty far end spectrum.
+    return -1;
+  }
+  if (spectrum_size != self->spectrum_size) {
+    // Data sizes don't match.
+    return -1;
+  }
+  if (far_q > 15) {
+    // If |far_q| is larger than 15 we cannot guarantee no wrap around.
+    return -1;
+  }
+
+  // Get binary spectrum.
+  binary_spectrum = BinarySpectrumFix(far_spectrum, self->mean_far_spectrum,
+                                      far_q, &(self->far_spectrum_initialized));
+  WebRtc_AddBinaryFarSpectrum(self->binary_farend, binary_spectrum);
+
+  return 0;
+}
+
+int WebRtc_AddFarSpectrumFloat(void* handle,
+                               const float* far_spectrum,
+                               int spectrum_size) {
+  DelayEstimatorFarend* self = (DelayEstimatorFarend*)handle;
+  uint32_t binary_spectrum = 0;
+
+  if (self == NULL) {
+    return -1;
+  }
+  if (far_spectrum == NULL) {
+    // Empty far end spectrum.
+    return -1;
+  }
+  if (spectrum_size != self->spectrum_size) {
+    // Data sizes don't match.
+    return -1;
+  }
+
+  // Get binary spectrum.
+  binary_spectrum = BinarySpectrumFloat(far_spectrum, self->mean_far_spectrum,
+                                        &(self->far_spectrum_initialized));
+  WebRtc_AddBinaryFarSpectrum(self->binary_farend, binary_spectrum);
+
+  return 0;
+}
+
+void WebRtc_FreeDelayEstimator(void* handle) {
+  DelayEstimator* self = (DelayEstimator*)handle;
+
+  if (handle == NULL) {
+    return;
+  }
+
+  free(self->mean_near_spectrum);
+  self->mean_near_spectrum = NULL;
+
+  WebRtc_FreeBinaryDelayEstimator(self->binary_handle);
+  self->binary_handle = NULL;
+
+  free(self);
+}
+
+void* WebRtc_CreateDelayEstimator(void* farend_handle, int max_lookahead) {
+  DelayEstimator* self = NULL;
+  DelayEstimatorFarend* farend = (DelayEstimatorFarend*)farend_handle;
+
+  if (farend_handle != NULL) {
+    self = static_cast<DelayEstimator*>(malloc(sizeof(DelayEstimator)));
+  }
+
+  if (self != NULL) {
+    int memory_fail = 0;
+
+    // Allocate memory for the farend spectrum handling.
+    self->binary_handle =
+        WebRtc_CreateBinaryDelayEstimator(farend->binary_farend, max_lookahead);
+    memory_fail |= (self->binary_handle == NULL);
+
+    // Allocate memory for spectrum buffers.
+    self->mean_near_spectrum = static_cast<SpectrumType*>(
+        malloc(farend->spectrum_size * sizeof(SpectrumType)));
+    memory_fail |= (self->mean_near_spectrum == NULL);
+
+    self->spectrum_size = farend->spectrum_size;
+
+    if (memory_fail) {
+      WebRtc_FreeDelayEstimator(self);
+      self = NULL;
+    }
+  }
+
+  return self;
+}
+
+int WebRtc_InitDelayEstimator(void* handle) {
+  DelayEstimator* self = (DelayEstimator*)handle;
+
+  if (self == NULL) {
+    return -1;
+  }
+
+  // Initialize binary delay estimator.
+  WebRtc_InitBinaryDelayEstimator(self->binary_handle);
+
+  // Set averaged far and near end spectra to zero.
+  memset(self->mean_near_spectrum, 0,
+         sizeof(SpectrumType) * self->spectrum_size);
+  // Reset initialization indicators.
+  self->near_spectrum_initialized = 0;
+
+  return 0;
+}
+
+int WebRtc_SoftResetDelayEstimator(void* handle, int delay_shift) {
+  DelayEstimator* self = (DelayEstimator*)handle;
+  RTC_DCHECK(self);
+  return WebRtc_SoftResetBinaryDelayEstimator(self->binary_handle, delay_shift);
+}
+
+int WebRtc_set_history_size(void* handle, int history_size) {
+  DelayEstimator* self = static_cast<DelayEstimator*>(handle);
+
+  if ((self == NULL) || (history_size <= 1)) {
+    return -1;
+  }
+  return WebRtc_AllocateHistoryBufferMemory(self->binary_handle, history_size);
+}
+
+int WebRtc_history_size(const void* handle) {
+  const DelayEstimator* self = static_cast<const DelayEstimator*>(handle);
+
+  if (self == NULL) {
+    return -1;
+  }
+  if (self->binary_handle->farend->history_size !=
+      self->binary_handle->history_size) {
+    // Non matching history sizes.
+    return -1;
+  }
+  return self->binary_handle->history_size;
+}
+
+int WebRtc_set_lookahead(void* handle, int lookahead) {
+  DelayEstimator* self = (DelayEstimator*)handle;
+  RTC_DCHECK(self);
+  RTC_DCHECK(self->binary_handle);
+  if ((lookahead > self->binary_handle->near_history_size - 1) ||
+      (lookahead < 0)) {
+    return -1;
+  }
+  self->binary_handle->lookahead = lookahead;
+  return self->binary_handle->lookahead;
+}
+
+int WebRtc_lookahead(void* handle) {
+  DelayEstimator* self = (DelayEstimator*)handle;
+  RTC_DCHECK(self);
+  RTC_DCHECK(self->binary_handle);
+  return self->binary_handle->lookahead;
+}
+
+int WebRtc_set_allowed_offset(void* handle, int allowed_offset) {
+  DelayEstimator* self = (DelayEstimator*)handle;
+
+  if ((self == NULL) || (allowed_offset < 0)) {
+    return -1;
+  }
+  self->binary_handle->allowed_offset = allowed_offset;
+  return 0;
+}
+
+int WebRtc_get_allowed_offset(const void* handle) {
+  const DelayEstimator* self = (const DelayEstimator*)handle;
+
+  if (self == NULL) {
+    return -1;
+  }
+  return self->binary_handle->allowed_offset;
+}
+
+int WebRtc_enable_robust_validation(void* handle, int enable) {
+  DelayEstimator* self = (DelayEstimator*)handle;
+
+  if (self == NULL) {
+    return -1;
+  }
+  if ((enable < 0) || (enable > 1)) {
+    return -1;
+  }
+  RTC_DCHECK(self->binary_handle);
+  self->binary_handle->robust_validation_enabled = enable;
+  return 0;
+}
+
+int WebRtc_is_robust_validation_enabled(const void* handle) {
+  const DelayEstimator* self = (const DelayEstimator*)handle;
+
+  if (self == NULL) {
+    return -1;
+  }
+  return self->binary_handle->robust_validation_enabled;
+}
+
+int WebRtc_DelayEstimatorProcessFix(void* handle,
+                                    const uint16_t* near_spectrum,
+                                    int spectrum_size,
+                                    int near_q) {
+  DelayEstimator* self = (DelayEstimator*)handle;
+  uint32_t binary_spectrum = 0;
+
+  if (self == NULL) {
+    return -1;
+  }
+  if (near_spectrum == NULL) {
+    // Empty near end spectrum.
+    return -1;
+  }
+  if (spectrum_size != self->spectrum_size) {
+    // Data sizes don't match.
+    return -1;
+  }
+  if (near_q > 15) {
+    // If |near_q| is larger than 15 we cannot guarantee no wrap around.
+    return -1;
+  }
+
+  // Get binary spectra.
+  binary_spectrum =
+      BinarySpectrumFix(near_spectrum, self->mean_near_spectrum, near_q,
+                        &(self->near_spectrum_initialized));
+
+  return WebRtc_ProcessBinarySpectrum(self->binary_handle, binary_spectrum);
+}
+
+int WebRtc_DelayEstimatorProcessFloat(void* handle,
+                                      const float* near_spectrum,
+                                      int spectrum_size) {
+  DelayEstimator* self = (DelayEstimator*)handle;
+  uint32_t binary_spectrum = 0;
+
+  if (self == NULL) {
+    return -1;
+  }
+  if (near_spectrum == NULL) {
+    // Empty near end spectrum.
+    return -1;
+  }
+  if (spectrum_size != self->spectrum_size) {
+    // Data sizes don't match.
+    return -1;
+  }
+
+  // Get binary spectrum.
+  binary_spectrum = BinarySpectrumFloat(near_spectrum, self->mean_near_spectrum,
+                                        &(self->near_spectrum_initialized));
+
+  return WebRtc_ProcessBinarySpectrum(self->binary_handle, binary_spectrum);
+}
+
+int WebRtc_last_delay(void* handle) {
+  DelayEstimator* self = (DelayEstimator*)handle;
+
+  if (self == NULL) {
+    return -1;
+  }
+
+  return WebRtc_binary_last_delay(self->binary_handle);
+}
+
+float WebRtc_last_delay_quality(void* handle) {
+  DelayEstimator* self = (DelayEstimator*)handle;
+  RTC_DCHECK(self);
+  return WebRtc_binary_last_delay_quality(self->binary_handle);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator_wrapper.h b/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator_wrapper.h
new file mode 100644
index 0000000..dbcafaf
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/utility/delay_estimator_wrapper.h
@@ -0,0 +1,248 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// Performs delay estimation on block by block basis.
+// The return value is  0 - OK and -1 - Error, unless otherwise stated.
+
+#ifndef MODULES_AUDIO_PROCESSING_UTILITY_DELAY_ESTIMATOR_WRAPPER_H_
+#define MODULES_AUDIO_PROCESSING_UTILITY_DELAY_ESTIMATOR_WRAPPER_H_
+
+#include <stdint.h>
+
+namespace webrtc {
+
+// Releases the memory allocated by WebRtc_CreateDelayEstimatorFarend(...)
+void WebRtc_FreeDelayEstimatorFarend(void* handle);
+
+// Allocates the memory needed by the far-end part of the delay estimation. The
+// memory needs to be initialized separately through
+// WebRtc_InitDelayEstimatorFarend(...).
+//
+// Inputs:
+//  - spectrum_size     : Size of the spectrum used both in far-end and
+//                        near-end. Used to allocate memory for spectrum
+//                        specific buffers.
+//  - history_size      : The far-end history buffer size. A change in buffer
+//                        size can be forced with WebRtc_set_history_size().
+//                        Note that the maximum delay which can be estimated is
+//                        determined together with WebRtc_set_lookahead().
+//
+// Return value:
+//  - void*             : Created |handle|. If the memory can't be allocated or
+//                        if any of the input parameters are invalid NULL is
+//                        returned.
+void* WebRtc_CreateDelayEstimatorFarend(int spectrum_size, int history_size);
+
+// Initializes the far-end part of the delay estimation instance returned by
+// WebRtc_CreateDelayEstimatorFarend(...)
+int WebRtc_InitDelayEstimatorFarend(void* handle);
+
+// Soft resets the far-end part of the delay estimation instance returned by
+// WebRtc_CreateDelayEstimatorFarend(...).
+// Input:
+//      - delay_shift   : The amount of blocks to shift history buffers.
+void WebRtc_SoftResetDelayEstimatorFarend(void* handle, int delay_shift);
+
+// Adds the far-end spectrum to the far-end history buffer. This spectrum is
+// used as reference when calculating the delay using
+// WebRtc_ProcessSpectrum().
+//
+// Inputs:
+//    - far_spectrum    : Far-end spectrum.
+//    - spectrum_size   : The size of the data arrays (same for both far- and
+//                        near-end).
+//    - far_q           : The Q-domain of the far-end data.
+//
+// Output:
+//    - handle          : Updated far-end instance.
+//
+int WebRtc_AddFarSpectrumFix(void* handle,
+                             const uint16_t* far_spectrum,
+                             int spectrum_size,
+                             int far_q);
+
+// See WebRtc_AddFarSpectrumFix() for description.
+int WebRtc_AddFarSpectrumFloat(void* handle,
+                               const float* far_spectrum,
+                               int spectrum_size);
+
+// Releases the memory allocated by WebRtc_CreateDelayEstimator(...)
+void WebRtc_FreeDelayEstimator(void* handle);
+
+// Allocates the memory needed by the delay estimation. The memory needs to be
+// initialized separately through WebRtc_InitDelayEstimator(...).
+//
+// Inputs:
+//      - farend_handle : Pointer to the far-end part of the delay estimation
+//                        instance created prior to this call using
+//                        WebRtc_CreateDelayEstimatorFarend().
+//
+//                        Note that WebRtc_CreateDelayEstimator does not take
+//                        ownership of |farend_handle|, which has to be torn
+//                        down properly after this instance.
+//
+//      - max_lookahead : Maximum amount of non-causal lookahead allowed. The
+//                        actual amount of lookahead used can be controlled by
+//                        WebRtc_set_lookahead(...). The default |lookahead| is
+//                        set to |max_lookahead| at create time. Use
+//                        WebRtc_set_lookahead(...) before start if a different
+//                        value is desired.
+//
+//                        Using lookahead can detect cases in which a near-end
+//                        signal occurs before the corresponding far-end signal.
+//                        It will delay the estimate for the current block by an
+//                        equal amount, and the returned values will be offset
+//                        by it.
+//
+//                        A value of zero is the typical no-lookahead case.
+//                        This also represents the minimum delay which can be
+//                        estimated.
+//
+//                        Note that the effective range of delay estimates is
+//                        [-|lookahead|,... ,|history_size|-|lookahead|)
+//                        where |history_size| is set through
+//                        WebRtc_set_history_size().
+//
+// Return value:
+//      - void*         : Created |handle|. If the memory can't be allocated or
+//                        if any of the input parameters are invalid NULL is
+//                        returned.
+void* WebRtc_CreateDelayEstimator(void* farend_handle, int max_lookahead);
+
+// Initializes the delay estimation instance returned by
+// WebRtc_CreateDelayEstimator(...)
+int WebRtc_InitDelayEstimator(void* handle);
+
+// Soft resets the delay estimation instance returned by
+// WebRtc_CreateDelayEstimator(...)
+// Input:
+//      - delay_shift   : The amount of blocks to shift history buffers.
+//
+// Return value:
+//      - actual_shifts : The actual number of shifts performed.
+int WebRtc_SoftResetDelayEstimator(void* handle, int delay_shift);
+
+// Sets the effective |history_size| used. Valid values from 2. We simply need
+// at least two delays to compare to perform an estimate. If |history_size| is
+// changed, buffers are reallocated filling in with zeros if necessary.
+// Note that changing the |history_size| affects both buffers in far-end and
+// near-end. Hence it is important to change all DelayEstimators that use the
+// same reference far-end, to the same |history_size| value.
+// Inputs:
+//  - handle            : Pointer to the delay estimation instance.
+//  - history_size      : Effective history size to be used.
+// Return value:
+//  - new_history_size  : The new history size used. If the memory was not able
+//                        to be allocated 0 is returned.
+int WebRtc_set_history_size(void* handle, int history_size);
+
+// Returns the history_size currently used.
+// Input:
+//      - handle        : Pointer to the delay estimation instance.
+int WebRtc_history_size(const void* handle);
+
+// Sets the amount of |lookahead| to use. Valid values are [0, max_lookahead]
+// where |max_lookahead| was set at create time through
+// WebRtc_CreateDelayEstimator(...).
+//
+// Input:
+//      - handle        : Pointer to the delay estimation instance.
+//      - lookahead     : The amount of lookahead to be used.
+//
+// Return value:
+//      - new_lookahead : The actual amount of lookahead set, unless |handle| is
+//                        a NULL pointer or |lookahead| is invalid, for which an
+//                        error is returned.
+int WebRtc_set_lookahead(void* handle, int lookahead);
+
+// Returns the amount of lookahead we currently use.
+// Input:
+//      - handle        : Pointer to the delay estimation instance.
+int WebRtc_lookahead(void* handle);
+
+// Sets the |allowed_offset| used in the robust validation scheme.  If the
+// delay estimator is used in an echo control component, this parameter is
+// related to the filter length.  In principle |allowed_offset| should be set to
+// the echo control filter length minus the expected echo duration, i.e., the
+// delay offset the echo control can handle without quality regression.  The
+// default value, used if not set manually, is zero.  Note that |allowed_offset|
+// has to be non-negative.
+// Inputs:
+//  - handle            : Pointer to the delay estimation instance.
+//  - allowed_offset    : The amount of delay offset, measured in partitions,
+//                        the echo control filter can handle.
+int WebRtc_set_allowed_offset(void* handle, int allowed_offset);
+
+// Returns the |allowed_offset| in number of partitions.
+int WebRtc_get_allowed_offset(const void* handle);
+
+// Enables/Disables a robust validation functionality in the delay estimation.
+// This is by default set to disabled at create time.  The state is preserved
+// over a reset.
+// Inputs:
+//      - handle        : Pointer to the delay estimation instance.
+//      - enable        : Enable (1) or disable (0) this feature.
+int WebRtc_enable_robust_validation(void* handle, int enable);
+
+// Returns 1 if robust validation is enabled and 0 if disabled.
+int WebRtc_is_robust_validation_enabled(const void* handle);
+
+// Estimates and returns the delay between the far-end and near-end blocks. The
+// value will be offset by the lookahead (i.e. the lookahead should be
+// subtracted from the returned value).
+// Inputs:
+//      - handle        : Pointer to the delay estimation instance.
+//      - near_spectrum : Pointer to the near-end spectrum data of the current
+//                        block.
+//      - spectrum_size : The size of the data arrays (same for both far- and
+//                        near-end).
+//      - near_q        : The Q-domain of the near-end data.
+//
+// Output:
+//      - handle        : Updated instance.
+//
+// Return value:
+//      - delay         :  >= 0 - Calculated delay value.
+//                        -1    - Error.
+//                        -2    - Insufficient data for estimation.
+int WebRtc_DelayEstimatorProcessFix(void* handle,
+                                    const uint16_t* near_spectrum,
+                                    int spectrum_size,
+                                    int near_q);
+
+// See WebRtc_DelayEstimatorProcessFix() for description.
+int WebRtc_DelayEstimatorProcessFloat(void* handle,
+                                      const float* near_spectrum,
+                                      int spectrum_size);
+
+// Returns the last calculated delay updated by the function
+// WebRtc_DelayEstimatorProcess(...).
+//
+// Input:
+//      - handle        : Pointer to the delay estimation instance.
+//
+// Return value:
+//      - delay         : >= 0  - Last calculated delay value.
+//                        -1    - Error.
+//                        -2    - Insufficient data for estimation.
+int WebRtc_last_delay(void* handle);
+
+// Returns the estimation quality/probability of the last calculated delay
+// updated by the function WebRtc_DelayEstimatorProcess(...). The estimation
+// quality is a value in the interval [0, 1]. The higher the value, the better
+// the quality.
+//
+// Return value:
+//      - delay_quality : >= 0  - Estimation quality of last calculated delay.
+float WebRtc_last_delay_quality(void* handle);
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_UTILITY_DELAY_ESTIMATOR_WRAPPER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/utility/pffft_wrapper.cc b/third_party/webrtc_aec3/src/modules/audio_processing/utility/pffft_wrapper.cc
new file mode 100644
index 0000000..88642fb
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/utility/pffft_wrapper.cc
@@ -0,0 +1,135 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/utility/pffft_wrapper.h"
+
+#include "rtc_base/checks.h"
+#include "third_party/pffft/src/pffft.h"
+
+namespace webrtc {
+namespace {
+
+size_t GetBufferSize(size_t fft_size, Pffft::FftType fft_type) {
+  return fft_size * (fft_type == Pffft::FftType::kReal ? 1 : 2);
+}
+
+float* AllocatePffftBuffer(size_t size) {
+  return static_cast<float*>(pffft_aligned_malloc(size * sizeof(float)));
+}
+
+}  // namespace
+
+Pffft::FloatBuffer::FloatBuffer(size_t fft_size, FftType fft_type)
+    : size_(GetBufferSize(fft_size, fft_type)),
+      data_(AllocatePffftBuffer(size_)) {}
+
+Pffft::FloatBuffer::~FloatBuffer() {
+  pffft_aligned_free(data_);
+}
+
+rtc::ArrayView<const float> Pffft::FloatBuffer::GetConstView() const {
+  return {data_, size_};
+}
+
+rtc::ArrayView<float> Pffft::FloatBuffer::GetView() {
+  return {data_, size_};
+}
+
+Pffft::Pffft(size_t fft_size, FftType fft_type)
+    : fft_size_(fft_size),
+      fft_type_(fft_type),
+      pffft_status_(pffft_new_setup(
+          fft_size_,
+          fft_type == Pffft::FftType::kReal ? PFFFT_REAL : PFFFT_COMPLEX)),
+      scratch_buffer_(
+          AllocatePffftBuffer(GetBufferSize(fft_size_, fft_type_))) {
+  RTC_DCHECK(pffft_status_);
+  RTC_DCHECK(scratch_buffer_);
+}
+
+Pffft::~Pffft() {
+  pffft_destroy_setup(pffft_status_);
+  pffft_aligned_free(scratch_buffer_);
+}
+
+bool Pffft::IsValidFftSize(size_t fft_size, FftType fft_type) {
+  if (fft_size == 0) {
+    return false;
+  }
+  // PFFFT only supports transforms for inputs of length N of the form
+  // N = (2^a)*(3^b)*(5^c) where b >=0 and c >= 0 and a >= 5 for the real FFT
+  // and a >= 4 for the complex FFT.
+  constexpr int kFactors[] = {2, 3, 5};
+  int factorization[] = {0, 0, 0};
+  int n = static_cast<int>(fft_size);
+  for (int i = 0; i < 3; ++i) {
+    while (n % kFactors[i] == 0) {
+      n = n / kFactors[i];
+      factorization[i]++;
+    }
+  }
+  int a_min = (fft_type == Pffft::FftType::kReal) ? 5 : 4;
+  return factorization[0] >= a_min && n == 1;
+}
+
+bool Pffft::IsSimdEnabled() {
+  return pffft_simd_size() > 1;
+}
+
+std::unique_ptr<Pffft::FloatBuffer> Pffft::CreateBuffer() const {
+  // Cannot use make_unique from absl because Pffft is the only friend of
+  // Pffft::FloatBuffer.
+  std::unique_ptr<Pffft::FloatBuffer> buffer(
+      new Pffft::FloatBuffer(fft_size_, fft_type_));
+  return buffer;
+}
+
+void Pffft::ForwardTransform(const FloatBuffer& in,
+                             FloatBuffer* out,
+                             bool ordered) {
+  RTC_DCHECK_EQ(in.size(), GetBufferSize(fft_size_, fft_type_));
+  RTC_DCHECK_EQ(in.size(), out->size());
+  RTC_DCHECK(scratch_buffer_);
+  if (ordered) {
+    pffft_transform_ordered(pffft_status_, in.const_data(), out->data(),
+                            scratch_buffer_, PFFFT_FORWARD);
+  } else {
+    pffft_transform(pffft_status_, in.const_data(), out->data(),
+                    scratch_buffer_, PFFFT_FORWARD);
+  }
+}
+
+void Pffft::BackwardTransform(const FloatBuffer& in,
+                              FloatBuffer* out,
+                              bool ordered) {
+  RTC_DCHECK_EQ(in.size(), GetBufferSize(fft_size_, fft_type_));
+  RTC_DCHECK_EQ(in.size(), out->size());
+  RTC_DCHECK(scratch_buffer_);
+  if (ordered) {
+    pffft_transform_ordered(pffft_status_, in.const_data(), out->data(),
+                            scratch_buffer_, PFFFT_BACKWARD);
+  } else {
+    pffft_transform(pffft_status_, in.const_data(), out->data(),
+                    scratch_buffer_, PFFFT_BACKWARD);
+  }
+}
+
+void Pffft::FrequencyDomainConvolve(const FloatBuffer& fft_x,
+                                    const FloatBuffer& fft_y,
+                                    FloatBuffer* out,
+                                    float scaling) {
+  RTC_DCHECK_EQ(fft_x.size(), GetBufferSize(fft_size_, fft_type_));
+  RTC_DCHECK_EQ(fft_x.size(), fft_y.size());
+  RTC_DCHECK_EQ(fft_x.size(), out->size());
+  pffft_zconvolve_accumulate(pffft_status_, fft_x.const_data(),
+                             fft_y.const_data(), out->data(), scaling);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/utility/pffft_wrapper.h b/third_party/webrtc_aec3/src/modules/audio_processing/utility/pffft_wrapper.h
new file mode 100644
index 0000000..160f0da
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/utility/pffft_wrapper.h
@@ -0,0 +1,94 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_AUDIO_PROCESSING_UTILITY_PFFFT_WRAPPER_H_
+#define MODULES_AUDIO_PROCESSING_UTILITY_PFFFT_WRAPPER_H_
+
+#include <memory>
+
+#include "api/array_view.h"
+
+// Forward declaration.
+struct PFFFT_Setup;
+
+namespace webrtc {
+
+// Pretty-Fast Fast Fourier Transform (PFFFT) wrapper class.
+// Not thread safe.
+class Pffft {
+ public:
+  enum class FftType { kReal, kComplex };
+
+  // 1D floating point buffer used as input/output data type for the FFT ops.
+  // It must be constructed using Pffft::CreateBuffer().
+  class FloatBuffer {
+   public:
+    FloatBuffer(const FloatBuffer&) = delete;
+    FloatBuffer& operator=(const FloatBuffer&) = delete;
+    ~FloatBuffer();
+
+    rtc::ArrayView<const float> GetConstView() const;
+    rtc::ArrayView<float> GetView();
+
+   private:
+    friend class Pffft;
+    FloatBuffer(size_t fft_size, FftType fft_type);
+    const float* const_data() const { return data_; }
+    float* data() { return data_; }
+    size_t size() const { return size_; }
+
+    const size_t size_;
+    float* const data_;
+  };
+
+  // TODO(https://crbug.com/webrtc/9577): Consider adding a factory and making
+  // the ctor private.
+  // static std::unique_ptr<Pffft> Create(size_t fft_size,
+  // FftType fft_type); Ctor. |fft_size| must be a supported size (see
+  // Pffft::IsValidFftSize()). If not supported, the code will crash.
+  Pffft(size_t fft_size, FftType fft_type);
+  Pffft(const Pffft&) = delete;
+  Pffft& operator=(const Pffft&) = delete;
+  ~Pffft();
+
+  // Returns true if the FFT size is supported.
+  static bool IsValidFftSize(size_t fft_size, FftType fft_type);
+
+  // Returns true if SIMD code optimizations are being used.
+  static bool IsSimdEnabled();
+
+  // Creates a buffer of the right size.
+  std::unique_ptr<FloatBuffer> CreateBuffer() const;
+
+  // TODO(https://crbug.com/webrtc/9577): Overload with rtc::ArrayView args.
+  // Computes the forward fast Fourier transform.
+  void ForwardTransform(const FloatBuffer& in, FloatBuffer* out, bool ordered);
+  // Computes the backward fast Fourier transform.
+  void BackwardTransform(const FloatBuffer& in, FloatBuffer* out, bool ordered);
+
+  // Multiplies the frequency components of |fft_x| and |fft_y| and accumulates
+  // them into |out|. The arrays must have been obtained with
+  // ForwardTransform(..., /*ordered=*/false) - i.e., |fft_x| and |fft_y| must
+  // not be ordered.
+  void FrequencyDomainConvolve(const FloatBuffer& fft_x,
+                               const FloatBuffer& fft_y,
+                               FloatBuffer* out,
+                               float scaling = 1.f);
+
+ private:
+  const size_t fft_size_;
+  const FftType fft_type_;
+  PFFFT_Setup* pffft_status_;
+  float* const scratch_buffer_;
+};
+
+}  // namespace webrtc
+
+#endif  // MODULES_AUDIO_PROCESSING_UTILITY_PFFFT_WRAPPER_H_
diff --git a/third_party/webrtc_aec3/src/modules/audio_processing/utility/pffft_wrapper_unittest.cc b/third_party/webrtc_aec3/src/modules/audio_processing/utility/pffft_wrapper_unittest.cc
new file mode 100644
index 0000000..2ad6849
--- /dev/null
+++ b/third_party/webrtc_aec3/src/modules/audio_processing/utility/pffft_wrapper_unittest.cc
@@ -0,0 +1,182 @@
+/*
+ *  Copyright (c) 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/utility/pffft_wrapper.h"
+
+#include <algorithm>
+#include <cstdlib>
+#include <memory>
+
+#include "test/gtest.h"
+#include "third_party/pffft/src/pffft.h"
+
+namespace webrtc {
+namespace test {
+namespace {
+
+constexpr size_t kMaxValidSizeCheck = 1024;
+
+static constexpr int kFftSizes[] = {
+    16,  32,      64,  96,  128,  160,  192,  256,  288,  384,   5 * 96, 512,
+    576, 5 * 128, 800, 864, 1024, 2048, 2592, 4000, 4096, 12000, 36864};
+
+void CreatePffftWrapper(size_t fft_size, Pffft::FftType fft_type) {
+  Pffft pffft_wrapper(fft_size, fft_type);
+}
+
+float* AllocateScratchBuffer(size_t fft_size, bool complex_fft) {
+  return static_cast<float*>(
+      pffft_aligned_malloc(fft_size * (complex_fft ? 2 : 1) * sizeof(float)));
+}
+
+double frand() {
+  return std::rand() / static_cast<double>(RAND_MAX);
+}
+
+void ExpectArrayViewsEquality(rtc::ArrayView<const float> a,
+                              rtc::ArrayView<const float> b) {
+  ASSERT_EQ(a.size(), b.size());
+  for (size_t i = 0; i < a.size(); ++i) {
+    SCOPED_TRACE(i);
+    EXPECT_EQ(a[i], b[i]);
+  }
+}
+
+// Compares the output of the PFFFT C++ wrapper to that of the C PFFFT.
+// Bit-exactness is expected.
+void PffftValidateWrapper(size_t fft_size, bool complex_fft) {
+  // Always use the same seed to avoid flakiness.
+  std::srand(0);
+
+  // Init PFFFT.
+  PFFFT_Setup* pffft_status =
+      pffft_new_setup(fft_size, complex_fft ? PFFFT_COMPLEX : PFFFT_REAL);
+  ASSERT_TRUE(pffft_status) << "FFT size (" << fft_size << ") not supported.";
+  size_t num_floats = fft_size * (complex_fft ? 2 : 1);
+  int num_bytes = static_cast<int>(num_floats) * sizeof(float);
+  float* in = static_cast<float*>(pffft_aligned_malloc(num_bytes));
+  float* out = static_cast<float*>(pffft_aligned_malloc(num_bytes));
+  float* scratch = AllocateScratchBuffer(fft_size, complex_fft);
+
+  // Init PFFFT C++ wrapper.
+  Pffft::FftType fft_type =
+      complex_fft ? Pffft::FftType::kComplex : Pffft::FftType::kReal;
+  ASSERT_TRUE(Pffft::IsValidFftSize(fft_size, fft_type));
+  Pffft pffft_wrapper(fft_size, fft_type);
+  auto in_wrapper = pffft_wrapper.CreateBuffer();
+  auto out_wrapper = pffft_wrapper.CreateBuffer();
+
+  // Input and output buffers views.
+  rtc::ArrayView<float> in_view(in, num_floats);
+  rtc::ArrayView<float> out_view(out, num_floats);
+  auto in_wrapper_view = in_wrapper->GetView();
+  EXPECT_EQ(in_wrapper_view.size(), num_floats);
+  auto out_wrapper_view = out_wrapper->GetConstView();
+  EXPECT_EQ(out_wrapper_view.size(), num_floats);
+
+  // Random input data.
+  for (size_t i = 0; i < num_floats; ++i) {
+    in_wrapper_view[i] = in[i] = static_cast<float>(frand() * 2.0 - 1.0);
+  }
+
+  // Forward transform.
+  pffft_transform(pffft_status, in, out, scratch, PFFFT_FORWARD);
+  pffft_wrapper.ForwardTransform(*in_wrapper, out_wrapper.get(),
+                                 /*ordered=*/false);
+  ExpectArrayViewsEquality(out_view, out_wrapper_view);
+
+  // Copy the FFT results into the input buffers to compute the backward FFT.
+  std::copy(out_view.begin(), out_view.end(), in_view.begin());
+  std::copy(out_wrapper_view.begin(), out_wrapper_view.end(),
+            in_wrapper_view.begin());
+
+  // Backward transform.
+  pffft_transform(pffft_status, in, out, scratch, PFFFT_BACKWARD);
+  pffft_wrapper.BackwardTransform(*in_wrapper, out_wrapper.get(),
+                                  /*ordered=*/false);
+  ExpectArrayViewsEquality(out_view, out_wrapper_view);
+
+  pffft_destroy_setup(pffft_status);
+  pffft_aligned_free(in);
+  pffft_aligned_free(out);
+  pffft_aligned_free(scratch);
+}
+
+}  // namespace
+
+TEST(PffftTest, CreateWrapperWithValidSize) {
+  for (size_t fft_size = 0; fft_size < kMaxValidSizeCheck; ++fft_size) {
+    SCOPED_TRACE(fft_size);
+    if (Pffft::IsValidFftSize(fft_size, Pffft::FftType::kReal)) {
+      CreatePffftWrapper(fft_size, Pffft::FftType::kReal);
+    }
+    if (Pffft::IsValidFftSize(fft_size, Pffft::FftType::kComplex)) {
+      CreatePffftWrapper(fft_size, Pffft::FftType::kComplex);
+    }
+  }
+}
+
+#if !defined(NDEBUG) && GTEST_HAS_DEATH_TEST && !defined(WEBRTC_ANDROID)
+
+class PffftInvalidSizeDeathTest : public ::testing::Test,
+                                  public ::testing::WithParamInterface<size_t> {
+};
+
+TEST_P(PffftInvalidSizeDeathTest, DoNotCreateRealWrapper) {
+  size_t fft_size = GetParam();
+  ASSERT_FALSE(Pffft::IsValidFftSize(fft_size, Pffft::FftType::kReal));
+  EXPECT_DEATH(CreatePffftWrapper(fft_size, Pffft::FftType::kReal), "");
+}
+
+TEST_P(PffftInvalidSizeDeathTest, DoNotCreateComplexWrapper) {
+  size_t fft_size = GetParam();
+  ASSERT_FALSE(Pffft::IsValidFftSize(fft_size, Pffft::FftType::kComplex));
+  EXPECT_DEATH(CreatePffftWrapper(fft_size, Pffft::FftType::kComplex), "");
+}
+
+INSTANTIATE_TEST_SUITE_P(PffftTest,
+                         PffftInvalidSizeDeathTest,
+                         ::testing::Values(17,
+                                           33,
+                                           65,
+                                           97,
+                                           129,
+                                           161,
+                                           193,
+                                           257,
+                                           289,
+                                           385,
+                                           481,
+                                           513,
+                                           577,
+                                           641,
+                                           801,
+                                           865,
+                                           1025));
+
+#endif
+
+// TODO(https://crbug.com/webrtc/9577): Enable once SIMD is always enabled.
+TEST(PffftTest, DISABLED_CheckSimd) {
+  EXPECT_TRUE(Pffft::IsSimdEnabled());
+}
+
+TEST(PffftTest, FftBitExactness) {
+  for (int fft_size : kFftSizes) {
+    SCOPED_TRACE(fft_size);
+    if (fft_size != 16) {
+      PffftValidateWrapper(fft_size, /*complex_fft=*/false);
+    }
+    PffftValidateWrapper(fft_size, /*complex_fft=*/true);
+  }
+}
+
+}  // namespace test
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/rtc_base/arraysize.h b/third_party/webrtc_aec3/src/rtc_base/arraysize.h
new file mode 100644
index 0000000..bf8e6d8
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/arraysize.h
@@ -0,0 +1,32 @@
+/*
+ *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_ARRAYSIZE_H_
+#define RTC_BASE_ARRAYSIZE_H_
+
+#include <stddef.h>
+
+// This file defines the arraysize() macro and is derived from Chromium's
+// base/macros.h.
+
+// The arraysize(arr) macro returns the # of elements in an array arr.
+// The expression is a compile-time constant, and therefore can be
+// used in defining new arrays, for example.  If you use arraysize on
+// a pointer by mistake, you will get a compile-time error.
+
+// This template function declaration is used in defining arraysize.
+// Note that the function doesn't need an implementation, as we only
+// use its type.
+template <typename T, size_t N>
+char (&ArraySizeHelper(T (&array)[N]))[N];
+
+#define arraysize(array) (sizeof(ArraySizeHelper(array)))
+
+#endif  // RTC_BASE_ARRAYSIZE_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/atomic_ops.h b/third_party/webrtc_aec3/src/rtc_base/atomic_ops.h
new file mode 100644
index 0000000..18a24a8
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/atomic_ops.h
@@ -0,0 +1,79 @@
+/*
+ *  Copyright 2011 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_ATOMIC_OPS_H_
+#define RTC_BASE_ATOMIC_OPS_H_
+
+#if defined(WEBRTC_WIN)
+// clang-format off
+// clang formating would change include order.
+
+// Include winsock2.h before including <windows.h> to maintain consistency with
+// win32.h. To include win32.h directly, it must be broken out into its own
+// build target.
+#include <winsock2.h>
+#include <windows.h>
+// clang-format on
+#endif  // defined(WEBRTC_WIN)
+
+namespace rtc {
+class AtomicOps {
+ public:
+#if defined(WEBRTC_WIN)
+  // Assumes sizeof(int) == sizeof(LONG), which it is on Win32 and Win64.
+  static int Increment(volatile int* i) {
+    return ::InterlockedIncrement(reinterpret_cast<volatile LONG*>(i));
+  }
+  static int Decrement(volatile int* i) {
+    return ::InterlockedDecrement(reinterpret_cast<volatile LONG*>(i));
+  }
+  static int AcquireLoad(volatile const int* i) { return *i; }
+  static void ReleaseStore(volatile int* i, int value) { *i = value; }
+  static int CompareAndSwap(volatile int* i, int old_value, int new_value) {
+    return ::InterlockedCompareExchange(reinterpret_cast<volatile LONG*>(i),
+                                        new_value, old_value);
+  }
+  // Pointer variants.
+  template <typename T>
+  static T* AcquireLoadPtr(T* volatile* ptr) {
+    return *ptr;
+  }
+  template <typename T>
+  static T* CompareAndSwapPtr(T* volatile* ptr, T* old_value, T* new_value) {
+    return static_cast<T*>(::InterlockedCompareExchangePointer(
+        reinterpret_cast<PVOID volatile*>(ptr), new_value, old_value));
+  }
+#else
+  static int Increment(volatile int* i) { return __sync_add_and_fetch(i, 1); }
+  static int Decrement(volatile int* i) { return __sync_sub_and_fetch(i, 1); }
+  static int AcquireLoad(volatile const int* i) {
+    return __atomic_load_n(i, __ATOMIC_ACQUIRE);
+  }
+  static void ReleaseStore(volatile int* i, int value) {
+    __atomic_store_n(i, value, __ATOMIC_RELEASE);
+  }
+  static int CompareAndSwap(volatile int* i, int old_value, int new_value) {
+    return __sync_val_compare_and_swap(i, old_value, new_value);
+  }
+  // Pointer variants.
+  template <typename T>
+  static T* AcquireLoadPtr(T* volatile* ptr) {
+    return __atomic_load_n(ptr, __ATOMIC_ACQUIRE);
+  }
+  template <typename T>
+  static T* CompareAndSwapPtr(T* volatile* ptr, T* old_value, T* new_value) {
+    return __sync_val_compare_and_swap(ptr, old_value, new_value);
+  }
+#endif
+};
+
+}  // namespace rtc
+
+#endif  // RTC_BASE_ATOMIC_OPS_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/checks.cc b/third_party/webrtc_aec3/src/rtc_base/checks.cc
new file mode 100644
index 0000000..239ea9f
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/checks.cc
@@ -0,0 +1,228 @@
+/*
+ *  Copyright 2006 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// Most of this was borrowed (with minor modifications) from V8's and Chromium's
+// src/base/logging.cc.
+
+#include <cstdarg>
+#include <cstdio>
+#include <cstdlib>
+
+#if defined(WEBRTC_ANDROID)
+#define RTC_LOG_TAG_ANDROID "rtc"
+#include <android/log.h>  // NOLINT
+#endif
+
+#if defined(WEBRTC_WIN)
+#include <windows.h>
+#endif
+
+#if defined(WEBRTC_WIN)
+#define LAST_SYSTEM_ERROR (::GetLastError())
+#elif defined(__native_client__) && __native_client__
+#define LAST_SYSTEM_ERROR (0)
+#elif defined(WEBRTC_POSIX)
+#include <errno.h>
+#define LAST_SYSTEM_ERROR (errno)
+#endif  // WEBRTC_WIN
+
+#include "rtc_base/checks.h"
+
+namespace {
+
+RTC_NORETURN void WriteFatalLogAndAbort(const std::string& output) {
+  const char* output_c = output.c_str();
+#if defined(WEBRTC_ANDROID)
+  __android_log_print(ANDROID_LOG_ERROR, RTC_LOG_TAG_ANDROID, "%s\n", output_c);
+#endif
+  fflush(stdout);
+  fprintf(stderr, "%s", output_c);
+  fflush(stderr);
+#if defined(WEBRTC_WIN)
+  DebugBreak();
+#endif
+  abort();
+}
+
+#if defined(__GNUC__)
+__attribute__((__format__(__printf__, 2, 3)))
+#endif
+void AppendFormat(std::string* s, const char* fmt, ...) {
+  va_list args, copy;
+  va_start(args, fmt);
+  va_copy(copy, args);
+  const int predicted_length = std::vsnprintf(nullptr, 0, fmt, copy);
+  va_end(copy);
+
+  if (predicted_length > 0) {
+    const size_t size = s->size();
+    s->resize(size + predicted_length);
+    // Pass "+ 1" to vsnprintf to include space for the '\0'.
+    std::vsnprintf(&((*s)[size]), predicted_length + 1, fmt, args);
+  }
+  va_end(args);
+}
+}  // namespace
+
+namespace rtc {
+namespace webrtc_checks_impl {
+
+#if RTC_CHECK_MSG_ENABLED
+// Reads one argument from args, appends it to s and advances fmt.
+// Returns true iff an argument was sucessfully parsed.
+bool ParseArg(va_list* args, const CheckArgType** fmt, std::string* s) {
+  if (**fmt == CheckArgType::kEnd)
+    return false;
+
+  switch (**fmt) {
+    case CheckArgType::kInt:
+      AppendFormat(s, "%d", va_arg(*args, int));
+      break;
+    case CheckArgType::kLong:
+      AppendFormat(s, "%ld", va_arg(*args, long));
+      break;
+    case CheckArgType::kLongLong:
+      AppendFormat(s, "%lld", va_arg(*args, long long));
+      break;
+    case CheckArgType::kUInt:
+      AppendFormat(s, "%u", va_arg(*args, unsigned));
+      break;
+    case CheckArgType::kULong:
+      AppendFormat(s, "%lu", va_arg(*args, unsigned long));
+      break;
+    case CheckArgType::kULongLong:
+      AppendFormat(s, "%llu", va_arg(*args, unsigned long long));
+      break;
+    case CheckArgType::kDouble:
+      AppendFormat(s, "%g", va_arg(*args, double));
+      break;
+    case CheckArgType::kLongDouble:
+      AppendFormat(s, "%Lg", va_arg(*args, long double));
+      break;
+    case CheckArgType::kCharP:
+      s->append(va_arg(*args, const char*));
+      break;
+    case CheckArgType::kStdString:
+      s->append(*va_arg(*args, const std::string*));
+      break;
+    case CheckArgType::kStringView: {
+      const absl::string_view sv = *va_arg(*args, const absl::string_view*);
+      s->append(sv.data(), sv.size());
+      break;
+    }
+    case CheckArgType::kVoidP:
+      AppendFormat(s, "%p", va_arg(*args, const void*));
+      break;
+    default:
+      s->append("[Invalid CheckArgType]");
+      return false;
+  }
+  (*fmt)++;
+  return true;
+}
+
+RTC_NORETURN void FatalLog(const char* file,
+                           int line,
+                           const char* message,
+                           const CheckArgType* fmt,
+                           ...) {
+  va_list args;
+  va_start(args, fmt);
+
+  std::string s;
+  AppendFormat(&s,
+               "\n\n"
+               "#\n"
+               "# Fatal error in: %s, line %d\n"
+               "# last system error: %u\n"
+               "# Check failed: %s",
+               file, line, LAST_SYSTEM_ERROR, message);
+
+  if (*fmt == CheckArgType::kCheckOp) {
+    // This log message was generated by RTC_CHECK_OP, so we have to complete
+    // the error message using the operands that have been passed as the first
+    // two arguments.
+    fmt++;
+
+    std::string s1, s2;
+    if (ParseArg(&args, &fmt, &s1) && ParseArg(&args, &fmt, &s2))
+      AppendFormat(&s, " (%s vs. %s)\n# ", s1.c_str(), s2.c_str());
+  } else {
+    s.append("\n# ");
+  }
+
+  // Append all the user-supplied arguments to the message.
+  while (ParseArg(&args, &fmt, &s))
+    ;
+
+  va_end(args);
+
+  WriteFatalLogAndAbort(s);
+}
+#else  // RTC_CHECK_MSG_ENABLED
+RTC_NORETURN void FatalLog(const char* file, int line) {
+  std::string s;
+  AppendFormat(&s,
+               "\n\n"
+               "#\n"
+               "# Fatal error in: %s, line %d\n"
+               "# last system error: %u\n"
+               "# Check failed.\n"
+               "# ",
+               file, line, LAST_SYSTEM_ERROR);
+  WriteFatalLogAndAbort(s);
+}
+#endif  // RTC_CHECK_MSG_ENABLED
+
+#if RTC_DCHECK_IS_ON
+
+RTC_NORETURN void UnreachableCodeReached(const char* file, int line) {
+  std::string s;
+  AppendFormat(&s,
+               "\n\n"
+               "#\n"
+               "# Unreachable code reached: %s, line %d\n"
+               "# last system error: %u\n"
+               "# ",
+               file, line, LAST_SYSTEM_ERROR);
+  WriteFatalLogAndAbort(s);
+}
+
+#else  // !RTC_DCHECK_IS_ON
+
+RTC_NORETURN void UnreachableCodeReached() {
+  std::string s;
+  AppendFormat(&s,
+               "\n\n"
+               "#\n"
+               "# Unreachable code reached (file and line unknown)\n"
+               "# last system error: %u\n"
+               "# ",
+               LAST_SYSTEM_ERROR);
+  WriteFatalLogAndAbort(s);
+}
+
+#endif  // !RTC_DCHECK_IS_ON
+
+}  // namespace webrtc_checks_impl
+}  // namespace rtc
+
+// Function to call from the C version of the RTC_CHECK and RTC_DCHECK macros.
+RTC_NORETURN void rtc_FatalMessage(const char* file,
+                                   int line,
+                                   const char* msg) {
+#if RTC_CHECK_MSG_ENABLED
+  static constexpr rtc::webrtc_checks_impl::CheckArgType t[] = {
+      rtc::webrtc_checks_impl::CheckArgType::kEnd};
+  rtc::webrtc_checks_impl::FatalLog(file, line, msg, t);
+#else
+  rtc::webrtc_checks_impl::FatalLog(file, line);
+#endif
+}
diff --git a/third_party/webrtc_aec3/src/rtc_base/checks.h b/third_party/webrtc_aec3/src/rtc_base/checks.h
new file mode 100644
index 0000000..21fca7e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/checks.h
@@ -0,0 +1,508 @@
+/*
+ *  Copyright 2006 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_CHECKS_H_
+#define RTC_BASE_CHECKS_H_
+
+// If you for some reson need to know if DCHECKs are on, test the value of
+// RTC_DCHECK_IS_ON. (Test its value, not if it's defined; it'll always be
+// defined, to either a true or a false value.)
+#if !defined(NDEBUG) || defined(DCHECK_ALWAYS_ON)
+#define RTC_DCHECK_IS_ON 1
+#else
+#define RTC_DCHECK_IS_ON 0
+#endif
+
+// Annotate a function that will not return control flow to the caller.
+#if defined(_MSC_VER)
+#define RTC_NORETURN __declspec(noreturn)
+#elif defined(__GNUC__)
+#define RTC_NORETURN __attribute__((__noreturn__))
+#else
+#define RTC_NORETURN
+#endif
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+RTC_NORETURN void rtc_FatalMessage(const char* file, int line, const char* msg);
+#ifdef __cplusplus
+}  // extern "C"
+#endif
+
+#ifdef RTC_DISABLE_CHECK_MSG
+#define RTC_CHECK_MSG_ENABLED 0
+#else
+#define RTC_CHECK_MSG_ENABLED 1
+#endif
+
+#if RTC_CHECK_MSG_ENABLED
+#define RTC_CHECK_EVAL_MESSAGE(message) message
+#else
+#define RTC_CHECK_EVAL_MESSAGE(message) ""
+#endif
+
+#ifdef __cplusplus
+// C++ version.
+
+#include <string>
+
+#include "absl/meta/type_traits.h"
+#include "absl/strings/string_view.h"
+#include "rtc_base/numerics/safe_compare.h"
+#include "rtc_base/system/inline.h"
+#include "rtc_base/system/rtc_export.h"
+
+// The macros here print a message to stderr and abort under various
+// conditions. All will accept additional stream messages. For example:
+// RTC_DCHECK_EQ(foo, bar) << "I'm printed when foo != bar.";
+//
+// - RTC_CHECK(x) is an assertion that x is always true, and that if it isn't,
+//   it's better to terminate the process than to continue. During development,
+//   the reason that it's better to terminate might simply be that the error
+//   handling code isn't in place yet; in production, the reason might be that
+//   the author of the code truly believes that x will always be true, but that
+//   they recognizes that if they are wrong, abrupt and unpleasant process
+//   termination is still better than carrying on with the assumption violated.
+//
+//   RTC_CHECK always evaluates its argument, so it's OK for x to have side
+//   effects.
+//
+// - RTC_DCHECK(x) is the same as RTC_CHECK(x)---an assertion that x is always
+//   true---except that x will only be evaluated in debug builds; in production
+//   builds, x is simply assumed to be true. This is useful if evaluating x is
+//   expensive and the expected cost of failing to detect the violated
+//   assumption is acceptable. You should not handle cases where a production
+//   build fails to spot a violated condition, even those that would result in
+//   crashes. If the code needs to cope with the error, make it cope, but don't
+//   call RTC_DCHECK; if the condition really can't occur, but you'd sleep
+//   better at night knowing that the process will suicide instead of carrying
+//   on in case you were wrong, use RTC_CHECK instead of RTC_DCHECK.
+//
+//   RTC_DCHECK only evaluates its argument in debug builds, so if x has visible
+//   side effects, you need to write e.g.
+//     bool w = x; RTC_DCHECK(w);
+//
+// - RTC_CHECK_EQ, _NE, _GT, ..., and RTC_DCHECK_EQ, _NE, _GT, ... are
+//   specialized variants of RTC_CHECK and RTC_DCHECK that print prettier
+//   messages if the condition doesn't hold. Prefer them to raw RTC_CHECK and
+//   RTC_DCHECK.
+//
+// - RTC_FATAL() aborts unconditionally.
+
+namespace rtc {
+namespace webrtc_checks_impl {
+enum class CheckArgType : int8_t {
+  kEnd = 0,
+  kInt,
+  kLong,
+  kLongLong,
+  kUInt,
+  kULong,
+  kULongLong,
+  kDouble,
+  kLongDouble,
+  kCharP,
+  kStdString,
+  kStringView,
+  kVoidP,
+
+  // kCheckOp doesn't represent an argument type. Instead, it is sent as the
+  // first argument from RTC_CHECK_OP to make FatalLog use the next two
+  // arguments to build the special CHECK_OP error message
+  // (the "a == b (1 vs. 2)" bit).
+  kCheckOp,
+};
+
+#if RTC_CHECK_MSG_ENABLED
+RTC_NORETURN RTC_EXPORT void FatalLog(const char* file,
+                                      int line,
+                                      const char* message,
+                                      const CheckArgType* fmt,
+                                      ...);
+#else
+RTC_NORETURN RTC_EXPORT void FatalLog(const char* file, int line);
+#endif
+
+// Wrapper for log arguments. Only ever make values of this type with the
+// MakeVal() functions.
+template <CheckArgType N, typename T>
+struct Val {
+  static constexpr CheckArgType Type() { return N; }
+  T GetVal() const { return val; }
+  T val;
+};
+
+// Case for when we need to construct a temp string and then print that.
+// (We can't use Val<CheckArgType::kStdString, const std::string*>
+// because we need somewhere to store the temp string.)
+struct ToStringVal {
+  static constexpr CheckArgType Type() { return CheckArgType::kStdString; }
+  const std::string* GetVal() const { return &val; }
+  std::string val;
+};
+
+inline Val<CheckArgType::kInt, int> MakeVal(int x) {
+  return {x};
+}
+inline Val<CheckArgType::kLong, long> MakeVal(long x) {
+  return {x};
+}
+inline Val<CheckArgType::kLongLong, long long> MakeVal(long long x) {
+  return {x};
+}
+inline Val<CheckArgType::kUInt, unsigned int> MakeVal(unsigned int x) {
+  return {x};
+}
+inline Val<CheckArgType::kULong, unsigned long> MakeVal(unsigned long x) {
+  return {x};
+}
+inline Val<CheckArgType::kULongLong, unsigned long long> MakeVal(
+    unsigned long long x) {
+  return {x};
+}
+
+inline Val<CheckArgType::kDouble, double> MakeVal(double x) {
+  return {x};
+}
+inline Val<CheckArgType::kLongDouble, long double> MakeVal(long double x) {
+  return {x};
+}
+
+inline Val<CheckArgType::kCharP, const char*> MakeVal(const char* x) {
+  return {x};
+}
+inline Val<CheckArgType::kStdString, const std::string*> MakeVal(
+    const std::string& x) {
+  return {&x};
+}
+inline Val<CheckArgType::kStringView, const absl::string_view*> MakeVal(
+    const absl::string_view& x) {
+  return {&x};
+}
+
+inline Val<CheckArgType::kVoidP, const void*> MakeVal(const void* x) {
+  return {x};
+}
+
+// The enum class types are not implicitly convertible to arithmetic types.
+template <typename T,
+          absl::enable_if_t<std::is_enum<T>::value &&
+                            !std::is_arithmetic<T>::value>* = nullptr>
+inline decltype(MakeVal(std::declval<absl::underlying_type_t<T>>())) MakeVal(
+    T x) {
+  return {static_cast<absl::underlying_type_t<T>>(x)};
+}
+
+template <typename T, decltype(ToLogString(std::declval<T>()))* = nullptr>
+ToStringVal MakeVal(const T& x) {
+  return {ToLogString(x)};
+}
+
+// Ephemeral type that represents the result of the logging << operator.
+template <typename... Ts>
+class LogStreamer;
+
+// Base case: Before the first << argument.
+template <>
+class LogStreamer<> final {
+ public:
+  template <typename U,
+            typename V = decltype(MakeVal(std::declval<U>())),
+            absl::enable_if_t<std::is_arithmetic<U>::value ||
+                              std::is_enum<U>::value>* = nullptr>
+  RTC_FORCE_INLINE LogStreamer<V> operator<<(U arg) const {
+    return LogStreamer<V>(MakeVal(arg), this);
+  }
+
+  template <typename U,
+            typename V = decltype(MakeVal(std::declval<U>())),
+            absl::enable_if_t<!std::is_arithmetic<U>::value &&
+                              !std::is_enum<U>::value>* = nullptr>
+  RTC_FORCE_INLINE LogStreamer<V> operator<<(const U& arg) const {
+    return LogStreamer<V>(MakeVal(arg), this);
+  }
+
+#if RTC_CHECK_MSG_ENABLED
+  template <typename... Us>
+  RTC_NORETURN RTC_FORCE_INLINE static void Call(const char* file,
+                                                 const int line,
+                                                 const char* message,
+                                                 const Us&... args) {
+    static constexpr CheckArgType t[] = {Us::Type()..., CheckArgType::kEnd};
+    FatalLog(file, line, message, t, args.GetVal()...);
+  }
+
+  template <typename... Us>
+  RTC_NORETURN RTC_FORCE_INLINE static void CallCheckOp(const char* file,
+                                                        const int line,
+                                                        const char* message,
+                                                        const Us&... args) {
+    static constexpr CheckArgType t[] = {CheckArgType::kCheckOp, Us::Type()...,
+                                         CheckArgType::kEnd};
+    FatalLog(file, line, message, t, args.GetVal()...);
+  }
+#else
+  template <typename... Us>
+  RTC_NORETURN RTC_FORCE_INLINE static void Call(const char* file,
+                                                 const int line) {
+    FatalLog(file, line);
+  }
+#endif
+};
+
+// Inductive case: We've already seen at least one << argument. The most recent
+// one had type `T`, and the earlier ones had types `Ts`.
+template <typename T, typename... Ts>
+class LogStreamer<T, Ts...> final {
+ public:
+  RTC_FORCE_INLINE LogStreamer(T arg, const LogStreamer<Ts...>* prior)
+      : arg_(arg), prior_(prior) {}
+
+  template <typename U,
+            typename V = decltype(MakeVal(std::declval<U>())),
+            absl::enable_if_t<std::is_arithmetic<U>::value ||
+                              std::is_enum<U>::value>* = nullptr>
+  RTC_FORCE_INLINE LogStreamer<V, T, Ts...> operator<<(U arg) const {
+    return LogStreamer<V, T, Ts...>(MakeVal(arg), this);
+  }
+
+  template <typename U,
+            typename V = decltype(MakeVal(std::declval<U>())),
+            absl::enable_if_t<!std::is_arithmetic<U>::value &&
+                              !std::is_enum<U>::value>* = nullptr>
+  RTC_FORCE_INLINE LogStreamer<V, T, Ts...> operator<<(const U& arg) const {
+    return LogStreamer<V, T, Ts...>(MakeVal(arg), this);
+  }
+
+#if RTC_CHECK_MSG_ENABLED
+  template <typename... Us>
+  RTC_NORETURN RTC_FORCE_INLINE void Call(const char* file,
+                                          const int line,
+                                          const char* message,
+                                          const Us&... args) const {
+    prior_->Call(file, line, message, arg_, args...);
+  }
+
+  template <typename... Us>
+  RTC_NORETURN RTC_FORCE_INLINE void CallCheckOp(const char* file,
+                                                 const int line,
+                                                 const char* message,
+                                                 const Us&... args) const {
+    prior_->CallCheckOp(file, line, message, arg_, args...);
+  }
+#else
+  template <typename... Us>
+  RTC_NORETURN RTC_FORCE_INLINE void Call(const char* file,
+                                          const int line) const {
+    prior_->Call(file, line);
+  }
+#endif
+
+ private:
+  // The most recent argument.
+  T arg_;
+
+  // Earlier arguments.
+  const LogStreamer<Ts...>* prior_;
+};
+
+template <bool isCheckOp>
+class FatalLogCall final {
+ public:
+  FatalLogCall(const char* file, int line, const char* message)
+      : file_(file), line_(line), message_(message) {}
+
+  // This can be any binary operator with precedence lower than <<.
+  template <typename... Ts>
+  RTC_NORETURN RTC_FORCE_INLINE void operator&(
+      const LogStreamer<Ts...>& streamer) {
+#if RTC_CHECK_MSG_ENABLED
+    isCheckOp ? streamer.CallCheckOp(file_, line_, message_)
+              : streamer.Call(file_, line_, message_);
+#else
+    streamer.Call(file_, line_);
+#endif
+  }
+
+ private:
+  const char* file_;
+  int line_;
+  const char* message_;
+};
+
+#if RTC_DCHECK_IS_ON
+
+// Be helpful, and include file and line in the RTC_CHECK_NOTREACHED error
+// message.
+#define RTC_UNREACHABLE_FILE_AND_LINE_CALL_ARGS __FILE__, __LINE__
+RTC_NORETURN RTC_EXPORT void UnreachableCodeReached(const char* file, int line);
+
+#else
+
+// Be mindful of binary size, and don't include file and line in the
+// RTC_CHECK_NOTREACHED error message.
+#define RTC_UNREACHABLE_FILE_AND_LINE_CALL_ARGS
+RTC_NORETURN RTC_EXPORT void UnreachableCodeReached();
+
+#endif
+
+}  // namespace webrtc_checks_impl
+
+// The actual stream used isn't important. We reference |ignored| in the code
+// but don't evaluate it; this is to avoid "unused variable" warnings (we do so
+// in a particularly convoluted way with an extra ?: because that appears to be
+// the simplest construct that keeps Visual Studio from complaining about
+// condition being unused).
+#define RTC_EAT_STREAM_PARAMETERS(ignored)                          \
+  (true ? true : ((void)(ignored), true))                           \
+      ? static_cast<void>(0)                                        \
+      : ::rtc::webrtc_checks_impl::FatalLogCall<false>("", 0, "") & \
+            ::rtc::webrtc_checks_impl::LogStreamer<>()
+
+// Call RTC_EAT_STREAM_PARAMETERS with an argument that fails to compile if
+// values of the same types as |a| and |b| can't be compared with the given
+// operation, and that would evaluate |a| and |b| if evaluated.
+#define RTC_EAT_STREAM_PARAMETERS_OP(op, a, b) \
+  RTC_EAT_STREAM_PARAMETERS(((void)::rtc::Safe##op(a, b)))
+
+// RTC_CHECK dies with a fatal error if condition is not true. It is *not*
+// controlled by NDEBUG or anything else, so the check will be executed
+// regardless of compilation mode.
+//
+// We make sure RTC_CHECK et al. always evaluates |condition|, as
+// doing RTC_CHECK(FunctionWithSideEffect()) is a common idiom.
+//
+// RTC_CHECK_OP is a helper macro for binary operators.
+// Don't use this macro directly in your code, use RTC_CHECK_EQ et al below.
+#if RTC_CHECK_MSG_ENABLED
+#define RTC_CHECK(condition)                                    \
+  (condition) ? static_cast<void>(0)                            \
+              : ::rtc::webrtc_checks_impl::FatalLogCall<false>( \
+                    __FILE__, __LINE__, #condition) &           \
+                    ::rtc::webrtc_checks_impl::LogStreamer<>()
+
+#define RTC_CHECK_OP(name, op, val1, val2)                 \
+  ::rtc::Safe##name((val1), (val2))                        \
+      ? static_cast<void>(0)                               \
+      : ::rtc::webrtc_checks_impl::FatalLogCall<true>(     \
+            __FILE__, __LINE__, #val1 " " #op " " #val2) & \
+            ::rtc::webrtc_checks_impl::LogStreamer<>() << (val1) << (val2)
+#else
+#define RTC_CHECK(condition)                                                  \
+  (condition)                                                                 \
+      ? static_cast<void>(0)                                                  \
+      : true ? ::rtc::webrtc_checks_impl::FatalLogCall<false>(__FILE__,       \
+                                                              __LINE__, "") & \
+                   ::rtc::webrtc_checks_impl::LogStreamer<>()                 \
+             : ::rtc::webrtc_checks_impl::FatalLogCall<false>("", 0, "") &    \
+                   ::rtc::webrtc_checks_impl::LogStreamer<>()
+
+#define RTC_CHECK_OP(name, op, val1, val2)                                   \
+  ::rtc::Safe##name((val1), (val2))                                          \
+      ? static_cast<void>(0)                                                 \
+      : true ? ::rtc::webrtc_checks_impl::FatalLogCall<true>(__FILE__,       \
+                                                             __LINE__, "") & \
+                   ::rtc::webrtc_checks_impl::LogStreamer<>()                \
+             : ::rtc::webrtc_checks_impl::FatalLogCall<false>("", 0, "") &   \
+                   ::rtc::webrtc_checks_impl::LogStreamer<>()
+#endif
+
+#define RTC_CHECK_EQ(val1, val2) RTC_CHECK_OP(Eq, ==, val1, val2)
+#define RTC_CHECK_NE(val1, val2) RTC_CHECK_OP(Ne, !=, val1, val2)
+#define RTC_CHECK_LE(val1, val2) RTC_CHECK_OP(Le, <=, val1, val2)
+#define RTC_CHECK_LT(val1, val2) RTC_CHECK_OP(Lt, <, val1, val2)
+#define RTC_CHECK_GE(val1, val2) RTC_CHECK_OP(Ge, >=, val1, val2)
+#define RTC_CHECK_GT(val1, val2) RTC_CHECK_OP(Gt, >, val1, val2)
+
+// The RTC_DCHECK macro is equivalent to RTC_CHECK except that it only generates
+// code in debug builds. It does reference the condition parameter in all cases,
+// though, so callers won't risk getting warnings about unused variables.
+#if RTC_DCHECK_IS_ON
+#define RTC_DCHECK(condition) RTC_CHECK(condition)
+#define RTC_DCHECK_EQ(v1, v2) RTC_CHECK_EQ(v1, v2)
+#define RTC_DCHECK_NE(v1, v2) RTC_CHECK_NE(v1, v2)
+#define RTC_DCHECK_LE(v1, v2) RTC_CHECK_LE(v1, v2)
+#define RTC_DCHECK_LT(v1, v2) RTC_CHECK_LT(v1, v2)
+#define RTC_DCHECK_GE(v1, v2) RTC_CHECK_GE(v1, v2)
+#define RTC_DCHECK_GT(v1, v2) RTC_CHECK_GT(v1, v2)
+#else
+#define RTC_DCHECK(condition) RTC_EAT_STREAM_PARAMETERS(condition)
+#define RTC_DCHECK_EQ(v1, v2) RTC_EAT_STREAM_PARAMETERS_OP(Eq, v1, v2)
+#define RTC_DCHECK_NE(v1, v2) RTC_EAT_STREAM_PARAMETERS_OP(Ne, v1, v2)
+#define RTC_DCHECK_LE(v1, v2) RTC_EAT_STREAM_PARAMETERS_OP(Le, v1, v2)
+#define RTC_DCHECK_LT(v1, v2) RTC_EAT_STREAM_PARAMETERS_OP(Lt, v1, v2)
+#define RTC_DCHECK_GE(v1, v2) RTC_EAT_STREAM_PARAMETERS_OP(Ge, v1, v2)
+#define RTC_DCHECK_GT(v1, v2) RTC_EAT_STREAM_PARAMETERS_OP(Gt, v1, v2)
+#endif
+
+#define RTC_UNREACHABLE_CODE_HIT false
+#define RTC_NOTREACHED() RTC_DCHECK(RTC_UNREACHABLE_CODE_HIT)
+
+// Kills the process with an error message. Never returns. Use when you wish to
+// assert that a point in the code is never reached.
+#define RTC_CHECK_NOTREACHED()                         \
+  do {                                                 \
+    ::rtc::webrtc_checks_impl::UnreachableCodeReached( \
+        RTC_UNREACHABLE_FILE_AND_LINE_CALL_ARGS);      \
+  } while (0)
+
+#define RTC_FATAL()                                                  \
+  ::rtc::webrtc_checks_impl::FatalLogCall<false>(__FILE__, __LINE__, \
+                                                 "FATAL()") &        \
+      ::rtc::webrtc_checks_impl::LogStreamer<>()
+
+// Performs the integer division a/b and returns the result. CHECKs that the
+// remainder is zero.
+template <typename T>
+inline T CheckedDivExact(T a, T b) {
+  RTC_CHECK_EQ(a % b, 0) << a << " is not evenly divisible by " << b;
+  return a / b;
+}
+
+}  // namespace rtc
+
+#else  // __cplusplus not defined
+// C version. Lacks many features compared to the C++ version, but usage
+// guidelines are the same.
+
+#define RTC_CHECK(condition)                                                 \
+  do {                                                                       \
+    if (!(condition)) {                                                      \
+      rtc_FatalMessage(__FILE__, __LINE__,                                   \
+                       RTC_CHECK_EVAL_MESSAGE("CHECK failed: " #condition)); \
+    }                                                                        \
+  } while (0)
+
+#define RTC_CHECK_EQ(a, b) RTC_CHECK((a) == (b))
+#define RTC_CHECK_NE(a, b) RTC_CHECK((a) != (b))
+#define RTC_CHECK_LE(a, b) RTC_CHECK((a) <= (b))
+#define RTC_CHECK_LT(a, b) RTC_CHECK((a) < (b))
+#define RTC_CHECK_GE(a, b) RTC_CHECK((a) >= (b))
+#define RTC_CHECK_GT(a, b) RTC_CHECK((a) > (b))
+
+#define RTC_DCHECK(condition)                                                 \
+  do {                                                                        \
+    if (RTC_DCHECK_IS_ON && !(condition)) {                                   \
+      rtc_FatalMessage(__FILE__, __LINE__,                                    \
+                       RTC_CHECK_EVAL_MESSAGE("DCHECK failed: " #condition)); \
+    }                                                                         \
+  } while (0)
+
+#define RTC_DCHECK_EQ(a, b) RTC_DCHECK((a) == (b))
+#define RTC_DCHECK_NE(a, b) RTC_DCHECK((a) != (b))
+#define RTC_DCHECK_LE(a, b) RTC_DCHECK((a) <= (b))
+#define RTC_DCHECK_LT(a, b) RTC_DCHECK((a) < (b))
+#define RTC_DCHECK_GE(a, b) RTC_DCHECK((a) >= (b))
+#define RTC_DCHECK_GT(a, b) RTC_DCHECK((a) > (b))
+
+#endif  // __cplusplus
+
+#endif  // RTC_BASE_CHECKS_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/compile_assert_c.h b/third_party/webrtc_aec3/src/rtc_base/compile_assert_c.h
new file mode 100644
index 0000000..db2e4a8
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/compile_assert_c.h
@@ -0,0 +1,25 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_COMPILE_ASSERT_C_H_
+#define RTC_BASE_COMPILE_ASSERT_C_H_
+
+// Use this macro to verify at compile time that certain restrictions are met.
+// The argument is the boolean expression to evaluate.
+// Example:
+//   RTC_COMPILE_ASSERT(sizeof(foo) < 128);
+// Note: In C++, use static_assert instead!
+#define RTC_COMPILE_ASSERT(expression) \
+  switch (0) {                         \
+    case 0:                            \
+    case expression:;                  \
+  }
+
+#endif  // RTC_BASE_COMPILE_ASSERT_C_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/constructor_magic.h b/third_party/webrtc_aec3/src/rtc_base/constructor_magic.h
new file mode 100644
index 0000000..8d12a7b
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/constructor_magic.h
@@ -0,0 +1,20 @@
+/*
+ *  Copyright 2004 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_CONSTRUCTOR_MAGIC_H_
+#define RTC_BASE_CONSTRUCTOR_MAGIC_H_
+
+// A macro to disallow the copy constructor and operator= functions. This should
+// be used in the declarations for a class.
+#define RTC_DISALLOW_COPY_AND_ASSIGN(TypeName) \
+  TypeName(const TypeName&) = delete;          \
+  TypeName& operator=(const TypeName&) = delete
+
+#endif  // RTC_BASE_CONSTRUCTOR_MAGIC_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/experiments/field_trial_parser.cc b/third_party/webrtc_aec3/src/rtc_base/experiments/field_trial_parser.cc
new file mode 100644
index 0000000..8fc89ce
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/experiments/field_trial_parser.cc
@@ -0,0 +1,250 @@
+/*
+ *  Copyright 2019 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "rtc_base/experiments/field_trial_parser.h"
+
+#include <inttypes.h>
+
+#include <algorithm>
+#include <map>
+#include <type_traits>
+#include <utility>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+#include "rtc_base/numerics/safe_conversions.h"
+
+namespace webrtc {
+namespace {
+
+int FindOrEnd(std::string str, size_t start, char delimiter) {
+  size_t pos = str.find(delimiter, start);
+  pos = (pos == std::string::npos) ? str.length() : pos;
+  return static_cast<int>(pos);
+}
+}  // namespace
+
+FieldTrialParameterInterface::FieldTrialParameterInterface(std::string key)
+    : key_(key) {}
+FieldTrialParameterInterface::~FieldTrialParameterInterface() {
+  RTC_DCHECK(used_) << "Field trial parameter with key: '" << key_
+                    << "' never used.";
+}
+
+void ParseFieldTrial(
+    std::initializer_list<FieldTrialParameterInterface*> fields,
+    std::string trial_string) {
+  std::map<std::string, FieldTrialParameterInterface*> field_map;
+  FieldTrialParameterInterface* keyless_field = nullptr;
+  for (FieldTrialParameterInterface* field : fields) {
+    field->MarkAsUsed();
+    if (!field->sub_parameters_.empty()) {
+      for (FieldTrialParameterInterface* sub_field : field->sub_parameters_) {
+        RTC_DCHECK(!sub_field->key_.empty());
+        sub_field->MarkAsUsed();
+        field_map[sub_field->key_] = sub_field;
+      }
+      continue;
+    }
+
+    if (field->key_.empty()) {
+      RTC_DCHECK(!keyless_field);
+      keyless_field = field;
+    } else {
+      field_map[field->key_] = field;
+    }
+  }
+
+  size_t i = 0;
+  while (i < trial_string.length()) {
+    int val_end = FindOrEnd(trial_string, i, ',');
+    int colon_pos = FindOrEnd(trial_string, i, ':');
+    int key_end = std::min(val_end, colon_pos);
+    int val_begin = key_end + 1;
+    std::string key = trial_string.substr(i, key_end - i);
+    absl::optional<std::string> opt_value;
+    if (val_end >= val_begin)
+      opt_value = trial_string.substr(val_begin, val_end - val_begin);
+    i = val_end + 1;
+    auto field = field_map.find(key);
+    if (field != field_map.end()) {
+      if (!field->second->Parse(std::move(opt_value))) {
+        RTC_LOG(LS_WARNING) << "Failed to read field with key: '" << key
+                            << "' in trial: \"" << trial_string << "\"";
+      }
+    } else if (!opt_value && keyless_field && !key.empty()) {
+      if (!keyless_field->Parse(key)) {
+        RTC_LOG(LS_WARNING) << "Failed to read empty key field with value '"
+                            << key << "' in trial: \"" << trial_string << "\"";
+      }
+    } else if (key.empty() || key[0] != '_') {
+      // "_" is be used to prefix keys that are part of the string for
+      // debugging purposes but not neccessarily used.
+      // e.g. WebRTC-Experiment/param: value, _DebuggingString
+      RTC_LOG(LS_INFO) << "No field with key: '" << key
+                       << "' (found in trial: \"" << trial_string << "\")";
+      std::string valid_keys;
+      for (const auto& f : field_map) {
+        valid_keys += f.first;
+        valid_keys += ", ";
+      }
+      RTC_LOG(LS_INFO) << "Valid keys are: " << valid_keys;
+    }
+  }
+
+  for (FieldTrialParameterInterface* field : fields) {
+    field->ParseDone();
+  }
+}
+
+template <>
+absl::optional<bool> ParseTypedParameter<bool>(std::string str) {
+  if (str == "true" || str == "1") {
+    return true;
+  } else if (str == "false" || str == "0") {
+    return false;
+  }
+  return absl::nullopt;
+}
+
+template <>
+absl::optional<double> ParseTypedParameter<double>(std::string str) {
+  double value;
+  char unit[2]{0, 0};
+  if (sscanf(str.c_str(), "%lf%1s", &value, unit) >= 1) {
+    if (unit[0] == '%')
+      return value / 100;
+    return value;
+  } else {
+    return absl::nullopt;
+  }
+}
+
+template <>
+absl::optional<int> ParseTypedParameter<int>(std::string str) {
+  int64_t value;
+  if (sscanf(str.c_str(), "%" SCNd64, &value) == 1) {
+    if (rtc::IsValueInRangeForNumericType<int, int64_t>(value)) {
+      return static_cast<int>(value);
+    }
+  }
+  return absl::nullopt;
+}
+
+template <>
+absl::optional<unsigned> ParseTypedParameter<unsigned>(std::string str) {
+  int64_t value;
+  if (sscanf(str.c_str(), "%" SCNd64, &value) == 1) {
+    if (rtc::IsValueInRangeForNumericType<unsigned, int64_t>(value)) {
+      return static_cast<unsigned>(value);
+    }
+  }
+  return absl::nullopt;
+}
+
+template <>
+absl::optional<std::string> ParseTypedParameter<std::string>(std::string str) {
+  return std::move(str);
+}
+
+template <>
+absl::optional<absl::optional<bool>> ParseTypedParameter<absl::optional<bool>>(
+    std::string str) {
+  return ParseOptionalParameter<bool>(str);
+}
+template <>
+absl::optional<absl::optional<int>> ParseTypedParameter<absl::optional<int>>(
+    std::string str) {
+  return ParseOptionalParameter<int>(str);
+}
+template <>
+absl::optional<absl::optional<unsigned>>
+ParseTypedParameter<absl::optional<unsigned>>(std::string str) {
+  return ParseOptionalParameter<unsigned>(str);
+}
+template <>
+absl::optional<absl::optional<double>>
+ParseTypedParameter<absl::optional<double>>(std::string str) {
+  return ParseOptionalParameter<double>(str);
+}
+
+FieldTrialFlag::FieldTrialFlag(std::string key) : FieldTrialFlag(key, false) {}
+
+FieldTrialFlag::FieldTrialFlag(std::string key, bool default_value)
+    : FieldTrialParameterInterface(key), value_(default_value) {}
+
+bool FieldTrialFlag::Get() const {
+  return value_;
+}
+
+webrtc::FieldTrialFlag::operator bool() const {
+  return value_;
+}
+
+bool FieldTrialFlag::Parse(absl::optional<std::string> str_value) {
+  // Only set the flag if there is no argument provided.
+  if (str_value) {
+    absl::optional<bool> opt_value = ParseTypedParameter<bool>(*str_value);
+    if (!opt_value)
+      return false;
+    value_ = *opt_value;
+  } else {
+    value_ = true;
+  }
+  return true;
+}
+
+AbstractFieldTrialEnum::AbstractFieldTrialEnum(
+    std::string key,
+    int default_value,
+    std::map<std::string, int> mapping)
+    : FieldTrialParameterInterface(key),
+      value_(default_value),
+      enum_mapping_(mapping) {
+  for (auto& key_val : enum_mapping_)
+    valid_values_.insert(key_val.second);
+}
+AbstractFieldTrialEnum::AbstractFieldTrialEnum(const AbstractFieldTrialEnum&) =
+    default;
+AbstractFieldTrialEnum::~AbstractFieldTrialEnum() = default;
+
+bool AbstractFieldTrialEnum::Parse(absl::optional<std::string> str_value) {
+  if (str_value) {
+    auto it = enum_mapping_.find(*str_value);
+    if (it != enum_mapping_.end()) {
+      value_ = it->second;
+      return true;
+    }
+    absl::optional<int> value = ParseTypedParameter<int>(*str_value);
+    if (value.has_value() &&
+        (valid_values_.find(*value) != valid_values_.end())) {
+      value_ = *value;
+      return true;
+    }
+  }
+  return false;
+}
+
+template class FieldTrialParameter<bool>;
+template class FieldTrialParameter<double>;
+template class FieldTrialParameter<int>;
+template class FieldTrialParameter<unsigned>;
+template class FieldTrialParameter<std::string>;
+
+template class FieldTrialConstrained<double>;
+template class FieldTrialConstrained<int>;
+template class FieldTrialConstrained<unsigned>;
+
+template class FieldTrialOptional<double>;
+template class FieldTrialOptional<int>;
+template class FieldTrialOptional<unsigned>;
+template class FieldTrialOptional<bool>;
+template class FieldTrialOptional<std::string>;
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/rtc_base/experiments/field_trial_parser.h b/third_party/webrtc_aec3/src/rtc_base/experiments/field_trial_parser.h
new file mode 100644
index 0000000..42535ed
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/experiments/field_trial_parser.h
@@ -0,0 +1,288 @@
+/*
+ *  Copyright 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#ifndef RTC_BASE_EXPERIMENTS_FIELD_TRIAL_PARSER_H_
+#define RTC_BASE_EXPERIMENTS_FIELD_TRIAL_PARSER_H_
+
+#include <stdint.h>
+
+#include <initializer_list>
+#include <map>
+#include <set>
+#include <string>
+#include <vector>
+
+#include "absl/types/optional.h"
+
+// Field trial parser functionality. Provides funcitonality to parse field trial
+// argument strings in key:value format. Each parameter is described using
+// key:value, parameters are separated with a ,. Values can't include the comma
+// character, since there's no quote facility. For most types, white space is
+// ignored. Parameters are declared with a given type for which an
+// implementation of ParseTypedParameter should be provided. The
+// ParseTypedParameter implementation is given whatever is between the : and the
+// ,. If the key is provided without : a FieldTrialOptional will use nullopt.
+
+// Example string: "my_optional,my_int:3,my_string:hello"
+
+// For further description of usage and behavior, see the examples in the unit
+// tests.
+
+namespace webrtc {
+class FieldTrialParameterInterface {
+ public:
+  virtual ~FieldTrialParameterInterface();
+  std::string key() const { return key_; }
+
+ protected:
+  // Protected to allow implementations to provide assignment and copy.
+  FieldTrialParameterInterface(const FieldTrialParameterInterface&) = default;
+  FieldTrialParameterInterface& operator=(const FieldTrialParameterInterface&) =
+      default;
+  explicit FieldTrialParameterInterface(std::string key);
+  friend void ParseFieldTrial(
+      std::initializer_list<FieldTrialParameterInterface*> fields,
+      std::string raw_string);
+  void MarkAsUsed() { used_ = true; }
+  virtual bool Parse(absl::optional<std::string> str_value) = 0;
+
+  virtual void ParseDone() {}
+
+  std::vector<FieldTrialParameterInterface*> sub_parameters_;
+
+ private:
+  std::string key_;
+  bool used_ = false;
+};
+
+// ParseFieldTrial function parses the given string and fills the given fields
+// with extracted values if available.
+void ParseFieldTrial(
+    std::initializer_list<FieldTrialParameterInterface*> fields,
+    std::string raw_string);
+
+// Specialize this in code file for custom types. Should return absl::nullopt if
+// the given string cannot be properly parsed.
+template <typename T>
+absl::optional<T> ParseTypedParameter(std::string);
+
+// This class uses the ParseTypedParameter function to implement a parameter
+// implementation with an enforced default value.
+template <typename T>
+class FieldTrialParameter : public FieldTrialParameterInterface {
+ public:
+  FieldTrialParameter(std::string key, T default_value)
+      : FieldTrialParameterInterface(key), value_(default_value) {}
+  T Get() const { return value_; }
+  operator T() const { return Get(); }
+  const T* operator->() const { return &value_; }
+
+  void SetForTest(T value) { value_ = value; }
+
+ protected:
+  bool Parse(absl::optional<std::string> str_value) override {
+    if (str_value) {
+      absl::optional<T> value = ParseTypedParameter<T>(*str_value);
+      if (value.has_value()) {
+        value_ = value.value();
+        return true;
+      }
+    }
+    return false;
+  }
+
+ private:
+  T value_;
+};
+
+// This class uses the ParseTypedParameter function to implement a parameter
+// implementation with an enforced default value and a range constraint. Values
+// outside the configured range will be ignored.
+template <typename T>
+class FieldTrialConstrained : public FieldTrialParameterInterface {
+ public:
+  FieldTrialConstrained(std::string key,
+                        T default_value,
+                        absl::optional<T> lower_limit,
+                        absl::optional<T> upper_limit)
+      : FieldTrialParameterInterface(key),
+        value_(default_value),
+        lower_limit_(lower_limit),
+        upper_limit_(upper_limit) {}
+  T Get() const { return value_; }
+  operator T() const { return Get(); }
+  const T* operator->() const { return &value_; }
+
+ protected:
+  bool Parse(absl::optional<std::string> str_value) override {
+    if (str_value) {
+      absl::optional<T> value = ParseTypedParameter<T>(*str_value);
+      if (value && (!lower_limit_ || *value >= *lower_limit_) &&
+          (!upper_limit_ || *value <= *upper_limit_)) {
+        value_ = *value;
+        return true;
+      }
+    }
+    return false;
+  }
+
+ private:
+  T value_;
+  absl::optional<T> lower_limit_;
+  absl::optional<T> upper_limit_;
+};
+
+class AbstractFieldTrialEnum : public FieldTrialParameterInterface {
+ public:
+  AbstractFieldTrialEnum(std::string key,
+                         int default_value,
+                         std::map<std::string, int> mapping);
+  ~AbstractFieldTrialEnum() override;
+  AbstractFieldTrialEnum(const AbstractFieldTrialEnum&);
+
+ protected:
+  bool Parse(absl::optional<std::string> str_value) override;
+
+ protected:
+  int value_;
+  std::map<std::string, int> enum_mapping_;
+  std::set<int> valid_values_;
+};
+
+// The FieldTrialEnum class can be used to quickly define a parser for a
+// specific enum. It handles values provided as integers and as strings if a
+// mapping is provided.
+template <typename T>
+class FieldTrialEnum : public AbstractFieldTrialEnum {
+ public:
+  FieldTrialEnum(std::string key,
+                 T default_value,
+                 std::map<std::string, T> mapping)
+      : AbstractFieldTrialEnum(key,
+                               static_cast<int>(default_value),
+                               ToIntMap(mapping)) {}
+  T Get() const { return static_cast<T>(value_); }
+  operator T() const { return Get(); }
+
+ private:
+  static std::map<std::string, int> ToIntMap(std::map<std::string, T> mapping) {
+    std::map<std::string, int> res;
+    for (const auto& it : mapping)
+      res[it.first] = static_cast<int>(it.second);
+    return res;
+  }
+};
+
+// This class uses the ParseTypedParameter function to implement an optional
+// parameter implementation that can default to absl::nullopt.
+template <typename T>
+class FieldTrialOptional : public FieldTrialParameterInterface {
+ public:
+  explicit FieldTrialOptional(std::string key)
+      : FieldTrialParameterInterface(key) {}
+  FieldTrialOptional(std::string key, absl::optional<T> default_value)
+      : FieldTrialParameterInterface(key), value_(default_value) {}
+  absl::optional<T> GetOptional() const { return value_; }
+  const T& Value() const { return value_.value(); }
+  const T& operator*() const { return value_.value(); }
+  const T* operator->() const { return &value_.value(); }
+  explicit operator bool() const { return value_.has_value(); }
+
+ protected:
+  bool Parse(absl::optional<std::string> str_value) override {
+    if (str_value) {
+      absl::optional<T> value = ParseTypedParameter<T>(*str_value);
+      if (!value.has_value())
+        return false;
+      value_ = value.value();
+    } else {
+      value_ = absl::nullopt;
+    }
+    return true;
+  }
+
+ private:
+  absl::optional<T> value_;
+};
+
+// Equivalent to a FieldTrialParameter<bool> in the case that both key and value
+// are present. If key is missing, evaluates to false. If key is present, but no
+// explicit value is provided, the flag evaluates to true.
+class FieldTrialFlag : public FieldTrialParameterInterface {
+ public:
+  explicit FieldTrialFlag(std::string key);
+  FieldTrialFlag(std::string key, bool default_value);
+  bool Get() const;
+  operator bool() const;
+
+ protected:
+  bool Parse(absl::optional<std::string> str_value) override;
+
+ private:
+  bool value_;
+};
+
+template <typename T>
+absl::optional<absl::optional<T>> ParseOptionalParameter(std::string str) {
+  if (str.empty())
+    return absl::optional<T>();
+  auto parsed = ParseTypedParameter<T>(str);
+  if (parsed.has_value())
+    return parsed;
+  return absl::nullopt;
+}
+
+template <>
+absl::optional<bool> ParseTypedParameter<bool>(std::string str);
+template <>
+absl::optional<double> ParseTypedParameter<double>(std::string str);
+template <>
+absl::optional<int> ParseTypedParameter<int>(std::string str);
+template <>
+absl::optional<unsigned> ParseTypedParameter<unsigned>(std::string str);
+template <>
+absl::optional<std::string> ParseTypedParameter<std::string>(std::string str);
+
+template <>
+absl::optional<absl::optional<bool>> ParseTypedParameter<absl::optional<bool>>(
+    std::string str);
+template <>
+absl::optional<absl::optional<int>> ParseTypedParameter<absl::optional<int>>(
+    std::string str);
+template <>
+absl::optional<absl::optional<unsigned>>
+ParseTypedParameter<absl::optional<unsigned>>(std::string str);
+template <>
+absl::optional<absl::optional<double>>
+ParseTypedParameter<absl::optional<double>>(std::string str);
+
+// Accepts true, false, else parsed with sscanf %i, true if != 0.
+extern template class FieldTrialParameter<bool>;
+// Interpreted using sscanf %lf.
+extern template class FieldTrialParameter<double>;
+// Interpreted using sscanf %i.
+extern template class FieldTrialParameter<int>;
+// Interpreted using sscanf %u.
+extern template class FieldTrialParameter<unsigned>;
+// Using the given value as is.
+extern template class FieldTrialParameter<std::string>;
+
+extern template class FieldTrialConstrained<double>;
+extern template class FieldTrialConstrained<int>;
+extern template class FieldTrialConstrained<unsigned>;
+
+extern template class FieldTrialOptional<double>;
+extern template class FieldTrialOptional<int>;
+extern template class FieldTrialOptional<unsigned>;
+extern template class FieldTrialOptional<bool>;
+extern template class FieldTrialOptional<std::string>;
+
+}  // namespace webrtc
+
+#endif  // RTC_BASE_EXPERIMENTS_FIELD_TRIAL_PARSER_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/gtest_prod_util.h b/third_party/webrtc_aec3/src/rtc_base/gtest_prod_util.h
new file mode 100644
index 0000000..0661cd7
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/gtest_prod_util.h
@@ -0,0 +1,38 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_GTEST_PROD_UTIL_H_
+#define RTC_BASE_GTEST_PROD_UTIL_H_
+
+// Define our own version of FRIEND_TEST here rather than including
+// gtest_prod.h to avoid depending on any part of GTest in production code.
+#define FRIEND_TEST_WEBRTC(test_case_name, test_name) \
+  friend class test_case_name##_##test_name##_Test
+
+// This file is a plain copy of Chromium's base/gtest_prod_util.h.
+//
+// This is a wrapper for gtest's FRIEND_TEST macro that friends
+// test with all possible prefixes. This is very helpful when changing the test
+// prefix, because the friend declarations don't need to be updated.
+//
+// Example usage:
+//
+// class MyClass {
+//  private:
+//   void MyMethod();
+//   FRIEND_TEST_ALL_PREFIXES(MyClassTest, MyMethod);
+// };
+#define FRIEND_TEST_ALL_PREFIXES(test_case_name, test_name) \
+  FRIEND_TEST_WEBRTC(test_case_name, test_name);            \
+  FRIEND_TEST_WEBRTC(test_case_name, DISABLED_##test_name); \
+  FRIEND_TEST_WEBRTC(test_case_name, FLAKY_##test_name);    \
+  FRIEND_TEST_WEBRTC(test_case_name, FAILS_##test_name)
+
+#endif  // RTC_BASE_GTEST_PROD_UTIL_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/logging.cc b/third_party/webrtc_aec3/src/rtc_base/logging.cc
new file mode 100644
index 0000000..a333d83
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/logging.cc
@@ -0,0 +1,581 @@
+/*
+ *  Copyright 2004 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "rtc_base/logging.h"
+
+#include <string.h>
+
+#if RTC_LOG_ENABLED()
+
+#if defined(WEBRTC_WIN)
+#include <windows.h>
+#if _MSC_VER < 1900
+#define snprintf _snprintf
+#endif
+#undef ERROR  // wingdi.h
+#endif
+
+#if defined(WEBRTC_MAC) && !defined(WEBRTC_IOS)
+#include <CoreServices/CoreServices.h>
+#elif defined(WEBRTC_ANDROID)
+#include <android/log.h>
+
+// Android has a 1024 limit on log inputs. We use 60 chars as an
+// approx for the header/tag portion.
+// See android/system/core/liblog/logd_write.c
+static const int kMaxLogLineSize = 1024 - 60;
+#endif  // WEBRTC_MAC && !defined(WEBRTC_IOS) || WEBRTC_ANDROID
+
+#include <inttypes.h>
+#include <stdio.h>
+#include <time.h>
+
+#include <algorithm>
+#include <cstdarg>
+#include <vector>
+
+#include "absl/base/attributes.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/platform_thread_types.h"
+#include "rtc_base/string_encode.h"
+#include "rtc_base/string_utils.h"
+#include "rtc_base/strings/string_builder.h"
+#include "rtc_base/synchronization/mutex.h"
+#include "rtc_base/thread_annotations.h"
+#include "rtc_base/time_utils.h"
+
+#if defined(WEBRTC_RACE_CHECK_MUTEX)
+#if defined(WEBRTC_ABSL_MUTEX)
+#error Please only define one of WEBRTC_RACE_CHECK_MUTEX and WEBRTC_ABSL_MUTEX.
+#endif
+#include "absl/base/const_init.h"
+#include "absl/synchronization/mutex.h"  // nogncheck
+using LoggingMutexLock = ::absl::MutexLock;
+#else
+using LoggingMutexLock = ::webrtc::MutexLock;
+#endif  // if defined(WEBRTC_RACE_CHECK_MUTEX)
+
+namespace rtc {
+namespace {
+// By default, release builds don't log, debug builds at info level
+#if !defined(NDEBUG)
+static LoggingSeverity g_min_sev = LS_INFO;
+static LoggingSeverity g_dbg_sev = LS_INFO;
+#else
+static LoggingSeverity g_min_sev = LS_NONE;
+static LoggingSeverity g_dbg_sev = LS_NONE;
+#endif
+
+// Return the filename portion of the string (that following the last slash).
+const char* FilenameFromPath(const char* file) {
+  const char* end1 = ::strrchr(file, '/');
+  const char* end2 = ::strrchr(file, '\\');
+  if (!end1 && !end2)
+    return file;
+  else
+    return (end1 > end2) ? end1 + 1 : end2 + 1;
+}
+
+// Global lock for log subsystem, only needed to serialize access to streams_.
+// TODO(bugs.webrtc.org/11665): this is not currently constant initialized and
+// trivially destructible.
+#if defined(WEBRTC_RACE_CHECK_MUTEX)
+// When WEBRTC_RACE_CHECK_MUTEX is defined, even though WebRTC objects are
+// invoked serially, the logging is static, invoked concurrently and hence needs
+// protection.
+absl::Mutex g_log_mutex_(absl::kConstInit);
+#else
+webrtc::Mutex g_log_mutex_;
+#endif
+
+}  // namespace
+
+/////////////////////////////////////////////////////////////////////////////
+// LogMessage
+/////////////////////////////////////////////////////////////////////////////
+
+bool LogMessage::log_to_stderr_ = true;
+
+// The list of logging streams currently configured.
+// Note: we explicitly do not clean this up, because of the uncertain ordering
+// of destructors at program exit.  Let the person who sets the stream trigger
+// cleanup by setting to null, or let it leak (safe at program exit).
+ABSL_CONST_INIT LogSink* LogMessage::streams_ RTC_GUARDED_BY(g_log_mutex_) =
+    nullptr;
+ABSL_CONST_INIT std::atomic<bool> LogMessage::streams_empty_ = {true};
+
+// Boolean options default to false (0)
+bool LogMessage::thread_, LogMessage::timestamp_;
+
+LogMessage::LogMessage(const char* file, int line, LoggingSeverity sev)
+    : LogMessage(file, line, sev, ERRCTX_NONE, 0) {}
+
+LogMessage::LogMessage(const char* file,
+                       int line,
+                       LoggingSeverity sev,
+                       LogErrorContext err_ctx,
+                       int err)
+    : severity_(sev) {
+  if (timestamp_) {
+    // Use SystemTimeMillis so that even if tests use fake clocks, the timestamp
+    // in log messages represents the real system time.
+    int64_t time = TimeDiff(SystemTimeMillis(), LogStartTime());
+    // Also ensure WallClockStartTime is initialized, so that it matches
+    // LogStartTime.
+    WallClockStartTime();
+    // TODO(kwiberg): Switch to absl::StrFormat, if binary size is ok.
+    char timestamp[50];  // Maximum string length of an int64_t is 20.
+    int len =
+        snprintf(timestamp, sizeof(timestamp), "[%03" PRId64 ":%03" PRId64 "]",
+                 time / 1000, time % 1000);
+    RTC_DCHECK_LT(len, sizeof(timestamp));
+    print_stream_ << timestamp;
+  }
+
+  if (thread_) {
+    PlatformThreadId id = CurrentThreadId();
+    print_stream_ << "[" << id << "] ";
+  }
+
+  if (file != nullptr) {
+#if defined(WEBRTC_ANDROID)
+    tag_ = FilenameFromPath(file);
+    print_stream_ << "(line " << line << "): ";
+#else
+    print_stream_ << "(" << FilenameFromPath(file) << ":" << line << "): ";
+#endif
+  }
+
+  if (err_ctx != ERRCTX_NONE) {
+    char tmp_buf[1024];
+    SimpleStringBuilder tmp(tmp_buf);
+    tmp.AppendFormat("[0x%08X]", err);
+    switch (err_ctx) {
+      case ERRCTX_ERRNO:
+        tmp << " " << strerror(err);
+        break;
+#ifdef WEBRTC_WIN
+      case ERRCTX_HRESULT: {
+        char msgbuf[256];
+        DWORD flags =
+            FORMAT_MESSAGE_FROM_SYSTEM | FORMAT_MESSAGE_IGNORE_INSERTS;
+        if (DWORD len = FormatMessageA(
+                flags, nullptr, err, MAKELANGID(LANG_NEUTRAL, SUBLANG_DEFAULT),
+                msgbuf, sizeof(msgbuf) / sizeof(msgbuf[0]), nullptr)) {
+          while ((len > 0) &&
+                 isspace(static_cast<unsigned char>(msgbuf[len - 1]))) {
+            msgbuf[--len] = 0;
+          }
+          tmp << " " << msgbuf;
+        }
+        break;
+      }
+#endif  // WEBRTC_WIN
+      default:
+        break;
+    }
+    extra_ = tmp.str();
+  }
+}
+
+#if defined(WEBRTC_ANDROID)
+LogMessage::LogMessage(const char* file,
+                       int line,
+                       LoggingSeverity sev,
+                       const char* tag)
+    : LogMessage(file, line, sev, ERRCTX_NONE, 0 /* err */) {
+  tag_ = tag;
+  print_stream_ << tag << ": ";
+}
+#endif
+
+// DEPRECATED. Currently only used by downstream projects that use
+// implementation details of logging.h. Work is ongoing to remove those
+// dependencies.
+LogMessage::LogMessage(const char* file,
+                       int line,
+                       LoggingSeverity sev,
+                       const std::string& tag)
+    : LogMessage(file, line, sev) {
+  print_stream_ << tag << ": ";
+}
+
+LogMessage::~LogMessage() {
+  FinishPrintStream();
+
+  const std::string str = print_stream_.Release();
+
+  if (severity_ >= g_dbg_sev) {
+#if defined(WEBRTC_ANDROID)
+    OutputToDebug(str, severity_, tag_);
+#else
+    OutputToDebug(str, severity_);
+#endif
+  }
+
+  LoggingMutexLock lock(&g_log_mutex_);
+  for (LogSink* entry = streams_; entry != nullptr; entry = entry->next_) {
+    if (severity_ >= entry->min_severity_) {
+#if defined(WEBRTC_ANDROID)
+      entry->OnLogMessage(str, severity_, tag_);
+#else
+      entry->OnLogMessage(str, severity_);
+#endif
+    }
+  }
+}
+
+void LogMessage::AddTag(const char* tag) {
+#ifdef WEBRTC_ANDROID
+  tag_ = tag;
+#endif
+}
+
+rtc::StringBuilder& LogMessage::stream() {
+  return print_stream_;
+}
+
+int LogMessage::GetMinLogSeverity() {
+  return g_min_sev;
+}
+
+LoggingSeverity LogMessage::GetLogToDebug() {
+  return g_dbg_sev;
+}
+int64_t LogMessage::LogStartTime() {
+  static const int64_t g_start = SystemTimeMillis();
+  return g_start;
+}
+
+uint32_t LogMessage::WallClockStartTime() {
+  static const uint32_t g_start_wallclock = time(nullptr);
+  return g_start_wallclock;
+}
+
+void LogMessage::LogThreads(bool on) {
+  thread_ = on;
+}
+
+void LogMessage::LogTimestamps(bool on) {
+  timestamp_ = on;
+}
+
+void LogMessage::LogToDebug(LoggingSeverity min_sev) {
+  g_dbg_sev = min_sev;
+  LoggingMutexLock lock(&g_log_mutex_);
+  UpdateMinLogSeverity();
+}
+
+void LogMessage::SetLogToStderr(bool log_to_stderr) {
+  log_to_stderr_ = log_to_stderr;
+}
+
+int LogMessage::GetLogToStream(LogSink* stream) {
+  LoggingMutexLock lock(&g_log_mutex_);
+  LoggingSeverity sev = LS_NONE;
+  for (LogSink* entry = streams_; entry != nullptr; entry = entry->next_) {
+    if (stream == nullptr || stream == entry) {
+      sev = std::min(sev, entry->min_severity_);
+    }
+  }
+  return sev;
+}
+
+void LogMessage::AddLogToStream(LogSink* stream, LoggingSeverity min_sev) {
+  LoggingMutexLock lock(&g_log_mutex_);
+  stream->min_severity_ = min_sev;
+  stream->next_ = streams_;
+  streams_ = stream;
+  streams_empty_.store(false, std::memory_order_relaxed);
+  UpdateMinLogSeverity();
+}
+
+void LogMessage::RemoveLogToStream(LogSink* stream) {
+  LoggingMutexLock lock(&g_log_mutex_);
+  for (LogSink** entry = &streams_; *entry != nullptr;
+       entry = &(*entry)->next_) {
+    if (*entry == stream) {
+      *entry = (*entry)->next_;
+      break;
+    }
+  }
+  streams_empty_.store(streams_ == nullptr, std::memory_order_relaxed);
+  UpdateMinLogSeverity();
+}
+
+void LogMessage::ConfigureLogging(const char* params) {
+  LoggingSeverity current_level = LS_VERBOSE;
+  LoggingSeverity debug_level = GetLogToDebug();
+
+  std::vector<std::string> tokens;
+  tokenize(params, ' ', &tokens);
+
+  for (const std::string& token : tokens) {
+    if (token.empty())
+      continue;
+
+    // Logging features
+    if (token == "tstamp") {
+      LogTimestamps();
+    } else if (token == "thread") {
+      LogThreads();
+
+      // Logging levels
+    } else if (token == "verbose") {
+      current_level = LS_VERBOSE;
+    } else if (token == "info") {
+      current_level = LS_INFO;
+    } else if (token == "warning") {
+      current_level = LS_WARNING;
+    } else if (token == "error") {
+      current_level = LS_ERROR;
+    } else if (token == "none") {
+      current_level = LS_NONE;
+
+      // Logging targets
+    } else if (token == "debug") {
+      debug_level = current_level;
+    }
+  }
+
+#if defined(WEBRTC_WIN) && !defined(WINUWP)
+  if ((LS_NONE != debug_level) && !::IsDebuggerPresent()) {
+    // First, attempt to attach to our parent's console... so if you invoke
+    // from the command line, we'll see the output there.  Otherwise, create
+    // our own console window.
+    // Note: These methods fail if a console already exists, which is fine.
+    if (!AttachConsole(ATTACH_PARENT_PROCESS))
+      ::AllocConsole();
+  }
+#endif  // defined(WEBRTC_WIN) && !defined(WINUWP)
+
+  LogToDebug(debug_level);
+}
+
+void LogMessage::UpdateMinLogSeverity()
+    RTC_EXCLUSIVE_LOCKS_REQUIRED(g_log_mutex_) {
+  LoggingSeverity min_sev = g_dbg_sev;
+  for (LogSink* entry = streams_; entry != nullptr; entry = entry->next_) {
+    min_sev = std::min(min_sev, entry->min_severity_);
+  }
+  g_min_sev = min_sev;
+}
+
+#if defined(WEBRTC_ANDROID)
+void LogMessage::OutputToDebug(const std::string& str,
+                               LoggingSeverity severity,
+                               const char* tag) {
+#else
+void LogMessage::OutputToDebug(const std::string& str,
+                               LoggingSeverity severity) {
+#endif
+  bool log_to_stderr = log_to_stderr_;
+#if defined(WEBRTC_MAC) && !defined(WEBRTC_IOS) && defined(NDEBUG)
+  // On the Mac, all stderr output goes to the Console log and causes clutter.
+  // So in opt builds, don't log to stderr unless the user specifically sets
+  // a preference to do so.
+  CFStringRef key = CFStringCreateWithCString(
+      kCFAllocatorDefault, "logToStdErr", kCFStringEncodingUTF8);
+  CFStringRef domain = CFBundleGetIdentifier(CFBundleGetMainBundle());
+  if (key != nullptr && domain != nullptr) {
+    Boolean exists_and_is_valid;
+    Boolean should_log =
+        CFPreferencesGetAppBooleanValue(key, domain, &exists_and_is_valid);
+    // If the key doesn't exist or is invalid or is false, we will not log to
+    // stderr.
+    log_to_stderr = exists_and_is_valid && should_log;
+  }
+  if (key != nullptr) {
+    CFRelease(key);
+  }
+#endif  // defined(WEBRTC_MAC) && !defined(WEBRTC_IOS) && defined(NDEBUG)
+
+#if defined(WEBRTC_WIN)
+  // Always log to the debugger.
+  // Perhaps stderr should be controlled by a preference, as on Mac?
+  OutputDebugStringA(str.c_str());
+  if (log_to_stderr) {
+    // This handles dynamically allocated consoles, too.
+    if (HANDLE error_handle = ::GetStdHandle(STD_ERROR_HANDLE)) {
+      log_to_stderr = false;
+      DWORD written = 0;
+      ::WriteFile(error_handle, str.data(), static_cast<DWORD>(str.size()),
+                  &written, 0);
+    }
+  }
+#endif  // WEBRTC_WIN
+
+#if defined(WEBRTC_ANDROID)
+  // Android's logging facility uses severity to log messages but we
+  // need to map libjingle's severity levels to Android ones first.
+  // Also write to stderr which maybe available to executable started
+  // from the shell.
+  int prio;
+  switch (severity) {
+    case LS_VERBOSE:
+      prio = ANDROID_LOG_VERBOSE;
+      break;
+    case LS_INFO:
+      prio = ANDROID_LOG_INFO;
+      break;
+    case LS_WARNING:
+      prio = ANDROID_LOG_WARN;
+      break;
+    case LS_ERROR:
+      prio = ANDROID_LOG_ERROR;
+      break;
+    default:
+      prio = ANDROID_LOG_UNKNOWN;
+  }
+
+  int size = str.size();
+  int line = 0;
+  int idx = 0;
+  const int max_lines = size / kMaxLogLineSize + 1;
+  if (max_lines == 1) {
+    __android_log_print(prio, tag, "%.*s", size, str.c_str());
+  } else {
+    while (size > 0) {
+      const int len = std::min(size, kMaxLogLineSize);
+      // Use the size of the string in the format (str may have \0 in the
+      // middle).
+      __android_log_print(prio, tag, "[%d/%d] %.*s", line + 1, max_lines, len,
+                          str.c_str() + idx);
+      idx += len;
+      size -= len;
+      ++line;
+    }
+  }
+#endif  // WEBRTC_ANDROID
+  if (log_to_stderr) {
+    fprintf(stderr, "%s", str.c_str());
+    fflush(stderr);
+  }
+}
+
+// static
+bool LogMessage::IsNoop(LoggingSeverity severity) {
+  if (severity >= g_dbg_sev || severity >= g_min_sev)
+    return false;
+  return streams_empty_.load(std::memory_order_relaxed);
+}
+
+void LogMessage::FinishPrintStream() {
+  if (!extra_.empty())
+    print_stream_ << " : " << extra_;
+  print_stream_ << "\n";
+}
+
+namespace webrtc_logging_impl {
+
+void Log(const LogArgType* fmt, ...) {
+  va_list args;
+  va_start(args, fmt);
+
+  LogMetadataErr meta;
+  const char* tag = nullptr;
+  switch (*fmt) {
+    case LogArgType::kLogMetadata: {
+      meta = {va_arg(args, LogMetadata), ERRCTX_NONE, 0};
+      break;
+    }
+    case LogArgType::kLogMetadataErr: {
+      meta = va_arg(args, LogMetadataErr);
+      break;
+    }
+#ifdef WEBRTC_ANDROID
+    case LogArgType::kLogMetadataTag: {
+      const LogMetadataTag tag_meta = va_arg(args, LogMetadataTag);
+      meta = {{nullptr, 0, tag_meta.severity}, ERRCTX_NONE, 0};
+      tag = tag_meta.tag;
+      break;
+    }
+#endif
+    default: {
+      RTC_NOTREACHED();
+      va_end(args);
+      return;
+    }
+  }
+
+  LogMessage log_message(meta.meta.File(), meta.meta.Line(),
+                         meta.meta.Severity(), meta.err_ctx, meta.err);
+  if (tag) {
+    log_message.AddTag(tag);
+  }
+
+  for (++fmt; *fmt != LogArgType::kEnd; ++fmt) {
+    switch (*fmt) {
+      case LogArgType::kInt:
+        log_message.stream() << va_arg(args, int);
+        break;
+      case LogArgType::kLong:
+        log_message.stream() << va_arg(args, long);
+        break;
+      case LogArgType::kLongLong:
+        log_message.stream() << va_arg(args, long long);
+        break;
+      case LogArgType::kUInt:
+        log_message.stream() << va_arg(args, unsigned);
+        break;
+      case LogArgType::kULong:
+        log_message.stream() << va_arg(args, unsigned long);
+        break;
+      case LogArgType::kULongLong:
+        log_message.stream() << va_arg(args, unsigned long long);
+        break;
+      case LogArgType::kDouble:
+        log_message.stream() << va_arg(args, double);
+        break;
+      case LogArgType::kLongDouble:
+        log_message.stream() << va_arg(args, long double);
+        break;
+      case LogArgType::kCharP: {
+        const char* s = va_arg(args, const char*);
+        log_message.stream() << (s ? s : "(null)");
+        break;
+      }
+      case LogArgType::kStdString:
+        log_message.stream() << *va_arg(args, const std::string*);
+        break;
+      case LogArgType::kStringView:
+        log_message.stream() << *va_arg(args, const absl::string_view*);
+        break;
+      case LogArgType::kVoidP:
+        log_message.stream() << rtc::ToHex(
+            reinterpret_cast<uintptr_t>(va_arg(args, const void*)));
+        break;
+      default:
+        RTC_NOTREACHED();
+        va_end(args);
+        return;
+    }
+  }
+
+  va_end(args);
+}
+
+}  // namespace webrtc_logging_impl
+}  // namespace rtc
+#endif
+
+namespace rtc {
+// Inefficient default implementation, override is recommended.
+void LogSink::OnLogMessage(const std::string& msg,
+                           LoggingSeverity severity,
+                           const char* tag) {
+  OnLogMessage(tag + (": " + msg), severity);
+}
+
+void LogSink::OnLogMessage(const std::string& msg,
+                           LoggingSeverity /* severity */) {
+  OnLogMessage(msg);
+}
+}  // namespace rtc
diff --git a/third_party/webrtc_aec3/src/rtc_base/logging.h b/third_party/webrtc_aec3/src/rtc_base/logging.h
new file mode 100644
index 0000000..e21c30e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/logging.h
@@ -0,0 +1,712 @@
+/*
+ *  Copyright 2004 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// RTC_LOG(...) an ostream target that can be used to send formatted
+// output to a variety of logging targets, such as debugger console, stderr,
+// or any LogSink.
+// The severity level passed as the first argument to the logging
+// functions is used as a filter, to limit the verbosity of the logging.
+// Static members of LogMessage documented below are used to control the
+// verbosity and target of the output.
+// There are several variations on the RTC_LOG macro which facilitate logging
+// of common error conditions, detailed below.
+
+// RTC_LOG(sev) logs the given stream at severity "sev", which must be a
+//     compile-time constant of the LoggingSeverity type, without the namespace
+//     prefix.
+// RTC_LOG_V(sev) Like RTC_LOG(), but sev is a run-time variable of the
+//     LoggingSeverity type (basically, it just doesn't prepend the namespace).
+// RTC_LOG_F(sev) Like RTC_LOG(), but includes the name of the current function.
+// RTC_LOG_T(sev) Like RTC_LOG(), but includes the this pointer.
+// RTC_LOG_T_F(sev) Like RTC_LOG_F(), but includes the this pointer.
+// RTC_LOG_GLE(sev [, mod]) attempt to add a string description of the
+//     HRESULT returned by GetLastError.
+// RTC_LOG_ERRNO(sev) attempts to add a string description of an errno-derived
+//     error. errno and associated facilities exist on both Windows and POSIX,
+//     but on Windows they only apply to the C/C++ runtime.
+// RTC_LOG_ERR(sev) is an alias for the platform's normal error system, i.e.
+//     _GLE on Windows and _ERRNO on POSIX.
+// (The above three also all have _EX versions that let you specify the error
+// code, rather than using the last one.)
+// RTC_LOG_E(sev, ctx, err, ...) logs a detailed error interpreted using the
+//     specified context.
+// RTC_LOG_CHECK_LEVEL(sev) (and RTC_LOG_CHECK_LEVEL_V(sev)) can be used as a
+//     test before performing expensive or sensitive operations whose sole
+//     purpose is to output logging data at the desired level.
+
+#ifndef RTC_BASE_LOGGING_H_
+#define RTC_BASE_LOGGING_H_
+
+#include <errno.h>
+
+#include <atomic>
+#include <sstream>  // no-presubmit-check TODO(webrtc:8982)
+#include <string>
+#include <utility>
+
+#include "absl/base/attributes.h"
+#include "absl/meta/type_traits.h"
+#include "absl/strings/string_view.h"
+#include "rtc_base/constructor_magic.h"
+#include "rtc_base/strings/string_builder.h"
+#include "rtc_base/system/inline.h"
+
+#if !defined(NDEBUG) || defined(DLOG_ALWAYS_ON)
+#define RTC_DLOG_IS_ON 1
+#else
+#define RTC_DLOG_IS_ON 0
+#endif
+
+#if defined(RTC_DISABLE_LOGGING)
+#define RTC_LOG_ENABLED() 0
+#else
+#define RTC_LOG_ENABLED() 1
+#endif
+
+namespace rtc {
+
+//////////////////////////////////////////////////////////////////////
+
+// Note that the non-standard LoggingSeverity aliases exist because they are
+// still in broad use.  The meanings of the levels are:
+//  LS_VERBOSE: This level is for data which we do not want to appear in the
+//   normal debug log, but should appear in diagnostic logs.
+//  LS_INFO: Chatty level used in debugging for all sorts of things, the default
+//   in debug builds.
+//  LS_WARNING: Something that may warrant investigation.
+//  LS_ERROR: Something that should not have occurred.
+//  LS_NONE: Don't log.
+enum LoggingSeverity {
+  LS_VERBOSE,
+  LS_INFO,
+  LS_WARNING,
+  LS_ERROR,
+  LS_NONE,
+  INFO = LS_INFO,
+  WARNING = LS_WARNING,
+  LERROR = LS_ERROR
+};
+
+// LogErrorContext assists in interpreting the meaning of an error value.
+enum LogErrorContext {
+  ERRCTX_NONE,
+  ERRCTX_ERRNO,    // System-local errno
+  ERRCTX_HRESULT,  // Windows HRESULT
+
+  // Abbreviations for LOG_E macro
+  ERRCTX_EN = ERRCTX_ERRNO,    // LOG_E(sev, EN, x)
+  ERRCTX_HR = ERRCTX_HRESULT,  // LOG_E(sev, HR, x)
+};
+
+class LogMessage;
+// Virtual sink interface that can receive log messages.
+class LogSink {
+ public:
+  LogSink() {}
+  virtual ~LogSink() {}
+  virtual void OnLogMessage(const std::string& msg,
+                            LoggingSeverity severity,
+                            const char* tag);
+  virtual void OnLogMessage(const std::string& message,
+                            LoggingSeverity severity);
+  virtual void OnLogMessage(const std::string& message) = 0;
+
+ private:
+  friend class ::rtc::LogMessage;
+#if RTC_LOG_ENABLED()
+  // Members for LogMessage class to keep linked list of the registered sinks.
+  LogSink* next_ = nullptr;
+  LoggingSeverity min_severity_;
+#endif
+};
+
+namespace webrtc_logging_impl {
+
+class LogMetadata {
+ public:
+  LogMetadata(const char* file, int line, LoggingSeverity severity)
+      : file_(file),
+        line_and_sev_(static_cast<uint32_t>(line) << 3 | severity) {}
+  LogMetadata() = default;
+
+  const char* File() const { return file_; }
+  int Line() const { return line_and_sev_ >> 3; }
+  LoggingSeverity Severity() const {
+    return static_cast<LoggingSeverity>(line_and_sev_ & 0x7);
+  }
+
+ private:
+  const char* file_;
+
+  // Line number and severity, the former in the most significant 29 bits, the
+  // latter in the least significant 3 bits. (This is an optimization; since
+  // both numbers are usually compile-time constants, this way we can load them
+  // both with a single instruction.)
+  uint32_t line_and_sev_;
+};
+static_assert(std::is_trivial<LogMetadata>::value, "");
+
+struct LogMetadataErr {
+  LogMetadata meta;
+  LogErrorContext err_ctx;
+  int err;
+};
+
+#ifdef WEBRTC_ANDROID
+struct LogMetadataTag {
+  LoggingSeverity severity;
+  const char* tag;
+};
+#endif
+
+enum class LogArgType : int8_t {
+  kEnd = 0,
+  kInt,
+  kLong,
+  kLongLong,
+  kUInt,
+  kULong,
+  kULongLong,
+  kDouble,
+  kLongDouble,
+  kCharP,
+  kStdString,
+  kStringView,
+  kVoidP,
+  kLogMetadata,
+  kLogMetadataErr,
+#ifdef WEBRTC_ANDROID
+  kLogMetadataTag,
+#endif
+};
+
+// Wrapper for log arguments. Only ever make values of this type with the
+// MakeVal() functions.
+template <LogArgType N, typename T>
+struct Val {
+  static constexpr LogArgType Type() { return N; }
+  T GetVal() const { return val; }
+  T val;
+};
+
+// Case for when we need to construct a temp string and then print that.
+// (We can't use Val<CheckArgType::kStdString, const std::string*>
+// because we need somewhere to store the temp string.)
+struct ToStringVal {
+  static constexpr LogArgType Type() { return LogArgType::kStdString; }
+  const std::string* GetVal() const { return &val; }
+  std::string val;
+};
+
+inline Val<LogArgType::kInt, int> MakeVal(int x) {
+  return {x};
+}
+inline Val<LogArgType::kLong, long> MakeVal(long x) {
+  return {x};
+}
+inline Val<LogArgType::kLongLong, long long> MakeVal(long long x) {
+  return {x};
+}
+inline Val<LogArgType::kUInt, unsigned int> MakeVal(unsigned int x) {
+  return {x};
+}
+inline Val<LogArgType::kULong, unsigned long> MakeVal(unsigned long x) {
+  return {x};
+}
+inline Val<LogArgType::kULongLong, unsigned long long> MakeVal(
+    unsigned long long x) {
+  return {x};
+}
+
+inline Val<LogArgType::kDouble, double> MakeVal(double x) {
+  return {x};
+}
+inline Val<LogArgType::kLongDouble, long double> MakeVal(long double x) {
+  return {x};
+}
+
+inline Val<LogArgType::kCharP, const char*> MakeVal(const char* x) {
+  return {x};
+}
+inline Val<LogArgType::kStdString, const std::string*> MakeVal(
+    const std::string& x) {
+  return {&x};
+}
+inline Val<LogArgType::kStringView, const absl::string_view*> MakeVal(
+    const absl::string_view& x) {
+  return {&x};
+}
+
+inline Val<LogArgType::kVoidP, const void*> MakeVal(const void* x) {
+  return {x};
+}
+
+inline Val<LogArgType::kLogMetadata, LogMetadata> MakeVal(
+    const LogMetadata& x) {
+  return {x};
+}
+inline Val<LogArgType::kLogMetadataErr, LogMetadataErr> MakeVal(
+    const LogMetadataErr& x) {
+  return {x};
+}
+
+// The enum class types are not implicitly convertible to arithmetic types.
+template <typename T,
+          absl::enable_if_t<std::is_enum<T>::value &&
+                            !std::is_arithmetic<T>::value>* = nullptr>
+inline decltype(MakeVal(std::declval<absl::underlying_type_t<T>>())) MakeVal(
+    T x) {
+  return {static_cast<absl::underlying_type_t<T>>(x)};
+}
+
+#ifdef WEBRTC_ANDROID
+inline Val<LogArgType::kLogMetadataTag, LogMetadataTag> MakeVal(
+    const LogMetadataTag& x) {
+  return {x};
+}
+#endif
+
+template <typename T, class = void>
+struct has_to_log_string : std::false_type {};
+template <typename T>
+struct has_to_log_string<T, decltype(ToLogString(std::declval<T>()))>
+    : std::true_type {};
+
+// Handle arbitrary types other than the above by falling back to stringstream.
+// TODO(bugs.webrtc.org/9278): Get rid of this overload when callers don't need
+// it anymore. No in-tree caller does, but some external callers still do.
+template <
+    typename T,
+    typename T1 = absl::decay_t<T>,
+    absl::enable_if_t<std::is_class<T1>::value &&
+                      !std::is_same<T1, std::string>::value &&
+                      !std::is_same<T1, LogMetadata>::value &&
+                      !has_to_log_string<T1>::value &&
+#ifdef WEBRTC_ANDROID
+                      !std::is_same<T1, LogMetadataTag>::value &&
+#endif
+                      !std::is_same<T1, LogMetadataErr>::value>* = nullptr>
+ToStringVal MakeVal(const T& x) {
+  std::ostringstream os;  // no-presubmit-check TODO(webrtc:8982)
+  os << x;
+  return {os.str()};
+}
+
+template <typename T, absl::enable_if_t<has_to_log_string<T>::value>* = nullptr>
+ToStringVal MakeVal(const T& x) {
+  return {ToLogString(x)};
+}
+
+#if RTC_LOG_ENABLED()
+void Log(const LogArgType* fmt, ...);
+#else
+inline void Log(const LogArgType* fmt, ...) {
+  // Do nothing, shouldn't be invoked
+}
+#endif
+
+// Ephemeral type that represents the result of the logging << operator.
+template <typename... Ts>
+class LogStreamer;
+
+// Base case: Before the first << argument.
+template <>
+class LogStreamer<> final {
+ public:
+  template <typename U,
+            typename V = decltype(MakeVal(std::declval<U>())),
+            absl::enable_if_t<std::is_arithmetic<U>::value ||
+                              std::is_enum<U>::value>* = nullptr>
+  RTC_FORCE_INLINE LogStreamer<V> operator<<(U arg) const {
+    return LogStreamer<V>(MakeVal(arg), this);
+  }
+
+  template <typename U,
+            typename V = decltype(MakeVal(std::declval<U>())),
+            absl::enable_if_t<!std::is_arithmetic<U>::value &&
+                              !std::is_enum<U>::value>* = nullptr>
+  RTC_FORCE_INLINE LogStreamer<V> operator<<(const U& arg) const {
+    return LogStreamer<V>(MakeVal(arg), this);
+  }
+
+  template <typename... Us>
+  RTC_FORCE_INLINE static void Call(const Us&... args) {
+    static constexpr LogArgType t[] = {Us::Type()..., LogArgType::kEnd};
+    Log(t, args.GetVal()...);
+  }
+};
+
+// Inductive case: We've already seen at least one << argument. The most recent
+// one had type `T`, and the earlier ones had types `Ts`.
+template <typename T, typename... Ts>
+class LogStreamer<T, Ts...> final {
+ public:
+  RTC_FORCE_INLINE LogStreamer(T arg, const LogStreamer<Ts...>* prior)
+      : arg_(arg), prior_(prior) {}
+
+  template <typename U,
+            typename V = decltype(MakeVal(std::declval<U>())),
+            absl::enable_if_t<std::is_arithmetic<U>::value ||
+                              std::is_enum<U>::value>* = nullptr>
+  RTC_FORCE_INLINE LogStreamer<V, T, Ts...> operator<<(U arg) const {
+    return LogStreamer<V, T, Ts...>(MakeVal(arg), this);
+  }
+
+  template <typename U,
+            typename V = decltype(MakeVal(std::declval<U>())),
+            absl::enable_if_t<!std::is_arithmetic<U>::value &&
+                              !std::is_enum<U>::value>* = nullptr>
+  RTC_FORCE_INLINE LogStreamer<V, T, Ts...> operator<<(const U& arg) const {
+    return LogStreamer<V, T, Ts...>(MakeVal(arg), this);
+  }
+
+  template <typename... Us>
+  RTC_FORCE_INLINE void Call(const Us&... args) const {
+    prior_->Call(arg_, args...);
+  }
+
+ private:
+  // The most recent argument.
+  T arg_;
+
+  // Earlier arguments.
+  const LogStreamer<Ts...>* prior_;
+};
+
+class LogCall final {
+ public:
+  // This can be any binary operator with precedence lower than <<.
+  // We return bool here to be able properly remove logging if
+  // RTC_DISABLE_LOGGING is defined.
+  template <typename... Ts>
+  RTC_FORCE_INLINE bool operator&(const LogStreamer<Ts...>& streamer) {
+    streamer.Call();
+    return true;
+  }
+};
+
+// This class is used to explicitly ignore values in the conditional
+// logging macros.  This avoids compiler warnings like "value computed
+// is not used" and "statement has no effect".
+class LogMessageVoidify {
+ public:
+  LogMessageVoidify() = default;
+  // This has to be an operator with a precedence lower than << but
+  // higher than ?:
+  template <typename... Ts>
+  void operator&(LogStreamer<Ts...>&& streamer) {}
+};
+
+}  // namespace webrtc_logging_impl
+
+// Direct use of this class is deprecated; please use the logging macros
+// instead.
+// TODO(bugs.webrtc.org/9278): Move this class to an unnamed namespace in the
+// .cc file.
+class LogMessage {
+ public:
+  // Same as the above, but using a compile-time constant for the logging
+  // severity. This saves space at the call site, since passing an empty struct
+  // is generally the same as not passing an argument at all.
+  template <LoggingSeverity S>
+  RTC_NO_INLINE LogMessage(const char* file,
+                           int line,
+                           std::integral_constant<LoggingSeverity, S>)
+      : LogMessage(file, line, S) {}
+
+#if RTC_LOG_ENABLED()
+  LogMessage(const char* file, int line, LoggingSeverity sev);
+  LogMessage(const char* file,
+             int line,
+             LoggingSeverity sev,
+             LogErrorContext err_ctx,
+             int err);
+#if defined(WEBRTC_ANDROID)
+  LogMessage(const char* file, int line, LoggingSeverity sev, const char* tag);
+#endif
+  // DEPRECATED - DO NOT USE - PLEASE USE THE MACROS INSTEAD OF THE CLASS.
+  // Android code should use the 'const char*' version since tags are static
+  // and we want to avoid allocating a std::string copy per log line.
+  ABSL_DEPRECATED("Use RTC_LOG macros instead of accessing this class directly")
+  LogMessage(const char* file,
+             int line,
+             LoggingSeverity sev,
+             const std::string& tag);
+  ~LogMessage();
+
+  void AddTag(const char* tag);
+  rtc::StringBuilder& stream();
+  // Returns the time at which this function was called for the first time.
+  // The time will be used as the logging start time.
+  // If this is not called externally, the LogMessage ctor also calls it, in
+  // which case the logging start time will be the time of the first LogMessage
+  // instance is created.
+  static int64_t LogStartTime();
+  // Returns the wall clock equivalent of |LogStartTime|, in seconds from the
+  // epoch.
+  static uint32_t WallClockStartTime();
+  //  LogThreads: Display the thread identifier of the current thread
+  static void LogThreads(bool on = true);
+  //  LogTimestamps: Display the elapsed time of the program
+  static void LogTimestamps(bool on = true);
+  // These are the available logging channels
+  //  Debug: Debug console on Windows, otherwise stderr
+  static void LogToDebug(LoggingSeverity min_sev);
+  static LoggingSeverity GetLogToDebug();
+  // Sets whether logs will be directed to stderr in debug mode.
+  static void SetLogToStderr(bool log_to_stderr);
+  // Stream: Any non-blocking stream interface.
+  // Installs the |stream| to collect logs with severtiy |min_sev| or higher.
+  // |stream| must live until deinstalled by RemoveLogToStream.
+  // If |stream| is the first stream added to the system, we might miss some
+  // early concurrent log statement happening from another thread happening near
+  // this instant.
+  static void AddLogToStream(LogSink* stream, LoggingSeverity min_sev);
+  // Removes the specified stream, without destroying it. When the method
+  // has completed, it's guaranteed that |stream| will receive no more logging
+  // calls.
+  static void RemoveLogToStream(LogSink* stream);
+  // Returns the severity for the specified stream, of if none is specified,
+  // the minimum stream severity.
+  static int GetLogToStream(LogSink* stream = nullptr);
+  // Testing against MinLogSeverity allows code to avoid potentially expensive
+  // logging operations by pre-checking the logging level.
+  static int GetMinLogSeverity();
+  // Parses the provided parameter stream to configure the options above.
+  // Useful for configuring logging from the command line.
+  static void ConfigureLogging(const char* params);
+  // Checks the current global debug severity and if the |streams_| collection
+  // is empty. If |severity| is smaller than the global severity and if the
+  // |streams_| collection is empty, the LogMessage will be considered a noop
+  // LogMessage.
+  static bool IsNoop(LoggingSeverity severity);
+  // Version of IsNoop that uses fewer instructions at the call site, since the
+  // caller doesn't have to pass an argument.
+  template <LoggingSeverity S>
+  RTC_NO_INLINE static bool IsNoop() {
+    return IsNoop(S);
+  }
+#else
+  // Next methods do nothing; no one will call these functions.
+  LogMessage(const char* file, int line, LoggingSeverity sev) {}
+  LogMessage(const char* file,
+             int line,
+             LoggingSeverity sev,
+             LogErrorContext err_ctx,
+             int err) {}
+#if defined(WEBRTC_ANDROID)
+  LogMessage(const char* file, int line, LoggingSeverity sev, const char* tag) {
+  }
+#endif
+  // DEPRECATED - DO NOT USE - PLEASE USE THE MACROS INSTEAD OF THE CLASS.
+  // Android code should use the 'const char*' version since tags are static
+  // and we want to avoid allocating a std::string copy per log line.
+  ABSL_DEPRECATED("Use RTC_LOG macros instead of accessing this class directly")
+  LogMessage(const char* file,
+             int line,
+             LoggingSeverity sev,
+             const std::string& tag) {}
+  ~LogMessage() = default;
+
+  inline void AddTag(const char* tag) {}
+  inline rtc::StringBuilder& stream() { return print_stream_; }
+  inline static int64_t LogStartTime() { return 0; }
+  inline static uint32_t WallClockStartTime() { return 0; }
+  inline static void LogThreads(bool on = true) {}
+  inline static void LogTimestamps(bool on = true) {}
+  inline static void LogToDebug(LoggingSeverity min_sev) {}
+  inline static LoggingSeverity GetLogToDebug() {
+    return LoggingSeverity::LS_INFO;
+  }
+  inline static void SetLogToStderr(bool log_to_stderr) {}
+  inline static void AddLogToStream(LogSink* stream, LoggingSeverity min_sev) {}
+  inline static void RemoveLogToStream(LogSink* stream) {}
+  inline static int GetLogToStream(LogSink* stream = nullptr) { return 0; }
+  inline static int GetMinLogSeverity() { return 0; }
+  inline static void ConfigureLogging(const char* params) {}
+  static constexpr bool IsNoop(LoggingSeverity severity) { return true; }
+  template <LoggingSeverity S>
+  static constexpr bool IsNoop() {
+    return IsNoop(S);
+  }
+#endif  // RTC_LOG_ENABLED()
+
+ private:
+  friend class LogMessageForTesting;
+
+#if RTC_LOG_ENABLED()
+  // Updates min_sev_ appropriately when debug sinks change.
+  static void UpdateMinLogSeverity();
+
+// These write out the actual log messages.
+#if defined(WEBRTC_ANDROID)
+  static void OutputToDebug(const std::string& msg,
+                            LoggingSeverity severity,
+                            const char* tag);
+#else
+  static void OutputToDebug(const std::string& msg, LoggingSeverity severity);
+#endif  // defined(WEBRTC_ANDROID)
+
+  // Called from the dtor (or from a test) to append optional extra error
+  // information to the log stream and a newline character.
+  void FinishPrintStream();
+
+  // The severity level of this message
+  LoggingSeverity severity_;
+
+#if defined(WEBRTC_ANDROID)
+  // The default Android debug output tag.
+  const char* tag_ = "libjingle";
+#endif
+
+  // String data generated in the constructor, that should be appended to
+  // the message before output.
+  std::string extra_;
+
+  // The output streams and their associated severities
+  static LogSink* streams_;
+
+  // Holds true with high probability if |streams_| is empty, false with high
+  // probability otherwise. Operated on with std::memory_order_relaxed because
+  // it's ok to lose or log some additional statements near the instant streams
+  // are added/removed.
+  static std::atomic<bool> streams_empty_;
+
+  // Flags for formatting options
+  static bool thread_, timestamp_;
+
+  // Determines if logs will be directed to stderr in debug mode.
+  static bool log_to_stderr_;
+#else  // RTC_LOG_ENABLED()
+  // Next methods do nothing; no one will call these functions.
+  inline static void UpdateMinLogSeverity() {}
+#if defined(WEBRTC_ANDROID)
+  inline static void OutputToDebug(const std::string& msg,
+                                   LoggingSeverity severity,
+                                   const char* tag) {}
+#else
+  inline static void OutputToDebug(const std::string& msg,
+                                   LoggingSeverity severity) {}
+#endif  // defined(WEBRTC_ANDROID)
+  inline void FinishPrintStream() {}
+#endif  // RTC_LOG_ENABLED()
+
+  // The stringbuilder that buffers the formatted message before output
+  rtc::StringBuilder print_stream_;
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(LogMessage);
+};
+
+//////////////////////////////////////////////////////////////////////
+// Logging Helpers
+//////////////////////////////////////////////////////////////////////
+
+#define RTC_LOG_FILE_LINE(sev, file, line)        \
+  ::rtc::webrtc_logging_impl::LogCall() &         \
+      ::rtc::webrtc_logging_impl::LogStreamer<>() \
+          << ::rtc::webrtc_logging_impl::LogMetadata(file, line, sev)
+
+#define RTC_LOG(sev)                        \
+  !rtc::LogMessage::IsNoop<::rtc::sev>() && \
+      RTC_LOG_FILE_LINE(::rtc::sev, __FILE__, __LINE__)
+
+// The _V version is for when a variable is passed in.
+#define RTC_LOG_V(sev) \
+  !rtc::LogMessage::IsNoop(sev) && RTC_LOG_FILE_LINE(sev, __FILE__, __LINE__)
+
+// The _F version prefixes the message with the current function name.
+#if (defined(__GNUC__) && !defined(NDEBUG)) || defined(WANT_PRETTY_LOG_F)
+#define RTC_LOG_F(sev) RTC_LOG(sev) << __PRETTY_FUNCTION__ << ": "
+#define RTC_LOG_T_F(sev) \
+  RTC_LOG(sev) << this << ": " << __PRETTY_FUNCTION__ << ": "
+#else
+#define RTC_LOG_F(sev) RTC_LOG(sev) << __FUNCTION__ << ": "
+#define RTC_LOG_T_F(sev) RTC_LOG(sev) << this << ": " << __FUNCTION__ << ": "
+#endif
+
+#define RTC_LOG_CHECK_LEVEL(sev) ::rtc::LogCheckLevel(::rtc::sev)
+#define RTC_LOG_CHECK_LEVEL_V(sev) ::rtc::LogCheckLevel(sev)
+
+inline bool LogCheckLevel(LoggingSeverity sev) {
+  return (LogMessage::GetMinLogSeverity() <= sev);
+}
+
+#define RTC_LOG_E(sev, ctx, err)                                 \
+  !rtc::LogMessage::IsNoop<::rtc::sev>() &&                      \
+      ::rtc::webrtc_logging_impl::LogCall() &                    \
+          ::rtc::webrtc_logging_impl::LogStreamer<>()            \
+              << ::rtc::webrtc_logging_impl::LogMetadataErr {    \
+    {__FILE__, __LINE__, ::rtc::sev}, ::rtc::ERRCTX_##ctx, (err) \
+  }
+
+#define RTC_LOG_T(sev) RTC_LOG(sev) << this << ": "
+
+#define RTC_LOG_ERRNO_EX(sev, err) RTC_LOG_E(sev, ERRNO, err)
+#define RTC_LOG_ERRNO(sev) RTC_LOG_ERRNO_EX(sev, errno)
+
+#if defined(WEBRTC_WIN)
+#define RTC_LOG_GLE_EX(sev, err) RTC_LOG_E(sev, HRESULT, err)
+#define RTC_LOG_GLE(sev) RTC_LOG_GLE_EX(sev, static_cast<int>(GetLastError()))
+#define RTC_LOG_ERR_EX(sev, err) RTC_LOG_GLE_EX(sev, err)
+#define RTC_LOG_ERR(sev) RTC_LOG_GLE(sev)
+#elif defined(__native_client__) && __native_client__
+#define RTC_LOG_ERR_EX(sev, err) RTC_LOG(sev)
+#define RTC_LOG_ERR(sev) RTC_LOG(sev)
+#elif defined(WEBRTC_POSIX)
+#define RTC_LOG_ERR_EX(sev, err) RTC_LOG_ERRNO_EX(sev, err)
+#define RTC_LOG_ERR(sev) RTC_LOG_ERRNO(sev)
+#endif  // WEBRTC_WIN
+
+#ifdef WEBRTC_ANDROID
+
+namespace webrtc_logging_impl {
+// TODO(kwiberg): Replace these with absl::string_view.
+inline const char* AdaptString(const char* str) {
+  return str;
+}
+inline const char* AdaptString(const std::string& str) {
+  return str.c_str();
+}
+}  // namespace webrtc_logging_impl
+
+#define RTC_LOG_TAG(sev, tag)                                 \
+  !rtc::LogMessage::IsNoop(sev) &&                            \
+      ::rtc::webrtc_logging_impl::LogCall() &                 \
+          ::rtc::webrtc_logging_impl::LogStreamer<>()         \
+              << ::rtc::webrtc_logging_impl::LogMetadataTag { \
+    sev, ::rtc::webrtc_logging_impl::AdaptString(tag)         \
+  }
+
+#else
+
+// DEPRECATED. This macro is only intended for Android.
+#define RTC_LOG_TAG(sev, tag) RTC_LOG_V(sev)
+
+#endif
+
+// The RTC_DLOG macros are equivalent to their RTC_LOG counterparts except that
+// they only generate code in debug builds.
+#if RTC_DLOG_IS_ON
+#define RTC_DLOG(sev) RTC_LOG(sev)
+#define RTC_DLOG_V(sev) RTC_LOG_V(sev)
+#define RTC_DLOG_F(sev) RTC_LOG_F(sev)
+#else
+#define RTC_DLOG_EAT_STREAM_PARAMS()                \
+  while (false)                                     \
+  ::rtc::webrtc_logging_impl::LogMessageVoidify() & \
+      (::rtc::webrtc_logging_impl::LogStreamer<>())
+#define RTC_DLOG(sev) RTC_DLOG_EAT_STREAM_PARAMS()
+#define RTC_DLOG_V(sev) RTC_DLOG_EAT_STREAM_PARAMS()
+#define RTC_DLOG_F(sev) RTC_DLOG_EAT_STREAM_PARAMS()
+#endif
+
+}  // namespace rtc
+
+#endif  // RTC_BASE_LOGGING_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/memory/aligned_malloc.cc b/third_party/webrtc_aec3/src/rtc_base/memory/aligned_malloc.cc
new file mode 100644
index 0000000..b00fab2
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/memory/aligned_malloc.cc
@@ -0,0 +1,98 @@
+/*
+ *  Copyright (c) 2011 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "rtc_base/memory/aligned_malloc.h"
+
+#include <stdlib.h>  // for free, malloc
+#include <string.h>  // for memcpy
+
+#include "rtc_base/checks.h"
+
+#ifdef _WIN32
+#include <windows.h>
+#else
+#include <stdint.h>
+#endif
+
+// Reference on memory alignment:
+// http://stackoverflow.com/questions/227897/solve-the-memory-alignment-in-c-interview-question-that-stumped-me
+namespace webrtc {
+
+uintptr_t GetRightAlign(uintptr_t start_pos, size_t alignment) {
+  // The pointer should be aligned with |alignment| bytes. The - 1 guarantees
+  // that it is aligned towards the closest higher (right) address.
+  return (start_pos + alignment - 1) & ~(alignment - 1);
+}
+
+// Alignment must be an integer power of two.
+bool ValidAlignment(size_t alignment) {
+  if (!alignment) {
+    return false;
+  }
+  return (alignment & (alignment - 1)) == 0;
+}
+
+void* GetRightAlign(const void* pointer, size_t alignment) {
+  if (!pointer) {
+    return NULL;
+  }
+  if (!ValidAlignment(alignment)) {
+    return NULL;
+  }
+  uintptr_t start_pos = reinterpret_cast<uintptr_t>(pointer);
+  return reinterpret_cast<void*>(GetRightAlign(start_pos, alignment));
+}
+
+void* AlignedMalloc(size_t size, size_t alignment) {
+  if (size == 0) {
+    return NULL;
+  }
+  if (!ValidAlignment(alignment)) {
+    return NULL;
+  }
+
+  // The memory is aligned towards the lowest address that so only
+  // alignment - 1 bytes needs to be allocated.
+  // A pointer to the start of the memory must be stored so that it can be
+  // retreived for deletion, ergo the sizeof(uintptr_t).
+  void* memory_pointer = malloc(size + sizeof(uintptr_t) + alignment - 1);
+  RTC_CHECK(memory_pointer) << "Couldn't allocate memory in AlignedMalloc";
+
+  // Aligning after the sizeof(uintptr_t) bytes will leave room for the header
+  // in the same memory block.
+  uintptr_t align_start_pos = reinterpret_cast<uintptr_t>(memory_pointer);
+  align_start_pos += sizeof(uintptr_t);
+  uintptr_t aligned_pos = GetRightAlign(align_start_pos, alignment);
+  void* aligned_pointer = reinterpret_cast<void*>(aligned_pos);
+
+  // Store the address to the beginning of the memory just before the aligned
+  // memory.
+  uintptr_t header_pos = aligned_pos - sizeof(uintptr_t);
+  void* header_pointer = reinterpret_cast<void*>(header_pos);
+  uintptr_t memory_start = reinterpret_cast<uintptr_t>(memory_pointer);
+  memcpy(header_pointer, &memory_start, sizeof(uintptr_t));
+
+  return aligned_pointer;
+}
+
+void AlignedFree(void* mem_block) {
+  if (mem_block == NULL) {
+    return;
+  }
+  uintptr_t aligned_pos = reinterpret_cast<uintptr_t>(mem_block);
+  uintptr_t header_pos = aligned_pos - sizeof(uintptr_t);
+
+  // Read out the address of the AlignedMemory struct from the header.
+  uintptr_t memory_start_pos = *reinterpret_cast<uintptr_t*>(header_pos);
+  void* memory_start = reinterpret_cast<void*>(memory_start_pos);
+  free(memory_start);
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/rtc_base/memory/aligned_malloc.h b/third_party/webrtc_aec3/src/rtc_base/memory/aligned_malloc.h
new file mode 100644
index 0000000..42a6daa
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/memory/aligned_malloc.h
@@ -0,0 +1,57 @@
+/*
+ *  Copyright (c) 2011 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_MEMORY_ALIGNED_MALLOC_H_
+#define RTC_BASE_MEMORY_ALIGNED_MALLOC_H_
+
+// The functions declared here
+// 1) Allocates block of aligned memory.
+// 2) Re-calculates a pointer such that it is aligned to a higher or equal
+//    address.
+// Note: alignment must be a power of two. The alignment is in bytes.
+
+#include <stddef.h>
+
+namespace webrtc {
+
+// Returns a pointer to the first boundry of |alignment| bytes following the
+// address of |ptr|.
+// Note that there is no guarantee that the memory in question is available.
+// |ptr| has no requirements other than it can't be NULL.
+void* GetRightAlign(const void* ptr, size_t alignment);
+
+// Allocates memory of |size| bytes aligned on an |alignment| boundry.
+// The return value is a pointer to the memory. Note that the memory must
+// be de-allocated using AlignedFree.
+void* AlignedMalloc(size_t size, size_t alignment);
+// De-allocates memory created using the AlignedMalloc() API.
+void AlignedFree(void* mem_block);
+
+// Templated versions to facilitate usage of aligned malloc without casting
+// to and from void*.
+template <typename T>
+T* GetRightAlign(const T* ptr, size_t alignment) {
+  return reinterpret_cast<T*>(
+      GetRightAlign(reinterpret_cast<const void*>(ptr), alignment));
+}
+template <typename T>
+T* AlignedMalloc(size_t size, size_t alignment) {
+  return reinterpret_cast<T*>(AlignedMalloc(size, alignment));
+}
+
+// Deleter for use with unique_ptr. E.g., use as
+//   std::unique_ptr<Foo, AlignedFreeDeleter> foo;
+struct AlignedFreeDeleter {
+  inline void operator()(void* ptr) const { AlignedFree(ptr); }
+};
+
+}  // namespace webrtc
+
+#endif  // RTC_BASE_MEMORY_ALIGNED_MALLOC_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/numerics/safe_compare.h b/third_party/webrtc_aec3/src/rtc_base/numerics/safe_compare.h
new file mode 100644
index 0000000..85f0a30
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/numerics/safe_compare.h
@@ -0,0 +1,176 @@
+/*
+ *  Copyright 2016 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// This file defines six constexpr functions:
+//
+//   rtc::SafeEq  // ==
+//   rtc::SafeNe  // !=
+//   rtc::SafeLt  // <
+//   rtc::SafeLe  // <=
+//   rtc::SafeGt  // >
+//   rtc::SafeGe  // >=
+//
+// They each accept two arguments of arbitrary types, and in almost all cases,
+// they simply call the appropriate comparison operator. However, if both
+// arguments are integers, they don't compare them using C++'s quirky rules,
+// but instead adhere to the true mathematical definitions. It is as if the
+// arguments were first converted to infinite-range signed integers, and then
+// compared, although of course nothing expensive like that actually takes
+// place. In practice, for signed/signed and unsigned/unsigned comparisons and
+// some mixed-signed comparisons with a compile-time constant, the overhead is
+// zero; in the remaining cases, it is just a few machine instructions (no
+// branches).
+
+#ifndef RTC_BASE_NUMERICS_SAFE_COMPARE_H_
+#define RTC_BASE_NUMERICS_SAFE_COMPARE_H_
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include <type_traits>
+#include <utility>
+
+#include "rtc_base/type_traits.h"
+
+namespace rtc {
+
+namespace safe_cmp_impl {
+
+template <size_t N>
+struct LargerIntImpl : std::false_type {};
+template <>
+struct LargerIntImpl<sizeof(int8_t)> : std::true_type {
+  using type = int16_t;
+};
+template <>
+struct LargerIntImpl<sizeof(int16_t)> : std::true_type {
+  using type = int32_t;
+};
+template <>
+struct LargerIntImpl<sizeof(int32_t)> : std::true_type {
+  using type = int64_t;
+};
+
+// LargerInt<T1, T2>::value is true iff there's a signed type that's larger
+// than T1 (and no larger than the larger of T2 and int*, for performance
+// reasons); and if there is such a type, LargerInt<T1, T2>::type is an alias
+// for it.
+template <typename T1, typename T2>
+struct LargerInt
+    : LargerIntImpl<sizeof(T1) < sizeof(T2) || sizeof(T1) < sizeof(int*)
+                        ? sizeof(T1)
+                        : 0> {};
+
+template <typename T>
+constexpr typename std::make_unsigned<T>::type MakeUnsigned(T a) {
+  return static_cast<typename std::make_unsigned<T>::type>(a);
+}
+
+// Overload for when both T1 and T2 have the same signedness.
+template <typename Op,
+          typename T1,
+          typename T2,
+          typename std::enable_if<std::is_signed<T1>::value ==
+                                  std::is_signed<T2>::value>::type* = nullptr>
+constexpr bool Cmp(T1 a, T2 b) {
+  return Op::Op(a, b);
+}
+
+// Overload for signed - unsigned comparison that can be promoted to a bigger
+// signed type.
+template <typename Op,
+          typename T1,
+          typename T2,
+          typename std::enable_if<std::is_signed<T1>::value &&
+                                  std::is_unsigned<T2>::value &&
+                                  LargerInt<T2, T1>::value>::type* = nullptr>
+constexpr bool Cmp(T1 a, T2 b) {
+  return Op::Op(a, static_cast<typename LargerInt<T2, T1>::type>(b));
+}
+
+// Overload for unsigned - signed comparison that can be promoted to a bigger
+// signed type.
+template <typename Op,
+          typename T1,
+          typename T2,
+          typename std::enable_if<std::is_unsigned<T1>::value &&
+                                  std::is_signed<T2>::value &&
+                                  LargerInt<T1, T2>::value>::type* = nullptr>
+constexpr bool Cmp(T1 a, T2 b) {
+  return Op::Op(static_cast<typename LargerInt<T1, T2>::type>(a), b);
+}
+
+// Overload for signed - unsigned comparison that can't be promoted to a bigger
+// signed type.
+template <typename Op,
+          typename T1,
+          typename T2,
+          typename std::enable_if<std::is_signed<T1>::value &&
+                                  std::is_unsigned<T2>::value &&
+                                  !LargerInt<T2, T1>::value>::type* = nullptr>
+constexpr bool Cmp(T1 a, T2 b) {
+  return a < 0 ? Op::Op(-1, 0) : Op::Op(safe_cmp_impl::MakeUnsigned(a), b);
+}
+
+// Overload for unsigned - signed comparison that can't be promoted to a bigger
+// signed type.
+template <typename Op,
+          typename T1,
+          typename T2,
+          typename std::enable_if<std::is_unsigned<T1>::value &&
+                                  std::is_signed<T2>::value &&
+                                  !LargerInt<T1, T2>::value>::type* = nullptr>
+constexpr bool Cmp(T1 a, T2 b) {
+  return b < 0 ? Op::Op(0, -1) : Op::Op(a, safe_cmp_impl::MakeUnsigned(b));
+}
+
+#define RTC_SAFECMP_MAKE_OP(name, op)      \
+  struct name {                            \
+    template <typename T1, typename T2>    \
+    static constexpr bool Op(T1 a, T2 b) { \
+      return a op b;                       \
+    }                                      \
+  };
+RTC_SAFECMP_MAKE_OP(EqOp, ==)
+RTC_SAFECMP_MAKE_OP(NeOp, !=)
+RTC_SAFECMP_MAKE_OP(LtOp, <)
+RTC_SAFECMP_MAKE_OP(LeOp, <=)
+RTC_SAFECMP_MAKE_OP(GtOp, >)
+RTC_SAFECMP_MAKE_OP(GeOp, >=)
+#undef RTC_SAFECMP_MAKE_OP
+
+}  // namespace safe_cmp_impl
+
+#define RTC_SAFECMP_MAKE_FUN(name)                                            \
+  template <typename T1, typename T2>                                         \
+  constexpr                                                                   \
+      typename std::enable_if<IsIntlike<T1>::value && IsIntlike<T2>::value,   \
+                              bool>::type Safe##name(T1 a, T2 b) {            \
+    /* Unary plus here turns enums into real integral types. */               \
+    return safe_cmp_impl::Cmp<safe_cmp_impl::name##Op>(+a, +b);               \
+  }                                                                           \
+  template <typename T1, typename T2>                                         \
+  constexpr                                                                   \
+      typename std::enable_if<!IsIntlike<T1>::value || !IsIntlike<T2>::value, \
+                              bool>::type Safe##name(const T1& a,             \
+                                                     const T2& b) {           \
+    return safe_cmp_impl::name##Op::Op(a, b);                                 \
+  }
+RTC_SAFECMP_MAKE_FUN(Eq)
+RTC_SAFECMP_MAKE_FUN(Ne)
+RTC_SAFECMP_MAKE_FUN(Lt)
+RTC_SAFECMP_MAKE_FUN(Le)
+RTC_SAFECMP_MAKE_FUN(Gt)
+RTC_SAFECMP_MAKE_FUN(Ge)
+#undef RTC_SAFECMP_MAKE_FUN
+
+}  // namespace rtc
+
+#endif  // RTC_BASE_NUMERICS_SAFE_COMPARE_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/numerics/safe_conversions.h b/third_party/webrtc_aec3/src/rtc_base/numerics/safe_conversions.h
new file mode 100644
index 0000000..e00219c
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/numerics/safe_conversions.h
@@ -0,0 +1,74 @@
+/*
+ *  Copyright 2014 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// Borrowed from Chromium's src/base/numerics/safe_conversions.h.
+
+#ifndef RTC_BASE_NUMERICS_SAFE_CONVERSIONS_H_
+#define RTC_BASE_NUMERICS_SAFE_CONVERSIONS_H_
+
+#include <limits>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_conversions_impl.h"
+
+namespace rtc {
+
+// Convenience function that returns true if the supplied value is in range
+// for the destination type.
+template <typename Dst, typename Src>
+inline constexpr bool IsValueInRangeForNumericType(Src value) {
+  return internal::RangeCheck<Dst>(value) == internal::TYPE_VALID;
+}
+
+// checked_cast<> and dchecked_cast<> are analogous to static_cast<> for
+// numeric types, except that they [D]CHECK that the specified numeric
+// conversion will not overflow or underflow. NaN source will always trigger
+// the [D]CHECK.
+template <typename Dst, typename Src>
+inline constexpr Dst checked_cast(Src value) {
+  RTC_CHECK(IsValueInRangeForNumericType<Dst>(value));
+  return static_cast<Dst>(value);
+}
+template <typename Dst, typename Src>
+inline constexpr Dst dchecked_cast(Src value) {
+  RTC_DCHECK(IsValueInRangeForNumericType<Dst>(value));
+  return static_cast<Dst>(value);
+}
+
+// saturated_cast<> is analogous to static_cast<> for numeric types, except
+// that the specified numeric conversion will saturate rather than overflow or
+// underflow. NaN assignment to an integral will trigger a RTC_CHECK condition.
+template <typename Dst, typename Src>
+inline constexpr Dst saturated_cast(Src value) {
+  // Optimization for floating point values, which already saturate.
+  if (std::numeric_limits<Dst>::is_iec559)
+    return static_cast<Dst>(value);
+
+  switch (internal::RangeCheck<Dst>(value)) {
+    case internal::TYPE_VALID:
+      return static_cast<Dst>(value);
+
+    case internal::TYPE_UNDERFLOW:
+      return std::numeric_limits<Dst>::min();
+
+    case internal::TYPE_OVERFLOW:
+      return std::numeric_limits<Dst>::max();
+
+    // Should fail only on attempting to assign NaN to a saturated integer.
+    case internal::TYPE_INVALID:
+      RTC_CHECK_NOTREACHED();
+  }
+
+  RTC_CHECK_NOTREACHED();
+}
+
+}  // namespace rtc
+
+#endif  // RTC_BASE_NUMERICS_SAFE_CONVERSIONS_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/numerics/safe_conversions_impl.h b/third_party/webrtc_aec3/src/rtc_base/numerics/safe_conversions_impl.h
new file mode 100644
index 0000000..e924ce3
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/numerics/safe_conversions_impl.h
@@ -0,0 +1,177 @@
+/*
+ *  Copyright 2014 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// Borrowed from Chromium's src/base/numerics/safe_conversions_impl.h.
+
+#ifndef RTC_BASE_NUMERICS_SAFE_CONVERSIONS_IMPL_H_
+#define RTC_BASE_NUMERICS_SAFE_CONVERSIONS_IMPL_H_
+
+#include <limits>
+
+namespace rtc {
+namespace internal {
+
+enum DstSign { DST_UNSIGNED, DST_SIGNED };
+
+enum SrcSign { SRC_UNSIGNED, SRC_SIGNED };
+
+enum DstRange { OVERLAPS_RANGE, CONTAINS_RANGE };
+
+// Helper templates to statically determine if our destination type can contain
+// all values represented by the source type.
+
+template <typename Dst,
+          typename Src,
+          DstSign IsDstSigned =
+              std::numeric_limits<Dst>::is_signed ? DST_SIGNED : DST_UNSIGNED,
+          SrcSign IsSrcSigned =
+              std::numeric_limits<Src>::is_signed ? SRC_SIGNED : SRC_UNSIGNED>
+struct StaticRangeCheck {};
+
+template <typename Dst, typename Src>
+struct StaticRangeCheck<Dst, Src, DST_SIGNED, SRC_SIGNED> {
+  typedef std::numeric_limits<Dst> DstLimits;
+  typedef std::numeric_limits<Src> SrcLimits;
+  // Compare based on max_exponent, which we must compute for integrals.
+  static const size_t kDstMaxExponent =
+      DstLimits::is_iec559 ? DstLimits::max_exponent : (sizeof(Dst) * 8 - 1);
+  static const size_t kSrcMaxExponent =
+      SrcLimits::is_iec559 ? SrcLimits::max_exponent : (sizeof(Src) * 8 - 1);
+  static const DstRange value =
+      kDstMaxExponent >= kSrcMaxExponent ? CONTAINS_RANGE : OVERLAPS_RANGE;
+};
+
+template <typename Dst, typename Src>
+struct StaticRangeCheck<Dst, Src, DST_UNSIGNED, SRC_UNSIGNED> {
+  static const DstRange value =
+      sizeof(Dst) >= sizeof(Src) ? CONTAINS_RANGE : OVERLAPS_RANGE;
+};
+
+template <typename Dst, typename Src>
+struct StaticRangeCheck<Dst, Src, DST_SIGNED, SRC_UNSIGNED> {
+  typedef std::numeric_limits<Dst> DstLimits;
+  typedef std::numeric_limits<Src> SrcLimits;
+  // Compare based on max_exponent, which we must compute for integrals.
+  static const size_t kDstMaxExponent =
+      DstLimits::is_iec559 ? DstLimits::max_exponent : (sizeof(Dst) * 8 - 1);
+  static const size_t kSrcMaxExponent = sizeof(Src) * 8;
+  static const DstRange value =
+      kDstMaxExponent >= kSrcMaxExponent ? CONTAINS_RANGE : OVERLAPS_RANGE;
+};
+
+template <typename Dst, typename Src>
+struct StaticRangeCheck<Dst, Src, DST_UNSIGNED, SRC_SIGNED> {
+  static const DstRange value = OVERLAPS_RANGE;
+};
+
+enum RangeCheckResult {
+  TYPE_VALID = 0,      // Value can be represented by the destination type.
+  TYPE_UNDERFLOW = 1,  // Value would overflow.
+  TYPE_OVERFLOW = 2,   // Value would underflow.
+  TYPE_INVALID = 3     // Source value is invalid (i.e. NaN).
+};
+
+// This macro creates a RangeCheckResult from an upper and lower bound
+// check by taking advantage of the fact that only NaN can be out of range in
+// both directions at once.
+#define BASE_NUMERIC_RANGE_CHECK_RESULT(is_in_upper_bound, is_in_lower_bound) \
+  RangeCheckResult(((is_in_upper_bound) ? 0 : TYPE_OVERFLOW) |                \
+                   ((is_in_lower_bound) ? 0 : TYPE_UNDERFLOW))
+
+template <typename Dst,
+          typename Src,
+          DstSign IsDstSigned =
+              std::numeric_limits<Dst>::is_signed ? DST_SIGNED : DST_UNSIGNED,
+          SrcSign IsSrcSigned =
+              std::numeric_limits<Src>::is_signed ? SRC_SIGNED : SRC_UNSIGNED,
+          DstRange IsSrcRangeContained = StaticRangeCheck<Dst, Src>::value>
+struct RangeCheckImpl {};
+
+// The following templates are for ranges that must be verified at runtime. We
+// split it into checks based on signedness to avoid confusing casts and
+// compiler warnings on signed an unsigned comparisons.
+
+// Dst range always contains the result: nothing to check.
+template <typename Dst, typename Src, DstSign IsDstSigned, SrcSign IsSrcSigned>
+struct RangeCheckImpl<Dst, Src, IsDstSigned, IsSrcSigned, CONTAINS_RANGE> {
+  static constexpr RangeCheckResult Check(Src value) { return TYPE_VALID; }
+};
+
+// Signed to signed narrowing.
+template <typename Dst, typename Src>
+struct RangeCheckImpl<Dst, Src, DST_SIGNED, SRC_SIGNED, OVERLAPS_RANGE> {
+  static constexpr RangeCheckResult Check(Src value) {
+    typedef std::numeric_limits<Dst> DstLimits;
+    return DstLimits::is_iec559
+               ? BASE_NUMERIC_RANGE_CHECK_RESULT(
+                     value <= static_cast<Src>(DstLimits::max()),
+                     value >= static_cast<Src>(DstLimits::max() * -1))
+               : BASE_NUMERIC_RANGE_CHECK_RESULT(
+                     value <= static_cast<Src>(DstLimits::max()),
+                     value >= static_cast<Src>(DstLimits::min()));
+  }
+};
+
+// Unsigned to unsigned narrowing.
+template <typename Dst, typename Src>
+struct RangeCheckImpl<Dst, Src, DST_UNSIGNED, SRC_UNSIGNED, OVERLAPS_RANGE> {
+  static constexpr RangeCheckResult Check(Src value) {
+    typedef std::numeric_limits<Dst> DstLimits;
+    return BASE_NUMERIC_RANGE_CHECK_RESULT(
+        value <= static_cast<Src>(DstLimits::max()), true);
+  }
+};
+
+// Unsigned to signed.
+template <typename Dst, typename Src>
+struct RangeCheckImpl<Dst, Src, DST_SIGNED, SRC_UNSIGNED, OVERLAPS_RANGE> {
+  static constexpr RangeCheckResult Check(Src value) {
+    typedef std::numeric_limits<Dst> DstLimits;
+    return sizeof(Dst) > sizeof(Src)
+               ? TYPE_VALID
+               : BASE_NUMERIC_RANGE_CHECK_RESULT(
+                     value <= static_cast<Src>(DstLimits::max()), true);
+  }
+};
+
+// Signed to unsigned.
+template <typename Dst, typename Src>
+struct RangeCheckImpl<Dst, Src, DST_UNSIGNED, SRC_SIGNED, OVERLAPS_RANGE> {
+  typedef std::numeric_limits<Dst> DstLimits;
+  typedef std::numeric_limits<Src> SrcLimits;
+  // Compare based on max_exponent, which we must compute for integrals.
+  static constexpr size_t DstMaxExponent() { return sizeof(Dst) * 8; }
+  static constexpr size_t SrcMaxExponent() {
+    return SrcLimits::is_iec559 ? SrcLimits::max_exponent
+                                : (sizeof(Src) * 8 - 1);
+  }
+  static constexpr RangeCheckResult Check(Src value) {
+    return (DstMaxExponent() >= SrcMaxExponent())
+               ? BASE_NUMERIC_RANGE_CHECK_RESULT(true,
+                                                 value >= static_cast<Src>(0))
+               : BASE_NUMERIC_RANGE_CHECK_RESULT(
+                     value <= static_cast<Src>(DstLimits::max()),
+                     value >= static_cast<Src>(0));
+  }
+};
+
+template <typename Dst, typename Src>
+inline constexpr RangeCheckResult RangeCheck(Src value) {
+  static_assert(std::numeric_limits<Src>::is_specialized,
+                "argument must be numeric");
+  static_assert(std::numeric_limits<Dst>::is_specialized,
+                "result must be numeric");
+  return RangeCheckImpl<Dst, Src>::Check(value);
+}
+
+}  // namespace internal
+}  // namespace rtc
+
+#endif  // RTC_BASE_NUMERICS_SAFE_CONVERSIONS_IMPL_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/numerics/safe_minmax.h b/third_party/webrtc_aec3/src/rtc_base/numerics/safe_minmax.h
new file mode 100644
index 0000000..6c41dfd
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/numerics/safe_minmax.h
@@ -0,0 +1,335 @@
+/*
+ *  Copyright 2017 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// Minimum and maximum
+// ===================
+//
+//   rtc::SafeMin(x, y)
+//   rtc::SafeMax(x, y)
+//
+// (These are both constexpr.)
+//
+// Accept two arguments of either any two integral or any two floating-point
+// types, and return the smaller and larger value, respectively, with no
+// truncation or wrap-around. If only one of the input types is statically
+// guaranteed to be able to represent the result, the return type is that type;
+// if either one would do, the result type is the smaller type. (One of these
+// two cases always applies.)
+//
+//   * The case with one floating-point and one integral type is not allowed,
+//     because the floating-point type will have greater range, but may not
+//     have sufficient precision to represent the integer value exactly.)
+//
+// Clamp (a.k.a. constrain to a given interval)
+// ============================================
+//
+//   rtc::SafeClamp(x, a, b)
+//
+// Accepts three arguments of any mix of integral types or any mix of
+// floating-point types, and returns the value in the closed interval [a, b]
+// that is closest to x (that is, if x < a it returns a; if x > b it returns b;
+// and if a <= x <= b it returns x). As for SafeMin() and SafeMax(), there is
+// no truncation or wrap-around. The result type
+//
+//   1. is statically guaranteed to be able to represent the result;
+//
+//   2. is no larger than the largest of the three argument types; and
+//
+//   3. has the same signedness as the type of the first argument, if this is
+//      possible without violating the First or Second Law.
+//
+// There is always at least one type that meets criteria 1 and 2. If more than
+// one type meets these criteria equally well, the result type is one of the
+// types that is smallest. Note that unlike SafeMin() and SafeMax(),
+// SafeClamp() will sometimes pick a return type that isn't the type of any of
+// its arguments.
+//
+//   * In this context, a type A is smaller than a type B if it has a smaller
+//     range; that is, if A::max() - A::min() < B::max() - B::min(). For
+//     example, int8_t < int16_t == uint16_t < int32_t, and all integral types
+//     are smaller than all floating-point types.)
+//
+//   * As for SafeMin and SafeMax, mixing integer and floating-point arguments
+//     is not allowed, because floating-point types have greater range than
+//     integer types, but do not have sufficient precision to represent the
+//     values of most integer types exactly.
+//
+// Requesting a specific return type
+// =================================
+//
+// All three functions allow callers to explicitly specify the return type as a
+// template parameter, overriding the default return type. E.g.
+//
+//   rtc::SafeMin<int>(x, y)  // returns an int
+//
+// If the requested type is statically guaranteed to be able to represent the
+// result, then everything's fine, and the return type is as requested. But if
+// the requested type is too small, a static_assert is triggered.
+
+#ifndef RTC_BASE_NUMERICS_SAFE_MINMAX_H_
+#define RTC_BASE_NUMERICS_SAFE_MINMAX_H_
+
+#include <limits>
+#include <type_traits>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_compare.h"
+#include "rtc_base/type_traits.h"
+
+namespace rtc {
+
+namespace safe_minmax_impl {
+
+// Make the range of a type available via something other than a constexpr
+// function, to work around MSVC limitations. See
+// https://blogs.msdn.microsoft.com/vcblog/2015/12/02/partial-support-for-expression-sfinae-in-vs-2015-update-1/
+template <typename T>
+struct Limits {
+  static constexpr T lowest = std::numeric_limits<T>::lowest();
+  static constexpr T max = std::numeric_limits<T>::max();
+};
+
+template <typename T, bool is_enum = std::is_enum<T>::value>
+struct UnderlyingType;
+
+template <typename T>
+struct UnderlyingType<T, false> {
+  using type = T;
+};
+
+template <typename T>
+struct UnderlyingType<T, true> {
+  using type = typename std::underlying_type<T>::type;
+};
+
+// Given two types T1 and T2, find types that can hold the smallest (in
+// ::min_t) and the largest (in ::max_t) of the two values.
+template <typename T1,
+          typename T2,
+          bool int1 = IsIntlike<T1>::value,
+          bool int2 = IsIntlike<T2>::value>
+struct MType {
+  static_assert(int1 == int2,
+                "You may not mix integral and floating-point arguments");
+};
+
+// Specialization for when neither type is integral (and therefore presumably
+// floating-point).
+template <typename T1, typename T2>
+struct MType<T1, T2, false, false> {
+  using min_t = typename std::common_type<T1, T2>::type;
+  static_assert(std::is_same<min_t, T1>::value ||
+                    std::is_same<min_t, T2>::value,
+                "");
+
+  using max_t = typename std::common_type<T1, T2>::type;
+  static_assert(std::is_same<max_t, T1>::value ||
+                    std::is_same<max_t, T2>::value,
+                "");
+};
+
+// Specialization for when both types are integral.
+template <typename T1, typename T2>
+struct MType<T1, T2, true, true> {
+  // The type with the lowest minimum value. In case of a tie, the type with
+  // the lowest maximum value. In case that too is a tie, the types have the
+  // same range, and we arbitrarily pick T1.
+  using min_t = typename std::conditional<
+      SafeLt(Limits<T1>::lowest, Limits<T2>::lowest),
+      T1,
+      typename std::conditional<
+          SafeGt(Limits<T1>::lowest, Limits<T2>::lowest),
+          T2,
+          typename std::conditional<SafeLe(Limits<T1>::max, Limits<T2>::max),
+                                    T1,
+                                    T2>::type>::type>::type;
+  static_assert(std::is_same<min_t, T1>::value ||
+                    std::is_same<min_t, T2>::value,
+                "");
+
+  // The type with the highest maximum value. In case of a tie, the types have
+  // the same range (because in C++, integer types with the same maximum also
+  // have the same minimum).
+  static_assert(SafeNe(Limits<T1>::max, Limits<T2>::max) ||
+                    SafeEq(Limits<T1>::lowest, Limits<T2>::lowest),
+                "integer types with the same max should have the same min");
+  using max_t = typename std::
+      conditional<SafeGe(Limits<T1>::max, Limits<T2>::max), T1, T2>::type;
+  static_assert(std::is_same<max_t, T1>::value ||
+                    std::is_same<max_t, T2>::value,
+                "");
+};
+
+// A dummy type that we pass around at compile time but never actually use.
+// Declared but not defined.
+struct DefaultType;
+
+// ::type is A, except we fall back to B if A is DefaultType. We static_assert
+// that the chosen type can hold all values that B can hold.
+template <typename A, typename B>
+struct TypeOr {
+  using type = typename std::
+      conditional<std::is_same<A, DefaultType>::value, B, A>::type;
+  static_assert(SafeLe(Limits<type>::lowest, Limits<B>::lowest) &&
+                    SafeGe(Limits<type>::max, Limits<B>::max),
+                "The specified type isn't large enough");
+  static_assert(IsIntlike<type>::value == IsIntlike<B>::value &&
+                    std::is_floating_point<type>::value ==
+                        std::is_floating_point<type>::value,
+                "float<->int conversions not allowed");
+};
+
+}  // namespace safe_minmax_impl
+
+template <
+    typename R = safe_minmax_impl::DefaultType,
+    typename T1 = safe_minmax_impl::DefaultType,
+    typename T2 = safe_minmax_impl::DefaultType,
+    typename R2 = typename safe_minmax_impl::TypeOr<
+        R,
+        typename safe_minmax_impl::MType<
+            typename safe_minmax_impl::UnderlyingType<T1>::type,
+            typename safe_minmax_impl::UnderlyingType<T2>::type>::min_t>::type>
+constexpr R2 SafeMin(T1 a, T2 b) {
+  static_assert(IsIntlike<T1>::value || std::is_floating_point<T1>::value,
+                "The first argument must be integral or floating-point");
+  static_assert(IsIntlike<T2>::value || std::is_floating_point<T2>::value,
+                "The second argument must be integral or floating-point");
+  return SafeLt(a, b) ? static_cast<R2>(a) : static_cast<R2>(b);
+}
+
+template <
+    typename R = safe_minmax_impl::DefaultType,
+    typename T1 = safe_minmax_impl::DefaultType,
+    typename T2 = safe_minmax_impl::DefaultType,
+    typename R2 = typename safe_minmax_impl::TypeOr<
+        R,
+        typename safe_minmax_impl::MType<
+            typename safe_minmax_impl::UnderlyingType<T1>::type,
+            typename safe_minmax_impl::UnderlyingType<T2>::type>::max_t>::type>
+constexpr R2 SafeMax(T1 a, T2 b) {
+  static_assert(IsIntlike<T1>::value || std::is_floating_point<T1>::value,
+                "The first argument must be integral or floating-point");
+  static_assert(IsIntlike<T2>::value || std::is_floating_point<T2>::value,
+                "The second argument must be integral or floating-point");
+  return SafeGt(a, b) ? static_cast<R2>(a) : static_cast<R2>(b);
+}
+
+namespace safe_minmax_impl {
+
+// Given three types T, L, and H, let ::type be a suitable return value for
+// SafeClamp(T, L, H). See the docs at the top of this file for details.
+template <typename T,
+          typename L,
+          typename H,
+          bool int1 = IsIntlike<T>::value,
+          bool int2 = IsIntlike<L>::value,
+          bool int3 = IsIntlike<H>::value>
+struct ClampType {
+  static_assert(int1 == int2 && int1 == int3,
+                "You may not mix integral and floating-point arguments");
+};
+
+// Specialization for when all three types are floating-point.
+template <typename T, typename L, typename H>
+struct ClampType<T, L, H, false, false, false> {
+  using type = typename std::common_type<T, L, H>::type;
+};
+
+// Specialization for when all three types are integral.
+template <typename T, typename L, typename H>
+struct ClampType<T, L, H, true, true, true> {
+ private:
+  // Range of the return value. The return type must be able to represent this
+  // full range.
+  static constexpr auto r_min =
+      SafeMax(Limits<L>::lowest, SafeMin(Limits<H>::lowest, Limits<T>::lowest));
+  static constexpr auto r_max =
+      SafeMin(Limits<H>::max, SafeMax(Limits<L>::max, Limits<T>::max));
+
+  // Is the given type an acceptable return type? (That is, can it represent
+  // all possible return values, and is it no larger than the largest of the
+  // input types?)
+  template <typename A>
+  struct AcceptableType {
+   private:
+    static constexpr bool not_too_large = sizeof(A) <= sizeof(L) ||
+                                          sizeof(A) <= sizeof(H) ||
+                                          sizeof(A) <= sizeof(T);
+    static constexpr bool range_contained =
+        SafeLe(Limits<A>::lowest, r_min) && SafeLe(r_max, Limits<A>::max);
+
+   public:
+    static constexpr bool value = not_too_large && range_contained;
+  };
+
+  using best_signed_type = typename std::conditional<
+      AcceptableType<int8_t>::value,
+      int8_t,
+      typename std::conditional<
+          AcceptableType<int16_t>::value,
+          int16_t,
+          typename std::conditional<AcceptableType<int32_t>::value,
+                                    int32_t,
+                                    int64_t>::type>::type>::type;
+
+  using best_unsigned_type = typename std::conditional<
+      AcceptableType<uint8_t>::value,
+      uint8_t,
+      typename std::conditional<
+          AcceptableType<uint16_t>::value,
+          uint16_t,
+          typename std::conditional<AcceptableType<uint32_t>::value,
+                                    uint32_t,
+                                    uint64_t>::type>::type>::type;
+
+ public:
+  // Pick the best type, preferring the same signedness as T but falling back
+  // to the other one if necessary.
+  using type = typename std::conditional<
+      std::is_signed<T>::value,
+      typename std::conditional<AcceptableType<best_signed_type>::value,
+                                best_signed_type,
+                                best_unsigned_type>::type,
+      typename std::conditional<AcceptableType<best_unsigned_type>::value,
+                                best_unsigned_type,
+                                best_signed_type>::type>::type;
+  static_assert(AcceptableType<type>::value, "");
+};
+
+}  // namespace safe_minmax_impl
+
+template <
+    typename R = safe_minmax_impl::DefaultType,
+    typename T = safe_minmax_impl::DefaultType,
+    typename L = safe_minmax_impl::DefaultType,
+    typename H = safe_minmax_impl::DefaultType,
+    typename R2 = typename safe_minmax_impl::TypeOr<
+        R,
+        typename safe_minmax_impl::ClampType<
+            typename safe_minmax_impl::UnderlyingType<T>::type,
+            typename safe_minmax_impl::UnderlyingType<L>::type,
+            typename safe_minmax_impl::UnderlyingType<H>::type>::type>::type>
+R2 SafeClamp(T x, L min, H max) {
+  static_assert(IsIntlike<H>::value || std::is_floating_point<H>::value,
+                "The first argument must be integral or floating-point");
+  static_assert(IsIntlike<T>::value || std::is_floating_point<T>::value,
+                "The second argument must be integral or floating-point");
+  static_assert(IsIntlike<L>::value || std::is_floating_point<L>::value,
+                "The third argument must be integral or floating-point");
+  RTC_DCHECK_LE(min, max);
+  return SafeLe(x, min)
+             ? static_cast<R2>(min)
+             : SafeGe(x, max) ? static_cast<R2>(max) : static_cast<R2>(x);
+}
+
+}  // namespace rtc
+
+#endif  // RTC_BASE_NUMERICS_SAFE_MINMAX_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/platform_thread_types.cc b/third_party/webrtc_aec3/src/rtc_base/platform_thread_types.cc
new file mode 100644
index 0000000..fc7a090
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/platform_thread_types.cc
@@ -0,0 +1,115 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "rtc_base/platform_thread_types.h"
+
+#if defined(WEBRTC_LINUX)
+#include <sys/prctl.h>
+#include <sys/syscall.h>
+#endif
+
+#if defined(WEBRTC_WIN)
+#include "rtc_base/arraysize.h"
+
+// The SetThreadDescription API was brought in version 1607 of Windows 10.
+// For compatibility with various versions of winuser and avoid clashing with
+// a potentially defined type, we use the RTC_ prefix.
+typedef HRESULT(WINAPI* RTC_SetThreadDescription)(HANDLE hThread,
+                                                  PCWSTR lpThreadDescription);
+#endif
+
+namespace rtc {
+
+PlatformThreadId CurrentThreadId() {
+#if defined(WEBRTC_WIN)
+  return GetCurrentThreadId();
+#elif defined(WEBRTC_POSIX)
+#if defined(WEBRTC_MAC) || defined(WEBRTC_IOS)
+  return pthread_mach_thread_np(pthread_self());
+#elif defined(WEBRTC_ANDROID)
+  return gettid();
+#elif defined(WEBRTC_FUCHSIA)
+  return zx_thread_self();
+#elif defined(WEBRTC_LINUX)
+  return syscall(__NR_gettid);
+#elif defined(__EMSCRIPTEN__)
+  return static_cast<PlatformThreadId>(pthread_self());
+#else
+  // Default implementation for nacl and solaris.
+  return reinterpret_cast<PlatformThreadId>(pthread_self());
+#endif
+#endif  // defined(WEBRTC_POSIX)
+}
+
+PlatformThreadRef CurrentThreadRef() {
+#if defined(WEBRTC_WIN)
+  return GetCurrentThreadId();
+#elif defined(WEBRTC_FUCHSIA)
+  return zx_thread_self();
+#elif defined(WEBRTC_POSIX)
+  return pthread_self();
+#endif
+}
+
+bool IsThreadRefEqual(const PlatformThreadRef& a, const PlatformThreadRef& b) {
+#if defined(WEBRTC_WIN) || defined(WEBRTC_FUCHSIA)
+  return a == b;
+#elif defined(WEBRTC_POSIX)
+  return pthread_equal(a, b);
+#endif
+}
+
+void SetCurrentThreadName(const char* name) {
+#if defined(WEBRTC_WIN)
+  // The SetThreadDescription API works even if no debugger is attached.
+  // The names set with this API also show up in ETW traces. Very handy.
+  static auto set_thread_description_func =
+      reinterpret_cast<RTC_SetThreadDescription>(::GetProcAddress(
+          ::GetModuleHandleA("Kernel32.dll"), "SetThreadDescription"));
+  if (set_thread_description_func) {
+    // Convert from ASCII to UTF-16.
+    wchar_t wide_thread_name[64];
+    for (size_t i = 0; i < arraysize(wide_thread_name) - 1; ++i) {
+      wide_thread_name[i] = name[i];
+      if (wide_thread_name[i] == L'\0')
+        break;
+    }
+    // Guarantee null-termination.
+    wide_thread_name[arraysize(wide_thread_name) - 1] = L'\0';
+    set_thread_description_func(::GetCurrentThread(), wide_thread_name);
+  }
+
+  // For details see:
+  // https://docs.microsoft.com/en-us/visualstudio/debugger/how-to-set-a-thread-name-in-native-code
+#pragma pack(push, 8)
+  struct {
+    DWORD dwType;
+    LPCSTR szName;
+    DWORD dwThreadID;
+    DWORD dwFlags;
+  } threadname_info = {0x1000, name, static_cast<DWORD>(-1), 0};
+#pragma pack(pop)
+
+#pragma warning(push)
+#pragma warning(disable : 6320 6322)
+  __try {
+    ::RaiseException(0x406D1388, 0, sizeof(threadname_info) / sizeof(ULONG_PTR),
+                     reinterpret_cast<ULONG_PTR*>(&threadname_info));
+  } __except (EXCEPTION_EXECUTE_HANDLER) {  // NOLINT
+  }
+#pragma warning(pop)
+#elif defined(WEBRTC_LINUX) // || defined(WEBRTC_ANDROID)
+  prctl(PR_SET_NAME, reinterpret_cast<unsigned long>(name));  // NOLINT
+#elif defined(WEBRTC_MAC) || defined(WEBRTC_IOS)
+  pthread_setname_np(name);
+#endif
+}
+
+}  // namespace rtc
diff --git a/third_party/webrtc_aec3/src/rtc_base/platform_thread_types.h b/third_party/webrtc_aec3/src/rtc_base/platform_thread_types.h
new file mode 100644
index 0000000..6b9101e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/platform_thread_types.h
@@ -0,0 +1,62 @@
+/*
+ *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_PLATFORM_THREAD_TYPES_H_
+#define RTC_BASE_PLATFORM_THREAD_TYPES_H_
+
+// clang-format off
+// clang formating would change include order.
+#if defined(WEBRTC_WIN)
+// Include winsock2.h before including <windows.h> to maintain consistency with
+// win32.h. To include win32.h directly, it must be broken out into its own
+// build target.
+#include <winsock2.h>
+#include <windows.h>
+#elif defined(WEBRTC_FUCHSIA)
+#include <zircon/types.h>
+#include <zircon/process.h>
+#elif defined(WEBRTC_POSIX)
+#include <pthread.h>
+#include <unistd.h>
+#if defined(WEBRTC_MAC)
+#include <pthread_spis.h>
+#endif
+#endif
+// clang-format on
+
+namespace rtc {
+#if defined(WEBRTC_WIN)
+typedef DWORD PlatformThreadId;
+typedef DWORD PlatformThreadRef;
+#elif defined(WEBRTC_FUCHSIA)
+typedef zx_handle_t PlatformThreadId;
+typedef zx_handle_t PlatformThreadRef;
+#elif defined(WEBRTC_POSIX)
+typedef pid_t PlatformThreadId;
+typedef pthread_t PlatformThreadRef;
+#endif
+
+// Retrieve the ID of the current thread.
+PlatformThreadId CurrentThreadId();
+
+// Retrieves a reference to the current thread. On Windows, this is the same
+// as CurrentThreadId. On other platforms it's the pthread_t returned by
+// pthread_self().
+PlatformThreadRef CurrentThreadRef();
+
+// Compares two thread identifiers for equality.
+bool IsThreadRefEqual(const PlatformThreadRef& a, const PlatformThreadRef& b);
+
+// Sets the current thread name.
+void SetCurrentThreadName(const char* name);
+
+}  // namespace rtc
+
+#endif  // RTC_BASE_PLATFORM_THREAD_TYPES_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/race_checker.cc b/third_party/webrtc_aec3/src/rtc_base/race_checker.cc
new file mode 100644
index 0000000..bf9dfdc
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/race_checker.cc
@@ -0,0 +1,54 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "rtc_base/race_checker.h"
+
+namespace rtc {
+
+RaceChecker::RaceChecker() {}
+
+// Note that the implementation here is in itself racy, but we pretend it does
+// not matter because we want this useful in release builds without having to
+// pay the cost of using atomics. A race hitting the race checker is likely to
+// cause access_count_ to diverge from zero and therefore cause the ThreadRef
+// comparison to fail, signaling a race, although it may not be in the exact
+// spot where a race *first* appeared in the code we're trying to protect. There
+// is also a chance that an actual race is missed, however the probability of
+// that has been considered small enough to be an acceptable trade off.
+bool RaceChecker::Acquire() const {
+  const PlatformThreadRef current_thread = CurrentThreadRef();
+  // Set new accessing thread if this is a new use.
+  if (access_count_++ == 0)
+    accessing_thread_ = current_thread;
+  // If this is being used concurrently this check will fail for the second
+  // thread entering since it won't set the thread. Recursive use of checked
+  // methods are OK since the accessing thread remains the same.
+  const PlatformThreadRef accessing_thread = accessing_thread_;
+  return IsThreadRefEqual(accessing_thread, current_thread);
+}
+
+void RaceChecker::Release() const {
+  --access_count_;
+}
+
+namespace internal {
+RaceCheckerScope::RaceCheckerScope(const RaceChecker* race_checker)
+    : race_checker_(race_checker), race_check_ok_(race_checker->Acquire()) {}
+
+bool RaceCheckerScope::RaceDetected() const {
+  return !race_check_ok_;
+}
+
+RaceCheckerScope::~RaceCheckerScope() {
+  race_checker_->Release();
+}
+
+}  // namespace internal
+}  // namespace rtc
diff --git a/third_party/webrtc_aec3/src/rtc_base/race_checker.h b/third_party/webrtc_aec3/src/rtc_base/race_checker.h
new file mode 100644
index 0000000..4d57460
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/race_checker.h
@@ -0,0 +1,78 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_RACE_CHECKER_H_
+#define RTC_BASE_RACE_CHECKER_H_
+
+#include "rtc_base/checks.h"
+#include "rtc_base/platform_thread_types.h"
+#include "rtc_base/thread_annotations.h"
+
+namespace rtc {
+
+namespace internal {
+class RaceCheckerScope;
+}  // namespace internal
+
+// Best-effort race-checking implementation. This primitive uses no
+// synchronization at all to be as-fast-as-possible in the non-racy case.
+class RTC_LOCKABLE RaceChecker {
+ public:
+  friend class internal::RaceCheckerScope;
+  RaceChecker();
+
+ private:
+  bool Acquire() const RTC_EXCLUSIVE_LOCK_FUNCTION();
+  void Release() const RTC_UNLOCK_FUNCTION();
+
+  // Volatile to prevent code being optimized away in Acquire()/Release().
+  mutable volatile int access_count_ = 0;
+  mutable volatile PlatformThreadRef accessing_thread_;
+};
+
+namespace internal {
+class RTC_SCOPED_LOCKABLE RaceCheckerScope {
+ public:
+  explicit RaceCheckerScope(const RaceChecker* race_checker)
+      RTC_EXCLUSIVE_LOCK_FUNCTION(race_checker);
+
+  bool RaceDetected() const;
+  ~RaceCheckerScope() RTC_UNLOCK_FUNCTION();
+
+ private:
+  const RaceChecker* const race_checker_;
+  const bool race_check_ok_;
+};
+
+class RTC_SCOPED_LOCKABLE RaceCheckerScopeDoNothing {
+ public:
+  explicit RaceCheckerScopeDoNothing(const RaceChecker* race_checker)
+      RTC_EXCLUSIVE_LOCK_FUNCTION(race_checker) {}
+
+  ~RaceCheckerScopeDoNothing() RTC_UNLOCK_FUNCTION() {}
+};
+
+}  // namespace internal
+}  // namespace rtc
+
+#define RTC_CHECK_RUNS_SERIALIZED(x)               \
+  rtc::internal::RaceCheckerScope race_checker(x); \
+  RTC_CHECK(!race_checker.RaceDetected())
+
+#if RTC_DCHECK_IS_ON
+#define RTC_DCHECK_RUNS_SERIALIZED(x)              \
+  rtc::internal::RaceCheckerScope race_checker(x); \
+  RTC_DCHECK(!race_checker.RaceDetected())
+#else
+#define RTC_DCHECK_RUNS_SERIALIZED(x) \
+  rtc::internal::RaceCheckerScopeDoNothing race_checker(x)
+#endif
+
+#endif  // RTC_BASE_RACE_CHECKER_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/random.cc b/third_party/webrtc_aec3/src/rtc_base/random.cc
new file mode 100644
index 0000000..5deb621
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/random.cc
@@ -0,0 +1,85 @@
+/*
+ *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "rtc_base/random.h"
+
+#include <math.h>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_conversions.h"
+
+namespace webrtc {
+
+Random::Random(uint64_t seed) {
+  RTC_DCHECK(seed != 0x0ull);
+  state_ = seed;
+}
+
+uint32_t Random::Rand(uint32_t t) {
+  // Casting the output to 32 bits will give an almost uniform number.
+  // Pr[x=0] = (2^32-1) / (2^64-1)
+  // Pr[x=k] = 2^32 / (2^64-1) for k!=0
+  // Uniform would be Pr[x=k] = 2^32 / 2^64 for all 32-bit integers k.
+  uint32_t x = NextOutput();
+  // If x / 2^32 is uniform on [0,1), then x / 2^32 * (t+1) is uniform on
+  // the interval [0,t+1), so the integer part is uniform on [0,t].
+  uint64_t result = x * (static_cast<uint64_t>(t) + 1);
+  result >>= 32;
+  return result;
+}
+
+uint32_t Random::Rand(uint32_t low, uint32_t high) {
+  RTC_DCHECK(low <= high);
+  return Rand(high - low) + low;
+}
+
+int32_t Random::Rand(int32_t low, int32_t high) {
+  RTC_DCHECK(low <= high);
+  const int64_t low_i64{low};
+  return rtc::dchecked_cast<int32_t>(
+      Rand(rtc::dchecked_cast<uint32_t>(high - low_i64)) + low_i64);
+}
+
+template <>
+float Random::Rand<float>() {
+  double result = NextOutput() - 1;
+  result = result / 0xFFFFFFFFFFFFFFFEull;
+  return static_cast<float>(result);
+}
+
+template <>
+double Random::Rand<double>() {
+  double result = NextOutput() - 1;
+  result = result / 0xFFFFFFFFFFFFFFFEull;
+  return result;
+}
+
+template <>
+bool Random::Rand<bool>() {
+  return Rand(0, 1) == 1;
+}
+
+double Random::Gaussian(double mean, double standard_deviation) {
+  // Creating a Normal distribution variable from two independent uniform
+  // variables based on the Box-Muller transform, which is defined on the
+  // interval (0, 1]. Note that we rely on NextOutput to generate integers
+  // in the range [1, 2^64-1]. Normally this behavior is a bit frustrating,
+  // but here it is exactly what we need.
+  const double kPi = 3.14159265358979323846;
+  double u1 = static_cast<double>(NextOutput()) / 0xFFFFFFFFFFFFFFFFull;
+  double u2 = static_cast<double>(NextOutput()) / 0xFFFFFFFFFFFFFFFFull;
+  return mean + standard_deviation * sqrt(-2 * log(u1)) * cos(2 * kPi * u2);
+}
+
+double Random::Exponential(double lambda) {
+  double uniform = Rand<double>();
+  return -log(uniform) / lambda;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/rtc_base/random.h b/third_party/webrtc_aec3/src/rtc_base/random.h
new file mode 100644
index 0000000..b3b9fd1
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/random.h
@@ -0,0 +1,96 @@
+/*
+ *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_RANDOM_H_
+#define RTC_BASE_RANDOM_H_
+
+#include <stdint.h>
+
+#include <limits>
+
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+class Random {
+ public:
+  // TODO(tommi): Change this so that the seed can be initialized internally,
+  // e.g. by offering two ways of constructing or offer a static method that
+  // returns a seed that's suitable for initialization.
+  // The problem now is that callers are calling clock_->TimeInMicroseconds()
+  // which calls TickTime::Now().Ticks(), which can return a very low value on
+  // Mac and can result in a seed of 0 after conversion to microseconds.
+  // Besides the quality of the random seed being poor, this also requires
+  // the client to take on extra dependencies to generate a seed.
+  // If we go for a static seed generator in Random, we can use something from
+  // webrtc/rtc_base and make sure that it works the same way across platforms.
+  // See also discussion here: https://codereview.webrtc.org/1623543002/
+  explicit Random(uint64_t seed);
+
+  Random() = delete;
+  Random(const Random&) = delete;
+  Random& operator=(const Random&) = delete;
+
+  // Return pseudo-random integer of the specified type.
+  // We need to limit the size to 32 bits to keep the output close to uniform.
+  template <typename T>
+  T Rand() {
+    static_assert(std::numeric_limits<T>::is_integer &&
+                      std::numeric_limits<T>::radix == 2 &&
+                      std::numeric_limits<T>::digits <= 32,
+                  "Rand is only supported for built-in integer types that are "
+                  "32 bits or smaller.");
+    return static_cast<T>(NextOutput());
+  }
+
+  // Uniformly distributed pseudo-random number in the interval [0, t].
+  uint32_t Rand(uint32_t t);
+
+  // Uniformly distributed pseudo-random number in the interval [low, high].
+  uint32_t Rand(uint32_t low, uint32_t high);
+
+  // Uniformly distributed pseudo-random number in the interval [low, high].
+  int32_t Rand(int32_t low, int32_t high);
+
+  // Normal Distribution.
+  double Gaussian(double mean, double standard_deviation);
+
+  // Exponential Distribution.
+  double Exponential(double lambda);
+
+ private:
+  // Outputs a nonzero 64-bit random number using Xorshift algorithm.
+  // https://en.wikipedia.org/wiki/Xorshift
+  uint64_t NextOutput() {
+    state_ ^= state_ >> 12;
+    state_ ^= state_ << 25;
+    state_ ^= state_ >> 27;
+    RTC_DCHECK(state_ != 0x0ULL);
+    return state_ * 2685821657736338717ull;
+  }
+
+  uint64_t state_;
+};
+
+// Return pseudo-random number in the interval [0.0, 1.0).
+template <>
+float Random::Rand<float>();
+
+// Return pseudo-random number in the interval [0.0, 1.0).
+template <>
+double Random::Rand<double>();
+
+// Return pseudo-random boolean value.
+template <>
+bool Random::Rand<bool>();
+
+}  // namespace webrtc
+
+#endif  // RTC_BASE_RANDOM_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/ref_count.h b/third_party/webrtc_aec3/src/rtc_base/ref_count.h
new file mode 100644
index 0000000..d8d652a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/ref_count.h
@@ -0,0 +1,67 @@
+/*
+ *  Copyright 2011 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#ifndef RTC_BASE_REF_COUNT_H_
+#define RTC_BASE_REF_COUNT_H_
+
+namespace rtc {
+
+// Refcounted objects should implement the following informal interface:
+//
+// void AddRef() const ;
+// RefCountReleaseStatus Release() const;
+//
+// You may access members of a reference-counted object, including the AddRef()
+// and Release() methods, only if you already own a reference to it, or if
+// you're borrowing someone else's reference. (A newly created object is a
+// special case: the reference count is zero on construction, and the code that
+// creates the object should immediately call AddRef(), bringing the reference
+// count from zero to one, e.g., by constructing an rtc::scoped_refptr).
+//
+// AddRef() creates a new reference to the object.
+//
+// Release() releases a reference to the object; the caller now has one less
+// reference than before the call. Returns kDroppedLastRef if the number of
+// references dropped to zero because of this (in which case the object destroys
+// itself). Otherwise, returns kOtherRefsRemained, to signal that at the precise
+// time the caller's reference was dropped, other references still remained (but
+// if other threads own references, this may of course have changed by the time
+// Release() returns).
+//
+// The caller of Release() must treat it in the same way as a delete operation:
+// Regardless of the return value from Release(), the caller mustn't access the
+// object. The object might still be alive, due to references held by other
+// users of the object, but the object can go away at any time, e.g., as the
+// result of another thread calling Release().
+//
+// Calling AddRef() and Release() manually is discouraged. It's recommended to
+// use rtc::scoped_refptr to manage all pointers to reference counted objects.
+// Note that rtc::scoped_refptr depends on compile-time duck-typing; formally
+// implementing the below RefCountInterface is not required.
+
+enum class RefCountReleaseStatus { kDroppedLastRef, kOtherRefsRemained };
+
+// Interfaces where refcounting is part of the public api should
+// inherit this abstract interface. The implementation of these
+// methods is usually provided by the RefCountedObject template class,
+// applied as a leaf in the inheritance tree.
+class RefCountInterface {
+ public:
+  virtual void AddRef() const = 0;
+  virtual RefCountReleaseStatus Release() const = 0;
+
+  // Non-public destructor, because Release() has exclusive responsibility for
+  // destroying the object.
+ protected:
+  virtual ~RefCountInterface() {}
+};
+
+}  // namespace rtc
+
+#endif  // RTC_BASE_REF_COUNT_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/ref_counted_object.h b/third_party/webrtc_aec3/src/rtc_base/ref_counted_object.h
new file mode 100644
index 0000000..873eacc
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/ref_counted_object.h
@@ -0,0 +1,88 @@
+/*
+ *  Copyright 2016 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#ifndef RTC_BASE_REF_COUNTED_OBJECT_H_
+#define RTC_BASE_REF_COUNTED_OBJECT_H_
+
+#include <type_traits>
+#include <utility>
+
+#include "rtc_base/constructor_magic.h"
+#include "rtc_base/ref_count.h"
+#include "rtc_base/ref_counter.h"
+
+namespace rtc {
+
+template <class T>
+class RefCountedObject : public T {
+ public:
+  RefCountedObject() {}
+
+  template <class P0>
+  explicit RefCountedObject(P0&& p0) : T(std::forward<P0>(p0)) {}
+
+  template <class P0, class P1, class... Args>
+  RefCountedObject(P0&& p0, P1&& p1, Args&&... args)
+      : T(std::forward<P0>(p0),
+          std::forward<P1>(p1),
+          std::forward<Args>(args)...) {}
+
+  virtual void AddRef() const { ref_count_.IncRef(); }
+
+  virtual RefCountReleaseStatus Release() const {
+    const auto status = ref_count_.DecRef();
+    if (status == RefCountReleaseStatus::kDroppedLastRef) {
+      delete this;
+    }
+    return status;
+  }
+
+  // Return whether the reference count is one. If the reference count is used
+  // in the conventional way, a reference count of 1 implies that the current
+  // thread owns the reference and no other thread shares it. This call
+  // performs the test for a reference count of one, and performs the memory
+  // barrier needed for the owning thread to act on the object, knowing that it
+  // has exclusive access to the object.
+  virtual bool HasOneRef() const { return ref_count_.HasOneRef(); }
+
+ protected:
+  virtual ~RefCountedObject() {}
+
+  mutable webrtc::webrtc_impl::RefCounter ref_count_{0};
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(RefCountedObject);
+};
+
+template <class T>
+class FinalRefCountedObject final : public T {
+ public:
+  using T::T;
+  // Until c++17 compilers are allowed not to inherit the default constructor,
+  // and msvc doesn't. Thus the default constructor is forwarded explicitly.
+  FinalRefCountedObject() = default;
+  FinalRefCountedObject(const FinalRefCountedObject&) = delete;
+  FinalRefCountedObject& operator=(const FinalRefCountedObject&) = delete;
+
+  void AddRef() const { ref_count_.IncRef(); }
+  void Release() const {
+    if (ref_count_.DecRef() == RefCountReleaseStatus::kDroppedLastRef) {
+      delete this;
+    }
+  }
+  bool HasOneRef() const { return ref_count_.HasOneRef(); }
+
+ private:
+  ~FinalRefCountedObject() = default;
+
+  mutable webrtc::webrtc_impl::RefCounter ref_count_{0};
+};
+
+}  // namespace rtc
+
+#endif  // RTC_BASE_REF_COUNTED_OBJECT_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/ref_counter.h b/third_party/webrtc_aec3/src/rtc_base/ref_counter.h
new file mode 100644
index 0000000..6ffeda8
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/ref_counter.h
@@ -0,0 +1,75 @@
+/*
+ *  Copyright 2017 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#ifndef RTC_BASE_REF_COUNTER_H_
+#define RTC_BASE_REF_COUNTER_H_
+
+#include <atomic>
+
+#include "rtc_base/ref_count.h"
+
+namespace webrtc {
+namespace webrtc_impl {
+
+class RefCounter {
+ public:
+  explicit RefCounter(int ref_count) : ref_count_(ref_count) {}
+  RefCounter() = delete;
+
+  void IncRef() {
+    // Relaxed memory order: The current thread is allowed to act on the
+    // resource protected by the reference counter both before and after the
+    // atomic op, so this function doesn't prevent memory access reordering.
+    ref_count_.fetch_add(1, std::memory_order_relaxed);
+  }
+
+  // Returns kDroppedLastRef if this call dropped the last reference; the caller
+  // should therefore free the resource protected by the reference counter.
+  // Otherwise, returns kOtherRefsRemained (note that in case of multithreading,
+  // some other caller may have dropped the last reference by the time this call
+  // returns; all we know is that we didn't do it).
+  rtc::RefCountReleaseStatus DecRef() {
+    // Use release-acquire barrier to ensure all actions on the protected
+    // resource are finished before the resource can be freed.
+    // When ref_count_after_subtract > 0, this function require
+    // std::memory_order_release part of the barrier.
+    // When ref_count_after_subtract == 0, this function require
+    // std::memory_order_acquire part of the barrier.
+    // In addition std::memory_order_release is used for synchronization with
+    // the HasOneRef function to make sure all actions on the protected resource
+    // are finished before the resource is assumed to have exclusive access.
+    int ref_count_after_subtract =
+        ref_count_.fetch_sub(1, std::memory_order_acq_rel) - 1;
+    return ref_count_after_subtract == 0
+               ? rtc::RefCountReleaseStatus::kDroppedLastRef
+               : rtc::RefCountReleaseStatus::kOtherRefsRemained;
+  }
+
+  // Return whether the reference count is one. If the reference count is used
+  // in the conventional way, a reference count of 1 implies that the current
+  // thread owns the reference and no other thread shares it. This call performs
+  // the test for a reference count of one, and performs the memory barrier
+  // needed for the owning thread to act on the resource protected by the
+  // reference counter, knowing that it has exclusive access.
+  bool HasOneRef() const {
+    // To ensure resource protected by the reference counter has exclusive
+    // access, all changes to the resource before it was released by other
+    // threads must be visible by current thread. That is provided by release
+    // (in DecRef) and acquire (in this function) ordering.
+    return ref_count_.load(std::memory_order_acquire) == 1;
+  }
+
+ private:
+  std::atomic<int> ref_count_;
+};
+
+}  // namespace webrtc_impl
+}  // namespace webrtc
+
+#endif  // RTC_BASE_REF_COUNTER_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/string_encode.cc b/third_party/webrtc_aec3/src/rtc_base/string_encode.cc
new file mode 100644
index 0000000..1570b93
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/string_encode.cc
@@ -0,0 +1,387 @@
+/*
+ *  Copyright 2004 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "rtc_base/string_encode.h"
+
+#include <cstdio>
+
+#include "rtc_base/arraysize.h"
+#include "rtc_base/checks.h"
+
+namespace rtc {
+
+/////////////////////////////////////////////////////////////////////////////
+// String Encoding Utilities
+/////////////////////////////////////////////////////////////////////////////
+
+namespace {
+const char HEX[] = "0123456789abcdef";
+
+// Convert an unsigned value from 0 to 15 to the hex character equivalent...
+char hex_encode(unsigned char val) {
+  RTC_DCHECK_LT(val, 16);
+  return (val < 16) ? HEX[val] : '!';
+}
+
+// ...and vice-versa.
+bool hex_decode(char ch, unsigned char* val) {
+  if ((ch >= '0') && (ch <= '9')) {
+    *val = ch - '0';
+  } else if ((ch >= 'A') && (ch <= 'F')) {
+    *val = (ch - 'A') + 10;
+  } else if ((ch >= 'a') && (ch <= 'f')) {
+    *val = (ch - 'a') + 10;
+  } else {
+    return false;
+  }
+  return true;
+}
+
+size_t hex_encode_output_length(size_t srclen, char delimiter) {
+  return delimiter && srclen > 0 ? (srclen * 3 - 1) : (srclen * 2);
+}
+
+// hex_encode shows the hex representation of binary data in ascii, with
+// |delimiter| between bytes, or none if |delimiter| == 0.
+void hex_encode_with_delimiter(char* buffer,
+                               const char* csource,
+                               size_t srclen,
+                               char delimiter) {
+  RTC_DCHECK(buffer);
+
+  // Init and check bounds.
+  const unsigned char* bsource =
+      reinterpret_cast<const unsigned char*>(csource);
+  size_t srcpos = 0, bufpos = 0;
+
+  while (srcpos < srclen) {
+    unsigned char ch = bsource[srcpos++];
+    buffer[bufpos] = hex_encode((ch >> 4) & 0xF);
+    buffer[bufpos + 1] = hex_encode((ch)&0xF);
+    bufpos += 2;
+
+    // Don't write a delimiter after the last byte.
+    if (delimiter && (srcpos < srclen)) {
+      buffer[bufpos] = delimiter;
+      ++bufpos;
+    }
+  }
+}
+
+}  // namespace
+
+std::string hex_encode(const std::string& str) {
+  return hex_encode(str.c_str(), str.size());
+}
+
+std::string hex_encode(const char* source, size_t srclen) {
+  return hex_encode_with_delimiter(source, srclen, 0);
+}
+
+std::string hex_encode_with_delimiter(const char* source,
+                                      size_t srclen,
+                                      char delimiter) {
+  std::string s(hex_encode_output_length(srclen, delimiter), 0);
+  hex_encode_with_delimiter(&s[0], source, srclen, delimiter);
+  return s;
+}
+
+size_t hex_decode(char* cbuffer,
+                  size_t buflen,
+                  const char* source,
+                  size_t srclen) {
+  return hex_decode_with_delimiter(cbuffer, buflen, source, srclen, 0);
+}
+
+size_t hex_decode_with_delimiter(char* cbuffer,
+                                 size_t buflen,
+                                 const char* source,
+                                 size_t srclen,
+                                 char delimiter) {
+  RTC_DCHECK(cbuffer);  // TODO(kwiberg): estimate output size
+  if (buflen == 0)
+    return 0;
+
+  // Init and bounds check.
+  unsigned char* bbuffer = reinterpret_cast<unsigned char*>(cbuffer);
+  size_t srcpos = 0, bufpos = 0;
+  size_t needed = (delimiter) ? (srclen + 1) / 3 : srclen / 2;
+  if (buflen < needed)
+    return 0;
+
+  while (srcpos < srclen) {
+    if ((srclen - srcpos) < 2) {
+      // This means we have an odd number of bytes.
+      return 0;
+    }
+
+    unsigned char h1, h2;
+    if (!hex_decode(source[srcpos], &h1) ||
+        !hex_decode(source[srcpos + 1], &h2))
+      return 0;
+
+    bbuffer[bufpos++] = (h1 << 4) | h2;
+    srcpos += 2;
+
+    // Remove the delimiter if needed.
+    if (delimiter && (srclen - srcpos) > 1) {
+      if (source[srcpos] != delimiter)
+        return 0;
+      ++srcpos;
+    }
+  }
+
+  return bufpos;
+}
+
+size_t hex_decode(char* buffer, size_t buflen, const std::string& source) {
+  return hex_decode_with_delimiter(buffer, buflen, source, 0);
+}
+size_t hex_decode_with_delimiter(char* buffer,
+                                 size_t buflen,
+                                 const std::string& source,
+                                 char delimiter) {
+  return hex_decode_with_delimiter(buffer, buflen, source.c_str(),
+                                   source.length(), delimiter);
+}
+
+size_t tokenize(const std::string& source,
+                char delimiter,
+                std::vector<std::string>* fields) {
+  fields->clear();
+  size_t last = 0;
+  for (size_t i = 0; i < source.length(); ++i) {
+    if (source[i] == delimiter) {
+      if (i != last) {
+        fields->push_back(source.substr(last, i - last));
+      }
+      last = i + 1;
+    }
+  }
+  if (last != source.length()) {
+    fields->push_back(source.substr(last, source.length() - last));
+  }
+  return fields->size();
+}
+
+size_t tokenize_with_empty_tokens(const std::string& source,
+                                  char delimiter,
+                                  std::vector<std::string>* fields) {
+  fields->clear();
+  size_t last = 0;
+  for (size_t i = 0; i < source.length(); ++i) {
+    if (source[i] == delimiter) {
+      fields->push_back(source.substr(last, i - last));
+      last = i + 1;
+    }
+  }
+  fields->push_back(source.substr(last, source.length() - last));
+  return fields->size();
+}
+
+size_t tokenize_append(const std::string& source,
+                       char delimiter,
+                       std::vector<std::string>* fields) {
+  if (!fields)
+    return 0;
+
+  std::vector<std::string> new_fields;
+  tokenize(source, delimiter, &new_fields);
+  fields->insert(fields->end(), new_fields.begin(), new_fields.end());
+  return fields->size();
+}
+
+size_t tokenize(const std::string& source,
+                char delimiter,
+                char start_mark,
+                char end_mark,
+                std::vector<std::string>* fields) {
+  if (!fields)
+    return 0;
+  fields->clear();
+
+  std::string remain_source = source;
+  while (!remain_source.empty()) {
+    size_t start_pos = remain_source.find(start_mark);
+    if (std::string::npos == start_pos)
+      break;
+    std::string pre_mark;
+    if (start_pos > 0) {
+      pre_mark = remain_source.substr(0, start_pos - 1);
+    }
+
+    ++start_pos;
+    size_t end_pos = remain_source.find(end_mark, start_pos);
+    if (std::string::npos == end_pos)
+      break;
+
+    // We have found the matching marks. First tokenize the pre-mask. Then add
+    // the marked part as a single field. Finally, loop back for the post-mark.
+    tokenize_append(pre_mark, delimiter, fields);
+    fields->push_back(remain_source.substr(start_pos, end_pos - start_pos));
+    remain_source = remain_source.substr(end_pos + 1);
+  }
+
+  return tokenize_append(remain_source, delimiter, fields);
+}
+
+bool tokenize_first(const std::string& source,
+                    const char delimiter,
+                    std::string* token,
+                    std::string* rest) {
+  // Find the first delimiter
+  size_t left_pos = source.find(delimiter);
+  if (left_pos == std::string::npos) {
+    return false;
+  }
+
+  // Look for additional occurrances of delimiter.
+  size_t right_pos = left_pos + 1;
+  while (source[right_pos] == delimiter) {
+    right_pos++;
+  }
+
+  *token = source.substr(0, left_pos);
+  *rest = source.substr(right_pos);
+  return true;
+}
+
+std::string join(const std::vector<std::string>& source, char delimiter) {
+  if (source.size() == 0) {
+    return std::string();
+  }
+  // Find length of the string to be returned to pre-allocate memory.
+  size_t source_string_length = 0;
+  for (size_t i = 0; i < source.size(); ++i) {
+    source_string_length += source[i].length();
+  }
+
+  // Build the joined string.
+  std::string joined_string;
+  joined_string.reserve(source_string_length + source.size() - 1);
+  for (size_t i = 0; i < source.size(); ++i) {
+    if (i != 0) {
+      joined_string += delimiter;
+    }
+    joined_string += source[i];
+  }
+  return joined_string;
+}
+
+size_t split(const std::string& source,
+             char delimiter,
+             std::vector<std::string>* fields) {
+  RTC_DCHECK(fields);
+  fields->clear();
+  size_t last = 0;
+  for (size_t i = 0; i < source.length(); ++i) {
+    if (source[i] == delimiter) {
+      fields->push_back(source.substr(last, i - last));
+      last = i + 1;
+    }
+  }
+  fields->push_back(source.substr(last, source.length() - last));
+  return fields->size();
+}
+
+std::string ToString(const bool b) {
+  return b ? "true" : "false";
+}
+
+std::string ToString(const char* const s) {
+  return std::string(s);
+}
+std::string ToString(const std::string s) {
+  return s;
+}
+
+std::string ToString(const short s) {
+  char buf[32];
+  const int len = std::snprintf(&buf[0], arraysize(buf), "%hd", s);
+  RTC_DCHECK_LE(len, arraysize(buf));
+  return std::string(&buf[0], len);
+}
+std::string ToString(const unsigned short s) {
+  char buf[32];
+  const int len = std::snprintf(&buf[0], arraysize(buf), "%hu", s);
+  RTC_DCHECK_LE(len, arraysize(buf));
+  return std::string(&buf[0], len);
+}
+std::string ToString(const int s) {
+  char buf[32];
+  const int len = std::snprintf(&buf[0], arraysize(buf), "%d", s);
+  RTC_DCHECK_LE(len, arraysize(buf));
+  return std::string(&buf[0], len);
+}
+std::string ToString(const unsigned int s) {
+  char buf[32];
+  const int len = std::snprintf(&buf[0], arraysize(buf), "%u", s);
+  RTC_DCHECK_LE(len, arraysize(buf));
+  return std::string(&buf[0], len);
+}
+std::string ToString(const long int s) {
+  char buf[32];
+  const int len = std::snprintf(&buf[0], arraysize(buf), "%ld", s);
+  RTC_DCHECK_LE(len, arraysize(buf));
+  return std::string(&buf[0], len);
+}
+std::string ToString(const unsigned long int s) {
+  char buf[32];
+  const int len = std::snprintf(&buf[0], arraysize(buf), "%lu", s);
+  RTC_DCHECK_LE(len, arraysize(buf));
+  return std::string(&buf[0], len);
+}
+std::string ToString(const long long int s) {
+  char buf[32];
+  const int len = std::snprintf(&buf[0], arraysize(buf), "%lld", s);
+  RTC_DCHECK_LE(len, arraysize(buf));
+  return std::string(&buf[0], len);
+}
+std::string ToString(const unsigned long long int s) {
+  char buf[32];
+  const int len = std::snprintf(&buf[0], arraysize(buf), "%llu", s);
+  RTC_DCHECK_LE(len, arraysize(buf));
+  return std::string(&buf[0], len);
+}
+
+std::string ToString(const double d) {
+  char buf[32];
+  const int len = std::snprintf(&buf[0], arraysize(buf), "%g", d);
+  RTC_DCHECK_LE(len, arraysize(buf));
+  return std::string(&buf[0], len);
+}
+
+std::string ToString(const long double d) {
+  char buf[32];
+  const int len = std::snprintf(&buf[0], arraysize(buf), "%Lg", d);
+  RTC_DCHECK_LE(len, arraysize(buf));
+  return std::string(&buf[0], len);
+}
+
+std::string ToString(const void* const p) {
+  char buf[32];
+  const int len = std::snprintf(&buf[0], arraysize(buf), "%p", p);
+  RTC_DCHECK_LE(len, arraysize(buf));
+  return std::string(&buf[0], len);
+}
+
+bool FromString(const std::string& s, bool* b) {
+  if (s == "false") {
+    *b = false;
+    return true;
+  }
+  if (s == "true") {
+    *b = true;
+    return true;
+  }
+  return false;
+}
+
+}  // namespace rtc
diff --git a/third_party/webrtc_aec3/src/rtc_base/string_encode.h b/third_party/webrtc_aec3/src/rtc_base/string_encode.h
new file mode 100644
index 0000000..c1401b9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/string_encode.h
@@ -0,0 +1,154 @@
+/*
+ *  Copyright 2004 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_STRING_ENCODE_H_
+#define RTC_BASE_STRING_ENCODE_H_
+
+#include <stddef.h>
+
+#include <string>
+#include <type_traits>
+#include <vector>
+
+#include "absl/types/optional.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/string_to_number.h"
+
+namespace rtc {
+
+//////////////////////////////////////////////////////////////////////
+// String Encoding Utilities
+//////////////////////////////////////////////////////////////////////
+
+std::string hex_encode(const std::string& str);
+std::string hex_encode(const char* source, size_t srclen);
+std::string hex_encode_with_delimiter(const char* source,
+                                      size_t srclen,
+                                      char delimiter);
+
+// hex_decode converts ascii hex to binary.
+size_t hex_decode(char* buffer,
+                  size_t buflen,
+                  const char* source,
+                  size_t srclen);
+
+// hex_decode, assuming that there is a delimiter between every byte
+// pair.
+// |delimiter| == 0 means no delimiter
+// If the buffer is too short or the data is invalid, we return 0.
+size_t hex_decode_with_delimiter(char* buffer,
+                                 size_t buflen,
+                                 const char* source,
+                                 size_t srclen,
+                                 char delimiter);
+
+// Helper functions for hex_decode.
+size_t hex_decode(char* buffer, size_t buflen, const std::string& source);
+size_t hex_decode_with_delimiter(char* buffer,
+                                 size_t buflen,
+                                 const std::string& source,
+                                 char delimiter);
+
+// Joins the source vector of strings into a single string, with each
+// field in source being separated by delimiter. No trailing delimiter is added.
+std::string join(const std::vector<std::string>& source, char delimiter);
+
+// Splits the source string into multiple fields separated by delimiter,
+// with duplicates of delimiter creating empty fields.
+size_t split(const std::string& source,
+             char delimiter,
+             std::vector<std::string>* fields);
+
+// Splits the source string into multiple fields separated by delimiter,
+// with duplicates of delimiter ignored.  Trailing delimiter ignored.
+size_t tokenize(const std::string& source,
+                char delimiter,
+                std::vector<std::string>* fields);
+
+// Tokenize, including the empty tokens.
+size_t tokenize_with_empty_tokens(const std::string& source,
+                                  char delimiter,
+                                  std::vector<std::string>* fields);
+
+// Tokenize and append the tokens to fields. Return the new size of fields.
+size_t tokenize_append(const std::string& source,
+                       char delimiter,
+                       std::vector<std::string>* fields);
+
+// Splits the source string into multiple fields separated by delimiter, with
+// duplicates of delimiter ignored. Trailing delimiter ignored. A substring in
+// between the start_mark and the end_mark is treated as a single field. Return
+// the size of fields. For example, if source is "filename
+// \"/Library/Application Support/media content.txt\"", delimiter is ' ', and
+// the start_mark and end_mark are '"', this method returns two fields:
+// "filename" and "/Library/Application Support/media content.txt".
+size_t tokenize(const std::string& source,
+                char delimiter,
+                char start_mark,
+                char end_mark,
+                std::vector<std::string>* fields);
+
+// Extract the first token from source as separated by delimiter, with
+// duplicates of delimiter ignored. Return false if the delimiter could not be
+// found, otherwise return true.
+bool tokenize_first(const std::string& source,
+                    const char delimiter,
+                    std::string* token,
+                    std::string* rest);
+
+// Convert arbitrary values to/from a string.
+// TODO(jonasolsson): Remove these when absl::StrCat becomes available.
+std::string ToString(bool b);
+
+std::string ToString(const char* s);
+std::string ToString(std::string t);
+
+std::string ToString(short s);
+std::string ToString(unsigned short s);
+std::string ToString(int s);
+std::string ToString(unsigned int s);
+std::string ToString(long int s);
+std::string ToString(unsigned long int s);
+std::string ToString(long long int s);
+std::string ToString(unsigned long long int s);
+
+std::string ToString(double t);
+std::string ToString(long double t);
+
+std::string ToString(const void* p);
+
+template <typename T,
+          typename std::enable_if<std::is_arithmetic<T>::value &&
+                                      !std::is_same<T, bool>::value,
+                                  int>::type = 0>
+static bool FromString(const std::string& s, T* t) {
+  RTC_DCHECK(t);
+  absl::optional<T> result = StringToNumber<T>(s);
+
+  if (result)
+    *t = *result;
+
+  return result.has_value();
+}
+
+bool FromString(const std::string& s, bool* b);
+
+template <typename T>
+static inline T FromString(const std::string& str) {
+  T val;
+  FromString(str, &val);
+  return val;
+}
+
+//////////////////////////////////////////////////////////////////////
+
+}  // namespace rtc
+
+#endif  // RTC_BASE_STRING_ENCODE_H__
diff --git a/third_party/webrtc_aec3/src/rtc_base/string_to_number.cc b/third_party/webrtc_aec3/src/rtc_base/string_to_number.cc
new file mode 100644
index 0000000..351610f
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/string_to_number.cc
@@ -0,0 +1,90 @@
+/*
+ *  Copyright 2017 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "rtc_base/string_to_number.h"
+
+#include <ctype.h>
+
+#include <cerrno>
+#include <cstdlib>
+
+#include "rtc_base/checks.h"
+
+namespace rtc {
+namespace string_to_number_internal {
+
+absl::optional<signed_type> ParseSigned(const char* str, int base) {
+  RTC_DCHECK(str);
+  if (isdigit(str[0]) || str[0] == '-') {
+    char* end = nullptr;
+    errno = 0;
+    const signed_type value = std::strtoll(str, &end, base);
+    if (end && *end == '\0' && errno == 0) {
+      return value;
+    }
+  }
+  return absl::nullopt;
+}
+
+absl::optional<unsigned_type> ParseUnsigned(const char* str, int base) {
+  RTC_DCHECK(str);
+  if (isdigit(str[0]) || str[0] == '-') {
+    // Explicitly discard negative values. std::strtoull parsing causes unsigned
+    // wraparound. We cannot just reject values that start with -, though, since
+    // -0 is perfectly fine, as is -0000000000000000000000000000000.
+    const bool is_negative = str[0] == '-';
+    char* end = nullptr;
+    errno = 0;
+    const unsigned_type value = std::strtoull(str, &end, base);
+    if (end && *end == '\0' && errno == 0 && (value == 0 || !is_negative)) {
+      return value;
+    }
+  }
+  return absl::nullopt;
+}
+
+template <typename T>
+T StrToT(const char* str, char** str_end);
+
+template <>
+inline float StrToT(const char* str, char** str_end) {
+  return std::strtof(str, str_end);
+}
+
+template <>
+inline double StrToT(const char* str, char** str_end) {
+  return std::strtod(str, str_end);
+}
+
+template <>
+inline long double StrToT(const char* str, char** str_end) {
+  return std::strtold(str, str_end);
+}
+
+template <typename T>
+absl::optional<T> ParseFloatingPoint(const char* str) {
+  RTC_DCHECK(str);
+  if (*str == '\0')
+    return absl::nullopt;
+  char* end = nullptr;
+  errno = 0;
+  const T value = StrToT<T>(str, &end);
+  if (end && *end == '\0' && errno == 0) {
+    return value;
+  }
+  return absl::nullopt;
+}
+
+template absl::optional<float> ParseFloatingPoint(const char* str);
+template absl::optional<double> ParseFloatingPoint(const char* str);
+template absl::optional<long double> ParseFloatingPoint(const char* str);
+
+}  // namespace string_to_number_internal
+}  // namespace rtc
diff --git a/third_party/webrtc_aec3/src/rtc_base/string_to_number.h b/third_party/webrtc_aec3/src/rtc_base/string_to_number.h
new file mode 100644
index 0000000..4cb5215
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/string_to_number.h
@@ -0,0 +1,116 @@
+/*
+ *  Copyright 2017 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_STRING_TO_NUMBER_H_
+#define RTC_BASE_STRING_TO_NUMBER_H_
+
+#include <limits>
+#include <string>
+#include <type_traits>
+
+#include "absl/types/optional.h"
+
+namespace rtc {
+
+// This file declares a family of functions to parse integers from strings.
+// The standard C library functions either fail to indicate errors (atoi, etc.)
+// or are a hassle to work with (strtol, sscanf, etc.). The standard C++ library
+// functions (std::stoi, etc.) indicate errors by throwing exceptions, which
+// are disabled in WebRTC.
+//
+// Integers are parsed using one of the following functions:
+//   absl::optional<int-type> StringToNumber(const char* str, int base = 10);
+//   absl::optional<int-type> StringToNumber(const std::string& str,
+//                                          int base = 10);
+//
+// These functions parse a value from the beginning of a string into one of the
+// fundamental integer types, or returns an empty Optional if parsing
+// failed. Values outside of the range supported by the type will be
+// rejected. The strings must begin with a digit or a minus sign. No leading
+// space nor trailing contents are allowed.
+// By setting base to 0, one of octal, decimal or hexadecimal will be
+// detected from the string's prefix (0, nothing or 0x, respectively).
+// If non-zero, base can be set to a value between 2 and 36 inclusively.
+//
+// If desired, this interface could be extended with support for floating-point
+// types.
+
+namespace string_to_number_internal {
+// These must be (unsigned) long long, to match the signature of strto(u)ll.
+using unsigned_type = unsigned long long;  // NOLINT(runtime/int)
+using signed_type = long long;             // NOLINT(runtime/int)
+
+absl::optional<signed_type> ParseSigned(const char* str, int base);
+absl::optional<unsigned_type> ParseUnsigned(const char* str, int base);
+
+template <typename T>
+absl::optional<T> ParseFloatingPoint(const char* str);
+}  // namespace string_to_number_internal
+
+template <typename T>
+typename std::enable_if<std::is_integral<T>::value && std::is_signed<T>::value,
+                        absl::optional<T>>::type
+StringToNumber(const char* str, int base = 10) {
+  using string_to_number_internal::signed_type;
+  static_assert(
+      std::numeric_limits<T>::max() <=
+              std::numeric_limits<signed_type>::max() &&
+          std::numeric_limits<T>::lowest() >=
+              std::numeric_limits<signed_type>::lowest(),
+      "StringToNumber only supports signed integers as large as long long int");
+  absl::optional<signed_type> value =
+      string_to_number_internal::ParseSigned(str, base);
+  if (value && *value >= std::numeric_limits<T>::lowest() &&
+      *value <= std::numeric_limits<T>::max()) {
+    return static_cast<T>(*value);
+  }
+  return absl::nullopt;
+}
+
+template <typename T>
+typename std::enable_if<std::is_integral<T>::value &&
+                            std::is_unsigned<T>::value,
+                        absl::optional<T>>::type
+StringToNumber(const char* str, int base = 10) {
+  using string_to_number_internal::unsigned_type;
+  static_assert(std::numeric_limits<T>::max() <=
+                    std::numeric_limits<unsigned_type>::max(),
+                "StringToNumber only supports unsigned integers as large as "
+                "unsigned long long int");
+  absl::optional<unsigned_type> value =
+      string_to_number_internal::ParseUnsigned(str, base);
+  if (value && *value <= std::numeric_limits<T>::max()) {
+    return static_cast<T>(*value);
+  }
+  return absl::nullopt;
+}
+
+template <typename T>
+typename std::enable_if<std::is_floating_point<T>::value,
+                        absl::optional<T>>::type
+StringToNumber(const char* str, int base = 10) {
+  static_assert(
+      std::numeric_limits<T>::max() <= std::numeric_limits<long double>::max(),
+      "StringToNumber only supports floating-point numbers as large "
+      "as long double");
+  return string_to_number_internal::ParseFloatingPoint<T>(str);
+}
+
+// The std::string overloads only exists if there is a matching const char*
+// version.
+template <typename T>
+auto StringToNumber(const std::string& str, int base = 10)
+    -> decltype(StringToNumber<T>(str.c_str(), base)) {
+  return StringToNumber<T>(str.c_str(), base);
+}
+
+}  // namespace rtc
+
+#endif  // RTC_BASE_STRING_TO_NUMBER_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/string_utils.cc b/third_party/webrtc_aec3/src/rtc_base/string_utils.cc
new file mode 100644
index 0000000..1720c62
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/string_utils.cc
@@ -0,0 +1,53 @@
+/*
+ *  Copyright 2004 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "rtc_base/string_utils.h"
+
+namespace rtc {
+
+size_t strcpyn(char* buffer,
+               size_t buflen,
+               const char* source,
+               size_t srclen /* = SIZE_UNKNOWN */) {
+  if (buflen <= 0)
+    return 0;
+
+  if (srclen == SIZE_UNKNOWN) {
+    srclen = strlen(source);
+  }
+  if (srclen >= buflen) {
+    srclen = buflen - 1;
+  }
+  memcpy(buffer, source, srclen);
+  buffer[srclen] = 0;
+  return srclen;
+}
+
+static const char kWhitespace[] = " \n\r\t";
+
+std::string string_trim(const std::string& s) {
+  std::string::size_type first = s.find_first_not_of(kWhitespace);
+  std::string::size_type last = s.find_last_not_of(kWhitespace);
+
+  if (first == std::string::npos || last == std::string::npos) {
+    return std::string("");
+  }
+
+  return s.substr(first, last - first + 1);
+}
+
+std::string ToHex(const int i) {
+  char buffer[50];
+  snprintf(buffer, sizeof(buffer), "%x", i);
+
+  return std::string(buffer);
+}
+
+}  // namespace rtc
diff --git a/third_party/webrtc_aec3/src/rtc_base/string_utils.h b/third_party/webrtc_aec3/src/rtc_base/string_utils.h
new file mode 100644
index 0000000..23c55cb
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/string_utils.h
@@ -0,0 +1,93 @@
+/*
+ *  Copyright 2004 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_STRING_UTILS_H_
+#define RTC_BASE_STRING_UTILS_H_
+
+#include <ctype.h>
+#include <stdarg.h>
+#include <stdio.h>
+#include <string.h>
+
+#if defined(WEBRTC_WIN)
+#include <malloc.h>
+#include <wchar.h>
+#include <windows.h>
+
+#endif  // WEBRTC_WIN
+
+#if defined(WEBRTC_POSIX)
+#include <stdlib.h>
+#include <strings.h>
+#endif  // WEBRTC_POSIX
+
+#include <string>
+
+namespace rtc {
+
+const size_t SIZE_UNKNOWN = static_cast<size_t>(-1);
+
+// Safe version of strncpy that always nul-terminate.
+size_t strcpyn(char* buffer,
+               size_t buflen,
+               const char* source,
+               size_t srclen = SIZE_UNKNOWN);
+
+///////////////////////////////////////////////////////////////////////////////
+// UTF helpers (Windows only)
+///////////////////////////////////////////////////////////////////////////////
+
+#if defined(WEBRTC_WIN)
+
+inline std::wstring ToUtf16(const char* utf8, size_t len) {
+  if (len == 0)
+    return std::wstring();
+  int len16 = ::MultiByteToWideChar(CP_UTF8, 0, utf8, static_cast<int>(len),
+                                    nullptr, 0);
+  std::wstring ws(len16, 0);
+  ::MultiByteToWideChar(CP_UTF8, 0, utf8, static_cast<int>(len), &*ws.begin(),
+                        len16);
+  return ws;
+}
+
+inline std::wstring ToUtf16(const std::string& str) {
+  return ToUtf16(str.data(), str.length());
+}
+
+inline std::string ToUtf8(const wchar_t* wide, size_t len) {
+  if (len == 0)
+    return std::string();
+  int len8 = ::WideCharToMultiByte(CP_UTF8, 0, wide, static_cast<int>(len),
+                                   nullptr, 0, nullptr, nullptr);
+  std::string ns(len8, 0);
+  ::WideCharToMultiByte(CP_UTF8, 0, wide, static_cast<int>(len), &*ns.begin(),
+                        len8, nullptr, nullptr);
+  return ns;
+}
+
+inline std::string ToUtf8(const wchar_t* wide) {
+  return ToUtf8(wide, wcslen(wide));
+}
+
+inline std::string ToUtf8(const std::wstring& wstr) {
+  return ToUtf8(wstr.data(), wstr.length());
+}
+
+#endif  // WEBRTC_WIN
+
+// Remove leading and trailing whitespaces.
+std::string string_trim(const std::string& s);
+
+// TODO(jonasolsson): replace with absl::Hex when that becomes available.
+std::string ToHex(const int i);
+
+}  // namespace rtc
+
+#endif  // RTC_BASE_STRING_UTILS_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/strings/string_builder.cc b/third_party/webrtc_aec3/src/rtc_base/strings/string_builder.cc
new file mode 100644
index 0000000..caa931b
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/strings/string_builder.cc
@@ -0,0 +1,141 @@
+/*
+ *  Copyright 2018 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "rtc_base/strings/string_builder.h"
+
+#include <stdarg.h>
+
+#include <cstdio>
+#include <cstring>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_minmax.h"
+
+namespace rtc {
+
+SimpleStringBuilder::SimpleStringBuilder(rtc::ArrayView<char> buffer)
+    : buffer_(buffer) {
+  buffer_[0] = '\0';
+  RTC_DCHECK(IsConsistent());
+}
+
+SimpleStringBuilder& SimpleStringBuilder::operator<<(const char* str) {
+  return Append(str, strlen(str));
+}
+
+SimpleStringBuilder& SimpleStringBuilder::operator<<(char ch) {
+  return Append(&ch, 1);
+}
+
+SimpleStringBuilder& SimpleStringBuilder::operator<<(const std::string& str) {
+  return Append(str.c_str(), str.length());
+}
+
+// Numeric conversion routines.
+//
+// We use std::[v]snprintf instead of std::to_string because:
+// * std::to_string relies on the current locale for formatting purposes,
+//   and therefore concurrent calls to std::to_string from multiple threads
+//   may result in partial serialization of calls
+// * snprintf allows us to print the number directly into our buffer.
+// * avoid allocating a std::string (potential heap alloc).
+// TODO(tommi): Switch to std::to_chars in C++17.
+
+SimpleStringBuilder& SimpleStringBuilder::operator<<(int i) {
+  return AppendFormat("%d", i);
+}
+
+SimpleStringBuilder& SimpleStringBuilder::operator<<(unsigned i) {
+  return AppendFormat("%u", i);
+}
+
+SimpleStringBuilder& SimpleStringBuilder::operator<<(long i) {  // NOLINT
+  return AppendFormat("%ld", i);
+}
+
+SimpleStringBuilder& SimpleStringBuilder::operator<<(long long i) {  // NOLINT
+  return AppendFormat("%lld", i);
+}
+
+SimpleStringBuilder& SimpleStringBuilder::operator<<(
+    unsigned long i) {  // NOLINT
+  return AppendFormat("%lu", i);
+}
+
+SimpleStringBuilder& SimpleStringBuilder::operator<<(
+    unsigned long long i) {  // NOLINT
+  return AppendFormat("%llu", i);
+}
+
+SimpleStringBuilder& SimpleStringBuilder::operator<<(float f) {
+  return AppendFormat("%g", f);
+}
+
+SimpleStringBuilder& SimpleStringBuilder::operator<<(double f) {
+  return AppendFormat("%g", f);
+}
+
+SimpleStringBuilder& SimpleStringBuilder::operator<<(long double f) {
+  return AppendFormat("%Lg", f);
+}
+
+SimpleStringBuilder& SimpleStringBuilder::AppendFormat(const char* fmt, ...) {
+  va_list args;
+  va_start(args, fmt);
+  const int len =
+      std::vsnprintf(&buffer_[size_], buffer_.size() - size_, fmt, args);
+  if (len >= 0) {
+    const size_t chars_added = rtc::SafeMin(len, buffer_.size() - 1 - size_);
+    size_ += chars_added;
+    RTC_DCHECK_EQ(len, chars_added) << "Buffer size was insufficient";
+  } else {
+    // This should never happen, but we're paranoid, so re-write the
+    // terminator in case vsnprintf() overwrote it.
+    RTC_NOTREACHED();
+    buffer_[size_] = '\0';
+  }
+  va_end(args);
+  RTC_DCHECK(IsConsistent());
+  return *this;
+}
+
+SimpleStringBuilder& SimpleStringBuilder::Append(const char* str,
+                                                 size_t length) {
+  RTC_DCHECK_LT(size_ + length, buffer_.size())
+      << "Buffer size was insufficient";
+  const size_t chars_added = rtc::SafeMin(length, buffer_.size() - size_ - 1);
+  memcpy(&buffer_[size_], str, chars_added);
+  size_ += chars_added;
+  buffer_[size_] = '\0';
+  RTC_DCHECK(IsConsistent());
+  return *this;
+}
+
+StringBuilder& StringBuilder::AppendFormat(const char* fmt, ...) {
+  va_list args, copy;
+  va_start(args, fmt);
+  va_copy(copy, args);
+  const int predicted_length = std::vsnprintf(nullptr, 0, fmt, copy);
+  va_end(copy);
+
+  RTC_DCHECK_GE(predicted_length, 0);
+  if (predicted_length > 0) {
+    const size_t size = str_.size();
+    str_.resize(size + predicted_length);
+    // Pass "+ 1" to vsnprintf to include space for the '\0'.
+    const int actual_length =
+        std::vsnprintf(&str_[size], predicted_length + 1, fmt, args);
+    RTC_DCHECK_GE(actual_length, 0);
+  }
+  va_end(args);
+  return *this;
+}
+
+}  // namespace rtc
diff --git a/third_party/webrtc_aec3/src/rtc_base/strings/string_builder.h b/third_party/webrtc_aec3/src/rtc_base/strings/string_builder.h
new file mode 100644
index 0000000..e528cf2
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/strings/string_builder.h
@@ -0,0 +1,175 @@
+/*
+ *  Copyright 2018 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_STRINGS_STRING_BUILDER_H_
+#define RTC_BASE_STRINGS_STRING_BUILDER_H_
+
+#include <cstdio>
+#include <string>
+#include <utility>
+
+#include "absl/strings/string_view.h"
+#include "api/array_view.h"
+#include "rtc_base/string_encode.h"
+
+namespace rtc {
+
+// This is a minimalistic string builder class meant to cover the most cases of
+// when you might otherwise be tempted to use a stringstream (discouraged for
+// anything except logging). It uses a fixed-size buffer provided by the caller
+// and concatenates strings and numbers into it, allowing the results to be
+// read via |str()|.
+class SimpleStringBuilder {
+ public:
+  explicit SimpleStringBuilder(rtc::ArrayView<char> buffer);
+  SimpleStringBuilder(const SimpleStringBuilder&) = delete;
+  SimpleStringBuilder& operator=(const SimpleStringBuilder&) = delete;
+
+  SimpleStringBuilder& operator<<(const char* str);
+  SimpleStringBuilder& operator<<(char ch);
+  SimpleStringBuilder& operator<<(const std::string& str);
+  SimpleStringBuilder& operator<<(int i);
+  SimpleStringBuilder& operator<<(unsigned i);
+  SimpleStringBuilder& operator<<(long i);                // NOLINT
+  SimpleStringBuilder& operator<<(long long i);           // NOLINT
+  SimpleStringBuilder& operator<<(unsigned long i);       // NOLINT
+  SimpleStringBuilder& operator<<(unsigned long long i);  // NOLINT
+  SimpleStringBuilder& operator<<(float f);
+  SimpleStringBuilder& operator<<(double f);
+  SimpleStringBuilder& operator<<(long double f);
+
+  // Returns a pointer to the built string. The name |str()| is borrowed for
+  // compatibility reasons as we replace usage of stringstream throughout the
+  // code base.
+  const char* str() const { return buffer_.data(); }
+
+  // Returns the length of the string. The name |size()| is picked for STL
+  // compatibility reasons.
+  size_t size() const { return size_; }
+
+// Allows appending a printf style formatted string.
+#if defined(__GNUC__)
+  __attribute__((__format__(__printf__, 2, 3)))
+#endif
+  SimpleStringBuilder&
+  AppendFormat(const char* fmt, ...);
+
+  // An alternate way from operator<<() to append a string. This variant is
+  // slightly more efficient when the length of the string to append, is known.
+  SimpleStringBuilder& Append(const char* str, size_t length);
+
+ private:
+  bool IsConsistent() const {
+    return size_ <= buffer_.size() - 1 && buffer_[size_] == '\0';
+  }
+
+  // An always-zero-terminated fixed-size buffer that we write to. The fixed
+  // size allows the buffer to be stack allocated, which helps performance.
+  // Having a fixed size is furthermore useful to avoid unnecessary resizing
+  // while building it.
+  const rtc::ArrayView<char> buffer_;
+
+  // Represents the number of characters written to the buffer.
+  // This does not include the terminating '\0'.
+  size_t size_ = 0;
+};
+
+// A string builder that supports dynamic resizing while building a string.
+// The class is based around an instance of std::string and allows moving
+// ownership out of the class once the string has been built.
+// Note that this class uses the heap for allocations, so SimpleStringBuilder
+// might be more efficient for some use cases.
+class StringBuilder {
+ public:
+  StringBuilder() {}
+  explicit StringBuilder(absl::string_view s) : str_(s) {}
+
+  // TODO(tommi): Support construction from StringBuilder?
+  StringBuilder(const StringBuilder&) = delete;
+  StringBuilder& operator=(const StringBuilder&) = delete;
+
+  StringBuilder& operator<<(const absl::string_view str) {
+    str_.append(str.data(), str.length());
+    return *this;
+  }
+
+  StringBuilder& operator<<(char c) = delete;
+
+  StringBuilder& operator<<(int i) {
+    str_ += rtc::ToString(i);
+    return *this;
+  }
+
+  StringBuilder& operator<<(unsigned i) {
+    str_ += rtc::ToString(i);
+    return *this;
+  }
+
+  StringBuilder& operator<<(long i) {  // NOLINT
+    str_ += rtc::ToString(i);
+    return *this;
+  }
+
+  StringBuilder& operator<<(long long i) {  // NOLINT
+    str_ += rtc::ToString(i);
+    return *this;
+  }
+
+  StringBuilder& operator<<(unsigned long i) {  // NOLINT
+    str_ += rtc::ToString(i);
+    return *this;
+  }
+
+  StringBuilder& operator<<(unsigned long long i) {  // NOLINT
+    str_ += rtc::ToString(i);
+    return *this;
+  }
+
+  StringBuilder& operator<<(float f) {
+    str_ += rtc::ToString(f);
+    return *this;
+  }
+
+  StringBuilder& operator<<(double f) {
+    str_ += rtc::ToString(f);
+    return *this;
+  }
+
+  StringBuilder& operator<<(long double f) {
+    str_ += rtc::ToString(f);
+    return *this;
+  }
+
+  const std::string& str() const { return str_; }
+
+  void Clear() { str_.clear(); }
+
+  size_t size() const { return str_.size(); }
+
+  std::string Release() {
+    std::string ret = std::move(str_);
+    str_.clear();
+    return ret;
+  }
+
+  // Allows appending a printf style formatted string.
+  StringBuilder& AppendFormat(const char* fmt, ...)
+#if defined(__GNUC__)
+      __attribute__((__format__(__printf__, 2, 3)))
+#endif
+      ;
+
+ private:
+  std::string str_;
+};
+
+}  // namespace rtc
+
+#endif  // RTC_BASE_STRINGS_STRING_BUILDER_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/swap_queue.h b/third_party/webrtc_aec3/src/rtc_base/swap_queue.h
new file mode 100644
index 0000000..3c8149c
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/swap_queue.h
@@ -0,0 +1,249 @@
+/*
+ *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_SWAP_QUEUE_H_
+#define RTC_BASE_SWAP_QUEUE_H_
+
+#include <stddef.h>
+
+#include <atomic>
+#include <utility>
+#include <vector>
+
+#include "absl/base/attributes.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+
+namespace internal {
+
+// (Internal; please don't use outside this file.)
+template <typename T>
+bool NoopSwapQueueItemVerifierFunction(const T&) {
+  return true;
+}
+
+}  // namespace internal
+
+// Functor to use when supplying a verifier function for the queue.
+template <typename T,
+          bool (*QueueItemVerifierFunction)(const T&) =
+              internal::NoopSwapQueueItemVerifierFunction>
+class SwapQueueItemVerifier {
+ public:
+  bool operator()(const T& t) const { return QueueItemVerifierFunction(t); }
+};
+
+// This class is a fixed-size queue. A single producer calls Insert() to insert
+// an element of type T at the back of the queue, and a single consumer calls
+// Remove() to remove an element from the front of the queue. It's safe for the
+// producer and the consumer to access the queue concurrently, from different
+// threads.
+//
+// To avoid the construction, copying, and destruction of Ts that a naive
+// queue implementation would require, for each "full" T passed from
+// producer to consumer, SwapQueue<T> passes an "empty" T in the other
+// direction (an "empty" T is one that contains nothing of value for the
+// consumer). This bidirectional movement is implemented with swap().
+//
+// // Create queue:
+// Bottle proto(568);  // Prepare an empty Bottle. Heap allocates space for
+//                     // 568 ml.
+// SwapQueue<Bottle> q(N, proto);  // Init queue with N copies of proto.
+//                                 // Each copy allocates on the heap.
+// // Producer pseudo-code:
+// Bottle b(568); // Prepare an empty Bottle. Heap allocates space for 568 ml.
+// loop {
+//   b.Fill(amount);  // Where amount <= 568 ml.
+//   q.Insert(&b);    // Swap our full Bottle for an empty one from q.
+// }
+//
+// // Consumer pseudo-code:
+// Bottle b(568);  // Prepare an empty Bottle. Heap allocates space for 568 ml.
+// loop {
+//   q.Remove(&b); // Swap our empty Bottle for the next-in-line full Bottle.
+//   Drink(&b);
+// }
+//
+// For a well-behaved Bottle class, there are no allocations in the
+// producer, since it just fills an empty Bottle that's already large
+// enough; no deallocations in the consumer, since it returns each empty
+// Bottle to the queue after having drunk it; and no copies along the
+// way, since the queue uses swap() everywhere to move full Bottles in
+// one direction and empty ones in the other.
+template <typename T, typename QueueItemVerifier = SwapQueueItemVerifier<T>>
+class SwapQueue {
+ public:
+  // Creates a queue of size size and fills it with default constructed Ts.
+  explicit SwapQueue(size_t size) : queue_(size) {
+    RTC_DCHECK(VerifyQueueSlots());
+  }
+
+  // Same as above and accepts an item verification functor.
+  SwapQueue(size_t size, const QueueItemVerifier& queue_item_verifier)
+      : queue_item_verifier_(queue_item_verifier), queue_(size) {
+    RTC_DCHECK(VerifyQueueSlots());
+  }
+
+  // Creates a queue of size size and fills it with copies of prototype.
+  SwapQueue(size_t size, const T& prototype) : queue_(size, prototype) {
+    RTC_DCHECK(VerifyQueueSlots());
+  }
+
+  // Same as above and accepts an item verification functor.
+  SwapQueue(size_t size,
+            const T& prototype,
+            const QueueItemVerifier& queue_item_verifier)
+      : queue_item_verifier_(queue_item_verifier), queue_(size, prototype) {
+    RTC_DCHECK(VerifyQueueSlots());
+  }
+
+  // Resets the queue to have zero content while maintaining the queue size.
+  // Just like Remove(), this can only be called (safely) from the
+  // consumer.
+  void Clear() {
+    // Drop all non-empty elements by resetting num_elements_ and incrementing
+    // next_read_index_ by the previous value of num_elements_. Relaxed memory
+    // ordering is sufficient since the dropped elements are not accessed.
+    next_read_index_ += std::atomic_exchange_explicit(
+        &num_elements_, size_t{0}, std::memory_order_relaxed);
+    if (next_read_index_ >= queue_.size()) {
+      next_read_index_ -= queue_.size();
+    }
+
+    RTC_DCHECK_LT(next_read_index_, queue_.size());
+  }
+
+  // Inserts a "full" T at the back of the queue by swapping *input with an
+  // "empty" T from the queue.
+  // Returns true if the item was inserted or false if not (the queue was full).
+  // When specified, the T given in *input must pass the ItemVerifier() test.
+  // The contents of *input after the call are then also guaranteed to pass the
+  // ItemVerifier() test.
+  ABSL_MUST_USE_RESULT bool Insert(T* input) {
+    RTC_DCHECK(input);
+
+    RTC_DCHECK(queue_item_verifier_(*input));
+
+    // Load the value of num_elements_. Acquire memory ordering prevents reads
+    // and writes to queue_[next_write_index_] to be reordered to before the
+    // load. (That element might be accessed by a concurrent call to Remove()
+    // until the load finishes.)
+    if (std::atomic_load_explicit(&num_elements_, std::memory_order_acquire) ==
+        queue_.size()) {
+      return false;
+    }
+
+    using std::swap;
+    swap(*input, queue_[next_write_index_]);
+
+    // Increment the value of num_elements_ to account for the inserted element.
+    // Release memory ordering prevents the reads and writes to
+    // queue_[next_write_index_] to be reordered to after the increment. (Once
+    // the increment has finished, Remove() might start accessing that element.)
+    const size_t old_num_elements = std::atomic_fetch_add_explicit(
+        &num_elements_, size_t{1}, std::memory_order_release);
+
+    ++next_write_index_;
+    if (next_write_index_ == queue_.size()) {
+      next_write_index_ = 0;
+    }
+
+    RTC_DCHECK_LT(next_write_index_, queue_.size());
+    RTC_DCHECK_LT(old_num_elements, queue_.size());
+
+    return true;
+  }
+
+  // Removes the frontmost "full" T from the queue by swapping it with
+  // the "empty" T in *output.
+  // Returns true if an item could be removed or false if not (the queue was
+  // empty). When specified, The T given in *output must pass the ItemVerifier()
+  // test and the contents of *output after the call are then also guaranteed to
+  // pass the ItemVerifier() test.
+  ABSL_MUST_USE_RESULT bool Remove(T* output) {
+    RTC_DCHECK(output);
+
+    RTC_DCHECK(queue_item_verifier_(*output));
+
+    // Load the value of num_elements_. Acquire memory ordering prevents reads
+    // and writes to queue_[next_read_index_] to be reordered to before the
+    // load. (That element might be accessed by a concurrent call to Insert()
+    // until the load finishes.)
+    if (std::atomic_load_explicit(&num_elements_, std::memory_order_acquire) ==
+        0) {
+      return false;
+    }
+
+    using std::swap;
+    swap(*output, queue_[next_read_index_]);
+
+    // Decrement the value of num_elements_ to account for the removed element.
+    // Release memory ordering prevents the reads and writes to
+    // queue_[next_write_index_] to be reordered to after the decrement. (Once
+    // the decrement has finished, Insert() might start accessing that element.)
+    std::atomic_fetch_sub_explicit(&num_elements_, size_t{1},
+                                   std::memory_order_release);
+
+    ++next_read_index_;
+    if (next_read_index_ == queue_.size()) {
+      next_read_index_ = 0;
+    }
+
+    RTC_DCHECK_LT(next_read_index_, queue_.size());
+
+    return true;
+  }
+
+  // Returns the current number of elements in the queue. Since elements may be
+  // concurrently added to the queue, the caller must treat this as a lower
+  // bound, not an exact count.
+  // May only be called by the consumer.
+  size_t SizeAtLeast() const {
+    // Acquire memory ordering ensures that we wait for the producer to finish
+    // inserting any element in progress.
+    return std::atomic_load_explicit(&num_elements_, std::memory_order_acquire);
+  }
+
+ private:
+  // Verify that the queue slots complies with the ItemVerifier test. This
+  // function is not thread-safe and can only be used in the constructors.
+  bool VerifyQueueSlots() {
+    for (const auto& v : queue_) {
+      RTC_DCHECK(queue_item_verifier_(v));
+    }
+    return true;
+  }
+
+  // TODO(peah): Change this to use std::function() once we can use C++11 std
+  // lib.
+  QueueItemVerifier queue_item_verifier_;
+
+  // Only accessed by the single producer.
+  size_t next_write_index_ = 0;
+
+  // Only accessed by the single consumer.
+  size_t next_read_index_ = 0;
+
+  // Accessed by both the producer and the consumer and used for synchronization
+  // between them.
+  std::atomic<size_t> num_elements_{0};
+
+  // The elements of the queue are acced by both the producer and the consumer,
+  // mediated by num_elements_. queue_.size() is constant.
+  std::vector<T> queue_;
+
+  SwapQueue(const SwapQueue&) = delete;
+  SwapQueue& operator=(const SwapQueue&) = delete;
+};
+
+}  // namespace webrtc
+
+#endif  // RTC_BASE_SWAP_QUEUE_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex.cc b/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex.cc
new file mode 100644
index 0000000..6c2d6ff
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex.cc
@@ -0,0 +1,39 @@
+/*
+ *  Copyright 2020 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "rtc_base/synchronization/mutex.h"
+
+#include "rtc_base/checks.h"
+#include "rtc_base/synchronization/yield.h"
+
+namespace webrtc {
+
+#if !defined(WEBRTC_ABSL_MUTEX)
+void GlobalMutex::Lock() {
+  while (mutex_locked_.exchange(1)) {
+    YieldCurrentThread();
+  }
+}
+
+void GlobalMutex::Unlock() {
+  int old = mutex_locked_.exchange(0);
+  RTC_DCHECK_EQ(old, 1) << "Unlock called without calling Lock first";
+}
+
+GlobalMutexLock::GlobalMutexLock(GlobalMutex* mutex) : mutex_(mutex) {
+  mutex_->Lock();
+}
+
+GlobalMutexLock::~GlobalMutexLock() {
+  mutex_->Unlock();
+}
+#endif  // #if !defined(WEBRTC_ABSL_MUTEX)
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex.h b/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex.h
new file mode 100644
index 0000000..e1512e9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex.h
@@ -0,0 +1,113 @@
+/*
+ *  Copyright 2020 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_SYNCHRONIZATION_MUTEX_H_
+#define RTC_BASE_SYNCHRONIZATION_MUTEX_H_
+
+#include <atomic>
+
+#include "absl/base/attributes.h"
+#include "absl/base/const_init.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/thread_annotations.h"
+
+#if defined(WEBRTC_RACE_CHECK_MUTEX)
+// To use the race check mutex, define WEBRTC_RACE_CHECK_MUTEX globally. This
+// also adds a dependency to absl::Mutex from logging.cc due to concurrent
+// invocation of the static logging system.
+#include "rtc_base/synchronization/mutex_race_check.h"
+#elif defined(WEBRTC_ABSL_MUTEX)
+#include "rtc_base/synchronization/mutex_abseil.h"  // nogncheck
+#elif defined(WEBRTC_WIN)
+#include "rtc_base/synchronization/mutex_critical_section.h"
+#elif defined(WEBRTC_POSIX)
+#include "rtc_base/synchronization/mutex_pthread.h"
+#else
+#error Unsupported platform.
+#endif
+
+namespace webrtc {
+
+// The Mutex guarantees exclusive access and aims to follow Abseil semantics
+// (i.e. non-reentrant etc).
+class RTC_LOCKABLE Mutex final {
+ public:
+  Mutex() = default;
+  Mutex(const Mutex&) = delete;
+  Mutex& operator=(const Mutex&) = delete;
+
+  void Lock() RTC_EXCLUSIVE_LOCK_FUNCTION() {
+    impl_.Lock();
+  }
+  ABSL_MUST_USE_RESULT bool TryLock() RTC_EXCLUSIVE_TRYLOCK_FUNCTION(true) {
+    return impl_.TryLock();
+  }
+  void Unlock() RTC_UNLOCK_FUNCTION() {
+    impl_.Unlock();
+  }
+
+ private:
+  MutexImpl impl_;
+};
+
+// MutexLock, for serializing execution through a scope.
+class RTC_SCOPED_LOCKABLE MutexLock final {
+ public:
+  MutexLock(const MutexLock&) = delete;
+  MutexLock& operator=(const MutexLock&) = delete;
+
+  explicit MutexLock(Mutex* mutex) RTC_EXCLUSIVE_LOCK_FUNCTION(mutex)
+      : mutex_(mutex) {
+    mutex->Lock();
+  }
+  ~MutexLock() RTC_UNLOCK_FUNCTION() { mutex_->Unlock(); }
+
+ private:
+  Mutex* mutex_;
+};
+
+// A mutex used to protect global variables. Do NOT use for other purposes.
+#if defined(WEBRTC_ABSL_MUTEX)
+using GlobalMutex = absl::Mutex;
+using GlobalMutexLock = absl::MutexLock;
+#else
+class RTC_LOCKABLE GlobalMutex final {
+ public:
+  GlobalMutex(const GlobalMutex&) = delete;
+  GlobalMutex& operator=(const GlobalMutex&) = delete;
+
+  constexpr explicit GlobalMutex(absl::ConstInitType /*unused*/)
+      : mutex_locked_(0) {}
+
+  void Lock() RTC_EXCLUSIVE_LOCK_FUNCTION();
+  void Unlock() RTC_UNLOCK_FUNCTION();
+
+ private:
+  std::atomic<int> mutex_locked_;  // 0 means lock not taken, 1 means taken.
+};
+
+// GlobalMutexLock, for serializing execution through a scope.
+class RTC_SCOPED_LOCKABLE GlobalMutexLock final {
+ public:
+  GlobalMutexLock(const GlobalMutexLock&) = delete;
+  GlobalMutexLock& operator=(const GlobalMutexLock&) = delete;
+
+  explicit GlobalMutexLock(GlobalMutex* mutex)
+      RTC_EXCLUSIVE_LOCK_FUNCTION(mutex_);
+  ~GlobalMutexLock() RTC_UNLOCK_FUNCTION();
+
+ private:
+  GlobalMutex* mutex_;
+};
+#endif  // if defined(WEBRTC_ABSL_MUTEX)
+
+}  // namespace webrtc
+
+#endif  // RTC_BASE_SYNCHRONIZATION_MUTEX_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex_abseil.h b/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex_abseil.h
new file mode 100644
index 0000000..9247065
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex_abseil.h
@@ -0,0 +1,38 @@
+/*
+ *  Copyright 2020 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_SYNCHRONIZATION_MUTEX_ABSEIL_H_
+#define RTC_BASE_SYNCHRONIZATION_MUTEX_ABSEIL_H_
+
+#include "absl/base/attributes.h"
+#include "absl/synchronization/mutex.h"
+#include "rtc_base/thread_annotations.h"
+
+namespace webrtc {
+
+class RTC_LOCKABLE MutexImpl final {
+ public:
+  MutexImpl() = default;
+  MutexImpl(const MutexImpl&) = delete;
+  MutexImpl& operator=(const MutexImpl&) = delete;
+
+  void Lock() RTC_EXCLUSIVE_LOCK_FUNCTION() { mutex_.Lock(); }
+  ABSL_MUST_USE_RESULT bool TryLock() RTC_EXCLUSIVE_TRYLOCK_FUNCTION(true) {
+    return mutex_.TryLock();
+  }
+  void Unlock() RTC_UNLOCK_FUNCTION() { mutex_.Unlock(); }
+
+ private:
+  absl::Mutex mutex_;
+};
+
+}  // namespace webrtc
+
+#endif  // RTC_BASE_SYNCHRONIZATION_MUTEX_ABSEIL_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex_benchmark.cc b/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex_benchmark.cc
new file mode 100644
index 0000000..40adca6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex_benchmark.cc
@@ -0,0 +1,95 @@
+/*
+ *  Copyright 2020 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "benchmark/benchmark.h"
+#include "rtc_base/synchronization/mutex.h"
+#include "rtc_base/system/unused.h"
+
+namespace webrtc {
+
+class PerfTestData {
+ public:
+  PerfTestData() : cache_line_barrier_1_(), cache_line_barrier_2_() {
+    cache_line_barrier_1_[0]++;  // Avoid 'is not used'.
+    cache_line_barrier_2_[0]++;  // Avoid 'is not used'.
+  }
+
+  int AddToCounter(int add) {
+    MutexLock mu(&mu_);
+    my_counter_ += add;
+    return 0;
+  }
+
+ private:
+  uint8_t cache_line_barrier_1_[64];
+  Mutex mu_;
+  uint8_t cache_line_barrier_2_[64];
+  int64_t my_counter_ = 0;
+};
+
+void BM_LockWithMutex(benchmark::State& state) {
+  static PerfTestData test_data;
+  for (auto s : state) {
+    RTC_UNUSED(s);
+    benchmark::DoNotOptimize(test_data.AddToCounter(2));
+  }
+}
+
+BENCHMARK(BM_LockWithMutex)->Threads(1);
+BENCHMARK(BM_LockWithMutex)->Threads(2);
+BENCHMARK(BM_LockWithMutex)->Threads(4);
+BENCHMARK(BM_LockWithMutex)->ThreadPerCpu();
+
+}  // namespace webrtc
+
+/*
+
+Results:
+
+NB when reproducing: Remember to turn of power management features such as CPU
+scaling before running!
+
+pthreads (Linux):
+----------------------------------------------------------------------
+Run on (12 X 4500 MHz CPU s)
+CPU Caches:
+  L1 Data 32 KiB (x6)
+  L1 Instruction 32 KiB (x6)
+  L2 Unified 1024 KiB (x6)
+  L3 Unified 8448 KiB (x1)
+Load Average: 0.26, 0.28, 0.44
+----------------------------------------------------------------------
+Benchmark                            Time             CPU   Iterations
+----------------------------------------------------------------------
+BM_LockWithMutex/threads:1        13.4 ns         13.4 ns     52192906
+BM_LockWithMutex/threads:2        44.2 ns         88.4 ns      8189944
+BM_LockWithMutex/threads:4        52.0 ns          198 ns      3743244
+BM_LockWithMutex/threads:12       84.9 ns          944 ns       733524
+
+std::mutex performs like the pthread implementation (Linux).
+
+Abseil (Linux):
+----------------------------------------------------------------------
+Run on (12 X 4500 MHz CPU s)
+CPU Caches:
+  L1 Data 32 KiB (x6)
+  L1 Instruction 32 KiB (x6)
+  L2 Unified 1024 KiB (x6)
+  L3 Unified 8448 KiB (x1)
+Load Average: 0.27, 0.24, 0.37
+----------------------------------------------------------------------
+Benchmark                            Time             CPU   Iterations
+----------------------------------------------------------------------
+BM_LockWithMutex/threads:1        15.0 ns         15.0 ns     46550231
+BM_LockWithMutex/threads:2        91.1 ns          182 ns      4059212
+BM_LockWithMutex/threads:4        40.8 ns          131 ns      5496560
+BM_LockWithMutex/threads:12       37.0 ns          130 ns      5377668
+
+*/
diff --git a/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex_critical_section.h b/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex_critical_section.h
new file mode 100644
index 0000000..cb3d6a0
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex_critical_section.h
@@ -0,0 +1,55 @@
+/*
+ *  Copyright 2020 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_SYNCHRONIZATION_MUTEX_CRITICAL_SECTION_H_
+#define RTC_BASE_SYNCHRONIZATION_MUTEX_CRITICAL_SECTION_H_
+
+#if defined(WEBRTC_WIN)
+// clang-format off
+// clang formating would change include order.
+
+// Include winsock2.h before including <windows.h> to maintain consistency with
+// win32.h. To include win32.h directly, it must be broken out into its own
+// build target.
+#include <winsock2.h>
+#include <windows.h>
+#include <sal.h>  // must come after windows headers.
+// clang-format on
+
+#include "absl/base/attributes.h"
+#include "rtc_base/thread_annotations.h"
+
+namespace webrtc {
+
+class RTC_LOCKABLE MutexImpl final {
+ public:
+  MutexImpl() { InitializeCriticalSection(&critical_section_); }
+  MutexImpl(const MutexImpl&) = delete;
+  MutexImpl& operator=(const MutexImpl&) = delete;
+  ~MutexImpl() { DeleteCriticalSection(&critical_section_); }
+
+  void Lock() RTC_EXCLUSIVE_LOCK_FUNCTION() {
+    EnterCriticalSection(&critical_section_);
+  }
+  ABSL_MUST_USE_RESULT bool TryLock() RTC_EXCLUSIVE_TRYLOCK_FUNCTION(true) {
+    return TryEnterCriticalSection(&critical_section_) != FALSE;
+  }
+  void Unlock() RTC_UNLOCK_FUNCTION() {
+    LeaveCriticalSection(&critical_section_);
+  }
+
+ private:
+  CRITICAL_SECTION critical_section_;
+};
+
+}  // namespace webrtc
+
+#endif  // #if defined(WEBRTC_WIN)
+#endif  // RTC_BASE_SYNCHRONIZATION_MUTEX_CRITICAL_SECTION_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex_pthread.h b/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex_pthread.h
new file mode 100644
index 0000000..8898ca5
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex_pthread.h
@@ -0,0 +1,54 @@
+/*
+ *  Copyright 2020 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_SYNCHRONIZATION_MUTEX_PTHREAD_H_
+#define RTC_BASE_SYNCHRONIZATION_MUTEX_PTHREAD_H_
+
+#if defined(WEBRTC_POSIX)
+
+#include <pthread.h>
+#if defined(WEBRTC_MAC)
+#include <pthread_spis.h>
+#endif
+
+#include "absl/base/attributes.h"
+#include "rtc_base/thread_annotations.h"
+
+namespace webrtc {
+
+class RTC_LOCKABLE MutexImpl final {
+ public:
+  MutexImpl() {
+    pthread_mutexattr_t mutex_attribute;
+    pthread_mutexattr_init(&mutex_attribute);
+#if defined(WEBRTC_MAC)
+    pthread_mutexattr_setpolicy_np(&mutex_attribute,
+                                   _PTHREAD_MUTEX_POLICY_FIRSTFIT);
+#endif
+    pthread_mutex_init(&mutex_, &mutex_attribute);
+    pthread_mutexattr_destroy(&mutex_attribute);
+  }
+  MutexImpl(const MutexImpl&) = delete;
+  MutexImpl& operator=(const MutexImpl&) = delete;
+  ~MutexImpl() { pthread_mutex_destroy(&mutex_); }
+
+  void Lock() RTC_EXCLUSIVE_LOCK_FUNCTION() { pthread_mutex_lock(&mutex_); }
+  ABSL_MUST_USE_RESULT bool TryLock() RTC_EXCLUSIVE_TRYLOCK_FUNCTION(true) {
+    return pthread_mutex_trylock(&mutex_) == 0;
+  }
+  void Unlock() RTC_UNLOCK_FUNCTION() { pthread_mutex_unlock(&mutex_); }
+
+ private:
+  pthread_mutex_t mutex_;
+};
+
+}  // namespace webrtc
+#endif  // #if defined(WEBRTC_POSIX)
+#endif  // RTC_BASE_SYNCHRONIZATION_MUTEX_PTHREAD_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex_race_check.h b/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex_race_check.h
new file mode 100644
index 0000000..7a79d8a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/synchronization/mutex_race_check.h
@@ -0,0 +1,64 @@
+/*
+ *  Copyright 2020 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_SYNCHRONIZATION_MUTEX_RACE_CHECK_H_
+#define RTC_BASE_SYNCHRONIZATION_MUTEX_RACE_CHECK_H_
+
+#include <atomic>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/system/unused.h"
+#include "rtc_base/thread_annotations.h"
+
+namespace webrtc {
+
+// This implementation class is useful when a consuming project can guarantee
+// that all WebRTC invocation is happening serially. Additionally, the consuming
+// project cannot use WebRTC code that spawn threads or task queues.
+//
+// The class internally check fails on Lock() if it finds the consumer actually
+// invokes WebRTC concurrently.
+//
+// To use the race check mutex, define WEBRTC_RACE_CHECK_MUTEX globally. This
+// also adds a dependency to absl::Mutex from logging.cc because even though
+// objects are invoked serially, the logging is static and invoked concurrently
+// and hence needs protection.
+class RTC_LOCKABLE MutexImpl final {
+ public:
+  MutexImpl() = default;
+  MutexImpl(const MutexImpl&) = delete;
+  MutexImpl& operator=(const MutexImpl&) = delete;
+
+  void Lock() RTC_EXCLUSIVE_LOCK_FUNCTION() {
+    bool was_free = free_.exchange(false, std::memory_order_acquire);
+    RTC_CHECK(was_free)
+        << "WEBRTC_RACE_CHECK_MUTEX: mutex locked concurrently.";
+  }
+  RTC_WARN_UNUSED_RESULT bool TryLock() RTC_EXCLUSIVE_TRYLOCK_FUNCTION(true) {
+    bool was_free = free_.exchange(false, std::memory_order_acquire);
+    return was_free;
+  }
+  void Unlock() RTC_UNLOCK_FUNCTION() {
+    free_.store(true, std::memory_order_release);
+  }
+
+ private:
+  // Release-acquire ordering is used.
+  // - In the Lock methods we're guaranteeing that reads and writes happening
+  // after the (Try)Lock don't appear to have happened before the Lock (acquire
+  // ordering).
+  // - In the Unlock method we're guaranteeing that reads and writes happening
+  // before the Unlock don't appear to happen after it (release ordering).
+  std::atomic<bool> free_{true};
+};
+
+}  // namespace webrtc
+
+#endif  // RTC_BASE_SYNCHRONIZATION_MUTEX_RACE_CHECK_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/synchronization/yield.cc b/third_party/webrtc_aec3/src/rtc_base/synchronization/yield.cc
new file mode 100644
index 0000000..cbb58d1
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/synchronization/yield.cc
@@ -0,0 +1,36 @@
+/*
+ *  Copyright 2020 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "rtc_base/synchronization/yield.h"
+
+#if defined(WEBRTC_WIN)
+#include <windows.h>
+#else
+#include <sched.h>
+#include <time.h>
+#endif
+
+namespace webrtc {
+
+void YieldCurrentThread() {
+  // TODO(bugs.webrtc.org/11634): use dedicated OS functionality instead of
+  // sleep for yielding.
+#if defined(WEBRTC_WIN)
+  ::Sleep(0);
+#elif defined(WEBRTC_MAC) && defined(RTC_USE_NATIVE_MUTEX_ON_MAC) && \
+    !RTC_USE_NATIVE_MUTEX_ON_MAC
+  sched_yield();
+#else
+  static const struct timespec ts_null = {0};
+  nanosleep(&ts_null, nullptr);
+#endif
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/rtc_base/synchronization/yield.h b/third_party/webrtc_aec3/src/rtc_base/synchronization/yield.h
new file mode 100644
index 0000000..d4f5f99
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/synchronization/yield.h
@@ -0,0 +1,20 @@
+/*
+ *  Copyright 2020 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#ifndef RTC_BASE_SYNCHRONIZATION_YIELD_H_
+#define RTC_BASE_SYNCHRONIZATION_YIELD_H_
+
+namespace webrtc {
+
+// Request rescheduling of threads.
+void YieldCurrentThread();
+
+}  // namespace webrtc
+
+#endif  // RTC_BASE_SYNCHRONIZATION_YIELD_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/system/arch.h b/third_party/webrtc_aec3/src/rtc_base/system/arch.h
new file mode 100644
index 0000000..be2367b
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/system/arch.h
@@ -0,0 +1,90 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// This file contains platform-specific typedefs and defines.
+// Much of it is derived from Chromium's build/build_config.h.
+
+#ifndef RTC_BASE_SYSTEM_ARCH_H_
+#define RTC_BASE_SYSTEM_ARCH_H_
+
+// Processor architecture detection.  For more info on what's defined, see:
+//   https://docs.microsoft.com/en-us/cpp/preprocessor/predefined-macros
+//   https://www.agner.org/optimize/calling_conventions.pdf
+//   https://sourceforge.net/p/predef/wiki/Architectures/
+//   or with gcc, run: "echo | gcc -E -dM -"
+#if defined(_M_X64) || defined(__x86_64__)
+#define WEBRTC_ARCH_X86_FAMILY
+#define WEBRTC_ARCH_X86_64
+#define WEBRTC_ARCH_64_BITS
+#define WEBRTC_ARCH_LITTLE_ENDIAN
+#elif defined(_M_ARM64) || defined(__aarch64__)
+#define WEBRTC_ARCH_ARM_FAMILY
+#define WEBRTC_ARCH_64_BITS
+#define WEBRTC_ARCH_LITTLE_ENDIAN
+#elif defined(_M_IX86) || defined(__i386__)
+#define WEBRTC_ARCH_X86_FAMILY
+#define WEBRTC_ARCH_X86
+#define WEBRTC_ARCH_32_BITS
+#define WEBRTC_ARCH_LITTLE_ENDIAN
+#elif defined(_M_ARM) || defined(__ARMEL__)
+#define WEBRTC_ARCH_ARM_FAMILY
+#define WEBRTC_ARCH_32_BITS
+#define WEBRTC_ARCH_LITTLE_ENDIAN
+#elif defined(__MIPSEL__) || defined(__MIPSEB__)
+#define WEBRTC_ARCH_MIPS_FAMILY
+#if defined(__LP64__)
+#define WEBRTC_ARCH_64_BITS
+#else
+#define WEBRTC_ARCH_32_BITS
+#endif
+#if defined(__MIPSEL__)
+#define WEBRTC_ARCH_LITTLE_ENDIAN
+#else
+#define WEBRTC_ARCH_BIG_ENDIAN
+#endif
+#elif defined(__PPC__)
+#if defined(__PPC64__)
+#define WEBRTC_ARCH_64_BITS
+#else
+#define WEBRTC_ARCH_32_BITS
+#endif
+#if defined(__LITTLE_ENDIAN__)
+#define WEBRTC_ARCH_LITTLE_ENDIAN
+#else
+#define WEBRTC_ARCH_BIG_ENDIAN
+#endif
+#elif defined(__sparc) || defined(__sparc__)
+#if __SIZEOF_LONG__ == 8
+#define WEBRTC_ARCH_64_BITS
+#else
+#define WEBRTC_ARCH_32_BITS
+#endif
+#define WEBRTC_ARCH_BIG_ENDIAN
+#elif defined(__riscv) && __riscv_xlen == 64
+#define WEBRTC_ARCH_64_BITS
+#define WEBRTC_ARCH_LITTLE_ENDIAN
+#elif defined(__riscv) && __riscv_xlen == 32
+#define WEBRTC_ARCH_32_BITS
+#define WEBRTC_ARCH_LITTLE_ENDIAN
+#elif defined(__pnacl__)
+#define WEBRTC_ARCH_32_BITS
+#define WEBRTC_ARCH_LITTLE_ENDIAN
+#elif defined(__EMSCRIPTEN__)
+#define WEBRTC_ARCH_32_BITS
+#define WEBRTC_ARCH_LITTLE_ENDIAN
+#else
+#error Please add support for your architecture in rtc_base/system/arch.h
+#endif
+
+#if !(defined(WEBRTC_ARCH_LITTLE_ENDIAN) ^ defined(WEBRTC_ARCH_BIG_ENDIAN))
+#error Define either WEBRTC_ARCH_LITTLE_ENDIAN or WEBRTC_ARCH_BIG_ENDIAN
+#endif
+
+#endif  // RTC_BASE_SYSTEM_ARCH_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/system/file_wrapper.cc b/third_party/webrtc_aec3/src/rtc_base/system/file_wrapper.cc
new file mode 100644
index 0000000..3e49315
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/system/file_wrapper.cc
@@ -0,0 +1,143 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "rtc_base/system/file_wrapper.h"
+#include "rtc_base/numerics/safe_conversions.h"
+
+#include <cerrno>
+
+#ifdef _WIN32
+#include <Windows.h>
+#else
+#include <string.h>
+#endif
+
+#include <utility>
+
+namespace webrtc {
+namespace {
+FILE* FileOpen(const char* file_name_utf8, bool read_only, int* error) {
+#if defined(_WIN32)
+  int len = MultiByteToWideChar(CP_UTF8, 0, file_name_utf8, -1, nullptr, 0);
+  std::wstring wstr(len, 0);
+  MultiByteToWideChar(CP_UTF8, 0, file_name_utf8, -1, &wstr[0], len);
+  FILE* file = _wfopen(wstr.c_str(), read_only ? L"rb" : L"wb");
+#else
+  FILE* file = fopen(file_name_utf8, read_only ? "rb" : "wb");
+#endif
+  if (!file && error) {
+    *error = errno;
+  }
+  return file;
+}
+
+const char* GetCstrCheckNoEmbeddedNul(const std::string& s) {
+  const char* p = s.c_str();
+  RTC_CHECK_EQ(strlen(p), s.size())
+      << "Invalid filename, containing NUL character";
+  return p;
+}
+}  // namespace
+
+// static
+FileWrapper FileWrapper::OpenReadOnly(const char* file_name_utf8) {
+  return FileWrapper(FileOpen(file_name_utf8, true, nullptr));
+}
+
+// static
+FileWrapper FileWrapper::OpenReadOnly(const std::string& file_name_utf8) {
+  return OpenReadOnly(GetCstrCheckNoEmbeddedNul(file_name_utf8));
+}
+
+// static
+FileWrapper FileWrapper::OpenWriteOnly(const char* file_name_utf8,
+                                       int* error /*=nullptr*/) {
+  return FileWrapper(FileOpen(file_name_utf8, false, error));
+}
+
+// static
+FileWrapper FileWrapper::OpenWriteOnly(const std::string& file_name_utf8,
+                                       int* error /*=nullptr*/) {
+  return OpenWriteOnly(GetCstrCheckNoEmbeddedNul(file_name_utf8), error);
+}
+
+FileWrapper::FileWrapper(FileWrapper&& other) {
+  operator=(std::move(other));
+}
+
+FileWrapper& FileWrapper::operator=(FileWrapper&& other) {
+  Close();
+  file_ = other.file_;
+  other.file_ = nullptr;
+  return *this;
+}
+
+bool FileWrapper::SeekRelative(int64_t offset) {
+  RTC_DCHECK(file_);
+  return fseek(file_, rtc::checked_cast<long>(offset), SEEK_CUR) == 0;
+}
+
+bool FileWrapper::SeekTo(int64_t position) {
+  RTC_DCHECK(file_);
+  return fseek(file_, rtc::checked_cast<long>(position), SEEK_SET) == 0;
+}
+
+long FileWrapper::FileSize() {
+  if (file_ == nullptr)
+    return -1;
+  long original_position = ftell(file_);
+  if (original_position < 0)
+    return -1;
+  int seek_error = fseek(file_, 0, SEEK_END);
+  if (seek_error)
+    return -1;
+  long file_size = ftell(file_);
+  seek_error = fseek(file_, original_position, SEEK_SET);
+  if (seek_error)
+    return -1;
+  return file_size;
+}
+
+bool FileWrapper::Flush() {
+  RTC_DCHECK(file_);
+  return fflush(file_) == 0;
+}
+
+size_t FileWrapper::Read(void* buf, size_t length) {
+  RTC_DCHECK(file_);
+  return fread(buf, 1, length, file_);
+}
+
+bool FileWrapper::ReadEof() const {
+  RTC_DCHECK(file_);
+  return feof(file_);
+}
+
+bool FileWrapper::Write(const void* buf, size_t length) {
+  RTC_DCHECK(file_);
+  return fwrite(buf, 1, length, file_) == length;
+}
+
+bool FileWrapper::Close() {
+  if (file_ == nullptr)
+    return true;
+
+  bool success = fclose(file_) == 0;
+  file_ = nullptr;
+  return success;
+}
+
+FILE* FileWrapper::Release() {
+  FILE* file = file_;
+  file_ = nullptr;
+  return file;
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/rtc_base/system/file_wrapper.h b/third_party/webrtc_aec3/src/rtc_base/system/file_wrapper.h
new file mode 100644
index 0000000..0b293d9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/system/file_wrapper.h
@@ -0,0 +1,113 @@
+/*
+ *  Copyright (c) 2011 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_SYSTEM_FILE_WRAPPER_H_
+#define RTC_BASE_SYSTEM_FILE_WRAPPER_H_
+
+#include <stddef.h>
+#include <stdio.h>
+
+#include <string>
+
+// Implementation that can read (exclusive) or write from/to a file.
+
+namespace webrtc {
+
+// This class is a thin wrapper around FILE*. It's main features are that it
+// owns the FILE*, calling fclose on destruction, and that on windows, file
+// names passed to the open methods are always treated as utf-8, regardless of
+// system code page.
+
+// Most of the methods return only a success/fail indication. When needed, an
+// optional argument |int* error| should be added to all methods, in the same
+// way as for the OpenWriteOnly methods.
+class FileWrapper final {
+ public:
+  // Opens a file, in read or write mode. Use the is_open() method on the
+  // returned object to check if the open operation was successful. On failure,
+  // and if |error| is non-null, the system errno value is stored at |*error|.
+  // The file is closed by the destructor.
+  static FileWrapper OpenReadOnly(const char* file_name_utf8);
+  static FileWrapper OpenReadOnly(const std::string& file_name_utf8);
+  static FileWrapper OpenWriteOnly(const char* file_name_utf8,
+                                   int* error = nullptr);
+  static FileWrapper OpenWriteOnly(const std::string& file_name_utf8,
+                                   int* error = nullptr);
+
+  FileWrapper() = default;
+
+  // Takes over ownership of |file|, closing it on destruction. Calling with
+  // null |file| is allowed, and results in a FileWrapper with is_open() false.
+  explicit FileWrapper(FILE* file) : file_(file) {}
+  ~FileWrapper() { Close(); }
+
+  // Copying is not supported.
+  FileWrapper(const FileWrapper&) = delete;
+  FileWrapper& operator=(const FileWrapper&) = delete;
+
+  // Support for move semantics.
+  FileWrapper(FileWrapper&&);
+  FileWrapper& operator=(FileWrapper&&);
+
+  // Returns true if a file has been opened. If the file is not open, no methods
+  // but is_open and Close may be called.
+  bool is_open() const { return file_ != nullptr; }
+
+  // Closes the file, and implies Flush. Returns true on success, false if
+  // writing buffered data fails. On failure, the file is nevertheless closed.
+  // Calling Close on an already closed file does nothing and returns success.
+  bool Close();
+
+  // Releases and returns the wrapped file without closing it. This call passes
+  // the ownership of the file to the caller, and the wrapper is no longer
+  // responsible for closing it. Similarly the previously wrapped file is no
+  // longer available for the wrapper to use in any aspect.
+  FILE* Release();
+
+  // Write any buffered data to the underlying file. Returns true on success,
+  // false on write error. Note: Flushing when closing, is not required.
+  bool Flush();
+
+  // Seeks to the beginning of file. Returns true on success, false on failure,
+  // e.g., if the underlying file isn't seekable.
+  bool Rewind() { return SeekTo(0); }
+  // TODO(nisse): The seek functions are used only by the WavReader. If that
+  // code is demoted to test code, seek functions can be deleted from this
+  // utility.
+  // Seek relative to current file position.
+  bool SeekRelative(int64_t offset);
+  // Seek to given position.
+  bool SeekTo(int64_t position);
+
+  // Returns the file size or -1 if a size could not be determined.
+  // (A file size might not exists for non-seekable files or file-like
+  // objects, for example /dev/tty on unix.)
+  long FileSize();
+
+  // Returns number of bytes read. Short count indicates EOF or error.
+  size_t Read(void* buf, size_t length);
+
+  // If the most recent Read() returned a short count, this methods returns true
+  // if the short count was due to EOF, and false it it was due to some i/o
+  // error.
+  bool ReadEof() const;
+
+  // Returns true if all data was successfully written (or buffered), or false
+  // if there was an error. Writing buffered data can fail later, and is
+  // reported with return value from Flush or Close.
+  bool Write(const void* buf, size_t length);
+
+ private:
+  FILE* file_ = nullptr;
+};
+
+}  // namespace webrtc
+
+#endif  // RTC_BASE_SYSTEM_FILE_WRAPPER_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/system/inline.h b/third_party/webrtc_aec3/src/rtc_base/system/inline.h
new file mode 100644
index 0000000..f585d34
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/system/inline.h
@@ -0,0 +1,31 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_SYSTEM_INLINE_H_
+#define RTC_BASE_SYSTEM_INLINE_H_
+
+#if defined(_MSC_VER)
+
+#define RTC_FORCE_INLINE __forceinline
+#define RTC_NO_INLINE __declspec(noinline)
+
+#elif defined(__GNUC__)
+
+#define RTC_FORCE_INLINE __attribute__((__always_inline__))
+#define RTC_NO_INLINE __attribute__((__noinline__))
+
+#else
+
+#define RTC_FORCE_INLINE
+#define RTC_NO_INLINE
+
+#endif
+
+#endif  // RTC_BASE_SYSTEM_INLINE_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/system/rtc_export.h b/third_party/webrtc_aec3/src/rtc_base/system/rtc_export.h
new file mode 100644
index 0000000..d1eb60a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/system/rtc_export.h
@@ -0,0 +1,43 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_SYSTEM_RTC_EXPORT_H_
+#define RTC_BASE_SYSTEM_RTC_EXPORT_H_
+
+// RTC_EXPORT is used to mark symbols as exported or imported when WebRTC is
+// built or used as a shared library.
+// When WebRTC is built as a static library the RTC_EXPORT macro expands to
+// nothing.
+
+#ifdef WEBRTC_ENABLE_SYMBOL_EXPORT
+
+#ifdef WEBRTC_WIN
+
+#ifdef WEBRTC_LIBRARY_IMPL
+#define RTC_EXPORT __declspec(dllexport)
+#else
+#define RTC_EXPORT __declspec(dllimport)
+#endif
+
+#else  // WEBRTC_WIN
+
+#if __has_attribute(visibility) && defined(WEBRTC_LIBRARY_IMPL)
+#define RTC_EXPORT __attribute__((visibility("default")))
+#endif
+
+#endif  // WEBRTC_WIN
+
+#endif  // WEBRTC_ENABLE_SYMBOL_EXPORT
+
+#ifndef RTC_EXPORT
+#define RTC_EXPORT
+#endif
+
+#endif  // RTC_BASE_SYSTEM_RTC_EXPORT_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/system_time.cc b/third_party/webrtc_aec3/src/rtc_base/system_time.cc
new file mode 100644
index 0000000..9efe76e
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/system_time.cc
@@ -0,0 +1,97 @@
+/*
+ *  Copyright 2021 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// If WEBRTC_EXCLUDE_SYSTEM_TIME is set, an implementation of
+// rtc::SystemTimeNanos() must be provided externally.
+#ifndef WEBRTC_EXCLUDE_SYSTEM_TIME
+
+#include <stdint.h>
+
+#include <limits>
+
+#if defined(WEBRTC_POSIX)
+#include <sys/time.h>
+#if defined(WEBRTC_MAC)
+#include <mach/mach_time.h>
+#endif
+#endif
+
+#if defined(WEBRTC_WIN)
+// clang-format off
+// clang formatting would put <windows.h> last,
+// which leads to compilation failure.
+#include <windows.h>
+#include <mmsystem.h>
+#include <sys/timeb.h>
+// clang-format on
+#endif
+
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_conversions.h"
+#include "rtc_base/system_time.h"
+#include "rtc_base/time_utils.h"
+
+namespace rtc {
+
+int64_t SystemTimeNanos() {
+  int64_t ticks;
+#if defined(WEBRTC_MAC)
+  static mach_timebase_info_data_t timebase;
+  if (timebase.denom == 0) {
+    // Get the timebase if this is the first time we run.
+    // Recommended by Apple's QA1398.
+    if (mach_timebase_info(&timebase) != KERN_SUCCESS) {
+      RTC_NOTREACHED();
+    }
+  }
+  // Use timebase to convert absolute time tick units into nanoseconds.
+  const auto mul = [](uint64_t a, uint32_t b) -> int64_t {
+    RTC_DCHECK_NE(b, 0);
+    RTC_DCHECK_LE(a, std::numeric_limits<int64_t>::max() / b)
+        << "The multiplication " << a << " * " << b << " overflows";
+    return rtc::dchecked_cast<int64_t>(a * b);
+  };
+  ticks = mul(mach_absolute_time(), timebase.numer) / timebase.denom;
+#elif defined(WEBRTC_POSIX)
+  struct timespec ts;
+  // TODO(deadbeef): Do we need to handle the case when CLOCK_MONOTONIC is not
+  // supported?
+  clock_gettime(CLOCK_MONOTONIC, &ts);
+  ticks = kNumNanosecsPerSec * static_cast<int64_t>(ts.tv_sec) +
+          static_cast<int64_t>(ts.tv_nsec);
+#elif defined(WINUWP)
+  ticks = WinUwpSystemTimeNanos();
+#elif defined(WEBRTC_WIN)
+  static volatile LONG last_timegettime = 0;
+  static volatile int64_t num_wrap_timegettime = 0;
+  volatile LONG* last_timegettime_ptr = &last_timegettime;
+  DWORD now = timeGetTime();
+  // Atomically update the last gotten time
+  DWORD old = InterlockedExchange(last_timegettime_ptr, now);
+  if (now < old) {
+    // If now is earlier than old, there may have been a race between threads.
+    // 0x0fffffff ~3.1 days, the code will not take that long to execute
+    // so it must have been a wrap around.
+    if (old > 0xf0000000 && now < 0x0fffffff) {
+      num_wrap_timegettime++;
+    }
+  }
+  ticks = now + (num_wrap_timegettime << 32);
+  // TODO(deadbeef): Calculate with nanosecond precision. Otherwise, we're
+  // just wasting a multiply and divide when doing Time() on Windows.
+  ticks = ticks * kNumNanosecsPerMillisec;
+#else
+#error Unsupported platform.
+#endif
+  return ticks;
+}
+
+}  // namespace rtc
+#endif  // WEBRTC_EXCLUDE_SYSTEM_TIME
diff --git a/third_party/webrtc_aec3/src/rtc_base/system_time.h b/third_party/webrtc_aec3/src/rtc_base/system_time.h
new file mode 100644
index 0000000..d86e94a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/system_time.h
@@ -0,0 +1,22 @@
+/*
+ *  Copyright 2021 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_SYSTEM_TIME_H_
+#define RTC_BASE_SYSTEM_TIME_H_
+
+namespace rtc {
+
+// Returns the actual system time, even if a clock is set for testing.
+// Useful for timeouts while using a test clock, or for logging.
+int64_t SystemTimeNanos();
+
+}  // namespace rtc
+
+#endif  // RTC_BASE_SYSTEM_TIME_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/thread_annotations.h b/third_party/webrtc_aec3/src/rtc_base/thread_annotations.h
new file mode 100644
index 0000000..8569fab
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/thread_annotations.h
@@ -0,0 +1,95 @@
+//
+// Copyright (c) 2013 The WebRTC project authors. All Rights Reserved.
+//
+// Use of this source code is governed by a BSD-style license
+// that can be found in the LICENSE file in the root of the source
+// tree. An additional intellectual property rights grant can be found
+// in the file PATENTS.  All contributing project authors may
+// be found in the AUTHORS file in the root of the source tree.
+//
+// Borrowed from
+// https://code.google.com/p/gperftools/source/browse/src/base/thread_annotations.h
+// but adapted for clang attributes instead of the gcc.
+//
+// This header file contains the macro definitions for thread safety
+// annotations that allow the developers to document the locking policies
+// of their multi-threaded code. The annotations can also help program
+// analysis tools to identify potential thread safety issues.
+
+#ifndef RTC_BASE_THREAD_ANNOTATIONS_H_
+#define RTC_BASE_THREAD_ANNOTATIONS_H_
+
+#if defined(__clang__) && (!defined(SWIG))
+#define RTC_THREAD_ANNOTATION_ATTRIBUTE__(x) __attribute__((x))
+#else
+#define RTC_THREAD_ANNOTATION_ATTRIBUTE__(x)  // no-op
+#endif
+
+// Document if a shared variable/field needs to be protected by a lock.
+// GUARDED_BY allows the user to specify a particular lock that should be
+// held when accessing the annotated variable.
+#define RTC_GUARDED_BY(x) RTC_THREAD_ANNOTATION_ATTRIBUTE__(guarded_by(x))
+
+// Document if the memory location pointed to by a pointer should be guarded
+// by a lock when dereferencing the pointer. Note that a pointer variable to a
+// shared memory location could itself be a shared variable. For example, if a
+// shared global pointer q, which is guarded by mu1, points to a shared memory
+// location that is guarded by mu2, q should be annotated as follows:
+//     int *q GUARDED_BY(mu1) PT_GUARDED_BY(mu2);
+#define RTC_PT_GUARDED_BY(x) RTC_THREAD_ANNOTATION_ATTRIBUTE__(pt_guarded_by(x))
+
+// Document the acquisition order between locks that can be held
+// simultaneously by a thread. For any two locks that need to be annotated
+// to establish an acquisition order, only one of them needs the annotation.
+// (i.e. You don't have to annotate both locks with both ACQUIRED_AFTER
+// and ACQUIRED_BEFORE.)
+#define RTC_ACQUIRED_AFTER(x) \
+  RTC_THREAD_ANNOTATION_ATTRIBUTE__(acquired_after(x))
+#define RTC_ACQUIRED_BEFORE(x) \
+  RTC_THREAD_ANNOTATION_ATTRIBUTE__(acquired_before(x))
+
+// The following three annotations document the lock requirements for
+// functions/methods.
+
+// Document if a function expects certain locks to be held before it is called
+#define RTC_EXCLUSIVE_LOCKS_REQUIRED(...) \
+  RTC_THREAD_ANNOTATION_ATTRIBUTE__(exclusive_locks_required(__VA_ARGS__))
+#define RTC_SHARED_LOCKS_REQUIRED(...) \
+  RTC_THREAD_ANNOTATION_ATTRIBUTE__(shared_locks_required(__VA_ARGS__))
+
+// Document the locks acquired in the body of the function. These locks
+// cannot be held when calling this function (as google3's Mutex locks are
+// non-reentrant).
+#define RTC_LOCKS_EXCLUDED(...) \
+  RTC_THREAD_ANNOTATION_ATTRIBUTE__(locks_excluded(__VA_ARGS__))
+
+// Document the lock the annotated function returns without acquiring it.
+#define RTC_LOCK_RETURNED(x) RTC_THREAD_ANNOTATION_ATTRIBUTE__(lock_returned(x))
+
+// Document if a class/type is a lockable type (such as the Mutex class).
+#define RTC_LOCKABLE RTC_THREAD_ANNOTATION_ATTRIBUTE__(lockable)
+
+// Document if a class is a scoped lockable type (such as the MutexLock class).
+#define RTC_SCOPED_LOCKABLE RTC_THREAD_ANNOTATION_ATTRIBUTE__(scoped_lockable)
+
+// The following annotations specify lock and unlock primitives.
+#define RTC_EXCLUSIVE_LOCK_FUNCTION(...) \
+  RTC_THREAD_ANNOTATION_ATTRIBUTE__(exclusive_lock_function(__VA_ARGS__))
+
+#define RTC_SHARED_LOCK_FUNCTION(...) \
+  RTC_THREAD_ANNOTATION_ATTRIBUTE__(shared_lock_function(__VA_ARGS__))
+
+#define RTC_EXCLUSIVE_TRYLOCK_FUNCTION(...) \
+  RTC_THREAD_ANNOTATION_ATTRIBUTE__(exclusive_trylock_function(__VA_ARGS__))
+
+#define RTC_SHARED_TRYLOCK_FUNCTION(...) \
+  RTC_THREAD_ANNOTATION_ATTRIBUTE__(shared_trylock_function(__VA_ARGS__))
+
+#define RTC_UNLOCK_FUNCTION(...) \
+  RTC_THREAD_ANNOTATION_ATTRIBUTE__(unlock_function(__VA_ARGS__))
+
+// An escape hatch for thread safety analysis to ignore the annotated function.
+#define RTC_NO_THREAD_SAFETY_ANALYSIS \
+  RTC_THREAD_ANNOTATION_ATTRIBUTE__(no_thread_safety_analysis)
+
+#endif  // RTC_BASE_THREAD_ANNOTATIONS_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/time_utils.cc b/third_party/webrtc_aec3/src/rtc_base/time_utils.cc
new file mode 100644
index 0000000..fe63d3a
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/time_utils.cc
@@ -0,0 +1,270 @@
+/*
+ *  Copyright 2004 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include <stdint.h>
+
+#if defined(WEBRTC_POSIX)
+#include <sys/time.h>
+#endif
+
+#if defined(WEBRTC_WIN)
+#include <sys/timeb.h>
+#endif
+
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_conversions.h"
+#include "rtc_base/system_time.h"
+#include "rtc_base/time_utils.h"
+
+namespace rtc {
+
+ClockInterface* g_clock = nullptr;
+
+ClockInterface* SetClockForTesting(ClockInterface* clock) {
+  ClockInterface* prev = g_clock;
+  g_clock = clock;
+  return prev;
+}
+
+ClockInterface* GetClockForTesting() {
+  return g_clock;
+}
+
+#if defined(WINUWP)
+
+namespace {
+
+class TimeHelper final {
+ public:
+  TimeHelper(const TimeHelper&) = delete;
+
+  // Resets the clock based upon an NTP server. This routine must be called
+  // prior to the main system start-up to ensure all clocks are based upon
+  // an NTP server time if NTP synchronization is required. No critical
+  // section is used thus this method must be called prior to any clock
+  // routines being used.
+  static void SyncWithNtp(int64_t ntp_server_time_ms) {
+    auto& singleton = Singleton();
+    TIME_ZONE_INFORMATION time_zone;
+    GetTimeZoneInformation(&time_zone);
+    int64_t time_zone_bias_ns =
+        rtc::dchecked_cast<int64_t>(time_zone.Bias) * 60 * 1000 * 1000 * 1000;
+    singleton.app_start_time_ns_ =
+        (ntp_server_time_ms - kNTPTimeToUnixTimeEpochOffset) * 1000000 -
+        time_zone_bias_ns;
+    singleton.UpdateReferenceTime();
+  }
+
+  // Returns the number of nanoseconds that have passed since unix epoch.
+  static int64_t TicksNs() {
+    auto& singleton = Singleton();
+    int64_t result = 0;
+    LARGE_INTEGER qpcnt;
+    QueryPerformanceCounter(&qpcnt);
+    result = rtc::dchecked_cast<int64_t>(
+        (rtc::dchecked_cast<uint64_t>(qpcnt.QuadPart) * 100000 /
+         rtc::dchecked_cast<uint64_t>(singleton.os_ticks_per_second_)) *
+        10000);
+    result = singleton.app_start_time_ns_ + result -
+             singleton.time_since_os_start_ns_;
+    return result;
+  }
+
+ private:
+  TimeHelper() {
+    TIME_ZONE_INFORMATION time_zone;
+    GetTimeZoneInformation(&time_zone);
+    int64_t time_zone_bias_ns =
+        rtc::dchecked_cast<int64_t>(time_zone.Bias) * 60 * 1000 * 1000 * 1000;
+    FILETIME ft;
+    // This will give us system file in UTC format.
+    GetSystemTimeAsFileTime(&ft);
+    LARGE_INTEGER li;
+    li.HighPart = ft.dwHighDateTime;
+    li.LowPart = ft.dwLowDateTime;
+
+    app_start_time_ns_ = (li.QuadPart - kFileTimeToUnixTimeEpochOffset) * 100 -
+                         time_zone_bias_ns;
+
+    UpdateReferenceTime();
+  }
+
+  static TimeHelper& Singleton() {
+    static TimeHelper singleton;
+    return singleton;
+  }
+
+  void UpdateReferenceTime() {
+    LARGE_INTEGER qpfreq;
+    QueryPerformanceFrequency(&qpfreq);
+    os_ticks_per_second_ = rtc::dchecked_cast<int64_t>(qpfreq.QuadPart);
+
+    LARGE_INTEGER qpcnt;
+    QueryPerformanceCounter(&qpcnt);
+    time_since_os_start_ns_ = rtc::dchecked_cast<int64_t>(
+        (rtc::dchecked_cast<uint64_t>(qpcnt.QuadPart) * 100000 /
+         rtc::dchecked_cast<uint64_t>(os_ticks_per_second_)) *
+        10000);
+  }
+
+ private:
+  static constexpr uint64_t kFileTimeToUnixTimeEpochOffset =
+      116444736000000000ULL;
+  static constexpr uint64_t kNTPTimeToUnixTimeEpochOffset = 2208988800000L;
+
+  // The number of nanoseconds since unix system epoch
+  int64_t app_start_time_ns_;
+  // The number of nanoseconds since the OS started
+  int64_t time_since_os_start_ns_;
+  // The OS calculated ticks per second
+  int64_t os_ticks_per_second_;
+};
+
+}  // namespace
+
+void SyncWithNtp(int64_t time_from_ntp_server_ms) {
+  TimeHelper::SyncWithNtp(time_from_ntp_server_ms);
+}
+
+int64_t WinUwpSystemTimeNanos() {
+  return TimeHelper::TicksNs();
+}
+
+#endif  // defined(WINUWP)
+
+int64_t SystemTimeMillis() {
+  return static_cast<int64_t>(SystemTimeNanos() / kNumNanosecsPerMillisec);
+}
+
+int64_t TimeNanos() {
+  if (g_clock) {
+    return g_clock->TimeNanos();
+  }
+  return SystemTimeNanos();
+}
+
+uint32_t Time32() {
+  return static_cast<uint32_t>(TimeNanos() / kNumNanosecsPerMillisec);
+}
+
+int64_t TimeMillis() {
+  return TimeNanos() / kNumNanosecsPerMillisec;
+}
+
+int64_t TimeMicros() {
+  return TimeNanos() / kNumNanosecsPerMicrosec;
+}
+
+int64_t TimeAfter(int64_t elapsed) {
+  RTC_DCHECK_GE(elapsed, 0);
+  return TimeMillis() + elapsed;
+}
+
+int32_t TimeDiff32(uint32_t later, uint32_t earlier) {
+  return later - earlier;
+}
+
+int64_t TimeDiff(int64_t later, int64_t earlier) {
+  return later - earlier;
+}
+
+TimestampWrapAroundHandler::TimestampWrapAroundHandler()
+    : last_ts_(0), num_wrap_(-1) {}
+
+int64_t TimestampWrapAroundHandler::Unwrap(uint32_t ts) {
+  if (num_wrap_ == -1) {
+    last_ts_ = ts;
+    num_wrap_ = 0;
+    return ts;
+  }
+
+  if (ts < last_ts_) {
+    if (last_ts_ >= 0xf0000000 && ts < 0x0fffffff)
+      ++num_wrap_;
+  } else if ((ts - last_ts_) > 0xf0000000) {
+    // Backwards wrap. Unwrap with last wrap count and don't update last_ts_.
+    return ts + (num_wrap_ - 1) * (int64_t{1} << 32);
+  }
+
+  last_ts_ = ts;
+  return ts + (num_wrap_ << 32);
+}
+
+int64_t TmToSeconds(const tm& tm) {
+  static short int mdays[12] = {31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31};
+  static short int cumul_mdays[12] = {0,   31,  59,  90,  120, 151,
+                                      181, 212, 243, 273, 304, 334};
+  int year = tm.tm_year + 1900;
+  int month = tm.tm_mon;
+  int day = tm.tm_mday - 1;  // Make 0-based like the rest.
+  int hour = tm.tm_hour;
+  int min = tm.tm_min;
+  int sec = tm.tm_sec;
+
+  bool expiry_in_leap_year =
+      (year % 4 == 0 && (year % 100 != 0 || year % 400 == 0));
+
+  if (year < 1970)
+    return -1;
+  if (month < 0 || month > 11)
+    return -1;
+  if (day < 0 || day >= mdays[month] + (expiry_in_leap_year && month == 2 - 1))
+    return -1;
+  if (hour < 0 || hour > 23)
+    return -1;
+  if (min < 0 || min > 59)
+    return -1;
+  if (sec < 0 || sec > 59)
+    return -1;
+
+  day += cumul_mdays[month];
+
+  // Add number of leap days between 1970 and the expiration year, inclusive.
+  day += ((year / 4 - 1970 / 4) - (year / 100 - 1970 / 100) +
+          (year / 400 - 1970 / 400));
+
+  // We will have added one day too much above if expiration is during a leap
+  // year, and expiration is in January or February.
+  if (expiry_in_leap_year && month <= 2 - 1)  // |month| is zero based.
+    day -= 1;
+
+  // Combine all variables into seconds from 1970-01-01 00:00 (except |month|
+  // which was accumulated into |day| above).
+  return (((static_cast<int64_t>(year - 1970) * 365 + day) * 24 + hour) * 60 +
+          min) *
+             60 +
+         sec;
+}
+
+int64_t TimeUTCMicros() {
+  if (g_clock) {
+    return g_clock->TimeNanos() / kNumNanosecsPerMicrosec;
+  }
+#if defined(WEBRTC_POSIX)
+  struct timeval time;
+  gettimeofday(&time, nullptr);
+  // Convert from second (1.0) and microsecond (1e-6).
+  return (static_cast<int64_t>(time.tv_sec) * rtc::kNumMicrosecsPerSec +
+          time.tv_usec);
+
+#elif defined(WEBRTC_WIN)
+  struct _timeb time;
+  _ftime(&time);
+  // Convert from second (1.0) and milliseconds (1e-3).
+  return (static_cast<int64_t>(time.time) * rtc::kNumMicrosecsPerSec +
+          static_cast<int64_t>(time.millitm) * rtc::kNumMicrosecsPerMillisec);
+#endif
+}
+
+int64_t TimeUTCMillis() {
+  return TimeUTCMicros() / kNumMicrosecsPerMillisec;
+}
+
+}  // namespace rtc
diff --git a/third_party/webrtc_aec3/src/rtc_base/time_utils.h b/third_party/webrtc_aec3/src/rtc_base/time_utils.h
new file mode 100644
index 0000000..de3c58c
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/time_utils.h
@@ -0,0 +1,145 @@
+/*
+ *  Copyright 2005 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_TIME_UTILS_H_
+#define RTC_BASE_TIME_UTILS_H_
+
+#include <stdint.h>
+#include <time.h>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/system/rtc_export.h"
+#include "rtc_base/system_time.h"
+
+namespace rtc {
+
+static const int64_t kNumMillisecsPerSec = INT64_C(1000);
+static const int64_t kNumMicrosecsPerSec = INT64_C(1000000);
+static const int64_t kNumNanosecsPerSec = INT64_C(1000000000);
+
+static const int64_t kNumMicrosecsPerMillisec =
+    kNumMicrosecsPerSec / kNumMillisecsPerSec;
+static const int64_t kNumNanosecsPerMillisec =
+    kNumNanosecsPerSec / kNumMillisecsPerSec;
+static const int64_t kNumNanosecsPerMicrosec =
+    kNumNanosecsPerSec / kNumMicrosecsPerSec;
+
+// TODO(honghaiz): Define a type for the time value specifically.
+
+class ClockInterface {
+ public:
+  virtual ~ClockInterface() {}
+  virtual int64_t TimeNanos() const = 0;
+};
+
+// Sets the global source of time. This is useful mainly for unit tests.
+//
+// Returns the previously set ClockInterface, or nullptr if none is set.
+//
+// Does not transfer ownership of the clock. SetClockForTesting(nullptr)
+// should be called before the ClockInterface is deleted.
+//
+// This method is not thread-safe; it should only be used when no other thread
+// is running (for example, at the start/end of a unit test, or start/end of
+// main()).
+//
+// TODO(deadbeef): Instead of having functions that access this global
+// ClockInterface, we may want to pass the ClockInterface into everything
+// that uses it, eliminating the need for a global variable and this function.
+RTC_EXPORT ClockInterface* SetClockForTesting(ClockInterface* clock);
+
+// Returns previously set clock, or nullptr if no custom clock is being used.
+RTC_EXPORT ClockInterface* GetClockForTesting();
+
+#if defined(WINUWP)
+// Synchronizes the current clock based upon an NTP server's epoch in
+// milliseconds.
+void SyncWithNtp(int64_t time_from_ntp_server_ms);
+
+// Returns the current time in nanoseconds. The clock is synchonized with the
+// system wall clock time upon instatiation. It may also be synchronized using
+// the SyncWithNtp() function above. Please note that the clock will most likely
+// drift away from the system wall clock time as time goes by.
+int64_t WinUwpSystemTimeNanos();
+#endif  // defined(WINUWP)
+
+// Returns the actual system time, even if a clock is set for testing.
+// Useful for timeouts while using a test clock, or for logging.
+int64_t SystemTimeMillis();
+
+// Returns the current time in milliseconds in 32 bits.
+uint32_t Time32();
+
+// Returns the current time in milliseconds in 64 bits.
+RTC_EXPORT int64_t TimeMillis();
+// Deprecated. Do not use this in any new code.
+inline int64_t Time() {
+  return TimeMillis();
+}
+
+// Returns the current time in microseconds.
+RTC_EXPORT int64_t TimeMicros();
+
+// Returns the current time in nanoseconds.
+RTC_EXPORT int64_t TimeNanos();
+
+// Returns a future timestamp, 'elapsed' milliseconds from now.
+int64_t TimeAfter(int64_t elapsed);
+
+// Number of milliseconds that would elapse between 'earlier' and 'later'
+// timestamps.  The value is negative if 'later' occurs before 'earlier'.
+int64_t TimeDiff(int64_t later, int64_t earlier);
+int32_t TimeDiff32(uint32_t later, uint32_t earlier);
+
+// The number of milliseconds that have elapsed since 'earlier'.
+inline int64_t TimeSince(int64_t earlier) {
+  return TimeMillis() - earlier;
+}
+
+// The number of milliseconds that will elapse between now and 'later'.
+inline int64_t TimeUntil(int64_t later) {
+  return later - TimeMillis();
+}
+
+class TimestampWrapAroundHandler {
+ public:
+  TimestampWrapAroundHandler();
+
+  int64_t Unwrap(uint32_t ts);
+
+ private:
+  uint32_t last_ts_;
+  int64_t num_wrap_;
+};
+
+// Convert from tm, which is relative to 1900-01-01 00:00 to number of
+// seconds from 1970-01-01 00:00 ("epoch"). Don't return time_t since that
+// is still 32 bits on many systems.
+int64_t TmToSeconds(const tm& tm);
+
+// Return the number of microseconds since January 1, 1970, UTC.
+// Useful mainly when producing logs to be correlated with other
+// devices, and when the devices in question all have properly
+// synchronized clocks.
+//
+// Note that this function obeys the system's idea about what the time
+// is. It is not guaranteed to be monotonic; it will jump in case the
+// system time is changed, e.g., by some other process calling
+// settimeofday. Always use rtc::TimeMicros(), not this function, for
+// measuring time intervals and timeouts.
+int64_t TimeUTCMicros();
+
+// Return the number of milliseconds since January 1, 1970, UTC.
+// See above.
+int64_t TimeUTCMillis();
+
+}  // namespace rtc
+
+#endif  // RTC_BASE_TIME_UTILS_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/type_traits.h b/third_party/webrtc_aec3/src/rtc_base/type_traits.h
new file mode 100644
index 0000000..0cb899c
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/type_traits.h
@@ -0,0 +1,140 @@
+/*
+ *  Copyright 2016 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef RTC_BASE_TYPE_TRAITS_H_
+#define RTC_BASE_TYPE_TRAITS_H_
+
+#include <cstddef>
+#include <type_traits>
+
+namespace rtc {
+
+// Determines if the given class has zero-argument .data() and .size() methods
+// whose return values are convertible to T* and size_t, respectively.
+template <typename DS, typename T>
+class HasDataAndSize {
+ private:
+  template <
+      typename C,
+      typename std::enable_if<
+          std::is_convertible<decltype(std::declval<C>().data()), T*>::value &&
+          std::is_convertible<decltype(std::declval<C>().size()),
+                              std::size_t>::value>::type* = nullptr>
+  static int Test(int);
+
+  template <typename>
+  static char Test(...);
+
+ public:
+  static constexpr bool value = std::is_same<decltype(Test<DS>(0)), int>::value;
+};
+
+namespace test_has_data_and_size {
+
+template <typename DR, typename SR>
+struct Test1 {
+  DR data();
+  SR size();
+};
+static_assert(HasDataAndSize<Test1<int*, int>, int>::value, "");
+static_assert(HasDataAndSize<Test1<int*, int>, const int>::value, "");
+static_assert(HasDataAndSize<Test1<const int*, int>, const int>::value, "");
+static_assert(!HasDataAndSize<Test1<const int*, int>, int>::value,
+              "implicit cast of const int* to int*");
+static_assert(!HasDataAndSize<Test1<char*, size_t>, int>::value,
+              "implicit cast of char* to int*");
+
+struct Test2 {
+  int* data;
+  size_t size;
+};
+static_assert(!HasDataAndSize<Test2, int>::value,
+              ".data and .size aren't functions");
+
+struct Test3 {
+  int* data();
+};
+static_assert(!HasDataAndSize<Test3, int>::value, ".size() is missing");
+
+class Test4 {
+  int* data();
+  size_t size();
+};
+static_assert(!HasDataAndSize<Test4, int>::value,
+              ".data() and .size() are private");
+
+}  // namespace test_has_data_and_size
+
+namespace type_traits_impl {
+
+// Determines if the given type is an enum that converts implicitly to
+// an integral type.
+template <typename T>
+struct IsIntEnum {
+ private:
+  // This overload is used if the type is an enum, and unary plus
+  // compiles and turns it into an integral type.
+  template <typename X,
+            typename std::enable_if<
+                std::is_enum<X>::value &&
+                std::is_integral<decltype(+std::declval<X>())>::value>::type* =
+                nullptr>
+  static int Test(int);
+
+  // Otherwise, this overload is used.
+  template <typename>
+  static char Test(...);
+
+ public:
+  static constexpr bool value =
+      std::is_same<decltype(Test<typename std::remove_reference<T>::type>(0)),
+                   int>::value;
+};
+
+}  // namespace type_traits_impl
+
+// Determines if the given type is integral, or an enum that
+// converts implicitly to an integral type.
+template <typename T>
+struct IsIntlike {
+ private:
+  using X = typename std::remove_reference<T>::type;
+
+ public:
+  static constexpr bool value =
+      std::is_integral<X>::value || type_traits_impl::IsIntEnum<X>::value;
+};
+
+namespace test_enum_intlike {
+
+enum E1 { e1 };
+enum { e2 };
+enum class E3 { e3 };
+struct S {};
+
+static_assert(type_traits_impl::IsIntEnum<E1>::value, "");
+static_assert(type_traits_impl::IsIntEnum<decltype(e2)>::value, "");
+static_assert(!type_traits_impl::IsIntEnum<E3>::value, "");
+static_assert(!type_traits_impl::IsIntEnum<int>::value, "");
+static_assert(!type_traits_impl::IsIntEnum<float>::value, "");
+static_assert(!type_traits_impl::IsIntEnum<S>::value, "");
+
+static_assert(IsIntlike<E1>::value, "");
+static_assert(IsIntlike<decltype(e2)>::value, "");
+static_assert(!IsIntlike<E3>::value, "");
+static_assert(IsIntlike<int>::value, "");
+static_assert(!IsIntlike<float>::value, "");
+static_assert(!IsIntlike<S>::value, "");
+
+}  // namespace test_enum_intlike
+
+}  // namespace rtc
+
+#endif  // RTC_BASE_TYPE_TRAITS_H_
diff --git a/third_party/webrtc_aec3/src/rtc_base/units/unit_base.h b/third_party/webrtc_aec3/src/rtc_base/units/unit_base.h
new file mode 100644
index 0000000..7196bae
--- /dev/null
+++ b/third_party/webrtc_aec3/src/rtc_base/units/unit_base.h
@@ -0,0 +1,306 @@
+/*
+ *  Copyright 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#ifndef RTC_BASE_UNITS_UNIT_BASE_H_
+#define RTC_BASE_UNITS_UNIT_BASE_H_
+
+#include <stdint.h>
+
+#include <algorithm>
+#include <cmath>
+#include <limits>
+#include <type_traits>
+
+#include "rtc_base/checks.h"
+#include "rtc_base/numerics/safe_conversions.h"
+
+namespace webrtc {
+namespace rtc_units_impl {
+
+// UnitBase is a base class for implementing custom value types with a specific
+// unit. It provides type safety and commonly useful operations. The underlying
+// storage is always an int64_t, it's up to the unit implementation to choose
+// what scale it represents.
+//
+// It's used like:
+// class MyUnit: public UnitBase<MyUnit> {...};
+//
+// Unit_T is the subclass representing the specific unit.
+template <class Unit_T>
+class UnitBase {
+ public:
+  UnitBase() = delete;
+  static constexpr Unit_T Zero() { return Unit_T(0); }
+  static constexpr Unit_T PlusInfinity() { return Unit_T(PlusInfinityVal()); }
+  static constexpr Unit_T MinusInfinity() { return Unit_T(MinusInfinityVal()); }
+
+  constexpr bool IsZero() const { return value_ == 0; }
+  constexpr bool IsFinite() const { return !IsInfinite(); }
+  constexpr bool IsInfinite() const {
+    return value_ == PlusInfinityVal() || value_ == MinusInfinityVal();
+  }
+  constexpr bool IsPlusInfinity() const { return value_ == PlusInfinityVal(); }
+  constexpr bool IsMinusInfinity() const {
+    return value_ == MinusInfinityVal();
+  }
+
+  constexpr bool operator==(const Unit_T& other) const {
+    return value_ == other.value_;
+  }
+  constexpr bool operator!=(const Unit_T& other) const {
+    return value_ != other.value_;
+  }
+  constexpr bool operator<=(const Unit_T& other) const {
+    return value_ <= other.value_;
+  }
+  constexpr bool operator>=(const Unit_T& other) const {
+    return value_ >= other.value_;
+  }
+  constexpr bool operator>(const Unit_T& other) const {
+    return value_ > other.value_;
+  }
+  constexpr bool operator<(const Unit_T& other) const {
+    return value_ < other.value_;
+  }
+  constexpr Unit_T RoundTo(const Unit_T& resolution) const {
+    RTC_DCHECK(IsFinite());
+    RTC_DCHECK(resolution.IsFinite());
+    RTC_DCHECK_GT(resolution.value_, 0);
+    return Unit_T((value_ + resolution.value_ / 2) / resolution.value_) *
+           resolution.value_;
+  }
+  constexpr Unit_T RoundUpTo(const Unit_T& resolution) const {
+    RTC_DCHECK(IsFinite());
+    RTC_DCHECK(resolution.IsFinite());
+    RTC_DCHECK_GT(resolution.value_, 0);
+    return Unit_T((value_ + resolution.value_ - 1) / resolution.value_) *
+           resolution.value_;
+  }
+  constexpr Unit_T RoundDownTo(const Unit_T& resolution) const {
+    RTC_DCHECK(IsFinite());
+    RTC_DCHECK(resolution.IsFinite());
+    RTC_DCHECK_GT(resolution.value_, 0);
+    return Unit_T(value_ / resolution.value_) * resolution.value_;
+  }
+
+ protected:
+  template <
+      typename T,
+      typename std::enable_if<std::is_integral<T>::value>::type* = nullptr>
+  static constexpr Unit_T FromValue(T value) {
+    if (Unit_T::one_sided)
+      RTC_DCHECK_GE(value, 0);
+    RTC_DCHECK_GT(value, MinusInfinityVal());
+    RTC_DCHECK_LT(value, PlusInfinityVal());
+    return Unit_T(rtc::dchecked_cast<int64_t>(value));
+  }
+  template <typename T,
+            typename std::enable_if<std::is_floating_point<T>::value>::type* =
+                nullptr>
+  static constexpr Unit_T FromValue(T value) {
+    if (value == std::numeric_limits<T>::infinity()) {
+      return PlusInfinity();
+    } else if (value == -std::numeric_limits<T>::infinity()) {
+      return MinusInfinity();
+    } else {
+      RTC_DCHECK(!std::isnan(value));
+      return FromValue(rtc::dchecked_cast<int64_t>(value));
+    }
+  }
+
+  template <
+      typename T,
+      typename std::enable_if<std::is_integral<T>::value>::type* = nullptr>
+  static constexpr Unit_T FromFraction(int64_t denominator, T value) {
+    if (Unit_T::one_sided)
+      RTC_DCHECK_GE(value, 0);
+    RTC_DCHECK_GT(value, MinusInfinityVal() / denominator);
+    RTC_DCHECK_LT(value, PlusInfinityVal() / denominator);
+    return Unit_T(rtc::dchecked_cast<int64_t>(value * denominator));
+  }
+  template <typename T,
+            typename std::enable_if<std::is_floating_point<T>::value>::type* =
+                nullptr>
+  static constexpr Unit_T FromFraction(int64_t denominator, T value) {
+    return FromValue(value * denominator);
+  }
+
+  template <typename T = int64_t>
+  constexpr typename std::enable_if<std::is_integral<T>::value, T>::type
+  ToValue() const {
+    RTC_DCHECK(IsFinite());
+    return rtc::dchecked_cast<T>(value_);
+  }
+  template <typename T>
+  constexpr typename std::enable_if<std::is_floating_point<T>::value, T>::type
+  ToValue() const {
+    return IsPlusInfinity()
+               ? std::numeric_limits<T>::infinity()
+               : IsMinusInfinity() ? -std::numeric_limits<T>::infinity()
+                                   : value_;
+  }
+  template <typename T>
+  constexpr T ToValueOr(T fallback_value) const {
+    return IsFinite() ? value_ : fallback_value;
+  }
+
+  template <int64_t Denominator, typename T = int64_t>
+  constexpr typename std::enable_if<std::is_integral<T>::value, T>::type
+  ToFraction() const {
+    RTC_DCHECK(IsFinite());
+    if (Unit_T::one_sided) {
+      return rtc::dchecked_cast<T>(
+          DivRoundPositiveToNearest(value_, Denominator));
+    } else {
+      return rtc::dchecked_cast<T>(DivRoundToNearest(value_, Denominator));
+    }
+  }
+  template <int64_t Denominator, typename T>
+  constexpr typename std::enable_if<std::is_floating_point<T>::value, T>::type
+  ToFraction() const {
+    return ToValue<T>() * (1 / static_cast<T>(Denominator));
+  }
+
+  template <int64_t Denominator>
+  constexpr int64_t ToFractionOr(int64_t fallback_value) const {
+    return IsFinite() ? Unit_T::one_sided
+                            ? DivRoundPositiveToNearest(value_, Denominator)
+                            : DivRoundToNearest(value_, Denominator)
+                      : fallback_value;
+  }
+
+  template <int64_t Factor, typename T = int64_t>
+  constexpr typename std::enable_if<std::is_integral<T>::value, T>::type
+  ToMultiple() const {
+    RTC_DCHECK_GE(ToValue(), std::numeric_limits<T>::min() / Factor);
+    RTC_DCHECK_LE(ToValue(), std::numeric_limits<T>::max() / Factor);
+    return rtc::dchecked_cast<T>(ToValue() * Factor);
+  }
+  template <int64_t Factor, typename T>
+  constexpr typename std::enable_if<std::is_floating_point<T>::value, T>::type
+  ToMultiple() const {
+    return ToValue<T>() * Factor;
+  }
+
+  explicit constexpr UnitBase(int64_t value) : value_(value) {}
+
+ private:
+  template <class RelativeUnit_T>
+  friend class RelativeUnit;
+
+  static inline constexpr int64_t PlusInfinityVal() {
+    return std::numeric_limits<int64_t>::max();
+  }
+  static inline constexpr int64_t MinusInfinityVal() {
+    return std::numeric_limits<int64_t>::min();
+  }
+
+  constexpr Unit_T& AsSubClassRef() { return static_cast<Unit_T&>(*this); }
+  constexpr const Unit_T& AsSubClassRef() const {
+    return static_cast<const Unit_T&>(*this);
+  }
+  // Assumes that n >= 0 and d > 0.
+  static constexpr int64_t DivRoundPositiveToNearest(int64_t n, int64_t d) {
+    return (n + d / 2) / d;
+  }
+  // Assumes that d > 0.
+  static constexpr int64_t DivRoundToNearest(int64_t n, int64_t d) {
+    return (n + (n >= 0 ? d / 2 : -d / 2)) / d;
+  }
+
+  int64_t value_;
+};
+
+// Extends UnitBase to provide operations for relative units, that is, units
+// that have a meaningful relation between values such that a += b is a
+// sensible thing to do. For a,b <- same unit.
+template <class Unit_T>
+class RelativeUnit : public UnitBase<Unit_T> {
+ public:
+  constexpr Unit_T Clamped(Unit_T min_value, Unit_T max_value) const {
+    return std::max(min_value,
+                    std::min(UnitBase<Unit_T>::AsSubClassRef(), max_value));
+  }
+  constexpr void Clamp(Unit_T min_value, Unit_T max_value) {
+    *this = Clamped(min_value, max_value);
+  }
+  constexpr Unit_T operator+(const Unit_T other) const {
+    if (this->IsPlusInfinity() || other.IsPlusInfinity()) {
+      RTC_DCHECK(!this->IsMinusInfinity());
+      RTC_DCHECK(!other.IsMinusInfinity());
+      return this->PlusInfinity();
+    } else if (this->IsMinusInfinity() || other.IsMinusInfinity()) {
+      RTC_DCHECK(!this->IsPlusInfinity());
+      RTC_DCHECK(!other.IsPlusInfinity());
+      return this->MinusInfinity();
+    }
+    return UnitBase<Unit_T>::FromValue(this->ToValue() + other.ToValue());
+  }
+  constexpr Unit_T operator-(const Unit_T other) const {
+    if (this->IsPlusInfinity() || other.IsMinusInfinity()) {
+      RTC_DCHECK(!this->IsMinusInfinity());
+      RTC_DCHECK(!other.IsPlusInfinity());
+      return this->PlusInfinity();
+    } else if (this->IsMinusInfinity() || other.IsPlusInfinity()) {
+      RTC_DCHECK(!this->IsPlusInfinity());
+      RTC_DCHECK(!other.IsMinusInfinity());
+      return this->MinusInfinity();
+    }
+    return UnitBase<Unit_T>::FromValue(this->ToValue() - other.ToValue());
+  }
+  constexpr Unit_T& operator+=(const Unit_T other) {
+    *this = *this + other;
+    return this->AsSubClassRef();
+  }
+  constexpr Unit_T& operator-=(const Unit_T other) {
+    *this = *this - other;
+    return this->AsSubClassRef();
+  }
+  constexpr double operator/(const Unit_T other) const {
+    return UnitBase<Unit_T>::template ToValue<double>() /
+           other.template ToValue<double>();
+  }
+  template <typename T>
+  constexpr typename std::enable_if<std::is_arithmetic<T>::value, Unit_T>::type
+  operator/(const T& scalar) const {
+    return UnitBase<Unit_T>::FromValue(
+        std::round(UnitBase<Unit_T>::template ToValue<int64_t>() / scalar));
+  }
+  constexpr Unit_T operator*(double scalar) const {
+    return UnitBase<Unit_T>::FromValue(std::round(this->ToValue() * scalar));
+  }
+  constexpr Unit_T operator*(int64_t scalar) const {
+    return UnitBase<Unit_T>::FromValue(this->ToValue() * scalar);
+  }
+  constexpr Unit_T operator*(int32_t scalar) const {
+    return UnitBase<Unit_T>::FromValue(this->ToValue() * scalar);
+  }
+
+ protected:
+  using UnitBase<Unit_T>::UnitBase;
+};
+
+template <class Unit_T>
+inline constexpr Unit_T operator*(double scalar, RelativeUnit<Unit_T> other) {
+  return other * scalar;
+}
+template <class Unit_T>
+inline constexpr Unit_T operator*(int64_t scalar, RelativeUnit<Unit_T> other) {
+  return other * scalar;
+}
+template <class Unit_T>
+inline constexpr Unit_T operator*(int32_t scalar, RelativeUnit<Unit_T> other) {
+  return other * scalar;
+}
+
+}  // namespace rtc_units_impl
+
+}  // namespace webrtc
+
+#endif  // RTC_BASE_UNITS_UNIT_BASE_H_
diff --git a/third_party/webrtc_aec3/src/system_wrappers/include/cpu_features_wrapper.h b/third_party/webrtc_aec3/src/system_wrappers/include/cpu_features_wrapper.h
new file mode 100644
index 0000000..612b4a5
--- /dev/null
+++ b/third_party/webrtc_aec3/src/system_wrappers/include/cpu_features_wrapper.h
@@ -0,0 +1,42 @@
+/*
+ *  Copyright (c) 2011 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef SYSTEM_WRAPPERS_INCLUDE_CPU_FEATURES_WRAPPER_H_
+#define SYSTEM_WRAPPERS_INCLUDE_CPU_FEATURES_WRAPPER_H_
+
+#include <stdint.h>
+
+namespace webrtc {
+
+// List of features in x86.
+typedef enum { kSSE2, kSSE3, kAVX2 } CPUFeature;
+
+// List of features in ARM.
+enum {
+  kCPUFeatureARMv7 = (1 << 0),
+  kCPUFeatureVFPv3 = (1 << 1),
+  kCPUFeatureNEON = (1 << 2),
+  kCPUFeatureLDREXSTREX = (1 << 3)
+};
+
+// Returns true if the CPU supports the feature.
+int GetCPUInfo(CPUFeature feature);
+
+// No CPU feature is available => straight C path.
+int GetCPUInfoNoASM(CPUFeature feature);
+
+// Return the features in an ARM device.
+// It detects the features in the hardware platform, and returns supported
+// values in the above enum definition as a bitmask.
+uint64_t GetCPUFeaturesARM(void);
+
+}  // namespace webrtc
+
+#endif  // SYSTEM_WRAPPERS_INCLUDE_CPU_FEATURES_WRAPPER_H_
diff --git a/third_party/webrtc_aec3/src/system_wrappers/include/field_trial.h b/third_party/webrtc_aec3/src/system_wrappers/include/field_trial.h
new file mode 100644
index 0000000..52db33b
--- /dev/null
+++ b/third_party/webrtc_aec3/src/system_wrappers/include/field_trial.h
@@ -0,0 +1,102 @@
+//
+// Copyright (c) 2014 The WebRTC project authors. All Rights Reserved.
+//
+// Use of this source code is governed by a BSD-style license
+// that can be found in the LICENSE file in the root of the source
+// tree. An additional intellectual property rights grant can be found
+// in the file PATENTS.  All contributing project authors may
+// be found in the AUTHORS file in the root of the source tree.
+//
+
+#ifndef SYSTEM_WRAPPERS_INCLUDE_FIELD_TRIAL_H_
+#define SYSTEM_WRAPPERS_INCLUDE_FIELD_TRIAL_H_
+
+#include <string>
+
+// Field trials allow webrtc clients (such as Chrome) to turn on feature code
+// in binaries out in the field and gather information with that.
+//
+// By default WebRTC provides an implementation of field trials that can be
+// found in system_wrappers/source/field_trial.cc. If clients want to provide
+// a custom version, they will have to:
+//
+// 1. Compile WebRTC defining the preprocessor macro
+//    WEBRTC_EXCLUDE_FIELD_TRIAL_DEFAULT (if GN is used this can be achieved
+//    by setting the GN arg rtc_exclude_field_trial_default to true).
+// 2. Provide an implementation of:
+//    std::string webrtc::field_trial::FindFullName(const std::string& trial).
+//
+// They are designed to wire up directly to chrome field trials and to speed up
+// developers by reducing the need to wire APIs to control whether a feature is
+// on/off. E.g. to experiment with a new method that could lead to a different
+// trade-off between CPU/bandwidth:
+//
+// 1 - Develop the feature with default behaviour off:
+//
+//   if (FieldTrial::FindFullName("WebRTCExperimentMethod2") == "Enabled")
+//     method2();
+//   else
+//     method1();
+//
+// 2 - Once the changes are rolled to chrome, the new code path can be
+//     controlled as normal chrome field trials.
+//
+// 3 - Evaluate the new feature and clean the code paths.
+//
+// Notes:
+//   - NOT every feature is a candidate to be controlled by this mechanism as
+//     it may require negotiation between involved parties (e.g. SDP).
+//
+// TODO(andresp): since chrome --force-fieldtrials does not marks the trial
+//     as active it does not get propagated to the renderer process. For now one
+//     needs to push a config with start_active:true or run a local finch
+//     server.
+//
+// TODO(andresp): find out how to get bots to run tests with trials enabled.
+
+namespace webrtc {
+namespace field_trial {
+
+// Returns the group name chosen for the named trial, or the empty string
+// if the trial does not exists.
+//
+// Note: To keep things tidy append all the trial names with WebRTC.
+std::string FindFullName(const std::string& name);
+
+// Convenience method, returns true iff FindFullName(name) return a string that
+// starts with "Enabled".
+// TODO(tommi): Make sure all implementations support this.
+inline bool IsEnabled(const char* name) {
+  return FindFullName(name).find("Enabled") == 0;
+}
+
+// Convenience method, returns true iff FindFullName(name) return a string that
+// starts with "Disabled".
+inline bool IsDisabled(const char* name) {
+  return FindFullName(name).find("Disabled") == 0;
+}
+
+// Optionally initialize field trial from a string.
+// This method can be called at most once before any other call into webrtc.
+// E.g. before the peer connection factory is constructed.
+// Note: trials_string must never be destroyed.
+void InitFieldTrialsFromString(const char* trials_string);
+
+const char* GetFieldTrialString();
+
+#ifndef WEBRTC_EXCLUDE_FIELD_TRIAL_DEFAULT
+// Validates the given field trial string.
+bool FieldTrialsStringIsValid(const char* trials_string);
+
+// Merges two field trial strings.
+//
+// If a key (trial) exists twice with conflicting values (groups), the value
+// in 'second' takes precedence.
+// Shall only be called with valid FieldTrial strings.
+std::string MergeFieldTrialsStrings(const char* first, const char* second);
+#endif  // WEBRTC_EXCLUDE_FIELD_TRIAL_DEFAULT
+
+}  // namespace field_trial
+}  // namespace webrtc
+
+#endif  // SYSTEM_WRAPPERS_INCLUDE_FIELD_TRIAL_H_
diff --git a/third_party/webrtc_aec3/src/system_wrappers/include/metrics.h b/third_party/webrtc_aec3/src/system_wrappers/include/metrics.h
new file mode 100644
index 0000000..8e0f084
--- /dev/null
+++ b/third_party/webrtc_aec3/src/system_wrappers/include/metrics.h
@@ -0,0 +1,438 @@
+//
+// Copyright (c) 2014 The WebRTC project authors. All Rights Reserved.
+//
+// Use of this source code is governed by a BSD-style license
+// that can be found in the LICENSE file in the root of the source
+// tree. An additional intellectual property rights grant can be found
+// in the file PATENTS.  All contributing project authors may
+// be found in the AUTHORS file in the root of the source tree.
+//
+
+#ifndef SYSTEM_WRAPPERS_INCLUDE_METRICS_H_
+#define SYSTEM_WRAPPERS_INCLUDE_METRICS_H_
+
+#include <stddef.h>
+
+#include <map>
+#include <memory>
+#include <string>
+
+#include "rtc_base/atomic_ops.h"
+#include "rtc_base/checks.h"
+
+#if defined(RTC_DISABLE_METRICS)
+#define RTC_METRICS_ENABLED 0
+#else
+#define RTC_METRICS_ENABLED 1
+#endif
+
+namespace webrtc {
+namespace metrics_impl {
+template <typename... Ts>
+void NoOp(const Ts&...) {}
+}
+}
+
+#if RTC_METRICS_ENABLED
+#define EXPECT_METRIC_EQ(val1, val2) EXPECT_EQ(val1, val2)
+#define EXPECT_METRIC_EQ_WAIT(val1, val2, timeout) \
+  EXPECT_EQ_WAIT(val1, val2, timeout)
+#define EXPECT_METRIC_GT(val1, val2) EXPECT_GT(val1, val2)
+#define EXPECT_METRIC_LE(val1, val2) EXPECT_LE(val1, val2)
+#define EXPECT_METRIC_TRUE(conditon) EXPECT_TRUE(conditon)
+#define EXPECT_METRIC_FALSE(conditon) EXPECT_FALSE(conditon)
+#define EXPECT_METRIC_THAT(value, matcher) EXPECT_THAT(value, matcher)
+#else
+#define EXPECT_METRIC_EQ(val1, val2) webrtc::metrics_impl::NoOp(val1, val2)
+#define EXPECT_METRIC_EQ_WAIT(val1, val2, timeout) webrtc::metrics_impl::NoOp(val1, val2, timeout)
+#define EXPECT_METRIC_GT(val1, val2) webrtc::metrics_impl::NoOp(val1, val2)
+#define EXPECT_METRIC_LE(val1, val2) webrtc::metrics_impl::NoOp(val1, val2)
+#define EXPECT_METRIC_TRUE(condition) webrtc::metrics_impl::NoOp(condition || true)
+#define EXPECT_METRIC_FALSE(condition) webrtc::metrics_impl::NoOp(condition && false)
+#define EXPECT_METRIC_THAT(value, matcher) webrtc::metrics_impl::NoOp(value, testing::_)
+#endif
+
+#if RTC_METRICS_ENABLED
+// Macros for allowing WebRTC clients (e.g. Chrome) to gather and aggregate
+// statistics.
+//
+// Histogram for counters.
+// RTC_HISTOGRAM_COUNTS(name, sample, min, max, bucket_count);
+//
+// Histogram for enumerators.
+// The boundary should be above the max enumerator sample.
+// RTC_HISTOGRAM_ENUMERATION(name, sample, boundary);
+//
+//
+// The macros use the methods HistogramFactoryGetCounts,
+// HistogramFactoryGetEnumeration and HistogramAdd.
+//
+// By default WebRTC provides implementations of the aforementioned methods
+// that can be found in system_wrappers/source/metrics.cc. If clients want to
+// provide a custom version, they will have to:
+//
+// 1. Compile WebRTC defining the preprocessor macro
+//    WEBRTC_EXCLUDE_METRICS_DEFAULT (if GN is used this can be achieved
+//    by setting the GN arg rtc_exclude_metrics_default to true).
+// 2. Provide implementations of:
+//    Histogram* webrtc::metrics::HistogramFactoryGetCounts(
+//        const std::string& name, int sample, int min, int max,
+//        int bucket_count);
+//    Histogram* webrtc::metrics::HistogramFactoryGetEnumeration(
+//        const std::string& name, int sample, int boundary);
+//    void webrtc::metrics::HistogramAdd(
+//        Histogram* histogram_pointer, const std::string& name, int sample);
+//
+// Example usage:
+//
+// RTC_HISTOGRAM_COUNTS("WebRTC.Video.NacksSent", nacks_sent, 1, 100000, 100);
+//
+// enum Types {
+//   kTypeX,
+//   kTypeY,
+//   kBoundary,
+// };
+//
+// RTC_HISTOGRAM_ENUMERATION("WebRTC.Types", kTypeX, kBoundary);
+//
+// NOTE: It is recommended to do the Chromium review for modifications to
+// histograms.xml before new metrics are committed to WebRTC.
+
+// Macros for adding samples to a named histogram.
+
+// Histogram for counters (exponentially spaced buckets).
+#define RTC_HISTOGRAM_COUNTS_100(name, sample) \
+  RTC_HISTOGRAM_COUNTS(name, sample, 1, 100, 50)
+
+#define RTC_HISTOGRAM_COUNTS_200(name, sample) \
+  RTC_HISTOGRAM_COUNTS(name, sample, 1, 200, 50)
+
+#define RTC_HISTOGRAM_COUNTS_500(name, sample) \
+  RTC_HISTOGRAM_COUNTS(name, sample, 1, 500, 50)
+
+#define RTC_HISTOGRAM_COUNTS_1000(name, sample) \
+  RTC_HISTOGRAM_COUNTS(name, sample, 1, 1000, 50)
+
+#define RTC_HISTOGRAM_COUNTS_10000(name, sample) \
+  RTC_HISTOGRAM_COUNTS(name, sample, 1, 10000, 50)
+
+#define RTC_HISTOGRAM_COUNTS_100000(name, sample) \
+  RTC_HISTOGRAM_COUNTS(name, sample, 1, 100000, 50)
+
+#define RTC_HISTOGRAM_COUNTS(name, sample, min, max, bucket_count)       \
+  RTC_HISTOGRAM_COMMON_BLOCK(name, sample,                               \
+                             webrtc::metrics::HistogramFactoryGetCounts( \
+                                 name, min, max, bucket_count))
+
+#define RTC_HISTOGRAM_COUNTS_LINEAR(name, sample, min, max, bucket_count)      \
+  RTC_HISTOGRAM_COMMON_BLOCK(name, sample,                                     \
+                             webrtc::metrics::HistogramFactoryGetCountsLinear( \
+                                 name, min, max, bucket_count))
+
+// Slow metrics: pointer to metric is acquired at each call and is not cached.
+//
+#define RTC_HISTOGRAM_COUNTS_SPARSE_100(name, sample) \
+  RTC_HISTOGRAM_COUNTS_SPARSE(name, sample, 1, 100, 50)
+
+#define RTC_HISTOGRAM_COUNTS_SPARSE_200(name, sample) \
+  RTC_HISTOGRAM_COUNTS_SPARSE(name, sample, 1, 200, 50)
+
+#define RTC_HISTOGRAM_COUNTS_SPARSE_500(name, sample) \
+  RTC_HISTOGRAM_COUNTS_SPARSE(name, sample, 1, 500, 50)
+
+#define RTC_HISTOGRAM_COUNTS_SPARSE_1000(name, sample) \
+  RTC_HISTOGRAM_COUNTS_SPARSE(name, sample, 1, 1000, 50)
+
+#define RTC_HISTOGRAM_COUNTS_SPARSE_10000(name, sample) \
+  RTC_HISTOGRAM_COUNTS_SPARSE(name, sample, 1, 10000, 50)
+
+#define RTC_HISTOGRAM_COUNTS_SPARSE_100000(name, sample) \
+  RTC_HISTOGRAM_COUNTS_SPARSE(name, sample, 1, 100000, 50)
+
+#define RTC_HISTOGRAM_COUNTS_SPARSE(name, sample, min, max, bucket_count)     \
+  RTC_HISTOGRAM_COMMON_BLOCK_SLOW(name, sample,                               \
+                                  webrtc::metrics::HistogramFactoryGetCounts( \
+                                      name, min, max, bucket_count))
+
+// Histogram for percentage (evenly spaced buckets).
+#define RTC_HISTOGRAM_PERCENTAGE_SPARSE(name, sample) \
+  RTC_HISTOGRAM_ENUMERATION_SPARSE(name, sample, 101)
+
+// Histogram for booleans.
+#define RTC_HISTOGRAM_BOOLEAN_SPARSE(name, sample) \
+  RTC_HISTOGRAM_ENUMERATION_SPARSE(name, sample, 2)
+
+// Histogram for enumerators (evenly spaced buckets).
+// |boundary| should be above the max enumerator sample.
+//
+// TODO(qingsi): Refactor the default implementation given by RtcHistogram,
+// which is already sparse, and remove the boundary argument from the macro.
+#define RTC_HISTOGRAM_ENUMERATION_SPARSE(name, sample, boundary) \
+  RTC_HISTOGRAM_COMMON_BLOCK_SLOW(                               \
+      name, sample,                                              \
+      webrtc::metrics::SparseHistogramFactoryGetEnumeration(name, boundary))
+
+// Histogram for percentage (evenly spaced buckets).
+#define RTC_HISTOGRAM_PERCENTAGE(name, sample) \
+  RTC_HISTOGRAM_ENUMERATION(name, sample, 101)
+
+// Histogram for booleans.
+#define RTC_HISTOGRAM_BOOLEAN(name, sample) \
+  RTC_HISTOGRAM_ENUMERATION(name, sample, 2)
+
+// Histogram for enumerators (evenly spaced buckets).
+// |boundary| should be above the max enumerator sample.
+#define RTC_HISTOGRAM_ENUMERATION(name, sample, boundary) \
+  RTC_HISTOGRAM_COMMON_BLOCK_SLOW(                        \
+      name, sample,                                       \
+      webrtc::metrics::HistogramFactoryGetEnumeration(name, boundary))
+
+// The name of the histogram should not vary.
+// TODO(asapersson): Consider changing string to const char*.
+#define RTC_HISTOGRAM_COMMON_BLOCK(constant_name, sample,                  \
+                                   factory_get_invocation)                 \
+  do {                                                                     \
+    static webrtc::metrics::Histogram* atomic_histogram_pointer = nullptr; \
+    webrtc::metrics::Histogram* histogram_pointer =                        \
+        rtc::AtomicOps::AcquireLoadPtr(&atomic_histogram_pointer);         \
+    if (!histogram_pointer) {                                              \
+      histogram_pointer = factory_get_invocation;                          \
+      webrtc::metrics::Histogram* prev_pointer =                           \
+          rtc::AtomicOps::CompareAndSwapPtr(                               \
+              &atomic_histogram_pointer,                                   \
+              static_cast<webrtc::metrics::Histogram*>(nullptr),           \
+              histogram_pointer);                                          \
+      RTC_DCHECK(prev_pointer == nullptr ||                                \
+                 prev_pointer == histogram_pointer);                       \
+    }                                                                      \
+    if (histogram_pointer) {                                               \
+      webrtc::metrics::HistogramAdd(histogram_pointer, sample);            \
+    }                                                                      \
+  } while (0)
+
+// The histogram is constructed/found for each call.
+// May be used for histograms with infrequent updates.`
+#define RTC_HISTOGRAM_COMMON_BLOCK_SLOW(name, sample, factory_get_invocation) \
+  do {                                                                        \
+    webrtc::metrics::Histogram* histogram_pointer = factory_get_invocation;   \
+    if (histogram_pointer) {                                                  \
+      webrtc::metrics::HistogramAdd(histogram_pointer, sample);               \
+    }                                                                         \
+  } while (0)
+
+// Helper macros.
+// Macros for calling a histogram with varying name (e.g. when using a metric
+// in different modes such as real-time vs screenshare). Fast, because pointer
+// is cached. |index| should be different for different names. Allowed |index|
+// values are 0, 1, and 2.
+#define RTC_HISTOGRAMS_COUNTS_100(index, name, sample) \
+  RTC_HISTOGRAMS_COMMON(index, name, sample,           \
+                        RTC_HISTOGRAM_COUNTS(name, sample, 1, 100, 50))
+
+#define RTC_HISTOGRAMS_COUNTS_200(index, name, sample) \
+  RTC_HISTOGRAMS_COMMON(index, name, sample,           \
+                        RTC_HISTOGRAM_COUNTS(name, sample, 1, 200, 50))
+
+#define RTC_HISTOGRAMS_COUNTS_500(index, name, sample) \
+  RTC_HISTOGRAMS_COMMON(index, name, sample,           \
+                        RTC_HISTOGRAM_COUNTS(name, sample, 1, 500, 50))
+
+#define RTC_HISTOGRAMS_COUNTS_1000(index, name, sample) \
+  RTC_HISTOGRAMS_COMMON(index, name, sample,            \
+                        RTC_HISTOGRAM_COUNTS(name, sample, 1, 1000, 50))
+
+#define RTC_HISTOGRAMS_COUNTS_10000(index, name, sample) \
+  RTC_HISTOGRAMS_COMMON(index, name, sample,             \
+                        RTC_HISTOGRAM_COUNTS(name, sample, 1, 10000, 50))
+
+#define RTC_HISTOGRAMS_COUNTS_100000(index, name, sample) \
+  RTC_HISTOGRAMS_COMMON(index, name, sample,              \
+                        RTC_HISTOGRAM_COUNTS(name, sample, 1, 100000, 50))
+
+#define RTC_HISTOGRAMS_ENUMERATION(index, name, sample, boundary) \
+  RTC_HISTOGRAMS_COMMON(index, name, sample,                      \
+                        RTC_HISTOGRAM_ENUMERATION(name, sample, boundary))
+
+#define RTC_HISTOGRAMS_PERCENTAGE(index, name, sample) \
+  RTC_HISTOGRAMS_COMMON(index, name, sample,           \
+                        RTC_HISTOGRAM_PERCENTAGE(name, sample))
+
+#define RTC_HISTOGRAMS_COMMON(index, name, sample, macro_invocation) \
+  do {                                                               \
+    switch (index) {                                                 \
+      case 0:                                                        \
+        macro_invocation;                                            \
+        break;                                                       \
+      case 1:                                                        \
+        macro_invocation;                                            \
+        break;                                                       \
+      case 2:                                                        \
+        macro_invocation;                                            \
+        break;                                                       \
+      default:                                                       \
+        RTC_NOTREACHED();                                            \
+    }                                                                \
+  } while (0)
+
+#else
+
+////////////////////////////////////////////////////////////////////////////////
+// This section defines no-op alternatives to the metrics macros when
+// RTC_METRICS_ENABLED is defined.
+
+#define RTC_HISTOGRAM_COUNTS_100(name, sample) webrtc::metrics_impl::NoOp(name, sample)
+
+#define RTC_HISTOGRAM_COUNTS_200(name, sample) webrtc::metrics_impl::NoOp(name, sample)
+
+#define RTC_HISTOGRAM_COUNTS_500(name, sample) webrtc::metrics_impl::NoOp(name, sample)
+
+#define RTC_HISTOGRAM_COUNTS_1000(name, sample) webrtc::metrics_impl::NoOp(name, sample)
+
+#define RTC_HISTOGRAM_COUNTS_10000(name, sample) webrtc::metrics_impl::NoOp(name, sample)
+
+#define RTC_HISTOGRAM_COUNTS_100000(name, sample) webrtc::metrics_impl::NoOp(name, sample)
+
+#define RTC_HISTOGRAM_COUNTS(name, sample, min, max, bucket_count) \
+  webrtc::metrics_impl::NoOp(name, sample, min, max, bucket_count)
+
+#define RTC_HISTOGRAM_COUNTS_LINEAR(name, sample, min, max, bucket_count) \
+  webrtc::metrics_impl::NoOp(name, sample, min, max, bucket_count)
+
+#define RTC_HISTOGRAM_COUNTS_SPARSE_100(name, sample) webrtc::metrics_impl::NoOp(name, sample)
+
+#define RTC_HISTOGRAM_COUNTS_SPARSE_200(name, sample) webrtc::metrics_impl::NoOp(name, sample)
+
+#define RTC_HISTOGRAM_COUNTS_SPARSE_500(name, sample) webrtc::metrics_impl::NoOp(name, sample)
+
+#define RTC_HISTOGRAM_COUNTS_SPARSE_1000(name, sample) webrtc::metrics_impl::NoOp(name, sample)
+
+#define RTC_HISTOGRAM_COUNTS_SPARSE_10000(name, sample) webrtc::metrics_impl::NoOp(name, sample)
+
+#define RTC_HISTOGRAM_COUNTS_SPARSE_100000(name, sample) webrtc::metrics_impl::NoOp(name, sample)
+
+#define RTC_HISTOGRAM_COUNTS_SPARSE(name, sample, min, max, bucket_count) \
+  webrtc::metrics_impl::NoOp(name, sample, min, max, bucket_count)
+
+#define RTC_HISTOGRAM_PERCENTAGE_SPARSE(name, sample) webrtc::metrics_impl::NoOp(name, sample)
+
+#define RTC_HISTOGRAM_BOOLEAN_SPARSE(name, sample) webrtc::metrics_impl::NoOp(name, sample)
+
+#define RTC_HISTOGRAM_ENUMERATION_SPARSE(name, sample, boundary) \
+  webrtc::metrics_impl::NoOp(name, sample, boundary)
+
+#define RTC_HISTOGRAM_PERCENTAGE(name, sample) webrtc::metrics_impl::NoOp(name, sample)
+
+#define RTC_HISTOGRAM_BOOLEAN(name, sample) webrtc::metrics_impl::NoOp(name, sample)
+
+#define RTC_HISTOGRAM_ENUMERATION(name, sample, boundary) \
+  webrtc::metrics_impl::NoOp(name, sample, boundary)
+
+#define RTC_HISTOGRAM_COMMON_BLOCK(constant_name, sample,  \
+                                   factory_get_invocation) \
+  webrtc::metrics_impl::NoOp(constant_name, sample, factory_get_invocation)
+
+#define RTC_HISTOGRAM_COMMON_BLOCK_SLOW(name, sample, factory_get_invocation) \
+  webrtc::metrics_impl::NoOp(name, sample, factory_get_invocation)
+
+#define RTC_HISTOGRAMS_COUNTS_100(index, name, sample) webrtc::metrics_impl::NoOp(index, name, sample)
+
+#define RTC_HISTOGRAMS_COUNTS_200(index, name, sample) webrtc::metrics_impl::NoOp(index, name, sample)
+
+#define RTC_HISTOGRAMS_COUNTS_500(index, name, sample) webrtc::metrics_impl::NoOp(index, name, sample)
+
+#define RTC_HISTOGRAMS_COUNTS_1000(index, name, sample) \
+  webrtc::metrics_impl::NoOp(index, name, sample)
+
+#define RTC_HISTOGRAMS_COUNTS_10000(index, name, sample) \
+  webrtc::metrics_impl::NoOp(index, name, sample)
+
+#define RTC_HISTOGRAMS_COUNTS_100000(index, name, sample) \
+  webrtc::metrics_impl::NoOp(index, name, sample)
+
+#define RTC_HISTOGRAMS_ENUMERATION(index, name, sample, boundary) \
+  webrtc::metrics_impl::NoOp(index, name, sample, boundary)
+
+#define RTC_HISTOGRAMS_PERCENTAGE(index, name, sample) webrtc::metrics_impl::NoOp(index, name, sample)
+
+#define RTC_HISTOGRAMS_COMMON(index, name, sample, macro_invocation) \
+  webrtc::metrics_impl::NoOp(index, name, sample, macro_invocation)
+
+#endif  // RTC_METRICS_ENABLED
+
+namespace webrtc {
+namespace metrics {
+
+// Time that should have elapsed for stats that are gathered once per call.
+enum { kMinRunTimeInSeconds = 10 };
+
+class Histogram;
+
+// Functions for getting pointer to histogram (constructs or finds the named
+// histogram).
+
+// Get histogram for counters.
+Histogram* HistogramFactoryGetCounts(const std::string& name,
+                                     int min,
+                                     int max,
+                                     int bucket_count);
+
+// Get histogram for counters with linear bucket spacing.
+Histogram* HistogramFactoryGetCountsLinear(const std::string& name,
+                                           int min,
+                                           int max,
+                                           int bucket_count);
+
+// Get histogram for enumerators.
+// |boundary| should be above the max enumerator sample.
+Histogram* HistogramFactoryGetEnumeration(const std::string& name,
+                                          int boundary);
+
+// Get sparse histogram for enumerators.
+// |boundary| should be above the max enumerator sample.
+Histogram* SparseHistogramFactoryGetEnumeration(const std::string& name,
+                                                int boundary);
+
+// Function for adding a |sample| to a histogram.
+void HistogramAdd(Histogram* histogram_pointer, int sample);
+
+struct SampleInfo {
+  SampleInfo(const std::string& name, int min, int max, size_t bucket_count);
+  ~SampleInfo();
+
+  const std::string name;
+  const int min;
+  const int max;
+  const size_t bucket_count;
+  std::map<int, int> samples;  // <value, # of events>
+};
+
+// Enables collection of samples.
+// This method should be called before any other call into webrtc.
+void Enable();
+
+// Gets histograms and clears all samples.
+void GetAndReset(
+    std::map<std::string, std::unique_ptr<SampleInfo>>* histograms);
+
+// Functions below are mainly for testing.
+
+// Clears all samples.
+void Reset();
+
+// Returns the number of times the |sample| has been added to the histogram.
+int NumEvents(const std::string& name, int sample);
+
+// Returns the total number of added samples to the histogram.
+int NumSamples(const std::string& name);
+
+// Returns the minimum sample value (or -1 if the histogram has no samples).
+int MinSample(const std::string& name);
+
+// Returns a map with keys the samples with at least one event and values the
+// number of events for that sample.
+std::map<int, int> Samples(const std::string& name);
+
+}  // namespace metrics
+}  // namespace webrtc
+
+#endif  // SYSTEM_WRAPPERS_INCLUDE_METRICS_H_
diff --git a/third_party/webrtc_aec3/src/system_wrappers/source/cpu_features.cc b/third_party/webrtc_aec3/src/system_wrappers/source/cpu_features.cc
new file mode 100644
index 0000000..0f81212
--- /dev/null
+++ b/third_party/webrtc_aec3/src/system_wrappers/source/cpu_features.cc
@@ -0,0 +1,115 @@
+/*
+ *  Copyright (c) 2011 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// Parts of this file derived from Chromium's base/cpu.cc.
+
+#include "rtc_base/system/arch.h"
+#include "system_wrappers/include/cpu_features_wrapper.h"
+#include "system_wrappers/include/field_trial.h"
+
+#if defined(WEBRTC_ARCH_X86_FAMILY) && defined(_MSC_VER)
+#include <intrin.h>
+#endif
+
+namespace webrtc {
+
+// No CPU feature is available => straight C path.
+int GetCPUInfoNoASM(CPUFeature feature) {
+  (void)feature;
+  return 0;
+}
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+
+#if defined(WEBRTC_ENABLE_AVX2)
+// xgetbv returns the value of an Intel Extended Control Register (XCR).
+// Currently only XCR0 is defined by Intel so |xcr| should always be zero.
+static uint64_t xgetbv(uint32_t xcr) {
+#if defined(_MSC_VER)
+  return _xgetbv(xcr);
+#else
+  uint32_t eax, edx;
+
+  __asm__ volatile("xgetbv" : "=a"(eax), "=d"(edx) : "c"(xcr));
+  return (static_cast<uint64_t>(edx) << 32) | eax;
+#endif  // _MSC_VER
+}
+#endif  // WEBRTC_ENABLE_AVX2
+
+#ifndef _MSC_VER
+// Intrinsic for "cpuid".
+#if defined(__pic__) && defined(__i386__)
+static inline void __cpuid(int cpu_info[4], int info_type) {
+  __asm__ volatile(
+      "mov %%ebx, %%edi\n"
+      "cpuid\n"
+      "xchg %%edi, %%ebx\n"
+      : "=a"(cpu_info[0]), "=D"(cpu_info[1]), "=c"(cpu_info[2]),
+        "=d"(cpu_info[3])
+      : "a"(info_type));
+}
+#else
+static inline void __cpuid(int cpu_info[4], int info_type) {
+  __asm__ volatile("cpuid\n"
+                   : "=a"(cpu_info[0]), "=b"(cpu_info[1]), "=c"(cpu_info[2]),
+                     "=d"(cpu_info[3])
+                   : "a"(info_type), "c"(0));
+}
+#endif
+#endif  // _MSC_VER
+#endif  // WEBRTC_ARCH_X86_FAMILY
+
+#if defined(WEBRTC_ARCH_X86_FAMILY)
+// Actual feature detection for x86.
+int GetCPUInfo(CPUFeature feature) {
+  int cpu_info[4];
+  __cpuid(cpu_info, 1);
+  if (feature == kSSE2) {
+    return 0 != (cpu_info[3] & 0x04000000);
+  }
+  if (feature == kSSE3) {
+    return 0 != (cpu_info[2] & 0x00000001);
+  }
+#if defined(WEBRTC_ENABLE_AVX2)
+  if (feature == kAVX2 &&
+      !webrtc::field_trial::IsEnabled("WebRTC-Avx2SupportKillSwitch")) {
+    int cpu_info7[4];
+    __cpuid(cpu_info7, 0);
+    int num_ids = cpu_info7[0];
+    if (num_ids < 7) {
+      return 0;
+    }
+    // Interpret CPU feature information.
+    __cpuid(cpu_info7, 7);
+
+    // AVX instructions can be used when
+    //     a) AVX are supported by the CPU,
+    //     b) XSAVE is supported by the CPU,
+    //     c) XSAVE is enabled by the kernel.
+    // See http://software.intel.com/en-us/blogs/2011/04/14/is-avx-enabled
+    // AVX2 support needs (avx_support && (cpu_info7[1] & 0x00000020) != 0;).
+    return (cpu_info[2] & 0x10000000) != 0 &&
+           (cpu_info[2] & 0x04000000) != 0 /* XSAVE */ &&
+           (cpu_info[2] & 0x08000000) != 0 /* OSXSAVE */ &&
+           (xgetbv(0) & 0x00000006) == 6 /* XSAVE enabled by kernel */ &&
+           (cpu_info7[1] & 0x00000020) != 0;
+  }
+#endif  // WEBRTC_ENABLE_AVX2
+  return 0;
+}
+#else
+// Default to straight C for other platforms.
+int GetCPUInfo(CPUFeature feature) {
+  (void)feature;
+  return 0;
+}
+#endif
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/system_wrappers/source/cpu_features_android.cc b/third_party/webrtc_aec3/src/system_wrappers/source/cpu_features_android.cc
new file mode 100644
index 0000000..95cc609
--- /dev/null
+++ b/third_party/webrtc_aec3/src/system_wrappers/source/cpu_features_android.cc
@@ -0,0 +1,19 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include <cpu-features.h>
+
+namespace webrtc {
+
+uint64_t GetCPUFeaturesARM(void) {
+  return android_getCpuFeatures();
+}
+
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/system_wrappers/source/cpu_features_linux.cc b/third_party/webrtc_aec3/src/system_wrappers/source/cpu_features_linux.cc
new file mode 100644
index 0000000..335bed4
--- /dev/null
+++ b/third_party/webrtc_aec3/src/system_wrappers/source/cpu_features_linux.cc
@@ -0,0 +1,96 @@
+/*
+ *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include <features.h>
+#include <stdlib.h>
+#include <string.h>
+
+#ifdef __GLIBC_PREREQ
+#define WEBRTC_GLIBC_PREREQ(a, b) __GLIBC_PREREQ(a, b)
+#else
+#define WEBRTC_GLIBC_PREREQ(a, b) 0
+#endif
+
+#if WEBRTC_GLIBC_PREREQ(2, 16)
+#include <sys/auxv.h>
+#else
+#include <errno.h>
+#include <fcntl.h>
+#include <link.h>
+#include <unistd.h>
+#endif
+
+#include "rtc_base/system/arch.h"
+#include "system_wrappers/include/cpu_features_wrapper.h"
+
+#if defined(WEBRTC_ARCH_ARM_FAMILY)
+#include <asm/hwcap.h>
+
+namespace webrtc {
+
+uint64_t GetCPUFeaturesARM(void) {
+  uint64_t result = 0;
+  int architecture = 0;
+  uint64_t hwcap = 0;
+  const char* platform = NULL;
+#if WEBRTC_GLIBC_PREREQ(2, 16)
+  hwcap = getauxval(AT_HWCAP);
+  platform = (const char*)getauxval(AT_PLATFORM);
+#else
+  ElfW(auxv_t) auxv;
+  int fd = open("/proc/self/auxv", O_RDONLY);
+  if (fd >= 0) {
+    while (hwcap == 0 || platform == NULL) {
+      if (read(fd, &auxv, sizeof(auxv)) < (ssize_t)sizeof(auxv)) {
+        if (errno == EINTR)
+          continue;
+        break;
+      }
+      switch (auxv.a_type) {
+        case AT_HWCAP:
+          hwcap = auxv.a_un.a_val;
+          break;
+        case AT_PLATFORM:
+          platform = (const char*)auxv.a_un.a_val;
+          break;
+      }
+    }
+    close(fd);
+  }
+#endif  // WEBRTC_GLIBC_PREREQ(2, 16)
+#if defined(__aarch64__)
+  architecture = 8;
+  if ((hwcap & HWCAP_FP) != 0)
+    result |= kCPUFeatureVFPv3;
+  if ((hwcap & HWCAP_ASIMD) != 0)
+    result |= kCPUFeatureNEON;
+#else
+  if (platform != NULL) {
+    /* expect a string in the form "v6l" or "v7l", etc.
+     */
+    if (platform[0] == 'v' && '0' <= platform[1] && platform[1] <= '9' &&
+        (platform[2] == 'l' || platform[2] == 'b')) {
+      architecture = platform[1] - '0';
+    }
+  }
+  if ((hwcap & HWCAP_VFPv3) != 0)
+    result |= kCPUFeatureVFPv3;
+  if ((hwcap & HWCAP_NEON) != 0)
+    result |= kCPUFeatureNEON;
+#endif
+  if (architecture >= 7)
+    result |= kCPUFeatureARMv7;
+  if (architecture >= 6)
+    result |= kCPUFeatureLDREXSTREX;
+  return result;
+}
+
+}  // namespace webrtc
+#endif  // WEBRTC_ARCH_ARM_FAMILY
diff --git a/third_party/webrtc_aec3/src/system_wrappers/source/field_trial.cc b/third_party/webrtc_aec3/src/system_wrappers/source/field_trial.cc
new file mode 100644
index 0000000..f1dccc9
--- /dev/null
+++ b/third_party/webrtc_aec3/src/system_wrappers/source/field_trial.cc
@@ -0,0 +1,155 @@
+// Copyright (c) 2014 The WebRTC project authors. All Rights Reserved.
+//
+// Use of this source code is governed by a BSD-style license
+// that can be found in the LICENSE file in the root of the source
+// tree. An additional intellectual property rights grant can be found
+// in the file PATENTS.  All contributing project authors may
+// be found in the AUTHORS file in the root of the source tree.
+//
+
+#include "system_wrappers/include/field_trial.h"
+
+#include <stddef.h>
+
+#include <map>
+#include <string>
+
+#include "absl/strings/string_view.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+#include "rtc_base/string_encode.h"
+
+// Simple field trial implementation, which allows client to
+// specify desired flags in InitFieldTrialsFromString.
+namespace webrtc {
+namespace field_trial {
+
+static const char* trials_init_string = NULL;
+
+#ifndef WEBRTC_EXCLUDE_FIELD_TRIAL_DEFAULT
+namespace {
+constexpr char kPersistentStringSeparator = '/';
+// Validates the given field trial string.
+//  E.g.:
+//    "WebRTC-experimentFoo/Enabled/WebRTC-experimentBar/Enabled100kbps/"
+//    Assigns the process to group "Enabled" on WebRTCExperimentFoo trial
+//    and to group "Enabled100kbps" on WebRTCExperimentBar.
+//
+//  E.g. invalid config:
+//    "WebRTC-experiment1/Enabled"  (note missing / separator at the end).
+bool FieldTrialsStringIsValidInternal(const absl::string_view trials) {
+  if (trials.empty())
+    return true;
+
+  size_t next_item = 0;
+  std::map<absl::string_view, absl::string_view> field_trials;
+  while (next_item < trials.length()) {
+    size_t name_end = trials.find(kPersistentStringSeparator, next_item);
+    if (name_end == trials.npos || next_item == name_end)
+      return false;
+    size_t group_name_end =
+        trials.find(kPersistentStringSeparator, name_end + 1);
+    if (group_name_end == trials.npos || name_end + 1 == group_name_end)
+      return false;
+    absl::string_view name = trials.substr(next_item, name_end - next_item);
+    absl::string_view group_name =
+        trials.substr(name_end + 1, group_name_end - name_end - 1);
+
+    next_item = group_name_end + 1;
+
+    // Fail if duplicate with different group name.
+    if (field_trials.find(name) != field_trials.end() &&
+        field_trials.find(name)->second != group_name) {
+      return false;
+    }
+
+    field_trials[name] = group_name;
+  }
+
+  return true;
+}
+}  // namespace
+
+bool FieldTrialsStringIsValid(const char* trials_string) {
+  return FieldTrialsStringIsValidInternal(trials_string);
+}
+
+void InsertOrReplaceFieldTrialStringsInMap(
+    std::map<std::string, std::string>* fieldtrial_map,
+    const absl::string_view trials_string) {
+  if (FieldTrialsStringIsValidInternal(trials_string)) {
+    std::vector<std::string> tokens;
+    rtc::split(std::string(trials_string), '/', &tokens);
+    // Skip last token which is empty due to trailing '/'.
+    for (size_t idx = 0; idx < tokens.size() - 1; idx += 2) {
+      (*fieldtrial_map)[tokens[idx]] = tokens[idx + 1];
+    }
+  } else {
+    RTC_DCHECK(false) << "Invalid field trials string:" << trials_string;
+  }
+}
+
+std::string MergeFieldTrialsStrings(const char* first, const char* second) {
+  std::map<std::string, std::string> fieldtrial_map;
+  InsertOrReplaceFieldTrialStringsInMap(&fieldtrial_map, first);
+  InsertOrReplaceFieldTrialStringsInMap(&fieldtrial_map, second);
+
+  // Merge into fieldtrial string.
+  std::string merged = "";
+  for (auto const& fieldtrial : fieldtrial_map) {
+    merged += fieldtrial.first + '/' + fieldtrial.second + '/';
+  }
+  return merged;
+}
+
+std::string FindFullName(const std::string& name) {
+  if (trials_init_string == NULL)
+    return std::string();
+
+  std::string trials_string(trials_init_string);
+  if (trials_string.empty())
+    return std::string();
+
+  size_t next_item = 0;
+  while (next_item < trials_string.length()) {
+    // Find next name/value pair in field trial configuration string.
+    size_t field_name_end =
+        trials_string.find(kPersistentStringSeparator, next_item);
+    if (field_name_end == trials_string.npos || field_name_end == next_item)
+      break;
+    size_t field_value_end =
+        trials_string.find(kPersistentStringSeparator, field_name_end + 1);
+    if (field_value_end == trials_string.npos ||
+        field_value_end == field_name_end + 1)
+      break;
+    std::string field_name(trials_string, next_item,
+                           field_name_end - next_item);
+    std::string field_value(trials_string, field_name_end + 1,
+                            field_value_end - field_name_end - 1);
+    next_item = field_value_end + 1;
+
+    if (name == field_name)
+      return field_value;
+  }
+  return std::string();
+}
+#endif  // WEBRTC_EXCLUDE_FIELD_TRIAL_DEFAULT
+
+// Optionally initialize field trial from a string.
+void InitFieldTrialsFromString(const char* trials_string) {
+  RTC_LOG(LS_INFO) << "Setting field trial string:" << trials_string;
+#ifndef WEBRTC_EXCLUDE_FIELD_TRIAL_DEFAULT
+  if (trials_string) {
+    RTC_DCHECK(FieldTrialsStringIsValidInternal(trials_string))
+        << "Invalid field trials string:" << trials_string;
+  };
+#endif  // WEBRTC_EXCLUDE_FIELD_TRIAL_DEFAULT
+  trials_init_string = trials_string;
+}
+
+const char* GetFieldTrialString() {
+  return trials_init_string;
+}
+
+}  // namespace field_trial
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/system_wrappers/source/metrics.cc b/third_party/webrtc_aec3/src/system_wrappers/source/metrics.cc
new file mode 100644
index 0000000..d428336
--- /dev/null
+++ b/third_party/webrtc_aec3/src/system_wrappers/source/metrics.cc
@@ -0,0 +1,328 @@
+// Copyright (c) 2014 The WebRTC project authors. All Rights Reserved.
+//
+// Use of this source code is governed by a BSD-style license
+// that can be found in the LICENSE file in the root of the source
+// tree. An additional intellectual property rights grant can be found
+// in the file PATENTS.  All contributing project authors may
+// be found in the AUTHORS file in the root of the source tree.
+//
+
+#include "system_wrappers/include/metrics.h"
+
+#include <algorithm>
+
+#include "rtc_base/constructor_magic.h"
+#include "rtc_base/synchronization/mutex.h"
+#include "rtc_base/thread_annotations.h"
+
+// Default implementation of histogram methods for WebRTC clients that do not
+// want to provide their own implementation.
+
+namespace webrtc {
+namespace metrics {
+class Histogram;
+
+namespace {
+// Limit for the maximum number of sample values that can be stored.
+// TODO(asapersson): Consider using bucket count (and set up
+// linearly/exponentially spaced buckets) if samples are logged more frequently.
+const int kMaxSampleMapSize = 300;
+
+class RtcHistogram {
+ public:
+  RtcHistogram(const std::string& name, int min, int max, int bucket_count)
+      : min_(min), max_(max), info_(name, min, max, bucket_count) {
+    RTC_DCHECK_GT(bucket_count, 0);
+  }
+
+  void Add(int sample) {
+    sample = std::min(sample, max_);
+    sample = std::max(sample, min_ - 1);  // Underflow bucket.
+
+    MutexLock lock(&mutex_);
+    if (info_.samples.size() == kMaxSampleMapSize &&
+        info_.samples.find(sample) == info_.samples.end()) {
+      return;
+    }
+    ++info_.samples[sample];
+  }
+
+  // Returns a copy (or nullptr if there are no samples) and clears samples.
+  std::unique_ptr<SampleInfo> GetAndReset() {
+    MutexLock lock(&mutex_);
+    if (info_.samples.empty())
+      return nullptr;
+
+    SampleInfo* copy =
+        new SampleInfo(info_.name, info_.min, info_.max, info_.bucket_count);
+
+    std::swap(info_.samples, copy->samples);
+
+    return std::unique_ptr<SampleInfo>(copy);
+  }
+
+  const std::string& name() const { return info_.name; }
+
+  // Functions only for testing.
+  void Reset() {
+    MutexLock lock(&mutex_);
+    info_.samples.clear();
+  }
+
+  int NumEvents(int sample) const {
+    MutexLock lock(&mutex_);
+    const auto it = info_.samples.find(sample);
+    return (it == info_.samples.end()) ? 0 : it->second;
+  }
+
+  int NumSamples() const {
+    int num_samples = 0;
+    MutexLock lock(&mutex_);
+    for (const auto& sample : info_.samples) {
+      num_samples += sample.second;
+    }
+    return num_samples;
+  }
+
+  int MinSample() const {
+    MutexLock lock(&mutex_);
+    return (info_.samples.empty()) ? -1 : info_.samples.begin()->first;
+  }
+
+  std::map<int, int> Samples() const {
+    MutexLock lock(&mutex_);
+    return info_.samples;
+  }
+
+ private:
+  mutable Mutex mutex_;
+  const int min_;
+  const int max_;
+  SampleInfo info_ RTC_GUARDED_BY(mutex_);
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(RtcHistogram);
+};
+
+class RtcHistogramMap {
+ public:
+  RtcHistogramMap() {}
+  ~RtcHistogramMap() {}
+
+  Histogram* GetCountsHistogram(const std::string& name,
+                                int min,
+                                int max,
+                                int bucket_count) {
+    MutexLock lock(&mutex_);
+    const auto& it = map_.find(name);
+    if (it != map_.end())
+      return reinterpret_cast<Histogram*>(it->second.get());
+
+    RtcHistogram* hist = new RtcHistogram(name, min, max, bucket_count);
+    map_[name].reset(hist);
+    return reinterpret_cast<Histogram*>(hist);
+  }
+
+  Histogram* GetEnumerationHistogram(const std::string& name, int boundary) {
+    MutexLock lock(&mutex_);
+    const auto& it = map_.find(name);
+    if (it != map_.end())
+      return reinterpret_cast<Histogram*>(it->second.get());
+
+    RtcHistogram* hist = new RtcHistogram(name, 1, boundary, boundary + 1);
+    map_[name].reset(hist);
+    return reinterpret_cast<Histogram*>(hist);
+  }
+
+  void GetAndReset(
+      std::map<std::string, std::unique_ptr<SampleInfo>>* histograms) {
+    MutexLock lock(&mutex_);
+    for (const auto& kv : map_) {
+      std::unique_ptr<SampleInfo> info = kv.second->GetAndReset();
+      if (info)
+        histograms->insert(std::make_pair(kv.first, std::move(info)));
+    }
+  }
+
+  // Functions only for testing.
+  void Reset() {
+    MutexLock lock(&mutex_);
+    for (const auto& kv : map_)
+      kv.second->Reset();
+  }
+
+  int NumEvents(const std::string& name, int sample) const {
+    MutexLock lock(&mutex_);
+    const auto& it = map_.find(name);
+    return (it == map_.end()) ? 0 : it->second->NumEvents(sample);
+  }
+
+  int NumSamples(const std::string& name) const {
+    MutexLock lock(&mutex_);
+    const auto& it = map_.find(name);
+    return (it == map_.end()) ? 0 : it->second->NumSamples();
+  }
+
+  int MinSample(const std::string& name) const {
+    MutexLock lock(&mutex_);
+    const auto& it = map_.find(name);
+    return (it == map_.end()) ? -1 : it->second->MinSample();
+  }
+
+  std::map<int, int> Samples(const std::string& name) const {
+    MutexLock lock(&mutex_);
+    const auto& it = map_.find(name);
+    return (it == map_.end()) ? std::map<int, int>() : it->second->Samples();
+  }
+
+ private:
+  mutable Mutex mutex_;
+  std::map<std::string, std::unique_ptr<RtcHistogram>> map_
+      RTC_GUARDED_BY(mutex_);
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(RtcHistogramMap);
+};
+
+// RtcHistogramMap is allocated upon call to Enable().
+// The histogram getter functions, which return pointer values to the histograms
+// in the map, are cached in WebRTC. Therefore, this memory is not freed by the
+// application (the memory will be reclaimed by the OS).
+static RtcHistogramMap* volatile g_rtc_histogram_map = nullptr;
+
+void CreateMap() {
+  RtcHistogramMap* map = rtc::AtomicOps::AcquireLoadPtr(&g_rtc_histogram_map);
+  if (map == nullptr) {
+    RtcHistogramMap* new_map = new RtcHistogramMap();
+    RtcHistogramMap* old_map = rtc::AtomicOps::CompareAndSwapPtr(
+        &g_rtc_histogram_map, static_cast<RtcHistogramMap*>(nullptr), new_map);
+    if (old_map != nullptr)
+      delete new_map;
+  }
+}
+
+// Set the first time we start using histograms. Used to make sure Enable() is
+// not called thereafter.
+#if RTC_DCHECK_IS_ON
+static volatile int g_rtc_histogram_called = 0;
+#endif
+
+// Gets the map (or nullptr).
+RtcHistogramMap* GetMap() {
+#if RTC_DCHECK_IS_ON
+  rtc::AtomicOps::ReleaseStore(&g_rtc_histogram_called, 1);
+#endif
+  return g_rtc_histogram_map;
+}
+}  // namespace
+
+#ifndef WEBRTC_EXCLUDE_METRICS_DEFAULT
+// Implementation of histogram methods in
+// webrtc/system_wrappers/interface/metrics.h.
+
+// Histogram with exponentially spaced buckets.
+// Creates (or finds) histogram.
+// The returned histogram pointer is cached (and used for adding samples in
+// subsequent calls).
+Histogram* HistogramFactoryGetCounts(const std::string& name,
+                                     int min,
+                                     int max,
+                                     int bucket_count) {
+  // TODO(asapersson): Alternative implementation will be needed if this
+  // histogram type should be truly exponential.
+  return HistogramFactoryGetCountsLinear(name, min, max, bucket_count);
+}
+
+// Histogram with linearly spaced buckets.
+// Creates (or finds) histogram.
+// The returned histogram pointer is cached (and used for adding samples in
+// subsequent calls).
+Histogram* HistogramFactoryGetCountsLinear(const std::string& name,
+                                           int min,
+                                           int max,
+                                           int bucket_count) {
+  RtcHistogramMap* map = GetMap();
+  if (!map)
+    return nullptr;
+
+  return map->GetCountsHistogram(name, min, max, bucket_count);
+}
+
+// Histogram with linearly spaced buckets.
+// Creates (or finds) histogram.
+// The returned histogram pointer is cached (and used for adding samples in
+// subsequent calls).
+Histogram* HistogramFactoryGetEnumeration(const std::string& name,
+                                          int boundary) {
+  RtcHistogramMap* map = GetMap();
+  if (!map)
+    return nullptr;
+
+  return map->GetEnumerationHistogram(name, boundary);
+}
+
+// Our default implementation reuses the non-sparse histogram.
+Histogram* SparseHistogramFactoryGetEnumeration(const std::string& name,
+                                                int boundary) {
+  return HistogramFactoryGetEnumeration(name, boundary);
+}
+
+// Fast path. Adds |sample| to cached |histogram_pointer|.
+void HistogramAdd(Histogram* histogram_pointer, int sample) {
+  RtcHistogram* ptr = reinterpret_cast<RtcHistogram*>(histogram_pointer);
+  ptr->Add(sample);
+}
+
+#endif  // WEBRTC_EXCLUDE_METRICS_DEFAULT
+
+SampleInfo::SampleInfo(const std::string& name,
+                       int min,
+                       int max,
+                       size_t bucket_count)
+    : name(name), min(min), max(max), bucket_count(bucket_count) {}
+
+SampleInfo::~SampleInfo() {}
+
+// Implementation of global functions in metrics.h.
+void Enable() {
+  RTC_DCHECK(g_rtc_histogram_map == nullptr);
+#if RTC_DCHECK_IS_ON
+  RTC_DCHECK_EQ(0, rtc::AtomicOps::AcquireLoad(&g_rtc_histogram_called));
+#endif
+  CreateMap();
+}
+
+void GetAndReset(
+    std::map<std::string, std::unique_ptr<SampleInfo>>* histograms) {
+  histograms->clear();
+  RtcHistogramMap* map = GetMap();
+  if (map)
+    map->GetAndReset(histograms);
+}
+
+void Reset() {
+  RtcHistogramMap* map = GetMap();
+  if (map)
+    map->Reset();
+}
+
+int NumEvents(const std::string& name, int sample) {
+  RtcHistogramMap* map = GetMap();
+  return map ? map->NumEvents(name, sample) : 0;
+}
+
+int NumSamples(const std::string& name) {
+  RtcHistogramMap* map = GetMap();
+  return map ? map->NumSamples(name) : 0;
+}
+
+int MinSample(const std::string& name) {
+  RtcHistogramMap* map = GetMap();
+  return map ? map->MinSample(name) : -1;
+}
+
+std::map<int, int> Samples(const std::string& name) {
+  RtcHistogramMap* map = GetMap();
+  return map ? map->Samples(name) : std::map<int, int>();
+}
+
+}  // namespace metrics
+}  // namespace webrtc
diff --git a/third_party/webrtc_aec3/src/third_party/pffft/README.txt b/third_party/webrtc_aec3/src/third_party/pffft/README.txt
new file mode 100644
index 0000000..ee20b42
--- /dev/null
+++ b/third_party/webrtc_aec3/src/third_party/pffft/README.txt
@@ -0,0 +1,416 @@
+PFFFT: a pretty fast FFT.
+
+TL;DR
+--
+
+PFFFT does 1D Fast Fourier Transforms, of single precision real and
+complex vectors. It tries do it fast, it tries to be correct, and it
+tries to be small. Computations do take advantage of SSE1 instructions
+on x86 cpus, Altivec on powerpc cpus, and NEON on ARM cpus. The
+license is BSD-like.
+
+
+Why does it exist:
+--
+
+I was in search of a good performing FFT library , preferably very
+small and with a very liberal license.
+
+When one says "fft library", FFTW ("Fastest Fourier Transform in the
+West") is probably the first name that comes to mind -- I guess that
+99% of open-source projects that need a FFT do use FFTW, and are happy
+with it. However, it is quite a large library , which does everything
+fft related (2d transforms, 3d transforms, other transformations such
+as discrete cosine , or fast hartley). And it is licensed under the
+GNU GPL , which means that it cannot be used in non open-source
+products.
+
+An alternative to FFTW that is really small, is the venerable FFTPACK
+v4, which is available on NETLIB. A more recent version (v5) exists,
+but it is larger as it deals with multi-dimensional transforms. This
+is a library that is written in FORTRAN 77, a language that is now
+considered as a bit antiquated by many. FFTPACKv4 was written in 1985,
+by Dr Paul Swarztrauber of NCAR, more than 25 years ago ! And despite
+its age, benchmarks show it that it still a very good performing FFT
+library, see for example the 1d single precision benchmarks here:
+http://www.fftw.org/speed/opteron-2.2GHz-32bit/ . It is however not
+competitive with the fastest ones, such as FFTW, Intel MKL, AMD ACML,
+Apple vDSP. The reason for that is that those libraries do take
+advantage of the SSE SIMD instructions available on Intel CPUs,
+available since the days of the Pentium III. These instructions deal
+with small vectors of 4 floats at a time, instead of a single float
+for a traditionnal FPU, so when using these instructions one may expect
+a 4-fold performance improvement.
+
+The idea was to take this fortran fftpack v4 code, translate to C,
+modify it to deal with those SSE instructions, and check that the
+final performance is not completely ridiculous when compared to other
+SIMD FFT libraries. Translation to C was performed with f2c (
+http://www.netlib.org/f2c/ ). The resulting file was a bit edited in
+order to remove the thousands of gotos that were introduced by
+f2c. You will find the fftpack.h and fftpack.c sources in the
+repository, this a complete translation of
+http://www.netlib.org/fftpack/ , with the discrete cosine transform
+and the test program. There is no license information in the netlib
+repository, but it was confirmed to me by the fftpack v5 curators that
+the same terms do apply to fftpack v4:
+http://www.cisl.ucar.edu/css/software/fftpack5/ftpk.html . This is a
+"BSD-like" license, it is compatible with proprietary projects.
+
+Adapting fftpack to deal with the SIMD 4-element vectors instead of
+scalar single precision numbers was more complex than I originally
+thought, especially with the real transforms, and I ended up writing
+more code than I planned..
+
+
+The code:
+--
+
+Only two files, in good old C, pffft.c and pffft.h . The API is very
+very simple, just make sure that you read the comments in pffft.h.
+
+
+Comparison with other FFTs:
+--
+
+The idea was not to break speed records, but to get a decently fast
+fft that is at least 50% as fast as the fastest FFT -- especially on
+slowest computers . I'm more focused on getting the best performance
+on slow cpus (Atom, Intel Core 1, old Athlons, ARM Cortex-A9...), than
+on getting top performance on today fastest cpus.
+
+It can be used in a real-time context as the fft functions do not
+perform any memory allocation -- that is why they accept a 'work'
+array in their arguments.
+
+It is also a bit focused on performing 1D convolutions, that is why it
+provides "unordered" FFTs , and a fourier domain convolution
+operation.
+
+
+Benchmark results (cpu tested: core i7 2600, core 2 quad, core 1 duo, atom N270, cortex-A9, cortex-A15, A8X)
+--
+
+The benchmark shows the performance of various fft implementations measured in 
+MFlops, with the number of floating point operations being defined as 5Nlog2(N)
+for a length N complex fft, and 2.5*Nlog2(N) for a real fft. 
+See http://www.fftw.org/speed/method.html for an explanation of these formulas.
+
+MacOS Lion, gcc 4.2, 64-bit, fftw 3.3 on a 3.4 GHz core i7 2600
+
+Built with:
+
+ gcc-4.2 -o test_pffft -arch x86_64 -O3 -Wall -W pffft.c test_pffft.c fftpack.c -L/usr/local/lib -I/usr/local/include/ -DHAVE_VECLIB -framework veclib -DHAVE_FFTW -lfftw3f 
+
+| input len |real FFTPack|  real vDSP |  real FFTW | real PFFFT | |cplx FFTPack|  cplx vDSP |  cplx FFTW | cplx PFFFT |
+|-----------+------------+------------+------------+------------| |------------+------------+------------+------------|
+|       64  |     2816   |     8596   |     7329   |     8187   | |     2887   |    14898   |    14668   |    11108   |
+|       96  |     3298   |      n/a   |     8378   |     7727   | |     3953   |      n/a   |    15680   |    10878   |
+|      128  |     3507   |    11575   |     9266   |    10108   | |     4233   |    17598   |    16427   |    12000   |
+|      160  |     3391   |      n/a   |     9838   |    10711   | |     4220   |      n/a   |    16653   |    11187   |
+|      192  |     3919   |      n/a   |     9868   |    10956   | |     4297   |      n/a   |    15770   |    12540   |
+|      256  |     4283   |    13179   |    10694   |    13128   | |     4545   |    19550   |    16350   |    13822   |
+|      384  |     3136   |      n/a   |    10810   |    12061   | |     3600   |      n/a   |    16103   |    13240   |
+|      480  |     3477   |      n/a   |    10632   |    12074   | |     3536   |      n/a   |    11630   |    12522   |
+|      512  |     3783   |    15141   |    11267   |    13838   | |     3649   |    20002   |    16560   |    13580   |
+|      640  |     3639   |      n/a   |    11164   |    13946   | |     3695   |      n/a   |    15416   |    13890   |
+|      768  |     3800   |      n/a   |    11245   |    13495   | |     3590   |      n/a   |    15802   |    14552   |
+|      800  |     3440   |      n/a   |    10499   |    13301   | |     3659   |      n/a   |    12056   |    13268   |
+|     1024  |     3924   |    15605   |    11450   |    15339   | |     3769   |    20963   |    13941   |    15467   |
+|     2048  |     4518   |    16195   |    11551   |    15532   | |     4258   |    20413   |    13723   |    15042   |
+|     2400  |     4294   |      n/a   |    10685   |    13078   | |     4093   |      n/a   |    12777   |    13119   |
+|     4096  |     4750   |    16596   |    11672   |    15817   | |     4157   |    19662   |    14316   |    14336   |
+|     8192  |     3820   |    16227   |    11084   |    12555   | |     3691   |    18132   |    12102   |    13813   |
+|     9216  |     3864   |      n/a   |    10254   |    12870   | |     3586   |      n/a   |    12119   |    13994   |
+|    16384  |     3822   |    15123   |    10454   |    12822   | |     3613   |    16874   |    12370   |    13881   |
+|    32768  |     4175   |    14512   |    10662   |    11095   | |     3881   |    14702   |    11619   |    11524   |
+|   262144  |     3317   |    11429   |     6269   |     9517   | |     2810   |    11729   |     7757   |    10179   |
+|  1048576  |     2913   |    10551   |     4730   |     5867   | |     2661   |     7881   |     3520   |     5350   |
+|-----------+------------+------------+------------+------------| |------------+------------+------------+------------|
+
+
+Debian 6, gcc 4.4.5, 64-bit, fftw 3.3.1 on a 3.4 GHz core i7 2600
+
+Built with:
+gcc -o test_pffft -DHAVE_FFTW -msse2 -O3 -Wall -W pffft.c test_pffft.c fftpack.c -L$HOME/local/lib -I$HOME/local/include/ -lfftw3f -lm
+
+| N (input length) | real FFTPack |   real FFTW  |  real PFFFT  | | cplx FFTPack |   cplx FFTW  |  cplx PFFFT  |
+|------------------+--------------+--------------+--------------| |--------------+--------------+--------------|
+|           64     |      3840    |      7680    |      8777    | |      4389    |     20480    |     11171    |
+|           96     |      4214    |      9633    |      8429    | |      4816    |     22477    |     11238    |
+|          128     |      3584    |     10240    |     10240    | |      5120    |     23893    |     11947    |
+|          192     |      4854    |     11095    |     12945    | |      4854    |     22191    |     14121    |
+|          256     |      4096    |     11703    |     16384    | |      5120    |     23406    |     13653    |
+|          384     |      4395    |     14651    |     12558    | |      4884    |     19535    |     14651    |
+|          512     |      5760    |     13166    |     15360    | |      4608    |     23040    |     15360    |
+|          768     |      4907    |     14020    |     16357    | |      4461    |     19628    |     14020    |
+|         1024     |      5120    |     14629    |     14629    | |      5120    |     20480    |     15754    |
+|         2048     |      5632    |     14080    |     18773    | |      4693    |     12516    |     16091    |
+|         4096     |      5120    |     13653    |     17554    | |      4726    |      7680    |     14456    |
+|         8192     |      4160    |      7396    |     13312    | |      4437    |     14791    |     13312    |
+|         9216     |      4210    |      6124    |     13473    | |      4491    |      7282    |     14970    |
+|        16384     |      3976    |     11010    |     14313    | |      4210    |     11450    |     13631    |
+|        32768     |      4260    |     10224    |     10954    | |      4260    |      6816    |     11797    |
+|       262144     |      3736    |      6896    |      9961    | |      2359    |      8965    |      9437    |
+|      1048576     |      2796    |      4534    |      6453    | |      1864    |      3078    |      5592    |
+|------------------+--------------+--------------+--------------| |--------------+--------------+--------------|
+
+
+
+MacOS Snow Leopard, gcc 4.0, 32-bit, fftw 3.3 on a 1.83 GHz core 1 duo
+
+Built with:
+
+ gcc -o test_pffft -DHAVE_FFTW -DHAVE_VECLIB -O3 -Wall -W pffft.c test_pffft.c fftpack.c -L/usr/local/lib -I/usr/local/include/ -lfftw3f -framework veclib
+
+| input len |real FFTPack|  real vDSP |  real FFTW | real PFFFT | |cplx FFTPack|  cplx vDSP |  cplx FFTW | cplx PFFFT |
+|-----------+------------+------------+------------+------------| |------------+------------+------------+------------|
+|      64   |      745   |     2145   |     1706   |     2028   | |      961   |     3356   |     3313   |     2300   |
+|      96   |      877   |      n/a   |     1976   |     1978   | |     1059   |      n/a   |     3333   |     2233   |
+|     128   |      951   |     2808   |     2213   |     2279   | |     1202   |     3803   |     3739   |     2494   |
+|     192   |     1002   |      n/a   |     2456   |     2429   | |     1186   |      n/a   |     3701   |     2508   |
+|     256   |     1065   |     3205   |     2641   |     2793   | |     1302   |     4013   |     3912   |     2663   |
+|     384   |      845   |      n/a   |     2759   |     2499   | |      948   |      n/a   |     3729   |     2504   |
+|     512   |      900   |     3476   |     2956   |     2759   | |      974   |     4057   |     3954   |     2645   |
+|     768   |      910   |      n/a   |     2912   |     2737   | |      975   |      n/a   |     3837   |     2614   |
+|    1024   |      936   |     3583   |     3107   |     3009   | |     1006   |     4124   |     3821   |     2697   |
+|    2048   |     1057   |     3585   |     3091   |     2837   | |     1089   |     3889   |     3701   |     2513   |
+|    4096   |     1083   |     3524   |     3092   |     2733   | |     1039   |     3617   |     3462   |     2364   |
+|    8192   |      874   |     3252   |     2967   |     2363   | |      911   |     3106   |     2789   |     2302   |
+|    9216   |      898   |      n/a   |     2420   |     2290   | |      865   |      n/a   |     2676   |     2204   |
+|   16384   |      903   |     2892   |     2506   |     2421   | |      899   |     3026   |     2797   |     2289   |
+|   32768   |      965   |     2837   |     2550   |     2358   | |      920   |     2922   |     2763   |     2240   |
+|  262144   |      738   |     2422   |     1589   |     1708   | |      610   |     2038   |     1436   |     1091   |
+| 1048576   |      528   |     1207   |      845   |      880   | |      606   |     1020   |      669   |     1036   |
+|-----------+------------+------------+------------+------------| |------------+------------+------------+------------|
+
+
+
+Ubuntu 11.04, gcc 4.5, 32-bit, fftw 3.2 on a 2.66 core 2 quad
+
+Built with:
+gcc -o test_pffft -DHAVE_FFTW -msse -mfpmath=sse -O3 -Wall -W pffft.c test_pffft.c fftpack.c -L/usr/local/lib -I/usr/local/include/ -lfftw3f -lm
+
+| input len |real FFTPack|  real FFTW | real PFFFT | |cplx FFTPack|  cplx FFTW | cplx PFFFT |
+|-----------+------------+------------+------------| |------------+------------+------------|
+|       64  |     1920   |     3614   |     5120   | |     2194   |     7680   |     6467   |
+|       96  |     1873   |     3549   |     5187   | |     2107   |     8429   |     5863   |
+|      128  |     2240   |     3773   |     5514   | |     2560   |     7964   |     6827   |
+|      192  |     1765   |     4569   |     7767   | |     2284   |     9137   |     7061   |
+|      256  |     2048   |     5461   |     7447   | |     2731   |     9638   |     7802   |
+|      384  |     1998   |     5861   |     6762   | |     2313   |     9253   |     7644   |
+|      512  |     2095   |     6144   |     7680   | |     2194   |    10240   |     7089   |
+|      768  |     2230   |     5773   |     7549   | |     2045   |    10331   |     7010   |
+|     1024  |     2133   |     6400   |     8533   | |     2133   |    10779   |     7877   |
+|     2048  |     2011   |     7040   |     8665   | |     1942   |    10240   |     7768   |
+|     4096  |     2194   |     6827   |     8777   | |     1755   |     9452   |     6827   |
+|     8192  |     1849   |     6656   |     6656   | |     1752   |     7831   |     6827   |
+|     9216  |     1871   |     5858   |     6416   | |     1643   |     6909   |     6266   |
+|    16384  |     1883   |     6223   |     6506   | |     1664   |     7340   |     6982   |
+|    32768  |     1826   |     6390   |     6667   | |     1631   |     7481   |     6971   |
+|   262144  |     1546   |     4075   |     5977   | |     1299   |     3415   |     3551   |
+|  1048576  |     1104   |     2071   |     1730   | |     1104   |     1149   |     1834   |
+|-----------+------------+------------+------------| |------------+------------+------------|
+
+
+
+Ubuntu 11.04, gcc 4.5, 32-bit, fftw 3.3 on a 1.6 GHz Atom N270
+
+Built with:
+gcc -o test_pffft -DHAVE_FFTW -msse -mfpmath=sse -O3 -Wall -W pffft.c test_pffft.c fftpack.c -L/usr/local/lib -I/usr/local/include/ -lfftw3f -lm
+
+| N (input length) | real FFTPack |   real FFTW  |  real PFFFT  | | cplx FFTPack |   cplx FFTW  |  cplx PFFFT  |
+|------------------+--------------+--------------+--------------| |--------------+--------------+--------------|
+|           64     |       452    |      1041    |      1336    | |       549    |      2318    |      1781    |
+|           96     |       444    |      1297    |      1297    | |       503    |      2408    |      1686    |
+|          128     |       527    |      1525    |      1707    | |       543    |      2655    |      1886    |
+|          192     |       498    |      1653    |      1849    | |       539    |      2678    |      1942    |
+|          256     |       585    |      1862    |      2156    | |       594    |      2777    |      2244    |
+|          384     |       499    |      1870    |      1998    | |       511    |      2586    |      1890    |
+|          512     |       562    |      2095    |      2194    | |       542    |      2973    |      2194    |
+|          768     |       545    |      2045    |      2133    | |       545    |      2365    |      2133    |
+|         1024     |       595    |      2133    |      2438    | |       569    |      2695    |      2179    |
+|         2048     |       587    |      2125    |      2347    | |       521    |      2230    |      1707    |
+|         4096     |       495    |      1890    |      1834    | |       492    |      1876    |      1672    |
+|         8192     |       469    |      1548    |      1729    | |       438    |      1740    |      1664    |
+|         9216     |       468    |      1663    |      1663    | |       446    |      1585    |      1531    |
+|        16384     |       453    |      1608    |      1767    | |       398    |      1476    |      1664    |
+|        32768     |       456    |      1420    |      1503    | |       387    |      1388    |      1345    |
+|       262144     |       309    |       385    |       726    | |       262    |       415    |       840    |
+|      1048576     |       280    |       351    |       739    | |       261    |       313    |       797    |
+|------------------+--------------+--------------+--------------| |--------------+--------------+--------------|
+
+
+
+Windows 7, visual c++ 2010 on a 1.6 GHz Atom N270
+
+Built with:
+cl /Ox -D_USE_MATH_DEFINES /arch:SSE test_pffft.c pffft.c fftpack.c
+
+(visual c++ is definitively not very good with SSE intrinsics...)
+
+| N (input length) | real FFTPack |  real PFFFT  | | cplx FFTPack |  cplx PFFFT  |
+|------------------+--------------+--------------| |--------------+--------------|
+|           64     |       173    |      1009    | |       174    |      1159    |
+|           96     |       169    |      1029    | |       188    |      1201    |
+|          128     |       195    |      1242    | |       191    |      1275    |
+|          192     |       178    |      1312    | |       184    |      1276    |
+|          256     |       196    |      1591    | |       186    |      1281    |
+|          384     |       172    |      1409    | |       181    |      1281    |
+|          512     |       187    |      1640    | |       181    |      1313    |
+|          768     |       171    |      1614    | |       176    |      1258    |
+|         1024     |       186    |      1812    | |       178    |      1223    |
+|         2048     |       190    |      1707    | |       186    |      1099    |
+|         4096     |       182    |      1446    | |       177    |       975    |
+|         8192     |       175    |      1345    | |       169    |      1034    |
+|         9216     |       165    |      1271    | |       168    |      1023    |
+|        16384     |       166    |      1396    | |       165    |       949    |
+|        32768     |       172    |      1311    | |       161    |       881    |
+|       262144     |       136    |       632    | |       134    |       629    |
+|      1048576     |       134    |       698    | |       127    |       623    |
+|------------------+--------------+--------------| |--------------+--------------|
+
+
+
+Ubuntu 12.04, gcc-4.7.3, 32-bit, with fftw 3.3.3 (built with --enable-neon), on a 1.2GHz ARM Cortex A9 (Tegra 3)
+
+Built with:
+gcc-4.7 -O3 -DHAVE_FFTW -march=armv7-a -mtune=cortex-a9 -mfloat-abi=hard -mfpu=neon -ffast-math test_pffft.c pffft.c -o test_pffft_arm fftpack.c -lm -I/usr/local/include/ -L/usr/local/lib/ -lfftw3f
+
+| input len |real FFTPack|  real FFTW | real PFFFT | |cplx FFTPack|  cplx FFTW | cplx PFFFT |
+|-----------+------------+------------+------------| |------------+------------+------------|
+|       64  |      549   |      452   |      731   | |      512   |      602   |      640   |
+|       96  |      421   |      272   |      702   | |      496   |      571   |      602   |
+|      128  |      498   |      512   |      815   | |      597   |      618   |      652   |
+|      160  |      521   |      536   |      815   | |      586   |      669   |      625   |
+|      192  |      539   |      571   |      883   | |      485   |      597   |      626   |
+|      256  |      640   |      539   |      975   | |      569   |      611   |      671   |
+|      384  |      499   |      610   |      879   | |      499   |      602   |      637   |
+|      480  |      518   |      507   |      877   | |      496   |      661   |      616   |
+|      512  |      524   |      591   |     1002   | |      549   |      678   |      668   |
+|      640  |      542   |      612   |      955   | |      568   |      663   |      645   |
+|      768  |      557   |      613   |      981   | |      491   |      663   |      598   |
+|      800  |      514   |      353   |      882   | |      514   |      360   |      574   |
+|     1024  |      640   |      640   |     1067   | |      492   |      683   |      602   |
+|     2048  |      587   |      640   |      908   | |      486   |      640   |      552   |
+|     2400  |      479   |      368   |      777   | |      422   |      376   |      518   |
+|     4096  |      511   |      614   |      853   | |      426   |      640   |      534   |
+|     8192  |      415   |      584   |      708   | |      386   |      622   |      516   |
+|     9216  |      419   |      571   |      687   | |      364   |      586   |      506   |
+|    16384  |      426   |      577   |      716   | |      398   |      606   |      530   |
+|    32768  |      417   |      572   |      673   | |      399   |      572   |      468   |
+|   262144  |      219   |      380   |      293   | |      255   |      431   |      343   |
+|  1048576  |      202   |      274   |      237   | |      265   |      282   |      355   |
+|-----------+------------+------------+------------| |------------+------------+------------|
+
+Same platform as above, but this time pffft and fftpack are built with clang 3.2:
+
+clang -O3 -DHAVE_FFTW -march=armv7-a -mtune=cortex-a9 -mfloat-abi=hard -mfpu=neon -ffast-math test_pffft.c pffft.c -o test_pffft_arm fftpack.c -lm -I/usr/local/include/ -L/usr/local/lib/ -lfftw3f
+
+| input len |real FFTPack|  real FFTW | real PFFFT | |cplx FFTPack|  cplx FFTW | cplx PFFFT |
+|-----------+------------+------------+------------| |------------+------------+------------|
+|       64  |      427   |      452   |      853   | |      427   |      602   |     1024   |
+|       96  |      351   |      276   |      843   | |      337   |      571   |      963   |
+|      128  |      373   |      512   |      996   | |      390   |      618   |     1054   |
+|      160  |      426   |      536   |      987   | |      375   |      669   |      914   |
+|      192  |      404   |      571   |     1079   | |      388   |      588   |     1079   |
+|      256  |      465   |      539   |     1205   | |      445   |      602   |     1170   |
+|      384  |      366   |      610   |     1099   | |      343   |      594   |     1099   |
+|      480  |      356   |      507   |     1140   | |      335   |      651   |      931   |
+|      512  |      411   |      591   |     1213   | |      384   |      649   |     1124   |
+|      640  |      398   |      612   |     1193   | |      373   |      654   |      901   |
+|      768  |      409   |      613   |     1227   | |      383   |      663   |     1044   |
+|      800  |      411   |      348   |     1073   | |      353   |      358   |      809   |
+|     1024  |      427   |      640   |     1280   | |      413   |      692   |     1004   |
+|     2048  |      414   |      626   |     1126   | |      371   |      640   |      853   |
+|     2400  |      399   |      373   |      898   | |      319   |      368   |      653   |
+|     4096  |      404   |      602   |     1059   | |      357   |      633   |      778   |
+|     8192  |      332   |      584   |      792   | |      308   |      616   |      716   |
+|     9216  |      322   |      561   |      783   | |      299   |      586   |      687   |
+|    16384  |      344   |      568   |      778   | |      314   |      617   |      745   |
+|    32768  |      342   |      564   |      737   | |      314   |      552   |      629   |
+|   262144  |      201   |      383   |      313   | |      227   |      435   |      413   |
+|  1048576  |      187   |      262   |      251   | |      228   |      281   |      409   |
+|-----------+------------+------------+------------| |------------+------------+------------|
+
+So it looks like, on ARM, gcc 4.7 is the best at scalar floating point
+(the fftpack performance numbers are better with gcc), while clang is
+the best with neon intrinsics (see how pffft perf has improved with
+clang 3.2).
+
+
+NVIDIA Jetson TK1 board, gcc-4.8.2. The cpu is a 2.3GHz cortex A15 (Tegra K1).
+
+Built with:
+gcc -O3 -march=armv7-a -mtune=native -mfloat-abi=hard -mfpu=neon -ffast-math test_pffft.c pffft.c -o test_pffft_arm fftpack.c -lm
+
+| input len |real FFTPack| real PFFFT | |cplx FFTPack| cplx PFFFT |
+|-----------+------------+------------| |------------+------------|
+|       64  |     1735   |     3308   | |     1994   |     3744   |
+|       96  |     1596   |     3448   | |     1987   |     3572   |
+|      128  |     1807   |     4076   | |     2255   |     3960   |
+|      160  |     1769   |     4083   | |     2071   |     3845   |
+|      192  |     1990   |     4233   | |     2017   |     3939   |
+|      256  |     2191   |     4882   | |     2254   |     4346   |
+|      384  |     1878   |     4492   | |     2073   |     4012   |
+|      480  |     1748   |     4398   | |     1923   |     3951   |
+|      512  |     2030   |     5064   | |     2267   |     4195   |
+|      640  |     1918   |     4756   | |     2094   |     4184   |
+|      768  |     2099   |     4907   | |     2048   |     4297   |
+|      800  |     1822   |     4555   | |     1880   |     4063   |
+|     1024  |     2232   |     5355   | |     2187   |     4420   |
+|     2048  |     2176   |     4983   | |     2027   |     3602   |
+|     2400  |     1741   |     4256   | |     1710   |     3344   |
+|     4096  |     1816   |     3914   | |     1851   |     3349   |
+|     8192  |     1716   |     3481   | |     1700   |     3255   |
+|     9216  |     1735   |     3589   | |     1653   |     3094   |
+|    16384  |     1567   |     3483   | |     1637   |     3244   |
+|    32768  |     1624   |     3240   | |     1655   |     3156   |
+|   262144  |     1012   |     1898   | |      983   |     1503   |
+|  1048576  |      876   |     1154   | |      868   |     1341   |
+|-----------+------------+------------| |------------+------------|
+
+The performance on the tegra K1 is pretty impressive. I'm not
+including the FFTW numbers as they as slightly below the scalar
+fftpack numbers, so something must be wrong (however it seems to be
+correctly configured and is using neon simd instructions).
+
+When using clang 3.4 the pffft version is even a bit faster, reaching
+5.7 GFlops for real ffts of size 1024.
+
+
+iPad Air 2 with iOS9, xcode 8.0, arm64. The cpu is an Apple A8X, supposedly running at 1.5GHz.
+
+| input len |real FFTPack|  real vDSP | real PFFFT | |cplx FFTPack|  cplx vDSP | cplx PFFFT |
+|-----------+------------+------------+------------| |------------+------------+------------|
+|       64  |     2517   |     7995   |     6086   | |     2725   |    13006   |     8495   |
+|       96  |     2442   |      n/a   |     6691   | |     2256   |      n/a   |     7991   |
+|      128  |     2664   |    10186   |     7877   | |     2575   |    15115   |     9115   |
+|      160  |     2638   |      n/a   |     8283   | |     2682   |      n/a   |     8806   |
+|      192  |     2903   |      n/a   |     9083   | |     2634   |      n/a   |     8980   |
+|      256  |     3184   |    11452   |    10039   | |     3026   |    15410   |    10199   |
+|      384  |     2665   |      n/a   |    10100   | |     2275   |      n/a   |     9247   |
+|      480  |     2546   |      n/a   |     9863   | |     2341   |      n/a   |     8892   |
+|      512  |     2832   |    12197   |    10989   | |     2547   |    16768   |    10154   |
+|      640  |     2755   |      n/a   |    10461   | |     2569   |      n/a   |     9666   |
+|      768  |     2998   |      n/a   |    11355   | |     2585   |      n/a   |     9813   |
+|      800  |     2516   |      n/a   |    10332   | |     2433   |      n/a   |     9164   |
+|     1024  |     3109   |    12965   |    12114   | |     2869   |    16448   |    10519   |
+|     2048  |     3027   |    12996   |    12023   | |     2648   |    17304   |    10307   |
+|     2400  |     2515   |      n/a   |    10372   | |     2355   |      n/a   |     8443   |
+|     4096  |     3204   |    13603   |    12359   | |     2814   |    16570   |     9780   |
+|     8192  |     2759   |    13422   |    10824   | |     2153   |    15652   |     7884   |
+|     9216  |     2700   |      n/a   |     9938   | |     2241   |      n/a   |     7900   |
+|    16384  |     2280   |    13057   |     7976   | |      593   |     4272   |     2534   |
+|    32768  |      768   |     4269   |     2882   | |      606   |     4405   |     2604   |
+|   262144  |      724   |     3527   |     2630   | |      534   |     2418   |     2157   |
+|  1048576  |      674   |     1467   |     2135   | |      530   |     1621   |     2055   |
+|-----------+------------+------------+------------| |------------+------------+------------|
+
+I double-checked to make sure I did not make a mistake in the time
+measurements, as the numbers are much higher than what I initially
+expected. They are in fact higher than the number I get on the 2.8GHz
+Xeon of my 2008 mac pro.. (except for FFT lengths >= 32768 where
+having a big cache is useful). A good surprise is also that the perf
+is not too far from apple's vDSP (at least for the real FFT).
+
diff --git a/third_party/webrtc_aec3/src/third_party/pffft/src/pffft.c b/third_party/webrtc_aec3/src/third_party/pffft/src/pffft.c
new file mode 100644
index 0000000..d76d351
--- /dev/null
+++ b/third_party/webrtc_aec3/src/third_party/pffft/src/pffft.c
@@ -0,0 +1,1881 @@
+/* Copyright (c) 2013  Julien Pommier ( pommier@modartt.com )
+
+   Based on original fortran 77 code from FFTPACKv4 from NETLIB
+   (http://www.netlib.org/fftpack), authored by Dr Paul Swarztrauber
+   of NCAR, in 1985.
+
+   As confirmed by the NCAR fftpack software curators, the following
+   FFTPACKv5 license applies to FFTPACKv4 sources. My changes are
+   released under the same terms.
+
+   FFTPACK license:
+
+   http://www.cisl.ucar.edu/css/software/fftpack5/ftpk.html
+
+   Copyright (c) 2004 the University Corporation for Atmospheric
+   Research ("UCAR"). All rights reserved. Developed by NCAR's
+   Computational and Information Systems Laboratory, UCAR,
+   www.cisl.ucar.edu.
+
+   Redistribution and use of the Software in source and binary forms,
+   with or without modification, is permitted provided that the
+   following conditions are met:
+
+   - Neither the names of NCAR's Computational and Information Systems
+   Laboratory, the University Corporation for Atmospheric Research,
+   nor the names of its sponsors or contributors may be used to
+   endorse or promote products derived from this Software without
+   specific prior written permission.  
+
+   - Redistributions of source code must retain the above copyright
+   notices, this list of conditions, and the disclaimer below.
+
+   - Redistributions in binary form must reproduce the above copyright
+   notice, this list of conditions, and the disclaimer below in the
+   documentation and/or other materials provided with the
+   distribution.
+
+   THIS SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+   EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED TO THE WARRANTIES OF
+   MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+   NONINFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT
+   HOLDERS BE LIABLE FOR ANY CLAIM, INDIRECT, INCIDENTAL, SPECIAL,
+   EXEMPLARY, OR CONSEQUENTIAL DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+   ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+   CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE
+   SOFTWARE.
+
+
+   PFFFT : a Pretty Fast FFT.
+
+   This file is largerly based on the original FFTPACK implementation, modified in
+   order to take advantage of SIMD instructions of modern CPUs.
+*/
+
+/*
+  ChangeLog: 
+  - 2011/10/02, version 1: This is the very first release of this file.
+*/
+
+#include "pffft.h"
+#include <stdlib.h>
+#include <stdio.h>
+#include <math.h>
+#include <assert.h>
+
+/* detect compiler flavour */
+#if defined(_MSC_VER)
+#  define COMPILER_MSVC
+#elif defined(__GNUC__)
+#  define COMPILER_GCC
+#endif
+
+#if defined(COMPILER_GCC)
+#  define ALWAYS_INLINE(return_type) inline return_type __attribute__ ((always_inline))
+#  define NEVER_INLINE(return_type) return_type __attribute__ ((noinline))
+#  define RESTRICT __restrict
+#  define VLA_ARRAY_ON_STACK(type__, varname__, size__) type__ varname__[size__];
+#elif defined(COMPILER_MSVC)
+#  define ALWAYS_INLINE(return_type) __forceinline return_type
+#  define NEVER_INLINE(return_type) __declspec(noinline) return_type
+#  define RESTRICT __restrict
+#  define VLA_ARRAY_ON_STACK(type__, varname__, size__) type__ *varname__ = (type__*)_alloca(size__ * sizeof(type__))
+#endif
+
+
+/* 
+   vector support macros: the rest of the code is independant of
+   SSE/Altivec/NEON -- adding support for other platforms with 4-element
+   vectors should be limited to these macros 
+*/
+
+
+// define PFFFT_SIMD_DISABLE if you want to use scalar code instead of simd code
+//#define PFFFT_SIMD_DISABLE
+
+/*
+   Altivec support macros 
+*/
+#if !defined(PFFFT_SIMD_DISABLE) && (defined(__ppc__) || defined(__ppc64__))
+typedef vector float v4sf;
+#  define SIMD_SZ 4
+#  define VZERO() ((vector float) vec_splat_u8(0))
+#  define VMUL(a,b) vec_madd(a,b, VZERO())
+#  define VADD(a,b) vec_add(a,b)
+#  define VMADD(a,b,c) vec_madd(a,b,c)
+#  define VSUB(a,b) vec_sub(a,b)
+inline v4sf ld_ps1(const float *p) { v4sf v=vec_lde(0,p); return vec_splat(vec_perm(v, v, vec_lvsl(0, p)), 0); }
+#  define LD_PS1(p) ld_ps1(&p)
+#  define INTERLEAVE2(in1, in2, out1, out2) { v4sf tmp__ = vec_mergeh(in1, in2); out2 = vec_mergel(in1, in2); out1 = tmp__; }
+#  define UNINTERLEAVE2(in1, in2, out1, out2) {                           \
+    vector unsigned char vperm1 =  (vector unsigned char)(0,1,2,3,8,9,10,11,16,17,18,19,24,25,26,27); \
+    vector unsigned char vperm2 =  (vector unsigned char)(4,5,6,7,12,13,14,15,20,21,22,23,28,29,30,31); \
+    v4sf tmp__ = vec_perm(in1, in2, vperm1); out2 = vec_perm(in1, in2, vperm2); out1 = tmp__; \
+  }
+#  define VTRANSPOSE4(x0,x1,x2,x3) {              \
+    v4sf y0 = vec_mergeh(x0, x2);               \
+    v4sf y1 = vec_mergel(x0, x2);               \
+    v4sf y2 = vec_mergeh(x1, x3);               \
+    v4sf y3 = vec_mergel(x1, x3);               \
+    x0 = vec_mergeh(y0, y2);                    \
+    x1 = vec_mergel(y0, y2);                    \
+    x2 = vec_mergeh(y1, y3);                    \
+    x3 = vec_mergel(y1, y3);                    \
+  }
+#  define VSWAPHL(a,b) vec_perm(a,b, (vector unsigned char)(16,17,18,19,20,21,22,23,8,9,10,11,12,13,14,15))
+#  define VALIGNED(ptr) ((((long)(ptr)) & 0xF) == 0)
+
+/*
+  SSE1 support macros
+*/
+#elif !defined(PFFFT_SIMD_DISABLE) && (defined(__x86_64__) || defined(_M_X64) || defined(__i386__) || defined(i386) || defined(_M_IX86))
+
+#include <xmmintrin.h>
+typedef __m128 v4sf;
+#  define SIMD_SZ 4 // 4 floats by simd vector -- this is pretty much hardcoded in the preprocess/finalize functions anyway so you will have to work if you want to enable AVX with its 256-bit vectors.
+#  define VZERO() _mm_setzero_ps()
+#  define VMUL(a,b) _mm_mul_ps(a,b)
+#  define VADD(a,b) _mm_add_ps(a,b)
+#  define VMADD(a,b,c) _mm_add_ps(_mm_mul_ps(a,b), c)
+#  define VSUB(a,b) _mm_sub_ps(a,b)
+#  define LD_PS1(p) _mm_set1_ps(p)
+#  define INTERLEAVE2(in1, in2, out1, out2) { v4sf tmp__ = _mm_unpacklo_ps(in1, in2); out2 = _mm_unpackhi_ps(in1, in2); out1 = tmp__; }
+#  define UNINTERLEAVE2(in1, in2, out1, out2) { v4sf tmp__ = _mm_shuffle_ps(in1, in2, _MM_SHUFFLE(2,0,2,0)); out2 = _mm_shuffle_ps(in1, in2, _MM_SHUFFLE(3,1,3,1)); out1 = tmp__; }
+#  define VTRANSPOSE4(x0,x1,x2,x3) _MM_TRANSPOSE4_PS(x0,x1,x2,x3)
+#  define VSWAPHL(a,b) _mm_shuffle_ps(b, a, _MM_SHUFFLE(3,2,1,0))
+#  define VALIGNED(ptr) ((((long)(ptr)) & 0xF) == 0)
+
+/*
+  ARM NEON support macros
+*/
+#elif !defined(PFFFT_SIMD_DISABLE) && (defined(__arm__) || defined(__aarch64__) || defined(__arm64__))
+#  include <arm_neon.h>
+typedef float32x4_t v4sf;
+#  define SIMD_SZ 4
+#  define VZERO() vdupq_n_f32(0)
+#  define VMUL(a,b) vmulq_f32(a,b)
+#  define VADD(a,b) vaddq_f32(a,b)
+#  define VMADD(a,b,c) vmlaq_f32(c,a,b)
+#  define VSUB(a,b) vsubq_f32(a,b)
+#  define LD_PS1(p) vld1q_dup_f32(&(p))
+#  define INTERLEAVE2(in1, in2, out1, out2) { float32x4x2_t tmp__ = vzipq_f32(in1,in2); out1=tmp__.val[0]; out2=tmp__.val[1]; }
+#  define UNINTERLEAVE2(in1, in2, out1, out2) { float32x4x2_t tmp__ = vuzpq_f32(in1,in2); out1=tmp__.val[0]; out2=tmp__.val[1]; }
+#  define VTRANSPOSE4(x0,x1,x2,x3) {                                    \
+    float32x4x2_t t0_ = vzipq_f32(x0, x2);                              \
+    float32x4x2_t t1_ = vzipq_f32(x1, x3);                              \
+    float32x4x2_t u0_ = vzipq_f32(t0_.val[0], t1_.val[0]);              \
+    float32x4x2_t u1_ = vzipq_f32(t0_.val[1], t1_.val[1]);              \
+    x0 = u0_.val[0]; x1 = u0_.val[1]; x2 = u1_.val[0]; x3 = u1_.val[1]; \
+  }
+// marginally faster version
+//#  define VTRANSPOSE4(x0,x1,x2,x3) { asm("vtrn.32 %q0, %q1;\n vtrn.32 %q2,%q3\n vswp %f0,%e2\n vswp %f1,%e3" : "+w"(x0), "+w"(x1), "+w"(x2), "+w"(x3)::); }
+#  define VSWAPHL(a,b) vcombine_f32(vget_low_f32(b), vget_high_f32(a))
+#  define VALIGNED(ptr) ((((long)(ptr)) & 0x3) == 0)
+#else
+#  if !defined(PFFFT_SIMD_DISABLE)
+#    warning "building with simd disabled !\n";
+#    define PFFFT_SIMD_DISABLE // fallback to scalar code
+#  endif
+#endif
+
+// fallback mode for situations where SSE/Altivec are not available, use scalar mode instead
+#ifdef PFFFT_SIMD_DISABLE
+typedef float v4sf;
+#  define SIMD_SZ 1
+#  define VZERO() 0.f
+#  define VMUL(a,b) ((a)*(b))
+#  define VADD(a,b) ((a)+(b))
+#  define VMADD(a,b,c) ((a)*(b)+(c))
+#  define VSUB(a,b) ((a)-(b))
+#  define LD_PS1(p) (p)
+#  define VALIGNED(ptr) ((((long)(ptr)) & 0x3) == 0)
+#endif
+
+// shortcuts for complex multiplcations
+#define VCPLXMUL(ar,ai,br,bi) { v4sf tmp; tmp=VMUL(ar,bi); ar=VMUL(ar,br); ar=VSUB(ar,VMUL(ai,bi)); ai=VMUL(ai,br); ai=VADD(ai,tmp); }
+#define VCPLXMULCONJ(ar,ai,br,bi) { v4sf tmp; tmp=VMUL(ar,bi); ar=VMUL(ar,br); ar=VADD(ar,VMUL(ai,bi)); ai=VMUL(ai,br); ai=VSUB(ai,tmp); }
+#ifndef SVMUL
+// multiply a scalar with a vector
+#define SVMUL(f,v) VMUL(LD_PS1(f),v)
+#endif
+
+#if !defined(PFFFT_SIMD_DISABLE)
+typedef union v4sf_union {
+  v4sf  v;
+  float f[4];
+} v4sf_union;
+
+#include <string.h>
+
+#define assertv4(v,f0,f1,f2,f3) assert(v.f[0] == (f0) && v.f[1] == (f1) && v.f[2] == (f2) && v.f[3] == (f3))
+
+/* detect bugs with the vector support macros */
+void validate_pffft_simd() {
+  float f[16] = { 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15 };
+  v4sf_union a0, a1, a2, a3, t, u; 
+  memcpy(a0.f, f, 4*sizeof(float));
+  memcpy(a1.f, f+4, 4*sizeof(float));
+  memcpy(a2.f, f+8, 4*sizeof(float));
+  memcpy(a3.f, f+12, 4*sizeof(float));
+
+  t = a0; u = a1; t.v = VZERO();
+  printf("VZERO=[%2g %2g %2g %2g]\n", t.f[0], t.f[1], t.f[2], t.f[3]); assertv4(t, 0, 0, 0, 0);
+  t.v = VADD(a1.v, a2.v);
+  printf("VADD(4:7,8:11)=[%2g %2g %2g %2g]\n", t.f[0], t.f[1], t.f[2], t.f[3]); assertv4(t, 12, 14, 16, 18);
+  t.v = VMUL(a1.v, a2.v);
+  printf("VMUL(4:7,8:11)=[%2g %2g %2g %2g]\n", t.f[0], t.f[1], t.f[2], t.f[3]); assertv4(t, 32, 45, 60, 77);
+  t.v = VMADD(a1.v, a2.v,a0.v);
+  printf("VMADD(4:7,8:11,0:3)=[%2g %2g %2g %2g]\n", t.f[0], t.f[1], t.f[2], t.f[3]); assertv4(t, 32, 46, 62, 80);
+
+  INTERLEAVE2(a1.v,a2.v,t.v,u.v);
+  printf("INTERLEAVE2(4:7,8:11)=[%2g %2g %2g %2g] [%2g %2g %2g %2g]\n", t.f[0], t.f[1], t.f[2], t.f[3], u.f[0], u.f[1], u.f[2], u.f[3]);
+  assertv4(t, 4, 8, 5, 9); assertv4(u, 6, 10, 7, 11);
+  UNINTERLEAVE2(a1.v,a2.v,t.v,u.v);
+  printf("UNINTERLEAVE2(4:7,8:11)=[%2g %2g %2g %2g] [%2g %2g %2g %2g]\n", t.f[0], t.f[1], t.f[2], t.f[3], u.f[0], u.f[1], u.f[2], u.f[3]);
+  assertv4(t, 4, 6, 8, 10); assertv4(u, 5, 7, 9, 11);
+
+  t.v=LD_PS1(f[15]);
+  printf("LD_PS1(15)=[%2g %2g %2g %2g]\n", t.f[0], t.f[1], t.f[2], t.f[3]);
+  assertv4(t, 15, 15, 15, 15);
+  t.v = VSWAPHL(a1.v, a2.v);
+  printf("VSWAPHL(4:7,8:11)=[%2g %2g %2g %2g]\n", t.f[0], t.f[1], t.f[2], t.f[3]);
+  assertv4(t, 8, 9, 6, 7);
+  VTRANSPOSE4(a0.v, a1.v, a2.v, a3.v);
+  printf("VTRANSPOSE4(0:3,4:7,8:11,12:15)=[%2g %2g %2g %2g] [%2g %2g %2g %2g] [%2g %2g %2g %2g] [%2g %2g %2g %2g]\n", 
+         a0.f[0], a0.f[1], a0.f[2], a0.f[3], a1.f[0], a1.f[1], a1.f[2], a1.f[3], 
+         a2.f[0], a2.f[1], a2.f[2], a2.f[3], a3.f[0], a3.f[1], a3.f[2], a3.f[3]); 
+  assertv4(a0, 0, 4, 8, 12); assertv4(a1, 1, 5, 9, 13); assertv4(a2, 2, 6, 10, 14); assertv4(a3, 3, 7, 11, 15);
+}
+#endif //!PFFFT_SIMD_DISABLE
+
+/* SSE and co like 16-bytes aligned pointers */
+#define MALLOC_V4SF_ALIGNMENT 64 // with a 64-byte alignment, we are even aligned on L2 cache lines...
+void *pffft_aligned_malloc(size_t nb_bytes) {
+  void *p, *p0 = malloc(nb_bytes + MALLOC_V4SF_ALIGNMENT);
+  if (!p0) return (void *) 0;
+  p = (void *) (((size_t) p0 + MALLOC_V4SF_ALIGNMENT) & (~((size_t) (MALLOC_V4SF_ALIGNMENT-1))));
+  *((void **) p - 1) = p0;
+  return p;
+}
+
+void pffft_aligned_free(void *p) {
+  if (p) free(*((void **) p - 1));
+}
+
+int pffft_simd_size() { return SIMD_SZ; }
+
+/*
+  passf2 and passb2 has been merged here, fsign = -1 for passf2, +1 for passb2
+*/
+static NEVER_INLINE(void) passf2_ps(int ido, int l1, const v4sf *cc, v4sf *ch, const float *wa1, float fsign) {
+  int k, i;
+  int l1ido = l1*ido;
+  if (ido <= 2) {
+    for (k=0; k < l1ido; k += ido, ch += ido, cc+= 2*ido) {
+      ch[0]         = VADD(cc[0], cc[ido+0]);
+      ch[l1ido]     = VSUB(cc[0], cc[ido+0]);
+      ch[1]         = VADD(cc[1], cc[ido+1]);
+      ch[l1ido + 1] = VSUB(cc[1], cc[ido+1]);
+    }
+  } else {
+    for (k=0; k < l1ido; k += ido, ch += ido, cc += 2*ido) {
+      for (i=0; i<ido-1; i+=2) {
+        v4sf tr2 = VSUB(cc[i+0], cc[i+ido+0]);
+        v4sf ti2 = VSUB(cc[i+1], cc[i+ido+1]);
+        v4sf wr = LD_PS1(wa1[i]), wi = VMUL(LD_PS1(fsign), LD_PS1(wa1[i+1]));
+        ch[i]   = VADD(cc[i+0], cc[i+ido+0]);
+        ch[i+1] = VADD(cc[i+1], cc[i+ido+1]);
+        VCPLXMUL(tr2, ti2, wr, wi);
+        ch[i+l1ido]   = tr2;
+        ch[i+l1ido+1] = ti2;
+      }
+    }
+  }
+}
+
+/*
+  passf3 and passb3 has been merged here, fsign = -1 for passf3, +1 for passb3
+*/
+static NEVER_INLINE(void) passf3_ps(int ido, int l1, const v4sf *cc, v4sf *ch,
+                                    const float *wa1, const float *wa2, float fsign) {
+  static const float taur = -0.5f;
+  float taui = 0.866025403784439f*fsign;
+  int i, k;
+  v4sf tr2, ti2, cr2, ci2, cr3, ci3, dr2, di2, dr3, di3;
+  int l1ido = l1*ido;
+  float wr1, wi1, wr2, wi2;
+  assert(ido > 2);
+  for (k=0; k< l1ido; k += ido, cc+= 3*ido, ch +=ido) {
+    for (i=0; i<ido-1; i+=2) {
+      tr2 = VADD(cc[i+ido], cc[i+2*ido]);
+      cr2 = VADD(cc[i], SVMUL(taur,tr2));
+      ch[i]    = VADD(cc[i], tr2);
+      ti2 = VADD(cc[i+ido+1], cc[i+2*ido+1]);
+      ci2 = VADD(cc[i    +1], SVMUL(taur,ti2));
+      ch[i+1]  = VADD(cc[i+1], ti2);
+      cr3 = SVMUL(taui, VSUB(cc[i+ido], cc[i+2*ido]));
+      ci3 = SVMUL(taui, VSUB(cc[i+ido+1], cc[i+2*ido+1]));
+      dr2 = VSUB(cr2, ci3);
+      dr3 = VADD(cr2, ci3);
+      di2 = VADD(ci2, cr3);
+      di3 = VSUB(ci2, cr3);
+      wr1=wa1[i], wi1=fsign*wa1[i+1], wr2=wa2[i], wi2=fsign*wa2[i+1]; 
+      VCPLXMUL(dr2, di2, LD_PS1(wr1), LD_PS1(wi1));
+      ch[i+l1ido] = dr2; 
+      ch[i+l1ido + 1] = di2;
+      VCPLXMUL(dr3, di3, LD_PS1(wr2), LD_PS1(wi2));
+      ch[i+2*l1ido] = dr3;
+      ch[i+2*l1ido+1] = di3;
+    }
+  }
+} /* passf3 */
+
+static NEVER_INLINE(void) passf4_ps(int ido, int l1, const v4sf *cc, v4sf *ch,
+                                    const float *wa1, const float *wa2, const float *wa3, float fsign) {
+  /* isign == -1 for forward transform and +1 for backward transform */
+
+  int i, k;
+  v4sf ci2, ci3, ci4, cr2, cr3, cr4, ti1, ti2, ti3, ti4, tr1, tr2, tr3, tr4;
+  int l1ido = l1*ido;
+  if (ido == 2) {
+    for (k=0; k < l1ido; k += ido, ch += ido, cc += 4*ido) {
+      tr1 = VSUB(cc[0], cc[2*ido + 0]);
+      tr2 = VADD(cc[0], cc[2*ido + 0]);
+      ti1 = VSUB(cc[1], cc[2*ido + 1]);
+      ti2 = VADD(cc[1], cc[2*ido + 1]);
+      ti4 = VMUL(VSUB(cc[1*ido + 0], cc[3*ido + 0]), LD_PS1(fsign));
+      tr4 = VMUL(VSUB(cc[3*ido + 1], cc[1*ido + 1]), LD_PS1(fsign));
+      tr3 = VADD(cc[ido + 0], cc[3*ido + 0]);
+      ti3 = VADD(cc[ido + 1], cc[3*ido + 1]);
+
+      ch[0*l1ido + 0] = VADD(tr2, tr3);
+      ch[0*l1ido + 1] = VADD(ti2, ti3);
+      ch[1*l1ido + 0] = VADD(tr1, tr4);
+      ch[1*l1ido + 1] = VADD(ti1, ti4);
+      ch[2*l1ido + 0] = VSUB(tr2, tr3);
+      ch[2*l1ido + 1] = VSUB(ti2, ti3);        
+      ch[3*l1ido + 0] = VSUB(tr1, tr4);
+      ch[3*l1ido + 1] = VSUB(ti1, ti4);
+    }
+  } else {
+    for (k=0; k < l1ido; k += ido, ch+=ido, cc += 4*ido) {
+      for (i=0; i<ido-1; i+=2) {
+        float wr1, wi1, wr2, wi2, wr3, wi3;
+        tr1 = VSUB(cc[i + 0], cc[i + 2*ido + 0]);
+        tr2 = VADD(cc[i + 0], cc[i + 2*ido + 0]);
+        ti1 = VSUB(cc[i + 1], cc[i + 2*ido + 1]);
+        ti2 = VADD(cc[i + 1], cc[i + 2*ido + 1]);
+        tr4 = VMUL(VSUB(cc[i + 3*ido + 1], cc[i + 1*ido + 1]), LD_PS1(fsign));
+        ti4 = VMUL(VSUB(cc[i + 1*ido + 0], cc[i + 3*ido + 0]), LD_PS1(fsign));
+        tr3 = VADD(cc[i + ido + 0], cc[i + 3*ido + 0]);
+        ti3 = VADD(cc[i + ido + 1], cc[i + 3*ido + 1]);
+
+        ch[i] = VADD(tr2, tr3);
+        cr3    = VSUB(tr2, tr3);
+        ch[i + 1] = VADD(ti2, ti3);
+        ci3 = VSUB(ti2, ti3);
+
+        cr2 = VADD(tr1, tr4);
+        cr4 = VSUB(tr1, tr4);
+        ci2 = VADD(ti1, ti4);
+        ci4 = VSUB(ti1, ti4);
+        wr1=wa1[i], wi1=fsign*wa1[i+1];
+        VCPLXMUL(cr2, ci2, LD_PS1(wr1), LD_PS1(wi1));
+        wr2=wa2[i], wi2=fsign*wa2[i+1]; 
+        ch[i + l1ido] = cr2;
+        ch[i + l1ido + 1] = ci2;
+
+        VCPLXMUL(cr3, ci3, LD_PS1(wr2), LD_PS1(wi2));
+        wr3=wa3[i], wi3=fsign*wa3[i+1]; 
+        ch[i + 2*l1ido] = cr3;
+        ch[i + 2*l1ido + 1] = ci3;
+
+        VCPLXMUL(cr4, ci4, LD_PS1(wr3), LD_PS1(wi3));
+        ch[i + 3*l1ido] = cr4;
+        ch[i + 3*l1ido + 1] = ci4;
+      }
+    }
+  }
+} /* passf4 */
+
+/*
+  passf5 and passb5 has been merged here, fsign = -1 for passf5, +1 for passb5
+*/
+static NEVER_INLINE(void) passf5_ps(int ido, int l1, const v4sf *cc, v4sf *ch,
+                                    const float *wa1, const float *wa2, 
+                                    const float *wa3, const float *wa4, float fsign) {  
+  static const float tr11 = .309016994374947f;
+  const float ti11 = .951056516295154f*fsign;
+  static const float tr12 = -.809016994374947f;
+  const float ti12 = .587785252292473f*fsign;
+
+  /* Local variables */
+  int i, k;
+  v4sf ci2, ci3, ci4, ci5, di3, di4, di5, di2, cr2, cr3, cr5, cr4, ti2, ti3,
+    ti4, ti5, dr3, dr4, dr5, dr2, tr2, tr3, tr4, tr5;
+
+  float wr1, wi1, wr2, wi2, wr3, wi3, wr4, wi4;
+
+#define cc_ref(a_1,a_2) cc[(a_2-1)*ido + a_1 + 1]
+#define ch_ref(a_1,a_3) ch[(a_3-1)*l1*ido + a_1 + 1]
+
+  assert(ido > 2);
+  for (k = 0; k < l1; ++k, cc += 5*ido, ch += ido) {
+    for (i = 0; i < ido-1; i += 2) {
+      ti5 = VSUB(cc_ref(i  , 2), cc_ref(i  , 5));
+      ti2 = VADD(cc_ref(i  , 2), cc_ref(i  , 5));
+      ti4 = VSUB(cc_ref(i  , 3), cc_ref(i  , 4));
+      ti3 = VADD(cc_ref(i  , 3), cc_ref(i  , 4));
+      tr5 = VSUB(cc_ref(i-1, 2), cc_ref(i-1, 5));
+      tr2 = VADD(cc_ref(i-1, 2), cc_ref(i-1, 5));
+      tr4 = VSUB(cc_ref(i-1, 3), cc_ref(i-1, 4));
+      tr3 = VADD(cc_ref(i-1, 3), cc_ref(i-1, 4));
+      ch_ref(i-1, 1) = VADD(cc_ref(i-1, 1), VADD(tr2, tr3));
+      ch_ref(i  , 1) = VADD(cc_ref(i  , 1), VADD(ti2, ti3));
+      cr2 = VADD(cc_ref(i-1, 1), VADD(SVMUL(tr11, tr2),SVMUL(tr12, tr3)));
+      ci2 = VADD(cc_ref(i  , 1), VADD(SVMUL(tr11, ti2),SVMUL(tr12, ti3)));
+      cr3 = VADD(cc_ref(i-1, 1), VADD(SVMUL(tr12, tr2),SVMUL(tr11, tr3)));
+      ci3 = VADD(cc_ref(i  , 1), VADD(SVMUL(tr12, ti2),SVMUL(tr11, ti3)));
+      cr5 = VADD(SVMUL(ti11, tr5), SVMUL(ti12, tr4));
+      ci5 = VADD(SVMUL(ti11, ti5), SVMUL(ti12, ti4));
+      cr4 = VSUB(SVMUL(ti12, tr5), SVMUL(ti11, tr4));
+      ci4 = VSUB(SVMUL(ti12, ti5), SVMUL(ti11, ti4));
+      dr3 = VSUB(cr3, ci4);
+      dr4 = VADD(cr3, ci4);
+      di3 = VADD(ci3, cr4);
+      di4 = VSUB(ci3, cr4);
+      dr5 = VADD(cr2, ci5);
+      dr2 = VSUB(cr2, ci5);
+      di5 = VSUB(ci2, cr5);
+      di2 = VADD(ci2, cr5);
+      wr1=wa1[i], wi1=fsign*wa1[i+1], wr2=wa2[i], wi2=fsign*wa2[i+1]; 
+      wr3=wa3[i], wi3=fsign*wa3[i+1], wr4=wa4[i], wi4=fsign*wa4[i+1]; 
+      VCPLXMUL(dr2, di2, LD_PS1(wr1), LD_PS1(wi1));
+      ch_ref(i - 1, 2) = dr2;
+      ch_ref(i, 2)     = di2;
+      VCPLXMUL(dr3, di3, LD_PS1(wr2), LD_PS1(wi2));
+      ch_ref(i - 1, 3) = dr3;
+      ch_ref(i, 3)     = di3;
+      VCPLXMUL(dr4, di4, LD_PS1(wr3), LD_PS1(wi3));
+      ch_ref(i - 1, 4) = dr4;
+      ch_ref(i, 4)     = di4;
+      VCPLXMUL(dr5, di5, LD_PS1(wr4), LD_PS1(wi4));
+      ch_ref(i - 1, 5) = dr5;
+      ch_ref(i, 5)     = di5;
+    }
+  }
+#undef ch_ref
+#undef cc_ref
+}
+
+static NEVER_INLINE(void) radf2_ps(int ido, int l1, const v4sf * RESTRICT cc, v4sf * RESTRICT ch, const float *wa1) {
+  static const float minus_one = -1.f;
+  int i, k, l1ido = l1*ido;
+  for (k=0; k < l1ido; k += ido) {
+    v4sf a = cc[k], b = cc[k + l1ido];
+    ch[2*k] = VADD(a, b);
+    ch[2*(k+ido)-1] = VSUB(a, b);
+  }
+  if (ido < 2) return;
+  if (ido != 2) {
+    for (k=0; k < l1ido; k += ido) {
+      for (i=2; i<ido; i+=2) {
+        v4sf tr2 = cc[i - 1 + k + l1ido], ti2 = cc[i + k + l1ido];
+        v4sf br = cc[i - 1 + k], bi = cc[i + k];
+        VCPLXMULCONJ(tr2, ti2, LD_PS1(wa1[i - 2]), LD_PS1(wa1[i - 1])); 
+        ch[i + 2*k] = VADD(bi, ti2);
+        ch[2*(k+ido) - i] = VSUB(ti2, bi);
+        ch[i - 1 + 2*k] = VADD(br, tr2);
+        ch[2*(k+ido) - i -1] = VSUB(br, tr2);
+      }
+    }
+    if (ido % 2 == 1) return;
+  }
+  for (k=0; k < l1ido; k += ido) {
+    ch[2*k + ido] = SVMUL(minus_one, cc[ido-1 + k + l1ido]);
+    ch[2*k + ido-1] = cc[k + ido-1];
+  }
+} /* radf2 */
+
+
+static NEVER_INLINE(void) radb2_ps(int ido, int l1, const v4sf *cc, v4sf *ch, const float *wa1) {
+  static const float minus_two=-2;
+  int i, k, l1ido = l1*ido;
+  v4sf a,b,c,d, tr2, ti2;
+  for (k=0; k < l1ido; k += ido) {
+    a = cc[2*k]; b = cc[2*(k+ido) - 1];
+    ch[k] = VADD(a, b);
+    ch[k + l1ido] =VSUB(a, b);
+  }
+  if (ido < 2) return;
+  if (ido != 2) {
+    for (k = 0; k < l1ido; k += ido) {
+      for (i = 2; i < ido; i += 2) {
+        a = cc[i-1 + 2*k]; b = cc[2*(k + ido) - i - 1];
+        c = cc[i+0 + 2*k]; d = cc[2*(k + ido) - i + 0];
+        ch[i-1 + k] = VADD(a, b);
+        tr2 = VSUB(a, b);
+        ch[i+0 + k] = VSUB(c, d);
+        ti2 = VADD(c, d);
+        VCPLXMUL(tr2, ti2, LD_PS1(wa1[i - 2]), LD_PS1(wa1[i - 1]));
+        ch[i-1 + k + l1ido] = tr2;
+        ch[i+0 + k + l1ido] = ti2;
+      }
+    }
+    if (ido % 2 == 1) return;
+  }
+  for (k = 0; k < l1ido; k += ido) {
+    a = cc[2*k + ido-1]; b = cc[2*k + ido];
+    ch[k + ido-1] = VADD(a,a);
+    ch[k + ido-1 + l1ido] = SVMUL(minus_two, b);
+  }
+} /* radb2 */
+
+static void radf3_ps(int ido, int l1, const v4sf * RESTRICT cc, v4sf * RESTRICT ch,
+                     const float *wa1, const float *wa2) {
+  static const float taur = -0.5f;
+  static const float taui = 0.866025403784439f;
+  int i, k, ic;
+  v4sf ci2, di2, di3, cr2, dr2, dr3, ti2, ti3, tr2, tr3, wr1, wi1, wr2, wi2;
+  for (k=0; k<l1; k++) {
+    cr2 = VADD(cc[(k + l1)*ido], cc[(k + 2*l1)*ido]);
+    ch[3*k*ido] = VADD(cc[k*ido], cr2);
+    ch[(3*k+2)*ido] = SVMUL(taui, VSUB(cc[(k + l1*2)*ido], cc[(k + l1)*ido]));
+    ch[ido-1 + (3*k + 1)*ido] = VADD(cc[k*ido], SVMUL(taur, cr2));
+  }
+  if (ido == 1) return;
+  for (k=0; k<l1; k++) {
+    for (i=2; i<ido; i+=2) {
+      ic = ido - i;
+      wr1 = LD_PS1(wa1[i - 2]); wi1 = LD_PS1(wa1[i - 1]);
+      dr2 = cc[i - 1 + (k + l1)*ido]; di2 = cc[i + (k + l1)*ido];
+      VCPLXMULCONJ(dr2, di2, wr1, wi1);
+
+      wr2 = LD_PS1(wa2[i - 2]); wi2 = LD_PS1(wa2[i - 1]);
+      dr3 = cc[i - 1 + (k + l1*2)*ido]; di3 = cc[i + (k + l1*2)*ido];
+      VCPLXMULCONJ(dr3, di3, wr2, wi2);
+        
+      cr2 = VADD(dr2, dr3);
+      ci2 = VADD(di2, di3);
+      ch[i - 1 + 3*k*ido] = VADD(cc[i - 1 + k*ido], cr2);
+      ch[i + 3*k*ido] = VADD(cc[i + k*ido], ci2);
+      tr2 = VADD(cc[i - 1 + k*ido], SVMUL(taur, cr2));
+      ti2 = VADD(cc[i + k*ido], SVMUL(taur, ci2));
+      tr3 = SVMUL(taui, VSUB(di2, di3));
+      ti3 = SVMUL(taui, VSUB(dr3, dr2));
+      ch[i - 1 + (3*k + 2)*ido] = VADD(tr2, tr3);
+      ch[ic - 1 + (3*k + 1)*ido] = VSUB(tr2, tr3);
+      ch[i + (3*k + 2)*ido] = VADD(ti2, ti3);
+      ch[ic + (3*k + 1)*ido] = VSUB(ti3, ti2);
+    }
+  }
+} /* radf3 */
+
+
+static void radb3_ps(int ido, int l1, const v4sf *RESTRICT cc, v4sf *RESTRICT ch,
+                     const float *wa1, const float *wa2)
+{
+  static const float taur = -0.5f;
+  static const float taui = 0.866025403784439f;
+  static const float taui_2 = 0.866025403784439f*2;
+  int i, k, ic;
+  v4sf ci2, ci3, di2, di3, cr2, cr3, dr2, dr3, ti2, tr2;
+  for (k=0; k<l1; k++) {
+    tr2 = cc[ido-1 + (3*k + 1)*ido]; tr2 = VADD(tr2,tr2);
+    cr2 = VMADD(LD_PS1(taur), tr2, cc[3*k*ido]);
+    ch[k*ido] = VADD(cc[3*k*ido], tr2);
+    ci3 = SVMUL(taui_2, cc[(3*k + 2)*ido]);
+    ch[(k + l1)*ido] = VSUB(cr2, ci3);
+    ch[(k + 2*l1)*ido] = VADD(cr2, ci3);
+  }
+  if (ido == 1) return;
+  for (k=0; k<l1; k++) {
+    for (i=2; i<ido; i+=2) {
+      ic = ido - i;
+      tr2 = VADD(cc[i - 1 + (3*k + 2)*ido], cc[ic - 1 + (3*k + 1)*ido]);
+      cr2 = VMADD(LD_PS1(taur), tr2, cc[i - 1 + 3*k*ido]);
+      ch[i - 1 + k*ido] = VADD(cc[i - 1 + 3*k*ido], tr2);
+      ti2 = VSUB(cc[i + (3*k + 2)*ido], cc[ic + (3*k + 1)*ido]);
+      ci2 = VMADD(LD_PS1(taur), ti2, cc[i + 3*k*ido]);
+      ch[i + k*ido] = VADD(cc[i + 3*k*ido], ti2);
+      cr3 = SVMUL(taui, VSUB(cc[i - 1 + (3*k + 2)*ido], cc[ic - 1 + (3*k + 1)*ido]));
+      ci3 = SVMUL(taui, VADD(cc[i + (3*k + 2)*ido], cc[ic + (3*k + 1)*ido]));
+      dr2 = VSUB(cr2, ci3);
+      dr3 = VADD(cr2, ci3);
+      di2 = VADD(ci2, cr3);
+      di3 = VSUB(ci2, cr3);
+      VCPLXMUL(dr2, di2, LD_PS1(wa1[i-2]), LD_PS1(wa1[i-1]));
+      ch[i - 1 + (k + l1)*ido] = dr2;
+      ch[i + (k + l1)*ido] = di2;
+      VCPLXMUL(dr3, di3, LD_PS1(wa2[i-2]), LD_PS1(wa2[i-1]));
+      ch[i - 1 + (k + 2*l1)*ido] = dr3;
+      ch[i + (k + 2*l1)*ido] = di3;
+    }
+  }
+} /* radb3 */
+
+static NEVER_INLINE(void) radf4_ps(int ido, int l1, const v4sf *RESTRICT cc, v4sf * RESTRICT ch,
+                                   const float * RESTRICT wa1, const float * RESTRICT wa2, const float * RESTRICT wa3)
+{
+  static const float minus_hsqt2 = (float)-0.7071067811865475;
+  int i, k, l1ido = l1*ido;
+  {
+    const v4sf *RESTRICT cc_ = cc, * RESTRICT cc_end = cc + l1ido; 
+    v4sf * RESTRICT ch_ = ch;
+    while (cc < cc_end) {
+      // this loop represents between 25% and 40% of total radf4_ps cost !
+      v4sf a0 = cc[0], a1 = cc[l1ido];
+      v4sf a2 = cc[2*l1ido], a3 = cc[3*l1ido];
+      v4sf tr1 = VADD(a1, a3);
+      v4sf tr2 = VADD(a0, a2);
+      ch[2*ido-1] = VSUB(a0, a2);
+      ch[2*ido  ] = VSUB(a3, a1);
+      ch[0      ] = VADD(tr1, tr2);
+      ch[4*ido-1] = VSUB(tr2, tr1);
+      cc += ido; ch += 4*ido;
+    }
+    cc = cc_; ch = ch_;
+  }
+  if (ido < 2) return;
+  if (ido != 2) {
+    for (k = 0; k < l1ido; k += ido) {
+      const v4sf * RESTRICT pc = (v4sf*)(cc + 1 + k);
+      for (i=2; i<ido; i += 2, pc += 2) {
+        int ic = ido - i;
+        v4sf wr, wi, cr2, ci2, cr3, ci3, cr4, ci4;
+        v4sf tr1, ti1, tr2, ti2, tr3, ti3, tr4, ti4;
+
+        cr2 = pc[1*l1ido+0];
+        ci2 = pc[1*l1ido+1];
+        wr=LD_PS1(wa1[i - 2]);
+        wi=LD_PS1(wa1[i - 1]);
+        VCPLXMULCONJ(cr2,ci2,wr,wi);
+
+        cr3 = pc[2*l1ido+0];
+        ci3 = pc[2*l1ido+1];
+        wr = LD_PS1(wa2[i-2]); 
+        wi = LD_PS1(wa2[i-1]);
+        VCPLXMULCONJ(cr3, ci3, wr, wi);
+
+        cr4 = pc[3*l1ido];
+        ci4 = pc[3*l1ido+1];
+        wr = LD_PS1(wa3[i-2]); 
+        wi = LD_PS1(wa3[i-1]);
+        VCPLXMULCONJ(cr4, ci4, wr, wi);
+
+        /* at this point, on SSE, five of "cr2 cr3 cr4 ci2 ci3 ci4" should be loaded in registers */
+
+        tr1 = VADD(cr2,cr4);
+        tr4 = VSUB(cr4,cr2); 
+        tr2 = VADD(pc[0],cr3);
+        tr3 = VSUB(pc[0],cr3);
+        ch[i - 1 + 4*k] = VADD(tr1,tr2);
+        ch[ic - 1 + 4*k + 3*ido] = VSUB(tr2,tr1); // at this point tr1 and tr2 can be disposed
+        ti1 = VADD(ci2,ci4);
+        ti4 = VSUB(ci2,ci4);
+        ch[i - 1 + 4*k + 2*ido] = VADD(ti4,tr3);
+        ch[ic - 1 + 4*k + 1*ido] = VSUB(tr3,ti4); // dispose tr3, ti4
+        ti2 = VADD(pc[1],ci3);
+        ti3 = VSUB(pc[1],ci3);
+        ch[i + 4*k] = VADD(ti1, ti2);
+        ch[ic + 4*k + 3*ido] = VSUB(ti1, ti2);
+        ch[i + 4*k + 2*ido] = VADD(tr4, ti3);
+        ch[ic + 4*k + 1*ido] = VSUB(tr4, ti3);
+      }
+    }
+    if (ido % 2 == 1) return;
+  }
+  for (k=0; k<l1ido; k += ido) {
+    v4sf a = cc[ido-1 + k + l1ido], b = cc[ido-1 + k + 3*l1ido];
+    v4sf c = cc[ido-1 + k], d = cc[ido-1 + k + 2*l1ido];
+    v4sf ti1 = SVMUL(minus_hsqt2, VADD(a, b));
+    v4sf tr1 = SVMUL(minus_hsqt2, VSUB(b, a));
+    ch[ido-1 + 4*k] = VADD(tr1, c);
+    ch[ido-1 + 4*k + 2*ido] = VSUB(c, tr1);
+    ch[4*k + 1*ido] = VSUB(ti1, d); 
+    ch[4*k + 3*ido] = VADD(ti1, d); 
+  }
+} /* radf4 */
+
+
+static NEVER_INLINE(void) radb4_ps(int ido, int l1, const v4sf * RESTRICT cc, v4sf * RESTRICT ch,
+                                   const float * RESTRICT wa1, const float * RESTRICT wa2, const float *RESTRICT wa3)
+{
+  static const float minus_sqrt2 = (float)-1.414213562373095;
+  static const float two = 2.f;
+  int i, k, l1ido = l1*ido;
+  v4sf ci2, ci3, ci4, cr2, cr3, cr4, ti1, ti2, ti3, ti4, tr1, tr2, tr3, tr4;
+  {
+    const v4sf *RESTRICT cc_ = cc, * RESTRICT ch_end = ch + l1ido; 
+    v4sf *ch_ = ch;
+    while (ch < ch_end) {
+      v4sf a = cc[0], b = cc[4*ido-1];
+      v4sf c = cc[2*ido], d = cc[2*ido-1];
+      tr3 = SVMUL(two,d);
+      tr2 = VADD(a,b);
+      tr1 = VSUB(a,b);
+      tr4 = SVMUL(two,c);
+      ch[0*l1ido] = VADD(tr2, tr3);
+      ch[2*l1ido] = VSUB(tr2, tr3);
+      ch[1*l1ido] = VSUB(tr1, tr4);
+      ch[3*l1ido] = VADD(tr1, tr4);
+      
+      cc += 4*ido; ch += ido;
+    }
+    cc = cc_; ch = ch_;
+  }
+  if (ido < 2) return;
+  if (ido != 2) {
+    for (k = 0; k < l1ido; k += ido) {
+      const v4sf * RESTRICT pc = (v4sf*)(cc - 1 + 4*k);
+      v4sf * RESTRICT ph = (v4sf*)(ch + k + 1);
+      for (i = 2; i < ido; i += 2) {
+
+        tr1 = VSUB(pc[i], pc[4*ido - i]);
+        tr2 = VADD(pc[i], pc[4*ido - i]);
+        ti4 = VSUB(pc[2*ido + i], pc[2*ido - i]);
+        tr3 = VADD(pc[2*ido + i], pc[2*ido - i]);
+        ph[0] = VADD(tr2, tr3);
+        cr3 = VSUB(tr2, tr3);
+
+        ti3 = VSUB(pc[2*ido + i + 1], pc[2*ido - i + 1]);
+        tr4 = VADD(pc[2*ido + i + 1], pc[2*ido - i + 1]);
+        cr2 = VSUB(tr1, tr4);
+        cr4 = VADD(tr1, tr4);
+
+        ti1 = VADD(pc[i + 1], pc[4*ido - i + 1]);
+        ti2 = VSUB(pc[i + 1], pc[4*ido - i + 1]);
+
+        ph[1] = VADD(ti2, ti3); ph += l1ido;
+        ci3 = VSUB(ti2, ti3);
+        ci2 = VADD(ti1, ti4);
+        ci4 = VSUB(ti1, ti4);
+        VCPLXMUL(cr2, ci2, LD_PS1(wa1[i-2]), LD_PS1(wa1[i-1]));
+        ph[0] = cr2;
+        ph[1] = ci2; ph += l1ido;
+        VCPLXMUL(cr3, ci3, LD_PS1(wa2[i-2]), LD_PS1(wa2[i-1]));
+        ph[0] = cr3;
+        ph[1] = ci3; ph += l1ido;
+        VCPLXMUL(cr4, ci4, LD_PS1(wa3[i-2]), LD_PS1(wa3[i-1]));
+        ph[0] = cr4;
+        ph[1] = ci4; ph = ph - 3*l1ido + 2;
+      }
+    }
+    if (ido % 2 == 1) return;
+  }
+  for (k=0; k < l1ido; k+=ido) {
+    int i0 = 4*k + ido;
+    v4sf c = cc[i0-1], d = cc[i0 + 2*ido-1];
+    v4sf a = cc[i0+0], b = cc[i0 + 2*ido+0];
+    tr1 = VSUB(c,d);
+    tr2 = VADD(c,d);
+    ti1 = VADD(b,a);
+    ti2 = VSUB(b,a);
+    ch[ido-1 + k + 0*l1ido] = VADD(tr2,tr2);
+    ch[ido-1 + k + 1*l1ido] = SVMUL(minus_sqrt2, VSUB(ti1, tr1));
+    ch[ido-1 + k + 2*l1ido] = VADD(ti2, ti2);
+    ch[ido-1 + k + 3*l1ido] = SVMUL(minus_sqrt2, VADD(ti1, tr1));
+  }
+} /* radb4 */
+
+static void radf5_ps(int ido, int l1, const v4sf * RESTRICT cc, v4sf * RESTRICT ch, 
+                     const float *wa1, const float *wa2, const float *wa3, const float *wa4)
+{
+  static const float tr11 = .309016994374947f;
+  static const float ti11 = .951056516295154f;
+  static const float tr12 = -.809016994374947f;
+  static const float ti12 = .587785252292473f;
+
+  /* System generated locals */
+  int cc_offset, ch_offset;
+
+  /* Local variables */
+  int i, k, ic;
+  v4sf ci2, di2, ci4, ci5, di3, di4, di5, ci3, cr2, cr3, dr2, dr3, dr4, dr5,
+    cr5, cr4, ti2, ti3, ti5, ti4, tr2, tr3, tr4, tr5;
+  int idp2;
+
+
+#define cc_ref(a_1,a_2,a_3) cc[((a_3)*l1 + (a_2))*ido + a_1]
+#define ch_ref(a_1,a_2,a_3) ch[((a_3)*5 + (a_2))*ido + a_1]
+
+  /* Parameter adjustments */
+  ch_offset = 1 + ido * 6;
+  ch -= ch_offset;
+  cc_offset = 1 + ido * (1 + l1);
+  cc -= cc_offset;
+
+  /* Function Body */
+  for (k = 1; k <= l1; ++k) {
+    cr2 = VADD(cc_ref(1, k, 5), cc_ref(1, k, 2));
+    ci5 = VSUB(cc_ref(1, k, 5), cc_ref(1, k, 2));
+    cr3 = VADD(cc_ref(1, k, 4), cc_ref(1, k, 3));
+    ci4 = VSUB(cc_ref(1, k, 4), cc_ref(1, k, 3));
+    ch_ref(1, 1, k) = VADD(cc_ref(1, k, 1), VADD(cr2, cr3));
+    ch_ref(ido, 2, k) = VADD(cc_ref(1, k, 1), VADD(SVMUL(tr11, cr2), SVMUL(tr12, cr3)));
+    ch_ref(1, 3, k) = VADD(SVMUL(ti11, ci5), SVMUL(ti12, ci4));
+    ch_ref(ido, 4, k) = VADD(cc_ref(1, k, 1), VADD(SVMUL(tr12, cr2), SVMUL(tr11, cr3)));
+    ch_ref(1, 5, k) = VSUB(SVMUL(ti12, ci5), SVMUL(ti11, ci4));
+    //printf("pffft: radf5, k=%d ch_ref=%f, ci4=%f\n", k, ch_ref(1, 5, k), ci4);
+  }
+  if (ido == 1) {
+    return;
+  }
+  idp2 = ido + 2;
+  for (k = 1; k <= l1; ++k) {
+    for (i = 3; i <= ido; i += 2) {
+      ic = idp2 - i;
+      dr2 = LD_PS1(wa1[i-3]); di2 = LD_PS1(wa1[i-2]);
+      dr3 = LD_PS1(wa2[i-3]); di3 = LD_PS1(wa2[i-2]);
+      dr4 = LD_PS1(wa3[i-3]); di4 = LD_PS1(wa3[i-2]);
+      dr5 = LD_PS1(wa4[i-3]); di5 = LD_PS1(wa4[i-2]);
+      VCPLXMULCONJ(dr2, di2, cc_ref(i-1, k, 2), cc_ref(i, k, 2));
+      VCPLXMULCONJ(dr3, di3, cc_ref(i-1, k, 3), cc_ref(i, k, 3));
+      VCPLXMULCONJ(dr4, di4, cc_ref(i-1, k, 4), cc_ref(i, k, 4));
+      VCPLXMULCONJ(dr5, di5, cc_ref(i-1, k, 5), cc_ref(i, k, 5));
+      cr2 = VADD(dr2, dr5);
+      ci5 = VSUB(dr5, dr2);
+      cr5 = VSUB(di2, di5);
+      ci2 = VADD(di2, di5);
+      cr3 = VADD(dr3, dr4);
+      ci4 = VSUB(dr4, dr3);
+      cr4 = VSUB(di3, di4);
+      ci3 = VADD(di3, di4);
+      ch_ref(i - 1, 1, k) = VADD(cc_ref(i - 1, k, 1), VADD(cr2, cr3));
+      ch_ref(i, 1, k) = VSUB(cc_ref(i, k, 1), VADD(ci2, ci3));//
+      tr2 = VADD(cc_ref(i - 1, k, 1), VADD(SVMUL(tr11, cr2), SVMUL(tr12, cr3)));
+      ti2 = VSUB(cc_ref(i, k, 1), VADD(SVMUL(tr11, ci2), SVMUL(tr12, ci3)));//
+      tr3 = VADD(cc_ref(i - 1, k, 1), VADD(SVMUL(tr12, cr2), SVMUL(tr11, cr3)));
+      ti3 = VSUB(cc_ref(i, k, 1), VADD(SVMUL(tr12, ci2), SVMUL(tr11, ci3)));//
+      tr5 = VADD(SVMUL(ti11, cr5), SVMUL(ti12, cr4));
+      ti5 = VADD(SVMUL(ti11, ci5), SVMUL(ti12, ci4));
+      tr4 = VSUB(SVMUL(ti12, cr5), SVMUL(ti11, cr4));
+      ti4 = VSUB(SVMUL(ti12, ci5), SVMUL(ti11, ci4));
+      ch_ref(i - 1, 3, k) = VSUB(tr2, tr5);
+      ch_ref(ic - 1, 2, k) = VADD(tr2, tr5);
+      ch_ref(i, 3, k) = VADD(ti2, ti5);
+      ch_ref(ic, 2, k) = VSUB(ti5, ti2);
+      ch_ref(i - 1, 5, k) = VSUB(tr3, tr4);
+      ch_ref(ic - 1, 4, k) = VADD(tr3, tr4);
+      ch_ref(i, 5, k) = VADD(ti3, ti4);
+      ch_ref(ic, 4, k) = VSUB(ti4, ti3);
+    }
+  }
+#undef cc_ref
+#undef ch_ref
+} /* radf5 */
+
+static void radb5_ps(int ido, int l1, const v4sf *RESTRICT cc, v4sf *RESTRICT ch, 
+                  const float *wa1, const float *wa2, const float *wa3, const float *wa4)
+{
+  static const float tr11 = .309016994374947f;
+  static const float ti11 = .951056516295154f;
+  static const float tr12 = -.809016994374947f;
+  static const float ti12 = .587785252292473f;
+
+  int cc_offset, ch_offset;
+
+  /* Local variables */
+  int i, k, ic;
+  v4sf ci2, ci3, ci4, ci5, di3, di4, di5, di2, cr2, cr3, cr5, cr4, ti2, ti3,
+    ti4, ti5, dr3, dr4, dr5, dr2, tr2, tr3, tr4, tr5;
+  int idp2;
+
+#define cc_ref(a_1,a_2,a_3) cc[((a_3)*5 + (a_2))*ido + a_1]
+#define ch_ref(a_1,a_2,a_3) ch[((a_3)*l1 + (a_2))*ido + a_1]
+
+  /* Parameter adjustments */
+  ch_offset = 1 + ido * (1 + l1);
+  ch -= ch_offset;
+  cc_offset = 1 + ido * 6;
+  cc -= cc_offset;
+
+  /* Function Body */
+  for (k = 1; k <= l1; ++k) {
+    ti5 = VADD(cc_ref(1, 3, k), cc_ref(1, 3, k));
+    ti4 = VADD(cc_ref(1, 5, k), cc_ref(1, 5, k));
+    tr2 = VADD(cc_ref(ido, 2, k), cc_ref(ido, 2, k));
+    tr3 = VADD(cc_ref(ido, 4, k), cc_ref(ido, 4, k));
+    ch_ref(1, k, 1) = VADD(cc_ref(1, 1, k), VADD(tr2, tr3));
+    cr2 = VADD(cc_ref(1, 1, k), VADD(SVMUL(tr11, tr2), SVMUL(tr12, tr3)));
+    cr3 = VADD(cc_ref(1, 1, k), VADD(SVMUL(tr12, tr2), SVMUL(tr11, tr3)));
+    ci5 = VADD(SVMUL(ti11, ti5), SVMUL(ti12, ti4));
+    ci4 = VSUB(SVMUL(ti12, ti5), SVMUL(ti11, ti4));
+    ch_ref(1, k, 2) = VSUB(cr2, ci5);
+    ch_ref(1, k, 3) = VSUB(cr3, ci4);
+    ch_ref(1, k, 4) = VADD(cr3, ci4);
+    ch_ref(1, k, 5) = VADD(cr2, ci5);
+  }
+  if (ido == 1) {
+    return;
+  }
+  idp2 = ido + 2;
+  for (k = 1; k <= l1; ++k) {
+    for (i = 3; i <= ido; i += 2) {
+      ic = idp2 - i;
+      ti5 = VADD(cc_ref(i  , 3, k), cc_ref(ic  , 2, k));
+      ti2 = VSUB(cc_ref(i  , 3, k), cc_ref(ic  , 2, k));
+      ti4 = VADD(cc_ref(i  , 5, k), cc_ref(ic  , 4, k));
+      ti3 = VSUB(cc_ref(i  , 5, k), cc_ref(ic  , 4, k));
+      tr5 = VSUB(cc_ref(i-1, 3, k), cc_ref(ic-1, 2, k));
+      tr2 = VADD(cc_ref(i-1, 3, k), cc_ref(ic-1, 2, k));
+      tr4 = VSUB(cc_ref(i-1, 5, k), cc_ref(ic-1, 4, k));
+      tr3 = VADD(cc_ref(i-1, 5, k), cc_ref(ic-1, 4, k));
+      ch_ref(i - 1, k, 1) = VADD(cc_ref(i-1, 1, k), VADD(tr2, tr3));
+      ch_ref(i, k, 1) = VADD(cc_ref(i, 1, k), VADD(ti2, ti3));
+      cr2 = VADD(cc_ref(i-1, 1, k), VADD(SVMUL(tr11, tr2), SVMUL(tr12, tr3)));
+      ci2 = VADD(cc_ref(i  , 1, k), VADD(SVMUL(tr11, ti2), SVMUL(tr12, ti3)));
+      cr3 = VADD(cc_ref(i-1, 1, k), VADD(SVMUL(tr12, tr2), SVMUL(tr11, tr3)));
+      ci3 = VADD(cc_ref(i  , 1, k), VADD(SVMUL(tr12, ti2), SVMUL(tr11, ti3)));
+      cr5 = VADD(SVMUL(ti11, tr5), SVMUL(ti12, tr4));
+      ci5 = VADD(SVMUL(ti11, ti5), SVMUL(ti12, ti4));
+      cr4 = VSUB(SVMUL(ti12, tr5), SVMUL(ti11, tr4));
+      ci4 = VSUB(SVMUL(ti12, ti5), SVMUL(ti11, ti4));
+      dr3 = VSUB(cr3, ci4);
+      dr4 = VADD(cr3, ci4);
+      di3 = VADD(ci3, cr4);
+      di4 = VSUB(ci3, cr4);
+      dr5 = VADD(cr2, ci5);
+      dr2 = VSUB(cr2, ci5);
+      di5 = VSUB(ci2, cr5);
+      di2 = VADD(ci2, cr5);
+      VCPLXMUL(dr2, di2, LD_PS1(wa1[i-3]), LD_PS1(wa1[i-2]));
+      VCPLXMUL(dr3, di3, LD_PS1(wa2[i-3]), LD_PS1(wa2[i-2]));
+      VCPLXMUL(dr4, di4, LD_PS1(wa3[i-3]), LD_PS1(wa3[i-2]));
+      VCPLXMUL(dr5, di5, LD_PS1(wa4[i-3]), LD_PS1(wa4[i-2]));
+
+      ch_ref(i-1, k, 2) = dr2; ch_ref(i, k, 2) = di2;
+      ch_ref(i-1, k, 3) = dr3; ch_ref(i, k, 3) = di3;
+      ch_ref(i-1, k, 4) = dr4; ch_ref(i, k, 4) = di4;
+      ch_ref(i-1, k, 5) = dr5; ch_ref(i, k, 5) = di5;
+    }
+  }
+#undef cc_ref
+#undef ch_ref
+} /* radb5 */
+
+static NEVER_INLINE(v4sf *) rfftf1_ps(int n, const v4sf *input_readonly, v4sf *work1, v4sf *work2, 
+                                      const float *wa, const int *ifac) {  
+  v4sf *in  = (v4sf*)input_readonly;
+  v4sf *out = (in == work2 ? work1 : work2);
+  int nf = ifac[1], k1;
+  int l2 = n;
+  int iw = n-1;
+  assert(in != out && work1 != work2);
+  for (k1 = 1; k1 <= nf; ++k1) {
+    int kh = nf - k1;
+    int ip = ifac[kh + 2];
+    int l1 = l2 / ip;
+    int ido = n / l2;
+    iw -= (ip - 1)*ido;
+    switch (ip) {
+      case 5: {
+        int ix2 = iw + ido;
+        int ix3 = ix2 + ido;
+        int ix4 = ix3 + ido;
+        radf5_ps(ido, l1, in, out, &wa[iw], &wa[ix2], &wa[ix3], &wa[ix4]);
+      } break;
+      case 4: {
+        int ix2 = iw + ido;
+        int ix3 = ix2 + ido;
+        radf4_ps(ido, l1, in, out, &wa[iw], &wa[ix2], &wa[ix3]);
+      } break;
+      case 3: {
+        int ix2 = iw + ido;
+        radf3_ps(ido, l1, in, out, &wa[iw], &wa[ix2]);
+      } break;
+      case 2:
+        radf2_ps(ido, l1, in, out, &wa[iw]);
+        break;
+      default:
+        assert(0);
+        break;
+    }
+    l2 = l1;
+    if (out == work2) {
+      out = work1; in = work2;
+    } else {
+      out = work2; in = work1;
+    }
+  }
+  return in; /* this is in fact the output .. */
+} /* rfftf1 */
+
+static NEVER_INLINE(v4sf *) rfftb1_ps(int n, const v4sf *input_readonly, v4sf *work1, v4sf *work2, 
+                                      const float *wa, const int *ifac) {  
+  v4sf *in  = (v4sf*)input_readonly;
+  v4sf *out = (in == work2 ? work1 : work2);
+  int nf = ifac[1], k1;
+  int l1 = 1;
+  int iw = 0;
+  assert(in != out);
+  for (k1=1; k1<=nf; k1++) {
+    int ip = ifac[k1 + 1];
+    int l2 = ip*l1;
+    int ido = n / l2;
+    switch (ip) {
+      case 5: {
+        int ix2 = iw + ido;
+        int ix3 = ix2 + ido;
+        int ix4 = ix3 + ido;
+        radb5_ps(ido, l1, in, out, &wa[iw], &wa[ix2], &wa[ix3], &wa[ix4]);
+      } break;
+      case 4: {
+        int ix2 = iw + ido;
+        int ix3 = ix2 + ido;
+        radb4_ps(ido, l1, in, out, &wa[iw], &wa[ix2], &wa[ix3]);
+      } break;
+      case 3: {
+        int ix2 = iw + ido;
+        radb3_ps(ido, l1, in, out, &wa[iw], &wa[ix2]);
+      } break;
+      case 2:
+        radb2_ps(ido, l1, in, out, &wa[iw]);
+        break;
+      default:
+        assert(0);
+        break;
+    }
+    l1 = l2;
+    iw += (ip - 1)*ido;
+
+    if (out == work2) {
+      out = work1; in = work2;
+    } else {
+      out = work2; in = work1;
+    }
+  }
+  return in; /* this is in fact the output .. */
+}
+
+static int decompose(int n, int *ifac, const int *ntryh) {
+  int nl = n, nf = 0, i, j = 0;
+  for (j=0; ntryh[j]; ++j) {
+    int ntry = ntryh[j];
+    while (nl != 1) {
+      int nq = nl / ntry;
+      int nr = nl - ntry * nq;
+      if (nr == 0) {
+        ifac[2+nf++] = ntry;
+        nl = nq;
+        if (ntry == 2 && nf != 1) {
+          for (i = 2; i <= nf; ++i) {
+            int ib = nf - i + 2;
+            ifac[ib + 1] = ifac[ib];
+          }
+          ifac[2] = 2;
+        }
+      } else break;
+    }
+  }
+  ifac[0] = n;
+  ifac[1] = nf;  
+  return nf;
+}
+
+
+
+static void rffti1_ps(int n, float *wa, int *ifac)
+{
+  static const int ntryh[] = { 4,2,3,5,0 };
+  int k1, j, ii;
+
+  int nf = decompose(n,ifac,ntryh);
+  float argh = (2*M_PI) / n;
+  int is = 0;
+  int nfm1 = nf - 1;
+  int l1 = 1;
+  for (k1 = 1; k1 <= nfm1; k1++) {
+    int ip = ifac[k1 + 1];
+    int ld = 0;
+    int l2 = l1*ip;
+    int ido = n / l2;
+    int ipm = ip - 1;
+    for (j = 1; j <= ipm; ++j) {
+      float argld;
+      int i = is, fi=0;
+      ld += l1;
+      argld = ld*argh;
+      for (ii = 3; ii <= ido; ii += 2) {
+        i += 2;
+        fi += 1;
+        wa[i - 2] = cos(fi*argld);
+        wa[i - 1] = sin(fi*argld);
+      }
+      is += ido;
+    }
+    l1 = l2;
+  }
+} /* rffti1 */
+
+void cffti1_ps(int n, float *wa, int *ifac)
+{
+  static const int ntryh[] = { 5,3,4,2,0 };
+  int k1, j, ii;
+
+  int nf = decompose(n,ifac,ntryh);
+  float argh = (2*M_PI)/(float)n;
+  int i = 1;
+  int l1 = 1;
+  for (k1=1; k1<=nf; k1++) {
+    int ip = ifac[k1+1];
+    int ld = 0;
+    int l2 = l1*ip;
+    int ido = n / l2;
+    int idot = ido + ido + 2;
+    int ipm = ip - 1;
+    for (j=1; j<=ipm; j++) {
+      float argld;
+      int i1 = i, fi = 0;
+      wa[i-1] = 1;
+      wa[i] = 0;
+      ld += l1;
+      argld = ld*argh;
+      for (ii = 4; ii <= idot; ii += 2) {
+        i += 2;
+        fi += 1;
+        wa[i-1] = cos(fi*argld);
+        wa[i] = sin(fi*argld);
+      }
+      if (ip > 5) {
+        wa[i1-1] = wa[i-1];
+        wa[i1] = wa[i];
+      }
+    }
+    l1 = l2;
+  }
+} /* cffti1 */
+
+
+v4sf *cfftf1_ps(int n, const v4sf *input_readonly, v4sf *work1, v4sf *work2, const float *wa, const int *ifac, int isign) {
+  v4sf *in  = (v4sf*)input_readonly;
+  v4sf *out = (in == work2 ? work1 : work2); 
+  int nf = ifac[1], k1;
+  int l1 = 1;
+  int iw = 0;
+  assert(in != out && work1 != work2);
+  for (k1=2; k1<=nf+1; k1++) {
+    int ip = ifac[k1];
+    int l2 = ip*l1;
+    int ido = n / l2;
+    int idot = ido + ido;
+    switch (ip) {
+      case 5: {
+        int ix2 = iw + idot;
+        int ix3 = ix2 + idot;
+        int ix4 = ix3 + idot;
+        passf5_ps(idot, l1, in, out, &wa[iw], &wa[ix2], &wa[ix3], &wa[ix4], isign);
+      } break;
+      case 4: {
+        int ix2 = iw + idot;
+        int ix3 = ix2 + idot;
+        passf4_ps(idot, l1, in, out, &wa[iw], &wa[ix2], &wa[ix3], isign);
+      } break;
+      case 2: {
+        passf2_ps(idot, l1, in, out, &wa[iw], isign);
+      } break;
+      case 3: {
+        int ix2 = iw + idot;
+        passf3_ps(idot, l1, in, out, &wa[iw], &wa[ix2], isign);
+      } break;
+      default:
+        assert(0);
+    }
+    l1 = l2;
+    iw += (ip - 1)*idot;
+    if (out == work2) {
+      out = work1; in = work2;
+    } else {
+      out = work2; in = work1;
+    }
+  }
+
+  return in; /* this is in fact the output .. */
+}
+
+
+struct PFFFT_Setup {
+  int     N;
+  int     Ncvec; // nb of complex simd vectors (N/4 if PFFFT_COMPLEX, N/8 if PFFFT_REAL)
+  int ifac[15];
+  pffft_transform_t transform;
+  v4sf *data; // allocated room for twiddle coefs
+  float *e;    // points into 'data' , N/4*3 elements
+  float *twiddle; // points into 'data', N/4 elements
+};
+
+PFFFT_Setup *pffft_new_setup(int N, pffft_transform_t transform) {
+  PFFFT_Setup *s = (PFFFT_Setup*)malloc(sizeof(PFFFT_Setup));
+  int k, m;
+  /* unfortunately, the fft size must be a multiple of 16 for complex FFTs 
+     and 32 for real FFTs -- a lot of stuff would need to be rewritten to
+     handle other cases (or maybe just switch to a scalar fft, I don't know..) */
+  if (transform == PFFFT_REAL) { assert((N%(2*SIMD_SZ*SIMD_SZ))==0 && N>0); }
+  if (transform == PFFFT_COMPLEX) { assert((N%(SIMD_SZ*SIMD_SZ))==0 && N>0); }
+  //assert((N % 32) == 0);
+  s->N = N;
+  s->transform = transform;  
+  /* nb of complex simd vectors */
+  s->Ncvec = (transform == PFFFT_REAL ? N/2 : N)/SIMD_SZ;
+  s->data = (v4sf*)pffft_aligned_malloc(2*s->Ncvec * sizeof(v4sf));
+  s->e = (float*)s->data;
+  s->twiddle = (float*)(s->data + (2*s->Ncvec*(SIMD_SZ-1))/SIMD_SZ);  
+
+  if (transform == PFFFT_REAL) {
+    for (k=0; k < s->Ncvec; ++k) {
+      int i = k/SIMD_SZ;
+      int j = k%SIMD_SZ;
+      for (m=0; m < SIMD_SZ-1; ++m) {
+        float A = -2*M_PI*(m+1)*k / N;
+        s->e[(2*(i*3 + m) + 0) * SIMD_SZ + j] = cos(A);
+        s->e[(2*(i*3 + m) + 1) * SIMD_SZ + j] = sin(A);
+      }
+    }
+    rffti1_ps(N/SIMD_SZ, s->twiddle, s->ifac);
+  } else {
+    for (k=0; k < s->Ncvec; ++k) {
+      int i = k/SIMD_SZ;
+      int j = k%SIMD_SZ;
+      for (m=0; m < SIMD_SZ-1; ++m) {
+        float A = -2*M_PI*(m+1)*k / N;
+        s->e[(2*(i*3 + m) + 0)*SIMD_SZ + j] = cos(A);
+        s->e[(2*(i*3 + m) + 1)*SIMD_SZ + j] = sin(A);
+      }
+    }
+    cffti1_ps(N/SIMD_SZ, s->twiddle, s->ifac);
+  }
+
+  /* check that N is decomposable with allowed prime factors */
+  for (k=0, m=1; k < s->ifac[1]; ++k) { m *= s->ifac[2+k]; }
+  if (m != N/SIMD_SZ) {
+    pffft_destroy_setup(s); s = 0;
+  }
+
+  return s;
+}
+
+
+void pffft_destroy_setup(PFFFT_Setup *s) {
+  pffft_aligned_free(s->data);
+  free(s);
+}
+
+#if !defined(PFFFT_SIMD_DISABLE)
+
+/* [0 0 1 2 3 4 5 6 7 8] -> [0 8 7 6 5 4 3 2 1] */
+static void reversed_copy(int N, const v4sf *in, int in_stride, v4sf *out) {
+  v4sf g0, g1;
+  int k;
+  INTERLEAVE2(in[0], in[1], g0, g1); in += in_stride;
+  
+  *--out = VSWAPHL(g0, g1); // [g0l, g0h], [g1l g1h] -> [g1l, g0h]
+  for (k=1; k < N; ++k) {
+    v4sf h0, h1;
+    INTERLEAVE2(in[0], in[1], h0, h1); in += in_stride;
+    *--out = VSWAPHL(g1, h0);
+    *--out = VSWAPHL(h0, h1);
+    g1 = h1;
+  }
+  *--out = VSWAPHL(g1, g0);
+}
+
+static void unreversed_copy(int N, const v4sf *in, v4sf *out, int out_stride) {
+  v4sf g0, g1, h0, h1;
+  int k;
+  g0 = g1 = in[0]; ++in;
+  for (k=1; k < N; ++k) {
+    h0 = *in++; h1 = *in++;
+    g1 = VSWAPHL(g1, h0);
+    h0 = VSWAPHL(h0, h1);
+    UNINTERLEAVE2(h0, g1, out[0], out[1]); out += out_stride;
+    g1 = h1;
+  }
+  h0 = *in++; h1 = g0;
+  g1 = VSWAPHL(g1, h0);
+  h0 = VSWAPHL(h0, h1);
+  UNINTERLEAVE2(h0, g1, out[0], out[1]);
+}
+
+void pffft_zreorder(PFFFT_Setup *setup, const float *in, float *out, pffft_direction_t direction) {
+  int k, N = setup->N, Ncvec = setup->Ncvec;
+  const v4sf *vin = (const v4sf*)in;
+  v4sf *vout = (v4sf*)out;
+  assert(in != out);
+  if (setup->transform == PFFFT_REAL) {
+    int k, dk = N/32;
+    if (direction == PFFFT_FORWARD) {
+      for (k=0; k < dk; ++k) {
+        INTERLEAVE2(vin[k*8 + 0], vin[k*8 + 1], vout[2*(0*dk + k) + 0], vout[2*(0*dk + k) + 1]);
+        INTERLEAVE2(vin[k*8 + 4], vin[k*8 + 5], vout[2*(2*dk + k) + 0], vout[2*(2*dk + k) + 1]);
+      }
+      reversed_copy(dk, vin+2, 8, (v4sf*)(out + N/2));
+      reversed_copy(dk, vin+6, 8, (v4sf*)(out + N));
+    } else {
+      for (k=0; k < dk; ++k) {
+        UNINTERLEAVE2(vin[2*(0*dk + k) + 0], vin[2*(0*dk + k) + 1], vout[k*8 + 0], vout[k*8 + 1]);
+        UNINTERLEAVE2(vin[2*(2*dk + k) + 0], vin[2*(2*dk + k) + 1], vout[k*8 + 4], vout[k*8 + 5]);
+      }
+      unreversed_copy(dk, (v4sf*)(in + N/4), (v4sf*)(out + N - 6*SIMD_SZ), -8);
+      unreversed_copy(dk, (v4sf*)(in + 3*N/4), (v4sf*)(out + N - 2*SIMD_SZ), -8);
+    }
+  } else {
+    if (direction == PFFFT_FORWARD) {
+      for (k=0; k < Ncvec; ++k) { 
+        int kk = (k/4) + (k%4)*(Ncvec/4);
+        INTERLEAVE2(vin[k*2], vin[k*2+1], vout[kk*2], vout[kk*2+1]);
+      }
+    } else {
+      for (k=0; k < Ncvec; ++k) { 
+        int kk = (k/4) + (k%4)*(Ncvec/4);
+        UNINTERLEAVE2(vin[kk*2], vin[kk*2+1], vout[k*2], vout[k*2+1]);
+      }
+    }
+  }
+}
+
+void pffft_cplx_finalize(int Ncvec, const v4sf *in, v4sf *out, const v4sf *e) {
+  int k, dk = Ncvec/SIMD_SZ; // number of 4x4 matrix blocks
+  v4sf r0, i0, r1, i1, r2, i2, r3, i3;
+  v4sf sr0, dr0, sr1, dr1, si0, di0, si1, di1;
+  assert(in != out);
+  for (k=0; k < dk; ++k) {    
+    r0 = in[8*k+0]; i0 = in[8*k+1];
+    r1 = in[8*k+2]; i1 = in[8*k+3];
+    r2 = in[8*k+4]; i2 = in[8*k+5];
+    r3 = in[8*k+6]; i3 = in[8*k+7];
+    VTRANSPOSE4(r0,r1,r2,r3);
+    VTRANSPOSE4(i0,i1,i2,i3);
+    VCPLXMUL(r1,i1,e[k*6+0],e[k*6+1]);
+    VCPLXMUL(r2,i2,e[k*6+2],e[k*6+3]);
+    VCPLXMUL(r3,i3,e[k*6+4],e[k*6+5]);
+
+    sr0 = VADD(r0,r2); dr0 = VSUB(r0, r2);
+    sr1 = VADD(r1,r3); dr1 = VSUB(r1, r3);
+    si0 = VADD(i0,i2); di0 = VSUB(i0, i2);
+    si1 = VADD(i1,i3); di1 = VSUB(i1, i3);
+
+    /*
+      transformation for each column is:
+      
+      [1   1   1   1   0   0   0   0]   [r0]
+      [1   0  -1   0   0  -1   0   1]   [r1]
+      [1  -1   1  -1   0   0   0   0]   [r2]
+      [1   0  -1   0   0   1   0  -1]   [r3]
+      [0   0   0   0   1   1   1   1] * [i0]
+      [0   1   0  -1   1   0  -1   0]   [i1]
+      [0   0   0   0   1  -1   1  -1]   [i2]
+      [0  -1   0   1   1   0  -1   0]   [i3]    
+    */
+    
+    r0 = VADD(sr0, sr1); i0 = VADD(si0, si1);
+    r1 = VADD(dr0, di1); i1 = VSUB(di0, dr1);
+    r2 = VSUB(sr0, sr1); i2 = VSUB(si0, si1);
+    r3 = VSUB(dr0, di1); i3 = VADD(di0, dr1);
+  
+    *out++ = r0; *out++ = i0; *out++ = r1; *out++ = i1;
+    *out++ = r2; *out++ = i2; *out++ = r3; *out++ = i3;
+  }
+}
+
+void pffft_cplx_preprocess(int Ncvec, const v4sf *in, v4sf *out, const v4sf *e) {
+  int k, dk = Ncvec/SIMD_SZ; // number of 4x4 matrix blocks
+  v4sf r0, i0, r1, i1, r2, i2, r3, i3;
+  v4sf sr0, dr0, sr1, dr1, si0, di0, si1, di1;
+  assert(in != out);
+  for (k=0; k < dk; ++k) {    
+    r0 = in[8*k+0]; i0 = in[8*k+1];
+    r1 = in[8*k+2]; i1 = in[8*k+3];
+    r2 = in[8*k+4]; i2 = in[8*k+5];
+    r3 = in[8*k+6]; i3 = in[8*k+7];
+
+    sr0 = VADD(r0,r2); dr0 = VSUB(r0, r2);
+    sr1 = VADD(r1,r3); dr1 = VSUB(r1, r3);
+    si0 = VADD(i0,i2); di0 = VSUB(i0, i2);
+    si1 = VADD(i1,i3); di1 = VSUB(i1, i3);
+
+    r0 = VADD(sr0, sr1); i0 = VADD(si0, si1);
+    r1 = VSUB(dr0, di1); i1 = VADD(di0, dr1);
+    r2 = VSUB(sr0, sr1); i2 = VSUB(si0, si1);
+    r3 = VADD(dr0, di1); i3 = VSUB(di0, dr1);
+
+    VCPLXMULCONJ(r1,i1,e[k*6+0],e[k*6+1]);
+    VCPLXMULCONJ(r2,i2,e[k*6+2],e[k*6+3]);
+    VCPLXMULCONJ(r3,i3,e[k*6+4],e[k*6+5]);
+
+    VTRANSPOSE4(r0,r1,r2,r3);
+    VTRANSPOSE4(i0,i1,i2,i3);
+
+    *out++ = r0; *out++ = i0; *out++ = r1; *out++ = i1;
+    *out++ = r2; *out++ = i2; *out++ = r3; *out++ = i3;
+  }
+}
+
+
+static ALWAYS_INLINE(void) pffft_real_finalize_4x4(const v4sf *in0, const v4sf *in1, const v4sf *in,
+                            const v4sf *e, v4sf *out) {
+  v4sf r0, i0, r1, i1, r2, i2, r3, i3;
+  v4sf sr0, dr0, sr1, dr1, si0, di0, si1, di1;
+  r0 = *in0; i0 = *in1;
+  r1 = *in++; i1 = *in++; r2 = *in++; i2 = *in++; r3 = *in++; i3 = *in++;
+  VTRANSPOSE4(r0,r1,r2,r3);
+  VTRANSPOSE4(i0,i1,i2,i3);
+ 
+  /*
+    transformation for each column is:
+
+    [1   1   1   1   0   0   0   0]   [r0]
+    [1   0  -1   0   0  -1   0   1]   [r1]
+    [1   0  -1   0   0   1   0  -1]   [r2]
+    [1  -1   1  -1   0   0   0   0]   [r3]
+    [0   0   0   0   1   1   1   1] * [i0]
+    [0  -1   0   1  -1   0   1   0]   [i1]
+    [0  -1   0   1   1   0  -1   0]   [i2]
+    [0   0   0   0  -1   1  -1   1]   [i3]    
+  */
+  
+  //cerr << "matrix initial, before e , REAL:\n 1: " << r0 << "\n 1: " << r1 << "\n 1: " << r2 << "\n 1: " << r3 << "\n";
+  //cerr << "matrix initial, before e, IMAG :\n 1: " << i0 << "\n 1: " << i1 << "\n 1: " << i2 << "\n 1: " << i3 << "\n";
+
+  VCPLXMUL(r1,i1,e[0],e[1]);
+  VCPLXMUL(r2,i2,e[2],e[3]);
+  VCPLXMUL(r3,i3,e[4],e[5]);
+
+  //cerr << "matrix initial, real part:\n 1: " << r0 << "\n 1: " << r1 << "\n 1: " << r2 << "\n 1: " << r3 << "\n";
+  //cerr << "matrix initial, imag part:\n 1: " << i0 << "\n 1: " << i1 << "\n 1: " << i2 << "\n 1: " << i3 << "\n";
+
+  sr0 = VADD(r0,r2); dr0 = VSUB(r0,r2); 
+  sr1 = VADD(r1,r3); dr1 = VSUB(r3,r1);
+  si0 = VADD(i0,i2); di0 = VSUB(i0,i2); 
+  si1 = VADD(i1,i3); di1 = VSUB(i3,i1);
+
+  r0 = VADD(sr0, sr1);
+  r3 = VSUB(sr0, sr1);
+  i0 = VADD(si0, si1);
+  i3 = VSUB(si1, si0);
+  r1 = VADD(dr0, di1);
+  r2 = VSUB(dr0, di1);
+  i1 = VSUB(dr1, di0);
+  i2 = VADD(dr1, di0);
+
+  *out++ = r0;
+  *out++ = i0;
+  *out++ = r1;
+  *out++ = i1;
+  *out++ = r2;
+  *out++ = i2;
+  *out++ = r3;
+  *out++ = i3;
+
+}
+
+static NEVER_INLINE(void) pffft_real_finalize(int Ncvec, const v4sf *in, v4sf *out, const v4sf *e) {
+  int k, dk = Ncvec/SIMD_SZ; // number of 4x4 matrix blocks
+  /* fftpack order is f0r f1r f1i f2r f2i ... f(n-1)r f(n-1)i f(n)r */
+
+  v4sf_union cr, ci, *uout = (v4sf_union*)out;
+  v4sf save = in[7], zero=VZERO();
+  float xr0, xi0, xr1, xi1, xr2, xi2, xr3, xi3;
+  static const float s = M_SQRT2/2;
+
+  cr.v = in[0]; ci.v = in[Ncvec*2-1];
+  assert(in != out);
+  pffft_real_finalize_4x4(&zero, &zero, in+1, e, out);
+
+  /*
+    [cr0 cr1 cr2 cr3 ci0 ci1 ci2 ci3]
+
+    [Xr(1)]  ] [1   1   1   1   0   0   0   0]
+    [Xr(N/4) ] [0   0   0   0   1   s   0  -s]
+    [Xr(N/2) ] [1   0  -1   0   0   0   0   0]
+    [Xr(3N/4)] [0   0   0   0   1  -s   0   s]
+    [Xi(1)   ] [1  -1   1  -1   0   0   0   0]
+    [Xi(N/4) ] [0   0   0   0   0  -s  -1  -s]
+    [Xi(N/2) ] [0  -1   0   1   0   0   0   0]
+    [Xi(3N/4)] [0   0   0   0   0  -s   1  -s]
+  */
+
+  xr0=(cr.f[0]+cr.f[2]) + (cr.f[1]+cr.f[3]); uout[0].f[0] = xr0;
+  xi0=(cr.f[0]+cr.f[2]) - (cr.f[1]+cr.f[3]); uout[1].f[0] = xi0;
+  xr2=(cr.f[0]-cr.f[2]);                     uout[4].f[0] = xr2;
+  xi2=(cr.f[3]-cr.f[1]);                     uout[5].f[0] = xi2;
+  xr1= ci.f[0] + s*(ci.f[1]-ci.f[3]);        uout[2].f[0] = xr1;
+  xi1=-ci.f[2] - s*(ci.f[1]+ci.f[3]);        uout[3].f[0] = xi1;
+  xr3= ci.f[0] - s*(ci.f[1]-ci.f[3]);        uout[6].f[0] = xr3;
+  xi3= ci.f[2] - s*(ci.f[1]+ci.f[3]);        uout[7].f[0] = xi3; 
+
+  for (k=1; k < dk; ++k) {
+    v4sf save_next = in[8*k+7];
+    pffft_real_finalize_4x4(&save, &in[8*k+0], in + 8*k+1,
+                           e + k*6, out + k*8);
+    save = save_next;
+  }
+
+}
+
+static ALWAYS_INLINE(void) pffft_real_preprocess_4x4(const v4sf *in, 
+                                             const v4sf *e, v4sf *out, int first) {
+  v4sf r0=in[0], i0=in[1], r1=in[2], i1=in[3], r2=in[4], i2=in[5], r3=in[6], i3=in[7];
+  /*
+    transformation for each column is:
+
+    [1   1   1   1   0   0   0   0]   [r0]
+    [1   0   0  -1   0  -1  -1   0]   [r1]
+    [1  -1  -1   1   0   0   0   0]   [r2]
+    [1   0   0  -1   0   1   1   0]   [r3]
+    [0   0   0   0   1  -1   1  -1] * [i0]
+    [0  -1   1   0   1   0   0   1]   [i1]
+    [0   0   0   0   1   1  -1  -1]   [i2]
+    [0   1  -1   0   1   0   0   1]   [i3]    
+  */
+
+  v4sf sr0 = VADD(r0,r3), dr0 = VSUB(r0,r3); 
+  v4sf sr1 = VADD(r1,r2), dr1 = VSUB(r1,r2);
+  v4sf si0 = VADD(i0,i3), di0 = VSUB(i0,i3); 
+  v4sf si1 = VADD(i1,i2), di1 = VSUB(i1,i2);
+
+  r0 = VADD(sr0, sr1);
+  r2 = VSUB(sr0, sr1);
+  r1 = VSUB(dr0, si1);
+  r3 = VADD(dr0, si1);
+  i0 = VSUB(di0, di1);
+  i2 = VADD(di0, di1);
+  i1 = VSUB(si0, dr1);
+  i3 = VADD(si0, dr1);
+
+  VCPLXMULCONJ(r1,i1,e[0],e[1]);
+  VCPLXMULCONJ(r2,i2,e[2],e[3]);
+  VCPLXMULCONJ(r3,i3,e[4],e[5]);
+
+  VTRANSPOSE4(r0,r1,r2,r3);
+  VTRANSPOSE4(i0,i1,i2,i3);
+
+  if (!first) {
+    *out++ = r0;
+    *out++ = i0;
+  }
+  *out++ = r1;
+  *out++ = i1;
+  *out++ = r2;
+  *out++ = i2;
+  *out++ = r3;
+  *out++ = i3;
+}
+
+static NEVER_INLINE(void) pffft_real_preprocess(int Ncvec, const v4sf *in, v4sf *out, const v4sf *e) {
+  int k, dk = Ncvec/SIMD_SZ; // number of 4x4 matrix blocks
+  /* fftpack order is f0r f1r f1i f2r f2i ... f(n-1)r f(n-1)i f(n)r */
+
+  v4sf_union Xr, Xi, *uout = (v4sf_union*)out;
+  float cr0, ci0, cr1, ci1, cr2, ci2, cr3, ci3;
+  static const float s = M_SQRT2;
+  assert(in != out);
+  for (k=0; k < 4; ++k) {
+    Xr.f[k] = ((float*)in)[8*k];
+    Xi.f[k] = ((float*)in)[8*k+4];
+  }
+
+  pffft_real_preprocess_4x4(in, e, out+1, 1); // will write only 6 values
+
+  /*
+    [Xr0 Xr1 Xr2 Xr3 Xi0 Xi1 Xi2 Xi3]
+
+    [cr0] [1   0   2   0   1   0   0   0]
+    [cr1] [1   0   0   0  -1   0  -2   0]
+    [cr2] [1   0  -2   0   1   0   0   0]
+    [cr3] [1   0   0   0  -1   0   2   0]
+    [ci0] [0   2   0   2   0   0   0   0]
+    [ci1] [0   s   0  -s   0  -s   0  -s]
+    [ci2] [0   0   0   0   0  -2   0   2]
+    [ci3] [0  -s   0   s   0  -s   0  -s]
+  */
+  for (k=1; k < dk; ++k) {    
+    pffft_real_preprocess_4x4(in+8*k, e + k*6, out-1+k*8, 0);
+  }
+
+  cr0=(Xr.f[0]+Xi.f[0]) + 2*Xr.f[2]; uout[0].f[0] = cr0;
+  cr1=(Xr.f[0]-Xi.f[0]) - 2*Xi.f[2]; uout[0].f[1] = cr1;
+  cr2=(Xr.f[0]+Xi.f[0]) - 2*Xr.f[2]; uout[0].f[2] = cr2;
+  cr3=(Xr.f[0]-Xi.f[0]) + 2*Xi.f[2]; uout[0].f[3] = cr3;
+  ci0= 2*(Xr.f[1]+Xr.f[3]);                       uout[2*Ncvec-1].f[0] = ci0;
+  ci1= s*(Xr.f[1]-Xr.f[3]) - s*(Xi.f[1]+Xi.f[3]); uout[2*Ncvec-1].f[1] = ci1;
+  ci2= 2*(Xi.f[3]-Xi.f[1]);                       uout[2*Ncvec-1].f[2] = ci2;
+  ci3=-s*(Xr.f[1]-Xr.f[3]) - s*(Xi.f[1]+Xi.f[3]); uout[2*Ncvec-1].f[3] = ci3;
+}
+
+
+void pffft_transform_internal(PFFFT_Setup *setup, const float *finput, float *foutput, v4sf *scratch,
+                             pffft_direction_t direction, int ordered) {
+  int k, Ncvec   = setup->Ncvec;
+  int nf_odd = (setup->ifac[1] & 1);
+
+  // temporary buffer is allocated on the stack if the scratch pointer is NULL
+  int stack_allocate = (scratch == 0 ? Ncvec*2 : 1);
+  VLA_ARRAY_ON_STACK(v4sf, scratch_on_stack, stack_allocate);
+
+  const v4sf *vinput = (const v4sf*)finput;
+  v4sf *voutput      = (v4sf*)foutput;
+  v4sf *buff[2]      = { voutput, scratch ? scratch : scratch_on_stack };
+  int ib = (nf_odd ^ ordered ? 1 : 0);
+
+  assert(VALIGNED(finput) && VALIGNED(foutput));
+
+  //assert(finput != foutput);
+  if (direction == PFFFT_FORWARD) {
+    ib = !ib;
+    if (setup->transform == PFFFT_REAL) { 
+      ib = (rfftf1_ps(Ncvec*2, vinput, buff[ib], buff[!ib],
+                      setup->twiddle, &setup->ifac[0]) == buff[0] ? 0 : 1);      
+      pffft_real_finalize(Ncvec, buff[ib], buff[!ib], (v4sf*)setup->e);
+    } else {
+      v4sf *tmp = buff[ib];
+      for (k=0; k < Ncvec; ++k) {
+        UNINTERLEAVE2(vinput[k*2], vinput[k*2+1], tmp[k*2], tmp[k*2+1]);
+      }
+      ib = (cfftf1_ps(Ncvec, buff[ib], buff[!ib], buff[ib], 
+                      setup->twiddle, &setup->ifac[0], -1) == buff[0] ? 0 : 1);
+      pffft_cplx_finalize(Ncvec, buff[ib], buff[!ib], (v4sf*)setup->e);
+    }
+    if (ordered) {
+      pffft_zreorder(setup, (float*)buff[!ib], (float*)buff[ib], PFFFT_FORWARD);       
+    } else ib = !ib;
+  } else {
+    if (vinput == buff[ib]) { 
+      ib = !ib; // may happen when finput == foutput
+    }
+    if (ordered) {
+      pffft_zreorder(setup, (float*)vinput, (float*)buff[ib], PFFFT_BACKWARD); 
+      vinput = buff[ib]; ib = !ib;
+    }
+    if (setup->transform == PFFFT_REAL) {
+      pffft_real_preprocess(Ncvec, vinput, buff[ib], (v4sf*)setup->e);
+      ib = (rfftb1_ps(Ncvec*2, buff[ib], buff[0], buff[1], 
+                      setup->twiddle, &setup->ifac[0]) == buff[0] ? 0 : 1);
+    } else {
+      pffft_cplx_preprocess(Ncvec, vinput, buff[ib], (v4sf*)setup->e);
+      ib = (cfftf1_ps(Ncvec, buff[ib], buff[0], buff[1], 
+                      setup->twiddle, &setup->ifac[0], +1) == buff[0] ? 0 : 1);
+      for (k=0; k < Ncvec; ++k) {
+        INTERLEAVE2(buff[ib][k*2], buff[ib][k*2+1], buff[ib][k*2], buff[ib][k*2+1]);
+      }
+    }
+  }
+  
+  if (buff[ib] != voutput) {
+    /* extra copy required -- this situation should only happen when finput == foutput */
+    assert(finput==foutput);
+    for (k=0; k < Ncvec; ++k) {
+      v4sf a = buff[ib][2*k], b = buff[ib][2*k+1];
+      voutput[2*k] = a; voutput[2*k+1] = b;
+    }
+    ib = !ib;
+  }
+  assert(buff[ib] == voutput);
+}
+
+void pffft_zconvolve_accumulate(PFFFT_Setup *s, const float *a, const float *b, float *ab, float scaling) {
+  int Ncvec = s->Ncvec;
+  const v4sf * RESTRICT va = (const v4sf*)a;
+  const v4sf * RESTRICT vb = (const v4sf*)b;
+  v4sf * RESTRICT vab = (v4sf*)ab;
+
+#ifdef __arm__
+  __builtin_prefetch(va);
+  __builtin_prefetch(vb);
+  __builtin_prefetch(vab);
+  __builtin_prefetch(va+2);
+  __builtin_prefetch(vb+2);
+  __builtin_prefetch(vab+2);
+  __builtin_prefetch(va+4);
+  __builtin_prefetch(vb+4);
+  __builtin_prefetch(vab+4);
+  __builtin_prefetch(va+6);
+  __builtin_prefetch(vb+6);
+  __builtin_prefetch(vab+6);
+# ifndef __clang__
+#   define ZCONVOLVE_USING_INLINE_NEON_ASM
+# endif
+#endif
+
+  float ar, ai, br, bi, abr, abi;
+#ifndef ZCONVOLVE_USING_INLINE_ASM
+  v4sf vscal = LD_PS1(scaling);
+  int i;
+#endif
+
+  assert(VALIGNED(a) && VALIGNED(b) && VALIGNED(ab));
+  ar = ((v4sf_union*)va)[0].f[0];
+  ai = ((v4sf_union*)va)[1].f[0];
+  br = ((v4sf_union*)vb)[0].f[0];
+  bi = ((v4sf_union*)vb)[1].f[0];
+  abr = ((v4sf_union*)vab)[0].f[0];
+  abi = ((v4sf_union*)vab)[1].f[0];
+ 
+#ifdef ZCONVOLVE_USING_INLINE_ASM // inline asm version, unfortunately miscompiled by clang 3.2, at least on ubuntu.. so this will be restricted to gcc
+  const float *a_ = a, *b_ = b; float *ab_ = ab;
+  int N = Ncvec;
+  asm volatile("mov         r8, %2                  \n"
+               "vdup.f32    q15, %4                 \n"
+               "1:                                  \n"
+               "pld         [%0,#64]                \n"
+               "pld         [%1,#64]                \n"
+               "pld         [%2,#64]                \n"
+               "pld         [%0,#96]                \n"
+               "pld         [%1,#96]                \n"
+               "pld         [%2,#96]                \n"
+               "vld1.f32    {q0,q1},   [%0,:128]!         \n"
+               "vld1.f32    {q4,q5},   [%1,:128]!         \n"
+               "vld1.f32    {q2,q3},   [%0,:128]!         \n"
+               "vld1.f32    {q6,q7},   [%1,:128]!         \n"
+               "vld1.f32    {q8,q9},   [r8,:128]!          \n"
+               
+               "vmul.f32    q10, q0, q4             \n"
+               "vmul.f32    q11, q0, q5             \n"
+               "vmul.f32    q12, q2, q6             \n" 
+               "vmul.f32    q13, q2, q7             \n"                 
+               "vmls.f32    q10, q1, q5             \n"
+               "vmla.f32    q11, q1, q4             \n"
+               "vld1.f32    {q0,q1}, [r8,:128]!     \n"
+               "vmls.f32    q12, q3, q7             \n"
+               "vmla.f32    q13, q3, q6             \n"
+               "vmla.f32    q8, q10, q15            \n"
+               "vmla.f32    q9, q11, q15            \n"
+               "vmla.f32    q0, q12, q15            \n"
+               "vmla.f32    q1, q13, q15            \n"
+               "vst1.f32    {q8,q9},[%2,:128]!    \n"
+               "vst1.f32    {q0,q1},[%2,:128]!    \n"
+               "subs        %3, #2                  \n"
+               "bne         1b                      \n"
+               : "+r"(a_), "+r"(b_), "+r"(ab_), "+r"(N) : "r"(scaling) : "r8", "q0","q1","q2","q3","q4","q5","q6","q7","q8","q9", "q10","q11","q12","q13","q15","memory");
+#else // default routine, works fine for non-arm cpus with current compilers
+  for (i=0; i < Ncvec; i += 2) {
+    v4sf ar, ai, br, bi;
+    ar = va[2*i+0]; ai = va[2*i+1];
+    br = vb[2*i+0]; bi = vb[2*i+1];
+    VCPLXMUL(ar, ai, br, bi);
+    vab[2*i+0] = VMADD(ar, vscal, vab[2*i+0]);
+    vab[2*i+1] = VMADD(ai, vscal, vab[2*i+1]);
+    ar = va[2*i+2]; ai = va[2*i+3];
+    br = vb[2*i+2]; bi = vb[2*i+3];
+    VCPLXMUL(ar, ai, br, bi);
+    vab[2*i+2] = VMADD(ar, vscal, vab[2*i+2]);
+    vab[2*i+3] = VMADD(ai, vscal, vab[2*i+3]);
+  }
+#endif
+  if (s->transform == PFFFT_REAL) {
+    ((v4sf_union*)vab)[0].f[0] = abr + ar*br*scaling;
+    ((v4sf_union*)vab)[1].f[0] = abi + ai*bi*scaling;
+  }
+}
+
+
+#else // defined(PFFFT_SIMD_DISABLE)
+
+// standard routine using scalar floats, without SIMD stuff.
+
+#define pffft_zreorder_nosimd pffft_zreorder
+void pffft_zreorder_nosimd(PFFFT_Setup *setup, const float *in, float *out, pffft_direction_t direction) {
+  int k, N = setup->N;
+  if (setup->transform == PFFFT_COMPLEX) {
+    for (k=0; k < 2*N; ++k) out[k] = in[k];
+    return;
+  }
+  else if (direction == PFFFT_FORWARD) {
+    float x_N = in[N-1];
+    for (k=N-1; k > 1; --k) out[k] = in[k-1]; 
+    out[0] = in[0];
+    out[1] = x_N;
+  } else {
+    float x_N = in[1];
+    for (k=1; k < N-1; ++k) out[k] = in[k+1]; 
+    out[0] = in[0];
+    out[N-1] = x_N;
+  }
+}
+
+#define pffft_transform_internal_nosimd pffft_transform_internal
+void pffft_transform_internal_nosimd(PFFFT_Setup *setup, const float *input, float *output, float *scratch,
+                                    pffft_direction_t direction, int ordered) {
+  int Ncvec   = setup->Ncvec;
+  int nf_odd = (setup->ifac[1] & 1);
+
+  // temporary buffer is allocated on the stack if the scratch pointer is NULL
+  int stack_allocate = (scratch == 0 ? Ncvec*2 : 1);
+  VLA_ARRAY_ON_STACK(v4sf, scratch_on_stack, stack_allocate);
+  float *buff[2];
+  int ib;
+  if (scratch == 0) scratch = scratch_on_stack;
+  buff[0] = output; buff[1] = scratch;
+
+  if (setup->transform == PFFFT_COMPLEX) ordered = 0; // it is always ordered.
+  ib = (nf_odd ^ ordered ? 1 : 0);
+
+  if (direction == PFFFT_FORWARD) {
+    if (setup->transform == PFFFT_REAL) { 
+      ib = (rfftf1_ps(Ncvec*2, input, buff[ib], buff[!ib],
+                      setup->twiddle, &setup->ifac[0]) == buff[0] ? 0 : 1);      
+    } else {
+      ib = (cfftf1_ps(Ncvec, input, buff[ib], buff[!ib], 
+                      setup->twiddle, &setup->ifac[0], -1) == buff[0] ? 0 : 1);
+    }
+    if (ordered) {
+      pffft_zreorder(setup, buff[ib], buff[!ib], PFFFT_FORWARD); ib = !ib;
+    }
+  } else {    
+    if (input == buff[ib]) { 
+      ib = !ib; // may happen when finput == foutput
+    }
+    if (ordered) {
+      pffft_zreorder(setup, input, buff[!ib], PFFFT_BACKWARD); 
+      input = buff[!ib];
+    }
+    if (setup->transform == PFFFT_REAL) {
+      ib = (rfftb1_ps(Ncvec*2, input, buff[ib], buff[!ib], 
+                      setup->twiddle, &setup->ifac[0]) == buff[0] ? 0 : 1);
+    } else {
+      ib = (cfftf1_ps(Ncvec, input, buff[ib], buff[!ib], 
+                      setup->twiddle, &setup->ifac[0], +1) == buff[0] ? 0 : 1);
+    }
+  }
+  if (buff[ib] != output) {
+    int k;
+    // extra copy required -- this situation should happens only when finput == foutput
+    assert(input==output);
+    for (k=0; k < Ncvec; ++k) {
+      float a = buff[ib][2*k], b = buff[ib][2*k+1];
+      output[2*k] = a; output[2*k+1] = b;
+    }
+    ib = !ib;
+  }
+  assert(buff[ib] == output);
+}
+
+#define pffft_zconvolve_accumulate_nosimd pffft_zconvolve_accumulate
+void pffft_zconvolve_accumulate_nosimd(PFFFT_Setup *s, const float *a, const float *b,
+                                       float *ab, float scaling) {
+  int i, Ncvec = s->Ncvec;
+
+  if (s->transform == PFFFT_REAL) {
+    // take care of the fftpack ordering
+    ab[0] += a[0]*b[0]*scaling;
+    ab[2*Ncvec-1] += a[2*Ncvec-1]*b[2*Ncvec-1]*scaling;
+    ++ab; ++a; ++b; --Ncvec;
+  }
+  for (i=0; i < Ncvec; ++i) {
+    float ar, ai, br, bi;
+    ar = a[2*i+0]; ai = a[2*i+1];
+    br = b[2*i+0]; bi = b[2*i+1];
+    VCPLXMUL(ar, ai, br, bi);
+    ab[2*i+0] += ar*scaling;
+    ab[2*i+1] += ai*scaling;
+  }
+}
+
+#endif // defined(PFFFT_SIMD_DISABLE)
+
+void pffft_transform(PFFFT_Setup *setup, const float *input, float *output, float *work, pffft_direction_t direction) {
+  pffft_transform_internal(setup, input, output, (v4sf*)work, direction, 0);
+}
+
+void pffft_transform_ordered(PFFFT_Setup *setup, const float *input, float *output, float *work, pffft_direction_t direction) {
+  pffft_transform_internal(setup, input, output, (v4sf*)work, direction, 1);
+}
diff --git a/third_party/webrtc_aec3/src/third_party/pffft/src/pffft.h b/third_party/webrtc_aec3/src/third_party/pffft/src/pffft.h
new file mode 100644
index 0000000..2bfa7b3
--- /dev/null
+++ b/third_party/webrtc_aec3/src/third_party/pffft/src/pffft.h
@@ -0,0 +1,177 @@
+/* Copyright (c) 2013  Julien Pommier ( pommier@modartt.com ) 
+
+   Based on original fortran 77 code from FFTPACKv4 from NETLIB,
+   authored by Dr Paul Swarztrauber of NCAR, in 1985.
+
+   As confirmed by the NCAR fftpack software curators, the following
+   FFTPACKv5 license applies to FFTPACKv4 sources. My changes are
+   released under the same terms.
+
+   FFTPACK license:
+
+   http://www.cisl.ucar.edu/css/software/fftpack5/ftpk.html
+
+   Copyright (c) 2004 the University Corporation for Atmospheric
+   Research ("UCAR"). All rights reserved. Developed by NCAR's
+   Computational and Information Systems Laboratory, UCAR,
+   www.cisl.ucar.edu.
+
+   Redistribution and use of the Software in source and binary forms,
+   with or without modification, is permitted provided that the
+   following conditions are met:
+
+   - Neither the names of NCAR's Computational and Information Systems
+   Laboratory, the University Corporation for Atmospheric Research,
+   nor the names of its sponsors or contributors may be used to
+   endorse or promote products derived from this Software without
+   specific prior written permission.  
+
+   - Redistributions of source code must retain the above copyright
+   notices, this list of conditions, and the disclaimer below.
+
+   - Redistributions in binary form must reproduce the above copyright
+   notice, this list of conditions, and the disclaimer below in the
+   documentation and/or other materials provided with the
+   distribution.
+
+   THIS SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+   EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED TO THE WARRANTIES OF
+   MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+   NONINFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT
+   HOLDERS BE LIABLE FOR ANY CLAIM, INDIRECT, INCIDENTAL, SPECIAL,
+   EXEMPLARY, OR CONSEQUENTIAL DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+   ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+   CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE
+   SOFTWARE.
+*/
+   
+/*
+   PFFFT : a Pretty Fast FFT.
+
+   This is basically an adaptation of the single precision fftpack
+   (v4) as found on netlib taking advantage of SIMD instruction found
+   on cpus such as intel x86 (SSE1), powerpc (Altivec), and arm (NEON).
+   
+   For architectures where no SIMD instruction is available, the code
+   falls back to a scalar version.  
+
+   Restrictions: 
+
+   - 1D transforms only, with 32-bit single precision.
+
+   - supports only transforms for inputs of length N of the form
+   N=(2^a)*(3^b)*(5^c), a >= 5, b >=0, c >= 0 (32, 48, 64, 96, 128,
+   144, 160, etc are all acceptable lengths). Performance is best for
+   128<=N<=8192.
+
+   - all (float*) pointers in the functions below are expected to
+   have an "simd-compatible" alignment, that is 16 bytes on x86 and
+   powerpc CPUs.
+  
+   You can allocate such buffers with the functions
+   pffft_aligned_malloc / pffft_aligned_free (or with stuff like
+   posix_memalign..)
+
+*/
+
+#ifndef PFFFT_H
+#define PFFFT_H
+
+#include <stddef.h> // for size_t
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+  /* opaque struct holding internal stuff (precomputed twiddle factors)
+     this struct can be shared by many threads as it contains only
+     read-only data.  
+  */
+  typedef struct PFFFT_Setup PFFFT_Setup;
+
+  /* direction of the transform */
+  typedef enum { PFFFT_FORWARD, PFFFT_BACKWARD } pffft_direction_t;
+  
+  /* type of transform */
+  typedef enum { PFFFT_REAL, PFFFT_COMPLEX } pffft_transform_t;
+
+  /*
+    prepare for performing transforms of size N -- the returned
+    PFFFT_Setup structure is read-only so it can safely be shared by
+    multiple concurrent threads. 
+  */
+  PFFFT_Setup *pffft_new_setup(int N, pffft_transform_t transform);
+  void pffft_destroy_setup(PFFFT_Setup *);
+  /* 
+     Perform a Fourier transform , The z-domain data is stored in the
+     most efficient order for transforming it back, or using it for
+     convolution. If you need to have its content sorted in the
+     "usual" way, that is as an array of interleaved complex numbers,
+     either use pffft_transform_ordered , or call pffft_zreorder after
+     the forward fft, and before the backward fft.
+
+     Transforms are not scaled: PFFFT_BACKWARD(PFFFT_FORWARD(x)) = N*x.
+     Typically you will want to scale the backward transform by 1/N.
+     
+     The 'work' pointer should point to an area of N (2*N for complex
+     fft) floats, properly aligned. If 'work' is NULL, then stack will
+     be used instead (this is probably the best strategy for small
+     FFTs, say for N < 16384).
+
+     input and output may alias.
+  */
+  void pffft_transform(PFFFT_Setup *setup, const float *input, float *output, float *work, pffft_direction_t direction);
+
+  /* 
+     Similar to pffft_transform, but makes sure that the output is
+     ordered as expected (interleaved complex numbers).  This is
+     similar to calling pffft_transform and then pffft_zreorder.
+     
+     input and output may alias.
+  */
+  void pffft_transform_ordered(PFFFT_Setup *setup, const float *input, float *output, float *work, pffft_direction_t direction);
+
+  /* 
+     call pffft_zreorder(.., PFFFT_FORWARD) after pffft_transform(...,
+     PFFFT_FORWARD) if you want to have the frequency components in
+     the correct "canonical" order, as interleaved complex numbers.
+     
+     (for real transforms, both 0-frequency and half frequency
+     components, which are real, are assembled in the first entry as
+     F(0)+i*F(n/2+1). Note that the original fftpack did place
+     F(n/2+1) at the end of the arrays).
+     
+     input and output should not alias.
+  */
+  void pffft_zreorder(PFFFT_Setup *setup, const float *input, float *output, pffft_direction_t direction);
+
+  /* 
+     Perform a multiplication of the frequency components of dft_a and
+     dft_b and accumulate them into dft_ab. The arrays should have
+     been obtained with pffft_transform(.., PFFFT_FORWARD) and should
+     *not* have been reordered with pffft_zreorder (otherwise just
+     perform the operation yourself as the dft coefs are stored as
+     interleaved complex numbers).
+     
+     the operation performed is: dft_ab += (dft_a * fdt_b)*scaling
+     
+     The dft_a, dft_b and dft_ab pointers may alias.
+  */
+  void pffft_zconvolve_accumulate(PFFFT_Setup *setup, const float *dft_a, const float *dft_b, float *dft_ab, float scaling);
+
+  /*
+    the float buffers must have the correct alignment (16-byte boundary
+    on intel and powerpc). This function may be used to obtain such
+    correctly aligned buffers.  
+  */
+  void *pffft_aligned_malloc(size_t nb_bytes);
+  void pffft_aligned_free(void *);
+
+  /* return 4 or 1 wether support SSE/Altivec instructions was enable when building pffft.c */
+  int pffft_simd_size();
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif // PFFFT_H
diff --git a/third_party/webrtc_aec3/src/third_party/rnnoise/COPYING b/third_party/webrtc_aec3/src/third_party/rnnoise/COPYING
new file mode 100644
index 0000000..cec4bb0
--- /dev/null
+++ b/third_party/webrtc_aec3/src/third_party/rnnoise/COPYING
@@ -0,0 +1,26 @@
+Copyright (c) 2017, Mozilla
+Copyright (c) 2007-2017, Jean-Marc Valin
+Copyright (c) 2005-2017, Xiph.Org Foundation
+Copyright (c) 2003-2004, Mark Borgerding
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions
+are met:
+- Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+- Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in the
+documentation and/or other materials provided with the distribution.
+- Neither the name of the Xiph.Org Foundation nor the names of its
+contributors may be used to endorse or promote products derived from
+this software without specific prior written permission.
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION
+OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
diff --git a/third_party/webrtc_aec3/src/third_party/rnnoise/OWNERS b/third_party/webrtc_aec3/src/third_party/rnnoise/OWNERS
new file mode 100644
index 0000000..da84dd2
--- /dev/null
+++ b/third_party/webrtc_aec3/src/third_party/rnnoise/OWNERS
@@ -0,0 +1,3 @@
+alessiob@chromium.org
+aleloi@chromium.org
+
diff --git a/third_party/webrtc_aec3/src/third_party/rnnoise/README.chromium b/third_party/webrtc_aec3/src/third_party/rnnoise/README.chromium
new file mode 100644
index 0000000..6fc775f
--- /dev/null
+++ b/third_party/webrtc_aec3/src/third_party/rnnoise/README.chromium
@@ -0,0 +1,27 @@
+Name: Recurrent neural network for audio noise reduction
+Short Name: rnnoise
+URL: https://github.com/xiph/rnnoise
+Version: 91ef401
+Date: Oct 10, 2017
+Revision:
+License: BSD 3-Clause
+License File: COPYING
+Security Critical: no
+License Android Compatible:
+Description:
+RNNoise is a noise suppression library based on a recurrent neural network.
+The library is used for speech processing in WebRTC.
+Local Modifications:
+* Only retaining COPYING and from src/ the following files:
+ - kiss_fft.c, kiss_fft.h
+ - rnn.c
+ - rnn_data.c
+ - tansig_table.h
+* KissFFT: non-floating point parts removed, code clean, from C to C++,
+  class wrapper added
+* BUILD targets and KissFFT unit tests added
+* rnn_vad_weights.h: output layer sizes + weights scaling factor
+* removing unwanted extern from constants in rnn_vad_weights.h and using
+  constants to declare array sizes
+* Add braces around arrays in unit test.
+* KissFFT removed
diff --git a/third_party/webrtc_aec3/src/third_party/rnnoise/src/rnn_activations.h b/third_party/webrtc_aec3/src/third_party/rnnoise/src/rnn_activations.h
new file mode 100644
index 0000000..f74e513
--- /dev/null
+++ b/third_party/webrtc_aec3/src/third_party/rnnoise/src/rnn_activations.h
@@ -0,0 +1,90 @@
+/* Copyright (c) 2008-2011 Octasic Inc.
+                 2012-2017 Jean-Marc Valin */
+/*
+   Redistribution and use in source and binary forms, with or without
+   modification, are permitted provided that the following conditions
+   are met:
+   - Redistributions of source code must retain the above copyright
+   notice, this list of conditions and the following disclaimer.
+   - Redistributions in binary form must reproduce the above copyright
+   notice, this list of conditions and the following disclaimer in the
+   documentation and/or other materials provided with the distribution.
+   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+   ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+   A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR
+   CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+   EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+   PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+   PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+   LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+   NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+   SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+*/
+#ifndef THIRD_PARTY_RNNOISE_SRC_RNN_ACTIVATIONS_H_
+#define THIRD_PARTY_RNNOISE_SRC_RNN_ACTIVATIONS_H_
+#include <cmath>
+namespace rnnoise {
+inline float TansigApproximated(float x) {
+  static constexpr float kTansigTable[201] = {
+      0.000000f, 0.039979f, 0.079830f, 0.119427f, 0.158649f, 0.197375f,
+      0.235496f, 0.272905f, 0.309507f, 0.345214f, 0.379949f, 0.413644f,
+      0.446244f, 0.477700f, 0.507977f, 0.537050f, 0.564900f, 0.591519f,
+      0.616909f, 0.641077f, 0.664037f, 0.685809f, 0.706419f, 0.725897f,
+      0.744277f, 0.761594f, 0.777888f, 0.793199f, 0.807569f, 0.821040f,
+      0.833655f, 0.845456f, 0.856485f, 0.866784f, 0.876393f, 0.885352f,
+      0.893698f, 0.901468f, 0.908698f, 0.915420f, 0.921669f, 0.927473f,
+      0.932862f, 0.937863f, 0.942503f, 0.946806f, 0.950795f, 0.954492f,
+      0.957917f, 0.961090f, 0.964028f, 0.966747f, 0.969265f, 0.971594f,
+      0.973749f, 0.975743f, 0.977587f, 0.979293f, 0.980869f, 0.982327f,
+      0.983675f, 0.984921f, 0.986072f, 0.987136f, 0.988119f, 0.989027f,
+      0.989867f, 0.990642f, 0.991359f, 0.992020f, 0.992631f, 0.993196f,
+      0.993718f, 0.994199f, 0.994644f, 0.995055f, 0.995434f, 0.995784f,
+      0.996108f, 0.996407f, 0.996682f, 0.996937f, 0.997172f, 0.997389f,
+      0.997590f, 0.997775f, 0.997946f, 0.998104f, 0.998249f, 0.998384f,
+      0.998508f, 0.998623f, 0.998728f, 0.998826f, 0.998916f, 0.999000f,
+      0.999076f, 0.999147f, 0.999213f, 0.999273f, 0.999329f, 0.999381f,
+      0.999428f, 0.999472f, 0.999513f, 0.999550f, 0.999585f, 0.999617f,
+      0.999646f, 0.999673f, 0.999699f, 0.999722f, 0.999743f, 0.999763f,
+      0.999781f, 0.999798f, 0.999813f, 0.999828f, 0.999841f, 0.999853f,
+      0.999865f, 0.999875f, 0.999885f, 0.999893f, 0.999902f, 0.999909f,
+      0.999916f, 0.999923f, 0.999929f, 0.999934f, 0.999939f, 0.999944f,
+      0.999948f, 0.999952f, 0.999956f, 0.999959f, 0.999962f, 0.999965f,
+      0.999968f, 0.999970f, 0.999973f, 0.999975f, 0.999977f, 0.999978f,
+      0.999980f, 0.999982f, 0.999983f, 0.999984f, 0.999986f, 0.999987f,
+      0.999988f, 0.999989f, 0.999990f, 0.999990f, 0.999991f, 0.999992f,
+      0.999992f, 0.999993f, 0.999994f, 0.999994f, 0.999994f, 0.999995f,
+      0.999995f, 0.999996f, 0.999996f, 0.999996f, 0.999997f, 0.999997f,
+      0.999997f, 0.999997f, 0.999997f, 0.999998f, 0.999998f, 0.999998f,
+      0.999998f, 0.999998f, 0.999998f, 0.999999f, 0.999999f, 0.999999f,
+      0.999999f, 0.999999f, 0.999999f, 0.999999f, 0.999999f, 0.999999f,
+      0.999999f, 0.999999f, 0.999999f, 0.999999f, 1.000000f, 1.000000f,
+      1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,
+      1.000000f, 1.000000f, 1.000000f,
+  };
+  // Tests are reversed to catch NaNs.
+  if (!(x < 8.f))
+    return 1.f;
+  if (!(x > -8.f))
+    return -1.f;
+  float sign = 1.f;
+  if (x < 0.f) {
+    x = -x;
+    sign = -1.f;
+  }
+  // Look-up.
+  int i = static_cast<int>(std::floor(0.5f + 25 * x));
+  float y = kTansigTable[i];
+  // Map i back to x's scale (undo 25 factor).
+  x -= 0.04f * i;
+  y = y + x * (1.f - y * y) * (1.f - y * x);
+  return sign * y;
+}
+inline float SigmoidApproximated(const float x) {
+  return 0.5f + 0.5f * TansigApproximated(0.5f * x);
+}
+inline float RectifiedLinearUnit(const float x) {
+  return x < 0.f ? 0.f : x;
+}
+}  // namespace rnnoise
+#endif  // THIRD_PARTY_RNNOISE_SRC_RNN_ACTIVATIONS_H_
diff --git a/third_party/webrtc_aec3/src/third_party/rnnoise/src/rnn_vad_weights.cc b/third_party/webrtc_aec3/src/third_party/rnnoise/src/rnn_vad_weights.cc
new file mode 100644
index 0000000..3642cb6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/third_party/rnnoise/src/rnn_vad_weights.cc
@@ -0,0 +1,392 @@
+#include "third_party/rnnoise/src/rnn_vad_weights.h"
+namespace rnnoise {
+const int8_t kInputDenseWeights[kInputLayerWeights] = {
+    -10,  0,    -3,   1,    -8,   -6,   3,    -13,  1,    0,    -3,   -7,
+    -5,   -3,   6,    -1,   -6,   0,    -6,   -4,   -1,   -2,   1,    1,
+    -7,   2,    21,   10,   -5,   -20,  24,   23,   37,   8,    -2,   33,
+    -6,   22,   13,   -2,   50,   8,    13,   1,    -15,  30,   -10,  30,
+    0,    3,    5,    27,   1,    4,    -3,   41,   56,   35,   -2,   49,
+    -13,  11,   13,   -2,   -47,  5,    -16,  -60,  -15,  77,   -17,  26,
+    -3,   14,   -21,  19,   -5,   -19,  -13,  0,    10,   14,   9,    31,
+    -13,  -41,  -10,  4,    22,   18,   -48,  -6,   -10,  62,   -3,   -18,
+    -14,  12,   26,   -28,  3,    14,   25,   -13,  -19,  6,    5,    36,
+    -3,   -65,  -12,  0,    31,   -7,   -9,   101,  -4,   26,   16,   17,
+    -12,  -12,  14,   -36,  -3,   5,    -15,  21,   2,    30,   -3,   38,
+    -4,   1,    -6,   7,    -7,   14,   38,   -22,  -30,  -3,   -7,   3,
+    -39,  -70,  -126, 25,   34,   94,   -67,  -22,  -33,  83,   -47,  -118,
+    4,    70,   33,   25,   62,   -128, -76,  -118, -113, 49,   -12,  -100,
+    -18,  -114, -33,  43,   32,   61,   40,   -9,   -106, 2,    36,   -100,
+    -40,  -5,   20,   -75,  61,   -51,  -9,   126,  -27,  -52,  5,    -24,
+    -21,  -126, -114, -12,  15,   106,  -2,   73,   -125, 50,   13,   -120,
+    35,   35,   4,    -61,  29,   -124, 6,    -53,  -69,  -125, 64,   -89,
+    36,   -107, -103, -7,   27,   121,  69,   77,   -35,  35,   95,   -125,
+    -49,  97,   -45,  -43,  -23,  23,   -28,  -65,  -118, 2,    8,    -126,
+    27,   -97,  92,   5,    55,   82,   17,   -57,  -115, 37,   8,    -106,
+    -46,  41,   -2,   21,   -44,  8,    -73,  -58,  -39,  34,   89,   -95,
+    95,   -117, 120,  -58,  31,   123,  1,    -32,  -109, -110, 60,   -120,
+    -43,  -74,  5,    91,   26,   21,   114,  82,   -83,  -126, 123,  22,
+    -16,  -67,  25,   -83,  46,   48,   -34,  -121, -124, -63,  -35,  -9,
+    31,   82,   123,  6,    -3,   117,  93,   -2,   -13,  -36,  124,  -112,
+    -6,   -102, -5,   -33,  -15,  44,   -69,  -127, -23,  -40,  -34,  -85,
+    68,   83,   -1,   40,   8,    84,   118,  -58,  -55,  -102, 123,  -55,
+    -14,  -123, 44,   -63,  -14,  21,   35,   16,   24,   -126, -13,  -114,
+    35,   20,   -36,  61,   -9,   97,   34,   19,   -32,  -109, 76,   -104,
+    99,   -119, 45,   -125, -51,  -28,  -8,   -69,  -8,   125,  -45,  -93,
+    113,  103,  -41,  -82,  52,   7,    126,  0,    -40,  104,  55,   -58,
+    17,   -124, -93,  -58,  8,    -45,  1,    56,   -123, 108,  -47,  -23,
+    115,  127,  17,   -68,  -13,  116,  -82,  -44,  45,   67,   -120, -101,
+    -15,  -125, 120,  -113, 17,   -48,  -73,  126,  -64,  -86,  -118, -19,
+    112,  -1,   -66,  -27,  -62,  121,  -86,  -58,  50,   89,   -38,  -75,
+    95,   -111, 12,   -113, 2,    -68,  2,    -94,  -121, 91,   -5,   0,
+    79,   43,   -7,   -18,  79,   35,   -38,  47,   1,    -45,  83,   -50,
+    102,  32,   55,   -96,  15,   -122, -69,  45,   -27,  91,   -62,  -30,
+    46,   -95,  22,   -72,  -97,  -1,   14,   -122, 28,   127,  61,   -126,
+    121,  9,    68,   -120, 49,   -60,  90,   3,    43,   68,   54,   34,
+    -10,  28,   21,   -24,  -54,  22,   -113, -12,  82,   -2,   -17,  -9,
+    127,  8,    116,  -92,  0,    -70,  -33,  123,  66,   116,  -74,  -4,
+    74,   -72,  -22,  -47,  1,    -83,  -60,  -124, 1,    122,  -57,  -43,
+    49,   40,   -126, -128, -8,   -29,  28,   -24,  -123, -121, -70,  -93,
+    -37,  -126, 11,   -125, -37,  11,   -31,  -51,  -124, 116,  -128, 8,
+    -25,  109,  75,   -12,  7,    8,    10,   117,  124,  -128, -128, 29,
+    -26,  101,  21,   -128, 87,   8,    -39,  23,   -128, 127,  -127, 74,
+    -55,  74,   112,  127,  4,    55,   44,   -92,  123,  34,   -93,  47,
+    -21,  -92,  17,   49,   -121, 92,   7,    -126, -125, 124,  -74,  3,
+    -59,  18,   -91,  3,    -9,   9,    56,   116,  7,    -29,  33,   87,
+    -21,  -128, -13,  57,   74,   9,    -29,  -61,  -97,  -21,  -95,  -12,
+    -114, 16,   82,   125,  -7,   10,   -24,  9,    77,   -128, -102, -25,
+    3,    -126, 10,   13,   -18,  51,   26,   127,  -79,  35,   51,   12,
+    -50,  -24,  1,    -7,   22,   81,   65,   120,  -30,  -38,  85,   122,
+    -4,   -106, -11,  27,   53,   41,   8,    -104, -66,  -38,  -124, 10,
+    12,   76,   117,  -109, 9,    11,   2,    -18,  3,    113,  -16,  -79,
+    -39,  -123, -20,  -128, 2,    13,   -33,  -58,  10,   84,   -104, 13,
+    64,   109,  1,    54,   -12,  28,   24,   63,   -126, 118,  -82,  46,
+    -12,  -15,  14,   -43,  60,   22,   -32,  -19,  -46,  91,   -107, 24,
+    -94,  26,   -47,  125,  6,    58,   -15,  -75,  -26,  -38,  -35,  103,
+    -16,  -17,  -13,  63,   -2,   45,   -45,  -73,  -23,  70,   -87,  51,
+    -17,  53,   76,   14,   -18,  -31,  -14,  103,  8,    21,   -28,  -33,
+    -20,  -47,  6,    39,   40,   -30,  7,    -76,  55,   31,   -20,  -21,
+    -59,  1,    25,   -11,  17,   5,    -13,  -39,  0,    -76,  50,   -33,
+    -29,  -50,  -16,  -11,  -12,  -1,   -46,  40,   -10,  65,   -19,  21,
+    -41,  -32,  -83,  -19,  -4,   49,   -60,  118,  -24,  -46,  9,    102,
+    -20,  8,    -19,  25,   31,   -3,   -37,  0,    25,   7,    29,   2,
+    -39,  127,  -64,  -20,  64,   115,  -30,  36,   100,  35,   122,  127,
+    127,  -127, 127,  -127, 19,   127,  -89,  -79,  -32,  39,   -127, 125,
+    -80,  126,  -127, 26,   8,    98,   -8,   -57,  -90,  -50,  126,  61,
+    127,  -126, 40,   -106, -68,  104,  -125, -119, 11,   10,   -127, 66,
+    -56,  -12,  -126, -104, 27,   75,   38,   -124, -126, -125, 84,   -123,
+    -45,  -114, -128, 127,  103,  -101, -124, 127,  -11,  -23,  -123, 92,
+    -123, 24,   126,  41,   -2,   -39,  -27,  -94,  40,   -112, -48,  127,
+    58,   14,   38,   -75,  -64,  73,   117,  100,  -119, -11,  6,    32,
+    -126, -14,  35,   121,  -10,  54,   -60,  89,   -3,   69,   -25,  -20,
+    43,   -86,  -34,  24,   27,   7,    -81,  -99,  -23,  -16,  -26,  13,
+    35,   -97,  80,   -29,  -13,  -121, -12,  -65,  -94,  70,   -89,  -126,
+    -95,  88,   33,   96,   29,   -90,  69,   114,  -78,  65,   90,   -47,
+    -47,  89,   1,    -12,  3,    8,    30,   5,    2,    -30,  -1,   6,
+    -7,   10,   -4,   46,   -27,  -40,  22,   -6,   -17,  45,   24,   -9,
+    23,   -14,  -63,  -26,  -12,  -57,  27,   25,   55,   -76,  -47,  21,
+    34,   33,   26,   17,   14,   6,    9,    26,   25,   -25,  -25,  -18};
+const int8_t kInputDenseBias[kInputLayerOutputSize] = {
+    38,  -6,  127,  127, 127,  -43, -127, 78,  127, 5,   127, 123,
+    127, 127, -128, -76, -126, 28,  127,  125, -30, 127, -89, -20};
+const int8_t kHiddenGruWeights[kHiddenLayerWeights] = {
+    -124, 23,   -123, -33,  -95,  -4,   8,    -84,  4,    101,  -119, 116,
+    -4,   123,  103,  -51,  29,   -124, -114, -49,  31,   9,    75,   -128,
+    0,    -49,  37,   -50,  46,   -21,  -63,  -104, 54,   82,   33,   21,
+    70,   127,  -9,   -79,  -39,  -23,  -127, 107,  122,  -96,  -46,  -18,
+    -39,  13,   -28,  -48,  14,   56,   -52,  49,   -1,   -121, 25,   -18,
+    -36,  -52,  -57,  -30,  54,   -124, -26,  -47,  10,   39,   12,   2,
+    9,    -127, -128, 102,  21,   11,   -64,  -71,  89,   -113, -111, 54,
+    31,   94,   121,  -40,  30,   40,   -109, 73,   -9,   108,  -92,  2,
+    -127, 116,  127,  127,  -122, 95,   127,  -37,  -127, 28,   89,   10,
+    24,   -104, -62,  -67,  -14,  38,   14,   -71,  22,   -41,  20,   -50,
+    39,   63,   86,   127,  -18,  79,   4,    -51,  2,    33,   117,  -113,
+    -78,  56,   -91,  37,   34,   -45,  -44,  -22,  21,   -16,  56,   30,
+    -84,  -79,  38,   -74,  127,  9,    -25,  2,    82,   61,   25,   -26,
+    26,   11,   117,  -65,  12,   -58,  42,   -62,  -93,  11,   11,   124,
+    -123, 80,   -125, 11,   -90,  42,   94,   4,    -109, -1,   85,   -52,
+    45,   -26,  -27,  77,   -5,   30,   90,   0,    95,   -7,   53,   29,
+    -82,  22,   -9,   74,   2,    -12,  -73,  114,  97,   -64,  122,  -77,
+    43,   91,   86,   126,  106,  72,   90,   -43,  46,   96,   -51,  21,
+    22,   68,   22,   41,   79,   75,   -46,  -105, 23,   -116, 127,  -123,
+    102,  57,   85,   10,   -29,  34,   125,  126,  124,  81,   -15,  54,
+    96,   -128, 39,   -124, 103,  74,   126,  127,  -50,  -71,  -122, -64,
+    93,   -75,  71,   105,  122,  123,  126,  122,  -127, 33,   -63,  -74,
+    124,  -71,  33,   41,   -56,  19,   6,    65,   41,   90,   -116, -3,
+    -46,  75,   -13,  98,   -74,  -42,  74,   -95,  -96,  81,   24,   32,
+    -19,  -123, 74,   55,   109,  115,  0,    32,   33,   12,   -20,  9,
+    127,  127,  -61,  79,   -48,  -54,  -49,  101,  -9,   27,   -106, 74,
+    119,  77,   87,   -126, -24,  127,  124,  31,   34,   127,  40,   3,
+    -90,  127,  23,   57,   -53,  127,  -69,  -88,  -33,  127,  19,   -46,
+    -9,   -125, 13,   -126, -113, 127,  -41,  46,   106,  -62,  3,    -10,
+    111,  49,   -34,  -24,  -20,  -112, 11,   101,  -50,  -34,  50,   65,
+    -64,  -106, 70,   -48,  60,   9,    -122, -45,  15,   -112, -26,  -4,
+    1,    39,   23,   58,   -45,  -80,  127,  82,   58,   30,   -94,  -119,
+    51,   -89,  95,   -107, 30,   127,  125,  58,   -52,  -42,  -38,  -20,
+    -122, 115,  39,   -26,  5,    73,   13,   -39,  43,   -23,  -20,  -125,
+    23,   35,   53,   -61,  -66,  72,   -20,  33,   8,    35,   4,    7,
+    18,   19,   16,   -45,  -50,  -71,  31,   -29,  -41,  -27,  10,   14,
+    27,   9,    -23,  98,   6,    -94,  92,   127,  -114, 59,   -26,  -100,
+    -62,  -127, -17,  -85,  -60,  126,  -42,  -6,   33,   -120, -26,  -126,
+    -127, -35,  -114, -31,  25,   -126, -100, -126, -64,  -46,  -31,  30,
+    25,   -74,  -111, -97,  -81,  -104, -114, -19,  -9,   -116, -69,  22,
+    30,   59,   8,    -51,  16,   -97,  18,   -4,   -89,  80,   -50,  3,
+    36,   -67,  56,   69,   -26,  107,  -10,  58,   -28,  -4,   -57,  -72,
+    -111, 0,    -75,  -119, 14,   -75,  -49,  -66,  -49,  8,    -121, 22,
+    -54,  121,  30,   54,   -26,  -126, -123, 56,   5,    48,   21,   -127,
+    -11,  23,   25,   -82,  6,    -25,  119,  78,   4,    -104, 27,   61,
+    -48,  37,   -13,  -52,  50,   -50,  44,   -1,   -22,  -43,  -59,  -78,
+    -67,  -32,  -26,  9,    -3,   40,   16,   19,   3,    -9,   20,   -6,
+    -37,  28,   39,   17,   -19,  -10,  1,    6,    -59,  74,   47,   3,
+    -119, 0,    -128, -107, -25,  -22,  -69,  -23,  -111, -42,  -93,  -120,
+    90,   -85,  -54,  -118, 76,   -79,  124,  101,  -77,  -75,  -17,  -71,
+    -114, 68,   55,   79,   -1,   -123, -20,  127,  -65,  -123, -128, -87,
+    123,  9,    -115, -14,  7,    -4,   127,  -79,  -115, 125,  -28,  89,
+    -83,  49,   89,   119,  -69,  -5,   12,   -49,  60,   57,   -24,  -99,
+    -110, 76,   -83,  125,  73,   81,   11,   8,    -45,  1,    83,   13,
+    -70,  -2,   97,   112,  -97,  53,   -9,   -94,  124,  44,   -49,  -24,
+    52,   76,   -110, -70,  -114, -12,  72,   -4,   -114, 43,   -43,  81,
+    102,  -84,  -27,  62,   -40,  52,   58,   124,  -35,  -51,  -123, -43,
+    56,   -75,  -34,  -35,  -106, 93,   -43,  14,   -16,  46,   62,   -97,
+    21,   30,   -53,  21,   -11,  -33,  -20,  -95,  4,    -126, 12,   45,
+    20,   108,  85,   11,   20,   -40,  99,   4,    -25,  -18,  -23,  -12,
+    -126, -55,  -20,  -44,  -51,  91,   -127, 127,  -44,  7,    127,  78,
+    38,   125,  -6,   -94,  -103, 73,   126,  -126, 18,   59,   -46,  106,
+    76,   116,  -31,  75,   -4,   92,   102,  32,   -31,  73,   42,   -21,
+    -28,  57,   127,  -8,   -107, 115,  124,  -94,  -4,   -128, 29,   -57,
+    70,   -82,  50,   -13,  -44,  38,   67,   -93,  6,    -39,  -46,  56,
+    68,   27,   61,   26,   18,   -72,  127,  22,   18,   -31,  127,  61,
+    -65,  -38,  1,    -67,  -1,   8,    -73,  46,   -116, -94,  58,   -49,
+    71,   -40,  -63,  -82,  -20,  -60,  93,   76,   69,   -106, 34,   -31,
+    4,    -25,  107,  -18,  45,   4,    -61,  126,  54,   -126, -125, 41,
+    19,   44,   32,   -98,  125,  -24,  125,  -96,  -125, 15,   87,   -4,
+    -90,  18,   -40,  28,   -69,  67,   22,   41,   39,   7,    -48,  -44,
+    12,   69,   -13,  2,    44,   -38,  111,  -7,   -126, -22,  -9,   74,
+    -128, -36,  -7,   -123, -15,  -79,  -91,  -37,  -127, -122, 104,  30,
+    7,    98,   -37,  111,  -116, -47,  127,  -45,  118,  -111, -123, -120,
+    -77,  -64,  -125, 124,  77,   111,  77,   18,   -113, 117,  -9,   67,
+    -77,  126,  49,   -20,  -124, 39,   41,   -124, -34,  114,  -87,  -126,
+    98,   -20,  59,   -17,  -24,  125,  107,  54,   35,   33,   -44,  12,
+    -29,  125,  -71,  -28,  -63,  -114, 28,   -17,  121,  -36,  127,  89,
+    -122, -49,  -18,  -48,  17,   24,   19,   -64,  -128, 13,   86,   45,
+    13,   -49,  55,   84,   48,   80,   -39,  99,   -127, 70,   -33,  30,
+    50,   126,  -65,  -117, -13,  -20,  -24,  127,  115,  -72,  -104, 63,
+    126,  -42,  57,   17,   46,   21,   119,  110,  -100, -60,  -112, 62,
+    -33,  28,   26,   -22,  -60,  -33,  -54,  78,   25,   32,   -114, 86,
+    44,   26,   43,   76,   121,  19,   97,   -2,   -3,   -73,  -68,  6,
+    -116, 6,    -43,  -97,  46,   -128, -120, -31,  -119, -29,  16,   16,
+    -126, -128, -126, -46,  -9,   -3,   92,   -31,  -76,  -126, -3,   -107,
+    -12,  -23,  -69,  5,    51,   27,   -42,  23,   -70,  -128, -29,  22,
+    29,   -126, -55,  50,   -71,  -3,   127,  44,   -27,  -70,  -63,  -66,
+    -70,  104,  86,   115,  29,   -92,  41,   -90,  44,   -11,  -28,  20,
+    -11,  -63,  -16,  43,   31,   17,   -73,  -31,  -1,   -17,  -11,  -39,
+    56,   18,   124,  72,   -14,  28,   69,   -121, -125, 34,   127,  63,
+    86,   -80,  -126, -125, -124, -47,  124,  77,   124,  -19,  23,   -7,
+    -50,  96,   -128, -93,  102,  -53,  -36,  -87,  119,  -125, 92,   -126,
+    118,  102,  72,   -2,   125,  10,   97,   124,  -125, 125,  71,   -20,
+    -47,  -116, -121, -4,   -9,   -32,  79,   -124, -36,  33,   -128, -74,
+    125,  23,   127,  -29,  -115, -32,  124,  -89,  32,   -107, 43,   -17,
+    24,   24,   18,   29,   -13,  -15,  -36,  62,   -91,  4,    -41,  95,
+    28,   -23,  6,    46,   84,   66,   77,   68,   -70,  -1,   -23,  -6,
+    65,   70,   -21,  9,    77,   -12,  2,    -118, 4,    9,    -108, 84,
+    52,   2,    52,   13,   -10,  58,   -110, 18,   66,   -95,  -23,  70,
+    31,   -3,   56,   56,   -3,   -7,   1,    -27,  -48,  -61,  41,   -4,
+    10,   -62,  32,   -7,   -24,  9,    -48,  -60,  -4,   79,   -20,  -38,
+    -76,  68,   -49,  -97,  0,    -15,  5,    -100, -49,  -95,  -99,  -115,
+    -9,   -40,  10,   104,  13,   56,   127,  -27,  -109, -94,  -118, -102,
+    -44,  -85,  52,   127,  -4,   14,   62,   121,  -122, -26,  -79,  -42,
+    -34,  1,    25,   -38,  -79,  -58,  -31,  -31,  -90,  -30,  -123, 32,
+    -56,  125,  66,   124,  -1,   3,    91,   -103, -7,   23,   78,   -18,
+    9,    69,   -69,  76,   -38,  -33,  -2,   -98,  18,   106,  84,   55,
+    87,   -47,  35,   -124, 64,   41,   -14,  46,   25,   -2,   120,  -21,
+    82,   19,   -79,  -37,  -3,   -8,   -16,  21,   19,   -5,   -28,  -112,
+    39,   -6,   -30,  53,   -69,  53,   46,   127,  123,  78,   20,   28,
+    -7,   73,   72,   17,   -40,  41,   111,  57,   32,   -95,  29,   28,
+    -39,  -65,  54,   -20,  -63,  29,   -67,  3,    44,   -57,  -47,  11,
+    61,   -22,  -44,  61,   48,   -100, 20,   125,  96,   -24,  -16,  3,
+    -69,  -126, 74,   -125, 9,    45,   -67,  -123, -59,  -72,  118,  69,
+    45,   50,   -57,  67,   13,   -66,  -106, 47,   62,   22,   -1,   -22,
+    -25,  -40,  -125, 3,    125,  32,   102,  -56,  -25,  -75,  -30,  122,
+    60,   -13,  36,   -73,  7,    -84,  124,  40,   -118, 17,   -87,  -118,
+    -8,   3,    -27,  111,  -40,  40,   -51,  127,  125,  -45,  -30,  -54,
+    46,   80,   -1,   -30,  101,  -17,  18,   26,   54,   7,    -12,  1,
+    -127, 123,  -122, -27,  -75,  64,   10,   25,   -15,  -44,  127,  -127,
+    5,    -84,  -81,  -7,   19,   -26,  126,  15,   116,  -126, 14,   -76,
+    44,   62,   -110, -124, 125,  -29,  -87,  -3,   -69,  82,   90,   57,
+    -123, 123,  100,  -19,  -51,  -32,  69,   37,   -57,  -128, -124, -72,
+    -13,  51,   -7,   -45,  -73,  5,    99,   -26,  -117, -96,  -109, 4,
+    -31,  -12,  0,    31,   -42,  -27,  12,   -81,  118,  39,   83,   14,
+    41,   -126, 107,  -82,  94,   -116, -122, -47,  -109, -84,  -128, -35,
+    -56,  66,   8,    -65,  19,   42,   -46,  -72,  -109, 41,   43,   -127,
+    -113, 58,   127,  42,   -75,  -1,   65,   117,  -55,  -113, -123, 124,
+    43,   -96,  -115, -19,  68,   15,   94,   3,    75,   0,    34,   9,
+    42,   110,  -48,  92,   -76,  99,   -17,  27,   32,   13,   125,  50,
+    -17,  56,   4,    53,   34,   -8,   99,   80,   -126, -21,  -65,  -11,
+    -46,  44,   -81,  -3,   -121, 123,  66,   -81,  -84,  119,  127,  84,
+    105,  45,   -66,  -42,  -23,  32,   -25,  12,   111,  127,  88,   125,
+    30,   24,   -127, -9,   -54,  127,  -116, -119, 88,   70,   94,   -120,
+    35,   -93,  15,   22,   -21,  25,   -110, -123, -45,  8,    -109, 125,
+    -122, -86,  -126, 8,    -14,  -120, -45,  -45,  69,   -125, -122, 6,
+    81,   86,   125,  95,   54,   77,   54,   -123, 126,  -85,  -117, 56,
+    11,   0,    -61,  -91,  -12,  -2,   -113, -3,   -15,  -122, -63,  -91,
+    10,   84,   -111, 125,  93,   21,   62,   -78,  -116, 13,   -57,  28,
+    -124, 126,  110,  12,   15,   95,   15,   -19,  -125, -97,  52,   -7,
+    101,  9,    20,   -125, -26,  -56,  72,   77,   12,   -126, 22,   -29,
+    47,   62,   95,   112,  69,   32,   97,   -83,  -8,   -5,   67,   -63,
+    -123, 79,   59,   0,    -6,   -17,  4,    -111, -52,  27,   65,   0};
+const int8_t kHiddenGruRecurrentWeights[kHiddenLayerWeights] = {
+    65,   83,   35,   56,   24,   -34,  -28,  -2,   125,  19,   42,   -9,
+    124,  -53,  24,   -87,  11,   35,   -81,  -35,  -125, -31,  123,  -21,
+    33,   -91,  113,  -93,  45,   -6,   53,   38,   -92,  8,    -27,  87,
+    4,    43,   43,   10,   -128, -128, -46,  127,  -38,  -45,  25,   -87,
+    19,   5,    52,   -96,  -23,  -29,  121,  -126, -24,  -20,  -2,   69,
+    -50,  6,    71,   -81,  -125, 90,   -94,  1,    -38,  36,   89,   17,
+    -60,  71,   -48,  18,   -15,  44,   -18,  59,   11,   114,  -51,  32,
+    110,  1,    4,    109,  -24,  127,  27,   60,   88,   24,   45,   -59,
+    75,   -36,  8,    57,   -32,  -25,  13,   126,  -89,  -61,  -76,  127,
+    18,   -62,  -68,  23,   -113, 5,    126,  43,   -88,  26,   -78,  18,
+    75,   21,   9,    -74,  20,   41,   126,  -118, -15,  9,    116,  126,
+    -127, 34,   -6,   126,  -128, -53,  -54,  -55,  -121, 70,   127,  -12,
+    -68,  82,   -25,  104,  -126, 126,  -21,  -26,  124,  -75,  -127, -120,
+    13,   61,   -64,  -108, -63,  -65,  -44,  -35,  -61,  -39,  109,  -74,
+    113,  -3,   108,  -30,  125,  120,  39,   125,  -128, -95,  -99,  111,
+    9,    25,   114,  -75,  -92,  -54,  -12,  -32,  -38,  10,   31,   10,
+    63,   51,   40,   -99,  74,   4,    50,   -128, -36,  -35,  -11,  -28,
+    -126, -7,   66,   -58,  -126, -22,  -83,  -61,  -127, 49,   126,  -8,
+    7,    62,   36,   -11,  -32,  -44,  63,   116,  41,   65,   -127, 126,
+    63,   -30,  -96,  74,   -92,  127,  38,   -18,  -128, 68,   -5,   101,
+    -4,   85,   58,   79,   0,    -58,  8,    119,  -70,  -1,   -79,  -68,
+    114,  -28,  -90,  -6,   -112, 2,    127,  -8,   10,   55,   -59,  -126,
+    127,  125,  80,   72,   35,   -54,  95,   -124, -124, 79,   23,   -46,
+    -61,  -127, -100, 99,   -77,  8,    -87,  5,    -2,   49,   85,   7,
+    -71,  82,   53,   -41,  22,   -22,  -93,  -103, 6,    52,   -56,  14,
+    -8,   -111, 85,   16,   54,   32,   -118, -24,  61,   -53,  96,   -70,
+    -5,   -17,  -67,  -84,  -7,   -82,  -107, -96,  21,   -83,  -58,  50,
+    12,   -126, -1,   -28,  34,   -126, 115,  17,   91,   1,    -127, 72,
+    11,   126,  -81,  6,    96,   -8,   77,   15,   -6,   63,   -27,  20,
+    -123, -109, 85,   -79,  -17,  126,  -92,  2,    -61,  20,   14,   17,
+    121,  123,  30,   57,   120,  127,  57,   42,   117,  98,   67,   39,
+    -20,  -70,  100,  7,    125,  122,  40,   16,   -79,  125,  83,   41,
+    -106, -57,  24,   55,   27,   -66,  -111, -44,  -7,   -43,  -66,  121,
+    42,   -128, -45,  35,   15,   -127, 34,   -35,  -34,  -40,  -18,  -6,
+    63,   111,  31,   116,  127,  19,   24,   -71,  -39,  34,   11,   19,
+    -40,  27,   12,   106,  -10,  56,   -82,  -106, -2,   -50,  -52,  114,
+    -126, -34,  -43,  -68,  10,   76,   57,   -118, -128, 37,   -104, 76,
+    125,  3,    -76,  127,  -29,  84,   -94,  -15,  55,   125,  79,   127,
+    -57,  -125, 104,  -68,  126,  126,  -77,  51,   45,   33,   -109, 115,
+    -11,  1,    95,   -121, -5,   -9,   -126, -114, 39,   68,   -126, -107,
+    -51,  -42,  24,   -8,   51,   -27,  -43,  66,   -45,  62,   -98,  -109,
+    69,   67,   0,    -125, -128, 49,   31,   126,  -122, 2,    -55,  -67,
+    -126, -70,  -128, -125, -77,  25,   16,   -8,   -102, 11,   -75,  82,
+    38,   -5,   5,    19,   34,   47,   -127, -93,  21,   24,   -97,  -18,
+    31,   39,   34,   -20,  22,   123,  7,    -77,  -81,  -46,  -9,   1,
+    23,   39,   -127, -43,  -8,   -50,  10,   -21,  59,   -9,   -4,   -13,
+    -27,  44,   127,  52,   -47,  70,   -43,  52,   101,  -49,  27,   45,
+    49,   33,   -125, 55,   114,  20,   -1,   76,   -24,  -96,  105,  24,
+    126,  75,   -21,  -105, 13,   -42,  40,   126,  -30,  -39,  -95,  125,
+    -63,  11,   6,    125,  125,  -14,  5,    42,   -61,  -4,   49,   88,
+    6,    -107, -28,  19,   -29,  47,   126,  6,    -46,  -89,  -18,  91,
+    -20,  -6,   118,  -21,  -22,  39,   115,  11,   -42,  54,   73,   -55,
+    -77,  62,   -27,  -59,  -99,  -12,  -127, -40,  56,   -3,   -124, -91,
+    71,   -111, 6,    -19,  82,   -24,  -35,  102,  -42,  7,    -126, -126,
+    -125, 18,   98,   -52,  127,  105,  -52,  40,   -83,  126,  -122, 109,
+    5,    127,  48,   6,    5,    -125, 100,  -16,  29,   85,   -89,  8,
+    4,    41,   62,   -127, 62,   122,  85,   122,  -107, 8,    -125, 93,
+    -127, 127,  102,  19,   19,   -66,  41,   -42,  114,  127,  -48,  -117,
+    -29,  -6,   -73,  -102, -3,   -19,  0,    88,   42,   87,   -117, -20,
+    2,    122,  28,   63,   71,   66,   120,  93,   124,  -43,  49,   103,
+    31,   90,   -91,  -22,  -126, 26,   -24,  -21,  51,   -126, 87,   -103,
+    -69,  -10,  -66,  -23,  20,   97,   36,   25,   -127, 30,   -20,  -63,
+    30,   51,   -116, 23,   40,   -39,  36,   -83,  -77,  -25,  -50,  110,
+    14,   13,   -109, 125,  -65,  -55,  -87,  124,  -126, -32,  -72,  -108,
+    127,  127,  -125, -124, 61,   121,  102,  -128, -127, 16,   100,  127,
+    -124, -68,  72,   -93,  -128, 43,   -93,  -19,  -125, -97,  -113, -33,
+    83,   127,  -44,  127,  -75,  127,  16,   44,   50,   -122, 23,   118,
+    46,   19,   26,   -128, 10,   4,    99,   -14,  -82,  -13,  30,   125,
+    57,   65,   60,   -71,  35,   98,   28,   7,    1,    43,   89,   70,
+    75,   121,  -59,  82,   -126, -53,  -16,  -116, -65,  52,   -52,  0,
+    80,   35,   45,   -61,  46,   8,    107,  27,   -26,  -118, 90,   57,
+    -10,  7,    -15,  0,    -39,  -4,   12,   29,   -1,   116,  84,   79,
+    119,  125,  -59,  28,   -6,   -25,  -43,  2,    90,   79,   67,   103,
+    -82,  2,    -6,   125,  19,   73,   0,    -105, 112,  -17,  104,  107,
+    124,  106,  19,   56,   -44,  55,   -112, 6,    -39,  -83,  126,  -93,
+    -98,  57,   -120, -23,  -38,  2,    -31,  -48,  106,  127,  127,  69,
+    16,   110,  71,   104,  62,   -12,  -22,  42,   -37,  -94,  34,   -1,
+    -32,  -12,  -124, -47,  -13,  60,   -75,  -66,  58,   -127, -2,   64,
+    76,   -106, 73,   -49,  -31,  127,  126,  31,   16,   127,  -110, 107,
+    -16,  -53,  20,   69,   -14,  -125, 59,   -44,  15,   120,  125,  125,
+    43,   6,    19,   -58,  127,  127,  43,   16,   82,   97,   -127, 127,
+    -93,  -41,  88,   0,    77,   -15,  116,  16,   -124, -31,  -3,   95,
+    -40,  -126, -54,  -126, -83,  -8,   -59,  6,    67,   -29,  4,    124,
+    -10,  112,  -28,  -8,   85,   -21,  45,   84,   6,    -8,   11,   72,
+    32,   84,   -62,  77,   2,    -36,  75,   31,   -50,  116,  126,  119,
+    -88,  -55,  -14,  -37,  126,  40,   -108, -6,   -6,   57,   64,   -28,
+    -76,  30,   -117, -93,  31,   -92,  -44,  -64,  94,   58,   65,   114,
+    41,   47,   71,   42,   -26,  99,   -126, 57,   -5,   74,   -19,  -113,
+    -1,   67,   -21,  126,  1,    -3,   33,   60,   -82,  37,   -48,  89,
+    114,  -38,  127,  -114, 35,   58,   -5,   21,   -46,  121,  -123, -43,
+    127,  115,  123,  122,  -101, 126,  127,  81,   52,   89,   -127, 102,
+    42,   117,  -9,   -2,   125,  127,  110,  96,   120,  66,   70,   124,
+    55,   84,   -38,  -58,  119,  -127, -16,  -79,  123,  18,   -127, -50,
+    -38,  120,  -85,  1,    7,    -56,  108,  -77,  -2,   21,   37,   1,
+    13,   -105, -69,  28,   -87,  33,   -104, -51,  126,  41,   3,    -121,
+    28,   71,   58,   86,   -8,   127,  94,   -55,  125,  40,   -19,  127,
+    -33,  -87,  -23,  7,    -111, -68,  9,    84,   -119, 55,   -82,  78,
+    -37,  -20,  -9,   -23,  53,   -13,  15,   -46,  116,  126,  -127, 56,
+    -126, 125,  -7,   -1,   45,   26,   125,  121,  29,   47,   -86,  30,
+    10,   76,   -125, -7,   23,   92,   -12,  -39,  -18,  92,   -97,  -8,
+    -85,  -41,  49,   -50,  123,  -37,  -126, -30,  14,   79,   -49,  -65,
+    9,    -36,  -38,  -96,  85,   -24,  -13,  37,   -25,  -5,   -64,  -127,
+    55,   -60,  -18,  -61,  -63,  127,  56,   67,   15,   124,  72,   120,
+    127,  40,   -10,  114,  24,   -23,  46,   78,   -53,  125,  86,   124,
+    86,   0,    38,   93,   21,   127,  123,  75,   -72,  13,   48,   33,
+    83,   -51,  15,   -32,  -49,  -33,  120,  64,   7,    9,    65,   60,
+    21,   -21,  -61,  -53,  -113, 84,   -97,  101,  37,   -114, -27,  41,
+    73,   126,  -10,  59,   61,   -15,  70,   -13,  82,   -4,   69,   56,
+    94,   -91,  -50,  92,   -74,  -48,  53,   -7,   -107, 127,  28,   30,
+    -26,  -21,  -61,  77,   82,   64,   -91,  -125, 122,  -104, 127,  123,
+    122,  123,  76,   -126, 127,  -6,   -80,  7,    40,   -66,  -65,  54,
+    -2,   23,   96,   -64,  74,   2,    -53,  -12,  -123, 39,   60,   -20,
+    16,   -17,  -97,  23,   -4,   -53,  -122, 32,   -16,  -54,  -95,  43,
+    71,   -1,   -67,  -33,  41,   18,   72,   28,   -83,  31,   -100, -91,
+    -27,  10,   -128, -106, 2,    76,   -13,  42,   34,   112,  -19,  44,
+    40,   -9,   -11,  65,   92,   -43,  -125, 2,    47,   -32,  25,   122,
+    -29,  12,   101,  -8,   -126, -23,  43,   7,    125,  -20,  -124, 82,
+    -2,   13,   -73,  -106, 115,  31,   116,  -23,  -44,  -71,  84,   3,
+    47,   91,   127,  127,  -15,  95,   7,    93,   5,    113,  -50,  54,
+    11,   13,   -127, 17,   72,   43,   -23,  5,    -70,  20,   15,   -27,
+    99,   69,   -109, -122, -94,  16,   127,  0,    116,  104,  45,   108,
+    -34,  87,   72,   -14,  118,  46,   42,   109,  -26,  95,   93,   127,
+    60,   127,  -93,  -54,  -122, 34,   -105, 56,   55,   103,  125,  -71,
+    -50,  95,   -72,  127,  107,  21,   73,   126,  61,   127,  127,  24,
+    -62,  90,   73,   90,   -46,  -78,  -124, 72,   123,  -42,  50,   -107,
+    17,   -32,  -62,  -89,  124,  1,    80,   -2,   117,  119,  -65,  -127,
+    -95,  -121, -52,  103,  66,   75,   -3,   -62,  -127, 127,  -74,  124,
+    79,   49,   40,   105,  -67,  -71,  -70,  43,   127,  119,  -4,   66,
+    43,   23,   91,   -126, 15,   63,   -119, 112,  103,  15,   -99,  31,
+    -127, 69,   116,  -46,  -67,  2,    -126, -29,  30,   30,   -69,  -98,
+    -47,  -87,  -70,  -127, 23,   -73,  30,   -7,   94,   -52,  -65,  98,
+    -45,  97,   53,   23,   -9,   -22,  -52,  -47,  6,    -1,   -85,  -15,
+    -61,  -14,  68,   110,  -10,  -121, -25,  -35,  -15,  -94,  -123, 27,
+    75,   48,   -66,  -56,  -44,  93,   109,  67,   -36,  24,   70,   -126,
+    8,    -127, 126,  52,   11,   -32,  120,  -13,  -26,  -28,  -125, 127,
+    106,  -50,  124,  36,   -126, -12,  0,    -23,  76,   -71,  -126, -12,
+    -17,  -82,  12,   124,  57,   33,   4,    77,   -46,  71,   -34,  72,
+    125,  -128, 124,  -24,  -128, 75,   -120, 69,   -45,  55,   33,   127,
+    -33,  4,    -105, -41,  -59,  -91,  123,  44,   -127, 127,  -67,  52,
+    25,   -125, -65,  100,  -25,  123,  6,    11,   -123, -92,  -33,  126,
+    -17,  -4,   29,   33,   127,  96,   3,    87,   -48,  -18,  -70,  123,
+    58,   -127, -3,   -52,  -1,   -36,  -41,  127,  51,   -52,  -27,  46,
+    -83,  57,   9,    126,  127,  94,   79,   -37,  -127, -40,  67,   52,
+    82,   -66,  122,  -13,  -73,  127,  -8,   -80,  46,   -48,  4,    -54};
+const int8_t kHiddenGruBias[kHiddenLayerBiases] = {
+    124, 125, -57, -126, 53,  123, 127,  -75, 68,  102, -2, 116,
+    124, 127, 124, 125,  126, 123, -16,  48,  125, 126, 78, 85,
+    11,  126, -30, -30,  -64, -3,  -105, -29, -17, 69,  63, 2,
+    -32, -10, -62, 113,  -52, 112, -109, 112, 7,   -40, 73, 53,
+    62,  6,   -2,  0,    0,   100, -16,  26,  -24, 56,  26, -10,
+    -33, 41,  70,  109,  -29, 127, 34,   -66, 49,  53,  27, 62};
+const int8_t kOutputDenseWeights[kOutputLayerWeights] = {
+    127,  127,  127, 127,  127,  20,  127,  -126, -126, -54, 14,  125,
+    -126, -126, 127, -125, -126, 127, -127, -127, -57,  -30, 127, 80};
+const int8_t kOutputDenseBias[kOutputLayerOutputSize] = {-50};
+}  // namespace rnnoise
diff --git a/third_party/webrtc_aec3/src/third_party/rnnoise/src/rnn_vad_weights.h b/third_party/webrtc_aec3/src/third_party/rnnoise/src/rnn_vad_weights.h
new file mode 100644
index 0000000..1a75bc6
--- /dev/null
+++ b/third_party/webrtc_aec3/src/third_party/rnnoise/src/rnn_vad_weights.h
@@ -0,0 +1,29 @@
+#ifndef THIRD_PARTY_RNNOISE_SRC_RNN_VAD_WEIGHTS_H_
+#define THIRD_PARTY_RNNOISE_SRC_RNN_VAD_WEIGHTS_H_
+#include <cstdint>
+#include <cstring>
+namespace rnnoise {
+// Weights scaling factor.
+const float kWeightsScale = 1.f / 256.f;
+// Input layer (dense).
+const size_t kInputLayerInputSize = 42;
+const size_t kInputLayerOutputSize = 24;
+const size_t kInputLayerWeights = kInputLayerInputSize * kInputLayerOutputSize;
+extern const int8_t kInputDenseWeights[kInputLayerWeights];
+extern const int8_t kInputDenseBias[kInputLayerOutputSize];
+// Hidden layer (GRU).
+const size_t kHiddenLayerOutputSize = 24;
+const size_t kHiddenLayerWeights =
+    3 * kInputLayerOutputSize * kHiddenLayerOutputSize;
+const size_t kHiddenLayerBiases = 3 * kHiddenLayerOutputSize;
+extern const int8_t kHiddenGruWeights[kHiddenLayerWeights];
+extern const int8_t kHiddenGruRecurrentWeights[kHiddenLayerWeights];
+extern const int8_t kHiddenGruBias[kHiddenLayerBiases];
+// Output layer (dense).
+const size_t kOutputLayerOutputSize = 1;
+const size_t kOutputLayerWeights =
+    kHiddenLayerOutputSize * kOutputLayerOutputSize;
+extern const int8_t kOutputDenseWeights[kOutputLayerWeights];
+extern const int8_t kOutputDenseBias[kOutputLayerOutputSize];
+}  // namespace rnnoise
+#endif  // THIRD_PARTY_RNNOISE_SRC_RNN_VAD_WEIGHTS_H_
